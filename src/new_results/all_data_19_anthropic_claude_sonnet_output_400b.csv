reviews,sentiment_scores,politeness_scores,reasonings
"['The major contribution of this work is extending routing networks (Rosenbaum et al., ICLR 2018) to use diverse architectures across routed modules. I view this as an important contribution and am very impressed by the experiment on Omniglot where it shows big performance gain on a split with very few examples. This idea of incorporating in architectural bias and not just parameter bias for small data problems is very compelling and intuitive to me on the surface. The ablation study was also very interesting in this regard. I really like the discourse and found it to be filled with interesting insights throughout ranging from the connection between routing networks and neural architecture search to the heuristic for selecting k.  However, after the great discourse, I was quite disappointed by the breadth of the experiments. \n\nThe paper is positioned as exploring two parallel ideas that are independently interesting 1) diversity in the architecture of modules in routing models 2) the effect of increasing depth in routing models. For the first idea, this is shown very well by the Omniglot experiment but is not evaluated in any other setting. Showing this in a few other experiments would have really driven this point home in my opinion.  The second idea is not really executed in a convincing way to me. The authors call it a ‘negative result’ in the end, but I’m not sure I really feel like I learned anything from this experiment. I wonder about statistical significance. I also feel like the authors are trying to turn it into a commentary that this is a pain point for all variants of routing models while they only actually tried it for their proposed architecture which makes quite a few decisions along the way. I would have liked to see more model variants and datasets before really feeling like I can make any empirical determinations about the fundamental limitations of all routing models in this regard.  Additionally, if there were such a fundamental scaling limitation, you would imagine that an experiment could be constructed that really highlighted this fact where all routing models do way worse.\n\nIn short, I think there are some really good idea in this paper and vote for acceptance on that basis. Had the authors provided more empirical evidence about architectural diversity, I would have given it a very high score. The analysis of depth is also a very interesting topic, but it could possibly even serve as another paper considering that the current results don’t really come to concrete conclusions for the community. \n', 'Overall, this is a valuable read. Authors tackle the head on problem of what is a good architecture where we can having routing with diverse models. The papers is written well, with comparisons to mixture of experts, other models that tackled this problem with either homogeneous architectures or static architectures. Below is my assessment on various axis:\n\nQuality - Enough experiments to justify some conclusions, equations helped ground the method with math.\n\nclarity - Very well written, good figures and analysis.\n\noriginality - While the authors achieve SOA results on OmniGlot and do explore a few options, I feel the work still lacks originality in the formulation or does not have original contributions to either the architectures used or the optimization procedures employed.\n\nsignificance - very significant to look at this problem both in terms of compute, accuracy perspective as well as scaling these networks for multiple tasks.\n\npros - thorough analysis, even the negative experiments are well written and throw more light into the problem space.\n\ncons - OmniGlot comparisons seem not fair as the model capacity is not added as part of the table which raises concerns on achieving state of the art with more high complexity models than routing mechanism. Will be great to move from CIFAR-10 and test things on CIFAR-100 to really see the value of proposed work. I would recommend a higher rating if authors address these two concerns.', 'The paper ""Diversity and Depth in Per-Example Routing Models"" extends previous work on routing networks by adding diversity to the type of architectural unit available for the router at each decision and by scaling to deeper networks. They evaluate their approach on Omniglot, where they achieve state of the art performance.\n\nOverall, the paper is very well written and every aspect can be easily understood. The overview over related work given in the paper is thorough, and the authors explain very well how their approach relates to previous approaches.\n\nThe architecture presented is a natural and important extension of previous work. Adding diversity in routing units has indeed not been investigated well and is an important contribution to the community. Additionally, the authors do a good job of identifying problems with existing approaches (overfitting, routing depth) and offer a empirically convincing solutions. \n\nThe result section given in the paper is its weakness and requires a more in-depth analysis:\n+ the results given for Omniglot are impressive\n+ the experiments analyzing the impact of diversity and routing depth are interesting and offer interesting insight into the architecture\n- the results do not show learning behavior over epochs; this is not necessary, but would give an additional insight into the learning behavior of the architecture\n- the experimental settings are confusing: why are the different experiments performed with different datasets? This makes it seem as if the authors cherry-picked the best results for the different experiments (this might not be the case, but the results on Omniglot alone are good enough that negative results and a detailed discussion of them would not have hurt the paper, but enriched the discourse)\n- additional experiments that offer a transition from larger datasets to smaller ones would be interesting; seeing how the performance of the architecture behaves e.g. on CIFAR10 for 1k, 5k, 10k, 25k and 50k would have illustrated how well the architecture is able to generalize from different numbers of samples\n\nIn summary, I think the paper analyzes a very important problem and has a lot of potential. However, it needs more extensive experiments that illustrate how the proposed architecture behaves over a wider variety of datasets.\n\nUPDATE AFTER REBUTTAL:\nI am still torn about this paper. On one hand, I still think that the topic and discourse provided by this paper is extremely important. On the other, the results - even after the revision - do not completely convince me. I might update my score after some discussion with the other reviewers.\n2ND UPDATE:\nAfter giving it some more thought, I find myself convinced that this paper has a contribution important enough to be accepted. I increase my score to 7.']","[50, 60, 60]","[80, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses both positive and negative opinions. They are impressed by the main contribution and find the ideas compelling, but are disappointed by the limited breadth of experiments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper while offering constructive criticism. They use phrases like 'I really like', 'very interesting', and 'I would have liked to see' which maintain a polite tone even when expressing concerns. The reviewer also balances criticism with positive feedback and provides specific suggestions for improvement, which is a polite approach to peer review."", ""The sentiment score is 60 (positive) because the reviewer starts with 'Overall, this is a valuable read' and mentions several positive aspects like 'well written', 'good figures and analysis', and 'thorough analysis'. However, it's not extremely positive due to some criticisms, particularly about originality and fairness of comparisons. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively (e.g., 'Will be great to move from CIFAR-10...'). The reviewer also uses phrases like 'I feel' and 'I would recommend' which soften the critique. The high level of detail and balanced approach in the review also contribute to its politeness."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive views about the paper, praising its writing quality, thoroughness, and importance of the topic. They mention that the paper is 'very well written' and offers a 'natural and important extension of previous work'. However, they also point out some weaknesses in the results section, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance praise with criticism, using phrases like 'the paper analyzes a very important problem' while also offering specific suggestions for improvement. The reviewer's willingness to update their opinion after the rebuttal and further reflection also demonstrates a polite and fair approach.""]"
"['The paper proposes a method for learning regression models through evolutionary\nalgorithms that promise to be more interpretable than other models while\nachieving similar or higher performance. The authors evaluate their approach on\n99 datasets from OpenML, demonstrating very promising performance.\n\nThe authors take a very interesting approach to modeling regression problems by\nconstructing complex algebraic expressions from simple building blocks with\ngenetic programming. In particular, they aim to keep the constructed expression\nas small as possible to be able to interpret it easier. The evaluation is\nthorough and convincing, demonstrating very good results.\n\nThe presented results show that the new method beats the performance of existing\nmethods; however, as only very limited hyperparameter tuning for the other\nmethods was performed, it is unclear to what extent this will hold true in\ngeneral. As the main focus of the paper is on the increased interpretability of\nthe learned models, this is only a minor flaw though.\n\nThe interpretability of the final models is measured in terms of their size.\nWhile this is a reasonable proxy that is easy to measure, the question remains\nto what extent the models are really interpretable by humans. This is definitely\nsomething that should be explored in future work, as a small-size model does not\nnecessarily imply that humans can understand it easily, especially as the\ngenerated algebraic expressions can be complex even for small trees.\n\nThe description of the proposed method could be improved; in particular it was\nunclear to this reviewer why the features needed to be differentiable and what\nthe benefit of this was (i.e. why was this the most appropriate way of adjusting\nweights).\n\nIn summary, the paper should be accepted.', ""This paper introduces a genetic algorithm that maintains an archive of representations that are iteratively evolved and selected by comparing validation error. Each representation is constructed as a syntax tree consists of elements that are common in neural network architectures. The experimental results showed that their algorithm is competitive to the state-of-the-art while achieving much smaller model size.\n\nComments:\n1. I think this paper lacks technical novelty. I'm going to focus on experimental result in the following two questions.\n2. FEAT is a typical genetic algorithm that converges slowly. In the appendix, one can verify that FEAT converges at least 10x slower than XGBoost. Can FEAT achieve lower error than XGBoost when they use the same amount of time? \nCan the authors provide a convergence plot of their algorithm (i.e. real time vs test error)?\n3. From Figure 3 it seems that the proposed algorithm is competitive to XGBoost, and the model size is much smaller than XGBoost. Have the authors tried to post-processing the model generated by XGBoost? How's the performance compare?"", '# Summary\nThe paper presents a method for learning network architectures for regression tasks. The focus is on learning interpretable representations of networks by enforcing a concise structure made from simple functions and logical operators. The method is evaluated on a very large number of regression tasks (99 problems) and is found to yield very competitive performance.\n\n# Quality\nThe quality of the paper is high. The method is described in detail and differences to previous work are clearly stated. Competing methods have been evaluated in a fair way with reasonable hyperparameter tuning.\n\nIt is very good to see a focus on interpretability. The proposed method is computationally heavy, as can be seen from figure 7 in the appendix, but I see the interpretability as the main benefit of the method. Since many applications, for which interpretability is key, can bear the additional computational cost, I would not consider this a major drawback. However, it would be fair to mention this point in the main paper.\n\n# Clarity\nThe paper reads well and is nicely structured. The figures and illustrations are easy to read and understand.\n\n# Originality\nThe paper builds on a large corpus of previous research, but the novelties are clearly outlined in section 3. However, the presented method is very far from my own field of research, so I find it difficult to judge exactly how novel it is.\n\n# Significance\nThe proposed method should be interesting to a wide cross-disciplinary audience and the paper is clearly solid work. The focus on interpretability fits well with the current trends in machine learning. However, the method is far from my area of expertise, so I find it difficult to judge the significance.\n']","[80, -20, 80]","[70, 20, 90]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'very interesting,' 'thorough and convincing,' and recommending acceptance. They highlight the promising performance and increased interpretability of the proposed method. The few criticisms mentioned are presented as minor or as suggestions for future work. The politeness score is 70 (polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'very interesting approach' and 'thorough and convincing,' which are polite ways to express approval. Even when pointing out potential improvements, the reviewer maintains a courteous tone, using phrases like 'could be improved' rather than more direct criticism. The overall language is professional and considerate throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (competitive results, smaller model size), they express concerns about the lack of technical novelty and the algorithm's slow convergence. The overall tone suggests skepticism rather than enthusiasm. The politeness score is mildly positive (20) as the reviewer uses neutral language and phrases their criticisms as questions or suggestions rather than harsh statements. They also begin with a neutral summary of the paper before moving into their concerns, which is a polite approach. However, the directness of the statement 'I think this paper lacks technical novelty' slightly reduces the politeness score."", ""The sentiment score is 80 (positive) because the review is overwhelmingly positive. The reviewer describes the paper as 'high' quality, praises its focus on interpretability, and notes that it 'reads well' and is 'nicely structured'. The only slight criticism is about computational heaviness, but this is not considered a major drawback. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise generously (e.g., 'It is very good to see...', 'The paper reads well...') and frame their one suggestion for improvement very gently ('it would be fair to mention...'). The reviewer also humbly acknowledges when certain aspects are outside their expertise, which adds to the polite tone.""]"
"['Quality: This submission claims to present a model that can control non-annotated attributes such as speaking style, accent, background noise, etc. Though empirical evidence in the form of numerical measurements is presented for some controllable attributes more evidence other than individual samples and authors claims is needed. For example a reliable numerical evidence is needed on page 4 following ""We also found..."", page 5 following ""We discovered...."", page 5 following ""It clearly presents..."", page 5 following ""Drawing samples..."" evidence is given only for 1 dimension, page 6 following ""Figure 7(b)..."". \n\nClarity: The model is simple though the exact form and nature of observed and latent class variables could be made more explicit. Including how they are computed/initialised/set. What are different modes using the proposed model? Why both negative results are in the appendix? \n\nOriginality: moderately\n\nSignificance: moderately\n', 'This paper proposes a two layer latent variable model to obtain disentangled latent representation, thus facilitates fine-grained control over various attributes including noise level, speaker rate etc.\n\nDetailed comments:\n\ni) This work is closely related to Akuzawa et al. (2018). The difference is not properly discussed. \n\nii) In the abstract, “end-to-end text-to-speech” is an unfortunate claim, because the proposed system has two separately trained component: 1) a text to mel-spectrogram model based on Tacotron and, 2) a WaveRNN for waveform synthesis.  In ASR, it’s absolutely fine to claim a spectrogram to text model as a end-to-end system, because the wave to spectrogram step is trivial.  In TTS, waveform synthesis is a very crucial step and largely determines the final naturalness results. \n\niii) In experiment, one need include the MOS score of ground truth for comparison or debiasing.\n\niv) Did you try different values of D other than 16? When you check the meaning of different dimensions, how many dimensions are meaningful? How many are meaningless, or even just dummy?\n\nIn summary,  \npros:\n- A good work with impressive results.\ncons:\n- Related work need to be properly discussed. \n- Doesn’t include the MOS of ground truth.\n- Moderate novelty. ', 'The authors describe the conditioned GAN model to generate speaker conditioned Mel spectra. They augment the z-space corresponding to the identification with latent variables that allow a richer set of produced audio. In a way this is like a partially conditioned model that has ""extra"" degrees of freedom. It looks that the ""latent"" variables are just concaneted to the ""original"" set of z-values (altough with particular conditions to maximize independence). The conditioning of the z-space has originality in it and may provide interesting to the audience. Ultimately one coud think about z-space direction being totally mapped to specific features of the produced signal.\n\nAlso, I am curious to know how the Mel spectra are used to produce the actual sound wave - as the phase information is not present if utilizing only the spectral amplitude. Very often this leads to suboptimal generation, and the remedy is to use the time domain like in ( https://arxiv.org/ftp/arxiv/papers/1810/1810.05319.pdf).  However, in this case the audio samples show a pretty nice generation of sound.  However, it is not really end to end.\n\nThe manuscript has some curious decisios in its concepts - I do not see the architecture really hiearchial, nor end to end. I would prefer modifications on the paper that concentrate on the truly novel features. \n\nThe paper is clear, well written and done with high ambition, from data set utilization  to novel architetures to human quality panels. Results are good and interesting.\n\nNEW:\nThe authors have addressed the concerns I had with the manuscript.\n\n\n\n']","[-30, 50, 70]","[20, 60, 80]","[""The sentiment score is slightly negative (-30) because the reviewer expresses several criticisms and requests for additional evidence, using phrases like 'more evidence other than individual samples and authors claims is needed' and 'reliable numerical evidence is needed'. However, it's not extremely negative as the reviewer also notes some positive aspects like 'empirical evidence in the form of numerical measurements is presented for some controllable attributes'. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, avoiding harsh language. They use neutral phrases like 'This submission claims' and 'Could be made more explicit' rather than directly criticizing the authors. The reviewer also balances critiques with some positive comments, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the paper as 'a good work with impressive results' in the summary, but also lists several cons and areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 60 (moderately polite) because the reviewer uses neutral language and provides specific, constructive feedback without using harsh or dismissive terms. The reviewer points out both pros and cons in a balanced manner, and phrases suggestions as questions or observations rather than direct criticisms."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, noting its originality, clarity, and good results. They mention that the authors have addressed their previous concerns, which is a strong positive indicator. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and expressing curiosity rather than criticism. They offer suggestions for improvement in a constructive manner. The reviewer's tone is professional and courteous, avoiding harsh or dismissive language even when pointing out areas for potential modification.""]"
"['This paper introduces a generative model for question answering.  Instead of modeling p(a|q,c), the authors propose to model p(q,a|c), factorized as p(a|c) * p(q|a,c).  This is a great idea, it was executed very well, and the paper is very well written.  I\'m glad to see this idea implemented and working.                                                       \n                                                                                                     \nReactions:                                                                                           \n- Section 2.1: Is there a bias problem here, where you\'re only ever training with the correct answer?  Oh, I see you covered that in section 2.6.  Great.\n- Section 2.4: what happens when there are multiple QA pairs per paragraph or image?  Are you just getting conflicting gradients at different batches, so you\'ll end up somewhere in the middle of the two answers?  Could you do better here?\n- Section 2.6: The equation you\'re optimizing there reduces to -log p(a|q,c), which is exactly the loss function used by typical models.  You should note that here.  It\'s a little surprising (and interesting) that training on this loss function does so poorly compared to the generative training.  This is because of how you\'ve factorized the distributions, so the model isn\'t as strong a discriminator as it could be, yes?\n- Section 3.1 (and section 2.6): Can you back up your claim of ""modeling more complex dependencies"" in the generative case?  Is that really what\'s going on?  How can we know?  What does ""modeling more complex dependencies"" even mean?  I don\'t think these statements really add anything currently, as they are largely vacuous without some more description and analysis.\n- Section 3.3: Your goal here seems similar to the goal of Clark and Gardner (2018), trying to correctly calibrate confidence scores in the face of SQuAD-like data, and similar to the goals of adding unanswerable questions in SQuAD 2.0.  I know that what you\'re doing isn\'t directly comparable to either of those, but some discussion of the options here for addressing this bias, and whether your approach is better, could be interesting.\n                                                                                                     \nClarity issues:                                                                                      \n- Bottom of page 2, ""sum with a vector of size d"" - it\'s not clear to me what this means.            \n- Top of page 3, ""Answer Encoder"", something is off with the sentence ""For each word representation"" \n- Section 2.5, ""we first embed words independently of the question"" - did you mean ""of the _context_""?\n- Section 2.5.2 - it\'s not clear to me how that particular bias mechanism ""allows the model to easily filter out parts of the context which are irrelevant to the question"".  The bias mechanism is independent of the question.\n- Section 2.7 - when you said ""beam search"", I was expecting a beam over the question words, or something.  I suppose a two-step beam search is still a beam search, it just conjured the wrong image for me, and I wonder if there\'s another way you can describe it that better evokes what you\'re actually doing.\n- Section 3.1 - ""and are results..."" - missing ""competitive with""?                                   \n- Last sentence: ""we believe their is"" -> ""we believe there is"" ', 'In this paper, authors proposed a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context. More specifically, it is decomposed into two components: the distributions of answers given a document, which is modeled by a single layer neural network; and the distribution of questions given an answer and document, which is modeled by a seq2seq model with a copy mechanism. During inference, it firstly extracts the most likely answer candidates, then evaluates the questions conditioned on the answer candidates and document and finally returns the answer with the max joint score from two aforementioned components.\n\n\nPros: \nThe paper is well written and easy to follow. \n\nThe ideas are also very interesting. \n\nIt gives a good ablation study and shows importance of each component in the proposed model.\n\n\nCons:\nThe empirical results are not good. For example, on the SQuAD dataset, since the proposed model also used ELMo (the large pre-trained contextualized embedding), cross attentions and self-attentions, it should be close or better than the baseline BiDAF + Self Attention + ELMo. However, the proposed model is significantly worse than the baseline (83.7 vs 85.6 in terms of F1 score). From my experience of the baseline BiDAF + Self Attention + ELMo, it obtains 1 more point gain if you fine tune the models.  On CLEVER dataset, I agree that incorporating with MAC cells will help the performance.\n\nIn Table 1, it should be clear if the authors could category those models into with/without ELMo for easy compassion. Furthermore, it is unclear how the authors select those baselines since there are many results on the SQuAD leaderboard. For example, there are many published systems outperformed e.g., RaSOR. \n\nQuestions:\nDuring inference, generating answer candidates should be important. How the number of candidate affects the results and the inference time? \n\nIn SQuAD dataset, its answers often contain one or two tokens/words. What is the performance if removed length of answer feature?\n\nDuring the fine turning step, have you tried other number of candidates?   ', 'This paper proposes a generative approach to textual QA on SQUAD and visual QA on CLEVR dataset, where, a joint distribution over the question and answer space, given the context (image or Wikipedia paragraphs) is learned (p(q,a|c)). During inference the answer is selected by argmax p(q,a|c) that is equal to p(a|c,q) if the question is given. Authors propose an architecture shown in Fig. 3 of the paper, where generation of each question word is condition on the corresponding answer, context and all the previous words generated in the question so far. The results compared to discriminative models are worse on SQUAD and CLEVR. Nevertheless, authors show that given the nature of the model that captures more complex relationships, the proposed model performs better than other models on a subset of SQUAD that they have created based on answer type (number/date/people), and also on adversarial SQUAD. \n\nComments / questions:\n\nThe paper is well written, except for a few parts mentioned below, all the equations / components are explained clearly. The motivation of the paper is clearly stated as using generative modelling in (V)QA to overcome biases in these systems, e.g., answering questions by just using word matching and ignoring the context (context=image or Wikipedia paragraph). I have the following questions / comments about the paper which addressing them by authors will help to better understand/evaluate the paper:\n1.\tIn page 3 on the top of section 2.3, can authors provide a more clear explanation of the additional 32-dimensional embedding added to each word representation? Also in Table 2, please add an ablation how much gain are you getting from this?\n2.\tIn the same page (page 3), section 2.4, paragraph 2, put the equation in a separate line and number it + clearly explain how you have calculated s^{endpoints} and s{length}.\n3.\tIn page 4 section 2.5.2 paragraph 2, the way the bias term is calculated and the incentive behind it is not clear. Can authors elaborate on this?\n4.\tIn page 6 section 3.2 the first paragraph authors claim that their model is performing multihop reasoning on CLEVR, while there is no explicit component in their model to perform multiple rounds of reasoning. Can authors clarify their statement? \n5.\tIn section 3.3 the third paragraph, where authors explain the question agnostic baselines, can they clarify what they mean by “the first answer of the correct type”? \n6.\tIn Table 5 and section 3.4 the second paragraph, authors are stating that “… The improvement may be due to the model’s attempt to explain all question words, some of which may be unlikely under the distractor”. It is very important that the authors do a complete ablation study similar to that of Table 2 to clarify how much gain is achieved using each component of generative model. \n7.\tIn page 8 under related works: \na.\tIn paragraph 2 where authors state “Duan et al. (2017) and Tang et al. (2017) train answering and generation models with separate parameters, but add a regularisation term that encourages the models to be consistent. They focus on answer sentence selection, so performance cannot easily be compared with our work.”. I do not agree that the performance can not be compared, it is easily comparable by labeling a sentence containing the answer interval as the answer sentence. Can authors provide comparison of their work with that of Duan et al. (2017) and Tang et al. (2017)?\nb.\tIn the same paragraph as 7.a, the authors have briefly mentioned “Echihabi & Marcu (2003) describe an earlier method for answering questions in terms of the distribution of questions given answers.” Can they provide a more clear explanation of this work and its relation to / difference with their work? \n\n////////////\nI would like to thank authors for providing detailed answers to my questions. After reading their feedback, I am now willing to change my score to accept. ']","[80, -20, 80]","[70, 60, 90]","[""The sentiment score is 80 because the reviewer starts with very positive comments, calling the paper's idea 'great', saying it was 'executed very well', and that the paper is 'very well written'. They express gladness to see the idea implemented. The rest of the review provides constructive feedback and suggestions, which is typical for peer reviews even when the overall sentiment is positive. The politeness score is 70 because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions rather than direct criticisms, and acknowledges when the authors have addressed potential issues. The reviewer also uses phrases like 'Could you do better here?' and 'some discussion... could be interesting' which are polite ways of suggesting improvements. The score is not higher because the tone is professional rather than overtly polite, and there are a few direct corrections of errors."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some positives ('well written', 'interesting ideas', 'good ablation study'), they express significant concerns about the empirical results being 'not good' and worse than baselines. The reviewer also points out several areas for improvement and asks critical questions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions or questions rather than harsh judgments. The reviewer maintains a professional tone while still clearly communicating areas of concern."", ""The sentiment score is 80 (positive) because the reviewer starts by acknowledging the paper is well-written and clearly motivated. They provide constructive feedback and questions, and ultimately state they are willing to change their score to 'accept' after receiving answers from the authors. The politeness score is 90 (very polite) due to the respectful tone throughout. The reviewer uses phrases like 'can authors provide', 'please add', and 'I would like to thank authors', which are courteous ways of making requests and expressing gratitude. They also frame their comments as questions or suggestions rather than demands, further contributing to the polite tone.""]"
"[""This paper first identifies an inequivalence between L2 regularization and the original weight decay in adaptive stochastic gradient methods, e.g., the Adam method, and then proposes two decoupled variants, SGDW and AdamW, respective. The authors also cited a recent work to provide a justification of their proposed update rules from the perspective of Bayesian filtering. To demonstrate the effectiveness of both methods, experiments on CIFAR10 and ImageNet32x32 are conducted to compare with the original methods. Results show that the proposed methods consistently lead to faster convergence. Overall the paper is well written and easy to follow, with enough details describing the experimental settings. \n\nFirst of all I appreciate the authors pointing out that weight decay is not equal to L2 regularization in general. This is evident once the original definition of weight decay is given. The main motivation comes from the argument that instead of using L2 regularization, weight decay should be used in adaptive gradient methods. The Bayesian filtering interpretation helps to justify the proposed method. But it is not clear to me why the hyperparameters w and \\alpha are decoupled in the proposed methods? For example, in Line 6 of Alg. 1, g_t is a function of w, and later in Line 8, g_t is coupled with \\alpha which naturally introduces a term w \\alpha into m_t. So both w and \\alpha are still coupled together in the proposed algorithm. If this is the case why the authors still call w and \\alpha decoupled? \n\nTo me the most interesting result is Proposition 3 where the authors show that weight decay actually corresponds to preconditioned L2 regularization. This helps to explain what's the algorithmic difference between these two methods in adaptive gradient methods, and provides an intuitive insight on why weight decay may lead to better results compared with the vanilla L2 regularization. \n\nExperiments on image recognition tasks basically confirm the authors' claims. However, as the authors have already pointed out, it is better to have more thorough experiments on other kinds of tasks, e.g., in text classification, etc. If the improvement does come from the difference between weight decay vs L2, then I would also expect the same improvement on other tasks. It would be great to see more experimental results on other tasks to have a better understanding of this problem. So far it is not clear whether the same improvement holds in general or not. \n"", ""This review has been somewhat challenging to complete. As the authors write, this work has already been impactful and motivated a great deal of further research. The empirical evaluation is convincing and the results have been reproduced and further studied by others. A moderate amount of space in the paper (Section 3, Section 4.5) is used to refer to work motivated by the paper itself. While I do not take issue with this I believe it should be considered for the final decision (in the sense that disentangling the contributions of the authors and related work becomes tricky). With this said, I continue with my review.\n\nPaper summary: The authors observe that L2 regularization is not effective when using the Adam optimizer. By replacing L2 regularization with decoupled weight decay the authors are able to close the generalization gap between SGD and Adam and make Adam more robust to hyperparameter settings. The empirical evaluation is comprehensive and convincing.\n\nDetailed comments:\n\n1) The authors emphasize the fact that L2 regularization and weight decay are not the same for different optimizers and claim that this goes against the belief of some practitioners. In my experience, most practitioners would not be surprised by this observation itself. The second observation made by the authors, that L2 regularization is not effective in Adam, is the more interesting (and perhaps surprising) observation.\n\n2) I am not convinced of the importance of Proposition 3. In practice, adaptive methods will have a preconditioner which depends locally on the parameters. I understand the motivation from the previous paragraph but felt that the formal result added little.\n\n3) Section 3 introduced the Bayesian filtering perspective of stochastic optimization. The authors share the observation of Aitchison, 2018 that decoupled weight decay can be recovered in this framework. My interpretation is that this observation is important _because_ of the empirical observations in this paper and does not necessarily provide theoretical support for the approach. However, the last paragraph of Section 3 seems to utilize the Bernstein-von Mises theorem to promote the idea that with large datasets the prior distribution is unimportant (and is ignored). I am not sure that I follow this argument. For example, this claim seems to be completely independent of the optimization algorithm used and moreover Propositions 1,2, and 3 are independent of the data distribution. I suspect that this confusion is due to a misunderstanding on my part and would appreciate clarification from the authors.\n\n4) The empirical evaluation in this paper is very strong and these practical techniques have already been adopted by the community in addition to spurring novel research. The empirical observation broadly explores two directions: decoupled weight decay leads to separable hyperparameter search spaces (meaning optimization is less sensitive to hyperparameters), and decoupled weight decay gives improved generalization (and training performance). Both claims are explored throughly with strong evidence given for the improvement due to AdamW.\n\nOverall, I find this paper to be presented well and with convincing empirical results. I feel that the theoretical justification for decoupling weight decay are a little weak, and believe that other work is moving towards better explanations then the ones presented in this paper [1,2,3]. Despite this, I believe that this paper should be accepted.\n\n\nMinor comments:\n\n- I find the notation in the paper confusing in general. x is used to denote weights, and w to denote hyperparameters (e.g. w' for L2 regularization scale and w for weight decay scale). I don't see why it wouldn't be preferable to use the more standard W for weights, x for inputs, and lambda for hparams.\n- Figure 4: it is difficult to distinguish between Adam and SGDWR (especially left).\n\n\n\nClarity: The paper is well written and clear. I find the notation confusing in places, but is consistent throughout.\n\nOriginality: This paper presents original findings but occasionally relies on work motivated by itself to convince the reader of its importance. I do not think that this subtracts from the value of the work.\n\nSignificance: The work is clearly significant. Even without knowing that practitioners have adopted the techniques presented in this work, the paper clearly distinguishes itself with strong empirical results."", 'In this paper, the authors investigate a very simple but still very interesting idea of decoupling weight decay and gradient step. It is a well known problem that Adam optimization method leads to worse generalization and stronger overfitting than SGD with momentum on classification tasks despite its faster convergence. The authors tried to find a reason for such behavior. They noticed that while SGD with L2 regularization is equivalent to SGD with weight decay, it is not the case for adaptive methods, such as Adam. The main contributions include the following:\n1.  Improvement of Adam method via decoupling weight decay and optimization step and using warm restarts. The authors thoroughly investigated the proposed idea on different learning rate schedules and different datasets. It would also be interesting to see results on architectures other than ResNet. In section 4.5 the authors claim that the proposed idea was used in different settings by many authors. So, I would recommend to elaborate on this section in the final version of the paper.\n2.  Reducing sensitivity of SGD to weight decay parameter. The authors noticed that the optimal weight decay parameter depends on the number of training epochs, therefore they proposed a functional form of dependency between weight decay and the number of batch passes. \n\nI also have the following concerns:\n1. One of the main advantages of Adam is the speed of convergence. Does AdamW or AdamWR converge faster than the corresponding SGD method? Figure 4 is not quite representative since it contains an experiment with a very large number of training epochs.\n2. While AdamWR delivers much better test accuracy than Adam, it is still slightly worse than SGDWR method.\n\nI would also recommend to change scale of y-axis, Figure 4, right. Since 0.5% percent difference can be significant for state-of-the-art classification results.\n\n\nOverall, the paper is written clearly and organized well. It contains a lot of experiments and proposes an explanation of the observed phenomena. While the idea is very simple, the experimental results show its efficiency.\n']","[60, 60, 70]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper being well-written and easy to follow. They appreciate the authors' work and find the results interesting, particularly Proposition 3. However, they also raise some questions and suggest more experiments, which prevents the score from being higher. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, starting with appreciation for the authors' work. They phrase their criticisms and suggestions in a constructive manner, using phrases like 'it is not clear to me' and 'it would be great to see' rather than making blunt demands. The reviewer maintains a professional and courteous tone throughout the review."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's impact, convincing empirical evaluation, and significance, recommending acceptance despite some theoretical weaknesses. The politeness score is 80 (quite polite) due to the reviewer's respectful tone, constructive feedback, and acknowledgment of the paper's strengths. The reviewer uses phrases like 'I believe,' 'I am not convinced,' and 'I would appreciate clarification,' which maintain a polite and professional tone throughout. The review also balances critique with praise, showing respect for the authors' work while providing honest feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting that it investigates an 'interesting idea' and is 'written clearly and organized well.' They also mention that the experimental results show the efficiency of the proposed method. However, it's not a perfect score as the reviewer does raise some concerns and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I would recommend' and 'It would be interesting to see,' which are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before mentioning areas for improvement, which is a polite approach to feedback.""]"
"['The paper introduces a decentralized training method for multi-agent reinforcement learning, where the agents infer the policies of other agents and use the inferred models for decision making. The method is intuitively straightforward and the paper provides some justification for convergence. I think the underlying theory is okay (new but not too surprising, a lot of the connections can be made with single agent RL), but the paper would be much stronger with experiments that have more than two players, one state and one dimensional actions.\n\n(\nUpdate: the new version of the paper addresses most of my concerns. There are a lot more experiments, and I think the paper is good for ICLR. \n\nHowever, I wonder if the reasoning for PR2 is limited to ""self-play"", otherwise Theorem 1 could break because of the individual Q_i functions will not be symmetric. This could limit the applications to other scenarios.\n\nAlso, maybe explain self-play mathematically to make the paper self contained?\n)\n\n1. From the abstract, "" PR2-Q and PR2-Actor-Critic, that are proved to converge in the self-play scenario"". Theorem 2 only shows that under relatively strong assumptions (e.g. single Nash equilibrium), the soft value iteration operator is a contraction. This seems to have little to do with the actual convergence of PR2-Q and PR2-AC, especially AC which uses gradient-based approach. Also here the ""convergence"" in the abstract seem to imply convergence to the (single) global optimal solution (as is shown in the experiments), for which I thought you cannot prove even for single agent AC -- the best you can do is to show that gradient norm converges to zero, which gives you a local optima. Maybe things are different with the presence of the (concave) entropy regularization?\n\n2. Theorem 2 also assumes that the opponent model $\\rho$ will find the global optimal solution (i.e. (11, 12) can be computed tractably). However, the paper does not discuss the case where $\\rho$ or $Q_\\theta$ in question is imperfect (similar to humans over/underestimate its opponents), which might cause the actual solution to deviate significantly from the (single) NE. This would definitely be a problem in more high-dimensional MARL scenarios. I wonder if one could extend the convergence arguments by extending Prop 2.\n\n3. The experiments mostly demonstrates almost the simplest non-trivial Markov games, where it could be possible that (11, 12) are true for PR2. However, the effectiveness of the method have not been demonstrated in other (slightly higher-dimensional) environments, such as the particle environments in the MADDPG paper. It does not seem to be very hard to implement this, and I wonder if this is related to the approximation error in (11, 12). The success in such environments would make the arguments much stronger, and provide sound empirical guidance to MARL practitioners.\n\nMinor points:\n- Are the policies in question stationary? How is PR2 different from the case of single agent RL (conditioned on perfect knowledge of a stationary opponent policy)?\n- I have a hard time understanding why PR2 would have different behavior than IGA even with full knowledge of the opponent policy, assuming each policy is updated with infinitesimally small (but same) learning rates. What is the shape of the PR2 optimization function wrt agent 1?\n- I wonder if using 2 layer neural networks with 100 units each on a 1 dimensional problem is overkill.\n- Figure 4(a): what are the blue dots?\n- Does (11) depend on the amount of data collected from the opponents? If so, how?\n- I would recommend combining Prop 1 and prop 2 to save space. Both results are straightforward to prove, but the importance sampling perspective might be useful.\n- Have you tried to compare with SGA (Balduzzi et al) or Optimistic mirror descent?\n- I am also curious about an ablation study over the components used to infer opponent policies. A much simpler case would be action-dependent baselines, which seem to implicitly use some information about the opponents.', '\n# Summary:\nThe paper proposes a new approach for fully decentralized training in multi-agent reinforcement learning, termed probabilistic recursive reasoning (PR2). The key idea is to build agent policies that take into account opponent best responses to each of the agent\'s potential actions, in a probabilistic sense. The authors show that such policies can be seen as recursive reasoning, prove convergence of the proposed method in self-play, a demonstrate it in a couple of iterated normal form games with non-trivial Nash equilibria where baselines fail to converge.\n\nI believe the community will find intuitions, methods, and theory developed by the authors interesting. However, I find some parts of the argument somewhat questionable as well as experimental verification insufficient (see comments below).\n\n\n# Comments and questions:\n\n## Weaknesses in the experimental evaluation:\nI find it hard to justify a fairly complex algorithm (even though inspired by cognitive science), when most of the simpler alternatives from the literature haven\'t been really tested on the same iterated games (the baselines in the paper are all simple gradient-based policy search methods).\n\nIn the introduction (paragraph 2), the authors point out potential limitations of previous opponent modeling algorithms, but never compare with them in experiments. If the claim is that other methods ""tend to work only under limited scenarios"" while PR2 is more general, then it would be fair to ask for a comprehensive comparison of PR2 vs alternatives in at least 1 such scenario. I would be interested to see how the classical family of ""Win or Learn Fast"" (WoLF) algorithms (Bowling and Veloso, 2002) and the recent LOLA (Foerster et al, 2018) compare with PR2 on the iterated matrix game (section 5.1).\n\nAlso, out of curiosity, it would be interesting to see how PR2 works on simple iterated matrix games, eg iterated Prisoner\'s dilemma.\n\n## Regarding the probabilistic formulation (section 4.3)\nEq. 8 borrows a probabilistic formulation of optimality in RL from Levine (2018). The expression given in Eq. 8 is proportional to the probability of a trajectory conditional on that each step is optimal wrt the agent\'s reward r^i, i.e., not for p(\\tau) but for p(\\tau | O=1).\n\nIf I understand it correctly, by optimizing the proposed KL objective, we fit both \\pi^i and \\rho^{-i} to the distribution of *optimal trajectories* with respect to r^i reward. That makes sense in a cooperative setting, but the problem arises when opponent\'s reward r^{-i} is different from r^i, in which case I don\'t understand how \\rho^{-i} happens to approximate the actual policy of the opponent(s). Am I missing something here?\n\nA minor point: shouldn\'t \\pi^{-i} in eq. 9 be actually \\rho^{-i}? (The derivations in appendix C suggest that.)\n\n## Regarding alternative approaches (section 4.5)\nThe authors point out intractability of trying to directly approximate \\pi^{-i}. The argument here is a little unclear. Wouldn\'t simple behavioral cloning work? Also, could we minimize KL(\\pi^{-i} || \\rho^{-i}) instead of KL(\\rho^{-i} || \\pi^{-i})?\n\n# Minor\n- I might be misreading it, but the last sentence of the abstract seems to suggest that this paper introduces opponent modeling to MARL, which contradicts the first sentence of paragraph 2 in the introduction.\n- It is very hard to read plots in Figure 3. Would be nice to have them in a larger format.\n\nOverall, I find the paper interesting, but it would definitely benefit from more thorough experimental evaluation.', 'The high-level problem this paper tackles is that of endowing RL agents with recursive reasoning capabilities in a multi-agent setting, based on the hypothesis that recursive reasoning is beneficial for the agents to converge to non-trivial equilibria.\n\nThe authors propose the probabilistic recursive reasoning (PR2) framework for an n-agent stochastic game. The conceptual difference between PR2 and non-correlated factorizations of the joint policy is that, from the perspective agent i, PR2 augments the joint policy of all agents by conditioning the policies of agent i\'s opponents on the action that agent i took. The authors derive the policy gradient for PR2 and show that it is possible to learn these action-conditional opponent policies via variational inference in addition to learning the policy and critic for agent i.\n\nThe proposed method is evaluated on two experiments: one is an iterated matrix game and the other is a differential game (""Max of Two Quadratics""). The authors show in the iterated matrix game that baselines with non-correlated factorization rotate around the equilibrium point, whereas PR2 converges to it. They also show in the differential game that PR2 discovers the global optimum whereas baselines with non-correlated factorizations do not.\n\nThis paper is clear, well-motivated, and well-written. I enjoyed reading it. I appreciated the connection to probabilistic reinforcement learning as a means for formulating the problem of optimizing the variational distribution for the action-conditional opponent policy and for making such an optimization practical. I also appreciated the illustrative choice of experiments that show the benefit of recursive reasoning. \n\nCurrently, PR2 provides a proof-of-concept of recursive reasoning in a multi-agent system where the true equilibrium is already known in closed form; it remains to be seen to what extent PR2 is applicable to multi-agent scenarios where the equilibrium the system is optimizing is less clear (e.g. GANs for image generation). Overall, although the experiments are still small scale, I believe this paper should be accepted as a first step towards endowing deep reinforcement learning agents with recursive reasoning capabilities.\n\nBelow are several comments.\n\n1. Discussion of limitations: As the authors noted in the Introduction and Related Work, multi-agent reinforcement problems that attempt to model opponents\' beliefs often become both expensive and impractical as the number of opponents (N) and the recursion depth (k) grows because such complexity requires high precision in the approximate the optimal policy. The paper can be made stronger with experiments that illustrate to what extent PR2 practically scales to problems with N > 2 or K > 1 in terms of how practical it is to train.\n2. Experiment request: To what extent do the approximation errors affect PR2\'s performance? It would be elucidating for the authors to include an experiment that illustrates where PR2 breaks down (for example, perhaps in higher-dimensional problems).\n3. Minor clarification suggestion: In Figure 1: it would be clearer to replace ""Angle"" with ""Perspective.""\n4. Minor clarification suggestion: It would be clearer to connect line 18 of Algorithm 1 to equation 29 on Appendix C.\n5. Minor clarification suggestion: In section 4.5: ""Despite the added complexity"" --> ""In addition to the added complexity.""\n6. Minor clarification: How are the importance weights in equation 7 reflected in Algorithm 1?\n7. Minor clarification: In equation 8, what is the significance of integrating over time rather than summing?\n8. Minor clarification: There seems to be a contradiction in section 5.2 on page 9. ""the learning outcomes of PR2-AC and MASQL are extremely sensitive to the way of annealing...However, our method does not need to tune the the annealing parameter at all..."" Does ""our method"" refer to PR2-AC here?']","[20, -20, 80]","[60, 60, 90]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and theoretical foundations, stating 'the underlying theory is okay (new but not too surprising)'. They also mention that the updated version addresses most of their concerns and is 'good for ICLR'. However, the score is not higher due to several critiques and suggestions for improvement throughout the review. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think', 'I wonder', and 'I would recommend', which are polite ways of offering suggestions. The reviewer also acknowledges improvements in the updated version. However, the score is not higher as the review is primarily focused on technical aspects rather than using overtly polite language."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting' and believes 'the community will find intuitions, methods, and theory developed by the authors interesting', they also point out several weaknesses and areas for improvement. The reviewer states that parts of the argument are 'somewhat questionable' and the experimental verification is 'insufficient'. They suggest more thorough experimental evaluation and comparisons with other methods. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions or questions (e.g. 'I would be interested to see...', 'Am I missing something here?'). The tone is professional and objective, avoiding harsh or personal criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses clear appreciation for the paper, describing it as 'clear, well-motivated, and well-written' and recommending acceptance. They highlight the paper's strengths and contributions, although they do note some limitations and areas for improvement. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I enjoyed reading it' and 'I appreciated', and frame their suggestions as 'comments' rather than criticisms. Even when pointing out potential issues or requesting clarifications, the language remains courteous and supportive. The high scores in both categories reflect a generally positive and professionally cordial review.""]"
"['The main contributions of the paper are an edit encoder model similar to (Guu et al. 2017 http://aclweb.org/anthology/Q18-1031), a new dataset of tree-structured source code edits, and thorough and well thought-out analysis of the edit encodings. The paper is clearly written, and provides clear support for each of their main claims.\n\nI think this would be of interest to NLP researchers and others working on sequence- and graph-transduction models, but I think the authors could have gone further to demonstrate the robustness of their edit encodings and their applicability to other tasks. This would also benefit greatly from a more direct comparison to Guu et al. 2017, which presents a very similar ""neural editor"" model.\n\nSome more specific points:\n\n- I really like the idea of transferring edits from one context to another. The one-shot experiment is well-designed, however it would benefit from also having a lower bound to get a better sense of how good the encodings are.\n\n- If I\'m reading it correctly, the edit encoder has access to the full sequences x- and x+, in addition to the alignment symbols. I wonder if this hurts the quality of the representations, since it\'s possible (albeit not efficient) to memorize the output sequence x+ and decode it directly from the 512-dimensional vector. Have you explored more constrained versions of the edit encoder (such as the bag-of-edits from Guu et al. 2017) or alternate learning objectives to control for this?\n\n- The WikiAtomicEdits corpus has 13.7 million English insertions - why did you subsample this to only 1M? There is also a human-annotated subset of that you might use as evaluation data, similar to the C#Fixers set.\n\n- On the human evaluation: Who were the annotators? The categories ""similar edit"", and ""semantically or syntactically same edit"" seem to leave a lot to interpretation; were more specific instructions given? It also might be interesting, if possible, to separately classify syntactically similar and semantically similar edits.\n\n- On the automatic evaluation: accuracy seems brittle for evaluating sequence output. Did you consider reporting BLEU, ROUGE, or another ""soft"" sequence metric?\n\n- It would be worth citing existing literature on classification of Wikipedia edits, for example Yang et al. 2017 (https://www.cs.cmu.edu/~diyiy/docs/emnlp17.pdf). An interesting experiment would be to correlate your edit encodings with their taxonomy.', 'The authors state nicely and clearly the main contributions they see in their work (Intro, last paragraph). Specifically the state the paper: 1) present a new and important machine learning task, 2) present a family of models that capture the structure of edits and compute efficient representations, 3) create a new source code edit dataset, 4) perform a set of experiments on the learned edit representations and present promising empirical evidence that the models succeed in capturing the semantics of edits. \n\nWe decided to organize this review by commenting on the above-stated contributions one at a time:\n\n“A new and important machine learning task”\n\nRegarding “new task”:\n\nPRO: We are unfamiliar with past work which presents this precise task; the task is new. Section 5 makes a good case for the novelty of this work.\n\nCON: None.\n\n\nRegarding “important task”:\n\nPRO: The authors motivate the task with tantalizing prospective applications-- automatically editing text and code, e.g. for grammar, clarity, and style. Conceptualizing edits as NLP objects of interest that can be concretely represented, clustered, and used for prediction is an advance.\n\nCON: Many text editors, office suites, and coding IDEs already include features which automatically suggest or apply edits for grammar, clarity, and style. The authors do not describe shortcomings in existing tools that might be better addressed using distributed representations of edits. Consequently, the significance of the proposed contribution is unclear.\n\n\n“A family of models that capture the structure of edits and compute efficient representations”\n\nRegarding “a family of models”:\n\nPRO: The family of models presented by the authors clearly generalizes: such models may be utilized for computational experiments on datasets and edit types beyond those specifically utilized in this evaluation. The authors apply well-utilized neural network architectures that may be trained and applied to large datasets. The architecture of the neural editor permits evaluation of the degree to which the editor successfully predicts the correct edit given a pre-edit input and a known representation of a similar edit.\n\nCON: The authors do not propose any scheme under which edit representations might be utilized for automatically editing text or code when an edit very similar to the desired edit is not already known and its representation available as input. Hence, we find the authors do not sufficiently motivate the input scheme of their neural editor. The input scheme of the neural editor makes trivial the case in which no edit is needed, as the editor would learn during training that the output x+ should be the same as the input x- when the representation of the “zero edit” is given as input. While the authors discuss the importance of “bottlenecking” the edit encoder so that it does not simply learn to encode the desired output x+, they do not concretely demonstrate that the edit encoder has done otherwise in the final experiments. Related to that: If the authors aimed to actually solve automated edits in text/code then it seems crucial their data contained ""negative examples"" i.e. segments which require no edits. In such an evaluation one would test also when the algorithm introduces unnecessary/erroneous edits. \n\n\nRegarding “capture structure of edits”:\n\nPRO: The authors present evidence that edit encoders tightly cluster relatively simple edits which involve adding or removing common tokens. The authors present evidence that relatively simple edits completed automatically by a “fixer” often cluster together, i.e. a known signal is retained in clustering. The authors present evidence that the nearest neighbors of edits in an edit-representation space often are semantically or structurally similar, as judged by human annotators. Section 4.3 includes interesting observations comparing edit patterns better captured by the graph or seq edit encoders. \n\nCON: The details of the human annotation tasks which generated the numerical results in Tables 1 and 2 are unclear: were unbiased third parties utilized? Were the edits stripped of their source-encoder label when evaluated? Objectively, what separates an “unrelated” from a “similar” edit, and what separates a “similar” from a “same” edit? Did multiple human annotators undertake this task in parallel, and what was their overall concordance (e.g. “intercoder reliability”)? Without concrete answers to these questions, the validity and significance of the DCG/NDCG results reported in Tables 1 and 2 are unclear. It is not clear from the two examples given in Table 1 that the three nearest neighbors embedded by the Seq encoder are “better”, i.e. overall more semantically and/or syntactically similar to the example edit, than those embedded by the Bag of Words model. It is unclear which specific aspects of “edit structure” are better captured by the Seq encoder than the Bag of Words model. The overall structure of Tables 1 and 2 is awkward, with concrete numerical results dominated by a spatially large section containing a small number of examples.\n\n\n“create a new source code edit dataset”\n\nPRO: The authors create a new source code edit dataset, an important contribution to the study of this new task.\n\nCON: Minor: is the provided dataset large enough to do more than simple experiments? See note below on sample size.\n\n\n“present promising empirical evidence that the models succeed in capturing the semantics of edits”\n\nPRO: The experiment results show how frequently the end-to-end system successfully predicted the correct edit given a pre-edit input and a known representation of a similar edit. Gold standard accuracies of more than 70%, and averaged transfer learning accuracies of more than 30%, suggest that this system shows promise for capturing the semantics of edits.\n\nCON: Due to concerns expressed above about the model design and evaluation of the edit representations, it remains unclear to what degree the models succeed in capturing the semantics of edits. Table 11 shows dramatic variation in success levels across fixer ID in the transfer learning task, yet the authors do not propose ways their end-to-end system might be adjusted to address areas of weak performance. The authors do not discuss the impact of training set size on their evaluation metrics. The authors do not discuss the degree to which their model training task would scale to larger language datasets such as those needed for the motivating applications.\n\n##############\nBased on the authors\' response, revisions, and disucssions we have updated the review and the score. ', 'This paper looks at learning to represent edits for text revisions and code changes. The main contributions are as follows:\n* They define a new task of representing and predicting textual and code changes \n* They make available a new dataset of code changes (text edit dataset was already available) with labels of the type of change\n* They try simple neural network models that show good performance in representing and predicting the changes\n\nThe NLP community has recently defined the problem of predicting atomic edits for text data (Faraqui, et al. EMNLP 2018, cited in the paper), and that is the source of their Wikipedia revision dataset. Although it is an interesting problem, it is not immediately clear from the Introduction of this paper what would be enabled by accurate prediction of atomic edits (i.e. simple insertions and deletions), and I hope the next version would elaborate on the motivation and significance for this new task. \n\nThe ""Fixer"" dataset that they created is interesting. Those edits supposedly make the code better, so modeling those edits could lead to ""better"" code. Having that as labeled data enables a clean and convincing evaluation task of predicting similar edits.\n\nThe paper focuses on the novelty of the task and the dataset, so the models are simple variations of the existing bidirectional LSTM and the gated graph neural network. Because much of the input text (or code) does not change, the decoder gets to directly copy parts of the input. For code data, the AST is used instead of flat text of the code. These small changes seem reasonable and work well for this problem.\n\nEvaluation is not easy for this task. For the task of representing the edits, they show visualizations of the clusters of similar edits and conduct a human evaluation to see how similar these edits actually are. This human evaluation is not described in detail, as they do not say how many people rated the similarity, who they were (how they were recruited), how they were instructed, and what the inter-rater agreement was. The edit prediction evaluation is done well, but it is not clear what it means when they say better prediction performance does not necessarily mean it generalizes better. That may be true, but then without another metric for better generalization, one cannot say that better performance means worse generalization. \n\nDespite these minor issues, the paper contributes significantly novel task, dataset, and results. I believe it will lead to interesting future research in representing text and code changes.']","[50, 50, 70]","[80, 75, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions, clear writing, and thorough analysis. However, they also suggest areas for improvement and further work. The politeness score is 80 (quite polite) due to the use of respectful language, constructive criticism, and positive acknowledgments. The reviewer uses phrases like 'I really like' and 'well-designed', while offering suggestions in a non-confrontational manner, such as 'I think the authors could have gone further' and 'It would be worth citing'. The tone is professional and supportive throughout, maintaining a balance between praise and constructive feedback."", ""Sentiment score: The review is generally positive, acknowledging the novelty and potential importance of the work, while also providing constructive criticism. The reviewer notes several 'PRO' points for each contribution, indicating appreciation for the authors' efforts. However, there are also significant 'CON' points raised, suggesting areas for improvement. The overall tone is balanced but leans positive, hence a score of 50.\n\nPoliteness score: The language used is consistently professional and respectful. The reviewer uses phrases like 'The authors state nicely and clearly' and 'We decided to organize this review,' which show consideration. Criticisms are presented objectively without harsh language. The reviewer also acknowledges their own potential limitations ('We are unfamiliar with past work'). The high level of detail and organization in the feedback also demonstrates respect for the authors' work. These factors contribute to a politeness score of 75."", ""The sentiment score is 70 (positive) because the reviewer generally expresses a favorable view of the paper, highlighting its contributions and potential for future research. They use phrases like 'interesting problem', 'clean and convincing evaluation task', and 'contributes significantly novel task, dataset, and results'. The reviewer does mention some minor issues, but these don't significantly detract from the overall positive sentiment. The politeness score is 80 (polite) because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and suggestions for improvement without being harsh or dismissive. The use of phrases like 'I hope', 'These small changes seem reasonable', and 'Despite these minor issues' demonstrates a considerate approach to feedback. The reviewer also acknowledges the paper's strengths and potential impact, which further contributes to the polite tone.""]"
"['I like the idea of the paper and I believe it addressing a very relevant problem. While the authors provide a good formalization of the problem and convincing demonstration of the generalization bound, the evaluation could have been better by including some more challenging experiments to really prove the point of the paper. It is surely good to present the toy example with the MNIST dataset but the ethnicity domain is less difficult than what the authors claim. This is also pretty evident from the results presented (e.g., in Table 3). The proposed approach provides maybe slightly better results than the state of the art but the results do not seem to be statistically significant. This is probable also due to the fact that the problem itself is made simpler by the cropped faces, no background, etc. I would have preferred to see an application domain where the improvement would be more substantial. Nevertheless, I think the theoretical presentation is good and I believe the manuscript has very good potential. ', 'In this work, authors consider transfer learning problem when labels for the target domain is not available. Unlike the conventional transfer learning, they introduce a new loss that separates examples from different domains. Besides, they apply the multi-class entropy minimization to optimize the performance in the target domain. Here are my concerns.\n1.\tThe concept is not clear. For domain adaptation, we usually assume domains share the same label space. When labels are different, it can be a transfer learning problem.\n2.\tOptimizing the verification loss is conventional for distance metric learning based transfer learning and authors should discuss more in the related work.\n3.\tThe empirical study is not sufficient. There lacks the method of transfer learning with distance metric learning. Moreover, the major improvement seems from the MCEM rather than the proposed network. How about DANN+MCEM?\n', 'The authors studied an interesting problem of unsupervised domain adaptation when the source and the target domains have disjoin labels spaces. The paper proposed a novel feature transfer network, that optimizes domain adversarial loss and domain separation loss.\n\nStrengths:\n\n1) The proposed approach on Feature Transfer Network was novel and interesting.\n2) The paper was very well written with a good analysis of various choices.\n3) Extensive empirical analysis on multi-class settings with a traditional MNIST dataset and a real-world face recognition dataset. \n\n\nWeakness:\n1) Practical considerations addressing feature reconstruction loss needs more explanation.\n\nComments:\n\nThe technical contribution of the paper was sound and novel. The paper considered existing work and in a good way generalizes and extends into disjoint label spaces. It was easy to read and follow, most parts of the paper including the Appendix make it a good contribution. However, the reviewer has the following suggestions"" \n\n1. Under the practical considerations for preventing the mode collapse via feature reconstruction, how is the reference network trained? In the Equation(6) for feature reconstruction, the f_ref term maps the source and target domain examples to new feature space. What do you mean by references network trained on the label data? Please clarify.\n\n2. Under the practical considerations for replacing the verification loss, it is said that ""Our theoretical analysis suggests to use a verification\nthe loss that compares the similarity between a pair of images"" - Can you please cite the references to make it easier for the reader to follow.']","[50, -50, 80]","[75, 20, 90]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the idea of the paper and believing it addresses a relevant problem. They also praise the theoretical presentation and see good potential in the manuscript. However, they also point out some limitations in the evaluation, which prevents a higher positive score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the strengths of the paper while constructively pointing out areas for improvement. They use phrases like 'I like', 'I believe', and 'It is surely good', which contribute to a polite tone. The criticism is presented in a gentle manner, suggesting preferences rather than making demands."", ""The sentiment score is -50 because the review expresses several concerns about the work, indicating a somewhat negative sentiment. The reviewer points out issues with concept clarity, lack of discussion in related work, and insufficient empirical study. However, it's not entirely negative as the reviewer acknowledges the authors' novel approach. The politeness score is 20 because the language used is professional and constructive. The reviewer uses phrases like 'Here are my concerns' instead of harsh criticism, and provides specific points for improvement. The tone is direct but not rude, maintaining a respectful academic discourse."", ""The sentiment score is 80 (positive) because the reviewer highlights several strengths of the paper, including its novelty, good writing, and extensive empirical analysis. The reviewer uses phrases like 'interesting problem', 'novel and interesting approach', and 'very well written'. While there is one weakness mentioned, it's presented as a minor issue needing more explanation rather than a significant flaw. The overall tone is appreciative of the paper's contribution.\n\nThe politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They begin by acknowledging the authors' work positively and frame their criticism as 'suggestions' rather than demands. The reviewer also uses phrases like 'please clarify' and 'Can you please cite', which are polite ways of requesting additional information. The overall tone is professional, supportive, and aimed at improving the paper rather than criticizing it harshly.""]"
"['This paper extends the recent results concerning GP equivalence of infinitely wide FC nets to the convolutional case. This paper is generally of a high quality (notwithstanding the lack of keys on figures) and provides insights to an important class of model. I recommend that this paper be accepted, but I think it could be improved in a few ways. \n\nFirstly, and rather mundanely: the figures. Fig 1 is not easy to read due to the density of plotting, and as there is no key it isn’t possible to tell what it shows. Figure 2 is rather is called a ‘graphical model’ but the variables (weights and biases) are not shown. It should be specified that this is the graphical model of the infinite limit, in which case the K variables should not be random. Also, the caption on this figure refers to variables that aren’t in the figure, and is grammatically incorrect (perhaps something like ‘the limit of an infinitely wide convolutional’ is missing?). Figure 3 has a caption which seems to be inconsistent with the coloring (for example green is center pixel in the text, but blue in the key). Figure 6 is also missing a key. In Figure 5, what does the tick symbol denote? Finally, the value some of Table 1 is questionable as so many entries are missing. For example, the Fashion-MNIST column has only two values, which seems to me of little use. [I would have given the paper a rating of 7 were it not for these issues]\n\nRegarding the presentation of the content, I found this paper generally easy to follow and the arguments sound. Here are few points:\n\nThere is an important distinction between finite width Bayesian-CNNs and the infinite limit, and this distinction is indeed made in the paper but not clearly enough in my view. I would anticipate that some readers might come away after a cursory reading thinking that Bayesian-CNNs are fundamentally worse than their parametric counterparts, but this is emphatically not the message of the paper. It seems that the infinite limit that is the cause of two problems. The first problem (or perhaps benefit) is that the infinite limit gives Gaussian inner layers, just as in the fully connected case. The second problem (and I’d say this is definitely a problem this time) is that the infinite limit loses the covariance between the pixels, at least with a fully connected final layer. I would recall [Matthews 2018, long version] section 7, which discusses that point that taking the infinite limit in the fully connected is actually potentially undesirable. To quote Matthews 2018, “MacKay (2002, p. 547) famously reflected on what is lost when taking the Gaussian process limit of a single hidden layer network, remarking that Gaussian processes will not learn hidden features”. Some discussion of this would enhance the presented paper, in my view. \n\nThe discussion of eq (7) could be made more clear. Eq (7) is only defined on K, and not in composition with A. It is important that the alpha dependency is preserved by the A operation, and while I suppose this is obvious I would welcome a bit more detail. It would help to demonstrate the application of the results of [Cho and Saul 2009] to the convolution case explicitly (i.e. for C o A), in my view. \n\nRegarding results, effort has clearly gone to keep the comparisons as fair as possible, but with these large datasets it is difficult to disentangle the many factors that might effect performance (as acknowledged on p9). It is a weakness of the paper that there is no toy example. An example demonstrating a situation which can only be solved with hierarchical features (e.g. features that are larger than the receptive field of a single layer) would be particularly interesting, as in this case I think the GP-CNN would fail, even with the average pooling, whereas the finite Bayesian-CNN would succeed (with a sufficiently accurate inference method).  \n\nIt would improve readability to stress the 1D notation in the main text rather than in a footnote. On first reading I missed this detail and was confused as I was trying to interpret everything as a 2D convolution. On reflection I think notation is used in the paper is good, but I think the generalization to 2D should be elevated to something more than the footnote. Perhaps a paragraph explaining how the 2D case works would be appropriate, especially as all the experiments are in 2D cases. \n\nSome further smaller points on specific [section, paragraph, line]s\n\n1,2,4 I think ‘easily’ is a bit of an overstatement. In this work the kernel is itself defined via a recursive convolutional operation, which doesn’t seem to me much more interpretable than the parametric convolution. At least the filters can be examined in parametric case, which isn’t the case here. I do agree with the sentiment that a function prior is better than an implicit weight prior, however.\n\n1,2,-1 This seems too vague to me, as at least to some extent, Matthew 2018 did indeed consider using NN-GPs to gain insight about equivalent NN models (e.g. section 5.3)\n\n1.1,:,: I find it very surprising that there are no references to Cho and Saul 2009 in this section (one does appear in 2.2.2, however). \n\n1.1,3,-2:-1 ‘Our work differs from all of these in that our GP corresponds exactly to a fully Bayesian CNN in the many channel limit’ I do not think this is completely true, as the deep convolution GP does correspond to an infinite limit of a Bayesian CNN, just not the same limit as the one taken in this paper. Similarly a DGP following the Danianou and Lawrence 2013 is an infinite limit of a NN, but one with bottlenecks between layers. It is important that readers appreciate that infinite limits can be taken in different ways, and the resulting models may be very different. This certain limit taken in this work has desirable computational properties, but arguably undesirable modelling implications.\n\n1.1,-1,-2 It should be made more clear here that the SGD trained models are non-Bayesian. \n\nFigure 3 The MC-CNN-GP appears to have performance that is nearly independent of the depth, even including 1 layer. Could this be explained?\n\n2.2,2,: The z^l variables are zero mean Gaussian with a fixed covariance, not delta functions, as I understand it. They are independent of each other due to the deterministic K^l, certainly, but they are not themselves deterministic. Could this be clarified? \n', '****Reply to authors\' rebuttal****\n\nDear Authors,\n\nI greatly appreciate the effort you have put into the rebuttal. The changes you have made have addressed most of my concerns and I believe that the few outstanding ones can be fixed without significantly affecting the main message of the paper. I will thus be recommending acceptance of the paper.\n\nBest wishes,\nRev 3\n\n\nSeveral remarks on the updated version:\n\n- (p.20, A.5.1) To ensure the random variables are well-defined, please state explicitly which sigma algebra is F (I am assuming the product Borel sigma-algebra + the relevant definitions of the random variables). This is important for the reader to understand what convergence in distribution on this particular space does and does not imply. Some readers might also appreciate if you used the mentioned ""infinite width, finite fan-out, networks"" (Matthews et al.) construction (or similar) which would ensure that the collection of random variables {z_i^l}_{i \\in N*} is well-defined for any network width and l, which currently does not seem to be the case according to Eqs. (28-29). If the full countably infinite vectors of random variables are not defined for all networks in the sequence, it is not possible to prove their convergence in distribution to the relevant GPs.\n\n- (p.21, A.5.3) Thank you for clarifying the definition of elements of the sequential limit. If possible, I would further recommend first fixing the probability space and then defining the random variables (the argument just before Theorem A.2 seems somewhat circular as R.V.s should first be defined on some space, and not put on a probability space post-hoc; perhaps some product space with the product sigma-algebra would work here?!). Furthermore, if I understand correctly, there are now L sequences of neural networks (one sequence for networks with 0, ..., L-1 ""infinite layers""), rather than a single sequence, and the ""infinite layers"" are squashed into a single ""infinite layer"" which is represented by z_i^\\infty? In other words, all the infinite layers are replaced by iid samples from a particular GP and only the finite layers have the standard neural network structure? If I am mistaken (or not), perhaps a further explanatory footnote would help the reader.\n\n- (p.21, A.5.3 & p.23, A.5.4) Thank you for improving the discussion of joint convergence. Please clarify that proving convergence for any finite m is sufficient for proving convergence in distribution of the countably infinite vector {z_i}_{i \\in N*} for the **product Borel sigma-algebra** (e.g. using an argument like the one on p.19 of Billingsley (1999)).\n\n- (p.21) ""Uniformly square-integrable"": to me, this phrase suggests that the collection of squares of the functions has to be uniformly integrable but the definition in Eq. (27) only states one of the conditions in definition of uniform integrability. Please clarify that ""uniform square-integrability"" here is not related to the standard notion of ""uniform integrability"" in the literature.\n\n\n\n\n\n****Summary****\n\nThis paper extends recent results on convergence of Bayesian fully connected networks (FCNs) to Gaussian processes (GPs), to the equivalent relationship between convolutional neural networks (CNNs) and GPs. This is currently an area of high interest, with Xiao et al. (2018) examining the same relationship from a mean-field perspective, and two other concurrent papers making contributions:\n\nhttps://arxiv.org/abs/1808.05587\nhttps://arxiv.org/abs/1810.10798\n\nThus the scope of the paper fits well within the aims of the conference.\n\nI really appreciate that the authors did not shy away from studying the effect of pooling layers, and find the connection to locally connected networks they describe intriguing and insightful. On the experimental side, the investigation of the relative importance of compositionality, equivariance and invariance on performance of CNNs is very interesting.\n\nThese experiments and investigations are however based on a theoretical foundation which suffers from several issues. The main problems are an incorrect proof of convergence of the joint distribution of filters, and an improper use of convergence in probability in cases where random variables do not share a common underlying probability space. Unfortunately, either of these by itself invalidates the main theoretical claims which is why I am recommending rejection of the paper.\n\nHowever, I believe that the argument in (A.4.3) can potentially be rectified, and, as I detail below, is of greater interest to the community relative to the ones in (A.4.1) and (A.4.2). If this is accomplished and the proofs in (A.4.1) and (A.4.2) are either also fixed or left out (A.4.3 is sufficient to justify the claims in the main body), I am willing to significantly improve my rating of this paper and potentially recommend acceptance. For this reason, a ""detailed comments"" section is appended at the end of the standard review where the technical issues are described in much greater detail.\n\n\n****General comments****\n\n**Bayesian vs. infinite neural networks**\n\nThe main theoretical claims concerning the relationship between Bayesian CNNs and GPs are within Section 2. Therein on top of page 4, the authors say ""In Appendix A.4 we give several **alternative** derivations of the correspondence"" (emphasis mine), and then progress to outline the skeleton of the argument (A.4.2) in Sections 2.2.1-2.2.3. Section 2.2.3 is concluded by statement of the main theoretical result of this paper, Eq. (10), which comes from (A.4.3) and can only be linked to the rest of Section 2 through the claim of equivalence between the ""alternative derivations"" (A.4.1), (A.4.2) and (A.4.3). The problem is that the equivalence claim does not hold, as explained below:\n\nThe most important distinction here is between what I will call a ""sequential"" and a ""simultaneous"" limit. In the ""sequential"" case (A.4.1 & A.4.2, Sections 2.2.1-2.2.3), layers are taken to infinity one by one, whereas in the ""simultaneous"" case (A.4.3, used to obtain the result concluding Section 2.2.3) all layers are **finite** for **all** members of the sequence, growing in width simultaneously.\n\nThe ""simultaneous"" limit (A.4.3) is in my view more interesting as it tells us that **finite** BNNs do indeed converge to GPs in distribution, i.e. that for each expectation of a continuous bounded function of the outputs of the limiting GP, there exists a BNN with a **finite** number of neurons in **each** layer for which the expectation of the same function is arbitrarily close. From a practical perspective, ""simultaneous"" limit tells us that inference algorithms for BNNs (which can be inaccurate and/or computationally expensive) can sometimes be replaced by exact or approximate inference algorithms for the limiting GP (cf. Section 5 in (Matthews et al., 2018, extended version)).\n\nThe ""sequential"" limit (A.4.1 & A.4.2) on the other hand does not establish existence of finite BNNs arbitrarily close to a particular GP, or justify use of the GP limit as approximation for finite BNNs as above. This is because the width of individual layers goes to infinity in a sequence from first to last. This means that most of the networks that constitute the sequence converging to the GP will have **one or more infinitely wide layers** and thus do not correspond to the finite BNNs we usually work with. In other words, ""sequential"" limit can only ever establish that there exists a network with **all but the final hidden layer infinite** that is arbitrarily close to the limiting GP. The only case where ""sequential"" and ""simultaneous"" limits agree is thus in the single hidden layer case first studied by Neal (1996). I will call the networks with one or more infinite layers ""infinite networks"", inspired by the work of Williams (1997) and others. Notice that infinite networks cannot be described by Eqs. (1) and (2) as the weights would be zero with probability one and thus output of the network would only depend on biases. It is not immediately obvious how to formally replace Eqs. (1) and (2) in the case of infinite networks which is one of the technical issues with the approaches in (A.4.1) and (A.4.2) (see the detailed comments section for further discussion).\n\nOthers may of course disagree and find ""sequential"" limits more interesting, but if the authors wish to keep the description of (A.4.2) in the main paper (Sections 2.2.1-2.2.3), it would be highly beneficial if readers were given the opportunity to understand the differences between the two types of limits so that they can form their own judgement. The authors should then also make clearer that the approach described in Sections 2.2.1-2.2.3 cannot be used to obtain the final result, Eq. (10). I would rather recommend reworking Sections 2.2.1-2.2.3 based on the ""simultaneous"" limit argument in (A.4.3) which unlike the current one can justify the result in Eq. (10) stated at the end.\n\n\n**Other comments**\n\n- (p.2, top) You say your results are ""strengthening and extending the result of Matthews et al. (2018)"" which is somewhat confusing. Matthews et al. prove a result for FCNs whereas this paper focuses on CNNs. Extension of (A.4.3) to FCNs may well be possible but is not included in this paper. Results in (A.4.1) and (A.4.2) are for the ""sequential"" whereas Matthews et al. study the ""simultaneous"" limit. Further differences:\n\t- Matthews et al. prove convergence for any countable rather than only finite input sets.\n\t- In Matthews et al.\'s work, Gaussianity is obtained through use of a particular version of CLT, whereas this work exploits Gaussianity of the prior over weights and biases. Going forward, an extension to more general priors/initialisations (like uniform or any sub-Gaussian) is likely to be easier using the CLT approach.\n\t- Matthews et al.\'s assumption on the activation functions is independent of the input set (p.7, Definition 1), whereas this work uses an assumption that is explicitly dependent on input (Eq. (37)) which might be potentially difficult to check.\n\n- (p.15, A.2 end) Should also mention Titsias (2009), ""Variational Learning of Inducing Variables in Sparse Gaussian Processes"", as a classical reference for approximate GP inference.\n\n\n****Questions****\n\n- (Section 4) Can you please provide more details on the MC approximation? Specifically, is only the last kernel approximated, or rather all of them, sequentially resampling from the Gaussian with empirical covariance in each layer? In case you tried, is there any qualitative or quantitative difference between the two approaches?\n\n- (Section 4 and Appendix A) Daniely et al. (2016) assume that the inputs to the neural network are l^2 normalised. You mention that the inputs have been normalised in the experiments (A.6). Is this assumption used in any of your proofs? Have you observed that l^2 normalisation improves empirical performance?\n\n- (p.8, Figure 6) How was ""the best CNN with the same parameters"" selected? If training error is zero for all, was it selected by validation accuracy? I was assuming that what is plotted is an estimate of the **expected** generalisation error, whereas the above selection procedure would be estimating supremum of the support of the generalisation error estimator which does not seem like a fair comparison. Can you please clarify?\n\n- (p.8 and A.6) Why only neural networks with zero training loss were allowed as benchmarks? How did the ones with non-zero training error fared in comparison? Can you please expand on footnote 3?\n\n- (p.8, last sentence) ""an observation specific to CNNs and FCNs or LCNs"": Matthews et al. (2018, extended version) observed in Section 5.2 that BNNs and their corresponding GP limits do not always perform the same even in the FCN case (cf. their Figure 8). Their paper unfortunately does not compare to equivalent FCNs trained by SGD. Have you experimented with or have an intuition for whether the cases where SGD trained models prevail coincide with the cases where BNNs+MCMC posterior inference outperform their GP limit?\n\n- (p.15, Table 3) The description says you were using erf activation (instead of the more standard ReLU): why? Have you observed any significant differences? Further, how big a proportion of the values in the image is black due to the numerical issues mentioned in A.6.4?\n\n- (p.18, just after Eq. 39) Use of PSD_{|X|d} in (A.4.3) suggests this proof assumes ""same"" padding is used?! Does the proof generalise to any padding/changing dimensions of filters inside the network?\n\n- (A.6) Can you comment on the pros & cons of ""label regression"" for classification and how does it compare with approximate inference when softmax is put on top of a GP (perhaps illustrating by a simple experiment on a toy dataset)?\n\n\n[end of standard review]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[detailed comments]\n\n****Technical concerns****\n\nNotation-wise, I would strongly encourage incorporating the dependence on network width into your notation, at the very least throughout the appendix. It would greatly reduce the amount of mental book-keeping the reader currently has to do, and significantly increase clarity at several places.\n\nOne of my main concerns is that the random variables and their underlying probability space are never formally set-up. This is problematic because convergence in probability is only defined for random variables sharing the same underlying space. At the moment, networks with different widths are not set-up to share a probability space. The practical implication for the approaches relying on convergence in probability of the empirical covariance matrices K is that the convergence in probability is not well-defined exactly because the empirical covariance matrices are not set-up on the same underlying probability space. A possible way to address this issue is to use an approach akin to what Matthews et al. (2018, extended version) call ""infinite width, finite fan-out, networks"" on page 20. This puts the networks on the same underlying space and because the empirical covariance matrices are measurable functions of thus defined random variables, they will also share the same underlying probability space.\n\nAlso regarding convergence in probability, please state explicitly with respect to which metric is the convergence considered when first mentioned (A.4.3 is explicitly using l^\\infty; A.4.2 perhaps l^2 or l^\\infty?), and make any necessary changes (e.g. show continuity of the mapping C in A.4.2).\n\nAt several places within the paper, you state that the law of large numbers (LLN) or the central limit theorem (CLT) can be applied. Apart from other concerns detailed later, these come with conditions on finiteness of certain expectations (usually the first one or two moments of the relevant random variables). Please provide proofs that these expectations are indeed finite and make any assumptions that you need explicit in the main text.\n\nAnother major concern is that none of (A.4.1), (A.4.2) and (A.4.3) successfully proves joint convergence of the filters at the top layer as claimed in the main text (e.g. Eq. (10)), and instead only focuses on marginal convergence of each filter which is not sufficient (cf. the comment on joint vs. pairwise Gaussianity below). This is perhaps sufficient if a single filter is the output of the network, but insufficient otherwise, especially when proving convergence with additional layers added on top of the last convolutional layer (as in Section 3) whenever the number filters is taken to infinity.\n\nIt would be nice, but not necessary for acceptance of the paper, to extend the proofs to uncountable index sets. I think you could use the same argument as described towards the end of Section 2.2  in (Matthews et al., 2018, extended version) and references therein.\n\n\n**Other comments**\n\n- I would strongly encourage distinguishing more clearly between probability distributions and density functions. For example, I would infer that lower case p refers to the probability distribution from Eq. (6); however, in Eqs. (8) and (9) the same notation is used for density functions (whilst integrating against the Lebesgue measure). This is quite confusing in this context as the two objects are not the same (see next two comments). I would suggest using capital P when referring to distribution, and lower case p when referring to its density.\n\n- (p.4, Eq. 6) If p is a density, it cannot be equal to a delta distribution. If it is a probability distribution then I am similarly confused - convergence in probability is a statement about behaviour of random variables, not probability distributions; in that case possibly Eq. (6) is trying to say that the empirical distribution of K^l (which is a random variable) conditioned on K^{l-1} converges weakly to the delta distribution on the RHS in probability? Please clarify.\n\n- (p.5, Eq. 10) I would recommend stating explicitly the mode of convergence. If p is the density then even assuming A.4.3 can be fixed to prove weak convergence of the **joint** distribution of filters is not enough not justify Eq. (10) - convergence in distribution does not imply pointwise convergence of the density function. If p is the distribution, then I would possibly use the more standard notation \'\\otimes\' instead of \'\\prod\'.\n\n- (p.17, end of A.4.2) You say ""Note that addition of various layers on top (as discussed in Section 3) does not change the proof in a qualitative way"". Can you please provide the formal details? At the very least, joint convergence of filters will have to be established if fully connected layers are added on top. This is the main reason why joint convergence of filters in the top layer is important.\n\n\n****Specific comments & issues for individual proofs****\n\n**Approaches suited infinite networks (""sequential limit"")**\n\nAs mentioned in the beginning, it is not entirely clear how to formalise infinite networks in a way analogous to Eqs. (1) and (2) in your paper. This is important because you are ultimately proving statements about random variables, like convergence in probability, and this is not possible if those random variables are not formally defined. This section only comments on technical issues with the approaches described in (A.4.1) and (A.4.2). From now on, I assume that the authors\' were able to formally define all the mentioned random variables in a way that fits with (A.4.1) and (A.4.2).\n\n\n(i) Hazan and Jaakola type approach (A.4.1)\n\nThis approach essentially iteratively applies a version of the recursion first studied by Hazan and Jaakola (2015), ""Steps Toward Deep Kernel Methods from Infinite Neural Networks"".\n\n- (p.16, A.4.1) Please provide reference for the claim that ""pairwise independent Gaussian implies joint independent Gaussian"". This seems to assume that the variables are jointly Gaussian which is, as far as I can see, not established here.\n\t- see second part of the linked answer for a nice example of three random variables with pairwise standard normal marginals, but joint not the multivariate standard normal:\n\n\thttps://stats.stackexchange.com/questions/180708/x-i-x-j-independent-when-i%E2%89%A0j-but-x-1-x-2-x-3-dependent/180727#180727 \n\n- (p.16, A.4.1) The application of the multivariate CLT is slightly more complicated than the text suggests. Except for the necessity of proving finiteness of the relevant moments, multivariate CLT does not out-of-the-box apply to infinite dimensional random variables like {z_j^{l+1}}_{1 \\leq j \\leq \\infty} as claimed. Hence joint convergence is not proved which will be problematic for the reasons explained earlier.\n\n\n(ii) Lee et al. type approach (A.4.2)\n\nThis type of approach follows the technique used by Lee et al. (2018), ""Deep Neural Networks as Gaussian Processes"".\n\nApplication of the weak law of large numbers (wLLN): As mentioned before, convergence in probability is only possible between random variables on the same underlying space. This is usually not a problem when wLLN is applied as the random variables converge to a constant random variable. Because every constant random variable generates the trivial sigma-algebra, it is measurable for any underlying probability space and thus convergence in probability is well-defined. The situation here is more complicated because the target is constant only conditionally on the previous layer, i.e. is not constant. As a side note, even the conditioning is only well-defined if all random variables live on the same space (conditioning on a random variable is technically conditioning on the sub-sigma-algebra it generates on the shared space).\n\nAssuming the problem with all K^{l, t} (t denotes the dependence on network width), for all l \\in {1, ... L} and t \\in {1, 2, 3, ...}, being on the same underlying probability space is solved, the next point is application of the wLLN itself. You claim ""we can apply the law of large numbers and conclude that [Eq. (6)]"" (p.4) which is not entirely correct here. Focusing on the application when the sizes of all the previous layers are held fixed, the two conditions that have to be checked here are: (i) the conditional expectation of the iid summands in Eq. (3) is finite; (ii) the sequence of iid variables is fixed. Please provide an explicit proof of (i). Regarding (ii), I am specifically concerned with the fact that with changing t (and thus network widths), the sequence of random variables changes (because the previous K^{l-1,t} matrix changes) which means that completely different size of the current layer may be necessary to get sufficiently close to the target (which has itself changed with t). In other words, instead of having a fixed infinite sequence of iid random variables, you currently have a sequence of growing finite sets of random variables which are iid only within the finite sets, but not between members of the sequence (different t). The direct implication is that this type of proof is not applicable to the ""simultaneous limit"" case as claimed in the main text (Section 2.2 says all proofs are equivalent and lead to Eq. (10) which explicitly takes the simultaneous limit), since the application would require some form of uniform convergence in probability akin to (A.4.3). I think that the approach taken in (A.4.3) is a correct way to address this issue and would thus recommend focusing on (A.4.3) and leaving (A.4.2) out. The appendix seems to acknowledge that (A.4.2) does not work for the ""simultaneous limit"" - please adapt the main text accordingly.\n\nA note on convergence in probability: In Eq. (3), the focus is on convergence in probability of individual entries of the K matrices. This in general does not imply convergence of all entries jointly. However, the type of convergence studied here is convergence to a constant random variable which is fortunate because simultaneous convergence of all entries in probability can be obtained for free in this case (thanks to having a **finite** number of entries of K). I think it might be potentially beneficial for the reader if this was explicitly stated as a footnote with an appropriate reference included.\n\nA note on marginal vs joint probability: As you say above Eq. (23), you are only proving convergence of a single filter marginally, instead of the full sequence {z_j^L}_{1 \\leq j \\leq \\infty} jointly. Convergence of the marginals does not imply convergence of the joint, which will be problematic for the reasons explained earlier.\n\n\n**Approaches for BNNs (""simultaneous limit"")**\n\n(iii) The proof in (A.4.3)\n\nMy biggest concern about this approach is that it only establishes convergence of a single filter marginally, instead of the full sequence {z_j^L}_{1 \\leq j \\leq \\infty} jointly. Convergence of the marginals does not imply convergence of the joint, which will be problematic for the reasons explained earlier.\n\nOther comments:\n\n- (p.17) You say ""Using Theorem A.1 and the arguments in the above section, it is not difficult to see that a sufficient condition is that the empirical covariance converges in probability to the analytic covariance"".\n\t- Can you please provide more detail as it is unclear what exactly do you have in mind?\n\t- I will be assuming from now on that you show that a particular combination of the Portmanteau theorem and convergence of K^L in probability to get pointwise convergence of the characteristic function is sufficient.\n\n- (p.18) Condition on activation function: The class \\Omega(R) is dependent on the considered input set X through the constant R. This seems slightly cumbersome as it would be desirable to know whether a particular activation function can be used without any reference to the data. It would be nice (but not necessary) if you can derive a condition on \\phi which would not rely on the constant R but allows ReLU.\n\n- (p.19, Eq. 48) I see where Eq. (48) is coming from, i.e. from Eq. (44) and the assumption of \\bar{\\varepsilon} ball around A(K_\\infty^l) being in PSD(R), but it would be nicer if you could be a bit more verbose here and also write out the bound explicitly (caveat: I did not check if the definition of \\bar{\\varepsilon} matches up but assume a potential modification would not affect the proof in a significant way).\n\n- (p.19) The second part of the proof is a little confusing, especially after Eq. (49) - please be more verbose here. For example, just after Eq. (49), it is said that because the two random variables have the same distribution, property (3) of \\Omega(R)\'s definition can be applied. However the two random variables are not identical and importantly are not constructed on the same underlying probability space. Property (3) is a statement about the the set of random variables {T_n (Sigma)}_{Sigma \\in PSD_2(R)} and not about the different 2x2 submatrices of K^{l+1}, but it needs to be applied to the latter. When this is clarified, the next point that could be made clearer is in the following sentence where changing t will affect the 2x2 submatrices of K^{l+1,t} as well as the bound through U(t) and V(t); it is not immediately obvious that the proof goes through as claimed so please be a bit more verbose.\n\n\n****Typos and other minor remarks****\n\n- (p.2, top) ""hidden layers go to infinity uniformly"": The use of word uniformly is non-standard in this context. Please clarify.\n\n- (p.3, Eq. 2) Using x for both inputs and post-activations is slightly confusing.\n\n- (p.4, Eq. 5) Should v_\\beta multiply \\sigma_\\beta^2 ?\n\n- (p. 4) The summands in Equation (3) are iid -> ""conditionally iid"" (please also specify the conditioning variables/sigma-algebra).\n\n- (p.4, Eq. 4) Eq. (4) is slightly confusing given you mention that K is a 4D object on the previous page.\n\t- I only understood K is ""flattened"" into |X|d x |X|d matrix when I reached (A.4.3) - this should be stated in main text as otherwise the above confusion arises.\n\n- (p.5, 3 and 3.1) The introduction of ""curly"" K is slighlty confusing. Please provide more detail when introducing the notation, e.g. state in what space the object lives.\n\n- (p.5, before Eq. (11)) Is R^{n^(l+1)} the right space for vec(z^L) ? It seems that the meaning of z changes here as compared to the definition in Eq. (2). If z is still defined as in Eq. (2), how exactly is the vec operator defined here? Please clarify.\n\n- (p.16, A.4.2) ""law of large number"" -> ""weak law of large numbers""\n\n- (p.17) T_n is technically not a function from PSD_2 only but also from some underlying probability space into a measurable space (i.e. can be viewed as a random variable from the product space of PSD_2 and some other measurable space).\n\n- (p.18, Eq. 38) Missing dot at the end. Also the K matrix either should or shouldn\'t have the superscript ""l"" (now mixed); it does have the superscript in Eq. (39) so probably ""should"".\n\n- (p.18, Eq. 39) Slightly confusing notation. Please clarify that both K and A(K) should have diagonal within the given range.\n\n- (p.18) ""squared integrable"" -> ""square integrable"" or ""square-integrable""\n\n- (p.18) Last display before Eq. (43): second inequality can be replaced by equality?!\n\n- (p.19, Eq. 47) The absolute value should be sup norm.\n\n- (p.19, Eq. 49) LHS is a scalar, RHS a 2x2 matrix (typo).\n\n- (p.19, last sentence of the proof) It does not seem the inequalities need to be strict.', 'Overall Score: 7/10.\nConfidence Score: 3/10. (This paper includes so many ideas that I have not been able to prove that are right due to\nmy limited knowledge, but I think that there are correct).\n\nSummary of the main ideas: This paper establishes a theoretical correspondence between BCNN with many channels and GP and\npropsoes a Monte Carlo method to estimate the GP corresponding to a NN architecture. It is a very strong and complete\npaper since its gives theoretical contents and experiments content. I think that it is a really good result that should\nbe read by anyone interested in Neural Network and GP equivalences, and that Machine Learning in general needs these kind\nof papers that establish this complicated equivalences.\n\nRelated to: The work by Lee and G. Matthews (2018) regarding equivalence between Deep Neural Networks and GPs and the\nConvolutional Neural Network framework.\n\nStrengths:\nTheoretical content, Experiments and methodology content (even a Monte Carlo approach) makes it a very complete paper.\nHaving been able to establish complicated and necessary equivalences.\n\nWeaknesses:\nVery difficult for newcomers or non expert technical readers.\n\nDoes this submission add value to the ICLR community? : Yes, it adds, and a lot.\n\nQuality:\nIs this submission technically sound?: Yes it is, it is a necessary step in GP-NN equivalence research.\nAre claims well supported by theoretical analysis or experimental results?: Yes, quite sure.\nIs this a complete piece of work or work in progress?: Complete piece of work.\nAre the authors careful and honest about evaluating both the strengths and weaknesses of their work?: Yes, they are.\n\nClarity:\nIs the submission clearly written?: Yes, but I suggest giving formal introductions to some concepts in the introduction\nand include a figure with the ideas given or the equivalences.\nIs it well organized?: Yes, although sometimes section feel a little but put one after the another. More cohesion would be\nadded if they are introduce before.\nDoes it adequately inform the reader?: Yes.\n\nOriginality:\nAre the tasks or methods new?: The monte carlo is new, the other methods not but the task of the equivalence is new.\nIs the work a novel combination of well-known techniques?: It is kind of a combination, but the proposed ideas are new, it is very theoretical.\nIs it clear how this work differs from previous contributions?: Yes, authors bother in explaining it clearly.\nIs related work adequately cited?: Yes, this is a huge positive point of the paper.\n\nSignificance:\nAre the results important?: From my point of view, yes they are.\nAre others likely to use the ideas or build on them?: I think so, because the topic is hot right now.\nDoes the submission address a difficult task in a better way than previous work?: It is a new task.\nDoes it advance the state of the art in a demonstrable way?: Yes, clearly.\nDoes it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?: Yes, the theoretical approach is sound.\n\n\nArguments for acceptance: It is a paper that provides theory, methodology and experiments regarding a very difficult and challenging task that add value to the community and makes progress in the area of the equivalence between NN and GPs.\n\nArguments against acceptance: I do not have.\n\nTypos:\n\n-> Define the channel concept in introduction.\n-> Put in bold best results of the experiments.\n-> Why not put ""deep"" in the title?\n-> In the introduction, introduce formally a CNN. (brief)\n-> Define the many channel limit.\n-> Put a figure with the equivalences and with the contents of the paper explaining a bit.\n\n\n\nAfter rebuttal:\n=============\n\nAuthors have addressed many topics that not only I but rev 3 address and hence I score this paper with a 7 and recommend it for publication.', 'The paper establishes a connection between  infinite channel Bayesian convolutional neural network and Gaussian processes. The authors prove that taking the number of channels in a Bayesian CNN to infinite leads to a GP with a specific Kernel (GP-CNN) and provide a Monte Carlo approach to evaluate the kernels when it is intractable. They show that without pooling the kernel fails to maintain the equivariance property that is achievable with a CNN without pooling.  GP-CNN with pooling maintains the invariance property. They make extensive  experimental comparison with CNN, demonstrating that as the number of channels become large, CNN achieve performance close to a GP-CNN. A discussion on reasons for best CNN to give a performance better than GP-CNN (especially with pooling), and a experimental comparison with finite width Bayesian CNN would have made the paper more concrete.  The paper has both strong theoretical and experimental contribution, and is also very relevant to the ICLR conference.\n\nQuality\n\nThe paper provides a theoretical connection between Bayesian CNN with infinite wide channels and Gaussian processes with a recursive kernel (GP-CNN). The derivations and arguments seem correct. The experiments are conducted comparing the performance of SGD trained CNN with  GP-CNN, and other models on mainly on CIFAR-10 data set. \nHowever, some discussion and clarity on the following points will be  useful to improve the paper.\n\n- (Page 5) on convergence of K^l :  From Equations (3) and (4), it can be seen that  K^l converges to  C(K^{l-1}), with C(K^{l-1}) defined slightly different from the paper, in that the expectation over z  is taken w.r.t z~ N(0;A(K)) instead of z ~ N(0; K). Is this equivalent to the expressions (7) and (8) described in the paper for a non-linear function \\phi ?\n- Experimental comparison with Bayesian CNN, demonstrating the effect of increasing the number of channels.\n- (Page 7) GP-CNN with pooling :  Paper proposes subsampling one particular pixel to improve computational efficiency. Has some experiments been performed to evaluate the performance of this approach ? How accurate is this approach ?\n- Discussion on the positive semi-definiteness of the recursive GP-CNN kernel\n- More explanations on why the best SGD-trained CNN gives a better performance than GP-CNN, especially with pooling. Does the Monte-Carlo approximation of GP-CNN kernel  computation could impact this performance? I suppose hyper-parameters of the GP-CNN kernel are not learnt from the data, could this result in a lower accuracy  ?\n- Discussion on learning the hyper-parameters of the GP-CNN kernel and its impact on the performance of the model. \n- Demonstrate  through some sample figures that GP-CNN with pooling achieves invariance while GP-CNN with out pooling fail to capture it.\n- Is the best result on CIFAR-10  achieved using the proposed method ? See Deep convolutional Gaussian processes by Kenneth Blomqvist, Samuel Kaski, Markus Heinonen\n- Include the results with CNN-GP both with pooling and without pooling in Table 1 and Table 2. \n- Provide the results of best SGD trained CNN against CNN-GP, both with pooling, as in Figure 3.c. Is the same trend observed in this case also ?\n- Experimental comparison and results on other Image datasets, specifically MNIST. Does the same observations hold on MNIST too ? \n\nClarity\n\nThe paper is relatively well written and clearly provides main ideas leading to the results. However, notations could have made more succinct, and figures could have been more legible( Axis labels are missing for some figures in Figure 3, and provide legends wherever possible). The is also an ambiguity in what CNN-GP refers to, with pooling to without pooling.\n- The term CNN-GP is overloaded in many places in the experimental section. I guess in Table 1, its CNN-GP without pooling, while in Table 2, its CNN-GP with pooling. Kindly make the distinction clear in the nomenclature itself, by calling one of them by a different name. Its also not clear when they mention SGD trained CNN, if it is with pooling or without pooling.  \n- What is the difference between the top and bottom pair of figures in Figure 3 (b). Why is the GP performance different in top and bottom cases.?\n- What does 10, 100, 1000 correspond to in Figure 3 ? Please explain it in caption.\n\nOriginality\n\nPrevious works of  Lee and G. Matthews (2018) had shown the equivalence between Deep Neural Networks and GPs. This paper has extended it  to deep convolutional  neural network setting, but is interesting in its own way. The have come up with an equivalent kernel corresponding to infinite wide Bayesian convolution neural network and provided a monte-carlo approach to compute it. Along with the theoretical contribution, they have also provided extensive experimental comparison. \n\nSignificance\n\nThe paper has made significant contributions connecting the Bayesian convolutional neural networks with Gaussian processes, in deriving the equivalent kernel for GPs, and in demonstrating the performance of the proposed approach on Image datasets']","[50, 50, 80, 70]","[75, 80, 70, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer recommends acceptance and describes the paper as 'generally of a high quality', but also points out several areas for improvement. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as ways to 'improve' or 'enhance' the paper rather than as flaws. The reviewer also acknowledges the authors' efforts and uses phrases like 'I would welcome' and 'I think' to soften critiques. The tone is professional and collegial throughout, even when pointing out issues with figures and presentation."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by expressing appreciation for the authors' efforts and states they will recommend acceptance, which is quite positive. However, they also raise several technical concerns and requests for clarification, tempering the overall sentiment. The politeness score is 80 (quite polite) because the reviewer consistently uses respectful language like 'I greatly appreciate', 'please clarify', and 'Thank you for...'. They offer constructive criticism in a professional manner, balancing positive feedback with areas for improvement. The reviewer maintains a collegial tone throughout, even when pointing out issues with the paper."", ""The sentiment score is 80 out of 100 because the reviewer expresses a very positive overall view of the paper, calling it 'a very strong and complete paper' and stating that 'it adds, and a lot' to the field. They recommend it for publication and have no arguments against acceptance. The score is not 100 because there are some minor criticisms, such as it being difficult for newcomers. The politeness score is 70 out of 100 because the reviewer uses respectful and constructive language throughout, offering suggestions politely ('I suggest...', 'Why not...') rather than demands. They also acknowledge their own limitations ('my limited knowledge'). However, the tone is professional rather than overtly friendly, hence not a perfect 100."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its strong theoretical and experimental contributions, and its relevance to the conference. They mention that the paper provides a theoretical connection, the derivations seem correct, and the experiments are well-conducted. However, it's not a perfect 100 as the reviewer suggests some improvements and clarifications.\n\nThe politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before suggesting improvements, and phrase their recommendations as suggestions rather than demands. For example, they use phrases like 'some discussion and clarity on the following points will be useful to improve the paper' and 'kindly make the distinction clear'. The tone is professional and supportive, aiming to help the authors improve their work.""]"
"['This paper proposes a method for estimating non-linear similarities between items using Gramian estimation. This is achieved by having two separate neural networks defined for each item to be compared, which are then combined via a dot product. The proposed innovation in this paper is to use Gramian estimation for the penalty parameter of the optimization which allows for the non-linear case. Two algorithms are proposed which allow for estimation in the stochastic / online setting. Experiments are presented which appear to show good performance on some standard benchmark tasks. \n\nOverall, I think this is an interesting set of ideas for an important problem. I have two reservations. First, the organization of the paper needs to be addressed in order to aid user readability. The paper often jumps across sections without giving motivation or connecting language. This will limit the audience of the paper and the work. Second (and more importantly), I found the experiments to be slightly underwhelming. The hyperparameters (batch size, learning rate) and architecture don’t have any rationale attached to them. It is also not entirely clear whether the chosen comparison methods fully constitute the current state of the art. Nonetheless, I think this is an interesting idea and strong work with compelling results. \n\nEditorial comments:\n\nThe organization of this paper leaves something to be desired. The introductions ends very abruptly, and then appears to begin again after the related work section. From what I can tell the first three sections all constitute the introduction and should be merged with appropriate edits to make the narrative clear.\n\n“where x and y are nodes in a graph and the similarity is wheter an edge” → typo and sentence ends prematurely. \n', 'This paper proposes an efficient algorithm to learn  neural embedding models with a dot-product structure over very large corpora. The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process. The algorithm uses less time and achieves significantly better quality than sampling based methods. \n\n1. About the experiments, it seems the sample size for sampling based experiments is not discussed. The number of noise samples have a large influence on the performance of the models. In figure 2, different sampling strategies are discussed. It would be cool if we can also see how the sampling size affects the estimation error. \n\n2. If we just look at the sampling based methods, in figure 2a, uniform sampling’s Gramian estimates is the worst. But the MAP of uniform sampling on validation set for all three datasets are not the worst. Do you have any comments?\n\n3. wheter an edge -> whether an edge.\n', ""Summary of the paper:\n\nThis work presents a novel method for similarity function learning using non-linear model. The main problem with the similarity function learning models is the pairwise component of the loss function which grows quadratically with the training set. The existing stochastic approximations which are agnostic to training set size have high variance and this in-turn results in poor convergence and generalisation. This paper presents a new stochastic approximation of the pairwise loss with reduced variance. This is achieved by exploiting the dot-product structure of the least-squares loss and is computationally efficient provided the embedding dimensions are small. The core idea is to rewrite the least-squares as the matrix dot product of two PSD matrices (Grammian). The Grammian matrix is the sum of the outer-product of embeddings along the training samples. The authors present two algorithms for training the model, 1)SAGram: By maintaining a cache of all embedding vectors of training points (O(nk) space)$, whenever a point is encountered it's cache is replaced with it's embedding vector. 2) SOGram: This algorithm keeps a moving average of the Grammian estimate to reduce the variance. Experimental results shows that this approach reduces the variance in the Grammian estimates, results in faster convergence and better generalisation.\n\nReview:\n\nThe paper is well written with clear contribution to the problem of similarity  learning.  My only complain is that, I think the evaluation is a bit weak and does not support the claim that is applicable all kinds of problems e.g. nlp and recommender systems. This task in Wikipedia does not seem to be standard (kind of arbitrary) — there are some recommendation results in the appendix but I think it should have been in the main paper.\n\nOverall interesting but I would recommend evaluating in standard similarity learning for nlp and other tasks (perhaps more than one)\n\nThere are specific similarity evaluation sets for word embeddings. It can be found in following papers: https://arxiv.org/pdf/1301.3781.pdf  \nhttp://www.aclweb.org/anthology/D15-1036""]","[50, 70, 50]","[70, 80, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'an interesting set of ideas for an important problem' and mentions 'compelling results'. However, they also express reservations about the organization and experiments, balancing out the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the strengths of the work while offering constructive criticism. They use phrases like 'I think' and 'I found' to soften their critiques, and provide specific suggestions for improvement rather than harsh criticism."", ""The sentiment score is 70 (positive) because the review begins with a positive summary of the paper, highlighting its efficiency and superior performance. The reviewer acknowledges the paper's contributions and innovative approach. The politeness score is 80 (very polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'it would be cool if' and asks for comments rather than demanding changes. The feedback is presented as suggestions and questions, maintaining a collegial tone. The reviewer also helpfully points out a minor typo, which is done matter-of-factly without criticism. The overall language is professional and courteous, focusing on improving the paper rather than criticizing it."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'well written with clear contribution', but then expresses concerns about the evaluation being 'a bit weak'. The overall tone is constructive and interested, but not overwhelmingly positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, softens criticism with phrases like 'My only complain is', and offers specific suggestions for improvement rather than harsh criticism. The reviewer maintains a professional and courteous tone while still providing honest feedback.""]"
"[""# [Updated after author response]\nThank you for your response. I am happy to see the updated paper. In particular, the added item in section 1.3 highlights where the novelty of the paper lies, and as a consequence, I think the significance of the paper is increased. Furthermore, the clarity of the paper has increased. \n\nIn its current form, I think the paper would be a valuable input to the deep learning community, highlighting an important issue (CF) for neural networks. I have therefore increased my score.\n\n------------------------------------------\n\n# Summary\nThe authors present an empirical study of catastrophic forgetting (CF) in deep neural networks. Eight models are tested against nine datasets with 10 classes each but a varying number of samples. The authors construct a number of sequential learning tasks to test the model performances in different scenarios. The main conclusion is that CF is still a problem in all models, despite claims in other papers.\n\n# Quality\nThe paper shows healthy criticism of the methods used to evaluate CF in previous works. I very much like this.\n\nWhile I like the different experimental set-ups and the attention to realistic scenarios outlined in section 1.2, I find the analysis of the experiments somewhat superficial. The accuracies of each model for each task and dataset are reported, but there is little insight into what causes CF. For instance, do some choices of hyperparameters consistently cause a higher/lower degree of CF across models? I also think the metrics proposed by Kemker et al. (2018) are more informative than just reporting the last and best accuracy, and that including these metrics would improve the quality of the paper.\n\n# Clarity\nThe paper is generally clearly written and distinct paragraphs are often highlighted, which makes reading and getting an overview much easier. In particular, I like the summary given in sections 1.3 and 1.4.\n\nSection 2.4 describing the experimental setup could be clearer. It takes a bit of time to decipher Table 2, and it would have been good with a few short comments on what the different types of tasks (D5-5, D9-1, DP10-10) will tell us about the model performances. E.g. what do you expect to see from the experiments of D5-5 that is not covered by D9-1 and vice versa? And why are the number of tasks in each category so different (8 vs 3 vs 1)?\n\nI am not a huge fan of 3D plots, and I don't think they do anything good in section 4. The perspective can make it tricky to compare models, and the different graphs overshadow each other. I would prefer 2D plots in the supplementary, with a few representative ones shown in the main paper. I would also experiment with turning Table 3 into a heat map.\n\n# Originality\nTo my knowledge, the paper presents the largest evaluation of CF in terms of evaluated datasets. Kemker et al. (2018) conduct a somewhat similar experiment using fewer datasets, but a larger number of classes, which makes the CF even clearer. I think it would be good to cite this paper and briefly discuss it in connection with the current work.\n\n# Significance\nThe paper is mostly a report of the outcome of a substantial experiment on CF, showing that all tested models suffer from CF to some extent. While this is interesting and useful to know, there is not much to learn in terms of what can cause or prevent CF in DNNs. The paper's significance lies in showing that CF is still a problem, but there is room for improvement in the analysis of the outcome of the experiments.\n\n# Other notes\nThe first sentence of the second paragraph in section 5 seems to be missing something.\n\n# References\nKemker, R., McClure, M., Abitino, A., Hayes, T., & Kanan, C. (2018). In AAAI Conference on Artificial Intelligence. https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16410"", 'Thanks for the updates and rebuttals from the authors. \n\nI now think including the results for HAT may not be essential for the current version of the paper. I now understand better about the main point of the paper - providing a different setting for evaluating algorithms for combatting CF, and it seems the widespread framework may not accurately reflect all aspects of the CF problems. \n\nI think showing the results for only 2 tasks are fine for other settings except for DP10-10 setting, since most of them already show CF in the given framework for 2 tasks. Maybe only for DP10-10, the authors can run multiple tasks setting, to confirm their claims about the permuted datasets. (but, I believe the vanilla FC model should show CF for multiple permuted tasks.)\n\nI have increased my rating to ""6: Marginally above acceptance threshold"" - it could have been much better to at least give some hints to overcome the CF for the proposed setting, but I guess giving extensive experimental comparisons could be valuable for a publication. \n\n=====================\nSummary:\n\nThe paper evaluates several recent methods regarding catastrophic forgetting with some stricter application scenarios taken into account. They argue that most methods, including EWC and IMM, are prone to CF, which is against the argument of the original paper. \n\nPro:\n- Extensive study on several datasets, scenarios give some intuition and feeling about the CF phenomenon. \n\nCon:\n- There are some more recent baselines., e.g., Joan Serrà, Dídac Surís, Marius Miron, Alexandros Karatzoglou, ""Overcoming catastrophic forgetting with hard attention to the task"" ICML2018, and it would be interesting to see the performance of those as well. \n- The authors say that the permutation based data set may not be useful. But, their experiments are only on two tasks, while many work in literature involves much larger number of tasks, sometimes up to 50. So, I am not sure whether the paper\'s conclusion that the permutation-based SLT should not be used since it\'s only based on small number of tasks. \n- While the empirical findings seem useful, it would have been nicer to propose some new method that can get around the issues presented in the paper. ', ""The paper presents a study of the application of some well known methods on 9 datasets focusing on the issue of catastrophic forgetting when considering a sequential learning task in them.  In general the presentation of concepts and results is a bit problematic and unclear. Comments, such that the paper presents ' a novel training and model selection paradigm for incremental learning in DNNs ' is not justified.  A better description of the results, e.g., in Table 3 should be presented, as well a better linking with the findings; a better structure of the latter would also be required to improve consistency of them. Improving these could make the paper candidate for a poster presentation.  ""]","[50, 40, -30]","[80, 70, 20]","[""Sentiment score: The review starts with a positive tone, thanking the authors for their response and expressing happiness with the updated paper. The reviewer notes improvements in clarity and significance, and states that the paper would be 'a valuable input to the deep learning community'. However, there are also some criticisms and suggestions for improvement, which is why I didn't give a higher positive score. Politeness score: The language used is consistently polite and constructive. The reviewer uses phrases like 'Thank you', 'I am happy to see', and 'I very much like this'. Even when offering criticisms, the tone remains respectful and helpful, suggesting improvements rather than just pointing out flaws. The reviewer also acknowledges the positive aspects of the paper throughout."", ""The sentiment score is 40 (slightly positive) because the reviewer has increased their rating to 'Marginally above acceptance threshold' and acknowledges the value of the extensive experimental comparisons. However, they still express some reservations and suggestions for improvement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, thanks the authors for their updates and rebuttals, and frames criticisms constructively. They use phrases like 'I now understand better' and 'I think' to soften their statements. The reviewer provides a balanced view, listing both pros and cons, and offers suggestions for improvement rather than harsh criticism."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper's presentation and clarity. However, it's not entirely negative as it suggests improvements that could make the paper suitable for a poster presentation. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively neutral language and offer constructive feedback. The reviewer avoids harsh or personal criticism, instead focusing on specific areas for improvement. The use of phrases like 'a bit problematic' and 'could make the paper candidate for' soften the criticism and maintain a professional tone.""]"
"['This paper presents a VAE approach in which a dependency structure on the latent variable is learned during training.  Specifically, a lower-triangular random binary matrix c is introduced, where c_{i,j} = 1 for i>j, indicates that z_i depends on z_j, where z is the latent vector.  Each element of c is separately parametrized by a Bernoulli distribution whose means are optimized for during training, using the target \\mathbb{E}_{p(c)}[\\mathcal{L}_c] where \\mathcal{L}_c indicates the ELBO for a particular instance of c.  The resulting ""Graph-VAE"" scheme is shown to train models with improved marginal likelihood than a number of baselines for MNIST, Omniglot, and CIFAR-10.\n\nThe core concept for this paper is good, the results are impressive, and the paper is, for the most part, easy to follow.  Though I think a lot of people have been thinking about how to learn dependency structures in VAEs, I think this work is the first to clearly lay out a concrete approach for doing so.  I thus think that even though this is not the most novel of papers, it is work which will be of significant interest to the ICLR community.  However, the paper has a number of technical issues and I do not believe the paper is suitable for publication unless they are addressed, or at the vest least acknowledged. I further have some misgivings with the experiments and the explanations of some key elements of the method.  Because of these issues, I think the paper falls below the acceptance threshold in its current form, but I think they could potentially be correctable during the rebuttal period and I will be very happy to substantially increase my score if they are; I feel this has the potential to be a very good paper that I would ultimately like to see published.\n\n%%% Lower bound %%%\n\nMy first major concern is in the justification of the final approach (Eq 8), namely using a lower bound argument to move the p(c) term outside of the log.  A target being a lower bound on something we care about is never in itself a justification for that target -- it just says that the resulting estimator is provably negatively biased.  The arguments behind the use of lower bounds in conventional ELBOs are based on much more subtle arguments in terms of the bound becoming tight if we have good posterior approximations and implicit assumptions that the bound will behave similarly to the true marginal.  The bound derived in A.1 of the current paper is instead almost completely useless and serves little purpose other than adding ""mathiness"" of the type discussed in https://arxiv.org/abs/1807.0334. Eq 8 is not a variational end-to-end target like you claim.  It is never tight and will demonstrably behave very differently to the original target.\n\nTo see why it will behave very differently, consider how the original and bound would combine two instances of c for the MNIST experiment, one corresponding to the MAP values of c in the final trained system, the other a value of c that has an ELBO which is, say, 10 nats lower.  Using Eq 8, these will have similar contributions to the overall expectation and so a good network setup (i.e. theta and phi) is one which produces a decent ELBO for both.  Under the original expectation, on the other hand, the MAP value of c corresponds to a setup that has many orders of magnitude higher probability and so the best network setup is the one that does well for the MAP value of c, with the other instance being of little importance.  We thus see that the original target and the lower bound behave very differently for a given p(c).\n\nThankfully, the target in Eq 8 is a potentially reasonable thing to do in its own right (maybe actually more so that the original formulation), because the averaging over c is somewhat spurious given you are optimizing its mean parameters anyway.  It is easy to show that the ""optimum"" p(c) for a given (\\theta,\\phi) is always a delta function on the value of c which has the highest ELBO_c.  As Fig 3 shows, the optimization of the parameters of p(c) practically leads to such a collapse.  This is effectively desirable behavior given the overall aims and so averaging over values of c is from a modeling perspective actually a complete red herring anyway.  It is very much possible that the training procedure represented by Eq 8 is (almost by chance) a good approach in terms of learning the optimal configuration for c, but if this is the case it needs to be presented as such, instead of using the current argument about putting a prior on c and constructing a second lower bound, which is a best dubious and misleading, and at worst complete rubbish.  Ideally, the current explanations would be replaced by a more principled justification, but even just saying you tried Eq 8 and it worked well empirically would be a lot better than what is there at the moment.\n\n%%% Encoder dependency structure does not match the generative model %%%\n\nMy second major concern is that the dependency structure used for the encoder is incorrect from the point of view of the generative model.  Namely, a dependency structure on the prior does not induce the same dependency structure on the posterior.  In general, just because z_1 and z_2 are independent, doesn\'t mean that z_1 and z_2 are independent given x (see e.g. Bishop).  Consequently, the encoder in your setup will be incapable of correctly representing the posterior implied by the generative model.  This has a number of serious practical and theoretical knock-on effects, such as prohibiting the bound becoming tight, causing the encoder to indirectly impact the expressivity of the generative model etc.  Note that this problem is not shared with the Ladder VAE, as there the Markovian dependency structure means produces a special case where the posterior and prior dependency structure is shared.\n\nAs shown in https://arxiv.org/abs/1712.00287 (a critical missing reference more generally), it is actually possible to derive the dependency structure of the posterior from that of the prior.  I think in your case their results imply that the encoder needs to be fully connected as the decoder can induce arbitrary dependencies between the latent variables.  I am somewhat surprised that this has not had more of an apparent negative impact on the empirical results and I think at the very very least the paper needs to acknowledge this issue.  I would recommend the authors run experiments using a fully connected encoder and the Graph-VAE decoder (and potentially also vice verse).  Should this approach perform well, it would represent a more principled approach to replace the old on from a generative model perspective.  Should it not, it would provide an empirical justification for what is, in essence, a different restriction to that of the learned prior structure: it is conceivably actually the case that these encoder restrictions induce the desired decoder behavior, but this is distinct to learning a particular dependency structure in the generative model.\n\n%%% Specifics of model and experiments %%%\n\nThough the paper is generally very easy to read, there as some key areas where the explanations are overly terse.  In particular, the explanation surrounding the encoding was difficult to follow and it took me a while to establish exactly what was going on; I am still unsure how \\tilde{\\psi} and \\hat{\\psi} are combined.  I think a more careful explanation here and a section giving more detail in the appendices would both help massively.\n\nI was not clear on exactly what was meant by the FC-VAE.  I do not completely agree with the assertion that a standard VAE has independent latents.  Though the typical choice that the prior is N(0,I) obviously causes the prior to have independent latents, as explained earlier, this does not mean the latents are independent in the posterior.  Furthermore, the encoder implicitly incorporates these dependencies through its mean vector, even if it uses a diagonal covariance (which is usually rather small anyway).  What is actually changed from this by the FC-VAE?  Are you doing some kind of normalizing flow approach here?  If so this needs proper explanation.\n\nRelatedly, I am also far from convinced by the arguments presented about why the FC-VAE does worse at the end of the experiments.  VAEs attempt to maximize a marginal likelihood (through a surrogate target) and a model which makes no structural assumptions will generally have a lower marginal likelihood than one which makes the correct structural assumptions.  It is thus perfectly reasonable that when you learn dependency structures, you will get a higher marginal likelihood than if you presume none.  I thus find your arguments about local optima somewhat speculative and further investigation is required.\n\n%%% Experiments %%%\n\nThough certainly not terrible, I felt that the experimental evaluation of the work could have been better.  The biggest issue I have is that no error bars are given for the results, so it is difficult to assess the robustness of the Graph-VAE.  I think it would be good to add convergence plots with error bars to see how the performance varies with time and provide an idea of variability.  More generally, the experiment section overall feels more terse and rushed than the rest of the paper, with some details difficult to find or potentially even straight up missing.\n\nThough Fig 3 is very nice, it would be nice to have additional plots seeing qualitatively what happens with the latent space.  E.g. on average what proportion of the c tend to zero?  Is the same dependency structure always learned?  What do the dataset encodings look like?  Are there noticeable qualitative changes in samples generated from the learned models?  I would be perfectly happy for the paper to extend over the 8 pages to allow more results addressing these questions.', ""The authors propose to augment the latent space of a Variational AutoEncoder [1] with an auto-regressive structure, to improve the expressiveness of both the inference network and the latent prior, making them into a general DAG of latent variables. This works goes further in the same direction as the Ladder VAE [2]. This paper introduces a mechanism for the latent model to directly learn its DAG structure by first considering the fully-connected DAG of latent variables, and adding Bernoulli variables controlling the presence or absence of each edge. The authors derive a new ELBO taking these variables into account, and use it to train the model. The gradients of the parameters of the Bernoulli variables are computed using the Gumbel-Softmax approach [3] and annealing the temperature.\n\nThe authors observe with they experiments that the Bernoulli variables converge relatively quickly towards 0 or 1 during the training, fixing the structure of the DAG for the rest of the training. They test their model against a VAE, a Ladder VAE and an alternative to their model were the DAG is fixed to remain fully-connected (FC-VAE), and observe improvements in terms of the ELBO values and log-likelihood estimations.\n\nThe main addition of this paper is the introduction of the gating mechanism to reduce the latent DAG from its fully-connected state. It is motivated by the tendency of latent models to fall into local optima.\n\nHowever, it is not clear to me what this mechanism as it is now adds to the model:\n\n- The reported results shows the improvements of Graph-VAE over FC-VAE to be quite small, making their relevance dubious in the absence of measurement of variance accross different trainings. Additionally, the reported performances for Ladder VAE are inferior to what [2] reports. Actually the performance of Ladder-VAE reported in [2] is better than the one reported for Graph-VAE in this paper, both on the MNIST and Omniglot datasets.\n\n- The authors observe that the Bernoulli variables have converged after around ~200 epochs. At this time, according to their reported experimental setup, the Gumbel-Softmax temperature is 0.999^200 ~= 0.82, which is still quite near 1.0, meaning the model is still pretty far from a real Bernoulli-like behavior. And actually, equation 9 is not a proper description of the Gumbel-Softmax as described by [3] : there should be only 2 samples from the Gumbel distribution, not 3. Given these two issues, I can't believe that the c_ij coefficients behave like Bernoulli variables in this experiment. As such, It seems to me that Graph-VAE is nothing more than a special reparametrization of FC-VAE that tends to favor saturating behavior for the c_ij variables.\n\n- On figure 3b, the learned structure is very symmetrical (z2, z3, z4 play an identical role in the final DAG). In my opinion, this begs for the introduction of a regulatory mechanism regarding the gating variable to push the model towards sparsity. I was honestly surprised to see this gating mechanism introduced without anything guiding the convergence of the c_ij variables.\n\nI like the idea of learning a latent structure DAG for VAEs, but this paper introduces a rather weak way to try to achieve this, and the experimental results are not convincing.\n\n[1] https://arxiv.org/abs/1312.6114\n[2] https://arxiv.org/abs/1602.02282\n[3] https://arxiv.org/abs/1611.01144"", ""Often in a deep generative model with multiple latent variables, the structure amongst the latent variables is pre-specified before parameter estimation. This work aims to learn the structure as part of the parameters. To do so, this work represents all possible dependencies amongst the latent random variables via a learned binary adjacency matrix, c, where a 1 denotes each parent child relationship.\n\nEach setting of c defines a latent variable as the root and subsequent parent-child relationships amongst the others. To be able to support (up to N-1) parents, the paper proposes a neural architecture where the sample from each parent is multiplied by the corresponding value of c_ij (0'd out if the edge does not exist in c), concatenated and fed into an MLP that predicts a distribution over the child node. The inference network shares parameters with the generative model (as in Sonderby et. al). Given any setting of c, one can define the variational lower-bound of the data. This work performs parameter estimation by sampling c and then performing gradient ascent on the resulting lower-bound.\n\nThe model is evaluated on MNIST, Omniglot and CIFAR where it is found to outperform a VAE with a single latent variable (with the same number of latent dimensions as the proposed graphVAE), the LadderVAE and the FCVAE (VAE with a fully connected graph). An ablation study is conducted to study the effect of number of nodes and their dimensionality.\n\nOverall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks.\n\nComments and questions for the authors:\n* Clarity\nIt might be instructive to describe in detail how the inference network is structured for different settings of c (for example, via a scenario with three latent variables) rather than via reference to Sonderby et. al.\n\nWhat prior distribution was used for c?\n\nFor the baseline comparing to the LadderVAE, what dimensionalities were used for the latent variables in the LadderVAE (which has a chain structured dependence amongst its latent variables)? The experimental setup keeps fixed the latent dimensionality to 80 -- the original paper recommends a different dimensionality for each latent variables in the chain [https://arxiv.org/pdf/1602.02282.pdf, Table 2] -- was this tried? Did the ladderVAE do better if each latent variable in the chain was allowed to have a dimensionality?\n\n* Related work\nThere is related work which leverages Bayesian non-parametric models to learn hierarchical priors for deep generative models. It is worth discussing for putting this line of work into context. For example:\nhttp://openaccess.thecvf.com/content_ICCV_2017/papers/Goyal_Nonparametric_Variational_Auto-Encoders_ICCV_2017_paper.pdf\nand more recently: https://arxiv.org/pdf/1810.06891.pdf\n\nIn the context of defining inference networks for generative models where the latent variables have structure, Webb et. al [https://arxiv.org/abs/1712.00287] describe how inference networks should be setup in order to invert the generative process.\n\n* Qualitative study\nNotable in its absence is a qualitative analysis of what happens to the data sampled from the model when the various nodes in the learned hierarchy are perturbed holding fixed their parents. Have you attempted this experiment? Are the edge relationships sensible or interesting?\n\nIs there a relationship between the complexity of each conditional distribution in the generative model and the learned latent structure? Specifically, have you experimented to see what happens to the learned structure amongst the latent variables if each conditional density is a linear function of its parents?\n""]","[-30, -60, 80]","[50, 20, 70]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The core concept for this paper is good, the results are impressive'), they express significant concerns and state that 'the paper falls below the acceptance threshold in its current form'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and expressing willingness to increase their score if issues are addressed. They use phrases like 'I think' and 'I feel' to soften criticisms, and acknowledge potential value in the work. However, some direct criticisms (e.g., 'complete rubbish') prevent a higher politeness score."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's contributions and results. They state that the improvements are 'quite small', the relevance is 'dubious', and the experimental results are 'not convincing'. The reviewer also points out several issues with the methodology and interpretation of results. However, the score is not at the extreme negative end because the reviewer does acknowledge liking the general idea behind the paper.\n\nThe politeness score is 20 because the reviewer maintains a professional and academic tone throughout, avoiding personal attacks or overly harsh language. They use phrases like 'it is not clear to me' and 'I can't believe that' to express disagreement, which are relatively polite ways to critique. The reviewer also acknowledges positive aspects, such as 'I like the idea'. However, the score is only slightly positive because the review is primarily critical and doesn't go out of its way to be exceptionally polite or encouraging."", ""The sentiment score is 80 (positive) because the reviewer states the paper is 'well written', proposes a 'new, interesting idea', and 'improves the quality of results on some standard benchmarks'. The overall tone is appreciative of the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, framing critiques as questions or suggestions rather than demands. For example, 'It might be instructive to...' and 'Have you attempted this experiment?' The reviewer also acknowledges the paper's strengths before offering constructive feedback. The language is professional and courteous, avoiding any harsh or dismissive statements.""]"
"['- Summary: This paper proposes verification algorithms for a class of convex-relaxable specifications to evaluate the robustness of the network under adversarial examples. Experimental results are shown for semantic specifications for CIFAR, errors in predicting sum of two digits and conservation of energy in a simple pendulum. \n\n- Clarity and correctness: It is a well-written and well-organized paper. Notations and expressions are clear. The math seems to be correct. \n\n- Significance: The paper claims to have introduced a class of convex-relaxable specifications which constitute specifications that can be verified using a convex relaxation. However, as described later in the paper, it is limited to feed-forward neural networks with ReLU and softmax activation functions and quadratic parts (it would be better to tone down the claims in the abstract and introduction parts.)\n\n- Novelty: The idea of accounting for label semantics and quadratic expressions when training a robust neural network is important and very practical. This paper introduces some nice ideas to generalize linear verification functions to a larger class of convex-relaxable functions, however, it seems to be more limited in practice than it claims and falls short in presenting justifying experimental results.\n\n** More detailed comments:\n\n** The idea of generalizing verifications to a convex-relaxable set is interesting, however, applying it in general is not very clear -- as the authors worked on a case by case basis in section 3.1. \n\n** One of my main concerns is regarding the relaxation step. There is no discussion on the effects of the tightness of the relaxation on the actual results of the models; when in reality, there is an infinite pool of candidates for \'convexifying\' the verification functions. It would be nice to see that analysis as well as a discussion on how much are we willing to lose w.r.t. to the tightness of the bounds -- especially when there is a trade-off between better approximation to the verification function and tightness of the bound. \n\n** I barely found the experimental results satisfying. To find ""reasonable"" inputs to the model, authors considered perturbing points in the test set. However, I am not sure if this is a reasonable assumption when there would be no access to test data points when training a neural network with robustness to adversarial examples. And if bounding them is a very hard task, I am wondering if that is a reasonable assumption to begin with.\n\n** It is hard to have a sense of how good the results are in Figure 1 due to lack of benchmark results (I could not find them in the Appendix either.)\n\n** The experimental results in section 4.4 are very limited. I suggest that the authors consider running more experiments on more data sets and re-running them with more settings (N=2 for digit sums looks very limited, and if increasing N has some effects, it would be nice to see them or discuss those effects.)\n\n** Page 2, ""if they do a find a proof"" should be --> ""if they do find a proof"" \n** Page 5, ""(as described in Section (Bunel et al., 2017; Dvijotham et al., 2018)"", ""Section"" should be omitted.\n\n******************************************************\nAfter reading authors\' responses, I decided to change the score to accept. It got clear to me that this paper covers broader models than I originally understood from the paper. Changing the expression to general forms was a useful adjustment in understanding of its framework. Comparing to other relaxation technique was also an interesting argument (added by the authors in section H in the appendix). Adding the experimental results for N=3 and 4 are reassuring.\nOne quick note: I think there should be less referring to papers on arxiv. I understand that this is a rapidly changing area, but it should not become the trend or the norm to refer to unpublished/unverified papers to justify an argument.', ""This paper considers more general non-linear verifications, which can be convexified, for neural networks, and demonstrate that the proposed methodology is capable of modeling several important properties, including the conversation law, semantic consistency, and bounding errors.\n\nA few other comments\n\n*) Is it critical that the non-linear verifications need to be convex relaxable. Recently, people have observed that a lot of nonconvex optimization problems also have good local solutions. Is it true that the convex relaxable condition is only required for provable algorithm? As the neural network itself is nonconvex, constraining the specification to be convex is a little awkward to me.\n\n*) The paper contains the example specification functions derived for three specific purpose, I'm wondering how broad the proposed technique could be. Say if I need my neural network to satisfy other additional properties, is there a general recipe or guideline. If not, what's the difficulty intuitively speaking?\n\nThe paper needs to be carefully proofread, and a lot of commas are missing."", 'This paper uses convex relaxation to verify a larger class of specifications\nfor neural network\'s properties. Many previous papers use convex relaxations on\nthe ReLU activation function and solve a relaxed convex problem to give\nverification bounds.  However, most papers consider the verification\nspecification simply as an affine transformation of neural network\'s output.\nThis paper extends the verification specifications to a larger family of\nfunctions that can be efficiently relaxed.\n\nThe author demonstrates three use cases for non-linear specifications,\nincluding verifying specifications involving label semantics, physic laws and\ndown-stream tasks, and show some experiments that the proposed verification\nmethod can find non-vacuous bound for these problems. Additionally, this paper\nshows some interesting experiments on the value of verification - a more\nverifiable model seems to provide more interpretable results.\n\nOverall, the proposed method seems to be a straightforward extension to\nexisting works like [2]. However the demonstrated applications of non-linear\nspecifications are indeed interesting, and the proposed method works well on \nthese tasks.\n\nI have some minor questions regarding this paper:\n\n1) For some non-linear specifications, we can convert these non-linear elements\ninto activation functions, and build an equivalent network for verification\nsuch that the final verification specification becomes linear. For example, for\nverifying the quadratic specification in physics we can add a ""quadratic\nactivation function"" to the network and deal with it using techniques in [1] or\n[2].  The authors should distinguish the proposed technique with these existing\ntechniques. My understanding is that the proposed method is more general, but\nthe authors should better discussing more on the differences in this paper.\n\n2) The authors should report the details on how they solve the relaxed convex\nproblem, and report verification time. Are there any tricks used to improve\nsolving time? What is the largest scale of network that the algorithm can\nhandle within a reasonable time?\n\n3) The detailed network architecture (Model A, Model B) is not shown. How many\nlayers and neurons are there in these networks? This is important to show the\nscalability of the proposed method.\n\n4) For the Mujoco experiment, I am not sure how to interpret the delta values\nin Figure 1. For CIFAR I know it is the delta of pixel values but it is not\nclear about the delta in Mujoco model. What is the normal range of predicted\nnumbers in this model?  How does the delta compare to it? Is the delta very\nsmall or trivial?\n\n5) Is it possible to show how loose the convex relaxation is for a small toy\nexample? For example, the specification involving quadratic function is a\ngood candidate.\n\nThere are some small glitches in equations:\n\n* In (4), k is undefined\n* In (20), I am not sure if it is equivalent to the four inequalities after (22).\nThere are 4 inequalities after (22) but only 3 in (20).\n\n\nMany papers uses convex relaxations for neural network verification. However\nvery few of them can deal with general non-linear units in neural networks.\nReLU activation is usually the only non-linear element than we can handle in\nmost neural network verification works. Currently the only works that can\nhandle other general non-linear elements are [1][2]. This paper uses more\ngeneral convex relaxations than these previous approaches, and it can handle\nnon-separable non-linear specifications. This is a unique contribution to this\nfield. I recommend accepting this paper as long as the minor issues mentioned\nabove can be fixed.\n\n[1] ""Efficient Neural Network Robustness Certification with General Activation\nFunctions"" by Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, Luca Daniel.\nNIPS 2018\n\n[2] ""A dual approach to scalable verification of deep networks."" by\nKrishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and\nPushmeet Kohli. UAI 2018.\n\n']","[20, 50, 60]","[60, 75, 80]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths ('well-written', 'well-organized', 'introduces some nice ideas'), they also express several concerns and limitations. The overall tone suggests cautious approval rather than strong enthusiasm or criticism. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames concerns as suggestions ('It would be nice to see...', 'I suggest that the authors...'). The reviewer also acknowledges the authors' responses positively in the final paragraph, showing a willingness to reconsider their initial assessment. The language is professional and courteous, avoiding harsh or dismissive statements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and capabilities in the first paragraph, which is generally positive. However, the subsequent comments and questions indicate some reservations and areas for improvement, balancing out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's strengths. The final comment about proofreading is direct but not rude. The overall tone is constructive and professional, maintaining politeness while providing feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper. They describe the proposed method as 'interesting' and 'works well', and recommend accepting the paper. However, they also mention that it's a 'straightforward extension' and raise several questions, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and maintains a professional tone. They use phrases like 'I have some minor questions' and 'The authors should' which are polite ways to offer feedback. The reviewer also acknowledges the paper's contributions and recommends acceptance, which contributes to the polite tone.""]"
"['This paper propose to add an OT-based regularization term to seq-2-seq models in order to better take into account the distance between the generated and the reference and/or source sentences, allowing one to capture the semantic meaning of the sequences. Indeed, it allows the computation of a distance between embeddings of a set of words, and this distance is then used to define a penalized objective function.\nThe main issue with this computation is that it provides a distance between a set of words but not a sequence of words. The ordering is then not taken into account. Authors should discuss this point in the paper.\nExperiments show an improvement of the method w.r.t. not penalized loss.\n\nMinor comments:\n- in Figure 1, the OT matching as described in the text is not the solution of eq (2) but rather the solution of eq. (3) or the entropic regularization (the set of ""edges"" is higher than the admissible highest number of edges).\n- Introduction ""OT [...] providing a natural measure of distance for sequences comparisons"": it is not clear why this statement is true. OT allows comparing distributions, with no notion of ordering (see above).  \n- Table 1: what is NMT?\n- first paragraph, p7: how do you define a ""substantial"" improvement of the scores?\n- how do you set parameter $\\gamma$ in the experiments? Why did you choose \\beta=0.5 for the ipot algorithm?\n\n', ""This submission deals with text generation. It proposes a sequence level objective, motivated by optimal transport, which is used as a regularizer to the (more standard) MLE. The goal is to complement MLE by allowing `soft matches` between different tokens with similar meanings. Empirical evaluation shows that the proposed technique improves over baselines on many sequence prediction tasks. I found this paper well motivated and a nice read. I would vote for acceptance.\n\nPros:\n- A well-motivated and interesting method.\n- Solid empirical results.\n- Writing is clear.\n\nCons:\n- The split of `syntax--MLE` and `semantics--OT` seems a bit awkward to me. Matching the exact tokens does not appear syntax to me. \n- Some technical details need to be clarified.\n\nDetails:\n- Could the authors comment on the efficiency by using the IPOT approximate algorithm, e.g., how much speed-up can one get? I'm not familiar with this algorithm, but is there convergence guarantee or one has to set some kind of maximum iterations when applying it in this model?\n\n- Bottom of page 4, the `Complementary MLE loss paragraph`. I thought the OT loss is used as a regularizer, from the introduction. If the paper claims MLE is actually used as the complements, evidence showing that the OT loss works reasonably well on its own without including log loss, which I think is not included in the experiments.\n\n- I really like the analysis presented in Section 3. But it's a bit hard for me to follow, and additional clarification might be needed.\n\n- It would be interesting to see whether the `soft-copying` version of OT-loss can be combined with the copy mechanisms based on attention weights.\n\n================================\n\nThanks for the clarification and revision! It addressed some of my concerns. I would stick to the current rating, and vote for an acceptance."", '====== Final Comments =======\nI thank the authors for updating the manuscript with clarifications and for clear replies to my concerns. \n\nI agree with R2 to some extent that the empirical performance of the method, as well as the formulation,  is interesting. In general, the authors addressed my concerns regarding how optimal transport training model interfaces with MLE training and the choice of using scaled softmax for computing the Wasserstein distances. However, I still find myself agreeing with R3 that the choice of sets to compute Wasserstein distances (as opposed to sequences is somewhat unjustified); and it is not clear how the theory in Sec. 3 justifies using sets instead of words, as the data distribution p_d is over sequences in both the W-2 term as well as the MLE term. This would be good to clarify further, or explain more clearly how Sec. 3 justifies this choice.\n\nAlso, I missed this in the original review, but the assumption that KL(\\mu| p_d) = KL(\\p_d| \\mu) since \\mu is close to p_d for MLE training does not seem like a sensible assumption under model misspecification (as MLE is mode covering). I would suggest the authors discuss this in a revision/ camera-ready version.\n\nIn light of these considerations, I am updating the rating to 6 (to reflect the points that have been addressed), but I still do not believe that the method is super-well justified, despite an interesting formulation and strong empirical results (which are aspects the paper could still improve upon). \n=====================\n\n**Summary**\n\nThe paper proposes a regularization / fine-tuning scheme in addition to maximum likelihood sequence training using optimal transport. The basic idea is to match a sampled sentence from a model with a ground truth sentence using optimal transport. Experimental results show that the proposed modification improves over MLE training across machine translation, summarization and image captioning domains.\n\n**Strengths**\n+ The proposed approach shows promising results across multiple domains.\n+ The idea of using optimal transport to match semantics of words intuitively makes sense.\n\n**Weaknesses**\n1. Generally, one would think that for optimal transport we would use probabilities which come from the model, i.e. given a set of words and probabilities for each of the words, one would move mass around from one word to another word (present in the ground truth) if the words were semantically relevant to each other and vice versa. However, it seems the proposed algorithm / model does not get the marginal distributions for the words from the model, and indeed does not use any beliefs from the model in the optimal transport formulation / algorithm [Alg. 1, Line 2]. This essentially then means, following objective 2, that optimal transport has no effect on the model’s beliefs on the correct word, but merely needs to ensure that the cosine similarity between words which have a high transport mass is minimized, and has no direct relation to the belief of the model itself. This strikes as a somewhat odd design choice. (*)\n\n2. In general, another issue with the implementation as described in the paper could be the choice of directly using the temperature scaled softmax as an estimate of the argmax from the model, instead of sampling utterances from the model. It seems worth reporting results, even if as a baseline what sampling from something like a concrete distribution [A] yeilds in terms of results. (*)\n\n3. As a confirmation, Is the differentiable formulation for sentences also used for MLE training part of the objective, or does MLE still use ground truth sentences (one-hot encoded) as input. Does this mean that the model is forwarded twice (once with ground truth, and once with softmax outputs)? In general, instead of/ in addition to an Algorithm box that expains the approach of Xie et.al., it would be good to have a clear algorithmic explanation of the training procedure of the proposed model itself. Further, the paper is not clear if the model is always used for finetuning the an MLE model (as Section 3) seems to suggest or if the optimal transport loss is used in conjunction with the model as the bullet ``complementary MLE loss’’ seems to suggest. (*)\n\n4. Section 3: It is not clear that the results / justifications hold for the proposed model since the distance optimized in the current paper is not a wasserstein-2 distance. Sure, it computes cosine distance, which is L-2 but it appears wasserstein-2 distance is defined for continuous probability measures, while the space on which the current paper computes distances is inherently the (discrete) space of word choices. (*)\n\nExperiments\n5. The SPICE metric for image captioning takes the content of the sentences (and semantics) into account, instead of checking for fluency. Prior work on using RL techniques for sequence predictions have used SPICE + CIDEr [B] to alleviate the problem with RL methods mentioned in page. 5. Would be good to weaken the claim. (*)\n\nMinor Points\n1. It might be good to be more clear about the objective from Xie et.al. by also stating the modified formulation they discuss, and explaining what choice of the function yeilds the bregman divergence of the form discussed in Eqn. 3. \n2. It would be nice to be consistent with how \\mathcal{L}_{ot} is used in the paper. Eqn. 4 lists it with two embedding matrices as inputs, while Alg. 1, Line 11 assigns it to be the inner product of two matrices.\n\n**Preliminary Evaluation**\nIn general, the paper is an interesting take on improving MLE for sequence models. However, while the idea of using optimal transport is interesting and novel for training sequence models, I have questions about the particular way in which it has been implemented, which seems somewhat unjustified. I also have further clarifications about a claimed justification for the model. Given convincing responses for these, and other clarification questions (marked with a *) this would be a good paper.\n\nReferences\n[A]: Maddison, Chris J., Andriy Mnih, and Yee Whye Teh. 2016. “The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables.” arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1611.00712.\n[B]: Liu, Siqi, Zhenhai Zhu, Ning Ye, Sergio Guadarrama, and Kevin Murphy. 2016. “Improved Image Captioning via Policy Gradient Optimization of SPIDEr.” arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1612.00370.\n']","[20, 80, 20]","[60, 90, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution and notes improvements in experiments, but also points out some issues and asks for clarifications. The overall tone is constructive rather than overly critical. The politeness score is moderately high (60) as the reviewer uses respectful language, offers suggestions rather than demands, and frames criticisms as points for discussion. The use of phrases like 'Authors should discuss this point' and 'how do you define' indicate a polite approach to feedback. The review maintains a professional and courteous tone throughout, without using harsh or dismissive language."", ""The sentiment score is 80 because the reviewer expresses a clearly positive view of the paper, stating it is 'well motivated and a nice read' and that they 'would vote for acceptance'. They list several pros and only minor cons. The final paragraph reaffirms their positive stance. The politeness score is 90 as the reviewer uses respectful and constructive language throughout. They offer praise where due and frame criticisms as suggestions or questions rather than direct attacks. The reviewer also thanks the authors for clarifications and revisions, showing appreciation for their efforts."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges improvements made by the authors and finds the empirical performance and formulation interesting. However, they still have some reservations about the justification of the method. The politeness score is moderately high (60) as the reviewer uses respectful language, thanks the authors for their updates, and frames criticisms constructively. They use phrases like 'I thank the authors', 'I agree with', and 'I would suggest' which contribute to a polite tone. The reviewer balances positive feedback with areas for improvement, maintaining a professional and courteous demeanor throughout.""]"
"['The paper studies few-host learning in a transductive setting: using meta learning to learn to propagate labels from training samples to test samples. \n\nThere is nothing strikingly novel in this work, using unlabeled test samples in a transductive way seem to help slightly. However, the paper does cover a setup that I am not aware that was studied before. The paper is written clearly, and the experiments seem solid. \n\nComments: \n-- What can be said about how computationally demanding the procedure is? running label propagation within meta learning might be too costly. \n-- It is not clear how the  per-example scalar sigma-i is learned. (for Eq 2)\n-- solving Eq 3 by matrix inversion does not scale. Would be best to also show results using iterative optimization \n\n\n\n\n', 'Summary\nThis paper proposes a meta-learning framework that leverages unlabeled data by learning the graph-based label propogation in an end-to-end manner.  The proposed approaches are evaluated on two few-shot datasets and achieves the state-of-the-art results. \n\nPros. \n-This paper is well-motivated. Studying label propagation in the meta-learning setting is interesting and novel. Intuitively, transductive label propagation should improve supervised learning when the number of labeled instances is low. \n-The empirical results show improvement over the baselines, which are expected. \n\nCons.\n-Some technical details  are missing. In Section 3.2.2, the authors only explain how they learn example-based \\sigma, but details on how to make graph construction end-to-end trainable are missing. Constructing the full weight matrix requires the whole dataset as input and selecting k-nearest neighbor is a non-differentiable operation. Can you give more explanations?\n-Does episode training help label propagation? How about the results of label propagation without the episode training? \n', 'This paper proposes to address few-shot learning in a transductive way by learning a label propagation model in an end-to-end manner.  Semi-supervised few-shot learning is important considering the limitation of the very few labeled instances. This is an interesting work. \n\nThe merits of this paper lie in the following aspects: (1) It is the first to learn label propagation for transductive few-shot learning. (2) The proposed approach produced effective empirical results.\n\nThe drawbacks  of the work include the following: (1) There is not much technical contribution. It merely just puts the CNN representation learning and the label propagation together to perform end-to-end learning. Considering the optimization problem involved in the learning process, it is hard to judge whether the effect of such a procedure from the optimization perspective.  (2) Empirically, it seems TPN achieved very small improvements over the very baseline label propagation.  Moreover, the performance reported in this paper seems to be much inferior to the state-of-the-art results reported in the literature. For example,  on miniImageNet, TADAM(Oreshkin et al, 2018) reported 58.5 (1-shot) and 76.7(5-shot), which are way better than the results reported in this work. This is a major concern.\n']","[20, 50, -20]","[50, 75, 50]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges that there's 'nothing strikingly novel' in the work, they also note that it covers a setup not studied before, is clearly written, and has solid experiments. The slight positivity is further supported by the statement that the approach 'seem to help slightly'. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They offer constructive criticism and suggestions without harsh language, and acknowledge the paper's strengths. The comments are framed as questions or suggestions rather than demands, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting the novelty and interesting aspects of the paper, and notes that the empirical results show improvement over baselines. However, it also raises some significant concerns about missing technical details and questions about the methodology. The overall tone is balanced between positives and negatives. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or requests for clarification rather than direct attacks, and acknowledges the paper's strengths before discussing weaknesses. The use of 'Pros' and 'Cons' sections also helps maintain a balanced and professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merits of the paper, they also point out significant drawbacks. The review starts positively, calling it an 'interesting work' and noting its novelty and empirical results. However, the criticism outweighs the praise, particularly the concerns about limited technical contribution and inferior performance compared to state-of-the-art results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'interesting work' and 'merits of this paper,' which maintain a professional and courteous tone even when expressing concerns.""]"
"['The authors made several claims and provide suggestions on training binary networks, however, they are not proved or theoretically analyzed.  The empirical verification of the proposed hypothesis was viewed as weak as the only two datasets used are small datasets MNIST and CIFAR-10, and the used network architectures are also limited. Much more rigorous and thorough testing is required for an empirical paper which proposes new claims. \n\nTake the first claim ""end-to-end training of binary networks crucially relies on the optimiser taking advantage of second moment gradient estimates"" as an example. As it is known that choice of optimizer is highly dependent on the specific dataset and network structure, it is not convincing to jump to this conclusion using the observations on two small datasets and limited network architectures.  E.g, many binarization papers use momentum for ImageNet dataset with residual networks. Does Adam also outperforms momentum in this case? Similarly, it is also hard for me to judge whether the other conclusions made about weight/gradient clipping, the momentum in batch normalization and learning rate, are correct or not.\n\nSome minor issues are:\n1. In Figure 4, different methods are not run to convergence, and the comparison may not be fair.\n2. The second paragraph in section 4: ""It can be seen that not clipping weights when learning rates are large can completely halt the optimisation (red curve in Figure 5)."" However, in figure 5, the red curve is ""Clipping gradients"", which one is correct?\n3. The authors propose a recipe for faster training of binary networks, is there experiments supporting that training networks with the proposed recipe is faster than the original counterpart? ', 'The paper systematically studies the training of binary neural networks, where binary in this case refers to single bit weight elements in the network. In particular, different existing training methods are tested and compared for training both MLPs and CNNs.\n\nThe main findings of the paper are:\n- Using methods such as AdaGrad, AdaDelta, RMSProp and ADAM yields better performance than simpler momentum-based methods such as vanilla momentum and Nesterov momentum, which in turn are much better than vanilla SGD\n- When training binary models, it is common to clip weights and/or gradients for the proxy weights in the network. In the paper it is however shown that these methods hinder using a fast learning rate in the beginning of training, while the methods are required in later stages of training in order to achieve good results\n- Pre-training the model with full-precision training works well in speeding up training\n\nFor a practitioner, the paper presents a very useful reference for what methods work well when training binary networks. Although there are some proposals and hypotheses for reasons behind the results, I see the paper as a review paper of existing methods for training binary networks, showing experiments where the methods are tested using the same benchmark and training procedure in order to give a fair comparison.\n\nAs a practical guide, the paper therefore has clear value. What is lacking compared to typical ICLR papers is rigorously presenting new findings. The authors present a hypothesis for why different batch sizes are needed in the beginning compared to the end of training, but I found neither the justification nor the results very convincing with respect to the hypothesis. The way I see it, the actual novel proposals that are made in the paper are two two-stage training methods: one in which the tricks of weight and gradient clipping are only used towards the end of training, and one where the first stage of training is done using a full precision model. It is however quite well known that some training schemes with different stages can lead to improved performance: for instance with ADAM, even if it is an adaptive method, lowering the learning rate towards the end of training is often beneficial. It might therefore be fair to compare the methods to other multi-stage training methods. In addition, I could not find the training curves or final performance figures of the method where clipping is only activated towards the end of training.\n\nTo put it all together, the paper is clearly useful for the community as it provides a useful summary of the performance of different methods for training binary neural networks. In addition, it presents two two-stage training schemes that seem to make training even faster. What the paper lacks is rigorous theoretical justifications and clearly novel ideas.\n\nSmall comments:\n- How are the training lengths decided for the different methods? If I am not mistaken, in Figure 2, it seems like the SGD and momentum methods have not yet converged when training is halted. Is there a budget for wall clock time or is early stopping used or something similar? Considering the nature of the paper, I would see this kind of decisions as important to report.\n- In the abstract, you might want to refer to binary weights somewhere. Based on the abstract it is easy to mix the binary networks in this paper with stochastic binary networks that can also be trained using the STE estimator\n- Are the differences in the performances in Table 3 statistically significant?', ""This is a good review paper covering techniques proposed across many of the well-known works in this area and doing an in-depth analysis of the value each of the techniques brings. Additionally, based on these studies the paper offers insights into the best algorithms and procedures to combine to achieving good results.\n\nOne recent whitepaper that has related work (not fully overlapping though), that may be worth looking by the authors is at https://arxiv.org/abs/1806.08342. It is fairly new and not very well-known so not surprising that the authors missed it.\n\nPros\n- Well written paper with lots of in-depth experiments \n- Does well at teasing out the impact of each of the techniques and gives some intuitive explanations of why they matter.\n- Provides better insights into how to make training of binary neural networks faster.\n- As the importance of low precision networks grows, this is a valuable paper in pushing the area of research forward.\n\nCons\n- A review paper, which doesn't add much new to the existing suite of techniques. Note: This is true for most review papers.\n""]","[-60, 20, 80]","[20, 60, 70]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer criticizes the lack of theoretical analysis, weak empirical verification, and limited dataset usage. They express skepticism about the authors' claims and suggest that more rigorous testing is required. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'it is not convincing' and 'it is hard for me to judge' rather than harsh or rude language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. The use of 'Some minor issues' to introduce less significant problems is also a relatively polite approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's value as a useful reference and guide for practitioners, highlighting its systematic approach and fair comparisons. However, they also point out limitations such as lack of rigorous theoretical justifications and novel ideas, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'clearly useful' and 'very useful reference' while also politely expressing concerns, such as 'What is lacking...' and 'What the paper lacks...'. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is 80 (positive) because the review starts with 'This is a good review paper' and lists several pros, indicating a generally positive view of the paper. The reviewer acknowledges the paper's depth, insights, and value to the field. The only con mentioned is a common characteristic of review papers, not a significant criticism. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and even suggests an additional resource the authors might find useful. The tone is professional and supportive, without any harsh criticism or demanding language.""]"
"['In distributed optimisation, it is well known that asynchronous methods outperform synchronous methods in many cases. However, the questions as to whether (and when) asynchronous methods can be shown to have any speed-up, as the number of nodes increases, has been open. The paper under review answers the question in the affirmative and does so very elegantly.\n\nI have only a few minor quibbles and a question. There are some recent papers that could be cited:\nhttp://proceedings.mlr.press/v80/zhou18b.html\nhttp://proceedings.mlr.press/v80/lian18a.html\nhttps://nips.cc/Conferences/2018/Schedule?showEvent=11368\nand the formatting of the bibliography needs to be improved. \n\nIn the synchronous case, some of the analyses extend to partially separable functions, e.g.:\nhttps://arxiv.org/abs/1406.0238\nand citations thereof. Would it be possible to extend the present work in that direction?', ""This paper studies the combination of the asynchronous parallelization and the accelerated stochastic coordinate descent method. The proved convergence rate is claimed to be consistent with the non parallel counterpart. The linear speedup is achievable when the maximal staleness is bounded by n^{1/2} roughly, that sounds very interesting result to me. However, I have a few questions about the correctness of the results:\n\n- Theorem 1 essentially shows that every single step is guaranteed to improve the last step in the expectation sense. However, this violates my my experiences to study Nesterov's accelerated methods. To my knowledge, Nesterov's accelerated methods generally do not guarantee improvement over each single step, because accelerate methods essentially constructs a sequence z_{t+1} = A z_t where A is a nonsymmetric matrix with spectral norm greater than 1.\n\n- The actual implemented algorithm is using the sparse update other than the analyzed version, since the analyzed version is not efficient or suitable for parallelization. However, the sparse updating rule is equivalent to the original version only for the non asynchronous version. Therefore, the analysis does not apply the actual implementation.\n\nminors:\n- pp2 line 8, K(epsilon) is not defined \n- Eq. (1.4), the index is missing.\n- missing reference: An Asynchronous Parallel Stochastic Coordinate Descent Algorithm, ICML 2014."", 'The authors design an accelerated, asynchronous block coordinate descent algorithm, which, for sufficiently small delays attains the iteration complexity of the current state of the art algorithm (which is not parallel/asynchronous). The authors prove a lower bound on the iteration complexity in order to show that their algorithm is near optimal. They also analyze an ODE which is the continuous time limit of A2BCD, which they use to motivate their approach.\n\nI am a little bit confused about the guarantee of the algorithm, as it does not agree with my intuition. Perhaps I am simply mistaken in my intuition, but I am concerned that there may need to be additional premises to the Theorem.\n\nMy main confusion is with Theorem 1, which says that for $\\psi < 3/7$ the iteration complexity is approximately the iteration complexity of NU_ACDM times a factor of $(1 + o(1))/(1-\\psi)$, i.e. within that factor of the optimal *non-asynchronous/parallel* algorithm. In particular, since $\\psi < 3/7$ this means that the algorithm is within a $7/4 + o(1)$ factor. As mentioned in Corollary 3, this applies for instance when $L_i = L$ for all i and $\\tau = \\Theta( n^{1/2}\\kappa^{-1/4} )$. Therefore, in a regime where $n \\approx \\kappa$, and $n$ very large, this would indicate that the algorithm would be almost as good as the best synchronous algorithm even for delays $\\tau \\approx n^{1/4}$. Perhaps I am missing something, but this seems very surprising to me, in particular, I would expect more significant slowdown due to $\\tau$. \n\nI am also a little bit surprised that the maximum tolerable delay is proportional to the *minimum* smoothness parameter $\\underbar{L}$. It seems like decreasing $\\underbar{L}$ should make optimization easier and therefore more delay should be tolerated. Perhaps this is simply an artifact of the analysis.\n']","[90, -50, -20]","[80, 50, 60]","[""The sentiment score is 90 (highly positive) because the reviewer describes the paper as answering an open question 'very elegantly' and expresses only 'minor quibbles'. The overall tone is highly appreciative of the work. The politeness score is 80 (quite polite) due to the respectful language used throughout. The reviewer frames their suggestions as 'minor quibbles' and a 'question', rather than demands. They also use phrases like 'could be cited' instead of more forceful language. The reviewer acknowledges the paper's contribution positively before offering any criticism, which is a polite approach in academic discourse."", ""The sentiment score is -50 because while the reviewer initially expresses interest in the paper's results, they subsequently raise significant concerns about the correctness of the results and the applicability of the analysis to the actual implementation. These concerns outweigh the initial positive sentiment. The politeness score is 50 because the reviewer uses respectful language throughout, framing their criticisms as questions and observations rather than direct attacks. They also acknowledge the interesting aspects of the work before presenting their concerns. The use of phrases like 'sounds very interesting result to me' and 'I have a few questions' contributes to the polite tone. However, the score is not higher as the review is primarily focused on technical concerns rather than offering excessive praise or using overtly polite language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' work and contributions, they express confusion and concern about some aspects of the algorithm and its guarantees. The reviewer uses phrases like 'I am a little bit confused,' 'I am concerned,' and 'Perhaps I am missing something,' which indicate some skepticism or uncertainty about the findings. However, the tone is not entirely negative, as the reviewer also considers that their own intuition might be mistaken. The politeness score is moderately positive (60) because the reviewer uses respectful and considerate language throughout. They frame their concerns as personal confusion rather than direct criticism, using phrases like 'Perhaps I am simply mistaken in my intuition' and 'I am a little bit surprised.' This approach maintains a polite and constructive tone while still expressing their reservations about the work.""]"
"['The paper extends previous work on differentiable placticity to include neuro modulation by parameterizing the learning rate of Hebbs update rule. In addition, the authors introduce retroactive modulation that basically allows the system to delay incorporation of plasticity updates via so eligibility traces. Experiments are performaed on 2 simple toy datasets and a simple language modeling task. A newly developed cue-reward association task shows the clear limitations of basic plasticity and how modulation can resolve this. Slight improvements can also be seen on a simple maze navigation task as well as on a basic language modeling dataset.\n\nOverall I like the motivation, provided background information and simplicity of the approach. Furthermore, the cue-reward experiment seems to be a well designed show case for neuro-modulation. However, as the authors acknowledge the overall simplicity of the tasks being evaluated with mostly marginal improvements makes the overall evaluation fall short. Unfortunately the paper doesn\'t provide any qualitative analysis on how modulation is employed by the models after training. Therefore, although I would like to see an extended version of this paper at the conference, without further experiments and analysis I see the current version rather as an interesting workshop contribution.\n\n\nStrengths:\n- motivation: the natural extension of previous work on differentiable plasticity based on existing knowledge from neuro science is an important next step\n- cue reward experiment exemplifies limitations of current plasticity approaches and clearly shows the potential benefits of neuro modulation\n- maze navigation shows incremental benefits over non-modulated plasticity\n- thorough experimentation\n- clipping-trick is a neat observation \n\n\nWeaknesses:\n- evaluation: only on toy tasks (which includes PTB), no real world tasks\n- very incremental improvements on PTB over a very simple baseline (far from SotA)\n- evaluated models (feed-forward NNs and LSTMs) are very basic and far from current SotA architectures\n- no qualitative analysis on how modulation is actually use by the systems. E.g., when is modulation strong and when is it not used \n\n\nComments:\n- perplexity improvements of less than 1.3 points over plasticity alone (which is the actual baseline for this paper) can hardy be called ""significant"". Even though they might be statistically significant (meaning nothing more than the two models being statistically different), minor architectural changes can lead to such improvements. Furthermore PTB is not a ""challenging"" LM benchmark.\n\n', 'Paper summary - This paper extends the differentiable plasticity framework of Miconi et al. (2018) by dynamically modulating the plasticity learning rate. This is accomplished via an output unit of the network which defines the plasticity learning rate for the next timestep. A variation on this dynamic learning rate related to eligibility traces is also proposed.\n\nBoth dynamic modulation variations strikingly outperform non-plastic and plastic non-modulated recurrent networks on a cue-reward association task with high-dimensional cues. The methods marginally outperform plastic non-modulated recurrent networks on a 9x9 water maze task. Finally, the authors show that adding dynamic plasticity to a small LSTM without dropout improves performance on Penn Treebank.\n\nThe paper motivates dynamic plasticity by analogy to the hypothesized role of dopamine in reward-driven learning in humans and animals.\n\nClarity -  The paper is very clear and well written. The introduction provides useful insights, motivates the work convincingly, and provides interesting connections to past work.\n\nOriginality - I don\'t know of any other work that models the role of dopamine in quite this way, or that applies dynamic plasticity modulation in settings like these.\n\nQuality - The experiments are well chosen and seem technically sound.\n\nSignificance - The results show that meta-learning by gradient descent to modulate the plasticity learning rate is a promising direction -- a significant contribution in my view.\n\nOther Comments - The citation to Zaremba et al. in Table 1 made it seem like the perplexity result on that line of the table was directly from Zaremba et al\'s paper. I\'d recommend removing the citation from that line to avoid confusion.\n\nOne thing I would have loved to see from this paper is a comparison of modulated-plasticity LSTMs with the sota from Melis et al., 2017. I gather that Experiment 3 presents small LSTMs without recurrent dropout instead because combining plasticity and dropout proved challenging (or at least the authors haven\'t tried it yet). I think the paper is solid as-is; positive results in this comparison would take it to the next level.\n\nQuestions:\nWhy were zero-sequences necessary in Experiment 1? This aspect of the task seems somewhat contrived, and it makes me wonder whether the striking failure of the non-modulated RNNs depends on this detail. Perhaps the authors could clarify on what a confounding ""time-locked scheduling strategy"" would look like in this task?\nWhy does Experiment 1 present pairs of stimuli, rather than high-dimensional individual stimuli?\nWhy is non-plastic rnn left out of Figure 2b?\n\nTypos\n""However, in Nature,"" -- no caps\nin appendix: ""(see Figure A.4)"" -- the figure is labeled ""Figure 3""\n', 'This work presents Backpropamine, a neuromodulated plastic LSTM training regime. It extends previous research on differentiable Hebbian plasticity by introducing a neuromodulatory term to help gate information into the Hebbian synapse. The neuromodulatory term is placed under network control, allowing it to be time varying (and hence to be sensitive to the input, for example). Another variant proposes updating the Hebbian synapse with modulated exponential average of the Hebbian product. This average is linked to the notion of an eligibility trace, and ties into some recent biological work that shows the role of dopamine in retroactively modulating synaptic plasticity.\n\nOverall the work is nicely motivated and clearly presented. There are some interesting ties to biological work -- in particular, to retroactive plasticity phenomena. There should be sufficient details for a reader to implement this model, thought there are some minor details missing regarding the experimental setup, which will be addressed below.\n\nThe authors test their model on three tasks: cue-award association, maze learning, and Penn Treebank (PTB). In the cue-award association task the retroactive and simple modulation networks perform well, while the non-modulated and non-plastics fail. For the maze navigation task the modulated networks perform better than the non-modulated networks, though the effect is less pronounced. Finally, on PTB the authors report improvements over baseline LSTMs. \n\nOne of the main claims of this paper is that neuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task”, and that therefore “differentiable neuromodulation of plasticity offers a powerful new framework for training neural networks”. This claim is unfortunately unfounded for a very important reason: the LSTM performance is not at all close to that which can be achieved by LSTMs in general. The authors cite such models in the appendix (Melor et al), but claim that “much larger models” are needed, potentially with other mechanisms, such as dropout. Though this may be true, these models still undermine the claim that “neuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task”. This claim is simply not true, and more care is needed in reporting the results here in the wider context of the literature. Also, I am left wondering what are considered the parameters of the models -- are only the neuromodulatory terms considered as the additional trainable parameters compared to baseline LSTMs? How are the Hebbian synapses themselves considered in this calculation? If the Hebbian synapses are not considered, then the authors need a control with matched memory-capacities to account for the extra capacity afforded by the Hebbian synapses. Given the ties between Hebbian synapses and attention (see Ba et al), an important control here could be an LSTM with Bahdanau (2014) style attention. \n\nFinally, the style (font) of the paper does not adhere to the ICLR style template, and must be changed.\n\nOverall, the ideas presented in the paper are intriguing, and further research down this line is encouraged. However, in its current state the work lacks sufficiently strong baselines to support the paper’s claims; thus, the merits of this approach cannot yet be properly assessed.\n']","[-20, 80, -20]","[60, 90, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they ultimately conclude that it falls short of being a conference-worthy contribution in its current state. The reviewer suggests it would be more suitable as a workshop contribution without further experiments and analysis. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and providing constructive criticism. They use phrases like 'I like the motivation' and 'I would like to see an extended version' which maintain a polite tone even while expressing concerns. The reviewer also provides a balanced view, listing both strengths and weaknesses, which contributes to the overall politeness of the review."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'very clear and well written', 'motivates the work convincingly', and call the contribution 'significant'. The experiments are praised as 'well chosen and seem technically sound'. The only minor criticisms are suggestions for improvement rather than flaws.\n\nThe politeness score is 90 (very polite) because the reviewer uses consistently respectful and constructive language. They offer praise generously and frame suggestions as polite requests ('I'd recommend', 'I would have loved to see'). Even when asking questions or pointing out potential issues, the tone remains courteous and inquisitive rather than critical. The use of phrases like 'Perhaps the authors could clarify' further demonstrates a polite and considerate approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'nicely motivated and clearly presented' with 'interesting ties to biological work', they also point out significant issues. The main criticism is that the paper's central claim about outperforming standard LSTMs is 'unfounded' and 'simply not true'. The reviewer also mentions the lack of strong baselines and the need for more care in reporting results. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and encouraging further research. They phrase criticisms constructively, using phrases like 'more care is needed' and 'I am left wondering' rather than harsh or dismissive language. The reviewer also ends on a polite note, calling the ideas 'intriguing' and encouraging further research, despite the identified shortcomings.""]"
"['The paper is well written and structured, presenting the problem clearly and accurately. It contains considerable relevant references and enough background knowledge. It nicely motivates the proposed approach, locates the contributions in the state-of-the-art and reviews related work. It is also very honest in terms of how it differs on the technical level from existing approaches. \nThe paper presents interesting and novel findings to further state-of-the-art’s understanding on how language concepts are represented in the intermediate layers of deep convolutional neural networks, showing that channels in convolutional representations are selectively sensitive to specific natural language concepts. It also nicely discusses how concepts granularity evolves with layers’ deepness in the case of natural language tasks.\nWhat I am missing, however, is an empirical study of concepts coverage over multiple layers, studying the multiple occurrences of single concepts at different layers, and a deeper dive on the rather noisy elements of natural language and the layers’ activation dynamics towards such elements.\nOverall, however, the ideas presented in the paper are interesting and original, and the experimental section is convincing. My recommendation is to accept this submission.\n', '========== Edit following authors\' response  ==========\n\nThank you for your detailed response and updated version. I think the new revision is significantly improved, mainly in more quantitative analyses and details in several places. I have updated my evaluation accordingly. \n\nSee a few more points below.\n\n1. Thank you for clarifying your definition of concepts. I still think that the word ""concept"" has a strong semantic connotation, while the linguistic elements your analyses capture may do other things. The results in appendix E do show that some semantic clusters arise. It\'s especially interesting to see the blocks in some of the heat maps, where similar ""concepts"" are clustered together (like the sports terms in AG); consider commenting on this. \n\n2. The new quantitative analyses are helpful. One other suggestion that I mentioned before is to connect detected concepts to external resources like WordNet or ConceptNet. That would help show that ""concepts"" are indeed semantic objects. \n \n3. The motivation for replicating as normalizing for length does make sense, although the input would still be unnatural. The comparison to ""one instance"" is helpful, but it\'s interesting that the differences between it and replication in figure 2 are not large. It would be good to show results that substantiate your assumption that without replication there will be a bias towards lengthy concepts. Does ""one instance"" detect more lengthy concepts than replication? \n\n4. The results on frequency and loss difference in 4.5 are very interesting. There is another angle to consider frequency: words that appear frequently often carry less semantic content (e.g. function words), so one might conjecture that they would require less units. It may be interesting to look at which concepts are detected at each frequency bin.\n\n5. Minor points: section 2.2 still mentions ""regression"" where it should be ""classification"".  \n\n6. A few remaining grammar issues:\n- ""one concept has a less activation value.."" - rephrase \n- end of section 3.3: ""this experiments"" -> ""these experiments""\n\n\n========== Original review follows ==========\n\nSummary:\n=======\nThis paper analyzes individual units in CNN models for text classification and translation tasks. It defines a measure of sensitivity for a unit and evaluates how sensitive each unit is to ""concepts"" in the input text, where concepts are morphemes, words, and phrases. The analysis shows that some units seem to learn semantic concepts, while others capture linguistic elements that are frequent or relevant for the end task. Layer-wise results show some correspondence between layer depth and linguistic element size.  \n\nThe paper studies an important question that is relatively under-studies in NLP compared to the computer vision community. The motivation for the work is quite convincing.  \nI found some of the results and analysis interesting, but overall felt that the work can be made much stronger by more quantitative evaluations. I am also worried that the notion of ""concept"" is misleading here. See below for this and other comments. I am willing to reconsider my evaluation pending response to the below issues. \n\nMain comments:\n=============\n1. Concepts: \n- morphemes, words, and phrases - are these ""concepts""? They are indeed ""fundamental building blocks of natural language"" (2.2), but ""concepts"" has a more semantic connotation that I\'m not sure these units target at. \n- Some of the results do suggest that units learn concepts, as the analysis in 4.2 shows a ""unit detecting the meaning of certainty in knowledge"" and later units that have similar sentiments. It would be informative to quantify this in some way, for example by matching detected concepts to WordNet synsets, sentiment lexicons, etc., or else tagging and classifying them with various NLP tools. This could also reveal if units learn more syntactic or semantic concepts, and so on. \n2. Generally, many of the analyses in the paper are qualitative and on a small scale. The results will be more convincing with more automatic aggregate measures. \n3. The structure of the paper is confusing. Section3 starts with the approach but then mentions datasets and tasks (3.1). Section 4 is titled experiments, but section 4.1 starts with defining the concept selectivity. I would suggest reorganizing sections 3 and 4, such that section 3 describes all the methods and metrics, while dataset-specific parts are moved to section 4. \n4. section 3.2 should provide more details on the sentence representation and how its obtained in the CNN models. A mathematical derivation and/or figure could be helpful. It is also not clear to me what\'s the motivation for mean-pooling over the l entries of the vector. \n5. section 3.3: the use of replicated text for ""concept alignment"" is puzzling. This is not a natural input to the model, and I think more justification and motivation åre needed for this issue, as well as perhaps comparison with other approaches. \n6. I found section 4.4 very interesting. It shows some intuitive results of larger linguistic elements learned at higher layers, but then some results that do not show such a trend. Then, hypothesizing that the middle layers are sufficient AND validating the hypothesis by retraining the model is excellent. It\'s a very nice demonstration that the analysis can lead to model improvements.  \n7. Figure 2 seems to be almost caused by construction of the different options for S_+. Is it surprising that the replicate set has the highest sensitivity? Is there a better control setup than comparing with a random set? \n8. One concern that I have is the effect of confounding factors like frequency on the results. The papers occasionally attributes importance to concepts (e.g. in 4.2), but I wonder if instead we may be seeing more frequent words. Controlling for the effect of frequency would be useful.   \n\n\nMinor comments:\n==============\n- Section 2.2, first paragraph: regression should be changed to classification\n- The related work is generally relevant, although one could mention a few other papers that analyzed individual neurons in NLP tasks [1, 2]\n- section 4.1: the random set may perhaps be denoted by something more neutral, not S_+ as the replicate and inclusion sets. \n- section 4.3, last paragraph: listing examples showing that units in Europarl focus on key words would be good. \n- Figure 5, y axis label: should this be number of units instead of concepts? \n- Appendix A has several interesting points but there is no reference to them from the main paper. \n\n\nWriting, grammar, etc.:\n======================\n- Introduction: among them - who is them? \n- 2.1: motivated from -> motivated by; In computer vision community -> In the computer vision community\n- 2.1: quantifying characteristics of representations in layer-wise -> rephrase\n- 3.2: dimension of sentence -> dimension of the/a sentence \n- 4.1: to which -> remove ""which"" \n- 4.2: in the several encoding layer -> in several encoding layers \n- 4.3: aliged -> aligned \n- Capitalize titles in references \n- A.2: with following -> with the following; how much candidate -> how much a candidate; consider following -> consider the following \n- A.3: induces similar bias -> induces a bias; such phrase -> such a phrase; on very -> on a very \n- C: where model -> where the model; In consistent -> Consistent; where model -> where the model \n\n\nReferences\n==========\n[1] Qian et al., Analyzing linguistic knowledge in sequential model of sentence\n[2] Shi et al., Why Neural Translations are the Right Length', 'This paper describes a method for identifying linguistic components (""concepts"") to which individual units of convolutional networks are sensitive, by selecting the sentences that most activate the given unit and then quantifying the activation of those units in response to subparts of those sentences that have been isolated and repeated. The paper reports analyses of the sensitivities of different units as well as the evolution of sensitivity across network layers, finding interesting patterns of sensitivity to specific words as well as higher-level categories.\n\nI think this paper provides some useful insights into the specialization of hidden layer units in these networks.  There are some places where I think the analysis could go deeper / some questions that I\'m left with (see comments below), but on the whole I think that the paper sheds useful light on the finer-grained picture of what these models learn internally. I like the fact that the analysis is able to identify a lack of substantial change between middle and deeper layers of the translation model, which inspires a prediction - subsequently borne out - that decreasing the number of layers will not substantially reduce task performance.\n\nThe paper is overall written pretty clearly (though some of the questions below could likely be attributed to sub-optimal clarity), and to my knowledge the analyses and insights that it contributes are original. Overall, I think this is a solid paper with some interesting contributions to neural network interpretability.\n\nComments/questions:\n\n-I\'m wondering about the importance of repeating the “concepts” to reach the average sentence length. Do the units not respond adequately with just one instance of the concept (eg ""the ball"" rather than ""the ball the ball the ball"")? What is the contribution of repetition alone?\n\n-Did you experiment with any other values for M (number of aligned candidate concepts per unit)? It seems that this is a non-trivial modeling decision, as it has bearing on the interesting question of how broadly selective a unit is.\n\n-You give examples of units that have interpretable sensitivity patterns - can you give a sense of what proportion of units do *not* respond in an interpretable way, based on your analysis?\n\n-What exactly is plotted on the y-axis of Figure 5? Is it number of units, or number of concepts? How does it pool over different instances of a category (different morphemes, different words, etc)? What is the relationship between that measure and the number of distinct words/morphemes etc that produce sensitivity?\n\n-I\'m interested in the units that cluster members of certain syntactic and semantic categories, and it would be nice to be able to get a broader sense of the scope of these sensitivities. What examples of these categories are captured? Is it clear why certain categories are selected over others? Are they obviously the most optimal categories for task performance?\n\n-p7 typo: ""morhpeme""']","[80, 20, 70]","[90, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, praising its structure, clarity, and contributions. They use phrases like 'well written', 'nicely motivates', and 'interesting and novel findings'. The only slight criticism is mentioned as 'What I am missing', but this is minor compared to the overall positive tone. The recommendation to accept further confirms the positive sentiment. The politeness score is 90 (very polite) due to the consistently respectful and constructive language used throughout. The reviewer acknowledges the paper's strengths extensively before offering a suggestion for improvement, and even then, frames it as a personal observation ('What I am missing') rather than a direct criticism. The review concludes with a positive recommendation, maintaining a courteous and professional tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges significant improvements in the revised version, noting it is 'significantly improved' with more quantitative analyses. However, they still have some remaining concerns and suggestions, indicating it's not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses polite language throughout, starting with 'Thank you for your detailed response' and phrasing critiques constructively, such as 'It would be good to show...' and 'One other suggestion...'. The tone is professional and respectful, offering suggestions rather than demands. The reviewer also acknowledges the authors' efforts in addressing previous concerns."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper provides 'useful insights', 'sheds useful light', and is a 'solid paper with some interesting contributions'. They use positive language throughout, though not effusively. The politeness score is 80 (quite polite) because the reviewer uses respectful language, acknowledges the paper's contributions, and frames criticisms as questions or suggestions rather than direct criticisms. Phrases like 'I think', 'I like the fact that', and 'I'm wondering about' contribute to the polite tone. The reviewer also provides specific, constructive feedback and even points out a minor typo, which shows careful reading and respect for the authors' work.""]"
"[""This paper proposed a framework that can improve the performances of reinforcement learning algorithms in tasks that involve long time horizons and sparse rewards. The proposed method is a hierarchical reinforcement learning framework that can use policy hierarchies with an arbitrary number of levels. To improve the sample efficiency in the learning process, the authors proposed to apply the hindsight experience replay mechanism at each level. Also, in order to avoid the actor function to output an unrealistic subgoal, the authors proposed the subgoal testing technique. \n\nThe proposed framework is interesting. And the example in Section 3.5 clearly demonstrate how this framework works. The authors proposed to solve a UMDP by solving a hierarchy of k UMDPs, where k is a hyperparameter. Each level (except for the bottom most level) will output subgoal states for the next level to achieve. This hierarchy is reasonable and easy to understand. However, from the definition on Page 3, it seems that all of the intermediate levels i (the case where 0 < i < k - 1) has the same state and action spaces. They are all equal to the state set of the original UMDP. Under this setting, will adding more intermediate levels help improve the performance a lot? We only see results with at most one intermediate level in the experiment. It will be better if the authors can show results on more levels (i.e. at least 4 levels in total). \n\nMoreover, the proposed framework has a policy limit parameter T, meaning that we only consider if a goal can be achieved within T steps or not, at each level. Is this parameter necessary to be the same for all levels? Also, it will be better if the author can show some results on the performances of the proposed method according to different values for T. The authors also proposed the subgoal testing technique. It is also better if the authors can show some performance comparisons on the cases with and without this technique.\n\nThe authors claimed that their method has the advantage over some existing HRL methods (e.g. the Option-Critic Architecture [1]) that their method can use policy hierarchies with an arbitrary number of levels while these methods can only use policy hierarchies with two levels. In the experiments, the authors also showed that, in some of their experiments, the 3-layer agent (with 2 subgoal layers) outperforms the 2-layer agent (with 1 subgoal layer), under their framework. However, the authors did not compare their 2-layer agent's performance with these existing HRL methods, which means that we do not know if their 3-layer agent's performance is better than that of some of the existing 2-layer agent methods. In addition to that, as I mentioned before, it is better if the authors can show experiment results on more levels (e.g. 4 levels and more) to show that their method can perform well in practice for policy hierarchies with many levels.\n\n\nReferences:\n\n[1] Pierre-Luc Bacon, Jean Harb, and Doina Precup. The option-critic architecture. CoRR, abs/1609.05140, 2016.\n\n"", ""This paper presents a novel approach for doing hierarchical deep RL. Each level of the hierarchy is rewarded for reaching a goal state. The top level's goal state is the environment goal, lower level goals states are the actions of the higher levels. The lowest level's actions are primitive actions. Each level can act until it reaches it goal or a maximum of T steps. Then HER is used to still learn from missed subgoals. For example, if the lowest level is given a subgoal and fails to achieve it, it is trained with a new experience where the goal was the achieved state. In addition, the level above is trained with an experience where the action it chose (the subgoal that was not achieved) is replaced with the subgoal that was achieved. So HER is replacing goals on one level and replacing actions on the higher level. The paper shows nice empirical results across 6 domains.\n\nThe two main differences from prior work are:\n1. Explicit constraint on how long the policies at each level can be.\n2. Use of HER in a novel way (on goals and actions) to learn from failed attempts at reaching subgoals from lower levels.\n\nThe use of HER in this work is really powerful and everything fits together nicely to make it work.\n\nThe only un-satisfying part of the algorithm is the need for a subgoal testing phase. Some actions are randomly decided to be testing phases, where all exploration is turned off at lower levels and the agent at the level selecting that subgoal is given negative reward if the subgoal is not achieved. This feels a bit unnatural to me. Does it not work if you punish a level for selecting a failed subgoal even if exploration is on? Does this phase unnecessarily punish levels for selecting subgoals that aren't reached early in learning, where even with no exploration a lower level may not have learned to reach the subgoal yet?\n\nThe main drawback of the paper is that there is no empirical comparison to related work. Instead the approach is only compared to doing learning with no hierarchy. Still, in all 6 domains, there is a clear improvement to using the hierarchy vs a flat hierarchy. \n\nPros:\n- Nice approach for hierarchical deep RL\n- Great use of HER to improve subgoal learning\n- Good empirical results showing benefit of approach over flat learning\nCons:\n- No empirical comparison to related work\n- Subgoal testing phase seems a bit hacky.\n"", 'Pros:\n1. A nice idea combining universal MDP formulation and Hindsight experience replay for HRL that can deal with hierarchies with more than two levels of policies in continuous tasks.\n2. Good empirical results \n\nCons:\n1. One limitation of this work is that the goal set is known. What if the goals are unknown?\n\n2. The current domains seems relative simple comparing other existing papers on HRL, hence it is hard to tell the significance of the method.\n\n3. It Lacks thorough experimental analysis. Some comments are suggestions are provided here.\n---Since the proposed framework can deal with arbitrary level of hierarchies, it might be better to include include an experiment comparing the more than 2 subgoal layers. This will help understand whether there is any diminishing return by increasing the number of layers.\n\n---What kind of policy representations and hyperparameters of the training algorithm are used? Are they the same for different domains? Some critical details and some ablation test should be provided.\n\n---The paper can also be strengthened if some comparisons to other HRL methods can be included.\n']","[20, 70, 20]","[60, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the proposed framework as 'interesting' and praises the clear demonstration in Section 3.5. However, they also raise several concerns and suggestions for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions using phrases like 'it will be better if' and 'it is also better if' rather than making demands. The reviewer also acknowledges the authors' claims and work before suggesting improvements. The tone is professional and courteous, avoiding any harsh or rude language."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its novel approach, good use of techniques, and clear empirical results. They use phrases like 'nice empirical results', 'really powerful', and 'everything fits together nicely'. However, it's not 100 as they do point out some drawbacks and areas for improvement. The politeness score is 60 (moderately polite) because the reviewer maintains a professional and respectful tone throughout. They balance praise with constructive criticism, using phrases like 'The only un-satisfying part' and 'The main drawback' to introduce concerns without being harsh. The language is not overly formal or deferential, hence not scoring higher, but it's consistently courteous and constructive."", ""The sentiment score is slightly positive (20) because the review starts with acknowledging the 'nice idea' and 'good empirical results', which are positive aspects. However, the review also lists several cons and limitations, which balance out the positivity. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames criticisms as suggestions or areas for improvement rather than direct attacks. The use of phrases like 'it might be better' and 'can be strengthened' indicate a constructive approach. The reviewer also acknowledges the potential of the work while suggesting improvements, which is a polite way to provide feedback.""]"
"['The paper first examines the objective function optimized in MAML and E-MAML and interprets the terms as different credit assignment criteria. MAML takes into account the dependences between pre-update trajectory and pre-update policy, post-update trajectory and post-update policy by forcing the gradient of the two policies to be aligned, which results in better learning properties. \nThought better, the paper points out MAML has incorrect estimation for the hessian in the objective. To address that, the paper propose a low variance curvature estimator (LVC). However, naively solving the new objective with LVC with TRPO is computationally prohibitive. The paper addresses this problem by proposing an objective function that combines PPO and a slightly modified version of LVC.\n\nQuality: strong, clarity:strong, originality:strong, significance: strong,\n\nPros:\n- The paper provides strong theoretical results. Though mathematically intense, the paper is written quite well and is easy to follow.\n- The proposed method is able to improve in sample complexity, speed and convergence over past methods.\n- The paper provides strong empirical results over MAML, E-MAML. They also show the effective of the LVC objective by comparing LVC over E-MAML using vanilla gradient update.\n- Figure 4 is particularly interesting. The results show different exploration patterns used by different method and is quite aligned with the theory.  \nCons:\n- It would be nice to add more comparison and analysis on the variance. Since LVC is claimed to reduce variance of the gradient, it would be nice to show more empirical evidences that supports this. (By looking at Figure 2, although not directly related, LVC-VPG seems to have pretty noisy behaviour)\n\n', 'In this paper, the author proposed an efficient surrogate loss for estimating  Hessian in the setting of Meta-reinforcement learning (Finn.et al, 2017), which significantly reduce the variance while introducing small bias. The author verified their proposed method with other meta-learning algorithms on the Mujoco benchmarks. The author also compared with unbiased higher order gradient estimation method-DiCE in terms of gradient variance and average return. \n\nThe work is essentially important due to the need for second-order gradient estimation for meta-learning (Finn et al., 2017) and other related work such as multi-agent RL. The results look promising and the method is easy to implement. I have two detail questions about the experiment:\n\n1) As the author states, the new proposed method introduces bias while reducing variance significantly. It is necessary to examine the MSE, Bias, Variance of the gradient estimatorsquantitatively  for the proposed and related baseline methods (including MAML, E-MAML-TRPO, LVC-VPG, etc). If the bias is not a big issue empirically, the proposed method is good to use in practice.\n\n2)  The author should add DiCE in the benchmark in section 7.1, which will verify its advantage over DiCE thoroughly.\n\nOverall this is a good paper and I vote for acceptance.\n\n\nFinn, Chelsea, et al. ""Model-agnostic meta-learning for fast adaptation of deep networks."" ICML 2017.\n\nFoerster, Jakob, et al. ""DiCE: The Infinitely Differentiable Monte-Carlo Estimator."" ICML 2018.', '\nIn this paper, the authors investigate the gradient calculation in the original MAML (Finn et al. 2017) and E-MAML (Al-Shedivat et al. 2018). By comparing the differences in the gradients of these two algorithms, the authors demonstrate the advantages of the original MAML in taking the casual dependence into account. To obtain the correct estimation of the gradient through auto-differentiation, the authors exploit the DiCE formulation. Considering the variance in the DiCE objective formulation, the authors finally propose an objective which leads to low-variance but biased gradient. The authors verify the proposed methods in meta-RL tasks and achieves comparable performances to MAML and E-MAML. \n\n\nAlthough the ultimate algorithm proposed by this paper is not far away from MAML and E-MAML, they did a quite good job in clarify the differences in the existing variants of MAML from the gradient computation perspective and reveal the potential error due to the auto-differentiation. The proposed new objective and the surrogate is well-motivated from such observation and the trade-off between variance and bias. \n\n\nMy major concern is how big the effect is if we use (3) comparing to (4) in calculate the gradient. As the authors showed, the only difference between (3) and (4) is the weights in front of the term \\nabla_\\theta\\log\\pi_\\theta: the E-MAML is a fixed weight and the MAML is using a adaptive through the inner product. Whether the final difference in Figure 4 between MAML and E-MAML is all caused by such difference in gradient estimation is not clearly. In fact, based on the other large-scale high-dimension empirical experiments in Figure 2, it seems the difference in gradient estimator (3) and (4) does not induced too much difference in final performances between MAML and E-MAML. Based on such observation, I was wondering the consistent better performance of the proposed algorithm might not because the corrected gradient computation from the proposed objective. It might because the clip operation or other components in the algorithm. To make a more convincing argument, it will be better if the authors can evaluate different gradient within the same updates.\n\nI am willing to raise my score if the author can address the question. \n\nminor:\n\nThe gradients calculation in Eq (2) and (3) are not consistent with the Algorithm and the appendix.\n\nThe notation is not consistent with common usage: \\nabla^2 is actually used for denoting the Laplace operator, i.e., \\nabla^2 = \\nabla \\cdot \\nable, which is a scalar. ']","[80, 80, 20]","[70, 70, 60]","[""The sentiment score is 80 (positive) because the review is overwhelmingly positive. The reviewer uses phrases like 'strong theoretical results', 'improves sample complexity, speed and convergence', and 'strong empirical results'. They list many pros and only one minor con. The 'Quality', 'clarity', 'originality', and 'significance' are all rated as 'strong'. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer constructive feedback and frame their single criticism as a suggestion for improvement ('It would be nice to...'). The tone is consistently appreciative of the paper's contributions while maintaining objectivity."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, stating it's 'essentially important', has 'promising' results, and is 'easy to implement'. The reviewer also votes for acceptance, indicating strong approval. The score isn't 100 as there are some suggestions for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the author's work positively. They offer constructive feedback and suggestions rather than criticisms. The tone is professional and courteous, though not excessively formal or deferential, hence not scoring 100."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the paper's contributions in clarifying differences in MAML variants and proposing a new objective. However, they express major concerns about the effectiveness of the proposed method, which tempers the positive sentiment. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and expresses willingness to raise their score if concerns are addressed. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism. The use of phrases like 'quite good job' and 'well-motivated' contribute to the polite tone, while the direct expression of concerns maintains professionalism without being overly deferential.""]"
"['\n========\nSummary\n========\n\nThe paper deals with the training of neural networks for classification or sequence generation tasks, using a cross-entropy loss. Minimizing the cross-entropy means maximizing the predicted probabilities of the ground-truth classes (averaged over the samples). The authors introduce a ""complementary entropy"" loss with the goal of minimizing the predicted probabilities of the complementary (incorrect) classes. To do that, they use the average of sample-wise entropy over the complement classes. By maximizing this entropy, the predicted complementary probabilities are encouraged to be equal and therefore, the authors claim that it neutralizes them as the number of classes grows large. The proposed training procedure, named COT, consists of alternating between the optimization of the two losses.\n\nThe procedure is tested on image classification tasks with different datasets (CIFAR-10, CIFAR-100, Street View House Numbers, Tiny ImageNet and ImageNet), machine translation (training using IWSLT dataset, validation and test using TED tst2012/2013 datasets), and speech recognition (Gooogle Commands dataset). In the experiments, COT outperforms state-of-the-art models for each task/dataset.\n\nAdversarial attacks are also considered for the classification of images of CIFAR-10: using the Fast Gradient Sign and Basic Iterative Fast Gradient Sign methods on different models, adversarial examples specifically designed for each model, are generated. Then results of these models are compared to COT on these examples. The authors admit\nthat the results are biased since the adversarial attacks only target part of the COT objective, hence more accurate comparisons should be done in future work.\n\n===========================\n Main comments and questions\n===========================\n\nEnd of page 1: ""the model behavior for classes other than the ground  truth stays unharnessed and not well-defined"". The probabilities  should still sum up to 1, so if the ground truth one is maximized,  the others are actually implicitly minimized. No?\n\nPage 3, sec 2.1: ""optimizing on the complement entropy drives ŷ_ij to 1/(K − 1)"". I believe that it drives each term ŷ_ij /(1 − ŷ_ig ) to be equal to 1/(K-1). Therefore, it drives ŷ_ij to (1 − ŷ_ig)/(K-1) for j!=g.\n\nThis indeed flattens the ŷ_ij for j!=g, but the effect on ŷ_ig is not controlled. In particular this latter can decrease. Then in the next step of the algorithm, ŷ_ig will be maximized, but with no explicit control over the complementary probabilities. There are two objectives that are optimized over the same variable theta. So the question is, are we sure that this procedure will converge? What prevents situations where the probabilities will alternate between two values? \n\nFor example, with 4 classes, we look at the predicted probabilities of a given sample of class 1:\nSuppose after step 1 of Algo 1, the predicted probabilities are:  0.5 0.3 0.1 0.1 \nAfter step 2:  0.1 0.3 0.3 0.3\nThen step 1: 0.5 0.3 0.1 0.1\nThen step 2: 0.1 0.3 0.3 0.3\nAnd so on... Can this happen? Or why not? Did the algorithm have trouble converging in any of the experiments?\n\nSec 3.1:\n""additional efforts for tuning hyper-parameters might be required for optimizers to achieve the best performance"": Which hyper-parameters are considered here? If it is the learning rate, why not use a different one, tuned for each objective?\n\nSec 3.2:\nThe additional optimization makes each training iteration more costly. How much more? How do the total running times of COT compare to the ones of the baselines? I think this should be mentioned in the paper.\n\nSec 3.4:\nAs the authors mention, the results are biased and so the comparison is not fair here. Therefore I wonder about the  relevance of this section. Isn\'t there an easy way to adapt the attacks to the two objectives to be able to illustrate the conjectured robustness of COT? For example, naively having a two steps perturbation of the input: one based on the gradient of the primary objective and then perturb the result using the gradient of the complementary objective?\n\n===========================\nSecondary comments and typos\n===========================\n\nPage 3, sec 2.1: ""...the proposed COT also optimizes the complement objective for neutralizing the predicted probabilities..."", using maximizes instead of optimizes would be clearer.\n\nIn the definition of the complement entropy, equation (2), C takes as parameter only y^hat_Cbar but then in the formula, ŷ_ig appears. Shouldn\'t C take all \\hat_y as an argument in this case?\n\nAlgorithm 1 page 4: I find it confusing that the (artificial) variable that appears in the argmin (resp. argmax) is theta_{t-1}\n(resp. theta\'_t) which is the previous parameter. Is there a reason for this choice?\n\nSec 3:\n""We perform extensive experiments to evaluate COT on the tasks"" --> COT on tasks\n\n""compare it with the baseline algorithms that achieve state-of-the-art in the respective domain."" --> domainS\n\n""to evaluate the model’s robustness trained by COT when attacked"" needs reformulation.\n\n""we select a state- of-the-art model that has the open-source implementation"" --> an open-source implementation\n\nSec 3.2:\nFigure 4: why is the median reported and not the mean (as in Figure 3, Tables 2 and 3)?\n\nTable 3 and 4: why is it the validation error that is reported and not the test error?\n\nSec 3.3:\n""Neural machine translation (NMT) has populated the use of neural sequence models"": populated has not the intended meaning.\n\n""We apply the same pre-processing steps as shown in the model"" --> in the paper?\n\nSec 3.4:\n""We believe that the models trained using COT are generalized better"" --> ""..using COT generalize better""\n\n""using both FGSM and I-FGSM method"" --> methodS\n\n""The baseline models are the same as Section 3.2."" --> as in Section 3.2.\n\n""the number of iteration is set at 10."" --> to 10\n\n""using complement objective may help defend adversarial attacks."" --> defend against\n\n""Studying on COT and adversarial attacks.."" --> could be better formulated\n\nReferences: there are some inconsistencies (e.g.: initials versus first name)\n\n\nPros\n====\n- Paper is clear and well-written\n- It seems to me that it is a new original idea\n- Wide applicability\n- Extensive convincing experimental results\n\nCons\n====\n- No theoretical guarantee that the procedure should converge\n- The training time may be twice longer (to clarify)\n- The adversarial section, as it is,  does not seem relevant for me\n\n', 'This paper considers augmenting the cross-entropy objective with ""complement"" objective maximization, which aims at neutralizing the predicted probabilities of classes other than the ground truth one. The main idea is to help the ground truth label stands out more easily by smoothing out potential peaks in non-ground-truth labels. The wide application of the cross-entropy objective makes this approach applicable to many different machine/deep learning applications varying from computer vision to NLP. \n\nThe paper is well-written, with a clear explanation for the motivation of introducing the complement entropy objective and several good visualization of its empirical effects (e.g., Figures 1 and 2). The numerical experiments also incorporate a wide spectrum of applications and network structures as well as dataset sizes, and the performance improvement is quite impressive and consistent. In particular, the adversarial attacks example looks very interesting.\n\nOne small suggestion is that the authors can also make some comments on the connection between the two-step update algorithm (Algorithm 1) with multi-objective optimization. In particular, I would suggest the authors also try some multi-objective optimization techniques apart from the simple but effective heuristics, and see if some Pareto-optimality can be guaranteed and better practical improvement can be achieved.', 'In this manuscript, the authors propose a secondary objective for softmax minimization. This complementary objective is based on evaluating the information gathered from the incorrect classes. Considering these two objectives leads to a new training approach. The manuscript ends with a collection of tests on a variety of problems.\n\nThis is an interesting point of view but the manuscript lacks discussion on several important questions:\n\n1) How is this idea related to regularization? If we increase the regularization parameter, we can attain sparse parameter vectors. \n2) Would this method also complement from overfitting?\n3) In the numerical experiments, the comparison is carried out against a ""baseline"" method. Do the authors use regularization with these baseline methods? I believe the comparison will be fair  if the regularization option is turned on for the baseline methods.\n4) Why combining the two objectives in a single optimization problem and then solving the resulting problem is not an option instead of the alternating method given in Algorithm 1?\n5) How does alternating between two objectives change the training time? Do the authors use backpropagation?']","[50, 80, -20]","[80, 90, 50]","[""The sentiment score is 50 (slightly positive) because while the reviewer provides constructive criticism and points out some issues, they also highlight several pros of the paper, including its clarity, originality, and extensive experimental results. The overall tone is balanced, with both positive and negative aspects discussed. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions, and acknowledges the paper's strengths. The use of phrases like 'I believe,' 'I wonder,' and 'Could be better formulated' indicate a considerate approach to feedback. The reviewer also provides a clear structure with separate sections for main comments, secondary comments, pros, and cons, which is helpful and respectful to the authors."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'well-written' with 'clear explanation' and 'good visualization'. The reviewer also notes that the performance improvement is 'impressive and consistent'. The only slight criticism is a 'small suggestion' for improvement, which doesn't significantly detract from the overall positive sentiment. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise generously and frame their suggestion in a gentle, non-demanding way ('One small suggestion is...'). The reviewer also shows engagement with the work by mentioning specific aspects they found interesting. The language is professional and courteous throughout, without any harsh or critical tones."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting', they immediately follow with criticisms, stating that the manuscript 'lacks discussion on several important questions'. This indicates more concern than approval. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'interesting point of view' and phrases questions constructively. They avoid harsh criticism and frame their points as questions or suggestions for improvement, maintaining a respectful tone. The reviewer's approach is professional and constructive, balancing critique with courtesy.""]"
"['Summary\n\nThe authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce ""Baby Language"" to give instructions to the agent as well as to automatically verify their execution.\n\nThe paper includes a detailed description of the minigrid env with the included tasks and instruction language set. \n\nAuthors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL). They show IL is much more data efficient than RL in this domain as well. Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).  \n\nPro\n- Human-in-the-loop research is an exciting direction.\n- The language instruction set is a starting point for high-level human instructions. \n\nCon\n- It is still unclear how to effectively learn with human-in-the-loop. The authors don\'t actually evaluate \n1) how well the bot imitates a human, or \n2) how an actual human would interact and speed up learning. \nAll experiments are done with standard learning approaches with a synthetic bot. \n- The authors assume that human feedback comes as instructions or demonstrations. These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)\n\nReproducibility\n- Open-sourcing the platform is a good contribution to the community.\n', 'Summary:\nThis paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures. The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects. MiniGrid is used to build the environments used for this platform. In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results. Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels. \n\nA platform like this can be very useful to expedite research in language learning, machine learning, etc. In my view, work like this should be highly encouraged by this conference and alike.  \n\nComments:\n1.  There are following papers should be cited as they are very related to this paper:\n    a) Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments\n        https://arxiv.org/abs/1711.07280 \n    b) AI2-THOR: An Interactive 3D Environment for Visual AI\n         https://arxiv.org/abs/1712.05474 \n2. Paper is well-written and easy to follow. The only part which needs an improvement is section 3.4 as the text is a bit confusing.\n3. Heuristic expert, simulated human, human, and bot are exchangeably used in the text. It is better to pick one of these to avoid any confusion in the text. In general, it is not clear to why \'a human in the loop\' is chosen, isn\'t just a program/bot that has is engineered using knowledge of the tasks?\n4. In Table 5, in GoToObjMaze row, data efficiency for ""With Pretraining"" is greater than ""Without Pretraining"", is this a typo? if not, why this is the case?\n5. One useful baseline which can be added to this paper is task-oriented language grounding. This task will be a better measure than current baselines, especially for RL case. Authors can check out the following paper:\nGated-Attention Architectures for Task-Oriented Language Grounding\nhttps://arxiv.org/abs/1706.07230\nThe code is available for this paper. \n\nQuestion:\nWhen this platform will be available for public? ', ""This paper focuses on grounded language learning with a human in the loop, in the sense where the language is synthetic, the environment is a 2D grid world, and the human is a simulated human teacher implemented using heuristics. This setup is dubbed the BabyAI platform, and includes curriculum learning over 19 levels of increasing difficulty.  \n\nOverall, the BabyAI platform is conceptually similar to numerous previous works that seek to learn grounded language in simulation environments. These efforts differ along various axes, for example visual realism, 2D vs 3D, partially vs. fully observed, different tasks, world-state manipulation or not, etc. The main original aspect of the BabyAI platform is the simulated human-teacher. \n\nStrengths\n- Learning with a human in the loop is an extremely important problem to study, although currently efforts are hampered by cost, lack or reproducibility, and the sample inefficiency of existing learning methods. This paper addresses all three of these issues, albeit by removing the human and natural language. This is simultaneously the greatest weakness of this approach. The contribution of this paper therefore rests on the quality/interestingness/utility of the provided synthetic language and the synthetic teacher.\n- Fortunately, the synthetic language does exhibit interesting compositional properties, it is readily extensible, it has the appealing property that it can be readily interpreted as a subset of english, and it is accompanied by a verifier to check if the specified actions were completed. \n\nWeaknesses\n- If the ultimate goal is learning with a human in the loop, the usefulness of the synthetic teacher is not clear, particularly as it is apparently easier to imitate from an RL trained agent than the teacher. The explanation 'This can explained by the fact that the RL expert has the same neural network architecture as the learner' does no seem obvious to me. \n- Regarding the human in the loop, since this is aspirational and not an aspect of the paper, the title of the paper does not seem reflective of its content (even with the 'First steps' qualifier). \n- If the main unique aspect is the simulated human-teacher, it is not clear why it is necessary to create a new environment, rather than re-using an existing environment. The effect of this is to limit comparisons with recent work and an increasing fragmentation of research across tasks that are related but can’t be compared.\n\nSummary:\nThis paper represents an important direction, in that it provides a testbed for studying the sample efficiency of grounded language learning in a simplified (yet still challenging and compositional) environment. I believe the environment and the provided synthetic language and verifier will prove useful to the community, and despite some reservations about the title and the simulated human-teacher, I recommend acceptance.""]","[50, 80, 50]","[75, 70, 75]","[""The sentiment score is 50 (slightly positive) because the review acknowledges both pros and cons of the paper. The reviewer praises the human-in-the-loop research direction and the language instruction set as a starting point, while also pointing out limitations such as the lack of actual human evaluation and assumptions about feedback forms. The overall tone is balanced but leans positive due to recognizing the platform as a good contribution to the community.\n\nThe politeness score is 75 (quite polite) because the reviewer uses neutral and respectful language throughout. They present criticisms as constructive feedback rather than harsh judgments. The use of phrases like 'exciting direction' and 'good contribution' shows appreciation for the authors' work. The reviewer also frames limitations as questions or suggestions for improvement rather than outright dismissals."", ""The sentiment score is 80 (positive) because the reviewer expresses strong support for the paper, stating it 'can be very useful' and 'should be highly encouraged'. The overall tone is appreciative of the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as improvements rather than criticisms. The reviewer acknowledges the paper's strengths ('well-written and easy to follow') while providing specific, helpful recommendations for enhancement. The language is professional and courteous, avoiding any harsh or dismissive comments."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges strengths of the paper and recommends acceptance, while also pointing out several weaknesses. The overall tone is balanced but leans positive, especially in the summary. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms constructively as 'weaknesses' rather than attacks. The reviewer also uses phrases like 'I believe' to soften opinions and 'despite some reservations' to balance criticism with the overall positive recommendation.""]"
"['Overall impression: \nI think that this is a well written interesting paper with strong results. One thing I’d have liked to see a bit more is an explanation of why self imitation is more effective than standard policy gradient? Where does the extra supervision/stability come from, and can this be explained intuitively? I’ve suggested some small changes/clarifications to be made inline, and a few more comparisons to add. But overall, I very much like this line of work and I recommend accepting this paper. \n\n\nAbstract:\nWe demonstrate its effectiveness on a number of challenging tasks. -> be more specific.\n\nThe term single-timestep optimization is not very clear. Can this be clarified?\n\nthey are more widely applicable in the sparse or episodic reward settings -> it is likely important to mention that they are agnostic to horizon of the task.\n\nRelated works: \nGuided Policy Search also does divergence minimization. GAIL considers the imitation learning work as a sort of divergence minimization problem as well, which should be explicitly mentioned. Other work for good exploration include DIAYN (Eysenbach et al 2018). The difference in resulting updates between (Oh et al) and this work should be clearly discussed in the methods section. \n\n“we learn shaped, dense rewards”-> too early in the paper for this to make sense. can provide some contextt\n\nSection 2.2:\nfully decides the expected return -> clarify this a bit. I think what you mean is that the dynamics are wrapped into this already, so it accounts for this, but this can be made explicit.\n\nSmall typos in appendix 5.1 (r should be replaced by the density ratio)\n\nThe update in (3) seems quite similar to what GAIL would do. What is the difference there? Or is the difference just in the fact that the experts are chosen from “self” experiences. \n\nHow is the priority list threshold and size chosen?\n\u2028Would a softer version of the priority queue update do anything useful? Or would it just reduce to policy gradient when weighted by rewards?\n\nAppendices are very clear and very informative while being succinct!\n\nI would have liked to see Appendix 5.3 in the main text (maybe a shorter form) to clarify the whole algorithm \n\nWhat is psi in appendix 5.3? The algorithm remains a bit unclear without this clarification\n\nExperiments. \nOnly 1 question to answer in this section is labelled? Put 2) and 3) appropriately. \n\nCan a comparison to Oh et al 2018 be added to this for the sake of completeness? Also can this be compared to using novelty/curiosity based exploration schemes?\n\nCan the authors comment on why the method reaches higher asymptotic performance but is often slower in the beginning than the other methods in Fig 3. ', 'The paper proposes how previously experienced high reward trajectories can be used to generate dense reward functions for more for efficient training of policies in context of reinforcement learning. The paper does this by computing the state-action pair distribution of high rewarding trajectories in the replay buffer, and using a surrogate reward that measures the distance between this distribution and the current state-action pair distribution. The paper derives approximate policy gradients for this surrogate reward function. The paper then describes limitations of doing this: possibility of getting stuck in the local neighborhood of currently well-performing trajectories. It also describes an extension based on Stein variational policy gradients to diversify behavior of an ensemble of policies that are learned together. The paper shows experimental results on a number of MuJoCo tasks.\n\nStrengths:\n1. Adequately leveraging high-return roll-outs for effective learning of policies is an important problem in RL. The paper proposes and empirically investigates a reasonable approach for doing this. The paper shows how using the proposed additional rewards leads to better performance on the choses benchmarks than baseline methods without the proposed rewards.\n\n2. I also like that the paper details the short-comings of the proposed approach, and how these could be fixed.\n\nWeaknesses:\n1. The paper uses sparse rewards in RL as a motivation. However, the proposed approach crucially relies on the fact that a good trajectory has at least been encountered once in the past to be of any use. I am not sure if how the proposed approach does justice to the motivation in the paper. The paper should re-write the motivation, or better explain why the proposed method addresses the motivation.\n\n2. Additionally, the paper does not provide adequate experimental validation. The experiment that I think will make the case for the paper is one that shows the sample efficiency of the proposed approach over other baseline methods, when given a successful past roll-out. The current experimental setup emphasizes the sparse reward scenario in RL, and it is just not clear to me as to why this is a good benchmark to study the effects of the proposed method. \n\n3. The paper primarily makes comparisons to on-policy methods. This may not be a fair comparison, as the proposed method uses past trajectories from a replay buffer (to compute reward). Perhaps improvements are coming because of use of this off-policy information. The paper should design experiments to de-conflate this: perhaps by also comparing to how these additional rewards will compare in context of off-policy methods (like Q-learning).\n\n4. I also do not understand how the benchmark tasks were chosen? Are the MuJoCo tasks studied here a fair representative of MuJoCo tasks studied in literature, or are these selected in any manner? While selecting and modifying benchmarks for the purpose of making a specific point is acceptable, it is important to include benchmark results on a full suite of tasks. This can help understand (desirable or un-desirable) side-effects of proposed ideas.\n\nAfter reading author response and the extra experiments, I have changed my rating to 6 (from the original rating of 5).', 'The paper describes a method to improve reinforcement learning for task with sparse rewards signals.\n\nThe basic idea is to select the best episodes from the system\'s experience, and learn to imitate them step by step as the system evolves, aiming at providing a less sparse learning signal.\n\nThe math works out to a gradient that is of similar form as a policy gradient, which makes it easy to interpolate both of them. The resulting training procedure is a policy gradient that gets additional reinforcement of the system\'s best runs.\n\nThe experiments show the validity especially for the most extreme case (episodic rewards), while, as expected, for the other extreme of dense rewards, the method\'s effect is not consistently positive.\n\nThe paper then critiques its own method and identifies a critical weakness: the reliance on good exploration. I like that a lot. The paper goes on to suggest an extension to address this by training an ensemble, and shows the effectiveness of this for a number of tasks. However, I feel that the description of this extension is less clear than that of the core idea, and introduces too many new ideas and concepts in a too condensed text.\n\nThe paper seems a significant in that it provides a notable improvement for sparse-rewards tasks, which are a common sub-class of real-world problems.\n\nMy background is not RL. While I am quite confident in my understanding of the paper\'s math, I am not 100% familiar with the typical benchmark sets. Hence, I cannot judge whether the results include good baselines, or whether the task selection is biased. I can also not judge the completeness of the related work, and how novel the work is. For these questions, I hope that the other reviewers can provide more information.\n\nPros:\n - intuitive idea for a common problem\n - solution elegantly has the form of a modified policy gradient\n - convincing experimental results\n - self-critique of core idea, and extension to address its main weakness\n - nicely written text, does not leave a lot of questions\n\nCons:\n - while the core idea is nicely motivated and described and good to follow, Section 2.3 feels very dense and too short.\n\nOverall, I find the core idea quite intuitive and elegant. The paper\'s background, motivation, and core method are well-written and, with some effort, quite readable for someone who is not an RL expert. I found that several questions I had during reading were preempted promptly and addressed. However, the description of the secondary method (Section 2.3) is too dense.\n\nTo me, the paper solidly meets the threshold of publication. Since I have no good comparison to other papers, I rate it a ""clear accept"" (8).\n\nMinor points:\n\nI noticed a few superfluous ""the"", please double-check.\n\nIn Table 1, please use the same exponent for directly comparable numbers, e.g. instead of ""1.8e5 4.4e4"", say ""18e4 4.4e4"". Or best just print the full numbers without exponent, I think you have the space.\n\nWhen reading Table 1, I could bnot immediately line up ""PPO"" and ""Self-imitation"" in the caption with the table columns. It took a while to infer that PPO refers to \\nu=0, and SI to \\nu=0.8. Can you add PPO and SI to the table headings?\n\nYou define p as ""the masking probability"", but it is not clear whether that is the probability for keeping a ""1"" in the mask,\nor for masking out the value. I can only guess from the results. I suggest to rephrase as ""the probability of retaining a reward"". Also, how about using plain words in Table 1\'s heading, such as ""Noisy rewards\\nSuppressing 10% of rewards"", so that one can understand the table without having to search for its description in the text?\n']","[70, -20, 80]","[80, 60, 90]","[""The sentiment score is 70 (positive) because the reviewer starts by stating it's a 'well written interesting paper with strong results' and recommends accepting the paper. They express liking the work overall, which indicates a positive sentiment. However, it's not 100 as they do have some suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I'd have liked to see a bit more...'), and balances critique with praise. They use phrases like 'Can this be clarified?' instead of demanding changes, which contributes to the polite tone. The score isn't 100 as the review maintains a professional, slightly formal tone rather than being excessively polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and areas for improvement. The reviewer's overall tone suggests that the paper has potential but requires substantial revisions. This is further evidenced by the initial rating of 5, which was later increased to 6 after the author's response.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I like that' and 'I am not sure' which soften criticism. The reviewer also balances critique with positive feedback, acknowledging the paper's strengths before discussing its weaknesses. The language is respectful and focuses on the content rather than making personal comments about the authors.\n\nOverall, the review is critical but fair, offering specific suggestions for improvement while recognizing the paper's contributions, which is reflected in the slightly negative sentiment score and the moderately positive politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the core idea as 'intuitive and elegant', mention 'convincing experimental results', and state that the paper 'solidly meets the threshold of publication'. They rate it as a 'clear accept (8)'. The few criticisms (e.g., density of Section 2.3) are minor compared to the praise. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('My background is not RL'), and offers constructive feedback. They phrase criticisms gently (e.g., 'Section 2.3 feels very dense') and balance them with positive comments. The reviewer also offers helpful suggestions for improvement in a courteous manner.""]"
"['This paper proposes to accelerate architecture search by replacing the expensive inner loop (wherein candidate architectures are trained to completion) with a HyperNetwork which predicts the weights of candidate architectures, as in SMASH. Contrary to SMASH, this work employs a Graph neural network to allow for the use of any feedforward architecture, enabling fast architecture search through parameter prediction using highly performant search spaces. The authors test their system and show that performance using Graph HyperNet-generated weights correlates with performance when trained normally. The authors benchmark their method against competing approaches (""traditional"" NAS techniques which incur the full expense of the inner loop, and one-shot techniques which learn a large model then select architectures by searching for paths in said model) and show competitive performance.\n\nThis is a solid technical contribution with a well-designed set of experiments. While the novelty is not especially high, the paper does a good job of synthesizing existing tools and achieves reasonably strong results with much less compute, making for a strong entry into the growing table of fast architecture search methods. I argue in favor of acceptance.\n\nNotes:\n\n-Whereas SMASH is limited to architectures which can be described with its proposed encoding scheme, GHNs only requires that the architecture be represented as a graph (which, to my knowledge, means it can handle any feedforward architecture). \n\n-Section 4.2: It\'s not entirely clear how this setup allows for variable sized kernels or variable #channels. Is the output of H simply as large as the largest allowable parameter tensor, and sliced as necessary? A snippet of code might be more illuminating here than a set of equations. Additionally (I may have missed this in the text) is the #channels in each node held fixed with a predfined pattern, or also searched for? Are the channels for each node within a block allowed to vary relative to one another?\n\n-Do you sample a new, random architecture at every SGD step during training of the GHN?\n\n-I have no expertise in graph neural networks, and I cannot judge the efficacy of this scheme wrt other GNN techniques, nor can I judge the forward-backward message passing scheme of section 4.4. If another reviewer has expertise in this area and can provide an evaluation that would be great.\n \n-GPU-days is an okay metric, but it\'s also problematic, since it will of course depend on the choice of GPU (e.g. you can achieve a 10x speedup just from switching from a 600-series to a V100! How does using 4 GPUS for 1 hour compare to 1 GPU for 4 hours? How does this change if you have more CPU power and can load data faster? What if you\'re using a DL framework which is faster than your competitor\'s?) Given that the difference here is an order of magnitude, I don\'t think it matters, but if authors begin to optimize for GPU-milliseconds then it will need to be better standardized.\n \n-Further empirical evidence showing the correlation between approximate performance and true performance is also strong. I very much like that this study has been run for a method based on finding paths in a larger model (ENAS) and shows that ENAS\' performance does indeed correlate with true performance, *but* not perfectly, something which (if I recall correctly) is not addressed in the original paper.\n \n-It is worth noting that for ImageNet-Mobile and CIFAR-10 they perform on par with the top methods but tend to use more parameters.  \n\n-I like figures 3 and 4, the comparisons against MSDNet and random networks as a function of op budget is good to see.\n\n-Table 4 shows that the correlation is weaker (regardless of method) for the top architectures, which I don\'t find surprising as I would expect the variation in performance amongst top architectures to be lower. It would be interesting to also see what the range of error rates are; I would expect that the correlation is higher when the range of error rates across the population of architectures is large, as it is easier to distinguish very bad architectures from very good architectures. Distinguishing among a set of good-to-very-good architectures is likely to be more difficult.\n\n-For Section 5.3, I found the choice to use unseen architectures a little bit confusing. I think that even for this study, there\'s no reason to use a held-out set, as we seek to scrutinize the ability of the system to approximate performance even with architectures it *does* see during training. \n\n-How much does the accuracy drop when using GHN weights? I would like to see a plot showing true accuracy vs. accuracy with GHN weights for the random-100 networks, as using approximations like this typically results in the approximated weights being substantially worse. I am curious to see just how much of a drop there is.\n\n-Section 5.4: it\'s interesting that performance is stronger when the GHN only sees a few (7) nodes during training, even though it sees 17 nodes during testing. I would expect that the best performance is attained with training-testing parity. Again, as I do not have any expertise in graph neural networks, I\'m not sure if this is common (to train on smaller graphs and generalize to larger ones), so if the authors or another reviewer would like to comment and further illuminate this behavior, that would be helpful.\n\nSome typos:\n\nAbstract: ""prematured""  should be ""premature""\n\nIntroducton, last paragraph: ""CNN networks."" CNN already stands for Convolutional Neural Network.', 'This paper proposes using graph neural network (GNN) as hypernetworks to generate free weight parameters for arbitrary CNN architectures. The achieved performance is satisfactory (e.g., error rate < 3 on CIFAR-10 with cutout). I’m particularly interested in the results on ImageNet: it seems the discovered arch on CIFAR-10 (with less than 1 GPU day) successfully transferred to ImageNet. \n\nGenerally speaking, the paper is comprehensive in studying the effects of GNN acting as hypernetworks for NAS.  The idea is clear, and the experiments are satisfactory. There are no technical flaws per my reading. The writing is also easy to follow.\nOn the other hand, the extension of using GNN is indeed natural and straightforward compared with (Brock et al. 2018). Towards that end, the contribution and novelty of the paper is largely marginal and not impressive. \n\nQuestion: \n1.\tThe authors mention that ‘the first hypernetwork to generate all the weights of arbitrary CNN networks rather than a subset (Brock et al. 2018)’. I’m sorry that I do not understand the particular meaning of such a statement, especially given the only difference of this work with (Brock et al. 2018) lies in how to represent NN architectures. I am not clear that why encoding via 3D tensor cannot “generate all weights”, but can only generate only “a subset”. Furthermore, I’m very curious about the effectiveness of representing the graph using LSTM encoding, and then feeding it to the hypernetworks, since simple LSTM encoding is shown to be very powerful [1]. This at least, should act as a baseline. \n\n2.\tCan the authors give more insights about why they can search on 9 operators within less than 1 GPU day? I mean that for example ENAS, can only support 5 operators due to GPU memory limitation (on single GPU card). Do the authors use more than one GPU to support the search process? \nFinally, given the literature of NAS is suffering from the issue of reproduction, I do hope the authors could release their codes and detailed pipelines. \n\n[1] Luo, Renqian, et al. ""Neural architecture optimization."" NIPS (2018).\n', 'The authors propose to use a graph hypernetwork (GHN) to speedup architecture search. Specifically, the architecture is formulated as a directed acyclic graph, which will be encoded by the (bidirectional) GHN as a dense vector for performance prediction. The prediction from GHN is then used as a proxy of the final performance during random search. The authors empirically show that GHN + random search is not only efficient but also performs competitively against the state-of-the-art. Additional results also suggest predictions from GHN is well correlated with the ground truth obtained by the standard training procedure. \n\nThe paper is well-written and technically sound. While the overall workflow of hypernets + random search resembles that of SMASH (Brock et al., 2018), the architecture of GHN itself is a nontrivial and useful contribution. I particularly like the facts that (1) GHN seems flexible enough to handle richer topologies than many prior works (where each node in the graph is typically restricted to have a fixed number of neighbors), thanks to graphnets (2) the authors have provided convincing empirical evidence to back up their design choices about GHN through ablation studies.\n\nIn terms of experiments, perhaps one missing piece is to investigate alternative hypernet architectures in a controlled setting. For example, the authors could have implemented the tensor encoding scheme as in SMASH in their codebase to compare the capabilities of graph vs. non-graph structured hypernetworks. \n\nI’m also curious about the stability of the algorithm and the confidence of the final results. What would be the standard deviation of the final performance if you repeat the entire experiments from scratch (training GHN+random search+architecture selection) using different random seeds?\n\nA related question is whether the final performance can be improved with more compute. The algorithm is terminated at 0.84 GPU day, but I wonder how the performance would change if we keep searching for longer time (with more architecture samples). It would be very informative to see the curve of performance vs search cost.']","[80, 50, 80]","[70, 80, 90]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, calling it a 'solid technical contribution' and arguing 'in favor of acceptance'. They praise the well-designed experiments and strong results. The politeness score is 70 (polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and asks questions without being critical or harsh. They use phrases like 'I like' and 'It would be interesting to see' which maintain a positive, collaborative tone. The reviewer also acknowledges their own limitations in certain areas, which is a polite way to request additional input. The presence of a few typo corrections at the end is done matter-of-factly without criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (comprehensive study, clear idea, satisfactory experiments, easy-to-follow writing) but also points out limitations (marginal contribution, not impressive novelty). The overall tone is balanced, leaning slightly positive.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful language throughout. They start with positive observations, use phrases like 'I'm particularly interested' and 'I'm sorry that I do not understand', which show consideration. Even when critiquing, they maintain a professional tone. The reviewer also offers constructive suggestions and expresses hope for code release, which is courteous.\n\nThe reviewer's language is consistently professional and considerate, avoiding harsh criticism while still providing honest feedback, which contributes to both the slightly positive sentiment and the high politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'well-written and technically sound' and mention that they 'particularly like' certain aspects of the work. The reviewer also notes that the authors have provided 'convincing empirical evidence'. While they do suggest some additional experiments, these are framed as curiosities rather than criticisms.\n\nThe politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their suggestions as questions or areas of curiosity rather than demands. Phrases like 'I'm curious about' and 'It would be very informative to see' demonstrate a polite and collaborative tone. The reviewer also acknowledges the authors' efforts and contributions, which adds to the overall politeness of the review.""]"
"['This paper presents a very interesting interpretation of the neural network architecture.\n\nI think what is remarkable is that the author presents the general results (beyond the dense layer) including a convolutional layer by using the higher-order tensor operation.\nAlso, this research gives us new insight into the network architecture, and have the potential which leads to many interesting future directions. \nSo I think this work has significant value for the community.\n\nThe paper is clearly written and easy to follow in the meaning that the statement is clear and enough validation is shown. (I found some part of the proof are hard to follow.)\n\n\\questions\nIn the experiment when you mention about ""embed solvers as a replacement to their corresponding blocks of layers"", I wonder how they are implemented. About the feedforward propagation, I guess that for example, the prox operator is applied multiple times to the input, but I cannot consider what happens about the backpropagation of the loss.\n\nIn the experiment, the author mentioned that  ""what happens if the algorithm is applied for multiple iterations?"". From this, I guess the author iterate the corresponding algorithms several times, but actually how many times were the iterations or are there any criterion to stop the algorithm?\n\n\\minor comments\nThe definition of \\lambda_max below Eq(3) are not shown, thus should be added.', 'This paper theoretically verifies an equivalence between stochastic solvers on a particular class of convex optimization problems and a forward pass through a dropout layer followed by a linear layer and a non-linear activation. Experiments show that replacing a block of layers with multiple iterations of the corresponding solver improves classification accuracy. My detailed comments are as follows. \n\n*Positive points: \n\n1. The perspective is novel and interesting, i.e., training a forward pass through a dropout layer followed by a linear layer and a non-linear activation is equivalent to optimizing a convex problem by a Proximal Stochastic Gradient method. More importantly, this perspective has been theoretically verified. \n\n2. In the experiments, training networks with solvers replacing deep layers is able to improve accuracy significantly. \n\n*Negative points:\n\n1. Some technical details are not clear and many notations are used without clear explanations. Specifically, many notations based on (Bibi & Ghanem, 2017) make the paper hard to follow. Moreover, there are many mistakes in proofs. Please revise the paper according to the following comments.\n\n2. There are many limitations for the proposed method. Specifically, the theoretical results are hard to be extended to more general neural networks (e.g., ResNet) with Batch Normalization which are widely used.\n\n3. The experiment section should be significantly improved. There are only two datasets (i.e., CIFAR-10, CIFAR-100). It would be convincing that more baselines are compared on other datasets, such as ImageNet.\n\n*Detailed comments:\n\n**Comments on technical issues.\n\n1. In Problem (1), the definition of $g(x)$ and $f¬_i()$ should be provided for clarity.\n\n2. The motivation and some details of Function (2) should be provided since $F(x^l)$ is important for proving the equivalence between stochastic solvers and a forward network. In addition, $x$ should be corrected as $x^l$.\n\n3. Is Equation (3) wrong? Based on the definition of Prox-GD in (Xiao & Zhang, 2014), it should be $x^l=Prox(x^{l-1} – 1/L \\nabla F(x^l)) = Prox((I-1/L A)x^{l-1} + 1/L (AA^T x^l + b))$ which is different from Equation (3). Moreover, the Lipschitz constant w.r.t. maximal eigenvalue should be proved.\n\n4. In Definitions D.1 and D.2, what is the definition of $fold_{H0}$? Is the dimensionality of $bdiag(D)$ wrong? Why is $bdiag(D)$ an identity mapping when $n_3=n_4$?\n\n5. There are some issues on Equation (7) and its proofs. Is $A(:, i, :, :)$ and $\\vec{X}(i, :, :, :) $ wrong? It affects the results of Equation (8). Does Equation (25) miss the operator $fold_{HO}$ in Appendix G? Please check the proofs of Proposition 1.\n\n6. There are some issues on proofs of Lemma 2. Why are $F_H \\otimes F_W \\otimes I_{n_1}$ and $F_H \\otimes F_W \\otimes I_{n_2}$ orthogonal? Is the third and fourth equality in (24) wrong? For the fourth equality in (24), Eigen decomposition seems to be for a matrix, not a tensor.\n\n\n**Comments on Experiments\n\n1. Training Networks is equivalent to optimizing proximal solvers. Why can training networks with solvers replacing blocks of layers improve accuracy? Reasonable explanations should be provided.\n\n2. Optimizing a convex optimization problem can easily obtain the optimal solution. What happens if solvers are used to replace more blocks of layers? Complexity analysis for these should be provided.\n\n3. The experiments are only conducted on two datasets (i.e., CIFAR-10, CIFAR-100). It would be better to compared more baselines on other datasets, such as ImageNet.\n', 'Overview:  This paper shows that the forward pass of a fully-connected layer (generalized to convolutions) followed by a nonlinearity in a neural network is equivalent to an iteration of a prox algorithm, where different regularizers in the objective of the related prox problem correspond to different nonlinearities such as ReLu. This connection is quite interesting. They further relate different stochastic prox algorithms to different dropout  layers and show results of improved performance on CIFAR-10 and CIFAR-100 on several architectures. The paper is well-written.\n\nMajor Concerns:\n\n1. While the equivalence of one iteration of a prox algorithm and a single forward pass of the block is understandable, it is not clear what happens from making several iterations (10 in the case of fully-connected layers in the experiments) of the prox algorithm. It seems that this would be equivalent to making a forward pass through 10 equivalent blocks (i.e., 10 layers with the same weights and biases). But then the backward pass is still through the original network, so the problem being solved is not clear. Clarity on this would help.\n\n2. Since the equivalence of 10 forward passes of a block are done at each iteration, using solvers does more computations (can be thought of as extra forward passes through extra layers as noted above), which makes the comparison not completely fair. Either adding more batches or more passes over the same batch multiple times (or at least for a few batches just to use the some computational power) would be more fair and likely improve the performance of the baseline networks.\n\nMinor Issues:\n\n1. missing definitions such as g(x) at beginning of Section 3 and p in Proposition 1.\n\n2. Give examples of where the prox problems in Table 1 show up in practice (outside of activation functions in neural networks)\n\n3. It says ""for different choices of dropout rate the baseline can always be improved by..."" in the Experiments.  This is not provable.\n\n4. Include results for Dropout rate p=0 in Table 5.']","[80, -20, 50]","[70, 60, 75]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'very interesting' and having 'significant value for the community'. They praise the paper's interpretation, generalization of results, and potential for future research. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive feedback. They phrase their questions and comments in a considerate manner, using phrases like 'I wonder' and 'I guess'. The reviewer maintains a professional and courteous tone while providing both positive feedback and suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('novel and interesting perspective', 'improves accuracy significantly'), they also highlight several significant negative points and areas for improvement. The review lists more negative points than positive ones, and the overall tone suggests substantial revisions are needed. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They begin by acknowledging positive aspects before moving to criticisms, and phrase their feedback as suggestions ('Please revise', 'It would be better') rather than harsh demands. The reviewer also uses polite phrases like 'Please check' and 'Reasonable explanations should be provided', maintaining a constructive tone even when pointing out errors or limitations."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting the interesting aspects of the paper and mentions it is well-written, but then lists several major concerns and minor issues. This balanced approach suggests a moderately positive view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as 'concerns' or 'issues', and offers constructive suggestions. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to peer review.""]"
"['For binary layers, how to calculate and backpropagate gradients is a big problem, particularly for the binary neural networks. To solve the problem, this paper proposes an unbiased and low variance augment-REINFORCE-merge (ARM) estimator. With the help of an appropriate reparameterization, the antithetic sampling in an augmented space can be used to drive a variance-reduction mechanism. The experimental results show that ARM estimator converges fast, has low computational complexity, and provides advanced prediction performance.\n\nThis paper is well-organized. The motivation of the proposed model is well-driven and algorithm is articulated clearly. Meanwhile, the derivations and analysis of the proposed algorithm are correct. The experimental results show that the proposed model is better than the other existing methods.\n\nA few minor revision are list below.\n1) In figure 1, it seems difficult to decide which one is better from the trace plots of the true/estimated gradients. Also, why the author choose to compare the REINFORCE instead of REBAR and RELAX, since REBAR and RELAX improve on REINFORCE by introducing stochastically estimated control variates. Also, about trace plots of the loss functions, I am curious why REINFORCE has a big vibration during 1500~2000 iterations. \n2) About Table 2, are all compared methods in the same experimental settings?\n', 'Overview.\nThe authors present an algorithm for lowering the variance of the score-function gradient estimator in the special case of stochastic binary networks. The algorithm, called Augment-REINFORCE-merge proceeds by augmenting binary random variables. ARM combines Rao-Blackwellization and common random numbers (equivalent to antithetic sampling in this case, due to symmetry) to produce what the authors claim to be a lower variance gradient estimator. The approach is somewhat novel. I have not seen other authors attempt to apply REINFORCE in an augmented space and with antithetic samples / common random numbers, and Rao-Blackwellization. This combination of techniques may be a good idea in the case of Bernoulli random variables. However, due to a number of issues discussed below, this claim is not possible to evaluate from the paper.\n\nIssues/Concerns\n- I assess the paper in its current form as too far below the acceptable standard in writing and in clarity of presentation, setting aside other conceptual issues which I discuss below. The paper contains many typos and a few run-on sentences that span 5-7 lines. This hinders understanding substantially. A number key terms are not explained, irregularly. Although the paper assumes that readers do not know the mean and a variance of a Bernoulli random variable, or theof  definition of an indicator function, it does not explain what random variable augmentation means. The one sentence that comes close to explaining it seems to have a typo: ""From (5) it becomes clear that the Bernoulli random variable z ∼ Bernoulli(σ(φ)) can be reparameterized by racing two augmented exponential random variables ..."". It is not clear what is meant by ""racing,"" here, and I do not find it clear from equation (5) what is going on. Unfortunately, in the abstract, the paper claims that variance reduction is achieved by ""data augmentation,"" which has a very specific meaning in machine learning unrelated to augmented random variables, further obfuscating meaning. Similarly, the term ""merge"" is not explained, despite the subheading 2.3.\n- Computational issues are not addressed in the paper. Whether or not this method is useful in practice depends on computational complexity\n- No effort is made to diagnose the source of the variance reduction, other than in the special case of analytically comparing with the Augment-REINFORCE estimator, which does not appear in any of the experiments. \n- No effort is made to empirically characterize the variance of the gradient estimator, unlike Tucker et al (2017) and Grathwohl et al. (2018).\n- The algorithm presented in the appendix appears to only address single-layer stochastic binary networks, which are uninteresting in practice.\n- Figure 2 (d), (e), and (f) all show that ARM was stopped early. Given that RELAX and REBAR overfit, this is a little troubling. Overal, these results are not very convincing that ARM is better, particularly in the absence of variance analysis (empirically, or other than w.r.t. the same algorithm without the merge step). All algorithms should be run for the same number of steps, particularly in cases where they may be prone to overfitting.\n- Figure 1 I believe contains an error for the REINFORCE figure. In my own research I have run these experiments myself, with a value of p close to the one used by the authors. REBAR and RELAX both reduce to a REINFORCE gradient estimator with a control variate that is differentiably reparametrizable, and so the erratic behaviour of the REINFORCE estimator in this case is likely wrong.\n- There is a mysterious sentence on page 6 that refers to ARM adjusting the ""frequencies, amplitudes, and signs of its gradient estimates with larger and more frequent spikes for larger true gradients""\n-The value to the community of another gradient estimator for binary random variables is low, given the plethora of other methods available. Given the questions remaining about this methodology and its experiments, I recommend against publication on this basis also.\n- Table 2 compares results that mix widely different architectures against each other, some taken directly from papers, others possibly retrained. This is not a valid comparison to make when evaluating a new gradient estimator, where the model must be fixed. \n\n\n* EDIT: I have re-evaluated the careful and comprehensive response to my concerns by the authors. I thank them for their effort in this. As many of the concerns were related to communication and have been addressed in the most recent draft, I think it is appropriate to move my review upwards. The revisions make this paper quite different from the original, and I am happy to re-evaluate on that basis--this is a peculiarity of the ICLR open review procedure, but I consider it a strength. \n\nI note that ""data augmentation"" in machine learning appears to have collided with a term in the Bayesian statistics literature, and the authors have provide a number of citations to support this. I strongly recommend ""variable augmentation"" going forward, as that is an accurate description (you are augmenting a random variable, rather than the input data domain). This appears to be one of the growing pains of the field of ML which has distinct and often orthogonal concerns to classical statistics around density approximation and computational issues.*\n\n', 'In this paper the authors propose a new variance-reduction technique to use when computing an expected loss gradient where the expectation is with respect to independent binary random variables, e.g. for training VAEs with a discrete latent space. The paper is interesting, highly relevant, simple to implement, suggests many possible extensions, and shows good results on the experiments performed. However the exposition leaves a lot to be desired.\n\nMajor comments:\n\nThe authors devote several pages of fairly dense mathematics to deriving the ARM estimate in section 2 (up to section 2.5). However I found it relatively easy to derive (15) directly, using elementary results such as the law of total expectation and a single 1-dimensional integral, in about 10 lines of equations. As the authors note, deriving (4) from (15) requires an extra line or two. In my opinion it would greatly improve the clarity of the paper to use a more direct and straightforward derivation (perhaps with the interesting historical account of how the authors first derived this result given in an appendix). I could understand the more lengthy derivation being helpful if it gave insight into the source of variance reduction, but I don\'t see this personally, and the current discussion of variance reduction does not refer to the derivation of (15) at all.\n\nThe analysis of variance in section 2.6 leaves a lot to be desired. The central claim of the paper is that this method reduces variance, so it is an important section! Firstly, the variance of ARM vs AR is interesting, but the variance of ARM vs REINFORCE seems also highly relevant. Secondly, it seems like it would be very informative to look at the ratio of stdev to the mean for the ARM gradient estimate, since the true gradient is multiplied by sigmoid(phi) sigmoid(-phi) and so is very small if the probability of z = 1 is close to 0 or 1, exactly in the same regime where ARM has an advantage in variance reduction over AR. For example, it may be that learning in this regime is very difficult due to the weak gradient even if the estimate is extremely low variance. Thirdly and somewhat relatedly, in this same regime (z = 1 close to 0 or 1) the ARM gradient estimate is very often 0, meaning no learning takes place, so it seems a bit strange to argue that the new method is fantastic in the regime where it\'s almost always not learning! Of course, not learning is better than adding lots of spurious variance as reinforce would, but perhaps this could be made clearer. Finally, the theoretical analysis involving correlation gives very little insight and is extremely hand-wavy. A short worked example in the 1D or 2D case explicitly computing the variance of REINFORCE, AR and ARM seems like it would be highly informative.\n\nMinor comments:\n\nIn the introduction, ""*approximately* maximizing the marginal likelihood"" might be more accurate, since as given in (28) the exact marginal likelihood is not optimized in practice, and the exact marginal likelihood is not of the form (1) but is rather the logarithm of something of the form (1).\n\nI wasn\'t clear why ""equal in distribution"" was used a few things for things that are simply equal, such as just above (5).\n\nIn section 2.3, I don\'t see any real reason the estimates in (9) and (11) ""could be highly positively correlated"", other than an argument along the lines of the simple one given in section 2.6 that they\'re often equal and so zero.\n\nAs an aside, in section 3.1, it is great not to assume conditional independence of the binary latent variables across layers, but assuming conditional independence within each layer is still very restrictive. It is reasonable for the generative distribution to have this property, since the resulting net can still be essentially ""universal"" by stacking enough layers, but assuming this factorization in the variational distribution is highly restrictive with hard-to-reason-about consequences for the learned generative model. I realize this is a commonly used assumption and the authors are interested in the variance reduction properties of their approach rather than the training itself, but I just mention that it would be great to see extensions of the current work that can cope tractably with correlated latent variables within each layer.\n\nIn section 3.2, according to my understanding of standard terminology, ""maximum likelihood inference"" is a misnomer and would normally be ""maximum likelihood estimation"", since maximum likelihood is a method for estimating parameters whereas inference is about inferring latent variable values given parameters.\n\nIn section 4, it would be great to see some plots of explicit variance estimates of the different methods, given the overall goal of the paper (unless I just missed this?), even though figure 1 gives some insight into the variance characteristics.\n\nIn section 4.2, the expression log 1/K \\sum_k Bernoulli... differs in the placement of log from Jang et al (2017). Which is the standard convention for this task?']","[80, -60, -20]","[70, 20, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They state that it is 'well-organized', the motivation is 'well-driven', the algorithm is 'articulated clearly', and the derivations and analysis are 'correct'. The reviewer also notes that the experimental results show the proposed model is 'better than the other existing methods'. The only slight negative is the mention of 'minor revision', but this is common in positive reviews.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their suggestions as 'minor revisions'. The questions raised are presented as curiosities rather than criticisms (e.g., 'I am curious why...'). The tone is professional and courteous, without any harsh or rude language. However, it doesn't reach the highest level of politeness as it maintains a formal, rather than overly deferential, tone."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's clarity, methodology, and overall contribution. They state the paper is 'too far below the acceptable standard' and recommend against publication. However, the edit at the end indicates some improvement after revisions, slightly moderating the negative sentiment. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and acknowledge the authors' efforts to address concerns in the edit. They also thank the authors for their comprehensive response. The reviewer provides detailed feedback and suggestions, which is a polite and constructive approach, even if the overall assessment is negative."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting aspects and relevance, they express significant concerns about the exposition and analysis. The review begins positively but quickly shifts to critiques, with phrases like 'leaves a lot to be desired' and 'strange to argue' indicating dissatisfaction. The politeness score is moderately positive (60) as the reviewer maintains a professional tone throughout, using phrases like 'in my opinion' and 'it would be great to see,' which soften the criticisms. They also acknowledge positive aspects of the paper and offer constructive suggestions for improvement, demonstrating respect for the authors' work while providing thorough feedback.""]"
"['### post rebuttal### authors addressed most of my concerns and greatly improved the manuscript and hence I am increasing my score. \n \nSummary: \n\nThe paper introduces a static formulation for unbalanced optimal transport by learning simultaneously a transport map T and scaling factor xi .\n\nSome theory is given to relate this formulation to unbalanced transport metrics such as Wasserstein Fisher Rao metrics  for e.g. Chizat et al 2018.  \n\nThe paper proposes to  relax the constraint in the proposed static formulation using a divergence.  furthermore using a bound on the divergence , the final discrepancy proposed  is written as a min max problem between the witness function f of the divergence and the transport map T , and scaling factor xi. \n\nAn algorithm is given to find the optimal map T as a generator in GAN and to learn the scaling factor  and the witness function of the divergence with a neural network paramterization , the whole optimized with stochastic gradient. \n\nSmall experimentation on image to image transportation with unbalance in the classes is given and show how the scaling factor behaves wrt to this kind of unbalance. \n\n\nNovelty and  Originality:\n\nThe paper claims that there are no known static formulations known with a scaling factor and a transport map learned simultaneously. We refer the authors to Unbalanced optimal Transport: Geometry and Kantrovich Formulation Chizat et al 2015. In page 19 in this paper Equation 2.33 a similar formulation to Equation 4 in this paper is given. (Note that phi corresponds to T and lambda to xi). This is known as the monge formulation of unbalanced optimal transport. The main difference is that the authors here introduce a stochastic map T and an additional probabilty space Z. Assuming that the mapping is deterministic those two formulations are equivalent. \n\nCorrectness: \n\nThe metric defined in this paper can be written as follow and corresponds to a generalization of the monge formulation in chizat 2015 :\nL(mu,nu)= inf_{T, xi}  int   c_1(x,T_x(z) ) xi(x) lambda(z) dmu(x)  + int c_2(x_i(x)) dmu(x)\n                        \t\t s.t T_# (xi mu)=nu\nIn order to get a kantorovich formulation out of this chizat et al 2015 defines semi couplings and the formulation is given in Equations 3.1 page 20. \n\nThis paper proposes to relax  T_# (xi mu)=nu with D_psi (xi \\mu, \\nu) and hence proposes to use:\n\nL(mu,nu)= inf_{T, xi} int   c_1(x,T_x(z) ) xi(x) lambda(z) dmu(x)  + int c_2(x_i(x)) dmu(x)+  D_psi (xi \\mu, \\nu)\n\nLemma 3.2 of the paper claims that the formulation above corresponds to the Kantrovich formulation of unbalanced transport. I doubt the correctness of this:\n\nInspecting the proof of Lemma 3.2 L \\geq W seems correct to me, but it is unclear what is going on in the proof of the other direction? The existence of T_x is not well supported by rigorous proof or citation? Where does xi come from in the third line of the equalities in the end of page 14? I don’t follow the equalities written at the end of page 14. \n\nAnother concern is the space Z, how does the metric depend on this space? should there be an inf on all Z?\n\nOther comments:\n\n- Appendix A is good wish you baselined your experiments with those algorithms. \n\n- The experiments don’t show any benefit for learning the scaling factor, are there any applications in biology that would make a better case for this method?\n\n- What was the architecture used to model T, xi, and f?\n\n- Improved training dynamics in the appendix, it seems you are ignoring the weighting while optimizing on theta? than how would the weighing be beneficial ?', 'In this paper the authors consider the unbalanced optimal transport problem between two measures with different total mass. The authors introduce first the now standard Kantorovich-like formulation, which considers a coupling whose marginals are penalized to look like the two target measures. The authors introduce a second formulation in (2), somewhat a Kantorovich/Monge hybrid that involves a ""random"" Monge map where the target point T(x) of a point x now depends also on an additional random variable z, to desribe T(x,z). The authors also consider a local mass creation term (\\xi) to weight the initial measure \\mu.\n\nThe authors emphasize the interest of the 2nd formulation, which, much like the original Monge problem, has an intractable push-forward constraint. This formulation is similar to recent work on Wasserstein Autoencoders (to which is added the scaling parameter). As with WAE, this constraint is relaxed to penalize the deviation between the ""random"" push-forward and the desired marginal. \n\nThe authors show then that the resulting problem, which involves a transportation cost integrated both on the random variable z and on the input domain x, weighted by xi + a simple penalization for xi + a divergence penalizing the deviation between push-forward and desired marginal, can be optimized altogether by using three NN: 1 for the parameterization of T, 1 for the parameterization of \\xi, and one to optimize using a function f a variational bound on the divergence. 2 gradient descents (T,\\xi), 1 gradient ascent (f, variational bound).\n\nThe authors then make a link between that penalize formulation and something that resembles unbalanced transport (I say resembles because there is some assymetry, and that the type of couplings is restricted). Finally the authors show that by letting increase the penalty in front of the divergence in (6) they recover something that looks like the solution of (2).\n\nFor the sake of completeness, the authors provide in the appendix an implementation of a simple dual ascent scheme to approximate unbalanced OT inspired from previous work by Seguy\'17, and show that, unlike that work, their implicit parameterization of the scaling factor \\xi can help, and illustrate this numerically.\n\nI give credit to the authors for addressing a new problem and providing an algorithmic formulation to do so. That algorithm is itself recovered from an alternative formulation of unbalanced OT, and is therefore interesting in its own right. Unfortunately, I have found the presentation rushed. I really believe the paper would deserve an extensive re-write. Everything is fairly clear until Section 3. Then, the authors introduce their main contribution.  Basically the section tries to prove two things at the same time, without really completing its job. One is to prove that ""dualizing"" the scaling+ random push-forward equality constraint is ok if one uses big enough regularizers (intuitive), the other that this scaled + random push-forward formulation is closely related to W_{ub}. This is less clear to me (see below). \n\nThe experiments are underwhelming. For faces they happen in latent spaces, and therefore one recovers transport between latent spaces later re-visualized through a decoder. For digits, all is fairly simple. They do not clearly mention whether this alternative UOT approach approximates UOT at all. Despite the title, there\'s no generation. Therefore my grade is really split between a 5 and a 6.\n\nminor comments and questions:\n\n- Is the reference to a local scaling (\\xi) for unbalanced transport entirely new? your paper is not clear on that, and it seems to me this idea already appears in the OT literature.\n\n- I do not understand the connexion you make with GANs. In what sense can you interpret any of your networks as generators? To me it just feels like a simultaneous optimization of various networks, yet without a clear generative purpose. Technically there may be several similarities (as we optimize on networks), but I am not sure this justifies referencing GANs in the title. Additionally, and almost mechanically, putting GAN in your paper, the reader will expect some generation results..\n\n- Numerical benchmarks: Is the technique you propose supposed to approximate the optimal value of Unbalanced OT at all? If yes, is there a way you could compare yourselves with Chizat\'s approach?\n\n- Somewhere in Lemma 3.2 the fact that you had to use an alternative definition \\tilde{W} (by restricting the class of couplings) is not really clarified to the reader. Qualitatively, what does it mean that you restrict the class of couplings to have the same support as \\mu? In which situations would \\tilde{W} be very different from W_{ub} ? (which, if I understand correctly, only appears in (2) but not elsewhere in the paper?)\n\n- I think it would help for the simple sake of readability to add integration domains under your \\int symbols.\n\n- T is used as a subset in Lemma 3.1, while it is used after and before as a map of (x,z)\n\n- T(x,z) looks intuitively like a noisy encoder as in Wasserstein AEs (with, of course, the addition of your term \\xi). Could you elaborate?\n\n- I have scanned the paper but did not see how you set lambda.', 'REVIEW\n\nThe authors propose a novel approach to estimate unbalanced optimal transport between sampled measures that scales well in the dimension and in the number of samples. This formulation is based on a formulation of the entropy-transport problems of Liero et al. where the transport map, growth maps and Lagrangian multipliers are parameterized by neural networks. The effectiveness of the approach is shown on some tasks.\n\nThis is overall an ingenious contribution that opens a venue for interesting uses of optimal transport tools in learning problems (I can think for instance of transfer learning). As such I think the idea would deserve publication. However, I have some concerns with the way the theory is presented and with the lack of discussions on the theoretical limitations. Also, the theory seems a bit disconnected from the practical set up, and this should be emphasized. These concerns are detailed below. \n\nREMARKS ON SECTION 3\n\nI think the theoretical part does not exhibit clearly the relationships with previous literature. The formulation proposed in the paper (6) is not new and consists in solving the optimal entropy-transport problem (2) on the set of product measures gamma that are deterministic, i.e. of the form\ngamma(x,y) = (id x T)_# (xi mu) for some T:X -> Y and xi : X -> R_+ (here (id x T)(x) =(x,T(x)) )\nIt is classical in optimal transport to switch between convex/transport plan formulation (easier to study) to non-convex/transport map formulations (easier to interpret). (As a technical note, the support restriction in Lemma 3.2 is automatically satisfied for all feasible plans, for super-linear costs c_2=phi_1).\n\nMore precisely, since the authors introduce a reference measure lambda on a space Z (these objects are not motivated anywhere, but I guess are used to allow for multivalued transport maps?), they look for plans of the form\ngamma(x,y) = (pi_x x T)_# (xi mu otime lambda) where (pi_x x T)(x,z) = (x,T(x,z) and ""otime"" yields product measures) (it is likely that similar connections could be made with the ""static"" formulations in Chizat et al.).\n\nIntroduced this way, the relationship to previous literature would have been clearer and the theoretical results are simple consequences of the results in Liero et al., who have characterized when optimal solutions of this form exist. Also this contradicts the remark that the authors make that it is better to model ""directly mass variation"" as their formulation is essentially equivalent.\n\nThe paragraph ""Relation to Unbalanced OT"" is, in my opinion, incomplete. The switch to non-convex formulation introduce many differences to convex approaches that are not mentioned: there is no guarantee that a minimizer can be found, there is a bias introduced by the architecture of the neural network, ... Actually, it is this bias that make the formulation useful in high dimension since it is know that optimal transport suffers from the curse of dimensionality (thus it would be useless to try to solve it exactly in high dimension). I suggest to improve this discussion.\n\nOTHER REMARKS\nA small remark: lemma 3.1 is the convex conjugate formula for the phi-divergence in the first argument. I suggest to call it this way to help the reader connect with concepts he or she already knows. Its rigorous proof (with measurability issues properly dealt with) can be found, for instance, in Liero et al. Theorem 2.7. It follows that the central objective (8) is a Lagrangian saddle-point formulation of the problem of Liero et al., where transport plans, scalings and Lagrange multipliers are parameterized by neural networks. I generally think it is best to make the link with previous work as simple as possible.\n\nAlso, Appendix C lacks details to understand precisely how the experiments where done. It is written :\n""In practice, [the correct output range] can be enforced by parameterizing f using a neural network with a final layer that maps to the correct range. In practice, we also found that employing a Lipschitz penalty on f stabilizes training.""\nThis triggers two remarks: \n- (i) how precisely is the correct range enforced? This should be stated.\n- (ii) a Lipschitz penalty on f yields a class of functions which is very unlikely to have the properties of Lemma 3.1 ; in fact, this amounts to replacing the last term in (6) by a sort of ""bounded Lipschitz"" distance which has very different property from a f-divergence. This makes the theory of section 3 a bit disconnected from the practice of section 4.\n']","[20, -20, -20]","[60, 60, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the authors addressed most of their concerns and improved the manuscript, leading to an increased score. However, the review still contains several critiques and doubts about the paper's novelty and correctness, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges improvements. They use phrases like 'I doubt the correctness of this' instead of more confrontational language, and provide detailed explanations for their concerns. The reviewer also offers suggestions and asks questions rather than making harsh judgments, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I give credit to the authors for addressing a new problem'), they express several criticisms and concerns. The reviewer finds the presentation 'rushed', the experiments 'underwhelming', and states that the paper 'would deserve an extensive re-write'. They also mention that their grade is 'split between a 5 and a 6', indicating a somewhat negative overall assessment. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use polite phrases like 'I give credit to the authors' and frame criticisms constructively, such as 'I really believe the paper would deserve an extensive re-write'. The reviewer also asks questions and provides detailed feedback, which is a courteous approach in academic review. However, some direct criticisms prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the contribution as 'ingenious' and deserving publication, they express several concerns about the presentation of theory, lack of discussion on theoretical limitations, and disconnection between theory and practical setup. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits before presenting criticisms, and phrases concerns as suggestions for improvement rather than harsh criticisms. The reviewer also uses polite language such as 'I think,' 'I suggest,' and provides detailed explanations for their comments, showing consideration for the authors.""]"
"['This paper presents a method for learning about the parts and motion dynamics of a video by trying to predict future frames.  Specifically, a model based on optical flow is defined, noting that the motion of hierarchically related parts are additive.  Flow fields are represented using an encoder/decoder architecture and a binary structural matrix encodes the representations between parts.  This matrix is predicted given the previous frame and flow field.  This is then used to estimate a new flow field and generate a possible future frame.  The system is trained to predict future frames using an L2 loss on the predicted image and motion field and regularized to prefer more compact and parsimonious representations.\n\nThe method is applied to synthetic datasets generated by moving shapes or MNIST digits and shown to work well compared to some recent baseline methods for part segmentation and hierarchy representation.  It is also applied and qualitatively evaluated for future frame prediction on an atari video game and human motion sequences.  The qualitative evaluation shows that part prediction is plausible but the results for future frame prediction are somewhat unclear as there are no baseline comparisons for this aspect of the task.\n\nOverall the approach seems very interesting and well motivated.   However, the experimental comparisons are limited and baselines are lacking.  Further, some relevant related work is missing.\n\nSpecific concerns:\n- Motion segmentation has been studied for a long time in computer vision, a comparison against some of these methods may be warranted.  See, e.g., Mangas-Flores and Jepson, CVPR 2013.\n- There is some missing related work on learning part relations.  See, e.g., Ross, et al IJCV 2010 and Ross and Zemel JMLR 2006.\n- There is also some missing work on future frame prediction.  In particular, PredNet seems relevant to discuss in the context of this work and as a baseline comparison method.  See Lotter et al ICLR 2017.\n- A reasonable baseline might be simply to apply the previous frames motion field to generate the next frame.  This would be a good comparison to include.\n- The ""Human Studies"" section is very unclear.  How is ""same tree structure"" defined exactly and how were humans asked to annotate the tree structure?  If it\'s about the hierarchical relationship, then I would expect humans to always be pretty consistent with the hierarchy of body parts and suggests that the model is doing relatively poorly.  If it\'s some other way, then this needs to be clarified.  Further, how was this study performed?  If this section can\'t be thoroughly explained it should be removed from the paper as it is at best confusing and potentially very misleading.\n- The system only considers a single frame and flow-field for part prediction.  From this perspective, the effectiveness of the method seems somewhat surprising.\n- The system takes as input both a frame and a flow field.  I assume that flow field is computed between I0 and I1 and not I1 and I2, however this is never specified anywhere I can find in the manuscript.  If this is not the case, then the problem setup is (almost) trivial.\n\n', 'The paper describes a method, which learns the hierarchical decomposition of moving objects into parts without supervision, based on prediction of the future. A deep neural network is structured into a sequence of encoders and decoders: the input image is decomposed into objects by a trained head, then motion is estimated from predicted convolutional kernels whose model is trained on optical flow; the latent motion output is encoded into separated motion fields for each object and then composed into a global model with a trainable structured matrix which encodes the part hierarchy. The latent space is stochastic similar to VAEs and trained with similar losses.\n\nStrengths:\n\nThe idea is interesting and nicely executed. I particularly appreciated the predicted kernels, and the trainable structure matrix. Although the field of hierarchical motion segmentation is well studied, up to my knowledge this method seems to be the first of its kind based on a fully end-to-end trainable method where the motion estimators, the decomposition and the motion decoders are learned jointly.\n\nThe method is evaluated on different datasets including fully synthetic ones with synthetic shapes or based on MNIST; very simple moving humans taken from ATARI games, and realistic humans from two different pose datasets. The motion decomposition is certainly not as good as the definition and the output of a state of the art human pose detector; however, given that the decomposition is discovered, the structure looks pretty good.\n\nWeaknesses\n\nI have two issues with the paper. First of all, although the related work section is rich, the methods based on hierarchical motion decompositions are rarer, although the field is quite large. Below are a couple of references:\n\nMihir Jain, Jan Van Gemert, Hervé Jégou, Patrick Bouthemy, and Cees GM Snoek. Action localization with tubelets from motion. CVPR, 2014.\n\nChenliang Xu and Jason J Corso. Evaluation of super-voxel methods for early video processing. CVPR, 2012.\n\nJue Wang, Bo Thiesson, Yingqing Xu, and Michael Cohen. Image and video segmentation by anisotropic kernel mean shift. ECCV, 2004 \n\nChenliang Xu, Caiming Xiong, and Jason J Corso. Streaming hierarchical video segmentation. ECCV 2012.\n\nMatthias Grundmann, Vivek Kwatra, Mei Han, and Irfan Essa. Efficient hierarchical graph-based video segmentation. CVPR, 2010.\n\nPeter Ochs, Jitendra Malik, and Thomas Brox. Segmentation of moving objects by long term video analysis. IEEE PAMI, 2014.\n\nDiscovering motion hierarchies via tree-structured coding of trajectories\nJuan-Manuel Pérez-Rúa, Tomas Crivelli, Patrick Pérez, Patrick Bouthemy, BMVC 2016.\n\nSamuel J Gershman, Joshua B Tenenbaum, and Frank Jäkel. Discovering hierarchical motion structure. Vision Research, 2015.\n\nSecondly, the presentation is not perfect. The paper is densely written with lots of information thrown rapidly at the reader. Readers familiar with similar work can understand the paper (I needed a second pass). But many parts could be better formulated and presented.\n\nI understood the equations, but I needed to ignore certain thinks in order to understand them. One of them is the superscript in the motion matrices M, which does not make sense to me. “g” seems to indicate “global” and “l” local, but then again a local parent matrix gets index “g”, and this index seems to switch whether the same node is seen as the current node or the parent of its child. \n\nFigure 3 is useful, but it is hard to make the connection with the notation. Symbols like z, M etc. should be included in the figure.\n\nThe three lines after equations 2 and 3 should be rewritten. They are understandable but clumsy. Also, we can guess where the binary constraints come from, but they should be introduced nevertheless.\n\nIn essence, the paper is understandable with more efforts than there should be necessary.\n\n\nOther remarks:\n\nThe loss L_struct is L_2, I don’t see how it can favor sparsity. This should be checked and discussed.\n\nA symbolic representation is mentioned in the introduction section. I am not sure that this notion is completely undisputed in science, it should at least not be presented as a fact.\n\nThe ATARI dataset seems to be smallish (a single video and 5000 frames only).\n', 'The paper proposes an unsupervised learning model that learns to (1) disentangle object into parts, (2) predict hierarchical structure for the parts and (3), based on the disentangled parts and the hierarchy, predict motion. The model is trained to predict future frames and motion with L2 loss given current frame and observed motion. The overall objective is similar to a standard VAE. \n\nOne interesting module proposed in this work is the structural descriptor which assumes motions are additive and global motion of an object part can be recovered by adding the local motion of this object with the global motions of its parents. The equation can be applied recursively and it generalizes to any arbitrary hierarchy depth.\n\nPros:\nThe overall methodology is quite novel and results look good. Merging hierarchical inference into the auto-encoder kind of structure for unsupervised learning is new.\nThe results are tested on both synthetic and real videos.\n\nCons:\nThe idea is only tested on relatively simple dataset. For the synthetic data, the objects only have very restrictive motions (ex. Circles always move diagonally). It is also unclear to me whether all the samples in the dataset share the same hierarchical tree structure or not (For human, it seems like every sample uses the same tree).  If this is the case, then it means you need 100K data to learn one hierarchical relationship for very simple video.\nFrom the human dataset results, since the appearance and motions become so different across videos, making the video clean and making the objects aligned (so that motions are aligned) seems important to make the model work. For example, from figure 11(f)(g), the right and left legs are exchanged for the person on the top. This brings up the concern that the model is fragile to more complicated scenes such that objects are not super aligned and the appearances differ a lot. (ex. Videos of people playing different sports shooting from different views)\nShould add more baselines. There are a lot of unsupervised video prediction works which also unsupervisedly disentangle motions and contents. \n\nOthers:\nThe sparsity constraint seems incorrect\n', '==== Review Summary ====\n\nThe paper demonstrates an interesting and potentially useful idea.  But much of it is poorely explained, and experimental results are not strongly convincing.  The only numerical evaluations are on a simple dataset that the authors made themselves.  The most interesting claim - that this network can learn unsupervised hierarchical object segmentation based on unlabelled video data -  is not well supported by the paper.  \n\n==== Paper Summary ====\n\nThis paper presents a deep neural network which learns object Segmentation, Structure, and Dynamics from unlabelled video.  The idea is quite useful, as it is a step towards learning models that can ""discover"" the concept of objects in a visual scene without any supervision.  \n\nThe central contributions of this paper are:\n(1) To show how one can use coherent motion (the fact that different parts of an object move together) to learn unsupervised object segmentation.\n(2) To show how once can learn the relation between objects (e.g. ""arm"" is part of ""body"") by observing relative motion between segments.\n\n==== General Feedback ====\n\nThe paper would benefit a lot from better explanations and being better tied together (see ""Details"" below for examples).   Figure captions would benefit from much better explanations and integration with the text - each figure caption should at least describe what the figure is intended to demonstrate.  Variables such as ($\\mathcal M$, $\\mathcal S$, $\\mathcal I$, $\\mathcal L$) should be indicated in figures .  \n\nMany things would benefit from being defined precisely with Equations.  For example I have no idea how the ""soft"" structural descriptor S is computed.  Is it (A) a parameter that is shared across data points and learned?  or (B) is it computed per-frame from the network?  And after it is calculated, how are the S_{ik} values (which fall between 0 and 1) used to combine the motion maps?  \n\n==== Scientific Questions ===\n\nI\'m confused as to what the latent variables z ""mean"".  It seems strange that there is a 1-d latent variable representing the motion of each part.  Translation of a segment within an image is 2D.  3D if you include planar rotation, then there\'s scaling motion and out-of-plane rotations, so it seems an odd design choice that motion should be squeezed into a 1D representation.\n\nI find it difficult to assess the quality of the ""next frame predictions"".  There\'s lots other literature on next-frame prediction to compare against (e.g. https://arxiv.org/abs/1605.08104).  At least you could compare to a naive baseline of simply shifting pixels based on the optical flow.  \n\nI\'m confused about how you are learning the ""estimated flow"".  My impression is that the input flow is calculated between the last 2 frames $\\hat M = flow(I_{t-1}, I_t)$.  And that the ""estimated"" flow is an estimate of $flow(I_{t}, I_{t+1})$.  But in Section 4.3 you seem to indicate that the ""estimated"" flow is just trained to ""reconstruct"" the input flow.... In that case why not just feed the input flow directly into the Image Decoder?  What I guess you\'re doing is trying to Predict the next flow ($flow(I_{t}, I_{t+1})$) but if you\'re doing this neither Figure 3 nor Section 4.2 indicates this, hence my confusion.  \n\n==== Details ====\n\nFigure 3: \n----\nThe ""shapes"" example is odd, because it\'s not obvious that there\'s a structural hierarchy linking the shapes.  Maybe a ""torso/left arm/right arm"" would be better for illustrative purposes?\nIt would be helpful to put the variable names ($\\mathcal M_k$, etc) on the figure.\nShould add a second arrow coming into the (f) the Structural descriptor from a leaf-variable $p_k$\nAlso it would be helpful to indicate where the losses are evaluated.\n""Next Frame"" should probably be ""Reconstruction"" (though ""Prediction"" might be a more accurate word).\n---\n\nSection 4.2:\nNotational point, it seems k can be from 1 to d.  But in Section 3 you say it can be from 1 to ""n"". Maybe it would be clearer to change both (""n"" and ""d"") to ""K"" to emphasize that ""k"" is an index which goes up to ""K"".  (edit... now after reading 5.1: Latent Representation, I understand.  If there are n parts in the dataset you use d>n dimensions and the network learns to ""drop"" the extra ones... it would help to clarify that here).\nStructural Descriptor: You say ""in practice, we relax the binary constraints""... Yet this is important.. should write down the equation and say how the ""soft"" version of [i \\in S] calculated.\nSection 4.3\n""elbo"" seems like the wrong name for this loss, as it\'s not an Evidence Lower BOund.  The elbo would be the sum of this loss and the first component of L_{recon}.  It is a regularizing term, so you could call it L_reg.\nIt\'s not obvious that sparse local motion maps mean a heirarchical tree structure, but I see how it could help.  I suggest that without evidence for this loss you soften the claim to ""this is intended to help encourage the model to learn a heirarchical tree structure""\nFigure 4: \nIt appears that each row indicates a different video in the dataset, but then in 4f you still have two rows but they appear to correspond to different algorithms... a vertical separator here might help show that the rows in 4f do not correspond to the rows in 4a-e.\n""Next Frame"" here appears to refer to ground truth, but in Figure 3 ""Next Frame"" appears to be the prediction (which you call reconstruction). \nSection 5.1\n\nFuture Prediction: No explanation either here or in Figure 4 of what it actually shows.  (What would a failure look like?)\nHierarchical structure... You binarize... how?\nFigure 9:\nWhat does this show?  The figure does not obviously demonstrate anything.  Maybe compare to ground-truth future frames?\nSection 5.3:\nFuture Prediction: These images are from the test set, right?  If so, that is worth mentioning. \nObject Segmentation (""in several different dimensions""  -> ""corresponding to the active latent dimensions?"")\nObject Segmentation: Visually, it looks nice, but I have now idea how good this segmentation is.  You compare verbally to R-NEM and PSD, but there\'re no numbers.\nHuman Studies... The line ""For those whose predicted tree structures are not consistent with ours, they all agree with our results and believe ours are more reasonable than others"" .. brings to mind an image of a room full of tortured experimental subjects not being allowed to leave until they sign a confession that their own tree structures were foolish mistakes and your tree structures are far superior.... So probably it should be removed because it sounds shady. \n']","[20, 50, 20, -30]","[60, 70, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer describes the approach as 'very interesting and well motivated' and acknowledges that the method works well on certain datasets. However, they also express several concerns and point out limitations, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'seems very interesting' and 'may be warranted' which maintain a polite tone. The reviewer also provides specific, detailed feedback which is helpful and courteous to the authors. However, the score is not maximally positive as the language, while polite, is still direct and critical in parts."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, describing the idea as 'interesting and nicely executed' and praising certain aspects of the method. However, they also point out weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits while offering constructive criticism. They use phrases like 'I particularly appreciated' and 'The idea is interesting,' which contribute to a polite tone. Even when discussing weaknesses, the reviewer maintains a professional and courteous demeanor, offering suggestions for improvement rather than harsh criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and good results of the paper, calling the methodology 'quite novel' and stating that 'results look good'. However, they also list several significant concerns under 'Cons', which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and presents both pros and cons in a balanced manner. They avoid harsh criticism and use phrases like 'It is unclear to me' instead of more accusatory language. The reviewer also offers constructive suggestions, such as adding more baselines, which contributes to the polite tone."", ""Sentiment score: The review starts with acknowledging the paper's interesting and potentially useful idea, but quickly shifts to criticisms. The reviewer points out poor explanations, unconvincing experimental results, and insufficient support for the main claim. The overall tone is more negative than positive, hence the negative score, but not extremely negative due to the initial positive acknowledgment.\n\nPoliteness score: The reviewer maintains a professional and generally polite tone throughout. They use phrases like 'The paper would benefit from...' and 'I'm confused about...' rather than direct criticisms. However, there are a few instances of blunt language, such as 'poorely explained' and 'not strongly convincing'. The suggestion to remove a line about human studies is delivered tactfully. Overall, the review is more polite than neutral, but not excessively so.""]"
"['As a reviewer I am expert in learning in structured data domains. \nThe paper proposes a quite complex system, involving many different choices and components, for obtaining chemical compounds with improved properties starting from a given corpora. \nOverall presentation is good, although some details/explanations/motivations are missing. I guess this was due to the need to keep the description of a quite complex system in the given space limit. Such details/explanations/motivations could, however, have been inserted in the appendix. As an example, let consider the description of the decoding of the junction tree. In that section, it is not explained when the decoding process stops. My understanding is that this is when, being in the root node, the choice is to go back to the parent (that does not exist). In the same section, it is not explicitly discussed that the probability to select between adding a node or going back to the parent should have a different distribution according to ""how many"" nodes have been generated before, i.e. we do not want to have a high probability to ""go back"" at the beginning of the decoding, while I guess it is desirable that such probability increases proportionally with the number of generated nodes. This leads to an issue that I personally think is important: the paper does lack an explicit probabilistic modelling of the different involved components, which may help for a better understanding of all the assumptions made in the construction of the proposed system. \nThe complexity of the proposed system is actually an issue since the author(s) do not attempt (except for  the presence or absence of the adversarial scaffold regularization and the number of trials in appendix) an analysis of the influence of the different components (and corresponding hyper-parameters). \nReference to previous relevant work seems to be complete.\nI think the paper is relevant for ICLR (although there is no explicit analysis of the obtained hidden representations) and of interest for a good portion of attendees.\n\nMinor issues:\n- Tree and Graph Encoding: asynchronous update implies that T should be a multiple of the diameter of the input graph to guarantee a proper propagation of information across the graph. A discussion about that would be needed.\n- eq.(6): \\mathbb{u}^d is not defined.\n- Section 3.3:\n   - first paragraph is not clear. An example and/or figure is needed to understand the argument, which is related to the presence of cycles.\n  - the definition of f(G_i) involves  \\mathbb{x}_u. I guess they should be  \\mathbb{x}_u^G.\n  - not clear how the log-likelihood of ground truth subgraphs is computed given that the predicted junction tree, especially at the beginning of training, may be way different from the correct one. Moreover, what is the assumed bias of this choice ?\n- Table I: please provide an explanation of why using a larger value for \\delta does provide worst performance than a smaller value. From an optimisation point of view it should provide at least an as good performance. This is a clear indication that the used procedure is suboptimal.\n- diversity could be influenced by the cardinality of the sample. Is this false ? please discuss why diversity is (not) biased versus larger sets.', ""Update:\nThe score has been updated to reflect the authors' great efforts in improving the manuscript. This reviewer would suggest to accept the paper now.\n\n\nOld Review Below:\n\nThe paper describes a graph-to-graph translation model for molecule optimization inspired from matched molecular pair analysis, which is an established approach for optimizing the properties of molecules. The model extends a chemistry-specific variational autoencoder architecture, and is assessed on a set of three benchmark tasks.\n\n\nWhile the idea of manuscript is interesting and promising for bioinformatics, there are several outstanding problems, which have to be addressed before it can be considered to be an acceptable submission. This referee is willing to adjust their rating if the raised points are addressed. Overall, the paper might also be more suited at a domain-specific bioinformatics conference.\n\n\nMost importantly, the paper makes several claims that are currently not backed up by experiments and/or data. \n\nFirst, the authors claim that MMPs “only covers the most simple and common transformation patterns”. This is not correct, since these MMP patterns can be as complex as desired. Also, it is claimed that the presented model is able to “learn far more complex transformations than hard-coded rules”. The authors will need to provide compelling evidence to back up these claims. At least, a comparison with a traditional MMPA method needs to be performed, and added as a baseline. Also, it has to be kept in mind that the reason MMPA was introduced was to provide an easily interpretable method, which performs only local transformations at one part of the molecule. “Far more complex transformations” may thus not be desirable in the context of MMPA. Can the authors comment on that?\n\nSecond, the authors state that they “sidestep” the problem of non-generalizing property predictors in reinforcement learning, by “unifying graph generation and property estimation in one model”. How does the authors’ model not suffer from the same problem? Can they provide evidence that their model is better in property estimation than other models?\n\n\nIn the first benchmark (logP) the GCPN baseline is shown, but in the second benchmark table, the GCPN baseline is missing. Why? The GCPN baseline will need to be added there. Can the authors also comment on how they ensure the comparison to the GPCN and VSeq2Seq is fair? Also, can the authors comment on why they think the penalized logP task is a good benchmark?\n\nAlso, the authors write that Jin et al ICML 2018 (JTVAE) is a state of the model. However, also Liu et al NIPS 2018 (CGVAE) state that their model is state of the art. Unfortunately, both JTVAE and CGVAE were never compared against the strongest literature method so far, by Popova et al, which was evaluated on a much more challenging set of tasks than JT-VAE and CGVAE. The authors cite this paper but do not compare against it, which should to be rectified. This referee understands it is more compelling to invent new models, but currently, the literature of generative models for molecules is in a state of anarchy due to lack of solid comparison studies, which is not doing the community a great service.\n\n\nFurthermore, the training details are not described in enough detail. \nHow exactly are the pairs selected? Where do the properties for the molecules come from? Were they calculated using the logP, QED and DRD2 models? How many molecules are used in total in each of these tasks?\n"", 'This paper proposed an extension of JT-VAE [1] into the graph to graph translation scenario. To help make the translation model predicting diverse and valid outcomes, the author added the latent variable to capture the multi-modality, and an adversarial regularization in the latent space. Experiment on molecule translation tasks show significant improvement over existing methods.\n\nThe paper is well written. The author explains the GNN, JT-VAE and GAN in a very organized way. The idea of modeling the molecule optimization as translation problem is interesting, and sounds more promising (and could be easier) than finding promising molecule from scratch. \n\nTechnically I think it is reasonable to use latent variable model to handle the multi-modality. Using GAN to align the distribution is also a well adapted method recently. Thus overall the method is not too surprising to me, but the paper executes it nicely. Given the significant empirical improvement, I think this paper has made a valid contribution to the area.\n\nRegarding the results in Table 1, I’m curious why the VSeq2Seq is better than JT-VAE and GCPN (given the latter two are the current state-of-the-art)? \n\nAnother thing I’m curious about is the ‘stacking’ of this translation model. Suppose we keep translating the molecule X1 -> X2 -> X3 ...  using the learned translation model, would the model still gets improvement after X2? When would it get maxed out?\nOr if we train with ‘path’ translation (i.e., train with improvement path with variable length), instead of just the pair translation, would that be helpful? I’m not asking for more experiments, but some discussion might be useful.\n\n[1] Jin et.al, Junction tree variational autoencoder for molecular graph generation, ICML 2018\n']","[-20, 50, 80]","[50, 60, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Overall presentation is good', 'Reference to previous relevant work seems to be complete', 'the paper is relevant for ICLR'), they raise several concerns and criticisms. These include missing details/explanations, lack of explicit probabilistic modeling, and insufficient analysis of different components. The complexity of the system is seen as an issue, and there are several 'Minor issues' pointed out. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I guess', 'I personally think', and 'please provide an explanation', which soften their criticisms. The reviewer also acknowledges potential space constraints and offers constructive suggestions. However, the language is not overly formal or deferential, maintaining a balance between politeness and directness in their critique."", ""The sentiment score is 50 (slightly positive) because the review starts with a positive update indicating the paper should now be accepted, which overrides the more critical tone of the original review. The original review had a mix of positive and negative comments, acknowledging the interesting idea but pointing out several issues. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers to adjust their rating if issues are addressed, and frames criticisms as suggestions or questions rather than harsh statements. However, they do directly challenge some of the authors' claims, which prevents a higher politeness score. The reviewer also uses formal academic language and offers detailed, constructive feedback, which contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'well written,' 'interesting,' and having made a 'valid contribution.' The reviewer acknowledges the significant empirical improvement shown in the paper. While they mention that the method is 'not too surprising,' they still praise its execution. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I'm curious' when asking questions, and offers suggestions for discussion rather than demanding changes. They also acknowledge the paper's strengths before offering any critiques or questions, which is a polite approach to reviewing.""]"
"['The paper proposes a modification to the traditional conditional GAN objective (which minimizes GAN loss as well as either L1 or L2 pixel-wise reconstruction losses) in order to promote diverse, multimodal generation of images. The modification involves replacing the L1/L2 reconstruction loss -- which predicts the first moment of a pixel-wise gaussian/laplace (respectively) likelihood model assuming a constant spherical covariance matrix -- with a new objective that matches the first and second moments of a pixel-wise gaussian/laplace likelihood model with diagonal covariance matrix. Two models are proposed for matching the first and second moments - the first one involves using a separate network to predict the moments from data which are then used to match the generator’s empirical estimates of the moments (using K samples of generated images). The second involves directly matching the empirical moment estimates using monte carlo.\n\nThe paper makes use of a well-established idea - modeling pixel-wise image likelihood with a diagonal covariance matrix i.e. heteroscedastic variance (which, as explained in [1], is a way to learn data-dependent aleatoric uncertainty). Following [1], the usage of first and second moment prediction is also prevalent in recent deep generative models (for example, [2]) i.e. image likelihood models predict the per-pixel mean and variance in the L2 likelihood case, for optimizing Equation 4 from the paper. Recent work has also attempted to go beyond the assumption of a diagonal covariance matrix (for example, in [3] a band-diagonal covariance matrix is estimated). Hence, the only novel idea in the paper seems to be the method for matching the empirical estimates of the first and second moments over K samples. The motivation for doing this makes intuitive sense since diversity in generation is desired, which is also demonstrated in the results.\n\nSection specific comments:\n- The loss of modality of reconstruction loss (section 3.2) seems like something which doesn’t require the extent of mathematical and empirical detail presented in the paper. Several of the cited works already mention the pitfalls of using reconstruction loss.\n\n- The analyses in section 4.4 are sound in derivation but not so much in the conclusions drawn. It is not clear that the lack of existence of a generator that is an optimal solution to the GAN and L2 loss (individually) implies that any learnt generator using GAN + L2 loss is suboptimal. More explanation on this part would help.\n\nThe paper is well written, presents a simple idea, complete with experiments for comparing diversity with competing methods. Some theoretical analyses do no directly support the proposition - e.g. sections 3.2 and 4.4 in my specific comments above. Hence, the claim that the proposed method prevents mode collapse (training stability) and gives diverse multi-modal predictions is supported by experiments and intuition for the method, but not so much theoretically. However, the major weakness of the paper is the lack of novelty of the core idea.\n\n=== Update after rebuttal:\nHaving read through the other reviews and the author\'s rebuttal, I am unsatisfied with the rebuttal and I do not recommend accepting the paper. My rating has decreased accordingly.\n\nThe reasons for my recommendation, after discussion with other reviews, are -- (1) lack of novelty and (2) weak theoretical results (some justification of which was stated in my initial review above). Elaborating more on the second point, I would like to mention some points which came up during the discussion with other reviewers: The theoretical result which states that not using reconstruction loss given that multi-modal outputs are desired is a weaker result than proving that the proposed method is actually effective in what it is designed to do. There are empirical results to back that claim, but I strongly believe that the theoretical results fall short and feel out of place in the overall justification for the proposed method. This, along with my earlier point of lack of novelty are the basis for my decision.\n\n\nReferences:\n[1] Kendall, Alex, and Yarin Gal. ""What uncertainties do we need in bayesian deep learning for computer vision?."" Advances in neural information processing systems. 2017.\n[2] Bloesch, M., Czarnowski, J., Clark, R., Leutenegger, S., & Davison, A. J. (2018). CodeSLAM-Learning a Compact, Optimisable Representation for Dense Visual SLAM. CVPR 2018.\n[3] Dorta, G., Vicente, S., Agapito, L., Campbell, N. D., & Simpson, I. (2018, February). Structured Uncertainty Prediction Networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.', 'This paper analyzes the model collapse problems on training conditional GANs and attribute it to the mismatch between GAN loss and reconstruction loss. This paper also proposes new types of reconstruction loss by measuring higher statistics for better multimodal conditional generation.\n\nPros:\n1.\tThe analysis in Sec 4.4 is insightful, which partially explains the success of MLMM and MCMLE over previous method in generating diverse conditional outputs.\n2.\tThe paper is well written and easy to follow.\n\nCons:\nAnalysis on the experiments is a little insufficient, as shown below.\n\nI have some questions (and suggestions) about experiments. \n1.\tHow does the training process affected by changing the reconstruction loss (e.g., how the training curve changes?)? Do MLMM and MCMLE converge slower or faster than the original ones? What about training stability? \n2.\tWhy only MLMM_1 is not compared with other methods on SRGAN-celebA and GLCIC-A? From pix2pix cases it seems that Gaussian MLMM_1 performs much better than MLMM_{1/2}.\n', ""The paper describes an alternative to L1/L2 errors (wrt output and one ground-truth example) that are used to augment adversarial losses when training conditional GANs. While these augmented losses are often needed to stabilize and guide GAN training, the authors argue that they also bias the optimization of the generator towards mode collapse. To address this, the method proposes two kinds of alternate losses--both of which essentially generate multiple sample outputs from the same input, fit these with a Gaussian distribution by computing the generating sample mean and variance, and try to maximize the likelihood of the true training output under this distribution. The paper provides theoretical and empirical analysis to show that the proposed approach leads to generators that produce samples that are both diverse and high-quality.\n\nI think this is a good paper and solves an important problem---where one usually had to sacrifice diversity to obtain stable training by adding a reconstruction loss. I recommend acceptance.\n\nAn interesting ablation experiment might be to see what happens when one no longer includes the GAN loss and trains only with the MLMM or MCMLE losses, and compare this to training with only the L1/L2 losses. The other thing I'd like the authors to comment on are the potential shortcomings of using a simple un-correlated Gaussian to model the sample distributions. It seems that such a distribution may not capture the fact that multiple dimensions of the output (i.e., multiple pixel intensities) are not independent conditioned on the input. Perhaps, it may be worth exploring whether Gaussians with general co-variance matrices, or independent in some de-correlated space (learned from say simply the set of outputs) may increase the efficacy of these losses.\n\n====Post-rebuttal\n\nI've read the other reviews and retain my positive impression of the paper. I also appreciate that the authors have conducted additional experiments based on my (non-binding) suggestions---and the results are indeed interesting. I am upgrading my score accordingly.""]","[-50, 50, 80]","[50, 75, 70]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The paper is well written, presents a simple idea, complete with experiments'), they also highlight significant weaknesses, particularly the 'lack of novelty of the core idea' and 'weak theoretical results'. The reviewer ultimately does not recommend accepting the paper, which indicates a negative overall sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific feedback. They acknowledge both strengths and weaknesses of the paper without using harsh or dismissive language. However, the review is not overly effusive or complimentary, maintaining a balanced and objective tone."", ""The sentiment score is 50 (slightly positive) because the review starts with listing pros, indicating some positive aspects of the paper. However, it also mentions cons and raises questions, balancing out the sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions and suggestions rather than direct criticisms. The reviewer acknowledges the paper's strengths before moving on to areas for improvement, which is a polite approach. The use of phrases like 'I have some questions (and suggestions)' further contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer explicitly states 'I think this is a good paper and solves an important problem' and recommends acceptance. They also mention upgrading their score after the rebuttal. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive suggestions, and acknowledges the authors' efforts in conducting additional experiments. The tone is professional and supportive, without any harsh criticism. The reviewer provides balanced feedback, offering both praise and suggestions for improvement in a courteous manner.""]"
"['This paper used a complex-valued network to learn the modified complex ratio mask with a weighted SDR loss for the speech enhancement task. It can get good enhancement performance.\n\nFor me, the complex-valued network is already there and weighted SDR loss is not difficult to think. The modified complex ratio mask is a bit interesting. However, I think it better to compare with [Donald S Williamson et al] where the hyperbolic tangent compression is used.\n\nApart from the objective metrics, a human listening test using MOS or preference score should be conducted.\n\nOn Fig 3, the unbounded complex mask might suffer from the infinity problem leading to training failure. However, on table 2, the performance of the unbounded mask is quite close to your method. It is a bit strange for me.\n\nThe total idea is good, but the novelty is not much.\n\n', 'This paper tackles one of important speech enhancement issues of how to predict phase information. The authors work on this problem based on three novel techniques, one is to use complex U-net, second is to propose a new complex mask representation, which is well bounded and well model complex mask distribution, and the last is an objective function motivated by SDR. The paper is well written, and also shows the experimental effectiveness of the proposed method by analyzing these three novel techniques and also by comparing the method with other speech enhancement methods. My major concern about this paper is that this paper is a little bit too specific to the speech enhancement applications, which will not be accepted with so many researches in the major ICLR community. My suggestion is to describe some potential applications of this method to the other (speech) applications including speech separation, noise-robust front-end for ASR, TTS, or other speech analysis, and also discuss the possibility of extending this method for multichannel input. I’m more interested in the multichannel enhancement because the phase (difference) is critical in this scenario. \n\nComments:\n- Introduction: It’s better to cite and discuss the paper of “E. Hakan et al, “Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks,” Proc. ICASSP’15, pp. 708--712 (2015). This paper is one of the first studies tries to incorporate the phase information to DNN based speech enhancement.\n- Several researchers prefer to use LSTM based enhancement method. Please discuss wether this method (objective function and complex masks) can be applied to complex extensions of LSTMs instead of complex U-net.\n- Page 2, the first paragraph: You may also refer https://arxiv.org/abs/1810.01395\n- Page 3, it’s better to explicitly mention that h = x + i y\n- Section 3.3: discuss how we treat STFT/iSTFT operations under a computational graph representation. It is not so obvious.\n- Section 3.3: again it’s better to mention E. Hakan’s method here.\n- Page 6 footnote: I cannot access to the URL. Please check it.\n- Experiments: I think it would be more interesting to add SDR (using speech and noise as a source) to the experimental measure. Some people use SDR as a speech enhancement measure, and I’m expecting that this method can have more reasonable performance since it is optimized based on wSDR.\n', 'The paper is written, provides good description of the state-of-the-art and comprehensive experimental results.\nThe methological contribution is mild, essentially changing a buiding block in a state-of-the-art neural architecture.\nThe paper is for the expert audience mostly and is difficult to grasp without a good background on deep learning for speech enhancement.\n']","[-20, 50, 20]","[50, 80, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good enhancement performance', 'total idea is good'), they also express several criticisms and doubts. The reviewer suggests that parts of the work are not novel or difficult, points out missing comparisons, and questions some results. The overall tone suggests that the paper is decent but not particularly impressive or innovative.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their criticisms ('I think it better to', 'It is a bit strange for me') rather than harsh or dismissive phrasing. The reviewer also acknowledges positive aspects of the work before presenting criticisms, which is a polite approach. However, the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a fairly neutral, matter-of-fact tone overall."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's importance, novelty, and effectiveness, but also expresses concerns about its specificity and suggests improvements. The politeness score is 80 (quite polite) as the reviewer uses respectful language, offers constructive criticism, and provides specific suggestions for improvement. The reviewer's tone is professional and supportive, using phrases like 'My suggestion is...' and 'I'm more interested in...' which maintain a courteous dialogue with the authors."", ""The sentiment score is slightly positive (20) because the review acknowledges that the paper is well-written, provides a good description of the state-of-the-art, and includes comprehensive experimental results. However, it also notes that the methodological contribution is 'mild' and the paper is difficult to understand without expert knowledge, which tempers the positive aspects. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states facts and observations in a direct, professional manner without using overtly courteous or discourteous language.""]"
"['In this paper, authors analyze the performance of neural networks and polynomial kernels in a natural regression setting where the data enjoys sparse latent structure, and the labels depend in a simple way on the latent variables. They give an almost-tight theoretical analysis of the performance and verify them with simulations.\n \nAuthors motivated the theoretical analysis from typical applications, for which the desired function can be only important to be approximated well on the relevant part of domains. Instead of formalizing the above problem, authors tackle a particular simple question. However, it is not easy to understand the relationships between the two problems.\n \nA regression task is studied where the data has a sparser latent structure. Authors measure the performance of estimators via the expected reconstruction error from theoretical perspectives for both two-layer ReLU network and polynomial kernel. Empirical experiments will be even better to show the performance of some applications consistent with the theoretical results.', 'The paper studies the representational power of two-layer ReLU networks and polynomials for approximating a linear generative model for data with sparsity in the latent vector. They show that ReLU networks achieve optimal rate whereas low degree polynomials get a much worse rate.\n\nOverall, the results are strong, the authors provide a lower bound on the degree of polynomial needed to approximate the model indicating the power of non-linearity. The observation of moving away from uniform approximators is well-motivated. The approximation theorem for ReLU is intriguing and uses new ideas which I have not seen before and are potentially useful in other applications. So far, only rational functions have been able to give such approximation guarantees. However, the motivation for studying sparse linear regression from a representation view-point is not very clear. Ideally, you would like to study representation for more complex models. \n\nQuestions/Comments:\n- Related work is missing prior work at the intersection of kernel methods and neural networks, please update.\n- Define notation before using, for example, \\rho_\\tau^{⨂m}\n- Expand proof sketches, they are not very clear, also full proofs are written with not much detail.\n- Is the dependence on \\mu tight? The current dependence sort of suggests that you need the observation matrix to be very close to identity.\n- Proof of Lemma B.1 is unclear, could you explain how you deduce the lemma from the inequality?', 'This paper studies the problem of understanding the representation power of neural nets with Relu activations for representing structured data. In order to formalize this, the authors consider data generated from a sparse generative model as follows: A sparse m-dimensional vector Z is sampled from a distribution over sparse vectors. In input X is formed \nas AZ, where A is an incoherent matrix. The corresponding output is Y= w. X. The goal is to fit the data of the form (X_i, Y_i). The main result of the paper is that a 2-layer ReLU network can fit the data with near optimal error. On the other hand, low degree polynomials~(of degree up to log m) cannot fit the data with non-trivial error. Finally,\nthe authors also show that polynomials of degree polylog(m) can, in fact, fit the data as well as a 2-layer ReLU network. The paper is well written and provides new insights into the representation power of neural nets. It is also nice to know that ReLU networks can be approximated by low degree polynomials in the non-worst case scenario. This\nis a good paper and I recommend acceptance.']","[50, 50, 80]","[75, 75, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' work positively, mentioning their 'almost-tight theoretical analysis' and verification through simulations. However, they also point out some areas for improvement, such as clarifying the relationship between the motivating problem and the actual analysis, and suggesting empirical experiments. This balanced view indicates a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout, avoiding harsh criticism. They offer constructive suggestions for improvement rather than outright criticism, and use phrases like 'it is not easy to understand' instead of more direct negative statements. The tone is academic and objective, maintaining a courteous approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strength of the results, the novelty of the ideas, and the potential usefulness in other applications. However, they also point out some limitations and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their comments as questions or suggestions rather than demands. They acknowledge the paper's strengths before discussing areas for improvement, which is a polite approach. The reviewer also uses phrases like 'please update' and 'could you explain,' which are polite ways of requesting changes or clarifications."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable opinion of the paper, describing it as 'well written,' providing 'new insights,' and explicitly recommending acceptance. The phrase 'This is a good paper' further reinforces the positive sentiment. The politeness score is 70 (polite) due to the respectful and professional tone throughout. The reviewer acknowledges the paper's strengths without using overly effusive language, maintaining a balanced and courteous approach. The use of phrases like 'It is also nice to know' and 'This is a good paper' contribute to the polite tone without being excessively formal or informal.""]"
"['This paper considers the problem of transferring motor skills from multiple experts to a student policy. To this end, the paper proposes two approaches: (1) an approach for policy cloning that learns to mimic the (local) linear feedback behavior of an expert (where the expert takes the form of a neural network), and (2) an approach that learns to compress a large number of experts via a latent space model. The approaches are applied to the problem of one-shot imitation from motion capture data (using the CMU motion capture database). The paper also considers an extension of the proposed approach to the problem of high-level planning; this is done by treating the learned latent space as a new action space and training a high-level policy that operates in this space. \n\nStrengths:\nS1. The supplementary video was clear and helpful in understanding the setup.\nS2. The paper is written in a generally readable fashion.\nS3. The related work section does a thorough job of describing the context of the work.  \n\nHowever, I have some significant concerns with the paper. These are described below. \n\nSignificant concerns:\nC1. My biggest concern is that the paper does not make a strong case for the benefits of LPFC over simpler strategies. The results in Figure 3 demonstrate that a linear feedback policy computed along the expert\'s nominal trajectory performs as well as (and occasionally even better than) LPFC. This is quite concerning.\nC2. Moreover, as the authors themselves admit, ""while LPFC did not work quite as well in the full-scale model as cloning from noisy rollouts, we believe it holds promise insofar as it may be useful in rollout-limited settings..."". However, the paper does not present any theoretical/experimental evidence that would suggest this.\nC3. Another concern has to do with the two-step procedure for LPFC (Section 2.2), where the first step is to learn an expert policy (in the form of a neural network) and the second step is to perform behavior cloning by finding a policy that tries to match the local behavior of the expert (i.e., finding a policy that attempts to produce similar actions as the expert policy linearized about the nominal trajectory). This two-step procedure seems unnecessary; the paper does not make a case for why the expert policies are not chosen as linear feedback controllers (along nominal trajectories) in the first place.\nC4. The linearization of the expert policy produced in (1) may not lead to a stabilizing feedback controller and could easily destabilize the system. It is easy to imagine cases where the expert neural network policy maintains trajectories of the system in a tube around the nominal trajectory, but whose linearization does not lead to a stabilizing feedback controller. Do you see this in practice? If not, is there any intuition for why this doesn\'t occur? If this doesn\'t occur in practice, this would suggest that the expert policies are not highly nonlinear in the neighborhood of states under consideration (in which case, why learn neural network experts in the first place instead of directly learning a linear feedback controller as the expert policy as suggested in C3?)\nC5. I would have liked to have seen more implementation details in Section 3. In particular, how exactly was the linear feedback policy along the expert\'s nominal trajectory computed? Is this the same as (2)? Or did you estimate a linear dynamical model (along the expert\'s nominal trajectory) and then compute an LQR controller? More details on the architecture used for the behavioral cloning baseline would also have been helpful (was this a MLP? How many layers?)\n\nMinor comments:\n- There are some periods missing at the end of equations (eqs. (1), (2), (6), (8), (9)).', 'The paper tackles the problem of distilling large numbers of expert demonstrations into a single policy that can both recreate original demonstrations in a physically-simulated environment and humanoid platform, and to generalize to novel motions. Towards this, the paper presents two approaches learn policies from expert demonstrations without involving costly closed loop RL training, and distilling these individual experts into a shared policy by learning latent time-varying codes.\n\nThe paper is well-written and the method is well-evaluated in the scope that it is proposed. Both components of the proposed approach have previously been explored in the literature - there is extensive work on learning local controllers for physics based evironments from demonstrations in both open loop and closed loop settings as well as work on mixtures of these controllers in machine learning, robotics and computer graphics communities. While the paper proposes these two components as a contribution, I would like to see a more detailed argument of what this work contributes over previous such approaches. \n\nAnother part  where I wish the paper could make a more compelling argument is that distilled policy can perform non-trivial generalization. Target following is a good illustrative example, but has been showcased by multitude of prior work. The paper talks about compositionality, and it would have been compelling to see examples of that if the method can achieve it. For example, simultaneously performing locomotion skills with upper body manipulation skills is something mixture of expert demonstrations approaches still struggle with and it would have been great to see this paper investigate the approach on this problem. \n\nOverall, this is a sound and well-written submission, but the existence of very related prior work with similar capabilities makes me reluctant to recommend this paper.', 'This paper mainly focuses the imitation of expert policy as well as compression of expert skills via a latent variable model. Overall, I feel this paper is not quite readable, albeit that the prosed methods are simple and straightforward. \n\nAs one major contribution of this paper, the authors introduce a first-order approximation to estimate the action of an expert, where perturbations are considered. However, this linear treatment could yield large errors when the residuals in (1) are still large, which is very common in high-dimensional and highly-nonlinear cases. Specifically, the estimation of “J” could be hard. In addition, just below (1), the authors mention (1) yields a “stabilized policy”, so what do you mean “stabilized”?\n\nAnother crucial issue lies on the treatment of “\\Delta(s)”, which is often unknown and hard to modeled, Thus, various optimal controllers are introduced so as to obtain robust controllers. Similarly, in (9) it is also difficult to decide what is “suitable perturbation distribution”.\n\nOverall, the linear treatment in (2) and assumption on “\\Delta(s)” in (5) actually oversimplify the imitation learning problem, which may not be applicable in real robot applications.\n\nOthers small comments:\n-Section 2.1 could be moved to supplementary material or appendix, as this part is indeed not a contribution.\n\n- in (5), it should be “-J_{i}^{*}”\n']","[-50, -20, -60]","[50, 60, -20]","[""The sentiment score is -50 because while the reviewer acknowledges some strengths (S1-S3), they express 'significant concerns' (C1-C5) that outweigh the positives. The concerns are substantial and question core aspects of the paper's methodology and results. However, the score isn't lower because the reviewer does recognize some merits and uses balanced language.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have some significant concerns' and 'I would have liked to have seen' rather than harsh or dismissive language. The reviewer also acknowledges the paper's strengths before diving into criticisms. However, the score isn't higher because the review is primarily focused on critiquing the paper rather than offering excessive praise or overly polite language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and well-evaluated, they express reluctance to recommend it due to the existence of similar prior work. The reviewer points out areas where the paper could make stronger arguments and suggests additional examples that could have made the work more compelling. Despite these criticisms, the overall tone is not harshly negative, hence the moderate negative score. The politeness score is positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. Phrases like 'well-written,' 'well-evaluated,' and 'sound submission' contribute to the polite tone. The reviewer also uses phrases like 'I would like to see' and 'I wish' when suggesting improvements, which maintains a courteous approach to feedback."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper is 'not quite readable' and points out several major issues with the methodology, such as oversimplification and potential inapplicability to real robot applications. The few positive comments (e.g., 'simple and straightforward' methods) are outweighed by the criticisms. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the feedback. Phrases like 'crucial issue' and 'oversimplify' are used without hedging, and there's a lack of positive reinforcement or encouragement. The reviewer does use some polite phrases like 'I feel' and 'could be', which prevents the score from being lower, but overall the tone is more blunt than polite.""]"
"['This is a strong theory paper and I recommend to accept.\n\nPaper Summary:\nThis paper studies the problem of learning a two-layer fully connected neural network where both the output layer and the first layer are unknown. In contrast to previous papers in this line which require the input distribution being standard Gaussian, this paper only requires the input distribution is symmetric. This paper proposes an algorithm which only uses polynomial samples and runs in polynomial time. \nThe algorithm proposed in this paper is based on the method-of-moments framework and several new techniques that are specially designed to exploit this two-layer architecture and the symmetric input assumption.\nThis paper also presents experiments to illustrate the effectiveness of the proposed approach (though in experiments, the algorithm is slightly modified).\n\nNovelty:\n1. This paper extends the key observation by Goel et al. 2018 to higher orders (Lemma 6). I believe this is an important generalization as it is very useful in studying multi-neuron neural networks.\n2. This paper proposes the notation, distinguishing matrix, which is a natural concept to study multi-neuron neural networks in the population level.\n3. The “Pure Neuron Detector” procedure is very interesting, as it reduces the problem of learning a group of weights to a much easier problem, learning a single weight vector. \n\nClarity:\nThis paper is well written.\n\nMajor comments:\nMy major concern is on the requirement of the output dimension. In the main text, this paper assumes the output dimension is the same as the number of neurons and in the appendix, the authors show this condition can be relaxed to the output dimension being larger than the number of neurons. This is a strong assumption, as in practice, the output dimension is usually 1 for many regression problems or the number of classes for classification problems. \nFurthermore, this assumption is actually crucial for the algorithm proposed in this paper. If the output dimension is small, then the “Pure Neuron Detection” step does work. Please clarify if I understand incorrectly. If this is indeed the case, I suggest discussing this strong assumption in the main text and listing the problem of relaxing it as an open problem. \n\n\nMinor comments:\n1. I suggest adding the following papers to the related work section in the final version:\nhttps://arxiv.org/abs/1805.06523\nhttps://arxiv.org/abs/1810.02054\nhttps://arxiv.org/abs/1810.04133\nhttps://arxiv.org/abs/1712.00779\nThese paper are relatively new but very relevant. \n\n2. There are many typos in the references. For example, “relu” should be ReLU.\n\n\n\n\n', 'This paper studies the problem of learning the parameters of a two-layer (or one-hidden layer) ReLU network $y=A\\sigma(Wx)$, under the assumption that the distribution of $x$ is symmetric. The main technique here is the ""pure neuron detector"", which is a high-order moment function of a vector. It can be proved that the pure neuron detector is zero if and only if the vector is equal to the row vector of A^{-1}. Hence, we can ""purify"" the two layer neural network into independent one layer neural networks, and solve the problem easily.\n\nThis paper proposes interesting ideas, supported by mathematical proofs. This paper contains analysis of the algorithm itself, analysis of finding z_i\'s from span(z_i z_i^T), and analysis of the noisy case. \nThis paper is reasonably well-written in the sense that the main technical ideas are easy to follow, but there are several grammatical errors, some of which I list below. I list my major comments below:\n\n1) [strong assumptions] The result critically depends on the fact that $x$ is symmetric around the origin and the requirement that activation function is a ReLU. Lemma 1, 2, 3 and Lemma 6 in the appendix are based on these two assumptions. For example, the algorithm fails if $x$ is symmetric around a number other than zero or there is a bias term (i.e. $y=A \\sigma(Wx+b) + b\'$ ). This strong assumptions significantly weaken the general message of this paper. Add a discussion on how to generalize the idea to more general cases, at least when the bias term is present. \n\n2) [sample efficiency] Tensor decomposition methods tend to suffer in sample efficiency, requiring a large number of samples. In the proposed algorithm (Algorithm 2), estimation of $E[y \\otimes x^{\\otimes 3}]$ and $E[y \\otimes y \\otimes (x \\otimes x)]$ are needed. How is the sample complexity with respect to the dimension? The theory in this paper suggests a poly(d, 1/\\epsilon) sample efficiency, but the exponent of the poly is not known. In Section 4.1, the authors talk about the sample efficiency and claim that the sample efficiency is 5x the number of parameters, but this does not match the result in Figure 2. In the left of Figure 2, when d=10, we need no more than 500 samples to get error of W and A very small, but in the right, when d=32, 10000 samples can not give very small error of W and A. I suspect that the required number of samples to achieve small error scales quadratically in the number of parameters in the neural network. Some theoretical or experimental investigation to identify the exponent of the polynomial on d is in order. Also, perhaps plotting in log-y is better for Figure 2.\n\n3) The idea of ""purifying"" the neurons has a potential to provide new techniques to analyze deeper neural networks. Explain how one might use the ""purification"" idea for deeper neural networks and what the main challenges are. \n\nMinor comments: \n\n""Why can we efficiently learn a neural network even if we assume one exists?"" -> ""The question of whether we can efficiently learn a neural network still remains generally open, even when the data is drawn from a neural network.""\n\n""with simple input distribution"" -> ""with a simple input distribution""\n\n', 'This paper pushes forward our understanding of learning neural networks. The authors show that they can learn a two-layer (one hidden layer) NN, under the assumption that the input distribution is symmetric. The authors convincingly argue that this is not an excessive limitation, particularly in view of the fact that this is intended to be a theoretical contribution. Specifically, the main result of the paper relies on the concept of smoothed analysis. It states that give data generated from a network, the input distribution can be perturbed so that their algorithm then returns an epsilon solution. \n\nThe main machinery of this paper is using a tensor approach (method of moments) that allows them to obtain a system of equations that give them their “neuron detector.” The resulting quadratic equations are linearized through the standard lifting approach (making a single variable in the place of products of variables). \n\nThis is an interesting paper. As with other papers in this area, it is somewhat difficult to imagine that the results would extend to tell us about guarantees on learning a general depth neural network. Nevertheless, the tools and ideas used are of interest, and while already quite difficult and sophisticated, perhaps do not yet seem stretched to their limits. ']","[80, 50, 70]","[70, 70, 50]","[""The sentiment score is 80 because the review starts with a strong positive statement ('This is a strong theory paper and I recommend to accept') and continues to highlight the paper's novelty, clarity, and contributions. The reviewer provides constructive feedback and suggestions, which indicates a generally positive sentiment. The politeness score is 70 because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or areas for clarification. The reviewer uses phrases like 'I suggest' and 'Please clarify if I understand incorrectly,' which demonstrate politeness. The tone is professional and constructive, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'interesting ideas' and 'mathematical proofs', and states that the main technical ideas are easy to follow. However, they also point out several significant limitations and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'I list my major comments below' and 'Add a discussion on...' which are polite ways of providing feedback. The minor grammatical corrections are presented neutrally. The overall tone is professional and courteous, aimed at improving the paper rather than criticizing the authors."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and 'pushes forward our understanding'. They also mention that the authors 'convincingly argue' their points and that the tools and ideas used are 'of interest'. While there are some reservations about the broader applicability of the results, the overall tone is appreciative of the work's contribution. The politeness score is 50 (somewhat polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths without being overly effusive. They offer constructive criticism in a balanced manner, noting limitations without being harsh. The language is professional and objective, maintaining a courteous tone while providing honest feedback.""]"
"['In this paper, the authors proposed a unified framework which computes spectral decompositions by stochastic gradient descent. This allows learning eigenfunctions over high-dimensional spaces and generating to new data without Nystrom approximation. From technical perspective, the paper is good. Nevertheless, I feel the paper is quite weak from the perspective of presentation. There are a couple of aspects the presentation can be improved from. \n\n(1) I feel the authors should formally define what a Spectral inference network is, especially what the network is composed of, what are the nodes, what are the edges, and the semantics of the network and what\'s motivation of this type of network.\n\n(2) In Section 3, the paper derives a sequence of formulas, and many of the relevant results were given without being proven or a reference. Although I know the results are most likely to be correct, it does not hurt to make them rigorous. There are also places in the paper, the claim or statement is inclusive. For example, in the end of Section 2.3, ""if the distribution p(x) is unknown, then constructing an explicitly orthonormal function basis may not be possible"". I feel the authors should avoid this type of handwaving claims.  \n\n(3) The authors may consider summarize all the technical contribution in the paper. \n\nOne specific question:\n\nWhat\'s Omega above formula (6)? Is it the support of x? Is it continuous or discrete? Above formula (8), the authors said ""If omega is a graph"". It is a little bit confusing there. ', 'Spectral Inference Networks, Unifying Deep and Spectral Learning\n\nThis paper presents a framework to learn eigenfunctions via a stochastic process. They are exploited in an unsupervised setting to learn representation of video data. Computing eigenfunctions can be computationally challenging in large-scale context. This paper proposes to tackle this challenge b y approximating then using a two-phase stochastic optimization process. The fundamental motivation is to merge approaches from spectral decomposition via stochastic approximation and learning an implicit representation. This is achievement with a clever use of masked gradients, Cholesky decomposition and explicit orthogonalization of resulting eigenvectors. A bilevel optimization process finds local minima as approximate eigenfunction, mimicking Borkar’97. Results are shown to correctly recover known 2d- schrodinger eigenfunctions and interpretable latent representation a video dataset, with a practical promising results using the arcade learning environment.\n\nPositive\n+ Computation of eigenfunctions on very large settings, without relying on Nystrom approximation\n+ Unifying spectral decomposition within a neural net framework\n\nSpecific comments\n- Accuracy issue - Shape of eigenfunctions are said to be correctly recovered, but no words indicates their accuracy. If eigenfunction values are wrong, this may be critical to the generalization of the method.\n- Clarity could be improved in the neural network implementation, what is exactly done and why, when building the network\n- Algorithm requires computing the jacobian of the covariance, which can be large and computationally expensive - how to scale it to large settings?\n- Fundamentally, a local minimum is reached - any future work on tackling a global solution?  Perhaps by exploring varying learning rates?\n- Practically, eigenfunction have an ambiguity to rotation - how is this enforced and checked during validation? (e.g., rotating eigenfunctions in Fig 1c)\n- Eigenfunction of transition matrix should, if not mistaken, be smooth, whereas Fig 2a shows granularity in the eigenfunctions values (noisy red-blue maps) - Is this regularization issue, and can this be explicitly correctly?\n- Perhaps a word on computational time/complexity?\n', ""In this paper, the authors propose to use a deep learning framework to solve a problem in linear algebra, namely the computation of the largest eigenvectors.\n\nI am not sure tu understand the difference between the framework described in sections 3.1 and 3.2. What makes section 3.2 more general than 3.1?\nIn particular, the graph example in section 3.2 with the graph Laplacian seems to fit in the framework of section 3.1. What is the probability p(x) in this example? Similarly for the Laplace-Beltrami operator what is the p(x)? I do not understand the sentence: 'Since these are purely local operators, we can replace the double expectation over x and x' with a single expectation.'\n\nThe experiments section is clearly not sufficient as no comparison with existing algorithms is provided. The task studied in this paper is a standard task in linear algebra and spectral learning. What is the advantage of the algorithm proposed in this paper compared to existing solutions? The authors provide no theoretical guarantee (like rate of convergence...) and do not compare empirically their algorithm to others.""]","[-20, 60, -50]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'good' from a technical perspective, they also state that it is 'quite weak' in terms of presentation. The review then lists several areas for improvement, indicating an overall critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh criticism. They use phrases like 'I feel' and 'the authors may consider' which soften the critique. The reviewer also acknowledges the likely correctness of the results, showing respect for the authors' work. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is 60 (positive) because the review begins with a neutral summary of the paper's content, followed by explicit positive points ('Positive' section). The reviewer highlights the paper's contributions in computing eigenfunctions on large settings and unifying spectral decomposition within a neural network framework. The specific comments, while critical, are presented as areas for improvement rather than fundamental flaws. The politeness score is 50 (slightly polite) because the reviewer uses neutral language throughout, avoiding harsh criticism. The specific comments are framed as questions or suggestions for improvement, rather than direct criticisms. The reviewer also acknowledges the paper's positive aspects before diving into more critical points, which is a polite approach in academic reviews."", ""The sentiment score is -50 because the reviewer expresses significant concerns and criticisms about the paper, particularly regarding the lack of clarity in certain sections and insufficient experimental comparisons. However, it's not entirely negative as the reviewer acknowledges the authors' proposal and doesn't outright reject the paper. The politeness score is 20 because the reviewer uses relatively neutral language and phrases criticisms as questions or observations rather than direct attacks. The reviewer maintains a professional tone throughout, even when pointing out shortcomings. The use of phrases like 'I am not sure to understand' and 'The experiments section is clearly not sufficient' are direct but not rude, showing a slight lean towards politeness in academic discourse.""]"
"['The paper examines an architectural feature in GAN generators -- self-modulation -- and presents empirical evidence supporting the claim that it helps improve modeling performance. The self-modulation mechanism itself is implemented via FiLM layers applied to all convolutional blocks in the generator and whose scaling and shifting parameters are predicted as a function of the noise vector z. Performance is measured in terms of Fréchet Inception Distance (FID) for models trained with and without self-modulation on a fairly comprehensive range of model architectures (DCGAN-based, ResNet-based), discriminator regularization techniques (gradient penalty, spectral normalization), and datasets (CIFAR10, CelebA-HQ, LSUN-Bedroom, ImageNet). The takeaway is that self-modulation is an architectural feature that helps improve modeling performance by a significant margin in most settings. An ablation study is also performed on the location where self-modulation is applied, showing that it is beneficial across all locations but has more impact towards the later layers of the generator.\n\nI am overall positive about the paper: the proposed idea is simple, but is well-explained and backed by rigorous evaluation. Here are the questions I would like the authors to discuss further:\n\n- The proposed approach is a fairly specific form of self-modulation. In general, I think of self-modulation as a way for the network to interact with itself, which can be a local interaction, like for squeeze-and-excitation blocks. In the case of this paper, the self-interaction allows the noise vector z to interact with various intermediate features across the generation process, which for me appears to be different than allowing intermediate features to interact with themselves. This form of noise injection at various levels of the generator is also close in spirit to what BigGAN employs, except that in the case of BigGAN different parts of the noise vector are used to influence different parts of the generator. Can you clarify how you view the relationship between the approaches mentioned above?\n- It’s interesting to me that the ResNet architecture performs better with self-modulation in all settings, considering that one possible explanation for why self-modulation is helpful is that it allows the “information” contained in the noise vector to better propagate to and influence different parts of the generator. ResNets also have this ability to “propagate” the noise signal more easily, but it appears that having a self-modulation mechanism on top of that is still beneficial. I’m curious to hear the authors’ thoughts in this.\n- Reading Figure 2b, one could be tempted to draw a correlation between the complexity of the dataset and the gains achieved by self-modulation over the baseline (e.g., Bedroom shows less difference between the two approaches than ImageNet). Do the authors agree with that?\n', 'This paper proposes a Self-Modulation framework for the generator network in GANs, where middle layers are directly modulated as a function of the generator input z.\nSpecifically, the method is derived via batch normalization (BN), i.e. the learnable scale and shift parameters in BN are assumed to depend on z, through a small one-hidden layer MLP. This idea is something new, although quite straight-forward.\nExtensive experiments with varying losses, architectures, hyperparameter settings are conducted to show self-modulation improves baseline GAN performance.\n\nThe paper is mainly empirical, although the authors compute two diagnostic statistics to show the effect of the self-modulation method. It is still not clear why self-modulation stabilizes the generator towards small conditioning values.\n\nThe paper presents two loss functions at the beginning of section 3.1 - the non-saturating loss and the hinge loss. It should be pointed out that the D in the hinge loss represents a neural network output without range restriction, while the D in the non-saturating loss represents sigmoid output, limiting to take in [0,1]. It seems that the authors are not aware of this difference.\n\nIn addition to report the median scores, standard deviations should be reported.\n\n===========  comments after reading response ===========\n\nI do not see in the updated paper that this typo (in differentiating D in hinge loss and non-saturating loss) is corrected. \n\nThough fundamental understanding can happen asynchronously, I reserve my concern that such empirical method is not substantial enough to motivate acceptance in ICLR, especially considering that in (only) 124/144 (86%) of the studied settings, the results are improved. And there is no analysis of the failure settings.', 'Summary:\nThe manuscript proposes a modification of generators in GANs which improves performance under two popular metrics for multiple architectures, loss, benchmarks, regularizers, and hyperparameter settings. Using the conditional batch normalization mechanism, the input noise vector is allowed to modulate layers of the generator. As this modulation only depends on the noise vector, this technique does not require additional annotations. In addition to the extensive experimentation on different settings showing performance improvements, the authors also present an ablation study, that shows the impact of the method when applied to different layers.\n\nStrengths:\n- The idea is simple. The experimentation is extensive and results are convincing in that they show a clear improvement in performance using the method in a large majority of settings.\n- I also like the ablation study showing the impact of the method applied at different layers.\n\nRequests for clarification/additional information:\n- I might have missed that, but are the authors offering an interpretation of their observation that the performance of the self-modulation model performs worse in the combination of spectral normalization and the SNDC architecture?\n- The ablation study shows that the impact is highest when modulation is applied to the last layer (if only one layer is modulated). It seems modulation on layer 4 comes in as a close second. I am curious about why that might be.\n- I would like to see some more interpretation on why this method works.\n- Did the authors inspect generated samples of the baseline and the proposed method? Is there a notable qualitative difference?\n\nOverall, the idea is simple, the explanation is clear and experimentation is extensive. I would like to see more commentary on why this method might have long-term impact (or not).']","[80, -30, 70]","[90, 20, 80]","[""The sentiment score is 80 (positive) because the reviewer states they are 'overall positive about the paper' and praises it for being 'well-explained and backed by rigorous evaluation'. The positive tone is consistent throughout, with the reviewer showing interest in the work and asking thoughtful questions for further discussion. The politeness score is 90 (very polite) due to the respectful and constructive nature of the feedback. The reviewer uses phrases like 'I would like the authors to discuss further' and 'I'm curious to hear the authors' thoughts', which demonstrate a collegial and collaborative approach. The questions are framed as invitations for clarification and further discussion rather than criticisms, maintaining a polite and professional tone throughout the review."", ""Sentiment score: The review starts with a neutral description of the paper's content, but then expresses several concerns and criticisms. The reviewer points out that the method is 'not clear', there's a potential misunderstanding by the authors, and expresses reservation about the paper's suitability for acceptance. These negative points outweigh the initial neutral tone, resulting in a slightly negative sentiment score.\n\nPoliteness score: The language used is generally professional and constructive. The reviewer offers specific suggestions for improvement and explains their concerns clearly. However, the tone is not overly polite or deferential, maintaining a neutral to slightly positive level of politeness throughout. The reviewer's direct statement of concerns at the end is honest but not rudely expressed."", ""The sentiment score is 70 (positive) because the reviewer expresses clear approval of the manuscript's strengths, noting the idea is simple, the experimentation is extensive, and the results are convincing. They use positive language like 'I like the ablation study' and describe the explanation as clear. The score is not higher because the reviewer does request additional clarifications and interpretations. The politeness score is 80 (very polite) because the reviewer uses respectful and constructive language throughout. They frame their requests for additional information as questions or curiosities rather than demands, using phrases like 'I might have missed that' and 'I am curious about'. The tone is professional and encouraging, without any harsh criticism or rude remarks.""]"
"['This paper addresses a novel variant of AutoML, to automatically learn and generate optimization schedules for iterative alternate optimization problems. The problem is formulated as a RL problem, and comprehensive experiments on four various applications have demonstrated that the optimization schedule produced can guide the task model to achieve better quality of convergence, more sample-efficient, and the trained controller is transferable between datasets and models. Overall, the writing is quite clear, the problem is interesting and important, and the results are promising. \n\nSome suggestions:\n\n1. What are the key limitations of AutoLoss ? Did we observe some undesirable behavior of the learned optimization schedule, especially when transfer between different datasets or different models ? More discussions on these questions can be very helpful to further understand the proposed method.  \n\n2. As the problem is formulated as an RL problem, which is well-known for its difficulty in training, did we encounter similar issues? More details in the implementation can be very helpful for reproducibility. \n\n3. Any plan for open source ? ', 'The authors proposed an AutoLoss controller that can learn to take actions of updating different parameters and using different loss functions.\n\nPros\n1. Propose a unified framework for different loss objectives and parameters.\n2. An interesting idea in meta learning for learning loss objectives/schedule.\n\nCons: \n1. The formulation uses REINFORCE, which is often known with high variance. Are the results averaged across different runs? Can you show the variance? It is hard to understand the results without discussing it. The sample complexity should be also higher than traditional approaches.\n2. It is hard to understand what the model has learned compared to hand-crafted schedule. Are there any analysis other than the results alone?\n3. Why do you set S=1 in the experiments? What’s the importance of S?\n4. I think it is quite surprising the AutoLoss can resolve mode collapse in GANs. I think more analysis is needed to support this claim. \n5. The evaluation metric of multi-task MT is quite weird. Normally people report BLEU, whereas the authors use PPL. \n6. According to https://github.com/pfnet-research/chainer-gan-lib, I think the bested reported DCGAN results is not 6.16 on CIFAR-10 and people still found other tricks such as spectral-norm is needed to prevent mode-collapse. \n\nMinor: \n1. The usage of footnote 2 is incorrect.\n2. In references, some words should be capitalized properly such as gan->GAN.\n', 'Summary: This paper proposes a meta-learning solution for problems involving optimizing multiple loss values. They use a simple (small mlp), discrete, stochastic controller to control applications of updates among a finite number of different update procedures. This controller is a function of heuristic features derived from the optimization problem, and is optimized using policy gradient either exactly in toy settings or in a online / truncated manor on larger problems. They present results on 4 settings: quadratic regression, MLP classification, GAN, and multi-task MNT. They show promising performance on a number of tasks as well as show the controllers ability to generalize to novel tasks.\n\nThis is an interesting method and tackles a impactful problem. The setup and formulation (using PG to meta-optimize a hyper parameter controller) is not extremely novel (there have been similar work learning hyper parameter controllers), but the structure, the problem domain, and applications are. The experimental results are through, and provide compelling proof that this method works as well as exploration as to why the method works (analyzing output softmax). Additionally the ""transfer to different models"" experiment is compelling.\n\nComments vaguely in order of importance:\n1. I am a little surprised that this training strategy works. In the online setting for larger scale problems, your gradients are highly correlated and highly biased. As far as I can tell, you are performing something akin to truncated back back prop through time with policy gradients. The biased introduced via this truncation has been studied in great depth in [3] and shown to be harmful. As of now, the greedy nature of the algorithm is hidden across a number of sections (not introduced when presenting the main algorithm). Some comment as to this bias -- or even suggesting that it might exist would be useful. As of now, it is implied that the gradient estimator is unbiased.\n\n2. Second, even ignoring this bias, the resulting gradients are heavily correlated. Algorithm 1 shows no sign of performing batched updates on \\phi or anything to remove these corrections. Despite these concerns, your results seem solid. Nevertheless, further understanding as to this would be useful.\n\n3. The structure of the meta-training loop was unclear to me. Algorithm 1 states S=1 for all tasks while the body -- the overhead section -- you suggest multiple trainings are required ( S>1?).\n\n4. If the appendix is correct and learning is done entirely online, I believe the initialization of the meta-parameters would matter greatly -- if the default task performed poorly with a uniform distribution for sampling losses, performance would be horrible. This seems like a limitation of the method if this is the case.\n\n5. Clarity: The first half of this paper was easy to follow and clear. The experimental section had a couple of areas that left me confused. In particular:\n5.1/Figure 1: I think there is an overloaded use of lambda? My understanding as written that lambda is both used in the grid search (table 1) to find the best loss l_1 and then used a second location, as a modification of l_2 and completely separate from the grid search?\n\n6. Validation data / test sets: Throughout this work, it is unclear what / how validation is performed. It seems you performing controller optimization (optimizing phi), on the validation set loss, while also reporting scores on this validation set. This should most likely instead be a 3rd dataset. You have 3 datasets worth of data for the regression task (it is still unclear, however, what is being used for evaluation), but it doesn\'t look like this is addressed in the larger scale experiments at all. Given the low meta-parameter count of the I don\'t think this represents a huge risk, and baselines also suffer from this issue (hyper parameter search on validation set) so I expect results to be similar. \n\n7. Page 4: ""When ever applicable, the final reward $$ is clipped to a given range to avoid exploding or vanishing gradients"". It is unclear to me how this will avoid these. In particular, the ""exploding"" will come from the \\nabla log p term, not from the reward (unless you have reason to believe the rewards will grow exponentially). Additionally, it is unclear how you will have vanishing rewards given the structure of the learned controller. This clipping will also introduce bias, this is not discussed, and will probably lower variance. This is a trade off made in a number of RL papers so it seems reasonable, but not for this reason.\n\n8. ""Beyond fixed schedules, automatically adjusting the training of G and D remains untacked"" -- this is not 100% true. While not a published paper, some early gan work [2] does contains a dynamic schedule but you are correct that this family of methods are not commonplace in modern gan research.\n\n9. Related work: While not exactly the same setting, I think [1] is worth looking at. This is quite similar causing me pause at this comment: ""first framework that tries to learn the optimization schedule in a data-driven way"". Like this work, they also lean a controller over hyper-parameters (in there case learning rate), with RL, using hand designed features.\n\n10. There seem to be a fair number of heuristic choices throughout. Why is IS squared in the reward for GAN training for example? Why is the scaling term required on all rewards? Having some guiding idea or theory for these choices or rational would be appreciated.\n\n11. Why is PPO introduced? In algorithm 1, it is unclear how PPO would fit into this? More details or an alternative algorithm in the appendix would be useful. Why wasn\'t PPO used on all larger scale models? Does the training / performance of the meta-optimizer (policy gradient  vs ppo) matter? I would expect it would. This detail is not discussed in this paper, and some details -- such as the learning rate for the meta-optimizer I was unable to find.\n\n12. ""It is worth noting that all GAN K:1 baselines perform worse than the rest and are skipped in Figure 2, echoing statements (Arjovsky, Gulrajani, Deng) that more updates of G than D might be preferable in GAN training."" I disagree with this statement. The WGAN framework is built upon a loss that can be optimized, and should be optimized, until convergence (the discriminator loss is non-saturating) -- not the reverse (more G steps than D steps) as suggested here. Arjovsky does discuss issues with training D to convergence, but I don\'t believe there is any exploration into multiple G steps per D step as a solution.\n\n13. Reproducibility seems like it would be hard. There are a few parameters (meta-learning rates, meta-optimizers) that I could not find for example and there is a lot of complexity.\n\n14: Claims in paper seem a little bold / overstating. The inception gain is marginal to previous methods, and trains slower than other baselines. This is also true of MNT section -- there, the best baseline model is not even given equal training time! There are highly positive points here, such as requiring less hyperparameter search / model evaluations to find performant models.\n\n15. Figure 4a. Consider reformatting data (maybe histogram of differences? Or scatter plot). Current representation is difficult to read / parse.\n\nTypos:\npage 2, ""objective term. on GANs, the AutoLoss: Capital o is needed.\nPage 3: Parameter Learning heading the period is not bolded.\n\n[1] Learning step size controllers for robust neural network training. Christian Daniel et. al.\n[2]http://torch.ch/blog/2015/11/13/gan.html\n[3] Understanding Short-Horizon Bias in Stochastic Meta-Optimization, Wu et.al.\n\nGiven the positives, and in-spite of the negatives, I would recommend to accept this paper as it discusses an interesting and novel approach when controlling multiple loss values.']","[80, -20, 60]","[70, 50, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'interesting and important' with 'promising' results. They also praise the clear writing and comprehensive experiments. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering suggestions rather than criticisms, and using phrases like 'can be very helpful' to frame their comments. The reviewer maintains a constructive tone, asking questions and suggesting areas for improvement without being harsh or demanding. The use of 'we' in the suggestions also creates a collaborative tone, further contributing to the politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper (unified framework, interesting idea), they list more cons than pros and raise several critical questions about the methodology and results. The tone is not overwhelmingly negative, but the balance of critique outweighs the positive aspects mentioned. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They frame their criticisms as questions or suggestions for improvement rather than harsh statements. The use of 'Pros' and 'Cons' sections helps organize the feedback in a constructive manner. The reviewer also uses phrases like 'It is hard to understand' instead of more accusatory language, maintaining a polite tone while still conveying their concerns."", ""The sentiment score is 60 (positive) because the reviewer starts by calling the paper 'interesting' and tackling an 'impactful problem'. They mention 'promising performance' and 'compelling proof'. Despite listing several concerns, they ultimately recommend accepting the paper. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'further understanding would be useful'), and balances critiques with positive remarks. They avoid harsh language and frame suggestions as opportunities for improvement rather than flaws.""]"
"['The authors propose in this paper an approach for learning models with tractable approximate posterior inference. The paper is well motivated (fast and accurate posterior inference) and the construction of the solutions (invertible architecture, appending vectors to input and output, choice of cost function) well described. From my understanding, it seems this method is also to be compatible with other methods of approximate Bayesian Computation (ABC).\nConcerning the experimental section:\n- The Mixture of Gaussians experiment is a good illustration of how the choice of cost functions influences the solution. However, I do not understand how are the *discrete* output y is handled. Is it indeed a discrete output (problem with lack of differentiability)? Softwax probability? Other modelling choice? \n- The inverse kinematics is an interesting illustration of the potential advantage of this method over conditional VAE and how close it is to ABC which can be reasonably computed for this problem.\n- For the medical application, INN outperforms other methods (except sometimes for ABC, which is far more expensive, or direct predictor, which doesn’t provide uncertainty estimates) over some metrics such as the error on parameters recovery (Table 1), calibration error, and does indeed have a approximate posterior which seems to correspond to the ABC solution better. I’m not sure I understand what we are supposed to learn from the astrophysics experiments.\nThe method proposed and the general problem it aims at tackling seem interesting enough, the toy experiments demonstrates well the advantage of the method. However, the real-world experiments are not necessarily the easiest to read. \nEDIT: the concerns were mostly addressed in the revision. ', 'While the invertible model structure itself is essentially the same as Real-NVP, the use of observation variables in the framework with theoretically sound bidirectional training for safe use of the seemingly naïve inclusion of y (i.e., y and z can be independent). Its abilities to model the posterior distributions of the inputs are supported by both quantitative and qualitative experiments. The demonstration on practical examples is a plus. \n\nThe advantage of INN, however, is not crystal clear to me versus other generative methods such as GAN and VAE. This is an interesting paper overall, so I am looking forward for further discussions.\n\nPros:\n1.\tExtensive analyses of the possibility of modeling posterior distributions with an INN have been shown. Detailed experiment setups are provided in the appendix.\n\n2.\tThe theoretical guarantee (with some assumptions) of the true posterior might be beneficial in practice for relatively low-dimensional or less complex tasks.\n\nComments/Questions:\n1.\tFrom the generative model point of view, could the authors elaborate on the comparison against cGAN (aside from the descriptions in Appendix 2)? It is quoted “cGAN…often lack satisfactory diversity in practice”. Also, can cGAN be used estimate the density of X (posterior or not)?\n\n2.\tFor the bidirectional training, did the ratios of the losses (L_z, L_y, L_x) have to be changed, or the iterations of forward/backward trainings have to be changed (e.g., 1 forward, 1 backward vs. 2 forward, 1 backward)? This question comes from my observation that the nature of the losses, especially for L_y vs. L_y,L_x (i.e., SL vs. USL) seem to be different.\n\n3.\t“we find it advantageous to pad both the in- and output of the network with equal number of zeros”: Is this to effectively increase the intermediate network dimensions? Also, does this imply that for both forward and inverse process those zero-padded entries always come out to be zero? It seems that there needs some way to enforce them to be zero to ensure that the propagation happens only among the entries belonging to the variables of interests (x, y and z).\n\n4.\tIt seems that most of the experiments are done in relatively small dimensional data. This is not necessarily a drawback, I am curious if this model could succeed on higher dimensional data (e.g., image), especially with the observation y.\n', '1) Summary\n\nThe authors propose to use invertible networks to solve ambiguous inverse problems. This is done by training one group of Real-NVP output variables supervised while training the other group via maximum likelihood under a Gaussian prior as done in the standard Real-NVP. Further, the authors suggest to not only train the forward model, but also the inverse model with an MMD critic, similar to previous works that used a more flexible GAN critic [1].\n\n2) Clarity\n\nThe paper is easy to understand and the main idea is well-motivated. \n\n3) Significance\n\nThe main contribution of this work is of conceptual nature and illustrates how invertible networks are a promising framework for many inverse problems. I really like the main idea and think it is inspiring. However, the experiments and technical contributions are rather limited. \n\nTheoretical / ML contribution: \n\nUsing an MMD to factorize groups of latent variables is well-known and combining flow-based maximum likelihood training in the forward model with GAN-like objectives in the inverse model has been done before as well.\n\nExperimental contribution: \n\nI am not fully convinced by the experiments. \nThe inverse kinematics experiment shows that the posterior collapses from large uncertainty to almost a point for the right-most joint. This seems like a negative result to me. \nThe medical experiment also seems rather limited, because if I understand correctly the tissue data is artificial and the proposed INN only outperforms competitors (despite ABC) on two out of three measurements. Further, the authors should have explained the experimental setup of the tissue experiment better, as it is not a standard task in the field. \nIn the astronomy experiment figure 4 shows strong correlations between some of the z variables, the authors claim that this is a feature of their method, but I argue that they should not be present if training with the factorial prior was successful. It would be good to show the correlation between y and z variables as well if they show high dependencies, learning was not very successful. Simply eyeballing the shape of the posterior is not enough to conclude independence. \n\nIn summary, even though interesting, the significance of the experimental results is hard to judge and I am a bit worried that if the proposed model is making some strange mistakes on artificial toy-data, how well it will perform on challenging realistic problems. \n\n4) Main Concerns\n\nThe authors claim that specifying a prior/posterior distribution in density modeling is complicated and typically the chosen distributions are too simplistic. This argument is, of course, valid, but they also have the same problem and specify z to be factorial Gaussian. So the same ""hen-and-egg"" problem applies here.\n\nThe authors also seem to suggest that they are the first to train flow-based models in forward and inverse direction, but this has already been done in the flow-GAN paper [1].\n\nMMD does not easily scale to high-dimensional problems, this is not a problem here as all artificial problems considered are very low-dimensional. But when applying the proposed algorithm in realistic settings, one will likely need extensions of MMD, like used in MMD GANs, which would introduce min/max games on both sides of the network. This will likely be hard to train and constitutes a fundamental limitation of the approach that needs to be discussed.\n\n5) Minor Concerns\n\n- Some basic citations on normalizing flows seem to be missing, e.g. [2,3].\n- How does one guarantee that padded regions are actually zero on output when padding input with zeros? Small variance in those dimensions could potentially code important information. Is this considered as part of y or z?\n- The authors require the existence of inverse and set this equal to bijectivity, but injectivity would be sufficient.\n- The authors mention that z is conditioned on y, but in their notation, the conditional density p(z|y) never shows up explicitly. It should be made clear, that p(z)=p(z|y) is a consequence of their additional MMD penalty and only holds at convergence.\n\n[1] Grover et al., ""Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models""\n[2] Tabak and Turner, ""Density estimation by dual ascent of the log-likelihood""\n[3] Deco and Brauer, ""Nonlinear higher-order statistical decorrelation by volume-conserving neural architectures""']","[60, 60, -20]","[70, 80, 50]","[""The sentiment score is 60 (positive) because the reviewer generally expresses approval of the paper, describing it as 'well motivated' and 'well described'. They also mention that the method and problem seem 'interesting enough'. However, it's not overwhelmingly positive as they express some confusion about certain aspects and suggest the real-world experiments could be clearer. The final edit indicates that most concerns were addressed in revision, further supporting a positive sentiment.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and ask questions for clarification rather than making harsh judgments. Phrases like 'From my understanding' and 'I'm not sure I understand' show a humble approach to giving feedback. The reviewer also acknowledges the strengths of the paper alongside areas for improvement, which is a polite way to provide feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, calling it 'interesting' and looking forward to further discussions. They highlight several pros and acknowledge the paper's contributions. However, they also raise some questions and express that the advantage of the proposed method is not entirely clear, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions, and maintains a constructive tone. They use phrases like 'could the authors elaborate' and 'I am curious' which are polite ways of requesting more information. The review is structured professionally with clear pros and comments sections, further contributing to its politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting concept and clear presentation, they express significant concerns about the experimental results and limitations of the approach. The reviewer states that 'the experiments and technical contributions are rather limited' and expresses worry about how well the model would perform on realistic problems. However, the score is not deeply negative as the reviewer does see value in the main idea.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I really like the main idea' and 'The paper is easy to understand', showing appreciation for the authors' work. Even when expressing concerns, the language remains constructive and not personally critical. The reviewer offers specific suggestions for improvement, which is a polite way to provide feedback.""]"
"['RNNs are difficult to explain, understand and analyze due to the continuous-valued memory vectors and observations features they use. Thus, this paper attempts to extract finite representation from RNNs so as to better interpret or understand RNNs. They introduce a new technique called Quantized Bottleneck Insertion to extract Moore Machines (MM). The extracted MM can be analyzed to improve the understanding of memory use and general behavior on the policies. The experiments on synthetic datasets and six Atari games validate the effectiveness of the proposal.\n\nHere are my detailed comments:\nInterpreting or understanding RNNs is a very interesting and important topic since RNNs and their variants like LSTM, GRU are widely used in different domains such as reinforcement learning, sentiment analysis, stock market prediction, natural language processing, etc. The more understandable on RNNs, the more trustful on them. In this paper, the authors try to extract more interpretable representation of RNNs, namely Moore Machines (MM). MM is actually a classical finite state automaton. The authors mention that (Zeng et al., 1993) is the most similar work to theirs. In fact a series of works have been proposed to extract finite state automaton, which is similar to (Zeng et al., 1993) such as [1], [2], [3], etc. I think the authors could make the related works more complete by incorporating these literatures I mentioned.\n \nBesides, I think this work is a good application of the idea of extraction of RNNs on reinforcement learning since no works have introduced this idea into this domain as far as I know. The authors use the autoencoder named as QBN to quantize the space of hidden states. This is a good operation of clustering or quantizing the space of hidden states since it can be tuned to make the final performance better. The authors also incorporate the minimization of MM to show the probability of shrinking memory which can also make the extracted MM more interpretable. As a result, the policy represented by MM is intuitive and vivid.\n \nNevertheless, there is an obvious weak point in this paper. Specifically, the authors claim that the main contribution of this paper is to introduce an approach for transforming RNNs to finite state representations. But I do not see any comparisons between the proposed methods and other relative methods such as the method proposed by (Zeng et al., 1993) to show the effectiveness or improvement of the proposed method. I suggest the authors could incorporate comparisons to make the results more convincing.\n \n[1] C. W. Omlin and C. L. Giles, ""Extraction of rules from discrete-time recurrent neural networks,"" Neural Networks, vol. 9, no. 1, pp. 41–52, 1996.\n[2] C. W. Omlin and C. L. Giles, ""Constructing deterministic finite-state automata in recurrent neural networks,"" Journal of the ACM, vol. 43, no. 6, pp. 937-972, 1996.\n[3] A. Cleeremans, D. Servan-Schreiber, and J. L. McClelland. ""Finite state automata and simple recurrent networks."" Neural computation, vol. 1, no. 3, pp. 372-381, 1989.', 'This paper proposes a method to learn a quantization of both observations and hidden states in an RNN. Its findings suggest that many problems can be reduced to relatively simple Moore Machines, even for complex environments such as Atari games.\n\nThe method works by pretraing an RNN to learn a policy (e.g. through the A3C algorithm), and then training pairs of encoder/decoder networks with a quantizing forward pass and a straight-through backpropagation. The learned quantizations can then be used to build a Moore Machine, which itself can be reduced with FSM reduction algorithms, yielding a discrete, symbolic approximation of the inner workings of RNNs, that could in principle be interpreted more easily than latent embedding spaces.\n\nOne downside of this paper is that it promises an exciting method to analyse the inner workings of RNNs, but then postpones this analysis to later work. Understandably, the synthetic experiments take some space and shows that the proposed method works as expected when the problem is amenable to discretization; maybe some parts of this could be in the appendix?\n\nAnother downside is that there is little indication of the computational implications of the method. The method was evaluated on a fairly small set of hyperparameters, and there are no indication of how long the optimization and finetuning takes. Presumably, minimizing a Moore Machine has been studied for decades, but how long does minimizing the 1000s of states in Atari games take? A second or an hour?\n\nThe paper is fairly well written and easy to understand. The method seems well grounded, although I\'m not familiar enough with the quantization literature to detect if something important is missing. I think this is a great tool that hopefully will be used to try to understand the memory mechanisms of RNNs. \n\nI think the proposed method (and the fact that it works in simple cases) warrants acceptance, but I think more experimental work would make this a great contribution. Since there is no reason for quantization to improve performance if it is done after training, then more emphasis should be put on the interpretability of the discretization; yet it is lacking in the current work. Some Atari games are known to require various amounts of memory, this could be analysed. Some other Atari games are known to be hard to solve, what happens to the RNN when the agent fails to achieve an optimal policy might also show up in the subsequent discretization and be interesting to analyse.\n\nComments:\n- In atari, you can have access to the RAM and from it, using exactly the same mechanisms and maybe a bit of tabular MDPs, you should be able to recover the optimal MM.\n- It is good that the authors report their failure to train MMNs from scratch; IMO this says something about the straight through estimators\' limits. Measuring how sensible these things are to change in their target distribution and comparing to previous uses of ST in quantization works could be interesting.\n- in Section 8 (appendix) ""Grammer"" should be ""Grammar""\n- All the (PO)MDPs that you analyse arguably have finite state spaces, and you set the ALE to be deterministic. What happens in continuous stochastic environments? \n- Do you think a similar technique could be used to recover a (possibly stochastic) MDP instead of a Moore Machine? It would be interesting to see MDP reduction methods applied to a learned MDP.\n\n', 'Approximation of RNNs is a hot and important topic in term of interpretability and control of nets. The related work section is good but in my opinion miss to give a position with respect to the work dedicated to extract rules from a net which are also way to ""interpret"" a RNNs - as an example https://arxiv.org/abs/1702.02540 from ICLR\'17. \n\npros:\n- important practical topic\n- The papers includes a variety of ideas/tricks which seems to bring performance as the 3 stage procedure and the gradient backpropagation over quantization. \n- Makes ""interpretable"" observations of some no so easy to understand nets on Atari games\n- Reach state of the art performance on artificial set of task \n\ncons:\n- The impact of each step is not always assessed by an experiment (especially ones introduced in section 4.1)\n- The method is never benchmarked against an other one. Neither in terms of performance of the approximation nor in terms of interpretability (thought other techniques are cited in the paper). I understand that this is because this pursue the two goals at the same time but I\'d be interested this tradeoff to be more investigated. \n- Performance on Atari games is usually reported in term of % wrt human performance which helps understanding where we stand. It would be good also to discuss the performance of the RNN on the game wrt other nets. As an example in this paper on space invaders the performance of the RNN is slightly better human but very far from state of the art yielded by prioritized duelling which is almost 10x higher in terms of score. While on breakout they are very good (see https://arxiv.org/pdf/1806.06923.pdf to have a recent list of score on Atari).\n- I\'d been interested in having an artificial task where to proposed algorithm does not succeed (an ideally some discussion on what make the structure recoverable or not).  \n  ']","[60, 60, 50]","[80, 80, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses interest in the topic, acknowledges the importance of the work, and praises several aspects of the paper, such as its application to reinforcement learning and the use of QBN. However, they also point out a 'weak point' and suggest improvements, which prevents the score from being higher. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides suggestions for improvement in a courteous manner. They use phrases like 'I think' and 'I suggest' which maintain a polite tone. The reviewer also acknowledges the positive aspects of the work before presenting criticisms, which is a polite approach to peer review."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, stating it 'warrants acceptance' and calling it a 'great tool'. They mention some downsides but also highlight the paper's strengths and potential. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and offering constructive criticism. They use phrases like 'fairly well written', 'great contribution', and provide specific suggestions for improvement without harsh criticism. The reviewer also acknowledges their own potential limitations ('I'm not familiar enough with the quantization literature'). The tone is professional and supportive throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the importance of the topic and lists several pros, indicating a generally positive view. However, they also provide a list of cons and areas for improvement, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or areas of interest (e.g., 'I'd be interested...', 'It would be good...'). They also acknowledge the paper's strengths before discussing its weaknesses. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out limitations.""]"
"['This paper proposes a method for functional regularization for training neural nets, such that the sequence of neural nets during training is stable in function space. Specifically, the authors define a L2 norm (i.e., a Hilbert norm), which can be used to measure distances in this space between two functions. The authors argue that this can aid in preventing catastrophic forgetting, which is demonstrated in a synthetic multi-task variant of MNIST.   The authors also show how to regularize the gradient updates to be conservative in function space in standard stochastic gradient style learning, but with rather inconclusive empirical results.  The authors also draw upon a connection to the natural gradient.\n\n\n***Clarity***\n\nThe paper is reasonably well written.  I think the logical flow could be improved at places.   I think the major issue with clarity is the title.  The authors use the term ""regularizing"" in a fairly narrow sense, in particular regularizing the training trajectory to be stable in function space.  However, the more dominant usage for regularizing is to regularize the final learned function to some prior, which is not studied or even really discussed in the paper.\n\nDetailed comments:\n\n-- The notation in Section 2 could be cleaned up.  The use of \\mu is a bit disconnected from the rest of the notation.  \n\n-- Computing the empirical L2 distance accurately can also be NP hard.  There\'s no stated guarantee of how large N needs to be to have a good empirical estimate.  Figure 3 is nice, but I think a more thorough discussion on this point could be useful.\n\n-- L2-Space was never formally defined.  \n\n-- Section 2.1 isn\'t explained clearly.  For instance, in the last paragraph, the first sentence states ""the networks are initialized at very different point"", and halfway into the paragraph a sentence states ""all three initializations begin at approximately the same point in function space."".  The upshot is that Figure 1 doesn\'t crisply capture the intuition the authors aim to convey.\n\n\n***Originality***\n\nStrictly speaking, the proposed formulation is novel as far as I am aware.  However, the basic idea has been the air for a while.  For instance, there are some related work in RL/IL on functional regularization:\n-- https://arxiv.org/abs/1606.00968\n\nThe proposed formulation is, in some sense, the obvious thing to try (which is a good thing).  The detailed connection to the natural gradient is nice.  I do wish that the authors made stronger use of properties of a Hilbert space, as the usage of Hilbert spaces is fairly superficial.  For instance, one can apply operators in a Hilbert space, or utilize an inner product.  It just feels like there was a lost opportunity to really explore the implications.\n\n\n***Significance***\n\nThis is the place where the contributions of this paper are most questionable.  While the multi-task MNIST experiments are nice in demonstrating resilience against catastrophic forgetting, the experiments are pretty synthetic.  What about a more ""real"" multi-task learning problem?\n\nMore broadly, it feels like this paper is suffering from a bit of an identity crisis.  It uses regularizing in a narrow sense to generate conservative updates.  It argues that this can help in catastrophic forgetting.  It also shows how to employ this to construct the standard bounded-update gradient descent rules, although without much rigorous discussion for the implications.  There are some nice empirical results on a synthetic multi-task learning task, and inconclusive results otherwise.  There\'s a nice little discussion on the connection to the natural gradient.  It argues that that this form of regularization lives in a Hilbert space, but the usage of a Hilbert space is fairly superficial.  All in all, there are some nice pieces of work here and there, but it\'s all together neither here or there in terms of an overall contribution.    \n\n\n***Overall Quality***\n\nI think if the authors really pushed one of the angles to a more meaningful contribution, this paper would\'ve been much stronger.  As it stands, the paper just feels too scattered in its focus, without a truly compelling result, either theoretically or empirically.', ""Summary:\nThis paper proposes first to measure distances, in a L2 space, between functions computed by neural networks. It then compares those distances with the parameter l2 distances of those networks, and empirically shows that the l2 parameter distance is a poor proxy for distances in the function space. Following those observations, the authors propose to use such constraint to combat catastrophic forgetting, and show some results on the permuted MNIST task. Finally, they propose the Hillber-constrained gradient descent (HCGD), a gradient descent algorithm that constraint movement in the function space, and evaluate it on a CNN (CIFAR10) and an LSTM (permuted MNIST).\n\nClarity:\nThe paper is well motivated, clearly written and easy to follow.\n\nNovelty:\nThe idea of trying to move in the function space rather than in the parameter space is definitely not new (see the whole literature about Natural Gradient for instance). However, the proposed HCGD seems quite new, but unfortunately it doesn’t seem to perform well.\n\nPros and Cons:\n+ The paper is well motivated, not only through the text but also with empirical evidence (section 2).\n+ The paper focuses on an important research direction in deep learning.\n+ This paper proposes a novel algorithm that penalizes movement in the function space.\n- However, it is not clear if the proposed algorithm actually penalizes the distance in function space, since it is performing a crude approximation of the distance measure (using one step of gradient).\n- Better way of penalizing movement in the function space already exists (at least for probability distributions: Natural Gradient)\n\nDetailed Comments:\n1. Batch Normalization and Weight Decay:\nI have mixed feelings about your experiments in section 2. Both Batch Normalization (BN) and Weight Decay (WD) have a regularization effect on the weights.  I am wondering if the change in ratio L2/l2 during the course of training is simply caused by the regularization terms getting stronger and stronger (compared to the cross-entropy loss). Also, BN makes the function computed by the network independent of the scale (of each row) of the weight matrices. I do think that running again those experiments without BN and WD would make the argument that “the parameter space is a proxy for function space” more robust. \n2. About HCGD:\nThe origins of the HCGD algorithm is extremely similar to the origins of Natural Gradient (NG) (just switch the L2 norm with the KL). The main difference resides in how the proximal formulation (equation 2) is approximated. For NG, one approximate the KL using a 2nd order Taylor expansion and then the proximal formulation is explicitly solved for Delta theta, where HCGD takes only a simple gradient step. It is thus not clear how well this step is  indeed a good approximation of the distance in function space. For CNNs and LSTMs, K-FAC [1-2], which is a Natural Gradient approximation, has been shown to outperform ADAM, so the proposed approximation might not be good enough, as HCGD doesn't beat ADAM in the experimental setup. One experiment that would be nice to have is to do one update of the parameter in a neural network (using HCGD) and then measure how much you actually moved in the function space. \n[1] Roger Grosse, James Martens, A Kronecker-factored Approximate Fisher Matrix for Convolution Layers, ICML 2016\n[2] James Martens, Jimmy Ba, Matt Johnson,Kronecker-factored Curvature Approximations for Recurrent Neural Networks, ICLR 2018\n\nMinor Comments:\nSection 2.3: “one would require require” -> “one would require”\nFigure 3: “that a set batch size” -> “that a fixed batch size”\nSection 3.1.1: “permuted different on” -> “permuted differently on”\nSection 3.2.1: “that minimizes equation 6” -> “that minimizes equation 5”\n\nConclusion:\nThe paper proposes nice empirical evidence than parameter distance is not a good proxy for function distance. However, it is not clear if the proposed algorithm actually fixes this problem."", 'Although, I liked the exploratory part of the paper I must admit that I found myself confused a few times. The results given in the paper suggest that the proposed HCGD does not demonstrate any advantages on CIFAR-10 and has a limited impact on seq. MNIST. I think that section 3.3 of the paper should be extended and demonstrate some more convincing results.    \nOverall, I am not certain about my assessment. Therefore, I set my confidence level to ""2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"". \n\nUpdate on 17 Nov:\n\nSection 2. \nI am not sure that the results shown in Figure 2 tell more answers than they pose new questions. \nFor instance, ""In particular, the parameter distance between successive epochs is negatively correlated with the L^2 distance for most of optimization (Fig. 2b). The distance from initialization shows a clean and positive relationship, but the relationship changes during optimization""  \nWould it be possible to have a supplementary figure with weight decay switched-off? I am not sure why you need it at all since the purpose is not to get state-of-the-art results. Could it also explain the angle for L^2/l^2 shown in the third column since weight decay is something that affects l^2? \nI am not sure that the discussion of the negative correlation is sufficient. The actual correlation is linked to the stage of convergence, it would be nice to have a figure showing its average value per epoch (you say it is negative for the most part of optimization) and some discussion on its impact for the remaining part of your paper. \n\nSection 3.\nI am not an expert in online learning, this is probably why I don\'t recognize the novelty of the proposed approach. Is it novel to train networks for new tasks while making the objective function accounting for the old tasks? It sounds like a definition of online learning of multiple tasks. Importantly, here it is done while keeping training data from the old tasks. I understand your arguments about storage, but I find it surprising that your proposed change to the objective function is novel. If it is the case, please emphasize it more and mention that despite its simplicity, this idea is very novel. Otherwise, please cite relevant papers where similar methods were used. \n\nI am not sure it is optimal to put Algorithm 1 in experimental results and applications. I don\'t see it as an application of your observations. I can imagine that the algorithm was inspired by your observations but it is your primary contribution and if possible should be discussed in a separate section. Here, you present it and then discuss how it is related to the natural gradient. \nPlease consider an alternative presentation where you first discuss the natural gradient and its various related works and algorithms, then present your algorithm and then demonstrate your empirical observations. This presentation might contradict the timeline of the development of your approach but it might help to better connect your work to other works  on the same topic. Also, it might help to better show novelties of your approach/observations. \n\nPlease comment if you find some interesting connection with [1].\n\n[1] ""Regularizing neural networks by penalizing confident output distributions"" https://arxiv.org/pdf/1701.06548.pdf\n\nUpdate on Nov 30:\nI updated my score to 6 and my confidence level to 3.  \n']","[-30, 20, -20]","[50, 80, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'reasonably well written', 'nice pieces of work here and there'), the overall tone is critical and points out several significant weaknesses. The reviewer questions the paper's significance, clarity, and overall contribution, describing it as 'scattered in its focus, without a truly compelling result'. However, the score is not extremely negative as the reviewer does recognize some merits and novel aspects of the work. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and specific suggestions for improvement. The language used is not overly harsh or personal, but rather focuses on the content of the paper. The reviewer also balances criticism with acknowledgment of positive aspects, which contributes to the polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some strengths of the paper ('well motivated', 'clearly written', 'focuses on an important research direction'), they also point out significant limitations and areas for improvement. The overall tone suggests cautious approval with reservations. The politeness score is high (80) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'I have mixed feelings' and 'It is not clear' rather than harsh criticisms, and offer specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is slightly negative (-20) because the reviewer expresses confusion and uncertainty about parts of the paper, and suggests that more convincing results are needed. However, they do mention liking the exploratory part, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, asks questions politely, and offers constructive suggestions. They avoid harsh criticism and use phrases like 'I am not sure' and 'please consider' which contribute to a polite tone. The reviewer also acknowledges their own potential lack of understanding in some areas, which adds to the politeness.""]"
"['This paper tests a number of untrained sentence representation models - based on random embedding projections, randomly-initialized LSTMs, and echo state networks - and compares the outputs of these models against influential trained sentence encoders (SkipThought, InferSent) on transfer and probing tasks. The paper finds that using the trained encoders yields only marginal improvement over the fully untrained models.\n\nI think this is a strong paper, with a valuable contribution. The paper sheds important light on weaknesses of current methods of sentence encoding, as well as weaknesses of the standard evaluations used for sentence representation models - specifically, on currently-available metrics, most of the performance achievements observed in sentence encoders can apparently be accomplished without any encoder training at all, casting doubt on the capacity of these encoders - or existing downstream tasks - to tap into meaningful information about language. The paper establishes stronger and more appropriate baselines for sentence encoders, which I believe will be valuable for assessment of sentence representation models moving forward. \n\nThe paper is clearly written and well-organized, and to my knowledge the contribution is novel. I appreciate the care that has been taken to implement fair and well-controlled comparisons between models. Overall, I am happy with this paper, and I would like to see it accepted. \n\nAdditional comments:\n\n-A useful addition to the reported results would be confidence intervals of some kind, to get a sense of the extent to which the small improvements for the trained encoders are statistically significant.\n\n-I wonder about how the embedding projection method would compare to simply training higher-dimensional word embeddings from the start. Do we expect substantial differences between these two options?', 'This paper proposes that randomly encoding a sentence using a set of pretrained word embeddings is almost as good as using a trained encoder with the same embeddings. This is shown through a variety of tasks where certain tasks perform well with a random encoder and certain ones don\'t.\n\nThe paper is well written and easy to understand and the experiments show interesting findings. There is a good analysis on how the size of the random encoder affects performance which is well motivated by Cover\'s theorem.\n\nHowever, the random encoders that are tested in the paper are relatively limited to random projections of the embeddings, a randomly initialized LSTM and an echo state network. Other comparisons would make the results significantly more interesting and would move away from the big assumption stated in the first sentence, i.e. that sentence embeddings are: ""learned non-linear recurrent combinations"". Some major models that are missed by this include paragraph vectors (which do not require any initial training if initialized with pretrained word embeddings), CNNs and Transformers. Given this, the takeaways from this paper seem quite limited to recurrent representations and it\'s unclear how it would generalize to other representations.\n\nAn additional problem is that the paper states that ST-LN used different and older word embeddings which may make the comparison flawed when compared with the random encoders. In this case, the only fairly trained sentence encoder that is compared with is InferSent. The RandLSTM also has an issue in that the biases are intialized around zero whereas it\'s well known that using an initially higher forget gate bias significantly improves the performance of the LSTM.\n\nFinally, the analysis of the results seems weak. The tasks are very different from each other and no reason or potential explanation is given why certain tasks are better than others with random encoders, except for SOMO and CoordInv. E.g. Could some tasks be solved by looking at keywords or bigrams? Do some tasks intrinsically require longer term dependencies? Do some tasks have more data?\n\nOther comments:\n- The results and especially random encoder results should be shown with confidence intervals.\n- Section 3.1.3 the text refers to W^r but that does not appear in any equations.\n\n=== After rebuttal ===\nThanks for adding the additional experiments (particularly with fully random embeddings) and result analyses to the paper. I feel that this makes the paper stronger and have raised my score accordingly.', 'This paper is about exploring better baselines for sentence-vector representations through randomly initialized/untrained networks. I applaud the overall message of this paper that we need to evaluate our models more thoroughly and have better baselines. The experimentation is quite thorough and I like that you\n1) explored several different architectures\n2) varied the dimensionality of representations\n3) examine representations with probing tasks in the Analysis section. \n\nMain Critique\n- In your takeaways you say that, “For some of the benchmark datasets, differences between random and trained encoders are so small that it would probably be best not to use those tasks anymore.” I don’t think this follows from your results. Just because current trained encoders do not perform better than random encoders on these tasks doesn’t in itself mean these tasks aren’t good evaluation tasks. These tasks could be faulty for other reasons, but just because we have no better technique than random encoders currently, doesn’t make these evaluation tasks not worthwhile. Perhaps you could further examine what features (n-gram, etc.) it takes to do well on these tasks in order to argue that they shouldn’t be used.\n- In your related work section you say that “We show that a lot of information may be crammed into vectors using randomly parameterized combinations of pre-trained word embeddings: that is, most of the power in modern NLP systems is derived from having high-quality word embeddings, rather than from having better encoders.” Did you run experiments with randomly initialized embeddings? This paper (https://openreview.net/forum?id=ryeNPi0qKX) finds that representations from LSTMs with randomly initialized embeddings can perform quite well on some transfer tasks. I think in order to make such a claim about the power of high-quality word embeddings you should include numbers comparing them to randomly initialized embeddings.\n\nQuestions\n- Did you find that your results were sensitive to the initialization technique used for your random LSTMs / projections?\n- Do you have a sense of why random non-linear features are able to perform well on these tasks? What kind of features are the skip-thought and InferSent representations learning if they do not perform much better? It’s interesting that many of the random encoder methods outperform the trained models on word content. I think you could discuss these Analysis section findings more.\n\nOther Critiques\n- In the introduction, instead of simply describing what is commonly done to obtain and evaluate sentence embeddings, it would be better to include a sentence or two about the motivation for sentence embeddings at all.\n- The first sentence, “Sentence embeddings are learned non-linear recurrent combinations of pre-trained word embeddings”, doesn’t seem to be true as BOE representations are also sentence embeddings and CNNs/transformers could also work. “Non-linear” and “recurrent” are not inherent requirements for sentence embeddings, but just techniques that researchers commonly use.\n- In the second paragraph of introduction instead saying “Natural language processing does not yet have a clear grasp on the relationship between word and sentence embeddings…” it might be better to say “NLP researchers” or the “NLP community” instead of “NLP” as a field doesn’t have a clear grasp.\n- In the introduction: “It is unclear how much sentence-encoding architectures improve over the raw word embeddings, and what aspect of such architectures is responsible for any improvement.” It would be also good to mention that it’s unclear how much the training task / procedure also is affects improvements.\n- You could describe more about applications of reservoir computing in your related work section as it’s been used in NLP before.\n- I don’t think you actually ever describe the type of data that InferSent is trained on, only that it is “expensive” annotated data. It might be useful to add a sentence about natural language inference for clarity.\n- In the conclusion, change “performance improvements are less than 1 and less than 2 points on average over the 10 SentEval tasks, respectively” to  “performance improvements are less than 2 percentage points on average over the 10 SentEval tasks, respectively”\n- It would be nice if you bolded/underlined the best performing numbers in your results tables.\n']","[90, 50, 60]","[80, 80, 80]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment, calling it a 'strong paper, with a valuable contribution' and stating they are 'happy with this paper' and would like to see it accepted. They praise multiple aspects including the clarity, organization, novelty, and careful implementation. The only slight reduction from 100 is due to the minor suggestions at the end. The politeness score is 80 because the language is consistently respectful and appreciative, using phrases like 'I appreciate' and 'I think'. The reviewer offers constructive suggestions politely. The score is not 100 as the tone is professional rather than overtly deferential."", ""Sentiment score (50): The review starts with positive comments about the paper being well-written and showing interesting findings. However, it also points out several limitations and areas for improvement, balancing the positive with constructive criticism. This mix of praise and critique suggests a moderately positive sentiment.\n\nPoliteness score (80): The reviewer uses polite and professional language throughout. They acknowledge the paper's strengths before presenting criticisms, and phrase their suggestions as recommendations rather than demands. The tone is respectful and constructive, even when pointing out flaws. Phrases like 'The paper is well written' and 'Thanks for adding the additional experiments' contribute to the polite tone. The reviewer avoids harsh or dismissive language, maintaining a courteous approach throughout."", ""The sentiment score is 60 (positive) because the reviewer begins by applauding the overall message of the paper and praising the thorough experimentation. They use positive language like 'I like that you...' and provide constructive feedback. However, they also present several critiques and questions, which prevents the score from being higher. The politeness score is 80 (very polite) due to the reviewer's respectful tone throughout. They use phrases like 'I applaud...', 'I like that...', and frame critiques as suggestions or questions rather than direct criticisms. The reviewer maintains a professional and courteous tone while providing detailed feedback, demonstrating a high level of politeness in academic discourse.""]"
"['This paper introduced a proximal approach to optimize neural networks by linearizing the network output instead of the loss function. They demonstrate their algorithm on multi-class hinge loss, where they can show that optimal step size can be computed in close form without significant additional cost. Their experimental results showed competitive performance to SGD/Adam on the same network architectures. \n\n1. Figure 1 is crucial to the algorithm design as it aims to prove that Loss-Preserving Linearization (LPL) preserves information on loss function. While the authors provided numerical plots to compare it with the SGD linearization, I personally prefer to see some analytically comparsion between SGD linearization and LPL even on the simplest case. An appendix with more numerical comparisons on other loss functions might also be insightful. \n2. It seems LPL is mainly compared to SGD for convergence (e.g. Fig 2). In Table 2 I saw some optimizers end up with much lower test accuracy. Can the authors show the convergence plots of these methods (similar to Figure 2)?', 'This paper proposes a Frank-Wolfe based method, called DFW, for training Deep Network. The DFW method linearizes the loss function into a smooth one, and also adopts Nesterov Momentum to accelerate the training. Both techniques have been widely used in the literature for similar settings. This paper mainly focuses on the algorithm part, but only empirically demonstrate the convergence results. \n\nAfter reading the authors’ feedback and the paper again, I think overall this is a good paper and should be of broader interest to the broader audience in machine learning community. \n\nIn Section 6.1, the authors mention the good generalization is due to large number of steps at a high learning rate. Can we possibly get any theoretical justification on this? \n\nThis paper uses multi class hinge loss as an example for illustration. Can this approach be applied for structure prediction, for example, various ranking loss? ', 'Dual Block-Coordinate Frank-Wolfe (Dual-BCFW) has been widely used in the literature of non-smooth and strongly-convex stochastic optimization problems, such as (structural) Support Vector Machine. To my knowledge, the submission is the first sound attempt to adapt this type of Dual-based algorithm for optimization of Deep Neural Network, which employs a proximal-point method that linearizes not the whole loss function but only the DNN (up to the logits) to form a convex subproblem and then deal with the loss part in the dual.\n\nThe attempt is not perfect (actually with a couple of issues detailed below), but the proposed approach is inspiring and I personally would love it published to encourage more development along this thread.  The following points out a couple of items that could probably help further improve the paper.\n\n*FW vs BCFW*\n\nThe algorithm employed in the paper is actually not Frank-Wolfe (FW) but Block-Coordinate Frank-Wolfe (BCFW), as it minimizes w.r.t. a block of dual variables belonging to the min-batch of samples.\n\n*Batch Size*\n\nThough the algorithm can be easily extended to the min-batch case, the author should discuss more how the batch size is interpreted in this case (i.e. minimizing w.r.t. a larger block of dual variables belonging to the batch of samples) and the algorithmic block (Algorithm 1) should be presented in a way reflecting the batch size since this is the way people use an algorithm in practice (to improve the utilization rate of a GPU).\n\n*Convex-Conjugate Loss*\n\nThe Dual FW algorithm does not need to be used along with the hinge loss (SVM loss). All convex loss function can derive a dual formulation based on its convex-conjugate. See [1,2] for examples. It would be more insightful to compare SGD vs dual-BCFW when both of them are optimizing the same loss functions (either hinge loss or cross-entropy loss) in the experimental comparison.\n\n[1] Shalev-Shwartz, Shai, and Tong Zhang. ""Stochastic dual coordinate ascent methods for regularized loss minimization."" JMLR (2013)\n[2] Tomioka, Ryota, Taiji Suzuki, and Masashi Sugiyama. ""Super-linear convergence of dual augmented Lagrangian algorithm for sparsity regularized estimation."" JMLR (2011).\n\n*BCFW vs BCD*\n\nActually, (Lacoste-Julien, S. et al., 2013) proposes Dual-BCFW to optimize structural SVM because the problem contains exponentially many number of dual variables. For typical multiclass hinge loss problem the Dual Block-Coordinate Descent that minimizes w.r.t. all dual variables of a sample in a closed-form update converges faster without extra computational cost. See the details in, for example, [3, appendix for the multiclass hinge loss case].\n\n[3] Fan, Rong-En, et al. ""LIBLINEAR: A library for large linear classification."" JMLR (2008).\n\n*Hyper-Parameter*\n\nThe proposed dual-BCFW still contains a hyperparameter (eta) due to the need to introduce a convex subproblem, which makes its number of hyperparameters still the same to SGD. ']","[60, 60, 60]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer begins by summarizing the paper's contributions in a neutral to positive tone, highlighting the novel approach and competitive performance. There are no overtly negative comments, only constructive suggestions for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, framing their suggestions as personal preferences ('I personally prefer') and requests ('Can the authors show...') rather than demands. The reviewer also acknowledges the authors' work positively before offering suggestions. The language is professional and courteous, avoiding any harsh criticism or commanding tone."", ""The sentiment score is 60 (positive) because the reviewer states 'overall this is a good paper and should be of broader interest to the broader audience in machine learning community.' This indicates a generally positive view, though not overwhelmingly enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, asks questions rather than making demands ('Can we possibly get...?', 'Can this approach be applied...?'), and acknowledges the authors' feedback. The reviewer also provides constructive suggestions without harsh criticism. The language is professional and courteous throughout, maintaining a respectful tone while still offering valuable feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses enthusiasm for the paper's novel approach, stating 'the proposed approach is inspiring' and that they 'would love it published'. However, they also mention 'a couple of issues', indicating it's not entirely positive. The politeness score is 80 (quite polite) due to the constructive tone throughout. The reviewer uses phrases like 'could probably help further improve the paper' and offers specific suggestions without harsh criticism. They acknowledge the paper's value while providing detailed, respectful feedback for improvement.""]"
"['The authors introduce a class of quasi-hyperbolic algorithms that mix SGD with SGDM (or similar with Adam) and show improved empirical results. They also prove theoretical convergence of the methods and motivate the design well. The paper is well-written and contained the necessary references. Although I did feel that the authors could have better compared their method against the recent AggMom (Aggregated Momentum: Stability Through Passive Damping by Lucas et al.). Seems like there are a few similarities there. \n\nI enjoyed reading this paper and endorse it for acceptance. The theoretical results presented and easy to follow and state the assumptions clearly. I appreciated the fact that the authors aimed to keep the paper self-contained in its theory. The numerical experiments are thorough and fair. The authors test  the algorithms on an extremely wide set of problems ranging from image recognition (including CIFAR and ImageNet), natural language processing (including the state-of-the-art machine translation model), and reinforcement learning (including MuJoCo). I have not seen such a wide comparison in any paper proposing training algorithms before. Further, the numerical experiments are well-designed and also fair. The hyperparameters are chosen carefully, and both training and validation errors are presented. I also appreciate that the authors made the code available during the reviewing phase. Out of curiosity, I ran the code on some of my workflows and found that there was some improvement in performance as well. \n\n\n', 'Update after the author response: I am changing my rating from 6 to 7. The authors did a good job at clarifying where the gain might be coming from, and even though I maintain that decoupling the two variables is a simple modification, it leads to some valuable insights and good results which would of interest to the larger research community.\n\n-------\nIn this paper the authors propose simple modifications to SGD and Adam, called QH-variants, that can not only recover the “parent” method but a host of other optimization tricks that are widely used in the applied deep learning community. Furthermore, the resulting method achieves better performance on a suit of different tasks making it an appealing choice over the competing methods. \n\nTraining a DNN can be tricky and substantial efforts have been made to improve on the popular SGD baseline with the goal of making training faster or reaching a better minima of the loss surface. The paper introduces a very simple modification to existing algorithms with surprisingly promising results. For example, on the face of it, QHM which is the modification of SGD, is exactly like momentum except we replace \\beta in eq. 1 to \\nu*\\beta. Without any analysis, I am not sure how such a change leads to dramatic difference in performance like the first subfigure in Fig. 2. The authors say that the performance of SGD was similar to that of momentum, but performance of momentum with \\beta = 0.7*0.999 should be the same as that of QHM. So where is the gain coming from? What am I missing here? Outside of that, the results are impressive and the simplicity of the method quite appealing. The authors put in substantial efforts to run a large number of experiments and providing a lot of extra material in the appendix for those looking to dive into all the details which is appreciated. \n\n\nIn summary, there are a few results that I don’t quite follow, but the rest of the paper is well organized and the method shows promise in practice. My only concern is the incremental nature of the method, which is only partly offset by the good presentation. ', 'Edit: Following response, I have updated my score from 6 to 7.\n\nI completed this review as an emergency reviewer - meaning that I had little time to complete the review. I did not have time to cover all of the material in the lengthy appendix but hope that I explored the parts most relevant to my comments below.\n\nPaper summary: The paper introduces QHM, a simple variant of classical momentum which takes a weighted average of the momentum and gradient update. The authors comprehensively analyze the relationships between QHM and other momentum based optimization schemes. The authors present an empirical evaluation of QHM and QHAdam showing comparable performance with existing approaches.\n\nDetailed comments:\n\nI\'ll use CM to denote classical momentum, referred to as ""momentum"" in the paper.\n\n\n1) In the introduction, you reference gradient variance reduction as a motivation for QHM. But in Section 3 you defer readers to the appendix for the motivation of QHM. I think that the main paper should include a brief explanation of this motivation.\n\n2) The proposed QHM looks quite similar to a special case of Aggregated Momentum [1]. It seems that the key difference is with the use of damping but I suspect that this can be largely eliminated by using different learning rates for each velocity (as in Section 4 of [1]) and/or adopting damping in AggMo. In fact, Section 4.1 in your paper recovers Nesterov momentum in a very similar way. More generally, could one think of AggMo as a generalization of QHM? It averages plain SGD and several momentum steps on different time scales.\n\n3) I thought that some of the surprising relations to other momentum based optimizers was the most interesting part of the paper. However, I found the presentation a little difficult. There are many algorithms presented but none are explored fully in the main paper. I had to flick between the main paper and appendix to uncover the information I wanted most from the paper.\n\nMoreover, I found some of the arguments in the appendix a little tough to follow. For example, with AccSGD you should specify that epsilon is a constant typically chosen to be 0.7.  When the correspondence to QHM is presented it is not obvious that QHM -> AccSGD but not the other way around. I would suggest that you present a few algorithms in greater detail, and list the other algorithms you explore at the end of Section 4 with pointers to the appendix.\n\n4) I am not sure that the QHAdam algorithm adds much to the paper. It is not explored theoretically and I found the empirical analysis fairly limited.\n\n5) In general, the empirical results support QHM as an improvement on SGD/NAG. But I have some (fairly minor) concerns.\n\n   a) For Figure 1, it looks like QHM beats QHAdam on MLP-EMNIST. Why not show these on the same plot? This goes back to my point 4 - it does not look like QHAdam improves on QHM and so I am not sure why it is included. The idea of averaging gradients and momentum is general - why explore QHAdam in particular?\n\n   b) For Figure 2, while I certainly appreciate the inclusion of error bars, they suggest that the performance of all methods are very similar. In Table 3, QH and the baselines are often not just within a standard deviation of eachother but also have very close means (relatively).\n\n6) I feel that some of the claims made in the paper are a little strong. E.g. ""our algorithms lead to significantly improved training in a variety of settings"". I felt that the evidence for this was lacking.\n\n\nOverall, I felt that the paper offered many interesting results but clarity could be improved. I have some questions about the empirical results but felt that the overall story was strong. I hope that the issues I presented above can be easily addressed by the authors.\n\n\nMinor comments:\n\n- I thought the use of bold text in the introduction was unnecessary\n- Some summary of the less common tasks in Table 2 should be given in the main paper\n\n\nClarity: I found the paper quite difficult to follow in places and found myself bouncing around the appendix frequently. While the writing is good I think that some light restructuring would improve the flow.\n\nSignificance: The paper presents a simple tweak to classical momentum but takes care to identify its relation to existing algorithms. The empirical results are not overwhelming but at least show QHM as competitive with CM on tasks and architecture where SGD is typically dominant.\n\nOriginality: To my knowledge, the paper presents original findings and places itself well amongst existing work.\n\n\nReferences:\n\n[1] Lucas et al. ""Aggregated Momentum: Stability Through Passive Damping"" https://arxiv.org/pdf/1804.00325.pdf']","[90, 60, 50]","[80, 70, 80]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They 'enjoyed reading this paper', 'endorse it for acceptance', and praise various aspects like the theoretical results, numerical experiments, and code availability. The only minor criticism is about comparing with a specific method, but this doesn't significantly impact the overall positive tone. The politeness score is 80 because the reviewer uses respectful and appreciative language throughout, such as 'I appreciated', 'I enjoyed', and 'The authors test'. They offer constructive feedback politely and acknowledge the authors' efforts. The tone is professional and courteous without being overly formal or excessively flattering."", ""The sentiment score is 60 (positive) because the reviewer changed their rating from 6 to 7, indicating an overall positive view of the paper. They praise the authors' clarifications, the valuable insights, and good results. The reviewer acknowledges the impressive results and the simplicity of the method. However, there are some concerns about understanding certain results and the incremental nature of the method, which prevents a higher score. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and the paper's strengths. They express their concerns and questions in a constructive manner, using phrases like 'What am I missing here?' instead of being critical. The reviewer also appreciates the extra material provided in the appendix, which shows respect for the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges interesting aspects of the paper and its overall strong story, while also pointing out areas for improvement. The review is not overwhelmingly positive, but it's more positive than negative. The politeness score is 80 because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I would suggest', 'I hope that'). The reviewer also acknowledges their own limitations (e.g., 'I did not have time to cover all of the material') and provides a balanced view, which contributes to the polite tone.""]"
"['This paper proposes to parameterize the weight matrices of neural nets using the SVD, with approximate orthogonality enforced on the singular vectors using Orthogonal Regularization (as opposed to e.g. the Cayley transform or optimizing on the Stiefel manifold), allowing for direct, efficient control over the spectra. The method is applied to GAN discriminators to stabilize training as a natural extension of Spectral Normalization. This method incurs a slight memory and compute cost and achieves a minor performance improvement over Spectral Normalization on two benchmark image generation tasks.\n\nI\'m a bit back and forth on this paper. On the one hand, I think the ideas this paper proposes are very interesting and could provide a strong basis off which future work can be built--the extension of spectral normalization to further study and manipulation of the spectra is natural and very promising. However, the results obtained are not particularly strong, and as they stand do not, in my opinion, justify the increased compute and memory cost of the proposed methods. The paper\'s presentation also wavers between being strong (there were some sections I read and immediately understood) and impenetrable (there were other sections which I had to read 5-10 times just to try and grip what was going on).\n\nUltimately, my vote is for acceptance. I think that we should not throw out a work with interesting and potentially useful ideas just because it does not set a new SOTA, especially when the current trend with GANs seems to suggest that top performance comes at a compute cost that all but a few groups do not have access to. With another editing pass to improve language and presentation this would be a strong, relevant paper worthy of the attention of the ICLR community.\n\nMy notes:\n\n-The key idea of parameterizing matrices as the SVD by construction, but using a regularizer to properly constrain U and V (instead of the expensive Cayley transform, or trying to pin the matrices to the Stifel manifold) is very intriguing, and I think there is a lot of potential here.\n\n-This paper suffers from a high degree of mathiness, substituting dense notation in places where verbal explanation would be more appropriate. There are several spots where explaining the intuition behind a given idea (particularly when proposing the various spectrum regularizers) would be far more effective than the huge amount of notation. In the author\'s defense, the notation is generally used as effectively as it could be. My issue is that it often is just insufficient, and communication would be better served with more illustrative figures and/or language.\n\n-I found the way the paper references Figure 1 confusing. The decays are substantially different for each layer--are these *all* supposed to be examples of slow decay? Layer 6 appears to have 90% of its singular values below 0.5, while layer 0 has more than 50%. If this is slow decay, what does an undesirable fast decay look like? Isn\'t the fast decay as shown in figure 2 almost exactly what we see for Layer 6 in figure 1? What is the significance of the sharp drop that occurs after some set number of singular values? The figure itself is easy to understand, but the way the authors repeatedly refer to it as an example of smooth singular decays is confusing.\n\n-what is D-optimal design? This is not something commonly known in the ML literature. The authors should explain what exactly that D-optimal regularizer does, and elucidate its backward dynamics (in an appendix if space does not permit it in the main body). Does it encourage all singular values to have similar values? Does it push them all towards 1? I found the brief explanation (""encourages a slow singular value decay"") to be too brief--consider adding  a plot of the D-optimal spectrum to Figure 1, so that the reader can easily see how it would compare to the observed spectra. Ideally, the authors would show an example of the target spectra for each of the proposed regularizers in Figure 1. This might also help elucidate what the authors consider a desirable singular value decay, and mollify some of the issues I take with the way the paper references figure 1.\n\n-The explanation of the Divergence Regularizer is similarly confusing and suffers from mathiness, a fact which I believe is further exacerbated by its somewhat odd motivation. Why, if the end result is a reference curve toward which the spectra will be regularized, do the authors propose (1) a random variable which is a transformation of a gaussian (2) to take the PDF of that random variable (3) discretize the PDF  (4) take the KL between a uniform discrete distribution and the discretized PMF and (5) ignore the normalization term? If the authors were actually working with random variables and proposing a divergence this might make sense, but the items under consideration are singular values which are non-stochastic parameters of a model, so treating them this way seems very odd. Based on figure 2 it looks like the resulting reference curves are fine, but the explanation of how to arrive there is quite convoluted--I would honestly have been more satisfied if the authors had simply designed a function (a polynomial logarithmic function perhaps) with a hyperparameter or two to control the curvature.\n\n-""Our experimental results show that both combinations achieve an impressive results on CIFAR10 and STL-10 datasets""\nPlease do not use subjective adjectives like ""impressive."" A 6.5% improvement is okay, but not very impressive, and when you use subjective language you run the risk of readers and reviewers subjectively disagreeing with you, as is the case with this reviewer. Please also fix the typo in this sentence, it should at least be ""...achieve [impressive] results"" or ""achieve an [impressive] improvement on..."" \n\nSection 3:\n-What is generalization supposed to mean in this context? It\'s unclear to me why this is at all relevant--is this supposed to be indicating the bounds for which the Discriminator will correctly distinguish real vs generated images? Or is there some other definition of generalization which is relevant? Does it actually matter for what we care about (training implicit generative models)? \n\n-What exactly is the use of this generalization bound? What does it tell us? What are the actual situations in which it holds? Is it possible that it will ever be relevant to training GANs or to developing new methods for training GANs?\n\nExperiments:\n-I appreciate that results are taken over 10 different random seeds.\n\n-If the choice of gamma is unimportant then why is it different for one experiment? I found footnote 4 confusing and contradictory.  \n\n-For figure 3, I do not think that the margin is ""significant""--it constitutes a relative 6.5% improvement, which I do not believe really justifies the increased complexity and compute cost of the method.\n\n-I appreciate Table 1 and Figure 4 for elucidating (a) how orthogonal the U and V matrices end up and (b) the observed decay of the spectra.\n\nAppendix:\n-Please change table 7 to be more readable, with captions underneath each figure rather than listed at the top and forcing readers to count the rows and match them to the caption. What is the difference between SN-GAN and Spectral Norm in this table? Or is that a typo, and it should be spectral-constraint?\n\n-I Would like to see a discussion of table 7 / interpretation of why the spectra look that way (and why they evolve that way over training) for each regularizer.  \n\nMinor:\n-Typos and grammatical mistakes throughout.\n-As per the CIFAR-10/100 website (https://www.cs.toronto.edu/~kriz/cifar.html) the Torralba citation is not the proper one for the CIFAR datasets, despite several recent papers which have used it.\n-Intro, last paragraph, ""Generation bound"" should be generalization bound?\n-Page 4, paragraph 2, last sentence, problem is misspelled.', 'The paper builds on the experimental observations made in Miyato et al. (2018) in which the authors highlight the utility of spectral normalization of weight matrices in the discriminator of a GAN to improve the stability of the training process. The paper proposes to reparameterize the weight matrices by something that looks like the singular value decomposition, i.e. W = U E V^T. Four different techniques to control the spectrum of W by imposing various constraints on E have been discussed. For maintaining the orthonormality of U and V penalties are added to the cost function. The paper also derives a bound on the generalization error and experimentally shows the ""desirable slow decay""  of singular values in weight matrices of the discriminator. Other experiments which compare the proposed approach with the SN-GAN have also been given.\n \n(1)The paper puts a lot of stress on the stability of the training process in the beginning but clear experiments supporting their claim related to improved ""stability"" are lacking. \n(2)It would be helpful for the readers if more clarity is added to the paper with respect to the desirability of ""slow decay of singular values"" and spectral normalization.\n(3)The point regarding convolutional layers should be part of the main paper.\n\n ', ""The paper is a natural extension of [1] which shows the importance of spectral normalization to encourage diversity of the discriminator weights in a GAN. A simple and effective parametrization of the weights similar to SVD is used: W = USV^T is used along with an orthonormal penalty on U and V and spectral penalty to control the decay of the spectrum. Unlike other parametrizations of orthogonal matrices which are exact but computationally expensive, the proposed one tends to be very accurate in practice and much faster.  A generalization bound is provided that shows the benefit of controlling the spectral norm. Experimental results show that the method is accurate in constraining the orthonormality of U and V and in controlling the spectrum. The experiments also show a marginal improvement of the proposed method over SN-GAN [1].\nHowever, the following it is unclear why one would want to control the whole spectrum when theorem 2 only involves the spectral norm. In [1], it is argued that this encourages diversity in the weights which seems intuitive. However, it seems enough to use Spectral Normalization to achieve such purpose empirically according to that same paper. It would be perhaps good to have an example where SN fails to control the spectrum in a way that significantly impacts the performance of the algorithm while the proposed method doesn't.\n\nOverall the paper is clearly written and the proposed algorithm effectively controls the spectrum as shown experimentally, however,  given that the idea is rather simple, it is important to show its significance with examples that clearly emphasize the importance of controlling the whole spectrum versus the spectral norm only.\n\n\nRevision: Figure 1 is convincing and hints to why SN-GAN acheives slow decay while in principle it only tries to control the spectral norm. I think this paper is a good contribution as it provides a simple and efficient algorithm to precisely control the spectrum. Moreover, a recent work ([2], theorem 1 ) provides theoretical evidence for the importance of controling the whole spectrum which makes this contribution even more relevant.\n\n\n[1] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida. Spectral Normalization for Generative Adversarial Networks. Feb. 2018.\n[2] M. Arbel, D. J. Sutherland, M. Bin ́kowski, and A. Gretton. On gradient regularizers for MMD GANs. NIPS 2018\n\n""]","[20, 50, 60]","[60, 75, 70]","[""The sentiment score is slightly positive (20) because while the reviewer expresses some reservations about the paper's results and presentation, they ultimately recommend acceptance and see potential in the ideas presented. The reviewer acknowledges interesting concepts and potential for future work, despite noting that the results are not particularly strong. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They offer specific, detailed feedback and suggestions for improvement without using harsh language. The reviewer balances criticism with positive remarks and shows consideration for the authors' efforts, even when pointing out areas that need work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and experimental work, but also points out areas for improvement. The review begins with a neutral summary of the paper's content, followed by constructive criticism. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering suggestions for improvement rather than harsh criticism. Phrases like 'It would be helpful for the readers' indicate a considerate tone. The reviewer also provides specific, actionable feedback without using negative or confrontational language."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper, describing it as a 'natural extension' and 'clearly written'. They note that the proposed algorithm is 'simple and effective' and 'accurate in practice'. The reviewer does raise some questions and suggests improvements, but overall the tone is supportive, especially after the revision where they state it's a 'good contribution'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively suggesting improvements. They use phrases like 'it would be perhaps good to' and 'it is important to show' which are polite ways of offering criticism. The reviewer also takes care to provide context and references, showing respect for the authors' work and the broader field.""]"
"['The big-little module is an extension of the multi-scale module. Different scales takes different complexities: higher complexity for low-scale, and lower complexity for high scale. Two schemes of merging two branches are also discussed, and the linear combination is empirically better. \n\nAs expected, the results are better than ResNets, ResNexts, SEResNexts. I do not have  comments except ablation study is needed to show the results for more choices of alpha, beta, e.g., alpha =1, beta =1.', ""The authors propose a new CNN architecture and show results on object and speech recognition. In particular, they propose a multi-scale CNN module that processes feature maps at various scales. They show compelling results on IN and a reduction of compute complexity\n\nPros:\n(+) The paper is well written\n(+) The method is elegant and reproducible\n(+) Results are compelling and experimentation is thorough\nCons:\n(-) Transfer to other visual tasks, beyond IN, is missing\n(-) Memory requirements are not mentioned, besides FLOPs, speed and parameters\n\nOverall, the proposed approach is elegant and clear. The impact of the multi-scale module is evident, in terms of FLOPs and performance. While their approach performs a little worse than NASNet, both in terms of FLOP efficiency and top1-error, it is simpler and easier to train. I'd like for the authors to also discuss memory requirements for training and testing the network. \n\nFinally, various papers have appeared over the recent years showing improvements over baselines on ImageNet. However, most of these papers are not impactful, because they do not show any impact to other visual tasks, such as detection. On the contrary, methods that do transfer get adopted very fast. I would be much more convinced of this approach, if the authors showed similar performance gains (both in terms of complexity and metrics) for COCO detection. \n"", 'This paper presents a novel multi-scale architecture that achieves a better trade-off speed/accuracy than most of the previous models. The main idea is to decompose a convolution block into multiple resolutions and trade computation for resolution, i.e. low computation for high resolution representations and higher computation for low resolution representations. In this way the low resolution can focus on having more layers and channels, but coarsely, while the high resolution can keep all the image details, but with a smaller representation. The branches (normally two) are merged at the end of each block with linear combination at high resolution. Results for image classification on ImageNet with different network architectures and for speech recognition on Switchboard show the accuracy and speed of the proposed model.\n\nPros:\n- The idea makes sense and it seems GPU friendly in the sense that the FLOPs reduction can be easily converted in a real speed-up\n- Results show that the joint use of two resolution can provide better accuracy and lower computational cost, which is normally quite difficult to obtain\n- The paper is well written and experiments are well presented.\n- The appendix shows many interesting additional experiments\n\nCons:\n- The improvement in performance and speed is not exceptional, but steady on all models.\n- Alpha and beta seem to be two hyper-parameters that need to be tuned for each layer.\n\nOverall evaluation:\nGlobally the paper seems well presented, with an interesting idea and many thorough experiments that show the validity of the approach. In my opinion this paper deserves to be published.\n\n\nAdditional comments:\n- - In the introduction (top of pag. 2) and in the contributions, the advantages of this approach are explained in a different manner that can be confusing. More precisely in the introduction the authors say that bL-Net yeald 2x computational saving with better accuracy. In the contributions they say that the savings in computation can be up to 1/2 with no loss in accuracy.  \n']","[60, 60, 80]","[20, 70, 70]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the effectiveness of the proposed method, stating that 'the results are better than ResNets, ResNexts, SEResNexts.' The reviewer also provides a brief summary of the work without criticism. However, it's not extremely positive as they do suggest an additional ablation study. The politeness score is 20 (slightly polite) because the language is professional and neutral, without any harsh criticism. The reviewer uses phrases like 'As expected' and 'I do not have comments except,' which maintain a respectful tone. However, the review doesn't go out of its way to be overtly polite or complimentary, hence the moderate score."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, highlighting several pros such as good writing, elegant method, and compelling results. They use phrases like 'compelling results' and 'elegant and clear'. However, it's not a perfect score due to some cons mentioned and suggestions for improvement. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They balance praise with constructive criticism, using phrases like 'I'd like for the authors to' instead of more demanding language. The reviewer also acknowledges the paper's strengths before suggesting improvements, which is a polite approach to feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They highlight several pros, state that the paper 'deserves to be published', and use positive language like 'interesting idea' and 'well presented'. The few cons mentioned are relatively minor. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout. They offer constructive feedback and balance positive comments with areas for improvement. The tone is objective and courteous, avoiding harsh criticism. The reviewer's language is more formal and less effusive than extremely polite reviews, hence the score of 70 rather than higher.""]"
"['I like the simplicity of the approach in this paper (especially compared to very computationally hungry methods such as Deepmind\'s ""Graph Networks as Learnable Physics Engines for Inference and Control""). The fact that the approach allows for online learning is also interesting. I very much appreciate that you tested your approach on a real robot arm!\n\nI have a number of questions, which I believe could help strengthen this paper:\n- The decomposition of H into L^TL ensures H is positive definite, however there are no constraints on g (gravity/external forces). How do you ensure the model doesn\'t degenerate into only using g and ignoring H? In the current formulation g only depends on q, however this seems insufficient to model velocity dependent external forces (e.g. contact dynamics). Please elaborate.\n- How would you handle partial observability of states? Have you tried this? \n- How would you extend this approach to soft robots or robots for which the dimensionality of the state space is unknown?\n- Have you tested your method on systems that are not kinematic chains? How would complex contact dynamics be handled (e.g. legged robots)?\n- It would be interesting to see more comparisons with recent work (e.g. Deepmind\'s).\n\nSome figures (e.g. Figure 6) are missing units on the axes. Please fix.', 'This paper looks at system identification for a multi-link robot based upon combining a neural network with the manipulator equations.  Specifically, the authors propose to model the robot dynamics using the typical manipulator equations, but have a deep neural network parameterize the H(q) and g(q) matrices.  They illustrate that the method can control the systems of a simualted 2-dof robot and real Barrett WAM arm, better than a pure neural network modeling approach, PID control, or an analytic model.\n\nOverall, I think there is a genuinely nice application in this paper, but it\'s not sufficiently compared to existing approaches nor put in the proper context.  There is a lot of language in the paper about encoding the prior via a PDE, but really what the authors are doing is quite simple: they are doing system identification under the standard robot manipulator equations but using a deep network to model the inertia tensor H(q) and the gravity term g(q).  Learning the parameters that make up H(q) and g(q) is completely standard system identification in robotics, but it\'s interesting to encode these as a generic deep network (I\'m somewhat surprised this hasn\'t been done before, though a quick search didn\'t turn up any obvious candidates).  However, given this setting, there are several major issues with the presentation and evaluation, which make the paper unsuitable in its current from.\n\n1) Given the fact that the authors are really just in the domain of system identification and control, there are _many_ approaches that they should compare to.  At the very least, however, the authors should compare to standard system identification techniques (see e.g., Wu et al., ""An overview of dynamic parameter identification of robots"", 2010, and references therein).  This is especially important on the real robot case, where the authors correctly mention that the WAM arm cannot be expressed exactly by the manipulator equations; this makes it all the more important to try identify system parameters via a data-driven approach, not with the hope of finding the exactly ""correct"" manipulator equations, but with finding some that are good enough to outperform the ""analytical"" model that the authors mention.  It\'s initially non-obvious to me that a generic neural network to model the H and g terms would do any better than some of these standard approaches.\n\n2) A lot of the derivations in the text are frankly unnecessary.  Any standard automatic differentiation toolkit will be able to compute all the necessary derivatives, and for a paper such as this the authors can simply specify the architecture of the system (that they use a Cholesky factorization representation of H, with diagonals required to be strictly positive) and let everything else be handled by TensorFlow, or PyTorch, etc.  The derivations in Sections 4.2 and 4.3 aren\'t needed.\n\n3) The authors keep referring to the Lagrangian equations as a PDE, and while this is true in general for the actual form here it\'s just a second order ODE; see e.g. https://en.wikipedia.org/wiki/Lagrangian_mechanics.  Moreover, these are really just the standard manipulator equations for multi-link systems, and can just be denoted as such.\n\nDespite these drawbacks, I really do like the overall idea of the approach presented here, it\'s just that the authors would need to _substantially_ revise the presentation and experiments in order to make this a compelling paper.  Specifically, if they simply present the method as a system identification approach for the manipulator equations, with the key terms parameterized by a deep network (and compare to relevant system identification approaches), I think the results here would be interesting, even if they would probably be more interesting to a robotics audience rather than a core ML audience.  But as it is, the paper really doesn\'t situation this work within the proper context, making it quite difficult to assess its importance or significance.', 'This paper discusses learning of robot dynamics models. They propose to learn the mass-matrix\nand the potential forces, which together describe the Lagrangian mechanics of the robot. The unknown\nterms are parametrized as a deep neural network, with some properties (such as positive definiteness)\nhard-coded in the network structure. The experimental results show the learned inverse model being used\nas the feed-forward term for controlling a physical robot. The results show that this approach lead to faster\nlearning, as long as the model accurately describes the system. The paper is well written and seems free\nof technical errors. The contribution is modest, but relevant, and could be a basis for further research. Below\nare a few points that could be improved:\n\n1) The paper uses the term partial differential equation in a non-standard way. While Eqs. 4/5 contain partial derivatives,\nthe unknown function is q, which is a function of time only. Therefore, the Lagrangian mechanics of robot arms are seen\nas ordinary differential equations. The current use of the PDE terms should be clarified, or removed.\n2) It is not made clear why the potential forces are learned directly, rather than as a derivative of the potential energy. Could you discuss the advantages/disadvantages? \n3) Somewhat related to the previous point: the paper presents learning of dissipative terms as a challenge for future works. Given that the formulation directly allows to add \\dot{q} as a variable in g, it seems like a trivial extension. Can you make clearer why this was not done in this paper (yet).\n4) The results on the physical robot arm state that the model cannot capture the cable dynamics, due to being a rigid body model. However, the formulation would allow modelling the cables as (non-linear) massless springs, which would probably\nexplain a large portion of the inaccuracies. I strongly suggest running additional experiments in which the actuator and joints have a separate position, and are connected by springs. If separate measurements of joint-position and actuator position are not available on the arm, it would still be interesting to perform the experiments in simulation, and compare the\nperformance on hardware with the analytical model that includes such springs.\n5) The choice is made to completely hardcode various properties of the mass matrix into the network structure. It would be possible to make some of these properties softcoded. For instance, the convective term C(q,\\dot{q})\\dot{q} could be learned separately, with the property  C + C^T = \\dot{H} encoded as a soft constraint. This would reduce the demand on computing derivatives online.']","[60, -30, 60]","[80, 50, 80]","[""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper's approach, appreciating its simplicity and the fact that it was tested on a real robot arm. The reviewer also expresses interest in the online learning aspect. However, the score is not higher because the reviewer follows up with several questions and suggestions for improvement, indicating that there are areas that need addressing. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, starting with positive feedback and framing their critiques as questions and suggestions rather than direct criticisms. Phrases like 'I like', 'I very much appreciate', and 'It would be interesting' contribute to the polite tone. The reviewer also offers constructive feedback in a professional manner, without using any harsh or dismissive language."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('genuinely nice application', 'interesting to encode these as a generic deep network'), the overall tone is critical. The reviewer points out several major issues and states the paper is 'unsuitable in its current form'. However, it's not entirely negative as the reviewer expresses interest in the core idea. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives and providing constructive criticism. They use phrases like 'I think' and 'I really do like the overall idea' to soften critiques. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. However, some direct criticisms (e.g., 'frankly unnecessary') prevent a higher politeness score."", ""The sentiment score is 60 (moderately positive) because the reviewer starts by acknowledging the paper's contribution, stating it is 'well written and seems free of technical errors.' They also mention that the contribution is 'modest, but relevant, and could be a basis for further research.' This indicates a generally positive view, although not overwhelmingly enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their suggestions as improvements rather than criticisms. They use phrases like 'could be improved' and ask questions instead of making demands. The reviewer also balances critique with praise, which is a polite approach. The suggestions are presented constructively, often explaining why they are important or how they could enhance the paper.""]"
"['\n\n*Pros:*\n-\tEasily accessible paper with good illustrations and a mostly fair presentation of the results (see suggestions below).\n-\tIt is a first attempt to generate audio with GANs which results in an efficient scheme for generating short, fixed-length audio segments of reasonable (but not high) quality.\n-\tHuman evaluations (using crowdsourcing) provides empirical evidence that the approach has merit.\n-\tThe paper appears reproducible and comes with data and code.\n\n*Cons*:\n-\tPotentially a missing comparison with existing generative methods (e.g. WaveNet). See comments/questions below ** \n-\tThe underlying idea is relatively straightforward in that the proposed methods is a non-trivial application of already known techniques from ML and audio signal processing.\n\n*Significance*: The proposed GAN-based audio generator is an interesting step in the development of more efficient audio generation and it is of interest to a subcommunity of ICLR as it provides a number of concrete techniques for applying GANs to audio.\n\n*Further comments/ questions:*\n-\tAbstract/introduction: I’d suggest being more explicit about the limitations of the method, i.e. you are currently able to generate short and fixed-length audio.\n-\tSpecGAN (p 4): I’d suggest including some justification of the chosen pre-processing of spectrograms (p. 4, last paragraph). \n-\t** Evaluation:  The paper dismisses existing generative methods early in the evaluation phase but the justification for doing so is not entirely clear to me: Firstly, if the inception score is used as an objective criterion it would seem reasonable to include the values in the paper. Secondly, as inception scores are based on spectrograms it could potentially favour methods using spectrograms directly (SpecGAN) or indirectly (WaveGAN, via early stopping) thus putting the purely sample based methods (e.g. WaveNet) at a disadvantage. It would seem fair to pre-screen the audio before dismissing competitors instead of solely relying on potentially biased inception scores (which was probably also done in this work, but not clearly stated…)? Finally, while not the aim of the paper, it would have been beneficial to discuss and understand the failures of existing methods in more detail to convince the reader that a fair attempt has been made to getting competitors to work before leaving them out entirely. \n-\tResults/analysis: It is unclear to me how many people annotated the individual samples? What is the standard deviation over the human responses (perhaps include in tab 1)? Consider including a reflection on (or perhaps even test statistically) the alignment between the qualitative diversity/quality scores and the subjective ratings to justify the use of the objective scores in the training/selection process.\n-\tRelated work: I think it would provide a better narrative if the existing techniques are outlined earlier on in the paper.\n', 'This paper proposes WaveGAN for unsupervised synthesis of raw-wave-form audio and SpecGAN that based on spectrogram. Experimental results look promising.\n\nI still believe the goal should be developing a text-to-speech synthesizer, at least one aspect.', 'This paper applies GANs for unsupervised audio generation. Particularly, DCGAN-like models are applied for generating audio. This application is interesting, but the algorithmic contribution is limited.\n \nQualitative ratings are poor. The important problem of generating variable-length audio is untouched.\n']","[60, 50, -60]","[80, 0, -20]","[""The sentiment score is 60 (moderately positive) because the review begins by listing several pros, indicating the paper has merit and makes a contribution. It acknowledges the paper's accessibility, novelty, empirical evidence, and reproducibility. However, it also lists some cons and areas for improvement, tempering the overall positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions (e.g. 'I'd suggest...') and questions rather than direct criticisms. The reviewer also acknowledges the paper's strengths before discussing limitations. The tone remains professional and constructive throughout, offering specific recommendations for improvement without being harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the experimental results 'look promising,' which indicates a positive view of the paper's contributions. However, the review is brief and doesn't express strong enthusiasm, hence the moderate positive score. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer states their opinions directly without using overtly polite phrases or rude language. The final sentence suggests an area for improvement but is phrased as a personal belief rather than a demand, maintaining a neutral tone."", ""The sentiment score is -60 because the review is generally negative. While it acknowledges the application as 'interesting', it criticizes the limited algorithmic contribution, poor qualitative ratings, and failure to address an important problem. This indicates a predominantly negative sentiment. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and lacks any softening phrases or positive reinforcement. The use of words like 'poor' and 'limited' without any mitigating language contributes to a somewhat impolite tone, though not extremely so.""]"
"['Authors case the problem of finding informative measurements by using a maximum likelihood formulation and show how a data-driven dimensionality reduction protocol is built for sensing signals using convolutional architectures. A novel parallelization scheme is discussed and analyzed for speeding up the signal recovery process.\n \nPrevious works have been proposed to jointly learn the signal sensing and reconstruction algorithm using convolutional networks. Authors do not consider them as the baseline methods due to the fact that the blocky reconstruction approach is unrealistic such as MRI. However, there is no empirical result to support his conclusion.  In addition, the comparisons to these methods can further convince the readers about the advantage of the proposed method.\n \nIt is not clear where the maximum deviation from isometry in Algorithm 1 is discussed since the MSE is used as a loss function.\n \nAuthors provided theoretical insights for the proposed algorithm. It indicates that the lower-bound of the mutual information is maximized and minimizing the mean squared error is a special case, but it is unclear why this can provide theoretical guarantee for the proposed method. More details are good for the connections between the theory and the proposed algorithm.\n \nOne of the contributions in this paper is the speed, so the results on the speed should be put in the main paper.', 'Quality & Clarity:\nThis is a nice paper with clear explanations and justifications. The experiments seem a little shakey.\n\nOriginality & Significance:\nI\'m personally not familiar enough to say the theoretical work is original, but it is presented as so. However it seems significant. The numerical results do not seem extremely significant, but to be fair I\'m not familiar with state of the art nearest neighbor results ie Fig 3.\n\nPros:\nI like that you don\'t take much for granted. E.g. you justify using convolutional net in 2.1, and answered multiple of my questions before I could type them (e.g. why didn\'t you include nonlinearities between convolutions, why bother with cascaded convolutions, and what you mean by near-optimal).\n\nCons:\nThe visual comparisons in Figure 4 are difficult to see. DLAMP appears to be over-smoothing but in general it\'s hard to compare to low-ish resolution noisy-looking textures. I strongly recommend using a test image with a clear texture to illustrate your point (eg the famous natural test image that has on the side a tablecloth with zig-zag lines)\n\nThe horizontal error bars are obfuscated by the lines between markers in Fig 3a.\n\nI don\'t understand Fig 3a. You are varying M, which is on the Y-axis, and observing epsilon, on the X-axis?\n\nQuestions:\nCan you state what is novel about the discussion in the ""Theoretical Insights"" subsection of 2.1? I guess this is described in your abstract as ""we cast the problem ... by using a maximum likelihood protocol..."" but your contribution could be made more explicit. For example ""We show that by jointly optimizing phi and lambda (sensing and recovery), we are maximizing the lower bound of mutual information between reconstructions (X) and samples (Y)"" (that is my understanding of the section)\n\nWhy don\'t you use the same M for all methods in the Figure 3 experiments? ie why did you use a different M for numax/random versus deepSSRR/DCN?\n\nWhy do you choose 20-layers for the denoiser? Seems deep...\n\nThe last part of the last sentence of the 2nd paragraph of section 3.1 should be a complete sentence ""though, with more number of parameters"". Does that mean that the DCN has more parameters than the DeepSSRR?\n\nI am willing to change score based on the response\n\n******************\nUpdate after author response:\nThanks for the clear response and Figure 3, and nice paper. My score is updated.\nPS: I still think that the (tiny) error bars are obfuscated because the line connecting them is the same thickness and color.', ""\nThis paper proposes a (CNNs) architecture for encoding and decoding images for compressed sensing. \nIn standard compressed sensing (CS), encoding usually is linear and corresponds to multiplying by a fat matrix that is iid gaussian. The decoding is performed with a recovery algorithm that tries to explain the linear measurements but also promotes sparsity. Standard decoding algorithms include Lasso (i.e. l1 regularization and a MSE constraint) \nor iterative algorithms that promote sparsity by construction. \n\nThis paper instead proposes a joint framework to learn a measurement matrix Phi and a decoder which is another CNN in a data-driven way. The proposed architecture is novel and interesting.  \n\nI particularly liked the theoretical motivation of the used MSE loss by maximizing mutual information. \n\nThe use of parallel convolutions is also neat and can significantly accelerate inference, which can be useful for some applications. \n\nThe empirical performance is very good and matches or outperforms previous state of the art reconstruction algorithms D-AMP and Learned D-Amp. \n\nOn comparisons with prior/concurrent work: The paper is essentially a CNN autoencoder architecture but specifically designed for compressed sensing problems. \nThere is vast literature on CNN autoencoders including (Jiang 2017 and Shi 2017) paper cited by the authors. I think it is fine to not compare against those since they divide the images into small blocks and hence have are a fundamentally different approach. This is fine even if block-reconstruction methods outperform this paper, in my opinion: new ideas should be allowed to be published even if they do not beat SOTA, as long as they have clearly novel ideas. It is important however to discuss these differences as the authors have done in page 2.  \n\nSpecific comments: \n\n1. It would be interesting to see a comparison to D-Amp and LDAmp for different number of measurements or for different SNRs (i.e. when y = Phi x+ noise ). I suspect each method will be better for a different regime?\n\n2. The paper: `The Sparse Recovery Autoencoder' (SRA) by Wu et al. https://arxiv.org/abs/1806.10175\nis related in that it learns both the sensing matrix and a decoder and is also focused on compressed sensing, but for non-image data. The authors should discuss the differences in architecture and training. \n\n3. Building on the SRA paper, it is possible that the learned Phi matrix is used but then reconstruction is done with l1-minimization. How does that perform for the matrices learned with DeepSSRR?\n\n4. Why is Figure 1 going from right to left?\n\n\n\n""]","[-20, 50, 80]","[50, 70, 70]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novel aspects of the work, they also point out several areas for improvement and missing information. The review starts with a neutral summary but then raises concerns about lack of empirical results, unclear connections between theory and algorithm, and missing important results in the main paper. These critiques outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism without using harsh or dismissive language, and phrase their suggestions as recommendations rather than demands. The tone is academic and objective, maintaining a polite distance while still clearly communicating areas for improvement.', ""The sentiment score is 50 (slightly positive) because the reviewer describes it as a 'nice paper with clear explanations and justifications', and mentions several pros. However, they also point out some cons and areas for improvement, balancing the overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than harsh criticisms. They also express willingness to change their score based on the authors' response, which shows flexibility and respect for the authors' perspective."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the proposed architecture as 'novel and interesting', mention that they 'particularly liked' certain aspects, and note that the empirical performance is 'very good'. The reviewer also states that the paper matches or outperforms previous state-of-the-art methods. While they do provide some suggestions for improvement, these are presented as constructive feedback rather than criticisms. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise where appropriate and frame their suggestions as 'specific comments' rather than demands. The reviewer also acknowledges the value of publishing new ideas even if they don't beat the state-of-the-art, which shows a considerate approach. The language is consistently courteous without being overly deferential.""]"
"[""The authors propose a Laplacian in the context of reinforcement learning, together with learning the representations. Overall the authors make a nice contribution. The insight of defining rho to be the stationary distribution of the Markov chain P^pi and connecting this to eq (1) is interesting. Also the definition of the reward function on p.7 in terms of the distance between phi(s_{t+1}) and phi(z_g) looks original. The method is also well illustrated and compared with other methods, showing the efficiency of the proposed method.\n\nOn the other hand I also have further comments and suggestions:\n\n- it would be good if the authors could comment on the choice of d. This is in fact a model selection problem. According to which criterion is this selected?\n\n- the authors define D(u,v) in eq (4). Why this choice? Is there some intuition or interpretation possible related to this expression?\n\n- in (6) beta is called a Lagrange multiplier. Given that a soft constraint (not a hard constraint) is added for the orthonormality constraint it is not a Lagrange multiplier.\n\nHow sensitive are the results with respect to the choice of beta in (6) (or epsilon in the eq above)? The orthonormality constraint will only be approximately satisfied. Isn't this a problem?\n\nWouldn't it be better in this case to rely on optimization algorithm on Grassmann and Stiefel manifolds?\n\n- The authors provide a scalable approach related to section 2 by stochastic optimization. Other scalable methods related to kernel spectral clustering (related to subsets/subgraphs and making out-of-sample extensions) were proposed in literature, e.g.\n\nMultiway Spectral Clustering with Out-of-Sample Extensions through Weighted Kernel PCA, IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(2), 335-347, 2010.\n\nKernel Spectral Clustering for Big Data Networks, Entropy, Special Issue: Big Data, 15(5), 1567-1586, 2013.\n\n\n"", 'Summary: This paper proposes a method to learn a state representation for RL using the Laplacian. The proposed method aims to generalize previous work, which has only been shown in finite state spaces, to continuous and large state spaces. It goes to approximate the eigenvectors of the Laplacian which is constructed using a uniformly random policy to collect training data. One use-case of the learnt state representation is for reward-shaping that is said to accelerate the training of standard goal-driven RL algorithms. \n\n\nIn overall, the paper is well written and easy to follow. The idea that formulates the problem of approximating the Laplacian engenfunctions as constraint optimization is interesting. I have some following major concerns regarding to the quality and presentation of the paper.\n\n- Though the idea of learning a state representation seems interesting and might be of interest within the RL research, the authors have not yet articulated the usefulness of this learnt representation. For larger domains, learning such a representation using a random policy might not be ideal because the random policy can not explore the whole state space efficiently. I wish to see more discussions on this, e.g. transfer learning, multi-task learning etc.\n\n- In terms of an application of the learnt representation, reward-shaping looks interesting and promising. However I am concerned about its sample efficiency and comparing experiments. It takes a substantial amount of data generated from a random policy to attain such a reward-shaping function, so the comparisons in Fig.5 are not fair any more in terms of sample efficiency. On the other hand, the learnt representation for reward-shaping is fixed to one goal, can one do transfer learning/multi-task learning to gain the benefit of such an expensive step of representation learning with a random policy.\n\n- The second equation, below the text""we rewrite the inequality as follows"" in page 5, is correct? this derivation is like E(X^2) = E(X) E(X)?\n\n- About the performance reported in Section 5.1, I wonder if the gap can be closer to zero if more eigenfunctions are used?\n\n\n================\nAfter rebuttal:\nThanks the authors for clarification. I have read the author\'s responses to my review. The authors have sufficiently addressed my concerns. I agree with the responses and decide to change my overall rating\n', ""This works proposes a scalable way of approximating the eigenvectors of the Laplacian in RL by optimizing the graph drawing objective on limited sampled states and pairs of states. The authors empirically show the benefits of their method in two different types of goal achieving task. \n\nPros:\n- Well written, well structured, an overall enjoyable read.\n- The related work section appears to be comprehensive and supports the motivations for the presented work.\n- Clear and rigorous derivations. \n- The method is evaluated both in terms of how well it is able to approximate the optimal Laplacian-based representations with limited samples compared to baseline models and how well it solves reward shaping in RL.\n\nCons:\n- In the experimental section, the methods used to learn the policies, DQN and DDPG, should be briefly explained or at least referenced.\n- A further discussion on why the authors chose a half-half mix of the L2 distance and sparse reward could be beneficial. The provided explanation (L2 distance doesn't provide enough gradient) is not very convincing nor justified.\n ""]","[60, 50, 80]","[70, 75, 70]","[""The sentiment score is 60 (positive) because the reviewer starts with praise, calling it a 'nice contribution' and highlighting several positive aspects of the work, such as 'interesting' insights and 'original' definitions. However, it's not extremely positive as the reviewer also has several questions and suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions ('it would be good if...') and questions rather than direct criticisms. The reviewer also acknowledges the authors' efforts in illustrating and comparing their method. The tone remains professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating the paper is 'well written and easy to follow' and finds the core idea 'interesting'. However, they also express 'major concerns' and point out several issues, balancing the positive and negative aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g. 'I wish to see more discussions on this'), and acknowledges the authors' responses positively in the post-rebuttal section. The reviewer maintains a professional and courteous tone while providing substantive feedback."", ""The sentiment score is 80 (positive) because the review starts with a clear summary of the work and lists several pros, including that it's well-written, comprehensive, rigorous, and empirically supported. The cons mentioned are minor suggestions for improvement rather than significant criticisms. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing suggestions constructively. The use of terms like 'well written,' 'enjoyable read,' and 'clear and rigorous' contribute to the polite tone. The cons are presented as suggestions for improvement rather than harsh criticisms, maintaining a courteous approach.""]"
"['Updated rating after author response from 8 to 7 because I agree that Figure 1 and some discussions were confusing in the original manuscript.\n--------------------------------------------------------------------------\n\nThis paper investigates the relationship between the eigenvectors of the Hessian. This paper investigates characteristics of Hessian of the empirical losses of DNNs through comprehensive experiments. These experiments showed many important insights, 1) the top-K eigenvalues become bigger in the early stage, and decrease in later stage. 2) Bigger SGD steps and smaller batch-size leads to smaller and earlier peak of eigenvalues. 3) The sharpest direction update does not contribute to the loss value decrease in the normal step size (or bigger). From these analyses, this paper proposes to decrease the SGD step length on top-K eigenvectors for speeding up the convergence. Experimental results showed that the proposed method could converge to local minima in a fewer epoch and obtain better result, which means higher test accuracy.\n\nThis paper is well-written and well-organized. Findings about eigenvalues and these relationship between the SGD step length are very impressive. Although the step length adjustment on the top-K eigenvector directions are not realistic solution for improving the current SGD-based optimization on DNNs due to heavy computational cost, I think these findings and insights are very helpful to ICLR and other ML communities.', 'The paper discusses connections between the properties of DNN loss surfaces and the step length SGD algorithms take, a timely topic.  On the whole, reasonably well done, with some interesting observations.\n\nIt makes several claims, most notably that there is an initial regime where SGD visits increasingly sharp regions of the loss surface, followed by a regime where the loss surface gets smoother.  Useful to know, and characterized moderately well.\n\nA weakness is that the generality of that claim is not made clear.  Like many papers in the area, it is an observation, the realm of which is not clarified.  E.g., what properties of the neural network or data does it depend on.  Also not clarified is how this depends on initialization, etc.\n\nThe evaluation should be more systematic, as it is hard to tell how general is the claims of the paper as well as how they depend on implementation details.\n \nThe discussion of Hessian directions ignores very relevant work by Yao et al (https://arxiv.org/abs/1802.08241 and follow up).\n\nThe first figure in Fig 1 is probably misleading, and probably not worth having, the latter two are what is measured and thus more interesting.\n\nThe obvious conclusion from the poor conditioning is that methods designed to addressed poor conditioning, i.e., second order methods, should be considered.  Those should have a complementary dynamics to what is discussed.  This is what is the elephant in the room when you talk about steering towards or away from regions whose curvature matches the SGD step. \n\nI don\'t know what it means to say ""Where applicable, the Hessian is estimated with regularization applied""  Is this to speed up computation, why doesn\'t this change the loss surface, etc.  If you are not measuring Hessian information precisely, then all the claims of the paper fall apart.\n\nSeveral times claims like ""SGD reaches a region in which the SGD step matches ...""  Of course, the energy surface changes with training time, so it is a little unclear what is being said.\n\nThe main method Nudged-SGD sounds like a poor-mans second order method.  Why not describe it as such (in more than a footnote and appendix), rather than introducing a new acronym.  I don\'t know that I believe the ""key design principle"" in the appendix for second order methods.  Second order methods rotate and stretch to take a locally-correct step length, and this method sounds like it is doing a poor mans version of that.  There is a good question as to whether the ""thresholding"" into large and small that NSGD is doing causes it to do something very different, but that isn\'t really evaluated.\n\nAveraging over two random seeds is not a lot.\n', 'Update after author response: I am changing my rating from 4 to 6 in light of the clarification and new experiments.\n\n-------\nIn this paper the authors study the relationship between the SGD step size and the curvature of the loss surface, empirically showing that: 1) SGD is guided towards sharp regions of the loss surface at the start especially with a large learning rate or a small batch size. 2) Loss increases on average when taking a SGD step in the sharpest directions. 3) Modifying the SGD step size in the sharp directions (for example removing its component in the sharpest direction), can lead to substantial changes in both the quality and the local landscape of the minima (for the example mentioned, leading to a better and sharper minima). Motivated by these observations, the authors propose a variant of SGD that leads to better performance on the datasets considered.\n\nDeep learning theory is a very important frontier for machine learning and one that’s needed to make the practice be guided more by the foundational principles than incessant tweaks. The paper makes some very interesting observations and uses those insights to improve the widely used SGD. However, I have a few concerns which leave me unconvinced about the impact of the contributions in the paper. My biggest problem is the use of second order information in the algorithm which makes the optimization process computationally cumbersome, and raises the question as to why might this approach be preferable to any other second order approach (the authors touch on Newton method in the appendix but the discussion far from settles the matter). Similar questions arise in considering the merit of the proposed methods in comparison to a host of other well-studied augmentations to SGD like momentum, Adam or AdaGrad. The quality of presentation is also a problem, and both the organization of the main matter as well as of the figures can use some polishing. The latter specifically sometimes lacked legends (Fig. 3 and 4), and some other times had legends covering a quarter of the plot (Fig. 5). Lastly, even though the claims sound theoretical, they are not derived from any set of first principles but come from observations on a few datasets. While this may after all be how SGD behaves in general, currently the paper doesn’t provide any evidence to believe that. \n\nMinor issues: “withe” (page 2, spelling), “\\alpha = 0.5, 1, 2 corresponding to red, green, and blue” (page 4, I believe it should be “blue, green and red”).\n\nIn summary, even though I liked what the paper set out to do, I am not convinced on the generalizability of these results and subsequently the rationale for using the proposed method over other competing options. A revised version of the paper with either validation on more datasets or sound theory generalizing the results to some extent would make for a much nicer contribution.']","[80, -20, -20]","[90, 20, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'well-written and well-organized' and the findings as 'very impressive'. They also state that the insights are 'very helpful' to the community. The politeness score is 90 (very polite) due to the consistently respectful and professional tone. The reviewer uses phrases like 'This paper investigates...' and 'Experimental results showed...', maintaining a formal and courteous language throughout. They offer praise without being overly effusive, and even when mentioning a potential limitation (computational cost), they do so in a constructive manner."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('reasonably well done, with some interesting observations'), they also point out several weaknesses and areas for improvement. The review is more critical than positive overall, highlighting issues with generality, evaluation, and methodology.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use neutral language and offer constructive criticism without being harsh or dismissive. Phrases like 'Useful to know' and 'The obvious conclusion' soften the critique. However, the review doesn't go out of its way to be overly polite or complimentary either, maintaining a balanced, academic tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('very interesting observations', 'improve the widely used SGD'), they express several concerns and are 'unconvinced about the impact of the contributions'. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits and providing constructive criticism. They use phrases like 'I liked what the paper set out to do' and offer specific suggestions for improvement, maintaining a professional and courteous tone even when expressing concerns.""]"
"['This paper investigates two issues regarding Adversarial Imitation Learning. They identify a bias in commonly used reward functions and provide a solution to this. Furthermore they suggest to improve sample efficiency by introducing a off-policy algorithm dubbed ""Discriminator-Actor-Critic"". They key point here being that they propose a replay buffer to sample transitions from. \n\nIt is well written and easy to follow. The authors are able to position their work well into the existing literature and pointing the differences out. \n\nPros:\n\t* Well written\n\t* Motivation is clear\n\t* Example on biased reward functions \n\t* Experiments are carefully designed and thorough\nCons:\n\t* The analysis of the results in section 5.1 is a bit short\n\nQuestions:\n\t* You provide a pseudo code of you method in the appendix where you give the loss function. I assume this corresponds to Eq. 2. Did you omit the entropy penalty or did you not use that termin during learning?\n\n\t* What\'s the point of plotting the reward of a random policy? It seems your using it as a lower bound making it zero. I think it would benefit the plots if you just mention it instead of plotting the line and having an extra legend\n\n\t* In Fig. 4 you show results for DAC, TRPO, and PPO for the HalfCheetah environment in 25M steps. Could you also provide this for the remaining environments?\n\n\t* Is it possible to show results of the effect of absorbing states on the Mujoco environments?\n\nMinor suggestions:\nIn Eq. (1) it is not clear what is meant by pi_E. From context we can assume that E stands for expert policy. Maybe add that. Figures 1 and 2 are not referenced in the text and their respective caption is very short. Please reference them accordingly and maybe add a bit of information. In section 4.1.1 you reference figure 4.1 but i think your talking about figure 3.', 'The paper suggests to use TD3 to compute an off-policy update instead of the TRPO/PPO updates in GAIL/AIRL in order to increase sample efficiency.\nThe paper further discusses the problem of implicit step penalties and survival bias caused by absorbing states, when using the upper-bounded/lower-bounded reward functions log(D) and -(1-log(D)) respectively. To tackle these problem, the paper proposes to explicit add a unique absorbing state at the end of each trajectory, such that its rewards can be learned as well.\n\nPro:\nThe paper is well written and clearly presented. \n\nUsing a more sample efficient RL method for the policy update is sensible and turned out effective in the experiments.\n\nProperly handling simulator resets in MDPs is a well known problem in reinforcement learning that I think is insufficiently discussed in the context of IRL.\n\n\nCons:\nThe contributions seem rather small.\na) Replacing the policy update is trivial, since the rl methods are used as black-box modules for the discussed AIL methods. \n\nb) Using importance weighting to reuse old trajectories for the discriminator update hardly counts as a contribution either--especially when the importance weights are simply omitted in practice. I also think that the reported problems due to the high variance have not been sufficiently investigated. There should be a better solution than just pretending that the replay buffer corresponds to roll-outs of the current policy. Would it maybe help to use self-normalized importance weights? The paper does also not analyze how such assumption/approximation affects the theoretical guarantees.\n\nc) The problem with absorbing states is in my opinion the most interesting contribution of the paper. However, the discussion is rather shallow and I do not think that the illustrative example is very convincing. Section 4.1.1. argues that for the given policy roll-out, the discriminator reward puts more reward on the policy trajectory than the expert trajectory. However, it is neither surprising nor problematic that the discriminator reward does not produce the desired behavior during learning. By assigning more cumulative reward for s2_a1->s1 than for s2_a2->g, the policy would (after a few more updates) choose the latter action much less frequently than with probability 0.5 and the corresponding reward would grow towards infinity until at some point Q(s2,a2) > Q(s2,a1)--when the policy would match the expert exactly. The illustrative example also uses more policy-labeled transitions than agent-labeled ones for learning the classifier, which may also be problematic. The paper further argues that a strictly positive reward function always rewards a policy for avoiding absorbing states, which I think is not true in general. A strictly positive reward function can still produce arbitrary large reward for any action that reaches an absorbing state. Hence, the immediate reward for choosing such action can be made larger than the discounted future reward when not ending the episode (for any gamma < 1). Even for state-only reward functions the problem does not persist when reseting the environment after reaching the absorbing state such that the training trajectories contain states that are only reached if the simulator gets reset. Hence, I am not convinced that adding a special absorbing state to the trajectory is necessary if the simulation reset is correctly implemented. This may be different for resets due to time limits that can not be predicted by the last state-action tuple. However, issues relating to time limits are not addressed in the paper. I also think that it is strange that the direct way of computing the return for the terminal state is much less stable than recursively computing it and think that the paper should include a convincing explanation.\n\n---------------\nUpdate 21.11.2018\n\nI think my initial assessment was too positive. During the rebuttal, I noticed that the discussion of reward bias was not only shallow but also wrong in some aspects and very misleading, because problems arising from hacky implementations of some RL toolboxes were discussed as theoretical shortcoming of AIL algorithms. Hence, I think the initial submission should be clearly rejected. However, the authors submitted a revised version that presents the root of the observed problem much more accurately. I think that the revised version is substantially better than the original submission. However, I think that my initial rating is still valid (better: became valid), because the main issues that I raised for the initial submission still apply to the current revision, namely:\n- The technical contributions are minor.\n- The theoretical discussion (in particular regarding absorbing states) is quite shallow.\n\nThe merits of the paper are:\n- Good results due to off-policy learning\n- Raising awareness and providing a fix for a common pitfall \n\nI think that the problems arising from incorrectly treated absorbing states needs to be discussed more profoundly. \nSome suggestions: \n\nSection 3.1\n""As we discuss in detail in Section 4.2 [...]""\nI think this should refer to section 4.1. Also the discussion should in section 4.1 should be a bit more detailed. How do common implementations implicitly assign zero rewards? Which implementations are affected? Which papers published inferior results due to this bug? I think it is also important to note, that absorbing states are hidden from the algorithm and that the reward function is thus only applied to non-absorbing states.\n\n""We will demonstrate empirically in Section 4.1 [...]""\nThe demonstration is currently missing. I think it would be nice to illustrate the problem on a simple example. The original example might actually work, as shown by the code example of the rebuttal, however the explanation was not convincing. Maybe it would be easier to argue with a simpler algorithm (e.g MaxEnt-IRL, potentially projecting the rewards to positive values)?\n\nSection 3.1 seems to focus too much on resets that are caused by time limits. Such resets are inherently different from terminal states such as falling down in locomotion tasks, because they can not be modelled with the given MDP formulation unless time is considered part of the state. Indeed, I think that for infinite horizon MDPs without time-awareness, time limits can not be modelled using absorbing states (I think the RL book misses to mention that time needs to be part of the state such that the policy remains Markovian, which is a bit misleading). Instead those resets are often handled by returning an estimate of the future return (bootstrapping). This treatment of time limits is already part of the TD3 implementation and as far as I understood not the focus of the paper. Instead section 3.1. should focus on resets caused by task failure/completion, which can actually be modelled with absorbing states, because the agent will always transition to the absorbing state when a terminal state is reached which is in line with Markovian dynamics.\n\nSection 4.2 should also add a few more details. Did I understand correctly, that when computing the return R_T the sum is indeed finite and stopped after a fixed horizon? If yes, this should be reflected in the equation, and the horizon should be mentioned in the paper. The paper should also better explain how  the proposed fix enables the algorithm to learn the reward of the absorbing state. For example, section 4.2. does not even mention that the state s_a was added as part of the solution. \n\n\n-------------\nUpdate 22.11.2018\nBy highlighting the difference between termination due to time-limits and termination due to task completion, and by better describing how the proposed fix addresses the problem of reward bias that is present in common AIL implementations, the newest revision further improves the submission. \nI think that the submission can get accepted and I adapted my rating accordingly.\n\nMinor:\nConclusion should also squeeze in somehow that the reward biases are caused by the implementations.\nTypo in 4.2: ""Thus, when sample[sic] from the replay buffer AIL algorithms will be able to see absorbing states there[sic]\nwere previous hidden, [...]""\n', 'The authors find 2 issues with Adversarial Imitation Learning-style algorithms: I) implicit bias in the reward functions and II) despite abilities of coping with little data, high interaction with the environment is required. The authors suggest ""Discriminator-Actor-Critic"" - an off-policy Reinforcement Learning reducing complexity up to 10 and being unbiased, hence very flexible. \n\nSeveral standard tasks, a robotic, and a VR task are used to show-case the effectiveness by a working implementation in TensorFlow Eager.\n\nThe paper is well written, and there is practically no criticism.\n\n']","[80, 20, 90]","[90, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer starts with a neutral summary of the paper's content, followed by praise for its clarity and positioning. The reviewer lists more pros than cons, and the cons are minor. The questions and suggestions are constructive rather than critical. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offers balanced feedback, and phrases criticisms and suggestions in a constructive manner. The use of 'please' in the minor suggestions and the overall tone of helpful inquiry further contribute to the polite nature of the review."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some merits of the paper ('well written', 'clearly presented', 'effective in experiments'), they also express significant criticisms ('contributions seem rather small', 'discussion is rather shallow'). The overall tone suggests cautious approval rather than strong enthusiasm or rejection. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, balancing praise and criticism without harsh wording. They offer constructive suggestions and frame criticisms as areas for improvement rather than outright flaws. The use of phrases like 'I think' and 'in my opinion' further softens the critique."", ""The sentiment score is 90 (highly positive) because the reviewer states 'there is practically no criticism' and describes the paper as 'well written'. They also highlight the authors' findings and contributions without any negative comments. The politeness score is 80 (quite polite) as the reviewer uses respectful and professional language throughout, acknowledging the authors' work positively. The tone is formal and constructive, without any harsh or rude expressions. The reviewer focuses on summarizing the paper's content and expressing approval, which contributes to both the positive sentiment and polite tone.""]"
"['The paper focuses on adversarial vulnerability of neural networks, and more specifically on perturbation-based versus invariance-based adversarial examples and how using bijective networks (with so-called metameric sampling) may help overcoming issues related to invariance. The approach is used to get around insufficiencies of cross-entropy-based information-maximization, as illustrated on experiments where the proposed variation on CE outperforms CE. \n\nWhile I am not a neural network expert, I felt that the ideas developed in the paper are worthwhile and should eventally lead to useful contributions and be published. This being said, I did not find the paper in its present form to be fit for publication in a high-tier conference or journal. The main reason for this is the disbalance between the somehow heavy and overly commented first four pages (especially in Section 2) contrasting with the surprisingly moderate level of detail when it comes to bijective networks, supposedly the heart of the actual original contribution. To me this is severely affecting the overall quality of the paper. The contents of sections 3 and 4 seem relevant, but I struggled find out what precisely is the main contribution in the end, probably because of the lack of detail on bijective networks mentioned before. Again, I am not an expert, and I will indicate that in the system of course, but while I cannot completely judge all aspects of the technical relevance and the originality of the approach, I am fairly convinced that the paper deserves to be substantially revised before it can be accepted for publication.   \n\nEdit: After paper additions I am changing my score to a 6. ', 'This paper studies a new perspective on why adversarial examples exist in machine learning -- instead of seeing adversarial examples as the result of a classifier being sensitive to changes in irrelevant information (aka nuisance), the authors see them as the result of a classifier being invariant to changes in relevant (aka semantic) information. They show how to efficiently find such adversarial examples in bijective networks. Moreover, they propose to modify the training objective so that the bijective networks could be more robust to such attacks.\n\nPros:\n -- clarity is good (except for a few places, e.g. no definition of F(x)_i in Definition 1; Page 6 ""three ways forward"" item 3: I(y;z_n|z_s) = I(y;z_s) should be I(y;z_n|z_s) = I(y;z_n).)\n -- the idea is original to the best of my knowledge\n -- the mathematical motivation is sound\n -- Figure 6 seems to show that the proposed defense works on MNIST (However, would you provide more details on how you interpolated z_n? Moreover, what do the images generated with z_s from one input and z_n from another input look like (in your method)?)\n\nCons:\n -- scope: as all the presented problems and solutions assume bijective mapping, I wonder how is it relevant to the traditional perspective of adversarial attack and defense? It seems to me that the contribution of this paper is identifying a problem of bijective networks and then proposing a solution, thus its significance is restricted.\n -- method: while the mathematical motivation is sound, I\'m not sure if the proposed training objective can achieve that goal. To elaborate, I see problems with both terms added in the proposed loss function:\n (a.) for the objective of maximizing the cross entropy of the nuisance classifier, it is possible that I(y;z_n) is not reduced, but rather the information about y is encoded in a way that the nuisance classifier is not able to decode, similar to what happens in a one-way function (for example, see https://en.wikipedia.org/wiki/Cryptographic_hash_function ). In the MNIST experiments, the nuisance classifier is a three-layer MLP, which may be too weak and susceptible to information concealing.\n (b.) for the objective of maximizing the likelihood of a factorized model of p(z_s, z_n), I don\'t see how optimizing it would reduce I(z_s; z_n). In general, even if z_s and z_n are strongly correlated, one can still fit such a factorized model. This only ensures that I(Z_s; Z_n) = 0 for Z_s, Z_n *sampled from the model*, but does not necessarily reduce I(z_s; z_n) for z_s, z_n *used to train the model*. The discrepancy between p(Z_s, Z_n) and p(z_s, z_n) could be huge, in which case one has the model misspecification problem which is another topic.\n (c.) a side question: why is the MLE objective using likelihood rather than log likelihood? Since the two cross entropy losses are similar to log likelihood, I feel there is a mismatch here.\n\n----------------------------------------\nAFTER REBUTTAL:\n\nThanks for your reply to my comments. The new revision has improved clarity and provided new supporting evidences. I would like to raise my rating to 6.\n\nThat being said, (as you agreed) the link from the conceptual goal to the proposed objective has mostly empirical support. Therefore I hope it may encourage future investigation on when and why the proposed objective is successful in achieving the conceptual goal.', 'This paper explores adversarial examples by investigating an invertible neural network. They begin by first correctly pointing out limitations with the commonly adopted ""l_p adversarial example"" definition in literature. The main idea involves looking at the preimage of different embeddings in the final layer of an invertible neural network. By training a classifier on top of the final embedding of the invertible network the authors are able to partition the final embedding into a set of ""semantic variables"", which are the components used for classification of the classifier, and a set of ""nuisance variables"" which are the complement of the logit variables. This partition allows the authors to define entire subspaces of adversarial images by holding the logit variables fixed and varying the nuisance variables, and applying the inverse to these modified embeddings. The authors are able to find many incorrectly classified images with this inversion technique. The authors then define a new loss which minimizes the mutual information between the nuisance variables and the predicted label. \n\nI found the ideas in this paper quite interesting and novel. Starting with the toy problem of adversarial spheres is great, and it\'s convincing that the inversion technique can be used to find errors on this dataset even when the classification accuracy is (empirically) 100%. The resulting adversarial images generated by applying their technique are also quite interesting, and this is a cool interesting way to study the robustness of networks in non-iid settings.\n\nThe main weakness is on the evaluation of their proposed new training objective, and I have a few suggestions as to how to strengthen this evaluation. It would be very convincing to me if the authors could show that their new training objective increases robustness to distributional shift. A potential benchmark for distributional shift could be https://arxiv.org/abs/1807.01697 (or just picking a subset of these image corruptions). If the proposed objective shows improvement on this benchmark (or a related one) then this would be a solid contribution.\n\nOne question I have for the authors is how typical the behavior in Figure 4 is? For any fixing of the logits, are all/most metameric samples classifiable by a human oracle? That is do you ever get garbage images from this sampling process. Adding a collection of random samples to the Appendix to demonstrate typical behavior could help demonstrate this.\n\nEdit: After paper additions I am changing my score to a 7. ']","[-20, 20, 70]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the ideas are worthwhile and should eventually lead to useful contributions, they also state that the paper is not fit for publication in its current form and requires substantial revision. The reviewer points out several issues with the paper's structure and lack of detail in key areas. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges their own limitations as a non-expert, and provides constructive feedback. They use phrases like 'I felt that', 'To me', and 'I am fairly convinced' which soften their criticisms. The reviewer also ends on a slightly more positive note by changing their score to a 6 after paper additions, showing a willingness to reconsider their initial assessment."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some pros of the paper (clarity, originality, sound mathematical motivation), they also point out significant cons and areas for improvement. The overall tone suggests a cautiously positive view, especially after the rebuttal where the reviewer raises their rating. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'I wonder', 'I'm not sure', and 'I hope', which maintain a polite and collaborative tone even when expressing concerns."", ""The sentiment score is 70 (positive) because the reviewer expresses that they found the ideas in the paper 'quite interesting and novel'. They also mention that the approach is 'convincing' and 'cool'. The reviewer does point out some weaknesses and suggests improvements, but overall the tone is positive and encouraging. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions in a non-demanding way (e.g., 'It would be very convincing to me if...'). The reviewer also asks questions in a polite manner and offers helpful suggestions for improvement, showing consideration for the authors' work.""]"
"['This paper describes approximation and estimation error bounds for functions in Besov spaces using estimators corresponding to deep ReLU networks. The general idea of connecting network parameters such as depth, width, and sparsity to classical function spaces is interesting and could lead to novel insights into how and why these networks work and under what settings. The authors carefully define Besov spaces and related literature, and overall the paper is clearly written. \n\nDespite these strengths, I\'m left with several questions about the results. The most critical is this: piecewise polynomials are members of the Besov spaces of interest, and ReLU networks produce piecewise linear functions. How can piecewise linear approximations of piecewise polynomial functions lead to minimax optimal rates? The authors\' analysis is based on cardinal B-spline approximations, which generally makes sense, but it seems like you would need more terms in a superposition of B-splines of order 2 (piecewise linear) than higher orders to approximate a piecewise polynomial to within a given accuracy. The larger number of terms should lead to worse estimation errors, which is contrary to the main result of the paper. I don\'t see how to reconcile these ideas. \n\nA second question is about the context of some broad claims, such as that the rates achieved by neural networks cannot be attained by any linear or nonadaptive method. Regarding linear methods, I agree with the author, but I feel like this aspect is given undue emphasis. The key paper cited for rates for linear methods is the Donoho and Johnstone Wavelet Shrinkage paper, in which they clearly show that nonlinear, nonadaptive wavelet shrinkage estimators do indeed achieve minimax rates (within a log factor) for Besov spaces. Given this, how should I interpret claims like ""any linear/non-linear approximator\nwith fixed N -bases does not achieve the approximation error ... in some parameter settings such as 0 < p < 2 < r ""?\nWavelets provide a fixed N-basis and achieve optimal rates for Besov spaces. Is the constraint on p and r a setting in which wavelet optimality breaks down? If not, then I don\'t think the claim is correct. If so, then it would be helpful to understand how relevant this regime for p and r is to practical settings (as opposed to being an edge case). \n\nThe work on mixed Besov spaces (e.g. tensor product space of 1-d Besov spaces) is a fine result but not surprising.\n\nA minor note: some of the references are strange, like citing a 2015 paper for minimax rates for Besov spaces that have been known for far longer or a 2003 paper that describes interpolation spaces that were beautifully described in DeVore \'98. It would be appropriate to cite these earlier sources. ', 'This paper makes two contributions:\n* First, the authors show that function approximation over Besov spaces for the family of deep ReLU networks of a given architecture provide better approximation rates than linear models with the same number of parameters.\n* Second, for this family and this function class they show minimax optimal sample complexity rates for generalization error incurred by optimizing the empirical squared error loss.\n\nClarity: Very dense; could benefit from considerably more exposition.\n\nOriginality: afaik original. Techniques seem to be inspired by a recent paper by Montanelli and Du (2017).\n\nSignificance: unclear.\n\nPros and cons: \nThis is a theory paper that focuses solely on approximation properties of deep networks. Since there is no discussion of any learning procedure involved, I would suggest that the use of the phrase ""deep learning"" throughout the paper be revised.\n\nThe paper is dense and somewhat inaccessible. Presentation could be improved by adding more exposition and comparisons with existing results.\n\nThe generalization bounds in Section 4 are given for an ideal estimator which is probably impossible to compute.', 'Summary:\n========\nThe paper presents rates of convergence for estimating nonparametric functions in Besov\nspaces using deep NNs with ReLu activations. The authors show that deep Relu networks,\nunlike linear smoothers, can achieve minimax optimality. Moreover, they show that in a\nrestricted class of functions called mixed Besov spaces, there is significantly milder\ndependence on dimensionality. Even more interestingly, the Relu network is able to\nadapt to the smoothness of the problem.\n\nWhile I am not too well versed on the background material, my educated guess is that the\nresults are interesting and relevant, and that the analysis is technically sound.\n\n\n\nDetailed Comments:\n==================\n\n\nMy main criticism is that the total rate of convergence (estimation error + approximation\nerror) has not been presented in a transparent way. The estimation error takes the form\nof many similar results in nonparametric statistics, but the approximation error is\ngiven in terms of the parameters of the network, which depends opaquely on the dimension\nand other smoothness parameters. It is not clear which of these terms dominate, and\nconsequently, how the parameters W, L etc. should be chosen so as to balance them.\n\n\nWhile the mixed Besov spaces enables better bounds, the condition appears quite strong.\nIn fact, the lower bound is better than for traditional Holder/Sobolev classes. Can you\nplease comment on how th m-Besov space compares to Holder/Sobolev classes? Also, can\nyou similiarly define mixed Holder/Sobolev spaces where traditional linear smoothers\nmight achieve minimax optimal results?\n\n\nMinor:\n- Defn of Holder class: you can make this hold for integral beta if you define m to be\nthe smallest integer less than beta (e.g. beta=7, m=6). Imo, this is standard in most\ntexts I have seen.\n- The authors claim that the approximation error does not depend on the dimensionality\n  needs clarification, since N clearly depends on the dimension. If I understand\n  correctly, the approximation error is in fact becoming smaller with d for m-Besov\n  spaces (since N is increasing with d), and what the authors meant was that the\n  exponential dependnence on d has now been eliminated. Is this correct?\n\nOther\n- On page 4, what does the curly arrow notation mean?\n- Given the technical nature of the paper, the authors have done a good job with the\n  presentation. However, in some places the discussion is very equation driven. For e.g.\n  in the 2nd half of page 4, it might help to explain many of the quantities presented in\n  plain words.\n\n\n\nConfidence: I am reasonably familiar with the nonparametric regression literature, but\nnot very versed on the deep learning theory literature. I did not read the proofs in\ndetail.\n']","[-20, 20, 60]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper (interesting idea, clearly written), they express significant concerns and questions about the results. The reviewer points out critical issues they can't reconcile and questions the validity of some broad claims made in the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms as questions or areas needing clarification rather than direct attacks. They use phrases like 'I'm left with several questions' and 'I don't see how to reconcile these ideas' which maintain a polite tone while expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and originality, but also points out several areas for improvement. The reviewer notes that the paper makes two significant contributions and is likely original. However, they also mention that the significance is unclear, the paper is dense and could benefit from more exposition, and there are some concerns about terminology usage. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism without using harsh language. They balance positive comments ('original', 'contributions') with areas for improvement ('could benefit from considerably more exposition', 'dense and somewhat inaccessible') in a respectful manner. The reviewer also uses phrases like 'I would suggest' which adds to the politeness of the critique."", ""The sentiment score is 60 (positive) because the reviewer starts by summarizing the paper's contributions positively, stating that the results are 'interesting and relevant' and the analysis is 'technically sound'. However, they do have some criticisms and suggestions for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'My main criticism is...'), and acknowledges their own limitations ('While I am not too well versed on the background material...'). They also compliment the authors on their presentation given the technical nature of the paper. The reviewer maintains a professional and courteous tone throughout, offering suggestions and asking questions rather than making demands.""]"
"[""This is an interesting paper which proposes a novel angle on the problem of learning long-term dependencies in recurrent nets. The authors argue that most of the action should be in the imaginary part of the eigenvalues of the Jacobian J=F' of the new_state = old_state + epsilon F(old_state, input) incremental type of recurrence, while the real part should be slightly negative. If they were 0 the discrete time updates would still not be stable, so slightly negative (which leads to exponential loss of information) leads to stability while making it possible for the information decay to be pretty slow. They also propose a gated variant which sometimes works better. \n\nThis is similar to earlier work based on orthogonal or unitary Jacobians of new_state = H(old_state,input) updates, since the Jacobian of H(old_state,input) = old_state + epsilon F( old_state,input) is I + epsilon F'. In this light, it is not clear why the proposed architecture would be better than the partially orthogonal / unitary variants previously proposed. My general concern with this this type of architecture is that they can store information in 'cycles' (like in fig 1g, 1h) but this is a pretty strong constraint. For example, in the experiments, the authors did not apparently vary the length of the sequences (which would break the trick of using periodic attractors to store information). In practical applications this is very important. Also, all of the experiments are with classification tasks with few categories (10), i.e., requiring only storing 4 bits of information. Memorization tasks requiring to store many more bits, and with randomly varying sequence lengths, would better test the abilities of the proposed architecture.\n\n"", 'In this paper, the authors provide a new approach to analyze the behavior of\nRNNs by relating the RNNs with ODE numerical schemes. They provide analysis on\nthe stability of forward Euler scheme and proposed an RNN architecture called\nAntisymmetricRNN to solve the gradient exploding/vanishing problem. \n\nThe paper is well presented although more recent works in this direction\nshould be cited and discussed. Also, some important issues are omitted and not\nexplained. \nFor example, the analysis begins with ""RNNs with feedback"" rather than vanilla\nRNN, since vanilla RNN does not have the residual structure as eq(3). The\nauthors should note that clearly in the paper. \n\nAlthough there are previous works relating ResNets with ODEs, such as [1],\nthis paper is original as it is the first work that relates the stability of\nODE numerical scheme with the gradient vanishing/exploding issues in RNNs. \n\nIn general, this paper provides a novel approach to analyze the gradient\nvanishing/exploding issue in RNNs and provides applicable solutions, thus I\nrecommend to accept it. \n\n\nDetailed comments:\n\nThe gradient exploding/vanishing issue has been extensively studied these\nyears and more recent results should be discussed in related works.\nAuthor mentioned that existing methods ""come with significant computational\noverhead and reportedly hinder representation power of these models"". However\nthis is not true for [2] which achieves full expressive power with\nno-overhead. \nIt is true that ""orthogonal weight matrices alone does not prevent exploding\nand vanishing gradients"", thus there are architectural approaches that can\nbound the gradient norm by constants [3]. \n\nThe authors argued that the critical criterion is important in preserving the\ngradient norm. However, later on added a diffusion term to maintain the\nstability of forward Euler method. Thus the gradient will vanish\nexponentially w.r.t. time step t as: (1-\\gamma)^t. Could the authors provide\nmore detailed analysis on this issue? \n\nSince eq(3) cannot be regarded as vanilla RNN, it would be better begin the\nanalysis with advanced RNN architectures that fit in this form, such as\nResidual RNN, Statistical Recurrent Units and Fourier Recurrent Units. \n\nWhy sharing the weight matrix of gated units and recurrent units? Is there any\nother reason to do this other than reducing the number of parameters?\n\nMore experiment should be conducted on real applications of RNN, such as\nlanguage model or machine translation. \n\n\n[1] Yiping Lu, Aoxiao Zhong, Quanzheng Li, and Bin Dong. Beyond finite layer\nneural networks: Bridging deep architectures and numerical differential\nequations. In ICML, pp. 3276–3285, 2018.  \n\n[2] Zhang, Jiong, Qi Lei, and Inderjit S. Dhillon. ""Stabilizing Gradients for\nDeep Neural Networks via Efficient SVD Parameterization."" In ICML, pp.\n5806-5814, 2018.\n\n[3] Zhang, Jiong, Yibo Lin, Zhao Song, and Inderjit S. Dhillon. ""Learning Long\nTerm Dependencies via Fourier Recurrent Units."" In ICML, pp. 5815-5823, 2018. \n', 'This paper introduces antisymmetric RNN, a novel RNNs architecture that is motivated through ordinary differential equation (ODE) framework. Authors consider a first order ODE and the RNN that results from the discretization of this ODE. They show how the stability criteria with respect to perturbation of  the initial state results in an ODE  in a trainability criteria for the corresponding  RNN. This criteria ensures that there are  no exploding/vanishing gradients. Authors then propose a specific parametrization, relying on antisymmetric matrix to ensure that the stability/trainability criteria is respected. They also propose a gated-variant of their architecture.  Authors evaluate their proposal on pixel-by-pixel MNIST and CIFAR10 where they show they can outperforms an LSTM.\n\nThe paper is well-written and pleasant to read. However, while the authors argue that their architecture allows to mitigate vanishing/exploding gradient, there is no empirically verification of this claim. In particular, it would be nice to visualize how the gradient norm changes as the gradient is  backpropagated in time, compare the gradient flows of Antisymmetric RNN with a LSTM or report the top eigenvalue of the jacobian for the different models.\n\nIn addition,  the analysis for the antisymmetric RNN assumes no input is given to the model. It is not clear to me how having an input at each timestep affects those results?\n\nA few more specific questions/remarks:\n-\tExperimentally, authors find that the gated antisymmetric RNN sometime outperforms its non-gated counterpart. However, one motivation for the gate mechanism is to better control the gradients flow. It is unclear to me what is the motivation of using gate for the antisymmetric RNN ?\n-\tas the proposed RNN relies on a antisymmetric matrix to represent the hidden-to-hidden transition matrix, which has less degree of liberty, can we expect the antisymmetric RNN to have same expressivity as a standard RNN. In particular, how easily can an antisymmetric RNN forgets information ?\n-\tOn the pixel-by-pixel MNIST, authors report the Arjosky results for the LSTM baseline.\nNote that some papers reported better performance for the LSTM baseline such as Recurrent Batch Norm (Cooijman et al., 2016) .\n\nAntisymmetric RNN appears to be well-motived architecture and seems to outperforms previous RNN variants that also aims at solving exploding/vanishing gradient problem. Overall I lean toward acceptance, although I do think that adding an experiment explicitly showing that the gradient does not explode/vanish would strengthen the paper. \n\n\n* Revision\n\nThanks for your response,  the paper new  version address my main concerns, I appreciate the new experiment looking at the eigenvalues of the  end-to-end Jacobian which clearly shows the advantage of the AntisymmetricRNN.\n']","[20, 50, 70]","[50, 75, 80]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and acknowledges its novel approach. However, they also express concerns and suggest improvements, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits before offering constructive criticism. They avoid harsh or dismissive language, instead framing their concerns as suggestions for improvement. The reviewer maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer recommends accepting the paper and acknowledges its novelty and originality. However, they also point out several areas for improvement and additional work needed. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or questions rather than direct attacks. They use phrases like 'Could the authors provide...?' and 'It would be better...' which maintain a constructive tone. The reviewer also balances critique with praise, showing respect for the authors' work while providing valuable feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, stating it is 'well-written and pleasant to read' and that they 'lean toward acceptance'. They also praise the architecture as 'well-motivated' and note that it outperforms previous variants. However, it's not 100 as they do suggest some improvements and have a few concerns. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'it would be nice to' and 'I appreciate' which contribute to a polite tone. The reviewer also thanks the authors for their response in the revision section, showing further courtesy.""]"
"['This paper proposed a post-processing rejection sampling scheme for GANs, named Discriminator Rejection Sampling (DRS), to help filter ‘good’ samples from GANs’ generator. More specifically, after training GANs’ generator and discriminator are fixed; GANs’ discriminator is further exploited to design a rejection sampler, which is used to reject the ‘bad’ samples generated from the fixed generator; accordingly, the accepted generated samples have good quality (better IS and FID results). Experiments of SAGAN model on GMM toys and ImageNet dataset show that DRS helps further increases the IS and reduces the FID.\n\nThe paper is easy to follow, and the experimental results are convincing. However, I am curious about the follow questions.\n\n(1)\tBesides helping generate better samples, could you list several other applications where the proposed technique is useful? \n\n(2)\tIn the last paragraph of Page 4, I don’t think the presented Discriminator Rejection Sampling “addresses” the issues in Sec 3.2, especially the first paragraph of Page 5.\n\n(3)\tThe hyperparameter gamma in Eq. (8) is of vital importance for the proposed DRS. Actually, it is believed the key to determining whether DRS works or not. Detailed analysis/experiments about hyperparameter gamma are considered missing. \n', ""his paper assumes that, in a GAN, the generator is not perfect and some information is left in the discriminator, so that it can be used to 'reject' some of the 'fake' examples produced by the generator.\n\nThe introduction, problem statement and justification for rejection sampling are excellent, with a level of clarity that makes it understandable by non expert readers, and a wittiness that makes the paper fun to read. I assume this work is novel: the reviewer is more an expert in rejection than in GANs, and is aware how few publications rely on rejection.\n\nHowever, the authors fail to compare their algorithm to a much simpler rejection scheme, and a revised version should discuss this issue.\nLet's jump to equation (8): compared to a simple use of the dicriminator for rejection, it adds the term under the log.\nThe basic rejection equation would read F(x) = D*(x) - gamma and one would adjust the threshold gamma to obtain the desired operating point. I am wondering why no comparison is provided with basic rejection? \n\nLet me try to understand the Gaussian mixture experiment, as the description is ambiguous:\n- GAN setting: 10K examples are generated and reported in figure 3?\n- DRS setting: 10K examples are generated, and submitted to algorithm in figure 1. For each batch, a line search sets gamma so that 95% of the examples are accepted. Thus only 9.5K are reported in figure 3.\n- What about basic rejection using F(x) = D*(x) - gamma: how does it compare to DRS at the same 95% accept?\n\nIf this is my understanding, then the comparison in Figure 3 in unfair, as DRS is allowed to pick and choose.\nFor completeness, basic rejection should also be added.\n\nGoing back to Eq.(8), one realizes that the difference between DRS rejection and basic rejection may be negligible.\nFirst order Taylor expansion of log(1-x) that would apply to the case where the rejection probability is small yields:\nF(x) = (D*(x) - D*_M) + exp(D*(x) - D*_M) \n\nx+ exp(x) is monotonous, so thresholding over it is the same as thresholding over x: back to basic rejection!"", ""This paper proposes a rejection sampling algorithm for sampling from the GAN generator. Authors establish a very clear connection between the optimal GAN discriminator and the rejection sampling acceptance probability. Then they explain very clearly that in practice the connection is not exact, and propose a practical algorithm. \n\nExperimental results suggest that the proposed algorithm helps the increase the accuracy of the generator, measured in terms of inception score and Frechet inception distance. \n\nIt would be interesting though to see if the proposed algorithm buys anything over a trivial rejection scheme such as looking at the discriminator values and rejecting the samples if they fall below a certain threshold. This being said, I do understand that the proposed practical acceptance ratio in equation (8) is 'close' to the theoretically justified acceptance ratio. Since in practice the learnt discriminator is not exactly the ideal discriminator D*(x), I think it is super okay to add a constant and optimize it on a validation set. (Equation (7) is off anyways since in practice the things (e.g. the discriminator) are not ideal). But again, I do think it would make the paper much stronger to compare equation (8) with some other heuristic based rejection schemes.\n\n ""]","[50, -20, 80]","[80, 60, 90]","[""The sentiment score is 50 (moderately positive) because the reviewer starts by summarizing the paper's content neutrally, then states that 'The paper is easy to follow, and the experimental results are convincing.' This indicates a generally positive view, though not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their questions as curiosities rather than criticisms ('I am curious about the follow questions'). They also acknowledge the paper's strengths before presenting their questions. The use of phrases like 'could you list' and 'Detailed analysis/experiments... are considered missing' rather than more direct criticisms contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer praises the introduction and clarity of the paper, they also point out significant shortcomings in the methodology and comparisons. The reviewer suggests that the authors failed to compare their algorithm to a simpler rejection scheme and questions the fairness of the comparison in Figure 3. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The reviewer also frames their concerns as questions and suggestions rather than harsh criticisms, maintaining a constructive tone. The use of phrases like 'Let me try to understand' and 'I am wondering why' contribute to the polite tone while still effectively communicating the reviewer's concerns."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, praising its clarity and the connection it establishes between GAN discriminators and rejection sampling. The reviewer also notes that experimental results suggest the proposed algorithm improves generator accuracy. The score is not 100 because the reviewer suggests an additional comparison that would make the paper stronger. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the authors' work positively and frame their suggestion for improvement in a considerate manner, using phrases like 'I do understand' and 'I think it is super okay'. The reviewer maintains a professional and supportive tone, even when proposing additional work.""]"
"['This paper proposes to construct multiple classification tasks from unsupervised data.\n\nQuality:\nThe detail of the proposed method is not mathematically presented and its performance is not theoretically analyzed.\nAlthough the proposed method is empirically shown to be superior to other approaches, the motivation is not clearly presented.\nHence the overall quality of this paper is not high.\n\nClarity:\nThe readability of this paper is not high as it is redundant or unclear at several points.\nFor example, Sections 2.1, 2.3 and Sections 2.2, 2.4 can be integrated, respectively, and more mathematical details can be included instead.\n\nOriginality:\nThe proposal of constructing meta-learning based on unsupervised learning seems to be original.\n\nSignificance:\n- The motivation is not clear. The proposed method artificially generates a number of classification tasks. But how to use such classifiers for artificially generated labels in real-world applications is not motivated.\n  It is better to give a representative application, to which the proposed method fits.\n- There is no theoretical analysis on the proposed method.\n  For example, why is the first embedding step required? Clustering can be directly performed on the give dataset D = {x_i}.\n- Although the paper discusses using unsupervised learning for meta-learning, only k-means is considered in the proposed method.\n  There are a number of types of unsupervised learning, including other clustering algorithms and other tasks such as outlier detection, hence analyzing them is also interesting.\n- The proposed method includes several hyper-parameters. But how to set them in practice it not clear.\n\nPros:\n- An interesting approach to meta-learning is presented.\n\nCons:\n- Motivation is not clear.\n- There is no theoretical analysis.\n', 'In this paper, the task of performing meta-learning based on the unsupervised dataset is considered. The high-level idea is to generate \'pseudo-labels\' via clustering of the given dataset using existing unsupervised learning techniques. Then the meta-learning algorithm is trained to easily discriminate between such labels. This paper seems to be tackling an important problem that has not been addressed yet to my knowledge. While the proposed method/contribution is quite simple, it possesses great potential for future applications and deeper exploration. The empirical results look strong and tried to address important aspects of the algorithm. The writing was clear and easy to follow. I especially liked how the authors tried to exploit possible pitfalls of their experimental design. \n\nMinor comments and questions:\n- Although the problem of interest is non-trivial and important, the proposed algorithm can be seen as just a naive combination of clustering and meta-learning. It would have been great to see some clustering algorithm that was specifically designed for this type of problem. Especially, the proposed CACTUs algorithm relies on sampling without replacement from the clustered dataset in order to enforce ""balance"" of the labels among the generated task. This might be leading to suboptimal results since the popularity of each cluster (i.e., how much it represents the whole dataset) is not considered. \n\n- CACTUs seems to be relying on having random scaling of the k-means algorithm in order to induce diversity on the set of partitions being generated. I am a bit skeptical about the effectiveness of such a method for diversity. If this holds, it would be interesting to see the visualization of such a concept.\n\n- Although only MAML was considered as the meta-learning algorithm, it would have been nice to consider one or more candidates to show that the proposed framework is generalizable. Still, I think the experiment is persuasive enough to expect that the algorithm would work well at practice.\n\n- Would there be a trivial generalization of the algorithm to semi-supervised learning?  \n\n-------\n\nI am satisfied with the author\'s response and changes they made to the text. I still think the paper brings significant contributions to the area, by showing that even generating the pseudo-tasks via unsupervised clustering method allows the meta-learning to happen.  ', 'The paper proposes to employ metalearning techniques for unsupervised tasks. The authors construct tasks in an automatic way from unlabeled data and run meta-learning over the constructed tasks.\n\nAlthough the paper presents a novel approach and the experiments included in the work show promising results, in my opinion, the paper is still not mature. There are some importants problems:\n* The motivation of the paper is weak. The authors include the problem statement as well as the definitions used in the paper without knowing what is the goal of the proposed algorithm. A clear example of a real problem where the proposed framework could be applied is necessary to motivate the work.\n* The paper is difficult to read and follow. The paper is composed by a set of parts without many links. This makes difficult to read the paper to not very experienced readers. A running example could be useful to increase the readability of the work. In my opinion, the paper contains too much material for the length of the conference. In fact, some important information has been moved to the appendices. \n*Experimental section is specially hard to follow. The authors want to solve too many questions in a short space. Comparisons with other related papers should be included. \n\n', 'summary\nThe goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. SoTA meta-learning frameworks (MAML and ProtoNet) typically require rather large labeled datasets and hand-specified task distributions to define a sequence of tasks on which the algorithms are trained on. This paper proposes to unsupervised generate the sequence of tasks using multiple partitions as pseudo labels via k-means and other clustering variants on the embedding space. Empirical experiments show the benefit of the meta-learning on the M-way K-shot image classification tasks.  Also, “sampling a partition from U(P)” on page 4, the U(P) notation seems not defined.\n\nEvaluation\n- The writing and presentation of the paper are in general well carried, except some part seems a little unclear, taking me quite a while to understand. For example,  in the “task generation for meta-learning” paragraph on page 3, the definition of task-specific labels (l_n) is puzzling to me at first glance.     \n\n- The proposed task construction in an unsupervised manner for the meta-learning framework is indeed simple and novel. \n\n- The empirical experiments are thorough and well-conducted with good justifications. The benefit of unsupervised meta-learning compared to simply supervised learning on the few-shot downstream tasks is shown in Table 1 and 2; Different embedding techniques have also been studied; the results of Oracle upper bound are also presented; task construction ablation is also shown. \n\n- Unsupervised meta-learning consists of multiple components such as learning embedding space, clustering methods, and various choices within the meta-learning frameworks. This together consumes a lot of hyper-parameters and the choice can somehow seem heuristic.\n\nConclusion\n- In general, I like this paper especially the empirical analysis section. Therefore, I vote for accepting this paper.\n']","[-50, 80, -50, 80]","[0, 90, 20, 70]","[""The sentiment score is -50 because the review is generally negative, pointing out several weaknesses in the paper such as lack of clear motivation, theoretical analysis, and mathematical presentation. However, it's not entirely negative as it acknowledges the proposal's originality and describes it as 'interesting'. The politeness score is 0 (neutral) because the reviewer uses direct and factual language without being overtly polite or rude. The critique is presented in a professional manner, listing both pros and cons, but doesn't use particularly courteous language or harsh criticism."", ""The sentiment score is 80 because the reviewer expresses a very positive view of the paper, praising its importance, potential, and strong empirical results. They use phrases like 'great potential', 'strong' results, and 'clear and easy to follow' writing. The only reason it's not higher is due to some minor criticisms and suggestions for improvement. The politeness score is 90 because the reviewer uses consistently respectful and constructive language. They offer criticisms in a gentle way, using phrases like 'it would have been great to see' and 'I am a bit skeptical' rather than harsh or dismissive language. The reviewer also explicitly states their satisfaction with the authors' response in the final paragraph, showing a collaborative and courteous approach to the review process."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's novel approach and promising results, they also state that the paper is 'not mature' and list several important problems. The overall tone is more negative than positive, but not entirely negative. The politeness score is 20 because the reviewer uses polite language such as 'in my opinion' and provides constructive criticism. However, the directness of the criticism and the lack of positive reinforcement prevent a higher politeness score. The reviewer maintains a professional tone throughout, avoiding rudeness while also not being overly deferential."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper, stating 'I like this paper especially the empirical analysis section' and concluding with 'I vote for accepting this paper.' The reviewer also highlights several positive aspects, such as the novelty of the approach and the thoroughness of the experiments. The politeness score is 70 (polite) as the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths while also providing gentle critiques, such as noting some unclear parts and the potential heuristic nature of hyperparameter choices. The reviewer maintains a professional tone without using overly formal or informal language.""]"
"['In this submission, the authors investigate using recurrent networks in distributed DQN with prioritized experience replay on the Atari and DMLab benchmarks. They experiment with several strategies to initialize the recurrent state when processing a sub-sequence sampled from the replay buffer: the best one consists in re-using the initial state computed when the sequence was originally played (even if it may now be outdated) but not doing any network update during the first k steps of the sequence (“burn-in” period). Using this scheme with LSTM units on top of traditional convolutional layers, along with a discount factor gamma = 0.997, leads to a significant improvement on Atari over the previous state-of-the-art, and competitive performance on DMLab.\n\nThe proposed technique (dubbed R2D2) is not particularly original (it is essentially “just” using RNNs in Ape-X), but experiments are thorough, investigating several important aspects related to recurrence and memory to validate the approach. These findings are definitely quite relevant to anyone using recurrent networks on RL tasks. The results on Atari are particularly impressive and should be of high interest to researchers working on this benchmark. The fact that the same network architecture and hyper-parameters also work pretty well on DMLab is encouraging w.r.t. the generality of the method.\n\nI do have a couple of important concerns though. The first one is that a few potentially important changes were made to the “traditional” settings typically used on Atari, which makes it difficult to perform a fair comparison to previously published results. Using gamma = 0.997 could by itself provide a significant boost, as hinted by results from “Meta-Gradient Reinforcement Learning” (where increasing gamma improved results significantly compared to the usual 0.99). Other potentially impactful changes are the absence of reward clipping (replaced with a rescaling scheme) and episodes not ending with life loss: I am not sure whether these make the task easier or harder, but they certainly change it to some extent (the “despite this” above 5.1 suggests it would be harder, but this is not shown empirically). Fortunately, this concern is partially alleviated by Section 6 that shows feedforward networks do not perform as well as recurrent ones, but this is only verified on 5 games: a full benchmark comparison would have been more reassuring (as well as running R2D2 with more “standard” Atari settings, even if it would mean using different hyper-parameters on DMLab).\n\nThe second important issue I see is that the authors do not seem to plan to share their code to reproduce their results. Given how time consuming and costly it is to run such experiments, and all potentially tricky implementation details (especially when dealing with recurrent networks), making this code available would be tremendously helpful to the research community (particularly since this paper claims a new SOTA on Atari). I am not giving too much weight to this issue in my review score since (unfortunately) the ICLR reviewer guidelines do not explicitly mention code sharing as a criterion, but I strongly hope the authors will consider it.\n\nBesides the above, I have a few additional small questions:\n1. “We also found no benefit from using the importance weighting that has been typically applied with prioritized replay”: this is potentially surprising since this could be “wrong”, mathematically speaking. Do you think this is because of the lack of stochasticity in the environments? (I know Atari is deterministic, but I am not sure about DMLab)\n2. Fig. 3 (left) shows R2D2 struggling on some DMLab tasks. Do you have any idea why? The caption of Table 3 in the Appendix suggests the absence of specific reward clipping may be an issue for some tasks, but have you tried adding it back? I also wonder if maybe training a unique network per task may make DMLab harder, since IMPALA has shown some transfer learning occurring between DMLab tasks? (although the comparison might be to the “deep experts” version of IMPALA — this is not clear in Fig. 3 — in which case this last question would be irrelevant)\n3. In Table 1, where do the IMPALA (PBT) numbers on DMLab come from? Looking at the current arxiv version of their paper, their Fig. 4 shows it goes above 70% in mean capped score, while your Table 1 reports only 61.5%. I also can’t find a median score being reported on DMLab in their paper, did you try to compute it from their Fig. 9? And why don’t you report their results on Atari?\n4. Table 4’s caption mentions “30 no-op starts” but you actually used the standard “random starts” setting, right? (not a fixed number of 30 no-ops)\n\nAnd finally a few minor comments / suggestions:\n- In the equation at bottom of p. 2, it seems like theta and theta- (the target network) have been accidentally swapped (at least compared to the traditional double DQN formula)\n- At top of p. 3 I guess \\bar{delta}_i is the mean of the delta_i’s, but then the index i should be removed\n- In Fig. 1 (left) please clarify which training phase these stats are computed on (whole training? beginning / middle / end?)\n- p. 4, “the true stored recurrent states at each step”: “true” is a bit misleading here as it can be interpreted as “the states one would obtain by re-processing the whole episode from scratch with the current network” => I would suggest to remove it, or to change it (e.g. “previously”). By the way, I think it would have been interesting to also compare to these states recomputed “from scratch”, since they are the actual ground truth.\n- I think you should mention in Table 1’s caption that the PBT IMPALA is a single network trained to solve all tasks\n- Typo at bottom of p. 7, “Indeed, Table 1 that even...”\n\nUpdate: score updated to 8 (from 7) following discussion below', 'Summary: \nLeveraging on recent advances on distributed training of RL agents, the paper proposes the analysis of RNN-based RL agents with experience replay (i.e., integrating the time dependencies through RNN). Precisely, the authors empirically compare a state-of-the-art training strategy (called zero start state) with three proposed training strategies (namely; zero-state with burn-in, stored-state and stored-state with burn-in). By comparing these different strategies through a proposed metric (Q-value discrepancy), the authors conclude on the effectiveness of the stored-state with burn-in strategy which they consider for the training of their proposed Recurrent Replay Distributed DQN (R2D2) agent. \n\nThe proposed analysis is well-motivated and has lead to significant results w.r.t. the state-of-the-art performances of RL agents.\n\nMajor concerns: My major concerns are three-fold:\n- The authors do not provide enough details about some ""informal"" experiments which are sometimes important to convince the reader about the relevance of the suggested insights (e.g., line 3 page 5). Beyond this point, the paper is generally hard to follow and reorganizing some sections (e.g., sec. 2.3 should appear after sec. 3 as it contains a lot of technical details) would certainly make the reading of the paper easier.\n- Hausknecht & Stone (2015) have proposed two training strategies (zero-state and Replaying whole episode trajectories see sec. 3 page 3). The authors should clarify why they did not considered the other states in their study.\n- The authors present results (mainly, fig. 2 and fig. 3) suggesting that the proposed R2D2 agent outperform the agents Ape-X and IMPALA, where R2D2 is trained using the aforementioned stored-state with burn-in strategy. It is not clear which are the considered training strategies adopted for the (compared to) state-of-the-art agents (Ape-X and IMPALA). The authors should clarify more precisely this point.\n\nMinor concerns: \n- The authors compare the different strategies only in terms of their proposed Q-value discrepancy metric. It could be interesting to consider other metrics in order to evaluate the ability of the methods on common aspects.\n', 'This paper investigates the use of recurrent NNs in distributted RL settings as a clear improvement of the feed-forward NN variations in partially observed environments. The authors present ""R2DR"" algorithm as a A+B approach from previous works (actually, R2D2 is an Ape-X-like agent using LTSM), as well as an empirical study of a number of ways for training RNN from replay in terms of the effects of parameter lag (and potential alleviating actions) and sample-afficiency. The results presented show impressive performance in Atari-57 and DMLab-30 benchmarks.\n\nIn summary, this is a very nice paper in which the authors attack a challenging task and empirically confirm that RNN agents generalise far better when scaling up through parallelisation and distributed training allows them to benefit from huge experience. The results obtained in ALE and DMLab improves significantly upon the SOTA works, showing that the trend-line in those benchmarks seem to have been broken. \n\nFurthermore, the paper presents their approach/analyses in a well-structured manner and sufficient clarity to retrace the essential contribution. The background and results are well-contextualised with relevant related work. \n\nMy only major comments are that I’m a bit skeptical about the lack of a more thorough (theoretical) analysis supporting their empirical findings (what gives me food for thought is that LSTM helps that much on even fully observable games such as Ms. Pacman); and the usual caveats regarding evaluation: evaluation conditions aren\'t well standardized so the different systems (Ape-X, IMPALA, Reactor, Rainbow, AC3 Gorilla, C51, etc.) aren\'t all comparable. These sort of papers would benefit from a more formal/comprehensive evaluation by means of an explicit enumeration of all the dimensions relevant for their analysis: the data, the knowledge, the software, the hardware, manipulation, computation and, of course, performance, etc. However only some of then are (partially) provided.   \n\n']","[70, 50, 80]","[80, 70, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, noting its thorough experiments, impressive results, and relevance to the field. They state the findings are 'definitely quite relevant' and the results are 'particularly impressive'. However, they also raise 'a couple of important concerns', which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively and framing criticisms constructively. They use phrases like 'I strongly hope the authors will consider' and 'I have a few additional small questions' which maintain a collegial tone. The reviewer also provides detailed, helpful feedback, which is a form of politeness in academic contexts."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's well-motivated analysis and significant results, but also expresses major concerns. The positive aspects are balanced by the criticisms, resulting in a moderately positive overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing concerns as suggestions for improvement rather than harsh criticisms. They use phrases like 'The authors should clarify' and 'It could be interesting to consider' which maintain a constructive tone. The reviewer also acknowledges the strengths of the paper before presenting concerns, which is a polite approach to feedback."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'very nice' and praises its well-structured approach, clarity, and significant improvements over state-of-the-art works. The reviewer also highlights the paper's impressive performance and breaking of trend-lines in benchmarks. The score is not 100 due to some skepticism about the lack of theoretical analysis and concerns about evaluation conditions. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' achievements and providing constructive feedback. The reviewer balances praise with gentle criticism, using phrases like 'My only major comments are' to soften the critique. The score is not higher as the review maintains a professional tone without being overly deferential.""]"
"['This paper addresses black-box classifier attacks in the “hard-label” setting, meaning that the only information the attacker has access to is single top-1 label predictions. Relative to even the standard black-box setting where the attacker has access to the per-class logits or probabilities, this setting is difficult as it makes the optimization landscape non-smooth. The proposed approach reformulates the optimization problem such that the outer-loop optimizes the direction using approximate gradients, and the inner-loop estimates the distance to the nearest attack in a given direction. The results show that the proposed approach successfully finds both untargeted and targeted adversarial examples for classifiers of various image datasets (including ImageNet), usually with substantially better query-efficiency and better final results (lower distance and/or higher success rate) than competing methods.\n\n=====================================\n\nPros:\n\nVery well-written and readable paper with good background and context for those (like me) who don’t closely follow the literature on adversarial attacks. Figs. 1-3 are nice visual aids for understanding the problem and optimization landscape.\n\nNovel formulation and approach that appears to be well-motivated from the literature on randomized gradient-free search methods. Novel theoretical analysis in Appendix that generalizes prior work to approximations (although, see notes below).\n\nGood empirical results showing that the method is capable of query-efficiently finding attacks of classifiers on real-world datasets including ImageNet. Also shows that the model needn’t be differentiable to be subject to such attacks by demonstrating the approach on a decision-tree based classifier. Appears to compare to and usually outperform appropriate baselines from prior work (though I’m not very familiar with the literature here).\n\n=====================================\n\nCons/questions/suggestions/nitpicks:\n\nEq 4-5: why \\texttt argmin? Inconsistent with other min/maxes.\n\nEq 4-5: Though I understood the intention, I think the equations are incorrect as written: argmin_{\\lambda} { F(\\lambda) } of a binary-valued function F would produce the set of all \\lambdas that make F=0, rather than the smallest \\lambda that makes F=1. I think it should be something like:\n\nmin_{\\lambda>0} {\\lambda}\ns.t. f(x_0+\\lambda \\theta/||\\theta||) != y_0\n\nSec 3.1: why call the first search “fine-grained”? Isn’t the binary search more fine-grained? I’d suggest changing it to “coarse-grained” unless I’m misunderstanding something.\n\nAlgorithm 2: it would be nice if this included all the tricks described as “implementation details” in the paragraph right before Sec. 4 -- e.g. averaging over multiple sampled directions u_t and line search to choose the step size \\eta. These seem important and not necessarily obvious to me.\n\nAlgorithm 2: it could be interesting to show how performance varies with number of sampled directions per step u_t.\n\nSec: 4.1.2: why might your algorithm perform worse than boundary-attack on targeted attacks for CIFAR classifiers? Would like to have seen at least a hypothesis on this.\n\nSec 6.3 Theorem 1: I think the theorem statement is a bit imprecise. There is an abuse of big-O notation here -- O(f(n)) is a set, not a quantity, so statements such as \\epsilon ~ O(...) and \\beta <= O(...) and “at most O(...)” are not well-defined (though common in informal settings) and the latter two are redundant given the meaning of O as an upper bound. The original theorem from [Nesterov & Spokoiny 2017] that this Theorem 1 would generalize doesn’t rely on big-O notation -- I think following the same conventions here might improve the theorem and proof.\n\n=====================================\n\nOverall, this is a good paper with nice exposition, addressing a challenging but practically useful problem setting and proposing a novel and well-motivated approach with strong empirical results.', 'This paper proposed a reformulation of objective function to solve the hard-label black-box attack problem. The idea is interesting and the performance of the proposed method seem to be capable of finding adversarial examples with smaller distortions and less queries compared with other hard-label attack algorithms. \n\nThis paper is well-written and clear.\n\n==============================================================================================\nQuestions\n\nA. Can it be proved the g(theta) is continuous? Also, the theoretical analysis assume the property of Lipschitz-smooth and thus obtain the complexity of number of queries. Does this assumption truly hold for g(theta), when f is a neural network classifiers? If so, how to obtain the Lipschitz constant of g that is used in the analysis sec 6.3? \n\nB. What is the random distortion in Table 1? What initialization technique is used for the query direction in the experiments? \n\nC. The GBDT result on MNIST dataset is interesting. The authors should provide tree models description in 4.1.3. However, on larger dataset, say imagenet, are the tree models performance truly comparable to ImageNet? If the test accuracy is low, then it seems less meaningful to compare the adversarial distortion with that of imagenet neural network classifiers. Please explain. \n\nD. For sec 3.2, it is not clear why the approximation is needed. Because the gradient of g with respect to theta is using equation (7) and theta is already given (from sampling); thus the Linf norm of theta is a constant. Why do we need the approximation? Given that, will there be any problems on the L2 norm case? \n', 'In this paper the authors propose optimizing for adversarial examples against black box models by considering minimizing the distance to the decision boundary.  They show that because this gives real valued feedback, the optimizer is able to find closer adversarial examples with fewer queries.  This would be heavily dependent on the model structure (with more complex decision boundaries likely being harder to optimize) but they show empirically in 4 models that this method works well.\n\nI am not convinced that the black box model setting is the most relevant (and 20k queries is still a fair bit), but this is important research nonetheless.  I generally found the writing to be clear and the idea to be elegant; I think readers will value this paper. \n']","[80, 70, 60]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the review begins with a detailed explanation of the paper's content, followed by a substantial 'Pros' section that highlights the paper's strengths. The reviewer uses phrases like 'Very well-written', 'Novel formulation', and 'Good empirical results'. Even in the 'Cons' section, the criticisms are mostly minor and presented as suggestions for improvement rather than major flaws. The review concludes by calling it 'a good paper with nice exposition'. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would be nice if' and 'I'd suggest' when making recommendations, showing consideration for the authors. The reviewer also acknowledges their own potential lack of expertise in certain areas, which is a polite way to frame criticisms. However, it's not extremely polite as it still directly points out flaws and areas for improvement, which is expected in a peer review."", ""The sentiment score is 70 (positive) because the reviewer starts by describing the paper's idea as 'interesting' and notes that the proposed method shows good performance. They also state that the paper is 'well-written and clear'. These are all positive comments indicating approval of the work. However, it's not an extremely high score because the reviewer does raise several questions and concerns in the latter part of the review. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions rather than criticisms. They use phrases like 'Please explain' and 'Can it be proved' which are polite ways of requesting clarification. The reviewer also acknowledges the positive aspects of the paper before moving on to their questions, which is a courteous approach. The language is professional and constructive throughout, without any harsh or rude phrasing."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, stating that it's 'important research' and that 'readers will value this paper.' They also praise the writing as clear and the idea as elegant. However, it's not extremely positive due to some reservations expressed about the relevance of the black box model setting. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the value of the work while offering constructive criticism. They use phrases like 'I am not convinced' rather than more harsh or dismissive language, maintaining a professional and courteous tone.""]"
"[""The work is a special case of density estimation problems in Statistics, with a use of conditional independence assumptions to learn the joint distribution of nodes. While the work appears to be impressive, such ideas have typically been used in Statistics and machine learning very widely over the years(Belief Propagation,  Topic modeling with anchor words assumptions etc...). This work could be easily extended to multi-class classifications where each node belongs to multiple classes. It would be interesting to know the authors' thoughts on that. The hard classification rule in the paper seems to be too restrictive to be of use in practical scenarios, and soft classification would be a useful pragmatic alternative. \n"", 'This paper proposed how to learn multi-class classifiers without multi-class labels. The main idea is shown in Figure 2, to regard the multi-class labels as hidden variables and optimize the likelihood of the input variables and the binary similarity labels. The difference from existing approaches is also illustrated in Figure 1, namely existing methods have binary classifiers inside multi-class classifiers while the proposed method has multi-class classifiers inside binary classifiers. The application of this technique to three general problem settings is discussed, see Figure 3.\n\nClarity: Overall, it is very well written. I just have two concerns.\n\nFirst, the authors didn\'t discuss the underlying assumption of the proposed method except the additional independence assumption. I think there should be more underlying assumptions. For example, by the definition P(S_{i,j}=0 or 1|Y_i,Y_j) and the optimization of L(theta;X,S), does the ""cluster assumption"" play a role in it? The cluster assumption is popular in unsupervised/semi-supervised learning and metric learning where the X part of training data is in a form of pairs or triples. However, there is no such an assumption in the original supervised multi-class learning. Without figuring out the underlying assumptions, it is difficult to get why the proposed method works and when it may fail.\n\nSecond, there are too many abbreviations without full names, and some of them seem rather important such as KLD and KCL. I think full names of them should be given for the first time they appear. This good habit can make your audience more broad in the long run.\n\nNovelty: As far as I know, the proposed approach is novel. It is clear that Section 3 is original. However, due to the writing style, it is hard to analyze which part in Section 4 is novel and which part is already known. This should be carefully revised in the final version. Moreover, there was a paper in ICML 2018 entitled ""classification from pairwise similarity and unlabeled data"", in which binary classifiers can be trained strictly following ERM without introducing the cluster assumption. The same technique can be used for learning from pairwise dissimilarity and unlabeled data as well as from pairwise similarity and dissimilarity data. I think this paper should be included in Section 2, the related work. \n\nSignificance: I didn\'t carefully check all experimental details but the experimental results look quite nice and promising. Given the fact that the technique used in this paper can be applied to many different tasks in machine learning ranging from supervised learning to unsupervised learning, I think this paper should be considered significant.\n\nNevertheless, I have a major concern as follows. In order to derive Eq. (2), the authors imposed an additional independence assumption: given X_i and X_j, S_{i,j} is independent of all other S_{i\',j\'}. Hence, Eqs. (2) and (3) approximately hold instead of exactly hold. Some comments should be given on how realistic this assumption is, or equivalently, how close (1) and (3) are. One more minor concern: why P(X) appears in (1) and then disappears in (2) and (3) when Y is marginalized?  ', 'In this paper the authors revisit the problem of multi-class classification and propose to use pairwise similarities (more accurately, what they use is the co-occurrence pattern of labels) instead of node labels. Thus, having less stringent requirements for supervision, their framework has broader applicability: in supervised and semi-supervised classification and in unsupervised cross-task transfer learning, among others.\n\nPros: The idea of using pairwise similarities to enable a binary classifier encapsulate a multi-class classifier is neat.\n\nCons: My main gripe is with the conditional independence assumption on pairwise similarities, which the author use to simplify the likelihood down to a cross-entropy. Such an assumption seems too simple to be useful in problems with complicated dependence structure. Yes, the authors conduct some experiments to show that their algorithms achieve good performance in some benchmark datasets, but a careful discussion (if possible, theoretical) of when such an assumption is viable and when it is an oversimplification is necessary (analogous assumptions are used in naive Bayes or variational Bayes for simplifying the likelihood, but those are much more flexible, and we know when they are useful and when not). \n\nSecondly, by using co-occurrence patterns, one throws away identifiability---the (latent) labels are only learnable up to a permutation unless external information is available. This point is not made clear in the paper, and the authors should describe how they overcome this in their supervised classification experiments.\n']","[20, 50, -20]","[50, 80, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the work 'appears to be impressive' and suggests potential extensions, indicating some value in the research. However, they also point out that similar ideas have been widely used before and suggest that the current approach might be too restrictive, tempering the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism. They offer constructive suggestions and invite the authors' thoughts on potential extensions, which is a polite way to encourage improvement. The tone is professional and objective, without any rude or overly critical remarks."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, significance, and promising experimental results. They state it is 'very well written' and should be 'considered significant'. However, they also raise some concerns and suggest improvements, which prevents a higher positive score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I think' and 'I have a concern' instead of more direct or negative language. The reviewer also balances criticism with positive feedback, demonstrating a polite and professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('neat idea'), they express significant concerns about the paper's assumptions and lack of clarity on certain points. The 'Cons' section is more substantial than the 'Pros', indicating overall criticism. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'My main gripe' instead of harsh language, and offer constructive suggestions for improvement rather than outright dismissal. The review maintains a professional tone, balancing critique with recognition of the paper's contributions.""]"
"['\n=================\nUpdated Thoughts\n=================\n\nI was primarily concerned about a lack of analysis regarding the technical contributions moving from AQM to AQM+. The revisions and author comments here have addressed the specific experiments I\'ve asked for and more generally clarified the contributions made as part of AQM+. I\'ve increased my rating to reflect my increased confidence in this paper. Overall, I think this is a good paper and will be interesting to the community.\n\nI also thank the authors for their substantial efforts to revise the paper and address these concerns.\n\n\n===========\nStrengths:\n===========\n\nThe approach is a sensible application of AQM to the GuessWhich setting and results in significant improvements over existing approaches both in terms of quantitative results and qualitative examples. \n\n===========\nConcerns:\n===========\n\n[A] Technical Novelty is Limited Compared to AQM \nThe major departures from the AQM approach claimed in the paper (Section 3.3) are:\n\t[1] the generation of candidate questions through beam search rather than predefined set \n\t[2.1] The approximate answerer being an RNN generating free-form language instead of a binary classifier. \n\t[2.2] Dropping the assumption that \\tilde p(a_t | c, q_t) = \\tilde p (a_t | c, q_t, h_{t-1}). \n\t[3] Estimate approximate information gain using subsets of the class and answer space corresponding to the beam-search generated question set and their corresponding answers.\n\nI have some concerns about these:\n\nFor [1], the original AQM paper explores this exact setting for GuessWhat in Section 5.2 -- generating the top-100 questions from a pretrained RNN question generator via beam search and ranking them based on information gain. From my understand, this aspect of the approach is not novel.\n\nFor [2.1] I disagree that this is a departure from the AQM approach, instead simply an artifact of the experimental setting. The original AQM paper was based in the GuessWhat game in which the answerer could only reply with yes/no/na; however, the method itself is agnostic of this choice. In fact, the detailed algorithm explanation in Appendix A of the AQM paper explicitly discusses the possibility of the answer generator being an RNN model. \n\nGenerally, the modifications to AQM largely seem like necessary, straight-forward adjustments to the problem setting of GuessWhich and not algorithmic advances. That said, the changes make sense and do adapt the method to this more complex setting where it performs quite well!\n\n\n[B] Design decisions are not well justified experimentally\nGiven that the proposed changes seem rather minor, it would be good to see strong analysis of their effect. Looking back at the claimed difference from AQM, there appear to be a few ablations missing:\n- How useful is generating questions? I would have liked to see a comparison to a Q_fix set samples from training. (This corresponds to difference [1] above.)\n- How important is dialog history to the aprxAns model? (This corresponds to difference [2.2] above).\n- How important is the choice to restrict to |C| classes? Figure 4b begins to study this question but conflates the experiment by simultaneously increasing |Q| and |A|. (This correspond to difference [3] above.)\n\n[C] No evaluation of Visual Dialog metrics\nIt would be useful to the community to see if this marked improvement in GuessWhich performance also results in improved ability to predict human response to novel dialogs. I (and I imagine many others) would like to see evaluation on the standard Visual Dialog test metrics. If this introspective inference process improves these metrics, it would significantly strengthen the paper!\n\n[D] No discussion of inference time\nIt would be useful to include discussion of relative inference time. The AQM framework requires substantially more computation than an non-introspective model. Could authors report this relative increase in inference efficiency (say at K=20)? \n\n\n[E] Lack of Comparison to Base AQM\nI would expect explicit comparison to AQM for a model named AQM+ or a discussion on why this is not possible.\n\n\n===========\nMinor Things:\n===========\n\n- I don\'t understand the 2nd claimed contribution from the introduction ""At every turn, AQM+ generates a question considering the context of the previous dialog, which is desirable in practice."" Is this claim because the aprxAns module uses history? \n\n- Review versions of papers often lack polished writing. I encourage the authors to review their manuscript for future versions with an eye for clarity of terminology, even if it means a departure from established notation in prior work. \n\n- The RL-QA qualitative results, are these from non-delta or delta? Is there a difference between the two in terms of interpretability? \n\n===========\nOverview:\n===========\n\nThe modifications made to adapt AQM to the GuessWhich setting presented here as AQM+ seem to be somewhat minor technical contributions. Further, where these difference could be explored in greater detail, there is a lack of analysis. That said, the proposed approach does make significant qualitative and quantitative improvements in the target problem. I\'m fairly on the fence for this paper and look forward to seeing additional analysis and the opinions of other reviewers.\n\n\n\n', 'The goal of this paper is to build a task-oriented dialogue generation system that can continuously generate questions and make a guess about the selected object.\n\nThis paper builds on the top of the previously proposed AQM algorithm and focuses on addressing the limitation of the AQM algorithm, which chooses the question that maximizes mutual information of the class and the current answer, but uses fixed sets of candidate questions/answers/classes.\nThe proposed AQM+, the extension of AQM, is to deal with 1) the natural language questions / answers using RNN as the generator instead of selecting from the candidate pool (RNN as generator) and 2) a large set of candidate classes (from 10 to 9628). \nThe novelty is relatively limited, considering that the model is revised from AQM.\nAlthough this work is incremental, this paper addresses the important issue about the generalization.\n\nThe experiments show that the model achieves good performance in the experiments.\nHowever, some questions should be clarified.\n\n1) In the ablation study, what is the performance of removing Qpost and remaining Qinfo (asking questions using AQM+, and guessing with an SL-trained model)?\n\n2) In the experiments, the baselines do not contain AQM. \nAlthough AQM has more constraints, it is necessary to see the performance difference between AQM and AQM+, . \nIf the difference is not significant, it means that this dataset cannot test the generalization capability of the model, so experiments on other datasets may be considered.\nIf the difference is significant, then the effectiveness of the model is well justified.\nThe authors should include the comparison in the experiments; otherwise, it is difficult to justify whether the proposed model is useful.\n', 'The paper proposes an improvement over the AQM approach for an information-theoretic framework for task-oriented dialog systems. Specifically, the paper tries to circumvent the problem of explicitly calculating the information gain while asking a question in the AQM setting. While the original AQM approach sweeps over all possible guesses and answers while estimating information gain, this is rendered impractical in scenarios where this space cannot be tractably enumerated. As a solution, AQM+ proposes sweeping over only some top-k relevant instantiations of answers and guesses in this space by normalizing the probabilities of the subset of the space in consideration. In addition, unlike AQM, AQM+ can ask questions which are relevant to the dialog context so far. Consequentially, this is generalizable and applicable for dialog systems with non ‘yes/no’ answers. Empirical observations demonstrate improvements over the existing approaches for such task-oriented dialog systems. The paper is not very well-written and at times is hard to understand. The contributions seem incremental as well in addition to the concerns mentioned below.\n\nComments:\n- The paper is overloaded with notations and the writing is not very smooth. The terse nature of the content makes it hard to follow in general. If someone apriori was not familiar with task-oriented dialog or the visual dialog setting in Das et al. (2017b), it would be quite hard to follow.\n- While mentioning SL/RL approaches while comparing or introducing the setup, the authors do not make any distinction between discriminative and generative dialog models. Specifically, SL approaches could either be trained discriminatively to rank options among the provided ones given dialog context or in a generative manner via token-level teacher forcing. The authors should clearly make this distinction in the introduction and in other places where it’s needed.\n- The authors should stress more upon the approximations involved while calculating mutual information. As far as I understand, even in the AQM approach the numerator and the denominator within the logarithm are estimated from a different set of parameters and as such they need not be consistent with each other under marginalization. The term resembles MI and ensuring consistency in such a framework would require either of the numerator or the denominator to be close to something like a variational approximation of the true distribution. In addition, AQM+ adopts the same framework as AQM but computes MI over some top-k of the random variables being considered. Could the authors comment more on why restricting the space of r.v.’s to some top-k samples is a good idea? Would that not lead to somewhat of a biased estimator?\n- Unless I am missing something, training aprxAgen from the training data (indA) seems odd. Assuming, this to be Qbot’s mental model of Abot -- there is no prior reason why this should be initialized or trained in such a manner. Similarly, the training paradigm of the depA setting is confusing. If they are trained in a manner similar to a regular Abot -- either SL or RL -- then they’re not approximate mental models but are rather just another Abot agent in play which is being queried by Qbot.\n- Under Comparative Models, in paragraph 2 of section 4.1, the authors state that “there are some reports….looks like human’s dialog”. Can the authors elaborate on what they mean by this statement? It’s not clear what the message to be conveyed here is.\n- Comparisons in GuessWhich highly rely on the PyTorch implementation in the mentioned github repository. However, the benchmarking performed in that repository for RL over SL is not accurate because of inherent bugs in the implementation of REINFORCE (see https://github.com/batra-mlp-lab/visdial-rl/issues/13 and https://github.com/batra-mlp-lab/visdial-rl/pull/12 ). I would suggest the authors to take this into account.\n- Can the authors also show performances for the GuessWhich models (under the AQM+ framework) on the original retrieval metrics for Visual Dialog mentioned in Das et al. (2017a)? This would be useful to judge the robustness of the proposed approach over the methods being compared with. \n\n\nUpdated Thoughts\n- The authors adressed the issues raised/comments made in the review. In light of my comments below to the author responses -- I am inclined towards increasing my rating.\n- In addition, I have mentioned some updates in the comments which might make the paper stronger -- centered around clarifications regarding the computation of the top-k info-gain term.']","[50, 20, -20]","[80, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by stating they have increased their rating and think it's a good paper that will be interesting to the community. They also thank the authors for their efforts. However, they still list some concerns, which balances out the positivity. The politeness score is 80 because the reviewer uses respectful language throughout, thanks the authors for their efforts, and frames criticisms constructively as suggestions or areas for improvement rather than harsh criticisms. They also acknowledge the strengths of the paper before discussing concerns. The tone remains professional and courteous throughout, even when pointing out limitations."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution to addressing generalization issues and achieving good performance in experiments. However, they also note that the novelty is relatively limited and raise some questions about the methodology. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their concerns as questions to be clarified rather than direct criticisms. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some improvements and empirical observations demonstrating benefits, they also express concerns about the paper being hard to understand, having incremental contributions, and various technical issues. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They use phrases like 'Can the authors elaborate' and 'I would suggest' which are polite ways of providing feedback. The review balances critique with recognition of the paper's contributions, indicating an effort to be fair and respectful.""]"
"[""This is a work regarding the alignment of word embedding for multiple languages.Though there are existing works similar to this one, most of them are only considering a pair of two languages, resulting in the composition issue mentioned in this work. The authors proposed a way of using a regularization term to reduce such degraded accuracy and demonstrate the validity of the proposed algorithm via experiments. I find the work to be interesting and well written. Several points that I want to bring up:\n\n1. The language tree at the end of section 5 is very interesting. Does it change if the initialization/parameter is different?\n\n2. The matrix P in (1) is simply a standard permutation matrix. I think the definitions are redundant.\n\n3. The experiment results are expected since the algorithms are designed for better composition quality. An additional experiment, e.g. classification of instances in multiple languages, could further help demonstrate the strength of the proposed technic.\n\n4. How to choose the regularization parameter \\mu and what's the effect of \\mu?\n\n5. Some written issues like the notation of orthogonal matrix set, both \\mathcal{O} and \\mathbb{O} are used."", 'This paper is concerned with the idea of inducing multilingual word embeddings (i.e., word vector spaces where words from more than two languages are represented) in an unsupervised way using a mapping-based approach. The main novelty of the work is a method, inspired by recent work of Nakashole and Flauger, and building on the unsupervised bilingual framework of Grave et al., which aims at bypassing the straightforward idea of independently mapping N-1 vector spaces to the N-th pivot space by adding constraints to ensure that the learned mappings can be composed (btw., it is not clear from the abstract what this means exactly).\n\nIn summary, this is an interesting paper, but my impression is that it needs more work to distinguish itself from prior work and stress the contribution more clearly. \n \nAlthough 11 languages are used in evaluation, the authors still limit the evaluation only to (arguably) very similar languages (all languages are Indo-European and there are no outliers, distant languages or languages from other families at all, not even the usual suspects like Finnish and Hungarian). Given the observed instability of GAN-based unsupervised bilingual embedding learning, dissected in Sogaard et al.\'s paper (ACL 2018) and also touched upon in the work of Artetxe et al. (ACL 2018), one of the critical questions for this work should also be: is the proposed method stable? What are the (in)stability criteria? When does the method fail and can it lead to sub-optimal solutions? What is the decrease in performance when moving to a more distant language like Finnish, Hungarian, or Turkish? Is the method more robust than GAN-based models? All this has to be at least discussed in the paper. \n\nAnother question is: do we really want to go \'fully unsupervised\' given that even a light and cheap source of supervision (e.g., shared numerals, cognates) can already result in more robust solutions? See the work of Artetxe et al. (ACL 2017, ACL 2018), Vulic and Korhonen (ACL 2016) or Sogaard et al. (ACL 2018) for some analyses on how the amount of bilingual supervision can yield more (or less) robust models? Is the proposed framework also applicable in weakly-supervised settings? Can such settings with weak supervision guarantee increased robustness (and maybe even better performance)? I have to be convinced more strongly: why do we need fully unsupervised multilingual models, especially when evaluation is conducted only with resource-rich languages?\n\nAnother straightforward question is: can the proposed framework handle cases where there exists supervision for some language pairs while other pairs lack supervision? How would the proposed framework adapt to such scenarios? This might be an interesting point to discuss further in Section 5.\n\nStyle and terminology: it is not immediately clear what is meant by (triplet) constraints (which is one of the central terms in the whole work). It is also not immediately clear what is meant by composed mappings, hyper-alignment (before Section 4), etc. There is also some confusion regarding the term alignment as it can define mappings between monolingual word embedding spaces as well as word-level links/alignments. Perhaps, using mapping instead of alignment might make the description more clear. In either case, I suggest to clearly define the key concepts for the paper. Also, the paper would contribute immensely from some running examples illustrating the main ideas (and maybe an illustrative figure similar to the ones presented in, e.g., Conneau et al.\'s work or Lample et al.\'s work). The paper concerns word translation and cross-lingual word embeddings, and there isn\'t a single example that serves to clarify the main intuition and lead the reader through the paper. The paper is perhaps too much focused on the technical execution of the idea to my own liking, forgetting to motivate the bigger picture.\n\nOther: the part on ""Language tree"" prior to ""Conclusion"" is not useful at all and does not contribute to the overall discussion. This could be safely removed and the space in the paper should be used to additional comparisons with more baselines (see above for some baselines).\n\nThe authors mention that their approach is ""relatively hard to scale"" only in their conclusion, while algorithmic complexity remains one of the key questions related to this work. I would like to see some quantitative (time) measurements related to the scaling problem, and a more thorough explanation why the method is hard to scale. The complexity and non-scalability of the method was one of my main concerns while reading the paper and I am puzzled to see some remarks on this aspect only at the very end of the paper. Going back to algorithmic complexity, I think that this is a very important aspect of the method to discuss explicitly. The authors should provide, e.g., O-notation complexity for the three variant models from Figure 2 and help the reader understand pros and cons of each design also when it comes to their design complexity. Is the only reason to move from the star model to the HUG model computational complexity? This argument has to be stressed more strongly in the paper.\n\nTwo very relevant papers have not be cited nor compared against. The work of Artetxe et al. (ACL 2018) is an unsupervised bilingual word embedding model similar to the MUSE model of Conneau et al. (ICLR 2018) which seems more robust when applied on distant languages. Again, going back to my previous comment, I would like to see how well HUG fares in such more challenging settings. Further, a recent work of Chen and Cardie (EMNLP 2018) is a multilingual extension of the bilingual GAN-based model of Conneau et al. Given that the main goal of this work and Chen and Cardie\'s work is the same: obtaining multilingual word embeddings, I wonder how the two approHowaches compare to each other. Another, more general comment concerns the actual evaluation task: as prior work, it seems that the authors optimise and evaluate their embeddings solely on the (intrinsic) word translation task, but if the main goal of this research is to boost downstream tasks in low-resource languages, I would expect additional evaluation tasks beyond word translation to make the paper more complete and convincing.\n\nThe method relies on a wide spectrum of hyper-parameters. How are these hyper-parameters set? How sensitive is the method to different hparams configurations? For instance, why is the Gromov-Wasserstein approach applied only to the first 2k vectors? How are the learning rate and the batch size determined?\n\nMinor:\nWhat is W in line 5 of Algorithm 1?\nGiven the large number of symbols used in the paper, maybe a table of symbols put somewhere at the beginning of the paper would make the paper easier and more pleasant to read.\nI would also compare the work to another relevant supervised baseline: the work from Smith et al. (ICLR 2017). This comparison might further strengthen the main claim of the paper that indirect translations can also be found without degrading performance in multilingual embedding spaces.', 'The authors present a method for unsupervised alignment of word across multiple languages. In particular, they extend an existing unsupervised bilingual alignment to the case of multiple languages by adding constraints to the optimization problem. The main aim is to ensure that the embeddings can now be composed and the performance (alignment quality) does not degrade across multiple compositions.\n\nStrengths\n- Very clearly written\n- A nice overview of existing methods and correct positioning of the author\'s contributions in the context of these works\n- A good experimental setup involving multiple languages\n\nWeaknesses\n- I am not sure how to interpret the results in Table 2 and Table 3 (see questions below).\n\nQuestions\n- On page 7 you have mentioned that ""this setting is unfair to the MST baseline, since ...."" Can you please elaborate on this? I am not sure I understand this correctly.\n\n- Regarding results in Table 2 and 3: It seems that there is a trade-off while adding constraints which results in poor bilingual translation quality. I am not sure is this is acceptable. I understand that your goal is to do indirect translation but does that mean we should ignore direct translation ?\n\n- In Table 3 can you report both W-Proc and W-Proc* results ? Is it possible that the GW-initialization helps bilingual translation as the performance of W-Proc* is clearly better than W-Proc in Table 2. However, could it be the case that this somehow affects the performance in the indirect translation case? IMO, this is worth confirming.\n\n- In Table 3, you are reporting  average accuracies across and within families. I would like to see the numbers for all language pairs independently. This is important because when you consider the average it is quite likely that for some language pair the numbers were much higher which tilts the average in favor of some approach. Also looking at the individual numbers will help us get some insights into the behavior across language pairs.\n\n- In the motivation (Figure 1) it was mentioned that compositions can be done (and are often desirable) along longer paths (En-Fr-Ru-It). However, in the final experiments the composition is only along a triplet (X-En-Y). Is that correct or did I misinterpret the results? If so, can you report the results when the number of compositions increases?\n\n\n\n ']","[70, -20, 50]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer finds the work 'interesting and well written'. They acknowledge the novelty of the approach and its validity. The overall tone is supportive, with constructive suggestions for improvement. The politeness score is 80 (quite polite) due to the respectful and professional language used throughout. The reviewer offers suggestions and questions in a courteous manner, using phrases like 'I find the work to be interesting' and 'Several points that I want to bring up'. There are no harsh criticisms or rude comments, and the reviewer maintains a collegial tone while providing specific, helpful feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting', they also state that it 'needs more work' and raise several critical questions and concerns. The reviewer points out multiple areas where the paper falls short or requires improvement, which contributes to the overall negative sentiment. However, the criticism is constructive and not overly harsh, hence the score is only mildly negative. The politeness score is positive (60) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and acknowledges the interesting aspects of the work. The reviewer consistently uses phrases like 'I suggest', 'I would like to see', and 'Perhaps', which maintain a polite tone even when providing critical feedback. The review also offers specific, actionable recommendations for improvement, which is a courteous approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the authors' work and noting several strengths, including clear writing and a good experimental setup. However, they also point out a weakness and have several questions, indicating a balanced but generally positive view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively, and asks questions in a courteous manner. They use phrases like 'Can you please elaborate' and 'I would like to see', which are polite ways of requesting more information or suggesting improvements. The reviewer also acknowledges the authors' goals and contributions, showing respect for their work.""]"
"['This paper proposes a method for learning skills in absence of a reward function. These skills are learned so that the diversity of the trajectories produced by each skill is maximised. This is achieved by having a discriminator attempting to tell these skills apart. The agent is rewarded for visiting states that are easy to distinguish and the discriminator is trained to better infer the skills from states visited by the agent. Furthermore, a maximum entropy policy is used to force the skills to be diverse. The proposed method is general and any RL algorithm with entropy maximisation in the objective can be used, the implementation in the paper uses the Soft Actor Critic method.\n\nThe problem that they are tackling is interesting and is of clear value for obtaining more generalisable RL algorithms. The paper is overall clear and easy to follow, the results are interesting and potentially useful, although I have some reservations regarding how they assess this usefulness in the current version of this paper.\nStructure-wise, I would say that the choice of writing the paper in the form of a Q&A, with very brief explanations and details was more distracting and at times unnecessary than I liked (e.g. Question 7 could move to Appendix as it is quite trivial).\n\nI really appreciated how much care has been taken to discuss differences with the closest prior work, Variational Intrinsic Control (VIC) by Gregor et al. \nOne such difference is that their prior distribution over skills is not learnt. While there are good arguments by the authors about why this is appealing (e.g. it prevents collapsing to sampling only a few skills), I feel this could be also quite a limitation of their method. This assumes that you have a good a-priori knowledge and assumptions regarding how many skills are useful or needed in the environment. This is unlikely to be the case in complex environments, where you first need to learn simple skills in order to explore the environment, and later learn to form new more complex skills. During this process, you might want to prune simplistic skills after you learnt more abstract and complex ones, for instance in the context of continual learning. I understand this could be investigated in future work, but I feel they take a rather optimistic take on this problem.\n\nOverall, the use case for the proposed method is slightly unclear to me. While the paper claims to allow diverse set of skills to be learnt, it is highly dependent on learning varied action sequences that help you visit different part of state space, regardless of their usefulness. This means there could be learn a lot of skills that capture part of the state space that is not useful or desirable for downstream tasks. While there is a case made for DIAYN being a stepping stone for imitation learning and hierarchical RL, I don’t find the reported experiments for imitation learning and HRL convincing. In the imitation learning experiment, the distance (KL divergence) between all skills and the expert data is computed and the closest skill is then chosen as the policy imitating the expert. The results are weak and no comparisons with any LfD baselines are reported. The HRL experiments also lack comparisons to any other HRL baseline. I feel that this section is rather weak, especially compared to the rest of the paper, and I am not sure it achieves much.\n\nAs a general comment, the choice of reporting the training progress using “hours spent training” is an peculiar choice which is never discussed. I understand that for methods with varying computational costs this might be a fairer comparison but it would be perhaps good to also report progress against number of required environment interactions (including pre-training).\nAnother assumption made is that the method is valuable in situations where the reward function is expensive to compute and the unsupervised pre-training is free (somewhat easing the large amount of pre-training required). However, it would have been interesting to see examples of such environments in their experiments supporting these claims, as this assumption is not valid for the chosen MuJoCo environments.\n\nDespite these comments, I still feel this is valuable work, that can clearly inspire further relevant work and deserves to be presented at ICLR.\nIt presents a solid contribution, given its technical novelty, proposed applications and its overall generality. \nHowever, the paper could use more convincing experiments to support its claims.\n\nAdditional comments and typos:\n- Figure 5 lack error bars across the 5 random seeds and are crucial to assess whether this performance difference is indeed significant given the amount of pre-training required.\n- Figure 7’s title and caption is missing...\n- typo: page 3, last paragraph “...mutual information between skills and states, **I(S; Z )**” not I(A; Z)\n- typo: page 7 paragraph next to Figure 6 “...whereas DIAYN explicitly **learns** skills that effectively partition the state space”\n- typo: page 7 above Figure 8 “...make them **exceedingly** difficult for non- hierarchical RL algorithms.”\n', '*Pros:*\n-\tMostly clear and well-written paper \n-\tTechnical contribution (learning many diverse skills) is principled and well-justified (although the basic idea builds on a large body of prior work from related fields as also evidenced from the reference list)\n-\tExtensive emperical evaluation on multiple tasks and different scenarios (mainly toy examples) showing promising results.\n\n*Cons:*\n-\tThe main paper assumes detailed knowledge of the actor critic setup to fully follow and appreciate the paper (a few details provided in the appendix) \n-\tp(z): it is not entirely clear to me how the dimensionality of z should be chosen in a principled manner aside from brute force evaluation (as in 4.2.2; which does not go beyond a few hundreds). What happens for many skills and would learning p(z) be preferable in this scenario?\n-\tNote: The work has been in the public domain for some time thereby limiting the apparent novelty. This has not influenced my decision as per ICLR policy. \n\n*Significance*: I think this work would be of interest to the ICLR crowd despite it having been in the public domain for a some time. It provides a simple objective for training RL models in an unsupervised manner by learning multiple diverse skills and contributes with an extensive and convincing empirical evaluation which will surely have a lasting impact in the RL subfield. \n\n*Further comments/questions*:\n-\tThe authors assume that only states and not actions are observable. Intuitively, it would seem easier to obtain the desired results if the actions are also available. Could the authors perhaps clarify why it is reasonable to assume that the actions are not observable to the planner when evaluating the objective in Eq 1?  Similarly, I’d like some insight into the behaviour of the proposed method if actions are also available (and how it differs from prior art in this case)?\n-\tI’d suggest enforcing consistently in the way variation across random seeds is visualised in the figures (e.g. traces in fig 4, no indication in fig5, shaped background in fig 6). \n-\tI’d suggest making it explicit what $\\theta$ refers to in Eq. 1 (and provide some details about the SAC setup for completeness, as previously mentioned)\n-\tMinor typos etc: {p2, l6} missing word, “SAC” never defined, “DOF” never defined, and a few other typos/punctuation issues throughout. \n', 'The authors propose a learning scheme for the unsupervised acquisition of skills. These skills are then applied to (1) accelerate reinforcement learning to maximize a reward, (2) perform hierarchical RL, and (3) imitate an expert trajectory.\n\nThe unsupervised learning of skills maximizes an information theoretic objective function. The authors condition their policy on latent variable Z, and the term skill refers to a policy conditioned on a fixed Z. The mutual information between states and skills is maximized to ensure that skills control the states, while the mutual information between actions and skills given the state is minimized, to ensure that states, not actions distinguish skills. The entropy of the mixture of policies is also maximized. Further manipulations on this objective function enable the scheme to be implemented using a soft actor-critic maximizing a pseudo reward involving a learned skill discriminator.\n\nThe authors clearly position their work in relation to others, and especially point out the differences to the most similar work, namely Gregor et al 2016. These differences while seemingly minor end up providing exceptional improvement in the number of skills learned and the domains tackled.\n\nThe question-answer style is somewhat unconventional. While the content comes across clearly, the flow / narrative is a bit broken.\n\nOverall, I believe that applicability of the work is very wide, touching inverse RL, hierarchical RL, imitation learning, and more. The simulational comparisons are also very useful.\n\nHowever, there is an issue that I\'d like to see addressed:\nFig 8: In a high-dimensional task, namely 111D ant navigation, DIAYN performs slightly worse than others. Incorporating a prior on useful skills makes DIAYN perform much better. Here, apart from the comparision with other state of the art RL methods, the authors should also compare to VIC. Indeed one of the key differences to VIC was the uniform prior on skills, which the authors now break albeit in a slightly different way. Thus, it is essential to also show the performance of VIC, and comment on any similarities / differences. The relation of this prior to the VIC prior should also be made clear. Further, the performance of VIC on the half cheetah hurdle should be also be shown.\n\nIf the above issue is addressed, I strongly recommend that the work be presented at ICLR.\n\nMinor issues / typos:\npg 1: ""policy that alters that state of the environment"" to ""policy that alters the state of the environment""\npg 3: ""mutual information between skills and states, I(A; Z)"" to ""mutual information between skills and states, I(S; Z)""\npg 4: ""guaranteeing that is has maximum entropy"" to ""guaranteeing that it has maximum entropy""\npg 4: "" soft actor critic"" to "" soft actor critic (SAC)"" since SAC is used later.\npg 5: full form of VIME not introduced\nFig 5: would be good to also show the variance as a shaded area around the mean.\npg 7: ""whereas DIAYN explicitly skills that effectively partition the state space"" ?']","[50, 60, 70]","[80, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's value and interesting aspects, but also expresses several reservations and critiques. The overall tone is constructive, recognizing the paper's potential while suggesting improvements. The politeness score is 80 (quite polite) due to the reviewer's respectful language, use of phrases like 'I really appreciated' and 'I understand', and the balanced approach in presenting both positive aspects and criticisms. The reviewer maintains a professional and courteous tone throughout, even when pointing out weaknesses in the paper."", ""The sentiment score is 60 (moderately positive) because the review starts with a list of pros, highlighting the paper's clarity, technical contribution, and extensive empirical evaluation. The reviewer also notes the paper's significance and potential impact. However, there are some cons and suggestions for improvement, which prevent a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I'd suggest...'). The reviewer also acknowledges the paper's strengths and potential impact. The use of 'I think' and 'Could the authors perhaps clarify...' further contributes to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses strong approval of the work, noting its wide applicability and usefulness. They 'strongly recommend' the work be presented if one issue is addressed, indicating overall positive sentiment. However, it's not 100 as there are some criticisms and requests for changes. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames criticisms constructively. The use of phrases like 'I believe' and 'I'd like to see' maintain a collegial tone. The score isn't 100 as the review is direct in its critique, which is appropriate for peer review but not overly deferential.""]"
"[""This paper introduces a deep RL algorithm to solve the Rubik's cube. The particularity of this algorithm is to handle the huge state space and very sparse reward of the Rubik's cube. To do so, a) it ensures each training batch contains states close to the reward by scrambling the solution; b) it computes an approximate value and policy for that state using the current model and c) it weights data points based by the inverse of the number of random moves from the solution used to generate that training point. The resulting model is compared to two non-ML algorithms and shown to be competitive either on computational speed or on the quality of the solution.  \n\nThis paper is well written and clear. To the best of my knowledge, this is the first RL-based approach to handle the Rubik's cube problem so well. The specificities of this problem make it interesting. While the idea of starting from the solution seemed straightforward at first, the paper describes more advanced tricks claimed to be necessary to make the algorithm work. The algorithm seems to be quite successful and competitive with expert algorithms, which I find very nice. Overall, I found the proposed approach interesting and sparsity of reward is an important problem so I would rather be in favor of accepting this paper. \n\nOn the negative side, I am slightly disappointed that the paper does not link to a repository with the code. Is this something the authors are considering in the future? While it does not seem difficult to code, it is still nice to have the experimental setup.\n\nThere has been (unsuccessful) attempts to solve the Rubik's cube using deep RL before. I found some of them here: https://github.com/jasonrute/puzzle_cube . I am not sure whether these can be considered prior art as I could not find associated accepted papers but some are quite detailed. Some could also provide additional baselines for the proposed methods and highlight the challenges of the Rubik's cube.\n\nI am also curious whether/how redundant positions are handled by the proposed approach and wished this would be discussed a bit. Considering the nature of the state space and the dynamics, I would have expected this to be a significant problem, unlike in Go or chess. Does the algorithm forbid the reverse of the last action? Is the learned value/policy function good enough that backwards moves are seldom explored? Since the paper mention that BFS is interesting to remove cycles, I assume identical states are not duplicated. Is this correct?"", 'The authors show how to solve the Rubik cube using reinforcement learning (RL) with Monte-Carlo tree search (MCTS). As common in recent applications like AlphaZero, the RL part learns a deep network for policy and a value function that reduce the breadth (policy) and depth (value function) of the tree searched in MCTS. This basic idea without extensions fails when trying to solve the Rubik cube because there is only one final success state so the early random policies and value functions never reach it. The solution proposed by the authors, called autodidactic iteration (ADI) is to start from the final state, construct a few previous states, and learn value function on this data where in a few moves a good state is reached. The distance to the final state is then increased and the value function learn more and more. This is an interesting idea that solves the Rubik cube, but the paper lacks a more detailed study. What other problems can be solved like this? Would a single successful trajectory be enough to use it in a wider context (as in https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration/) ? Is the method to increase distance from final state specific to Rubik cube or general? Is the training stable with respect to this or is it critical to get it right? The lack of analysis and ablations makes the paper weaker.\n\n[Revision] Thanks for the replies. I still believe experiments on more tasks would be great but will be happy to accept this paper.', 'The authors provide a good idea to solve Rubik’s Cube using an approximate policy iteration method, which they call it as Autodidactic iteration. The method overcomes the problem of sparse rewards by creating its own rewards system. Autodidactic iteration starts with solved cube and then propagate backwards to the state. \n\nThe testing results are very impressive. Their algorithm solves 100% of randomly scrambled(1000 times) cubes and has a median solve length of 30 moves. The God’s number is 26 in the quarter turn metric, while their median moves 30 is only 4 hands away from the God’s number. I appreciate the non-human domain knowledge part most because a more general algorithm can be used to other area without  enough pre-knowledges. \n\nThe training conception to design rewards by starting from solved state to expanded status is smart, but I am not very clear how to assign the rewards based on the stored states? Only pure reinforcement learning method applied sounds simple, but performance is great. The results are good enough with the neural network none-random search guidance. Do you have solving time comparison  between your method and other approximate methods? \n\nPros: -  solved nearly 100% problems with reasonable  moves.\n          -  a more general algorithm solving unknown states value problems.\n\nCons: - the Rubik’s cube problem has been solved with other optimal approaches in the past. This method is not as competitive as other optimal solution solver within similar running time for this particular game.\n           - to solve more dimension cubes, this method might be out of time.  \n']","[70, 20, 70]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, describing it as 'well written and clear' and stating they are 'in favor of accepting this paper'. They highlight the novelty and success of the approach. The score is not higher because the reviewer does express some disappointments and curiosities. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They balance positive comments with areas for improvement, and phrase criticisms as questions or curiosities rather than direct criticisms. The reviewer's tone is professional and courteous, showing consideration for the authors' work while still providing honest feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting idea and successful solution to the Rubik's cube problem, but expresses concerns about the lack of detailed study and analysis. The initial review is somewhat critical, but the revision note indicates a willingness to accept the paper, which slightly improves the overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the authors' achievements while providing constructive criticism. The reviewer avoids harsh or dismissive language, instead framing concerns as suggestions for improvement and questions for further exploration. The revision note is particularly polite, showing flexibility and a positive attitude towards the authors' responses."", ""The sentiment score is 70 (positive) because the reviewer expresses appreciation for the authors' idea, describes the results as 'very impressive', and highlights several pros of the method. The reviewer does mention some cons, but these are presented as minor drawbacks rather than major criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the work, and phrases criticisms as questions or suggestions rather than direct attacks. The reviewer uses phrases like 'I appreciate' and 'The authors provide a good idea', which contribute to a polite tone. The constructive nature of the feedback, balancing praise with areas for improvement, also adds to the politeness of the review.""]"
"['Summary: \n\nThis paper proposed a feature boosting and suppression method for dynamic channel pruning. To be specific, the proposed method firstly predicts the importance of each channel and then use an affine function to amplify/suppress the importance of different channels. However, the idea of dynamic channel pruning is not novel. Moreover, the comparisons in the experiments are quite limited. \n\nMy detailed comments are as follows.\n\n\nStrengths:\n\n1. The motivation for this paper is reasonable and very important. \n\n2. The authors proposed a new method for dynamic channel pruning.\n\nWeaknesses:\n\n1. The idea of dynamic channel pruning is not novel. In my opinion, this paper is only an extension to Network Slimming (Liu et al., 2017). What is the essential difference between the proposed method and Network Slimming?\n\n2. The writing and organization of this paper need to be significantly improved. There are many grammatical errors and this paper should be carefully proof-read.\n\n3. The authors argued that the importance of features is highly input-dependent. This problem is reasonable but the proposed method still cannot handle it. According to Eqn. (7), the prediction of channel saliency relies on a data batch rather than a single data. Given different inputs in a batch, the selected channels should be different for each input rather than a general one for the whole batch. Please comment on this issue.\n\n4. The proposed method does not remove any channels from the original model. As a result, both the memory and the computational cost will not be reduced. It is confusing why the proposed method can yield a significant speed-up in the experiments.\n\n5. The authors only evaluate the proposed method on shallow models, e.g., VGG and ResNet18. What about the deeper model like ResNet50 on ImageNet?\n\n6. It is very confusing why the authors only reported top-5 error of VGG. The results of top-1 error for VGG should be compared in the experiments.\n\n7. Several state-of-the-art channel pruning methods should be considered as the baselines, such as ThiNet (Luo et al., 2017), Channel pruning (He et al., 2017) and DCP (Zhuang et al., 2018)\n[1] Channel pruning for accelerating very deep neural networks. CVPR 2017.\n[2] Thinet: A filter level pruning method for deep neural network compression. CVPR 2017.\n[3] Discrimination-aware Channel Pruning for Deep Neural Networks. NIPS 2018.\n', 'This manuscript presents a nice method that can dynamically prune some channels in a CNN network to speed up the training. The main strength of the proposed method is to determine which channels to be suppressed based upon each data sample without incurring too much computational burden or too much memory consumption.  The good thing is that the proposed pruning strategy does not result in a big performance decrease. Overall, this is a nicely written paper and may be empirically useful for training a very large CNN. Nevertheless, the authors did not present a real-world application in which it is important to speed up by 2 or 3 times at a small cost, so it is hard to judge the real impact of the proposed method.', 'The authors propose a dynamic inference technique for accelerating neural network prediction with minimal accuracy loss.  The technique prunes channels in an input-dependent way through the addition of auxiliary channel saliency prediction+pruning connections.\n\nPros:\n- The paper is well-written and clearly explains the technique, and Figure 1 nicely summarizes the weakness of static channel pruning\n- The technique itself is simple and memory-efficient\n- The performance decrease is small\n\nCons:\n- There is no clear motivation for the setting (keeping model accuracy while increasing inference speed by 2x or 5x)\n- In contrast to methods that prune weights, the model size is not reduced, decreasing the utility in many settings where faster inference and smaller models are desired (e.g. mobile, real-time)\n- The experiments are limited to classification and fairly dated architectures (VGG16, ResNet-18)\n\nOverall, the method is nicely explained but the motivation is not clear.  Provided that speeding up inference without reducing the size of the model is desirable, this paper gives a good technique for preserving accuracy.', 'This paper propose a channel pruning method for dynamically selecting channels during testing. The analysis has shown that some channels are not always active. \n\nPros:\n- The results on ImageNet are promising. FBS achieves state-of-the-art results on VGG-16 and ResNet-18.\n- The method is simple yet effective.\n- The paper is clear and easy to follow.\n\nCons:\n- Lack of experiments on mobile networks like shufflenets and mobilenets\n- Missing citations of some state-of-the-art methods [1] [2].\n- The speed-up ratios on GPU or CPU are not demonstrated. The dynamic design of Dong et al., 2017 did not achieve good GPU speedup.\n- Some small typos.\n\n[1] Amc: Automl for model compression and acceleration on mobile devices\n[2] Netadapt: Platform-aware neural network adaptation for mobile applications ']","[-50, 50, 20, 50]","[20, 75, 60, 70]","[""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses and limitations of the paper. While the reviewer acknowledges some strengths, the majority of the comments are negative, highlighting issues with novelty, writing quality, and experimental design. However, it's not entirely negative, as the reviewer recognizes the reasonable motivation and the proposal of a new method.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Please comment on this issue' and frame criticisms as questions or suggestions rather than harsh statements. The reviewer also begins by acknowledging the paper's strengths before moving on to weaknesses, which is a polite approach. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many overtly polite phrases or softening language."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the method as 'nice' and 'nicely written', and acknowledges its strengths and potential usefulness. However, they also point out a limitation regarding the lack of real-world application, which prevents a more strongly positive score. The politeness score is 75 (quite polite) due to the use of positive language ('nice method', 'good thing', 'nicely written') and the balanced way of presenting both strengths and limitations without harsh criticism. The reviewer maintains a professional and respectful tone throughout, offering constructive feedback."", ""The sentiment score is slightly positive (20) because the review acknowledges some pros of the paper, such as it being well-written and the technique being simple and memory-efficient. However, it also points out significant cons and states that the motivation is not clear, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses neutral and professional language throughout, presenting both pros and cons in a balanced manner without using harsh or critical language. The reviewer acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach in academic reviews."", ""The sentiment score is 50 (moderately positive) because the review begins with a neutral description of the paper, followed by a balanced list of pros and cons. The pros highlight promising results, effectiveness, and clarity, which are positive aspects. However, the cons point out several limitations, balancing the overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths before presenting criticisms, and the cons are phrased as constructive feedback rather than harsh criticism. The use of 'pros' and 'cons' headings also contributes to a structured, professional tone. The reviewer doesn't use overly effusive praise or harsh language, maintaining a polite but objective stance.""]"
"['Summary:\nThis work presents a method to generate adversary examples capable of fooling a neural network classifier. Szegedy et al. (2013) were the first to expose the weakness of neural networks against adversarial attacks, by adding a human-imperceptible noise to images to induce misclassification. Since then, several works tackled this problem by modifying the image directly in the pixel space: the norm-balls convention. The authors argue that this leads to non-realistic attacks and that a network would not benefit from training with these adversarial images when performing in the real world. Their solution and contributions are parametric norm-balls: unlike state-of-the-art methods, they perform perturbations in the image formation space, namely the geometry and the lighting, which are indeed perturbations that could happen in real life. For that, they defined a differentiable renderer by making some assumptions to simplify its expression compared to solving a light transport equation. The main simplifications are the direct illumination to gain computation efficiency and the distant illumination and diffuse material assumptions to represent lighting in terms of spherical harmonics as in Ramamoorthi et al. (2001), which require only 9 parameters to approximate lighting. This allows them to analytically derivate their loss function according to the geometry and lighting and therefore generate their adversary examples via gradient descent. They show that their adversary images generalize to other classifiers than the one used (ResNet). They then show that injecting these images into the training set increase the robustness of WideResNet against real attacks. These real attack images were taken by the authors in a laboratory with varying illumination.\n\nStrength:\n- The proposed perturbations in the image formation space simulate the real life scenario attacks.\n- The presented results show that the generated adversary images do fool the classifier (used to compute the loss) but also new classifiers (different than the one used to compute the loss). As a consequence the generated adversary images increase the robustness of the considered classifier. \n- Flexibility in their cost function allows for diverse types of attacks: the same modified geometry can fool a classifier in several views, either into detecting the same object or detecting different false objects under different views. \n\nMajor comments:\n- Method can only compute synthetic adversary examples, unlike state-of-the-art.\n- The main contribution claimed by the author is that their perturbations are realistic and that it would help better increase the robustness of classifiers against real attacks. However, they do not give any comparison to the state-of-the-art methods as is expected. \n\nMinor comments:\n- Even if the paper is well written, they are still some typos. \n', 'The paper demonstrates a method for constructing adversarial examples by modifications or perturbations to physical parameters in the scene itself---specifically scene lighting and object geometry---such that images taken of that scene are able to fool a classifier. It achieves this through a novel differentiable rendering engine, which allows the proposed method to back-propagate gradients to the desired physical parameters. Also interesting in the paper is the use of spherical harmonics, which restrict the algorithm to plausible lighting. The method is computationally efficient and appears to work well, generating plausible scenes that fool a classifier when imaged from different viewpoints.\n\nOverall, I have a positive view of the paper. However, there are certain issues below that the authors should address in the rebuttal for me to remain with my score of accept (especially the first one):\n\n\n- The paper has no discussion of or comparisons to the work of Athalye and Sutskever, 2017 and Zeng et al., 2017, except for a brief mention in Sec 2 that these methods also use differentiable renderers for adversarial attacks. These works address the same problem as this paper---computing physically plausible adversarial attacks---and by very similar means---back-propagation through a rendering engine. Therefore it is critical that the paper clarifies its novelty over these methods, and if appropriate, include comparisons.\n\n- While the goal of finding physically plausible adversarial examples is indeed important, I disagree with the claim that image-level attacks are ""primarily tools of basic research, and not models of real-world security scenarios"". In many applications, an attacker may have access to and be able to modify images after they\'ve been captured and prior to sending them through a classifier (e.g., those attempting to detect transmission of spam or sensitive images). I believe the paper can make its case about the importance of physical adversarial perturbations without dismissing image-level perturbations as entirely impractical.\n\n- The Athalye 18 reference noted in Fig 1 is missing (the references section includes the reference to Athalye and Sutskever \'17).\n\n===Post-rebuttal\n\nThanks for addressing my questions. With the new comparisons and discussions wrt the most relevant methods, I believe the contributions of the paper are clearer. I\'m revising my score from 6 to 7.\n', 'Quality of the paper:  The paper is quite clear on the background literature on adversarial examples, physics based rendering, and the core idea of generating adversarial perturbations as a function of illumination and geometric changes.   \nOriginality and Significance: The idea of using differential renderers to produce physically consistent adversarial perturbations is novel. \nReferences: The references in the paper given its scope is fine.  It is recommended to  explore references to other recent papers that use simulation for performance enhancement in the context of transfer learning, performance characterization (e.g. veerasavarappu et al in arxiv, WACV, CVPR (2015 - 17)) \n\nPros:  Good paper , illustrates the utility of differentiable rendering and simulations to generate adversarial examples and to use them for improving robustness.\nCons: The experimental section needs to be extended and the results are limited to simulations on CIFAR-100 and evaluation on lab experimental data.  Inclusion of images showing CIFAR-100 images augmented with random lighting, adversarial lighting would have been good. The details of the image generation process for that experiment is vague and not reproducible. ']","[50, 60, 60]","[75, 70, 80]","[""The sentiment score is 50 (slightly positive) because the review begins by summarizing the work in a neutral tone, then lists strengths of the paper, which is positive. However, it also includes major and minor comments for improvement, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms as 'comments' rather than direct criticisms. The reviewer also uses phrases like 'the authors argue' and 'they show,' which maintain a professional and courteous tone. The minor comment about typos is presented gently, further contributing to the overall polite tone of the review."", ""The sentiment score is 60 (positive) because the reviewer expresses an overall positive view of the paper, stating 'Overall, I have a positive view of the paper.' They also praise aspects of the work as 'interesting' and note that the method 'appears to work well.' However, the score is not higher because the reviewer raises several issues that need to be addressed. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement (e.g., 'the authors should address'). The reviewer also thanks the authors for addressing their questions in the post-rebuttal section, showing courtesy. The language is professional and objective without being overly formal or deferential, hence the score is positive but not at the maximum."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting it as a 'Good paper' with novel ideas and clear background. They highlight several pros and the originality of the work. However, it's not a perfect score due to some cons mentioned, particularly regarding the experimental section. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive feedback and recommendations without harsh criticism. They balance positive comments with areas for improvement, and use phrases like 'it is recommended' rather than demanding changes, which contributes to the polite tone.""]"
"['The authors demonstrate the generalization bound for deep neural networks using the PAC-Bayesian approach. They adopt the idea of noise resilience in the analysis and obtain a result that has improved dependence in terms of the network dimensions, but involves parameters (e.g., pre-activation) that may be large potentially. \n\nMy major concern is also regarding the dependence on the pre-activation that can be very large in practice. This is also shown in the numerical experiments. Therefore, the overall generalization bound can be larger than existing results, though the later have stronger dependence on the network sizes. By examining the analysis for the main result, it seems to me that the reason the authors can induce weaker dependence on network sizes is essentially they involved the pre-activation parameters. This can be viewed as a trade-off how strong the generalization bound depend on the network sizes and other related parameters (like the pre-activation here) rather than strictly tighten the error bound from a more refined/structured way. I also suggest that the authors provide the comparison of their bound and existing ones to see the quantitative difference of the results. \n\nRegarding the noise resilience, it is not clear to where the noise resilience shows up from the analysis or the result. From the proof of the main result, the analysis seems to be standard as in the PAC-Bayesian analysis, which is based on bounding the difference of the network before and after injecting randomness into the parameters. The difference with respect to the previous result due to the different way of bounding such a gap, where the Jacobian, the pre-activation and function output pop up. But this does not explain how well a network can tolerate the noise, either in the parameter space of the data space. This is different with the previous analysis based on the noise resilience, such as [1]. So, the title and the way the authors explain as noise resilience is somewhat misleading. More detailed explanation will help.\n\n[1] Arora et al. Stronger generalization bounds for deep nets via a compression approach. \n', 'The fact that a number of current generalization bounds for (deep) neural networks are not expressed on the deterministic predictor at stake is arguably an issue. This is notably the case of many recent PAC-Bayesian studies of neural networks stochastic surrogates (typically, a Gaussian noise is applied to the network weight parameters). The paper proposes to make these PAC-Bayesian bounds deterministic by studying their ""noise-resilience"" properties. The proposed generalization result bounds the margin of a (ReLU) neural network classifier from the empirical margin and a complexity term relying on conditions on the values of each layer (e.g., via layer Jacobian norm, the layer output norm, and the smallest pre-activation value). \n\nI have difficulty to attest if the proposed conditions are sound. Namely, the authors genuinely admit that the empirically observed pre-activation values are not large enough to make the bound informative (I must say that I truly appreciate the authors\' candor when it comes to analyzing their result). That being said, the fact that the bounds does not scale with the spectral norm of the weight matrices, like previous PAC-Bayesian result for neural networks, is an asset of the current analysis.\n\nI must say that I had only a quick look to it the proofs, all of them being in the supplementary material along most of the technical details. Nevertheless, it appears to me as an honest, original and rigorous theoretical study, and I think it deserves to be presented to the community. It can bring interesting discussion and suggest new paths to explore to explain the generalization properties of neural networks.\n\nMinor comment: For the reader benefit, Theorem F.1 in page 7 should quickly recall the meaning of some notation, even if it\'s the ""short version"" of the theorem statement.\n\n====\nupdate: The bound comparison added value to the paper. It strengthens my opinion that this work deserves to be published. I therefore increase my score to 7. ', 'This paper provides new generalization bounds for deep neural networks using the PAC-Bayesian framework. Recent efforts along these lines have proved bounds that \neither apply to a classifier drawn from a distribution or to a compressed form of the trained classifier. In contrast, the paper uses PAC Bayesian bounds to \nprovide generalization bounds for the original trained network. At this same time, the goal is to provide bounds that do not scale exponentially in the depth of the\nnetwork and depend on more nuanced parameters such as the noise-stability of the network. In order to do that the paper formalizes properties that a classifier must \nsatisfy on the training data. While these are a little difficult to understand in general, in the context of ReLU networks these boil down to bounding the l2-norms\nof the Jacobian and the hidden layer outputs on each data point. Additionally, the paper also requires the pre-activations to be sufficiently large, which as the authors \nacknowledge, is an unrealistic assumption that is not true in practice. Despite that, the paper makes an important contribution towards our current understanding of \ngeneralization of deep nets. It would have been helpful if the authors had a more detailed discussion on how their assumptions relate to the specific assumptions in the papers\nof Arora et al. and Neyshabur et al. This would help when comparing the results of the paper with existing ones. ', 'This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model. While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution. This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain.\n\nI think the paper could have been written more clearly. I had a hard time following the arguments in the paper. For example, I had to start reading from the Appendix to understand what is going on and found the appendix more helpful than the main text. Moreover, the constraints should be discussed more clearly and verified through experiments.\n\nI see Constraint 2 as a major shortcoming of the paper. The promise of the paper was to avoid making assumptions on the input domain (one of the drawbacks in Neyshabur et al 2018) but the constraint 2 is on any input in the domain. In my view, this makes the result less interesting.\n\nFinally, as authors mention themselves, I think conditions in Theorem F.1 (the label should be 4.1 since it is in Section 4) could be improved with more work. More specifically, it seems that the condition on the pre-activation value can be improved by rebalancing using the positive homogeneity of ReLU activations.\n\nOverall, while I find the motivation and the approach interesting, I think this is not a complete piece of work and it can be improved significantly.\n\n===========\nUpdate: Authors have addressed my main concern, improved the presentation and added extra experiments that improve the quality of the paper.  I recommend accepting this paper. ']","[-20, 80, 60, 50]","[60, 90, 70, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' work, they express major concerns about the dependence on pre-activation parameters and the potential misleading nature of the noise resilience claim. The reviewer suggests that the overall generalization bound might be larger than existing results, which indicates a critical stance. However, the tone is not entirely negative as they also recognize the improved dependence on network dimensions.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'My major concern is...' and 'I also suggest that...' which are polite ways of expressing criticism and making recommendations. The reviewer also acknowledges the authors' work and provides constructive feedback, which contributes to the polite tone. There are no rude or harsh statements, and the critique is presented in a balanced and considerate manner."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper, describing it as 'honest, original and rigorous' and stating that it 'deserves to be presented to the community'. The reviewer also appreciates the authors' candor and sees value in the work's potential to stimulate discussion. The final update further reinforces the positive sentiment by increasing the score and explicitly stating the work deserves publication. The politeness score is 90 (very polite) due to the reviewer's respectful and constructive tone throughout. They acknowledge the paper's strengths, offer balanced feedback, and express appreciation for the authors' honesty. The language used is professional and courteous, with no harsh criticisms or rude remarks. The reviewer even takes care to explain their thought process and limitations (e.g., 'I had only a quick look at the proofs'), which adds to the overall politeness of the review."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's 'important contribution' and provides a detailed summary of its contents, indicating overall approval. However, they also point out some limitations, such as 'unrealistic assumptions' and the need for more detailed comparisons with existing work, which prevents a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively (e.g., 'It would have been helpful if...'). The tone is professional and objective, without any harsh or dismissive comments."", ""The sentiment score is 50 (slightly positive) because the reviewer initially expresses some concerns and criticisms, but in the update, they recommend accepting the paper after the authors addressed their main concerns. This shows a positive shift in sentiment. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive criticism. They use phrases like 'I think' and 'Overall, while I find the motivation and the approach interesting' which maintain a polite tone even when expressing concerns. The update is particularly polite, acknowledging the authors' improvements without any negative language.""]"
"['This paper introduces the study of the problem of frequency estimation algorithms with machine learning advice. The problem considered is the standard frequency estimation problem in data streams where the goal is to estimate the frequency of the i-th item up to an additive error, i.e. the |\\tilde f_i - f_i| should be minimized where \\tilde f_i is the estimate of the true frequency f_i.\n\nPros:\n-- Interesting topic of using machine learned advice to speed up frequency estimation is considered\n-- New rigorous bounds are given on the complexity of frequency estimation under Zipfian distribution using machine learned advice\n-- Experiments are given to justify claimed improvements in performance\n\nCons:\n\n-- While the overall claim of the paper in the introduction seems to be to speed up frequency estimation using machine learned advice, results are only given for the Zipfian distribution.\n\n-- The overall error model in this paper, which is borrowed from Roy et al. is quite restrictive as at it assumes that the queries to the frequency estimation data structure are coming from the same distribution as that given by f_i’s themselves. While in some applications this might be natural, this is certainly very restrictive in situations where f_i’s are updated not just by +/-1 increments but through arbitrary +/-Delta updates, as in this case it might be more natural to assume that the distribution of the queries might be proportional to the frequency that the corresponding coordinate is being updated, for example.\n\n-- The algorithm proposed in the paper is very straightforward and just removes heavy hitters using oracle advice and then hashes everything else using the standard CountMin sketch.\n\n-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher’18.\n\n-- The analysis is relatively straightforward and boils down to bucketing the error and integration over the buckets.\n\n\nOther comments:\n-- The machine learned advice is assumed to be flawless at identifying the Heavy Hitters, authors might want to consider incorporating errors in the analysis.\n\n\n\n', 'Quality/clarity:\n- The problem setting description is neither formal nor intuitive which made it very hard for me to understand exactly the problem you are trying to solve. Starting with S and i: I guess S and i are both simply varying-length sequences in U.\n- In general the intro should focus more on an intuitive (and/or formal) explanation of the problem setting, with some equations that explain the problem you want to work on. Right now it is too heavy on \'related work\' (this is just my opinion).\n\nOriginality/Significance:\nI have certainly never seen a ML-based paper on this topic. The idea of \'learning\' prior information about the heavy hitters seems original.\n\nPros:\nIt seems like a creative and interesting place to use machine learning. the plots in Figure 5.2 seem promising.\n\nCons:\n- The formalization in Paragraph 3 of the Intro is not very formal. I guess S and i are both simply varying-length sequences in U.\n- In general the intro should focus more on an intuitive (and/or formal) explanation of the problem setting, with some equations that explain the problem you want to work on. Right now it is too heavy on \'related work\' (this is just my opinion).\n\n-In describing Eqn 3 there are some weird remarks, e.g. ""N is the sum of all frequencies"". Do you mean that N is the total number of available frequencies? i.e. should it be |D|? It\'s not clear to me that the sum of frequencies would be bounded if D is not discrete.\n- Your F and \\tilde{f} are introduced as infinite series. Maybe they should be {f1, f2,..., fN}, i.e. N queries, each of which you are trying to be estimate.\n- In general, you have to introduce the notation much more carefully. Your audience should not be expected to be experts in hashing for this venue!! \'C[1,...,B]\' is informal abusive notation. You should clearly state using both mathematical notation AND using sentences what each symbol means. My understanding is that that h:U->b, is a function from universe U to natural number b, where b is an element from the discrete set {1,...,B}, to be used as an index for vector C. The algorithm maintains this vector C\\in N^B (ie C is a B-length vector of natural numbers). In other words, h is mapping a varying-length sequence from U to an *index* of the vector C (a.k.a: a bin). Thus C[b] denotes the b-th element/bin of C, and C[h(i)] denotes the h(i)-th element. \n- Still it is unclear where \'fj\' comes from. You need to state in words eg ""C[b] contains the accumulation of all fj\'s such that h(j)=b; i.e. for each sequence j \\in U, if the hash function h maps the sequence to bin b (ie $h(j)=b$), then we include the *corresponding frequency* in the sum.""\n- What I don\'t understand is how fj is dependent on h. When you say ""at the end of the stream"", you mean that given S, we are analyzing the frequency of a series of sequences {i_1,...,i_N}?\n- Sorry, it\'s just confusing and I didn\'t really understand ""Single Hash Function"" from Sec 3.2 until I started typing this out.\n- The term ""sketch"" is used in Algorithm1, like 10, before \'sketch\' is defined!!\n-I\'m not going to trudge through the proofs, because I don\'t think this is self-contained (and I\'m clearly not an expert in the area).\n\nConclusion:\nHonestly, this paper is very difficult to follow. However to sum up the idea: you want to use deep learning techniques to learn some prior on the hash-estimation problem, in the form of a heavy-hitter oracle. It seems interesting and shows promising results, but the presentation has to be cleaned up for publication in a top ML venue.\n\n\n\n******\nUpdate after response:\nThe authors have provided improvements to the introduction of the problem setting, satisfying most of my complaints from before. I am raising my score accordingly, since the paper does present some novel results.', 'The authors are proposing an end-to-end learning-based framework that can be incorporated into all classical frequency estimation algorithms in order to learn the underlying nature of the data in terms of the frequency in data streaming settings and which does not require labeling. According to my understanding, the other classical streaming algorithms also do not require labeling but the novelty here I guess lie in learning the oracle (HH) which feels like a logical thing to do as such learning using neural networks worked well for many other problems.\n\nThe problem formulation and applications of this research are well explained and the paper is well written for readers to understand. The experiments show that the learning based approach performs better than their all unlearned versions. \n\nBut the only negative aspect is the basis competitor algorithms are very simple in nature without any form of learning and that are very old. So, I am not sure if there are any new machine learning based frequency estimation algorithms.  \n\n\n']","[-20, -20, 50]","[50, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') that outweigh them. The reviewer points out limitations in the paper's scope, restrictive assumptions, and questions the novelty of the approach. However, the tone isn't entirely negative as the reviewer recognizes the interesting topic and new bounds provided. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present both pros and cons in a balanced manner, and phrase criticisms as observations rather than harsh judgments. The use of phrases like 'authors might want to consider' in the final comment shows a constructive approach rather than a dismissive one."", ""The sentiment score is slightly negative (-20) because the reviewer points out several issues with the paper, particularly regarding clarity and formalization. However, they also note some positive aspects like originality and promising results. The initial review is quite critical, but the update after response is more positive, indicating some improvement. The politeness score is slightly positive (20) because the reviewer uses professional language and offers constructive criticism. They apologize for not understanding certain parts and acknowledge their lack of expertise in some areas. The reviewer also provides detailed suggestions for improvement, which is helpful and courteous. However, some phrases like 'I'm not going to trudge through the proofs' could be seen as slightly impolite, preventing a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and potential of the proposed framework, praising its well-explained problem formulation and improved performance. However, they also express a concern about the simplicity of the competitor algorithms, which prevents a more strongly positive score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively and framing their criticism constructively. They use phrases like 'According to my understanding' and 'I am not sure if' which soften their critique and maintain a courteous tone.""]"
"['Interesting work, extending previous work by Balestriero and Baraniuk in a relevant and non-trivial direction. The presentation could be cleaner and clearer, \n\nThe paper contains solid work and contributes to an interesting perspective/interpretation of deep networks. The presentation is reasonably clear, although somewhat cluttered by a large number of subscripts and superscripts, which could be avoided by using a more modular formulation; e.g., in equation (1), when referring to a specific layer l, the superscript l can be dropped as it adds no useful information. By the way, when l is first used, just before equation (1), it is undefined, although the reader can guess what it stands for.\n\nIt is not clear why $[\\pi^{(l)}]_{k,t}$ is defined after equation (5), as these quantities are not mentioned in Theorem 2. Another confusion issue is that it is not clear if the assumption made in Proposition 1 concerning is only valid there of if it is assued to hold elsewhere in the paper.\n\nProposition 2 is simply a statement of the well-known relationship between between soft-max (a.k.a. logistic regression) and the maximum entropy principle (see, for example, http://www.win-vector.com/dfiles/LogisticRegressionMaxEnt.pdf).\n\n', 'This work extends the applicability of the spline theory of deep networks explored in previous works of Balestriero/ Baraniuk. The previous works setup DNs as layer-wise max-affine spline operators (MASOs) and recovers several non-linearities practically used as special cases of these MASOs. The previous works already recover RELU variants and some downsampling operators that the current submission characterizes as ""hard"" quantization.\n\nThe major contribution of this work is extending the application to ""soft"" quantization that recovers several new non-linear activations such as soft-max. It is well-known that the k-means algorithm can be considered as a run of an EM algorithm to recover the mean parameters of a gaussian mixture model. The ""hard"" to ""soft"" transformation, and any interpolation in between follows from combining this insight with the previous works. As such there isnt a major technical contribution imho in this work. Furthermore, the presented orthogonalization for easier inference has been used before in many works, some of which this submission also cites, most importantly in the previous work of Balestriero/ Baraniuk that this submission extends. \n\nNevertheless there is value in novel results that may follow from previous works in a straightforward but non-trivial fashion, as long as it is well-presented and thoroughly researched and implication well-highlighted. This paper does that adequately, so I will suggest weak accept. Furthermore, this work could spark interesting future works and fruitful discussions at the ICLR. It is well-written and the experimental evaluation is adequate.\n\nI would suggest a couple of ways to possibly improve the exposition. The paper is somewhat notation heavy. When considering single layers, the superscript for the layer could be dropped in favor of clarity. I would suggest moving the definition of MASOs to the main text, and present Proposition 8 in some form in the main text as well. To a reader not familiar with previous works, or with splines, this could be helpful. Use of orthogonalization could be highlighted not just a tool for tractability but also regularization. For inference on GMMs, it corresponds to a type of variational inference, which could be mentioned. \n', ""At the core of this paper is the insight from [1] that a neural network layer constructed from a combination of linear, piecewise affine and convex operators can be interpreted as a max-affine spline operator (MASO). MASOs are directly connected to vector quantization (VQ) and K-means clustering, which means that a deep network implicitly constructs a hierarchical clustering of the training data during learning. This paper now substitutes VQ with probabilistic clustering models (GMMs) and extends the MASO interpretation of a wider range of possible operations in deep neural networks (sigmoidal activation functions, etc.).\n\nGiven the detailed treatment of MASOs in [1], this paper is a logical continuation of this approach. As such, it may seem only incremental, but I would consider it as an important piece to ensure a solid foundation of the 'MASO-view' on deep neural networks.\n\nMy main criticism is with respect to the quality and clarity of the presentation. Without reading in detail [1] it is very difficult to understand the presented work here. Moreover, compared to [1], a lot of explanatory content is missing, e.g. [1] had nice visualisations of the resulting partitioning on toy data.\n\nClearly, this work and [1] belong together in a larger form (e.g. a journal article), I hope that this is considered by the authors.""]","[50, 40, 50]","[60, 70, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the work as 'interesting' and 'solid', and acknowledges its contribution to the field. However, they also point out several areas for improvement in presentation and clarity, which prevents a higher score. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the paper's strengths before discussing its weaknesses, which is a polite approach. The reviewer also uses phrases like 'it is not clear' instead of more accusatory language, maintaining a professional and courteous tone."", ""The sentiment score is 40 (slightly positive) because while the reviewer acknowledges the paper's value and suggests a 'weak accept', they also point out that there isn't a major technical contribution. The overall tone is constructive and appreciative of the work's potential impact. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. The reviewer acknowledges the paper's strengths and potential while diplomatically pointing out areas for enhancement, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as a 'logical continuation' and an 'important piece' in the field, despite noting it may seem incremental. They also express hope for future work. However, they do criticize the presentation quality, which prevents a higher score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the paper's merits before presenting concerns, and phrase criticisms as suggestions (e.g., 'I hope that this is considered by the authors'). The reviewer maintains a professional and courteous tone throughout the review.""]"
"['The authors propose an exploration bonus that is aimed to aid in sparse reward RL problems. The bonus is given by an auxillary network which tries to score whether a candidate observation is difficult to reach with respect to all previously observed novel observations which are stored in a memory buffer. The paper considers many experiments on complex 3D environments. \n\nThe paper is well written and very well illustrated. The method can be clearly understood from the 3 figures and the examples are nice. I think the method is interesting and novel and it is evaluated on a realistic and challenging problem.\n\nIt would be good if the authors could further elaborate on the scalability of the method in terms of compute/memory requirements and related to that if the implementation is cumbersome. I didn’t understand well how the method avoids the issue of old memories leaving the buffer. It seems for a large enough environment important observations will eventually become discarded causing a poor approximation of the curiosity bonus? For the large scale experiments I would like to know more rough details of the number of the compute time needed for the method relative to the PPO baseline and the other baseline (e.g. number of nodes for example and how long they run approximately)\n\nAre there any potential issues with adapting the method on 2D environments like Atari? this could permit direct comparisons with several other recently proposed techniques in this area.\n\nThe Grid-Oracle result is very interesting and a contribution on it’s own if similar results for complex 3D environments are not published anywhere else. It demonstrates well that exploration bonuses can help drastically in these tasks. I think if possible it would be interesting to have an idea how fast this method converges (number of training steps) and not just the final reward as reported in the tables. Indeed as a general problem the current number of training steps of any methods shown seem to indicate these techniques are too data hungry for non-simulated environments. For some applications (e.g. aimed at sim-to-real transfer) the grid-oracle approach might be a good alternative to consider. I would be interested to know if the authors had some thoughts on this.\n\nOverall I lean towards accept, the method is shown to work on relatively very complex problems in DMLab and VizDoom while most sparse reward solutions proposed are typically evaluated on relatively simpler and unrealistic tasks. I would consider to further increase my score if the authors can address some of the comments. \n', 'In this paper, the authors study the problem of exploration in RL when the reward process is sparse. They introduce a new curiosity based approach which considers a state novel if it was not visited before and is far from the visited states. They show that their methods perform better than two other approaches, one without curiosity-driven exploration and the second one a one-step curiosity-driven approach. \n\nThe paper is well-written and easy to follow. The authors motivate this work by bringing an example where the state observation might be novel but important. They show that if part of the environment just changes randomly, then there is no need to explore there as much as vanilla curiosity-driven approaches to suggest. The approach in this paper partially addresses this drawback of curiosity-driven approaches. The authors miss the point why the curiosity-driven exploration approaches as in this work are in interest. \n\nThe problem mentioned in this paper can be also solved based on efficient exploration-exploration methods where the distribution of next states is considered rather than the samples themselves. An efficient explorative/exploitative RL agent explores part of state space more if there is uncertainty in the reward and state distribution rather than not being able to predict a particular sample. In curiosity-driven approaches, if the predictability of the next state is considered, all methods are sentenced to failure in stochastic environments. The approach in this paper partially mitigate this problem but for a very specific environment setup, but still, fails if the environment is stochastic. \n\n', ""The main idea of this paper is to propose a heuristic method for exploration in deep reinforcement learning. The work is fairly innovative in its approach, where an episodic memory is used to store agent’s observations while rewarding the agent for reaching novel observations not yet stored in memory. The novelty here is determined by a pre-trained network that computes the within k-step-reachability of current observation to the observations stored in memory. The method is quite simple but promising and can be easily integrated with any RL algorithm.\n\nThey test their method on a pair of 3D environments, VizDoom and DMLab. The experiments are well executed and analysed. \n\nPositives:\n-\tThey do a rigorous analysis of parameters, and explicitly count the pre-training interactions with the environment in their learning curves.\n-\tThis method does not hurt when dense environmental rewards are present.\n-\tThe memory buffer is smaller than the episode length, which avoids trivial solutions.\n-\tThe idea of having a discriminator assess distance between states is interesting.\n\nQuestions and critics:\n-\tThe tasks explored in this paper are all navigation based tasks, would this method also apply equally successfully to non-navigation domains such as manipulation? \n-\tMy main concern is that the pre-training of the embedding and comparator networks directly depends on how good the random exploration policy is that collects the data. In navigation domains it makes sense that the random policy could cover the space fairly well, however, this will not be the case for more complex tasks involving more complex dynamics.\n-\tIt was surprising to me that the choice of k does not seem to be that important. As it implicitly defines what “novelty” means for an environment, I would have expected that its value should be calibrated better. Could that be a function of the navigation tasks considered?\n-\tThe DMLab results are not great or comparable to the state-of-the-art methods, which may hinder interpreting how good the policies really are. This was perhaps a conscious choice given they are only interested in early training results, but that seems like a confound.\n-\tThe architecture does not include an RNN which makes certain things very surprising even though they shouldn't (e.g. firing, or moving around a corner, are specifically surprising for ICM) as they cannot be learnt, but perhaps if they had an RNN in the architecture these would be easy to explain? Would be interesting to see what are the authors thoughts on this (apart from their computational complexity argument they mention)?\n-\tHaving the memory contain only information about the current episode with no information transfer between episodes seems a bit strange to me, I would like to hear the motivation behind this?\n-\tThe fact that the memory is reset between episodes, and that the buffer is small, can mean that effectively the method implements some sort of complex pseudo count over meta-states per episode? \n-\tThe embedding network is only trained during the pre-training phase and frozen during the RL task. This sounds a bit limiting to me: what if the agent starts exploring part of the space that was not covered during pre-training? Obviously this could lead to collapses when allowing to fine-tune it, but I feel this is rather restrictive. Again, I feel that the choice of navigation tasks did not magnify this problem, which would arise more in harder exploration tasks.\n-\tI think that alluding that their method is similar to babies’ behaviour in their cradle is stretched at best and not a constructive way to motivate their work…\n-\tIn Figure 6 and 7, all individual curves from each seed run are shown, which is a bit distracting. Perhaps showing the mean and std would be a cleaner and easier-to-interpret way to report these results?\n\nOverall, it is a simple and interesting idea and seems quite easy to implement. However, everything is highly dependent on how varying the environment is, how bad the exploration policy used for pre-training is, how good the embeddings are once frozen, and how k, action repeat and memory buffer size interact. Given that the experiments are all navigation based, it makes it hard for me to assess whether this method can work as well in other domains with harder exploration setups.\n"", 'This paper proposes a new method to give exploration bonuses in RL algorithms by giving larger bonuses to observations that are farther away (> k) in environment steps to past observations in the current episode, encouraging the agent to visit observations farther away. This is in contrast to existing exploration bonuses based on prediction gain or prediction error, which do not work properly for stochastic transitions.\n\nOverall, I very much like the idea, but I found many little pieces of confusing explanations that could be further clarified, and also some questionable implementation details. However the experimental results are very promising, and the approach should be modular and slotable into existing deep RL methods.\n\nSection Introduction: I’m confused by how you can define such a bonus if the memory is the current episode. Won’t the shortest-path distance of the next observation always be 1 because it is immediately following the current step, and thus this results in a constant bonus? You explain how you get around this in practice, but intuitively and from a high-level, this idea does not make sense. It would perhaps make more sense if you used a different aggregation, such average, in which case you would be giving bonuses to observations that are farther away from the past on average.\n\nAlso, while eventually this idea makes sense, it only makes sense within a single episode. If you clear the memory between episodes, then you are relying on some natural stochasticity of the algorithm to avoid revisiting the same states as in the previous episode. Otherwise, it seems like there is not much to be gained from actually resetting and starting a new episode; it would encourage more exploration to just continue the same episode, or not clear memory when starting a new episode.\n\nSection 2.2: You say you have a novelty threshold of 0 in practice, doesn’t this mean you end up always adding new observations to the memory? In this case, then it seems like your aggregation method of taking the 90th percentile is really the only mechanism that avoids the issue of always predicting a constant distance of 1 (and relying on the function approximator’s natural errors). \n\nI do think you should rework your intuition. It seems to me what you are actually doing is creating some sort of implicit discretization of the observation space, and rewarding observations that you have not seen before under this discretization. This is what would correspond to a shortest-path distance aggregation.\n\nExperiments: I like your grid oracle, as it acts as a baseline for using PPO and provides a point of reference for how well an exploration bonus could potentially be. But why aren’t grid oracle results put into your graphs? Your results look good and are very promising.\n\nOther points:\n- The pre-training of the R-network is concerning, but you have already responded with preliminary results.\n- I do share some of the concerns other reviewers have brought up about generality beyond navigation tasks, e.g. Atari games. To me, it seems like this method can run into difficulty when reachability is not as nice as it is in navigation tasks, for example if the decisions of the task followed a more tree-like structure. This also does not work well with the fact that you reset every episode, so there is nothing to encourage an agent to try different branches of the tree every episode.\n']","[70, 20, 50, 50]","[80, 50, 80, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written', 'very well illustrated', and the method as 'interesting and novel'. The reviewer also 'leans towards accept'. However, it's not 100 as there are some questions and suggestions for improvement. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'It would be good if...' and 'I would be interested to know...' which are polite ways of making suggestions. The reviewer also acknowledges the strengths of the paper before offering critiques, which is a polite approach in academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is well-written and easy to follow, and that the authors' approach partially addresses a drawback of curiosity-driven approaches. However, the reviewer also points out some limitations and criticisms, which prevents the score from being higher. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The reviewer avoids harsh or dismissive language, instead offering constructive feedback. The tone is professional and objective, which contributes to the politeness, though it doesn't reach the highest levels of overt courtesy."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's innovative approach and well-executed experiments, but also raises several questions and concerns. The review begins with positive points about the paper's main idea and methodology, followed by a balanced list of positives and critiques. The overall tone suggests the reviewer finds the work promising but with some limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing critiques as questions or suggestions rather than direct criticisms. The reviewer acknowledges the paper's strengths before presenting concerns, and uses phrases like 'I would like to hear' and 'Perhaps showing' to offer constructive feedback in a courteous manner."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses that they 'very much like the idea' and finds the experimental results 'very promising'. However, they also mention 'confusing explanations' and 'questionable implementation details', which tempers the positivity. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive feedback with areas for improvement. They use phrases like 'I'm confused by...' instead of more direct criticisms, and offer suggestions for improvement rather than just pointing out flaws. The reviewer also acknowledges the authors' responses to previous concerns, showing consideration for their perspective.""]"
"['The paper presents an application of Bayesian neural networks in predicting \nfuture street scenes. The inference is done by using variational approximation \nto the posterior. Moreover, the authors propose to using a synthetic (approximate)\nlikelihood and the optimization step in variational approxiation is based on a regularization.\nThese modifications are claimed by the authors that it yields a better results in practice \n(more stable, capture the multi-modal nature). Numerical parts in the paper support\nthe authors\' claims: their method outperforms some other state-of-the-art methods.\n\nThe presentation is not too hard to follow.\nI think this is a nice applied piece, although I have never worked on this applied side.\n\nMinor comment:\nIn the second sentence, in Section 3.1, page 3, \n$f: x \\mapsto y$    NOT $f: x \\rightarrow y$. \nWe use the ""\\rightarrow"" for spaces X,Y not for variables.  \n\n\n', 'The submission considers a disadvantage of a standard dropout-based Bayesian inference approach, namely the pessimization of model uncertainty by means of maximizing the average likelihood for every data sample. The formulation by Gal & Ghahramani is improved upon two-fold: via simplified modeling of the approximating variational distribution (on kernel/bias instead of on patch level), and by using a discriminator (i.e. classifier) for providing a ""synthetic"" likelihood estimate. The latter relaxes the assumptions such that not every data sample needs to be explained equally well by the models.\nResults are demonstrated on a variety of tasks, most prominently street scene forecasting, but also digit completion and precipitation forecasting. The proposed method improves upon the state of the art, while more strongly capturing multi-modality than previous methods.\n\nTo the best of my knowledge, this is the first work w.r.t. future prediction with a principled treatment of uncertainty. I find the contributions significant, well described, and the intuition behind them is conveyed convincingly. The experiments in Section 4 (and appendix) yield convincing results on a range of problems.\nClarity of the submission is overall good; Sections 3.1-3.3 treat the contributions in sufficient detail. Descriptions of both generator and discriminator for street scenes (Section 3.4) are sufficiently clear, although I would like to see a more detailed description of the training process (how many iterations for each, learning rate, etc?) for better reproducability.\nIn Section 3.4, it is not completely clear to me why the future vehicle odometry is provided as an input, in addition to past odometry and past segmentation confidences. I assume this would not be present in a real-world scenario? I also have to admit that I fail to understand Figure 4; at least I cannot see any truly significant differences, unless I heavily zoom in on screen.\n\nSmall notes:\n- Is the \'y\' on the right side of Equation (5) a typo? (should this be \'x\'?)\n- The second to last sentence at the bottom of page 6 (""Always the comparison..."") suffers from weird grammar', 'The work proposes a Bayesian neural network model that is a hybrid between autoencoders and GANs, although it is not presented like that. Specifically, the paper starts from a Bayesian Neural Network model, as presented in Gal and Ghahramani, 2016 and makes two modifications.\n\nFirst, it proposes to define one Bernoulli variational distribution per weight kernel, instead  of per patch (in the original work there was one Bernoulli distribution per patch kernel). As the paper claims, this reduces the complexity to be exponential to the number of weights, instead of the number of patches, which leads to a much smaller number of possible models. Also, because of this modification the same variational distributions are shared between locations, being closer to the convolutional nature of the model.\n\nThe second modification is the introduction of synthetic likelihoods. Specifically, in the original network the variational distributions are designed such that the KL-divergence of the true posterior p(ω|X, y) and the approximate posterior q(ω) is minimiezd. This leads to the optimizer encouraging the final model to be close to the mean, thus resulting in less diversity. By re-formulating the KL-divergence, the final objective can be written such that it depends on the likelihood ratio between generated/""fake"" samples and ""true"" data samples. This ratio can then be approximated by a GAN-like discriminator. As the optimizer now is forced to care about the ratio instead of individual samples, the model is more diverse.\n\nBoth modifications present some interesting ideas. Specifically, the number of variational parameters is reduced, thus the final models could be much better scaleable. Also, using synthetic likelihoods in a Bayesian context is novel, to the best of my knowledge, and does seem to be somewhat empirically justified. \n\nThe negative points of the paper are the following.\n\n- The precise novelty of the first modification is not clearly explained. Indeed, the number of possible models with the proposed approach is reduced. However, what is the degree to which it is reduced. With some rough calculations, for an input image of resolution 224x224, with a kernel size of 3x3 and stride 1, there should be about 90x90 patches. That is roughly a complexity of O(N^2) ~ 8K (N is the number of patches). Consider the proposed variational distributions with 512 outputting channels, this amount to 3x3x512 ~ 4.5K. So, is the advantage mostly when the spatial resolution of the image is very high? What about intermediate layers, where the resolution is typically smaller?\n\n- Although seemingly ok, the experimental validation has some unclarities.\n  + First, it is not clear whether it is fair in the MNIST experiment to report results only from the best sampled model, especially considering that the difference from the CVAE baseline is only 0.5%. The standard deviation should also be reported.\n  + In Table 2 it is not clear what is compared against what. There are three different variants of the proposed model. The WD-SL does exactly on par with the Bayes-Standard (although for some reason the boldface font is used only for the proposed method. The improvement appears to come from the synthetic likelihoods. Then, there is another ""fine-tuned"" variant for which only a single time step is reported, namely +0.54 sec. Why not report numbers for all three future time steps? Then, the fine-tuned version (WD-SL-ft) is clearly better than the best baselines of Luc et al., however, the segmentation networks are also quite different (about 7% difference in mIoU), so it is not clear if the improvement really comes from the synhetic likelihoods or from the better segmentation network. In short, the only configuration that appears to be convincing as is is for the 0.06 sec. I would ask the authors to fill in the blank X spots and repeat fair experiments with the baseline.\n\n- Generally, although the paper is ok written, there are several unclarities.\n  + Z_K in eq. (4) is not defined, although I guess it\'s the matrix of the z^{i, j}_{k, k\'}\n  + In eq (6) is the z x σ a matrix or a scalar operation? Is z a matrix or a scalar?\n  + The whole section 3.4 is confusing and it feels as if it is there to fill up space. There is a rather intricate architecture, but it is not clear where it is used. In the first experment a simple fully connected network is used. In the second experiment a ResNet is used. So, where the section 3.4 model used?\n  + In the first experiment a fully connected network is used, although the first novelty is about convolutions. I suppose the convolutions are not used here? If not, is that a fair experiment to outline the contributions of the method?\n  + It is not clear why considering the mean of the best 5% predictions helps with evaluating the predicted uncertainty? I understand that this follows by the citation, but still an explanation is needed.\n\nAll in all, there are some interesting ideas, however, clarifications are required before considering acceptance.']","[70, 80, -20]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as a 'nice applied piece' and mentions that the presentation is 'not too hard to follow'. They also note that the numerical parts support the authors' claims and that their method outperforms other state-of-the-art methods. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames their only criticism as a 'Minor comment'. The reviewer also admits their own limitations ('I have never worked on this applied side'), which shows humility. The overall tone is constructive and supportive, with only a small technical correction offered politely at the end."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, calling the contributions 'significant' and 'well described', and stating that the results are 'convincing'. They also note that it's the first work of its kind with a 'principled treatment of uncertainty'. The few criticisms are minor and presented as requests for clarification rather than major flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They phrase their suggestions and questions politely, using phrases like 'I would like to see' and 'I have to admit'. The reviewer also provides constructive feedback and helpful suggestions for improvement, which is a polite way to offer criticism. The language is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas and novel aspects of the work, they also point out several significant issues and unclarities that require addressing before acceptance. The review starts positively but then lists multiple negative points and areas needing clarification, indicating an overall slightly negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting ideas' and 'novel' to acknowledge positive aspects. Even when pointing out issues, the language remains constructive and not personally critical, using phrases like 'clarifications are required' rather than harsh criticism. The reviewer also provides detailed explanations for their concerns, which is a polite way to give feedback.\n\nThe combination of constructive criticism, acknowledgment of positive aspects, and the use of professional language throughout results in a review that is slightly negative in sentiment but quite polite in tone.""]"
"['This paper studies convergence of gradient descent on a two-layer fully connected ReLU network with binary output and square loss. The main result is that if the number of hidden units is polynomially large in terms of the number of training samples, then under suitable randomly initialization conditions and given that the output weights are fixed, gradient descent necessarily converge to zero training loss.\n\nPros:\nThe paper is presented clearly enough, but I still urge the authors to carefully check for typos and grammatical mistakes as they revise the paper. As far as I have checked, the proofs are correct. The analysis is quite simple and elegant. This is one thing that I really like about this paper compared to previous work. \n\nCons:\nThe current setting and conditions for the main result to hold are quite a bit limited. If one has polynomially large number of neurons (i.e. on the order of n^6 where n is number of training samples) as stated in the paper, then the weights of the hidden layer can be easily chosen so that the outputs of all training samples become linearly independent in the hidden layer (see e.g. [1] for the construction, which requires only n neurons even with weight sharing) , and thus fixing these weights and optimizing for the output weights would lead directly to a convex problem with the same theoretical guarantee. At this point, it would be good to explain why this paper is focusing on the opposite setting, namely fixing the output weights and learning just the hidden layer weights, because it seems that this just makes the problem become more non-trivial compared to the previous case while yielding almost the same results . Either way, this is not the way how practical neural networks are trained as only a subset of the weights are optimized. Thus it\'s hard to conclude from here why the commonly used GD w.r.t. all variables converges to zero loss as stated in the abstract.\n\nThe condition on the Gram matrix H_infty in Theorem 3.1 seems to be critical. I would like to see the proof that this condition can be fulfilled under certain conditions on the training data.\n\nIn Lemma 3.1, it seems that ""log^2(n/delta)"" should be ""log(n^2/delta)""? \n\nDespite the above limitations, I think that the analysis in this paper is still interesting (mainly due to its simplicity) from a theoretical perspective. Given the difficulty of the problem, I\'m happy to vote for its acceptance.\n\n[1] Optimization landscape and expressivity of deep CNNs', ""This work considers optimizing a two-layer over-parameterized ReLU network with the squared loss and given a data set with arbitrary labels. It is shown that for a sufficiently large number of hidden neurons (polynomially in number of samples) gradient descent converges to a global minimum with a linear convergence rate. The proof idea is to show that a certain Gram matrix of the data, which depends also on the weights, has a lower bounded minimum eigenvalue throughout the optimization process. Then, it is shown that this property implies convergence of gradient descent.\n\nThis work is very interesting. Proving convergence of gradient descent for over-parameterized networks with ReLU activations and data with arbitrary labels is a major challenge. It is surprising that the authors found a relatively concise proof in the case of two-layer networks. The insight on the connection between the spectral properties of the Gram matrix and convergence of gradient descent is nice and seems to be a very promising technique for future work. One weakness of the result is the extremely large number of hidden neurons that are required to guarantee convergence.\n\nThe paper is clearly written in most parts. The statement of Lemma 3.2 and its application appear to be incorrect as mentioned in the comments. I am convinced by the authors' response and the current proof that it can be fixed by defining an event which is independent of t. Moreover, I think it would be nice to include experiments that corroborate the theoretical findings. Specifically, it would be interesting to see if in practice most of the patterns of ReLUs do not change or if there is some other phenomenon.\n\nAs mentioned in the comments, it would be good to add a discussion on the assumption of non-degeneracy of the H^{infty} matrix and include a proof (or exact reference) which shows under which conditions the minimum eigenvalue is positive.\n\n-------------Revision--------------\n\nI disagree with most of the points that AnonReviewer3 raised (e.g., second layer fixed is not hard, contribution is limited). I do agree that the main weakness is the number of neurons.  However, I think that the result is significant nonetheless. I did not change my original score.\n"", ""This paper studies one hidden layer neural networks with square loss, where they show that in over-parameterized setting, random initialization + gradient descent gets to zero loss. The results depend on the property of data matrix, but not the output values.\n\nThe high level idea of the proof is quite different from recent papers, and it would be quite interesting to see how powerful this is for deep neural nets, and whether any insights could help practitioners in the future. \n\nSome discussions regarding the results: \n\nI would suggest the authors to be specific about ‘with high probability’, whether it is 1-c, or 1-n^{-c}. The proof step using Markov’s inequality gives 1-c probability, which is stated as ‘with high probability’. What about other ‘high probability’ statements?\n\nIn the statement of Theorem 3.1 and 4.1, please add ‘i.i.d.’ (independence) for generating w_r s.\n\nThe current statement of Lemma 3.2 is confusing. The authors state that given t, w.h.p. (let’s say 0.9 for now) over initialization, the minimum eigenvalue is lower bounded. This does not imply, for example, that there exists an initialization, such that for 20 different t s, the minimum eigenvalue is lower bounded. The proof uses Markov’s inequality for a single t. Therefore, I am slightly worried about its correctness. I hope the authors could address my concern. \n\nAlso, in the proof of Lemma 3.2, (just to improve the readability,) I would suggest the authors to make it clear that the expectation is taken over the initialization of the weights. \n\nSome typos: \n\n‘converges’ -> ‘converges to’ in the abstract\n‘close’ -> ‘close to’ on page 5\n‘a crucial’ -> ‘a crucial role’ on page 5\nIn the proof of Lemma 3.2, x_0 should be x_i\nwhether using boldface for H_{ij} should be consistent\n'The next lemma shows we show' in page 6\n'Markov inequality' -> ‘Markov’s inequality’\n‘a fixed a neural network architecture’ in page 8\n\nIt is good to see other comments and discussions on this paper. I believe the authors will make a revision and I would be happy to see the new version of the paper and re-evaluate if some of my comments are not correct.  \n"", 'Additional Review\n\nThis paper did NOT handle the non-differentiability and non-linearity very well. We can see this from the following three perspectives:\n\n1. Proof idea: the proof of this paper is noisy version of the convergence analysis of  a simple convex problem --it treats the contribution of the non-linearity and non-differentiability as bounded noise.\n2. The network size is of order n^6.\n3. Network size requirement is dependent on \\lambda_0. \n\n1.Proof idea: The proof is essentially a noisy version of the convergence analysis of a linear regression problem provided in Appendix (at the end of this updated review). The only difference between linear regression and the problem in this paper is the changing patterns due to the non-linearity of ReLU. However, this paper views the changing patterns as noises compared to those unchanging patterns (e.g., S_i v.s. S_i^\\perpendicular). The key trick is that if the actual trajectory radius (i.e.,the largest deviation from the initial point) R’ is much smaller than the desired trajectory radius R (given by a formula), then along the trajectory, the contribution of non-linearity is just O(n^2 R), which is small compared to the contribution of linearity, i.e., -\\lambda_0 (shown in proof on page 9). \n\nFollowing the above analysis, if the experiment shows that R’ is really small compared to R, then the approach of treating non-linearity as noise is fine. However, it is not the case for the problem studied in the experiments (Sec 5, Fig 1). In figure 1, we can easily see that the maximum distance R’ is O(1), which is far larger than R = c*\\lambda_0/n^2 =10^-6 when n=1k. Therefore, the proof idea used in this paper is fundamentally not able to explain the phenomenon shown in the experiment. In fact, to address this issue, authors need to consider significant contribution of non-linearity, instead of just viewing them as noises. \n\n2. The network size is too large. This paper requires O(n^6) neurons, that is 10^18 neurons for n=1000 samples used in the experiment. The theoretical trick to make R’< R is to note that R’ can be bounded by O(1/sqrt{m}) while R is independent of m, thus picking a sufficiently large m can make R’ very small. In a word, the reason that this paper requires so many neurons because of the inability of properly addressing non-linearity. \n\n3. I found the dependence of the network size on the least eigenvalue funny, although the authors claim this tool is elegant. After authors add Thm 3.1 in the revision, I realize that the dependence on \\lambda_0 might come from the fact that authors do NOT handle the issue of non-differentiability. \n\nLet us see a simple example. Assume I have a dataset with \\lambda_0 = 1. Now I am adding one more data point (x=0_d, y=1) to the dataset. After adding this sample, \\lambda_0 clearly becomes 0. It seems I am just adding a constant 1 to the loss function and the gradient descent can also converge to the global min with a linear convergence rate since the constant does NOT contribution to the gradient. However, it seems the proof does NOT work. This is due to the fact that the “gradient” of the non-differentiable points are NOT well defined. Here is a simple example: h(w)=(y-ReLU(w*x))^2, where x= 0, y =1. By the definition provided in this paper (Eq.4), we can easily see that dh/dw = 1 for any w, even if h(w) = 1 for any w. This means that the constant can provide “fake” gradient information and make  the maximum distance become infinity, (R’=\\inf). Therefore, the whole proof collapses. In fact, changing the gradient definition from I{z>=0} to I{z>0} does not address the issue and we can see this from this example w=g(w)=Relu(w)-Relu(-w) has a zero gradient at w=0. \n\nIn summary, the problem considered in this paper where the size m=O(n^6), maximum distance R’= O(1/n^2) is too easy compared to most problems in practice where m=\\Theta(n), R’=O(1). To address the latter problem, we need a better definition of subgradient and need to analyze the significant contribution of non-linearity and non-differentiability, instead of just viewing them as noises. \n\n=================================Appendix===============================\n\nThe proof basically follows from the convergence analysis of the following linear regression problem (note that u_j is fixed):\n           \\min_{w_1,...,w_m}\\sum_{i=1}^{n}(f(x_i;w_1,...,w_m)-y_i)^2 = L(w_1,...,w_m)\nwhere   f(x;w_1,...,w_m)=1/\\sqrt{m}\\sum_{j=1}^{m} a_j*(w_j^T x)*1{u_j^T x>=0}\n\nGradient Descent Algorithm:\n-Initialization:\n-For each j=1,...,m: a_j ~ U({-1,1}), u_j~N(0, I)\n-Fix a_1,...,a_m, u_1,...,u_m\n-Update:\n-For t = 1,...,T\n    w_j(t+1)  = w_j(t) - \\eta* \\nabla_{w_j}L(w_1,...,w_m) for j=1,..., m.\n\nIn this problem, since a_j and u_j are fixed, then model f is just a linear model w.r.t. w_j’s and the above problem is just a simple linear regression problem. Therefore, it is not difficult to prove the linear convergence rate for the gradient descent for the above problem under some mild assumptions.  Note that in this paper, u_j(t)= w_j(t) and are not fixed in iterations, i.e., patterns can change. \n\n=========================\nFirst, I apologize to the authors and ACs for the late review, since this paper desearves much more time to judge the quality. \n\nSummary: This paper proves that the gradient descent/flow converges to the global optimum with zero training error under the settings (1) the neural network is a heavily over-parameterized ReLU network (i.e., requiting Omega(n^6) neurons); (2) the algorithm update rule “ignores” the non-differentiable point; (3) the parameters in the output layer (i.e., a_i’s) are fixed; (4) the data set has some non-degenerate properties and comes from a unit ball. The proof relies on the fact that the Gram matrix is always positive definite on the converging trajectory. \n\nPros: The proof is simple and seems to be correct. The paper is paper is written clearly  and easy to follow. \n\nCons:\n\nThe problem setting considered in this paper does not seem to be difficult enough. The difficulty of analyzing the landscape property of a ReLU network and proving the global convergence of the gradient descent mainly lies in the following three perspective and this paper does not try to tackle any one of them. \n\nFirst, it is very hard to characterize the landscape or the convergence trajectory at/ near the non-differentiable point and this paper fails to touch it. The parameter space is separated into several regions by the hyperplanes and the loss function is differentiable in the interior of each region and non-differentiable on the boundary. I believe the very first question authors need to answer is wether there are critical points on the boundary and why the sub-gradient descent escapes from  any of these points. However, in this paper, authors avoid this problem by defining an update rule used  in practice and this rule does not use the sub-gradient at the non-differentiable point. Thus, it is totally unclear to me wether this global convergence result comes from the fact that this update rule can generally avoid the non-differentiable  points on the boundary or the fact that the landscape is so nice such that there are no critical points on the boundary or the fact that all points on the convergence trajectory is differentiable only in this unique problem.\n\nSecond, the problem is much easier if the loss is not jointly optimized over the parameters in the first and second layer. Having parameters in one layer fixed does not seem to be a big problem at first glance, but then I realize it indeed makes the problem much easier, which can be seen in the following example. If we randomly sample the weight vector w_i from N(0, I) and only optimize  over the parameters in the second layer, then it is straightforward to show the following result.\n\nResult: If \\lambda_\\min(H^\\inf)>0 and m=\\Omega(n\\log n), then with high probability, the loss function L is strongly convex with respect to a=(a_1,…, a_m) and the loss function is zero at the global minimum.\n\nThe above result shows that if we fix the parameters in the first layer and only optimize the parameters in the second layer, it is easy to prove the global convergence with a linear convergence rate. In fact, this result does not require the samples coming from a unit ball and the network size is only slightly over-parameterized. Therefore, if we are allowed to fix the parameters in some layer, how are the result presented in this paper fundamentally different from the above result. \n\nAuthors may say that the loss is not convex with respect to the weights in the first layer even if the second layer is fixed. However, when the second layer is fixed, the loss function is  smooth and convex in each parameter region and some recent works have shown that in this case, the loss function is a weakly global function. This means that the loss function is similar to a convex function except those plateaus and this further indicates that if the initial point is chosen in a strictly convex basin, the gradient descent is able to converge to a global min.  However, the problem becomes far more difficult if the loss is jointly optimized over  all parameters in the first and second layer. This can be easily seen since in each parameter region, the loss is no longer a convex function and this may lead to some high order saddle points such that the gradient descent cannot provably escape. Furthermore, the critical points on the boundary can be much more difficult to characterize for this joint optimization problem. \n\n\nThird, the dataset considered in this paper does not seem to be a fundamental pattern and it seems more like a technical condition required by the proof. It is easy to see that a linearly separable dataset does not necessarily satisfy the conditions that 1) the gram matrix is positive definite and that 2) samples come from the surface of a unit ball. Therefore, I do not understand the reason why we need to analyze this pattern. Clearly, in practice, the data samples is unlikely sampled from a ball surface and it is totally unclear to me why the gram matrix is necessarily positive definite. I understand that some technical assumptions are needed in a theoretical work, but I would like to see more discussions on the dataset, e.g., some necessary conditions on the dataset such that the global convergence is possible.\n\n\nLast, I understand that the over-parameterization assumption is needed. In fact, I expect the network size to be of the order Omega(n*ploylog(n)). I am wondering wether Omega(n^6) is a necessary condition or wether there exists a case such that Theta(n^6) is required. \n\n\nAbove all, I believe this paper is a half-baked paper with some interesting explorations. In summary, it cannot deal with non-differential points, which is considered a major difficulty for analyzing ReLU. In addition, it makes an un-justified assumption on some matrix, it requires too many neurons, and fixed 2nd layer. With so many strong assumptions, and compared to related works like [1], Mei et al., Bach and ..., its contribution is rather limited.\n\n[1] https://arxiv.org/abs/1702.05777\n']","[50, 70, 60, -80]","[80, 80, 80, -20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper, but ultimately recommends acceptance. They appreciate the clarity and elegance of the analysis, while also pointing out limitations. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'I urge the authors' and 'I would like to see', and the overall respectful manner of presenting criticisms. The reviewer also uses positive language like 'I'm happy to vote for its acceptance' despite the limitations noted."", ""The sentiment score is 70 (positive) because the reviewer describes the work as 'very interesting' and 'surprising', highlighting its major contribution and promising techniques. They mention only one weakness (large number of hidden neurons required), indicating overall positive sentiment. The politeness score is 80 (quite polite) due to the respectful and constructive tone throughout. The reviewer acknowledges the paper's strengths, offers suggestions politely ('it would be nice to include...'), and disagrees with another reviewer's points without being rude. The language is professional and courteous throughout, avoiding harsh criticism and focusing on constructive feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper's approach and potential implications, stating it's 'quite interesting' and could potentially help practitioners. They also offer constructive feedback and express willingness to re-evaluate. The politeness score is 80 (very polite) due to the reviewer's respectful tone throughout. They use phrases like 'I would suggest,' 'please add,' and 'I hope the authors could address my concern,' which are polite ways of offering criticism. The reviewer also ends on a positive note, expressing eagerness to see a revised version. The high scores are not 100 because there are some critiques and concerns raised, but these are presented in a constructive and courteous manner."", ""The sentiment score is -80 because the review is highly critical of the paper, pointing out multiple significant flaws and limitations. The reviewer states that the paper 'did NOT handle the non-differentiability and non-linearity very well' and provides detailed explanations of why the approach is inadequate. They use strong negative language like 'fundamentally not able to explain', 'too large', and 'half-baked paper'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism and somewhat dismissive language. For example, phrases like 'I found the dependence... funny' and 'it seems more like a technical condition required by the proof' come across as slightly rude. However, the reviewer does apologize for the late review and acknowledges some positive aspects, which prevents the score from being lower.""]"
"['Evaluation:\nThis is a solid paper: The idea is clear, it is well communicated and put into context of the existing literature, and the results are promising. The experiments are well chosen and illustrate the method well. The connection between the chosen setting (BAMDPs) to POMDPs is explained well and explored in the empirical evaluation as well. I think that the methods section could go into a bit more detail, and the underlying assumptions that the authors make could be discussed more critically.\n\nSummary:\nThis paper looks at Bayes-Adaptive MDPs (BAMDPs) in which the latent parameter space is either\n- a discrete finite set or\n- a bounded continuous set that can be approximated via discretization.\nConsequently, the authors choose to represent the belief as a categorical distribution, which can be represented by a vector of weights.\nThey further assume that the environment model is known. Hence, the posterior belief can be computed exactly.\nIf I understand correctly, the main contribution is that the authors represent the policy as a neural network and train it using a policy gradient algorithm.\nThis is a good first step towards scalable Bayesian policy optimisation.\n\nMain Feedback:\n- In the Introduction, first paragraph, you say one of the aspects of real-world robotics is that there\'s ""(1) an underlying dynamical system with unknown latent parameters"". I would argue that the dynamic system itself is typically also unknown, including how it is parametrized by these latent parameters. I think it is important to point this out more explicitly in the introduction (it is mentioned in sec 2 and 5, but maybe it\'s worth mentioning it in 4 again as well): for the problems that you look at, you assume that the form of the transition function is known (just not its parameters phi). \n- In the main methods section (4), it would be nice to see some more detail about the Bayes filter. Can you write out the distribution over the latent parameters, and write out how the filtering is done? Explain how to compute the normalising constant (and mention explicitly why this is possible for your set-up, and why it would be infeasible if the latent space cannot be discretized). How exactly is the posterior distribution represented and fed to the policy? Seeing this done explicitly in Section 4 (even if it repeats some things that are explained in 2) would help someone that is interested in (re-)implementing the proposed method.\n- I would like to see a more critical discussion in Section 7 about the assumptions that the authors make: that the environment models are known, and that the latent space can be discretized. How realistic are those assumptions (and in which kind of real-world problems can we make them), and what are ways forward to drop these assumptions?\n\nOther Comments:\n- Introduction: Using an encoder for the state/belief is an implementation choice, and (as I see it) not part of the main contribution. I would focus on explaining the intuition behind BPO in the introduction, and only mention the architecture choice as a side note.\n- Related Work: The authors might be interested in the recent work of Igl et al. (ICML 2018, ""Deep Variational RL for POMDPs""), who approximate the belief in a POMDP using variational inference and a particle filter.\n\nSignificance for ICLR:\n- In the light-dark experiment, the authors visualise the belief that the agent has at every time step. It would have been nice to see an analysis of how exactly the belief looks also for maybe 1-2 other experiments, and how (when) the agent makes a decision based on this. This could replace Table 2 (which I guess should be called Figure 2?), which I did not find very insightful.', 'Summary: This paper proposes a policy optimization framework for Bayesian RL (BPO). BPO is based on a Bayesian model-based RL formulation. Using a Bayesian approach, it is expected to have better trade-off between exploration and exploitation in RL, and be able to deal with model uncertainty as well. Experiments are done on multiple domains consisting both POMDP planning tasks and RL.\n\nIn general, the paper is well written. Related work are thoroughly discussed. In my opinion, the proposed idea is a solid combination of existing techniques: Monte-Carlo sampling (step 3), Bayes belief update, and policy gradient in POMDP (G(PO)MDP). However, this combination is still worth trying and has been shown to scale to larger problems through the use of deep learning.\n\nI have some following major concerns about the paper:\n\n- Root sampling (step 3 in Algorithm 1) would result in sampled models that are fixed in every simulation. In a pure nature of Bayes RL, after each update at new observation (step 11: belief update), the model distribution already changes. Thus how does this Algorithm can guarantee an optimal solution for BAMDP? can the authors have more discussions on this point? Does this explain why TRPO (using a mean model) can perform comparably to BPO in Ant? \n\n- Belief representation is based on a Bayes filter which requires discretization. Finely discretized belief would increase the complexity and computation dramatically with the dimension of the latent space. This would result in very slow SIMULATE steps, especially for a long-horizon problem, let alone further computation for BatchPolicyOptimization.\n\n- I wonder how TRPO using RNN would perform in this case, instead of using a wrong starting model (an average model)?', 'In this paper, the author proposed to utilize a novel policy structure and recent batch policy optimization methods such as PPO or TRPO to solve Bayes-Adaptive MDP (BAMDP) and Partial Observable MDP(POMDP) problems. The author verified the proposed method on discrete and continuous POMDP and BAMDP benchmarks compared with other baseline methods.  \n\nThe main part of the paper is trying to explain Bayesian RL and the relationship between BAMDP and POMDP, and several related work. There is only a half page that explains the main idea of the proposed method, and it seems that the author combines several existing techniques and utilize deep learning to solve BAMDP and POMDP problems.\n\nThe detail of the experiment is not clarified explicitly, such as the structure and size of the policy, training details of the BPO, and detail parameters changed to formulate BAMDP for Mujoco environments.\n\nThe paper strikes me as a valuable contribution once the detail of the experiments are addressed, but personally I am not sure that whether the novelty of this paper is enough for the main conference track.', 'Summary:\n\nIn this paper, the authors propose a policy gradient algorithm for solving a Bayes-Adaptive MDP (BAMDP). At each iteration, the algorithm samples several MDPs from the prior distribution and simulates a trajectory for each sampled MDP. During the simulation, the algorithm uses a Bayes filter to update the posterior belief distribution at each time step. Finally, the algorithm uses the sampled trajectories and update the policy using the TRPO algorithm. \n\nThe authors propose to pass the state and belief through separate encoders, to reduce their dimensions, and then put them together and give them to the policy network. Although the experiments show that the encoding did not improve the performance significantly, except in the Lightdark problem. \n\nThe authors show that their algorithm can also be used to solve POMDPs by replacing the state-belief pair with just belief. Basically turning a POMDP to a belief state MDP and then applying the algorithm. They evaluate their algorithm in two POMDP problems, one discrete and one continuous, in both their algorithm achieves a reasonable performance. \n\nA tricky part of the algorithm is how to define a Bayes filter for continuous latent states. This is crucial in updating the posterior after each observation. The way the authors handle this is by discretization, and how the discretization should be done (high or low resolution) is a hyper parameter. Although the experiments indicate that the proposed algorithm, especially with encoders, is quite robust w.r.t. the discretization. \n\n\nComments:\n\n- The idea behind the algorithm proposed in the paper is quite simple. It is a combination of Bayesian optimization (sampling several MDPs from the prior), using a Bayes filter to update the belief, and a policy gradient algorithm (TRPO) to estimate the gradient and update the policy parameter. The only challenges are 1) the design of the Bayes filter, in particular when the latent state is continuous, in which the idea used in the paper is very simple, discretization, and 2) dealing with potentially high dimensional state-belief pair, which was handled by the encoders. \n\n- The structure of the paper could be improved significantly. Four pages have been dedicated to the preliminaries and related work, and another four pages to the experiments. This leaves only less than two pages for the algorithm. While I think a comprehensive discussion of the experiments is quite helpful, I found the preliminaries and related work too long. I even think that the experiments could have been written better. There are parts that have been explained too much and parts that are not clear or left for the appendix. With a better structure, the algorithm could have been explained better. I personally would like to see more discussion on how the distribution over MDPs is updated. \n\n-  I did not find the experiments very convincing. In BAMDP problems (Chain and MuJoCos), the proposed algorithm performs similarly to the adaptive policy gradient method. We only see improvement in the POMDP tasks (Tiger, Lightdark), which I think the main reason is that the algorithms selected for comparison are not the right algorithms for POMDPs. For example, many different algorithms have been used to solve Tiger (or other discrete POMDPs) in the POMDP literature, and I do not see any of them in the paper. \n ']","[60, 20, -20, -20]","[80, 60, 50, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by calling it a 'solid paper' and praises various aspects like clear communication, well-chosen experiments, and promising results. However, they also mention areas for improvement, which prevents a higher score. The politeness score is 80 (quite polite) due to the constructive tone throughout, use of phrases like 'it would be nice to see' and 'I would like to see', and the absence of harsh criticism. The reviewer offers suggestions in a respectful manner, balancing positive feedback with areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer begins with a generally positive tone, stating that the paper is 'well written' and the idea is 'solid'. However, they also express 'major concerns', which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'In my opinion' and 'I wonder', and frames criticisms as questions or suggestions rather than direct attacks. The reviewer also acknowledges the paper's strengths before presenting concerns, which is a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as a 'valuable contribution,' they express doubts about its novelty and suitability for the main conference track. They also point out several areas where more detail is needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's potential value and framing criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone, using phrases like 'personally I am not sure' to soften their critique about the paper's novelty."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express several criticisms and concerns. The reviewer notes that the idea is 'quite simple' and that the experiments are not 'very convincing'. They also suggest that the paper structure 'could be improved significantly'. However, they do recognize some merits, such as the algorithm achieving 'reasonable performance' in some tasks.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, such as 'could be improved' rather than more harsh phrasing. The reviewer also balances negative points with positive observations. However, the score is not higher because the review lacks explicitly polite language or praise, focusing more on a neutral, matter-of-fact tone.""]"
"['\n\n[clarity]\nThis paper is basically well written. \nThe motivation is clear and reasonable.\nHowever, I have some points that I need to confirm for review (Please see the significance part).\n\n\n[originality]\nThe idea of taking advantage of von Mises-Fisher distributions is not novel in the context of DL/DNN research community.\nE.g.,\nvon Mises-Fisher Mixture Model-based Deep learning: Application to Face Verification.\n\nHowever, as described in the paper, the incorporation of von Mises-Fisher for calculating loss function seems to be novel, to the best of my knowledge.\n\n\n[significance]\nUnfortunately, the experiments in this paper do not fully support the effectiveness of the proposed method. \nSee below for more detailed comments.\n\n\n*weak baseline (comparison)\nAs an anonymous reviewer pointed out, the author should run baseline method with beam search if the authors aim to convince readers (including reviewers) for the effectiveness of the proposed method.\nI understand that it is important to investigate the effectiveness of the proposed method in the identical settings. However, it is also important to compare the proposed method with strong baseline to reveal the relative effectiveness of the proposed method comparing with the current state-of-the-art methods. \n\n\n* open vocabulary setting\nI am confused whether the experimental setting for the proposed method is really in an open vocabulary setting or not.\nIf my understanding is correct, the vocabulary sizes used for the proposed method were 50,000 (iwslt2016) and 300,000 (wmt16), which cannot be an open vocabulary setting. \nIf this is correct, the applicability of the proposed method is potentially limited comparing with the subword-based approach.\nIs there any comment for this question?\n\n\n* convergence speed\nI think the claim of faster convergence of the proposed method in terms of iteration may be misleading. This might be true, but it is empirically proven only by single dataset and single run. The authors should show more empirical results on several datasets or provide a theoretical justification for this claim.\n\n\nOverall, basically I like the idea of the proposed method. \nI also aim to remove the large computational cost of softmax in neural encoder-decoder approach.\nIn my feeling, the proposed method should be a bit more improved for a recommendation of clear acceptance.\n', 'This paper describes a technique for replacing the softmax layer in sequence-to-sequence models with one that attempts to predict a continuous word embedding, which will then be mapped into a (potentially huge) pre-trained embedding vector via nearest neighbor search. The obvious choice for building a loss around such a prediction (squared error) is shown to be inappropriate empirically, and instead a von Mises-Fisher loss is proposed. Experiments conducted on small-data, small-model, greedy-search German->English, French->English and English->French scenarios demonstrate translation quality on par with BPE, and superior performance to a number of other continuous vector losses. They also provide convincing arguments that this new objective is more efficient in terms of both time and number of learned parameters.\n\nThis is a nice innovation for sequence-to-sequence modeling. The technical contribution required to make it work is non-trivial, and the authors have demonstrated promising results on a small system. I’m not sure whether this has any chance of supplanting BPE as the go-to solution for large vocabulary models, but I think it’s very healthy to add this method to the discussion.\n\nOther than the aforementioned small baseline systems, this paper has few issues, so I’ll take some of my usual ‘problems with the paper’ space to discuss some downsides with this method. First: the need to use pre-trained word embeddings may be a step backward. It’s always a little scary to introduce more steps into the pipeline, and it’s uncomfortable to hear the authors state that they may be able to improve performance by changing the word embedding objective. As we move to large training sets, having pre-trained embeddings is likely to stop being an advantage and start being a hindrance. Second: though this can drastically increase vocabulary sizes, it is still a closed vocabulary model, which is a weakness when compared to BPE (though I suppose you could do both).\n\nSmaller issues:\n\nFirst paragraph after equation (1): “the hidden state … t, h.” -> “the hidden state h … t.”\n\nEquation (2): it might help your readers to spell out how setting \\kappa to ||\\hat{e}|| allows you to ignore the unit-norm assumption of \\mu.\n\n“the negative log-likelihood of the vMF…” - missing capital\n\nUnnumbered equation immediately before “Regularization of NLLvMF”: C_m||\\hat{e}|| is missing round brackets around ||\\hat{e}|| to make it an argument of the C_m function.\n\nIs predicting the word vector whose target embedding has the highest value of vMF probability any more expensive than nearest neighbor search? Does it preclude the use of very fast nearest neighbor searches?\n\nIt might be a good idea to make it clear in 4.3 that you see an extension to beam search for your method to be non-trivial (and that you aren’t simply leaving out beam search for comparability to the various empirical loss functions). This didn’t become clear to me until the Future Work section.\n\nIn Table 5, I don’t fully understand F1 in terms of word-level translation accuracy. Recall is easy to understand (does the reference word appear in the system output?) but precision is harder to conceptualize. It might help to define the metric more carefully.', ""This paper proposes to replace the softmax over the vocab in the decoder with a single embedding layer using the Von Mises-Fisher distribution, which speeds up training 2.5x compared to a standard softmax+cross entropy decoder. The goal is admirable, as the softmax during training is a huge time sink (the proposed approach does not speed up inference due to requiring a nearest neighbor computation over the whole vocab). The approach is evaluated on machine translation (De/F>En and En>F), and the results indicate that there is minor quality loss (measured by BLEU) when using vMF. One huge limitation of the approach is the lack of a beam search-like algorithm; as such, the model is compared to greedy softmax+CE decoders (I would like to see numbers with a standard beam search model as well just to emphasize the quality drop from the state-of-the-art systems). With that said, I found this approach quite exciting and it has potential to be further improved, so I'm a weak accept.  \n\ncomments:\n- is convergence time the right thing to measure when you're comparing the two different types of models? i'd like to see something like flops as in the transformer paper. \n- relatedly, it's great that you can use a bigger batch size! this could be very important especially for non-MT tasks that require producing longer output sequences (e.g., summarization). \n- it looks like the choice of pretrained embedding makes a very significant difference in BLEU. i wonder if contextualized embeddings such as ELMo or CoVE could be somehow incorporated into this framework, since they generally outperform static word embeddings. ""]","[-20, 80, 60]","[60, 90, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('basically well written', 'motivation is clear and reasonable', 'idea seems to be novel'), they express several significant concerns about the paper's experiments and claims. The reviewer states that 'the experiments in this paper do not fully support the effectiveness of the proposed method' and lists multiple issues with the methodology and results.\n\nThe politeness score is moderately positive (60) as the reviewer uses respectful and constructive language throughout. They begin with positive comments, use phrases like 'I understand that...', 'I am confused...', and 'Is there any comment for this question?', which show consideration for the authors. The reviewer also ends on a positive note, stating 'Overall, basically I like the idea of the proposed method.' However, the score is not higher as the review is still critical and direct in its feedback."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as a 'nice innovation' and praises its 'non-trivial technical contribution' and 'promising results'. They also mention that it's 'very healthy to add this method to the discussion'. While they do raise some concerns, these are presented as constructive feedback rather than major criticisms. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'nice innovation', offer balanced feedback, and even when pointing out issues, they do so in a gentle manner (e.g., 'Smaller issues:'). The reviewer also takes time to explain their thought process and offer suggestions, which demonstrates respect for the authors' work."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses excitement about the approach, calling it 'quite exciting' and stating it has 'potential to be further improved'. They also give a 'weak accept' recommendation. However, they do point out some limitations, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the 'admirable' goal of the paper and providing constructive feedback. They phrase criticisms as suggestions or questions rather than direct attacks. The tone is professional and courteous, though not overly formal or deferential.""]"
"['This paper investigates sophistical exploration approaches for reinforcement learning. Motivated by the fact that most of bandit algorithms do not handle heteroscedasticity of noise, the authors built on Information Direct Sampling and on Distributional Reinforcement Learning to propose a new exploration algorithm family. Two versions of the exploration strategy are evaluated against the state-of-the-art on Atari games: DQN-IDS for homoscedatic noise and C51-IDS for heteroscedastic noise. \n\nThe paper is well-written. The background section provides the clues to understand the approach. In IDS, the selected action is the one that minimizes the ratio between a squared conservative estimate of the regret and the information gain. Following (Ktischner and Krause 2018), the authors propose to use \\log(1+\\sigma^2_t(a)/\\rho^2(a)) as the information gain function, which corresponds to a Gaussian prior, where \\sigma^2_t is the variance of the parametric estimate of E[R(a)] and \\rho^2(a) is the variance of R(a). \\sigma^2_t is evaluated by bootstrap (Boostrapped DQN). Where the paper becomes very interesting is that recent works on distributional RL allow to evaluate \\rho^2(a). This is the main input of this paper: combining two recent approaches for handling heteroscedasticity of noise in Reinforcement Learning.\n\nMajor concern:\nWhile the approach is appealing for handling heteroscedastic noise, the use of a normalized variance (eq 9) and a lower bound of variance (page 7) reveal that the approach needs some tuning which is not theoretically founded. \nThis is problematic since in reinforcement learning, the environment is usually assumed to be unknown. What are the results when the lower bound of the variance is not used? When the variance of Z(a) is low, the variance of the parametric estimate should be low also. It is not the case?\n\n\nMinor concerns:\n\nThe color codes of Figure 1 are unclear. The color of curves in subfigures (b) (c) (d) corresponds to the color code of IDS.\n\nThe way in which \\rho^2(s,a) is computed in algorithm 1 is not precisely described. In particular page 6, the equation \\rho^2(s,a)=Var(Z_k(s,a)) raises some questions: Is \\rho evaluated for a particular bootstrap k or is \\rho is averaged over the K bootstraps ?\n_____________________________________________________________________________________________________________________________________________\n\nI read the answers of authors. I increased my rating.\n', ""The authors propose a way of extending Information-Directed Sampling (IDS) to reinforcement learning. The proposed approach uses Bootstrapped DQN to estimate parametric uncertainty in Q-values, and distributional RL to estimate intrinsic uncertainty in the return. The two types of uncertainty are combined to obtain a simple exploration strategy based on IDS. The approach outperforms a number of strong baselines on a subset of 12 Atari 2600 games.\n\nClarity - I found the paper to be very well-written and easy to follow. Both the background material and the experimental setup were explained very clearly. The main ideas were also motivated quite well. It would have been nice to include a bit more discussion of why IDS is a good strategy, i.e. what are the theoretical guarantees in the bandit case? Section 3.2 could also provide a more intuitive argument.\n\nNovelty - The paper essentially combines the IDS formulation of Kirschner & Krause, Bootstrapped DQN of Osband et al., and the C51 distributional RL method of Bellemare et al. Most of the novelty is in how to combine these ideas effectively in the deep RL setting, which I found sufficient.\n\nSignificance - Improving over existing exploration strategies for deep RL would be a significant achievement. While the results are impressive, I have a few concerns regarding some of the claims.\n\nThe subset of games used to evaluate the proposed approach seems to be biased towards games where there is either a dense reward or exploration is known to be easy. Almost every deep RL paper on exploration includes results for at least some of the hard exploration games (see “Unifying Count-Based Exploration and Intrinsic Motivation”). Why were these games excluded from the evaluation? The results would be much stronger if results on all 57 games were included.\n\nThe main difference between DQN-IDS and C51-IDS is that C51-IDS will tend to favor actions with lower return uncertainty. Doesn’t this mean that the improved performance of C51-IDS is due to an improved ability to exploit rather than explore? If this is indeed the case, then I would expect more evidence that this doesn't come at a cost of reduced performance on tasks where exploration is difficult.\n\nFinally, the comparison between Bootstrapped DQN and DQN-IDS conflates the exploration strategies (IDS vs Thompson sampling) with the choice of optimizer (Adam vs RMSProp), so the claim that simply changing the exploration strategy to IDS leads to a major improvement is not valid. It would be interesting to see results for Bootstrapped DQN using the authors’ implementation and choice of optimizer to fully separate the effect of the exploration strategy.\n\nOverall quality - This is an interesting paper with some promising results. I’m not convinced that the proposed method leads to better exploration, but I think it still makes a valuable contribution to the work on balancing exploration and exploitation in RL.\n\n-------\n\nThe rebuttal and revisions addressed some of my concerns so I am increasing my score to 7 "", 'Combining the parametric uncertainty of bootstrapped DQN with the return uncertainty of C51, the authors propose a deep RL algorithm that can explore in the presence of heteroscedasticity. The motivation is quite well written, going through IDS and the approximations in a way that didn\'t presume prior familiarity.\n\nThe core idea seems quite sound, but the fact that the distributional loss can\'t be propagated through the full network is troubling. The authors\' choice of bootstrapped DQN feels arbitrary, as a different source of parametric uncertainty might be more compatible (e.g. noisy nets), and this possibility isn\'t discussed.\n\nThe computational limitations are understandable, but the authors should be more transparent about how the subset of games were selected. A toy example would have actually added quite a bit, as it would nice to see that the extent to which this algorithm helps is proportional to the heteroscedasticity in the environment. The advantage of DQN-IDS over bootstrapped suggests that something other than just the sensitivity to return variance is causing these improvements.\n\nIdeally, results with and without the heuristically chosen lower bound (rho) would be presented, as its unclear how much this is needed and its presence loosens the connection to IDS.\n\nThis is a small point, but the treatment of intrinsic motivation (i.e. changing the reward function) for exploration seems overly harsh. Most of these methods are amenable to experience replay, which would propagate the exploration signals and allow for ""deep"" exploration. The fact that they often change the optimal policy should be enough motivation to not discuss them further.\n\nEDIT: I think dealing with the lower bound and including plots for all 55 games pushed this over the edge. It would\'ve been nice if there non-zero scores on Montezuma\'s Revenge, but I know that is a high bar for a general purpose exploration method. In general I think this approach shows great promise going forward score 6-->7']","[60, 60, 70]","[80, 80, 60]","[""The sentiment score is 60 (positive) because the reviewer starts by acknowledging the paper is well-written and provides a detailed, appreciative summary of the work. They describe the paper as 'very interesting' and recognize its contribution in combining two recent approaches. However, the score is not higher due to the 'major concern' raised about the need for tuning and lack of theoretical foundation for some aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'concerns' rather than outright flaws. The reviewer also mentions increasing their rating after reading the authors' responses, showing openness to dialogue. The language is professional and constructive throughout, without any rude or dismissive comments."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, praising its clarity, novelty, and potential significance. They describe it as 'very well-written,' 'easy to follow,' and having 'impressive' results. However, they also raise some concerns and are 'not convinced' about certain aspects, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame criticisms as suggestions or concerns rather than harsh judgments. Phrases like 'It would have been nice to include...' and 'I would expect more evidence...' demonstrate a polite approach to offering feedback. The overall tone is professional and courteous, maintaining a balance between positive reinforcement and constructive criticism."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, noting that the 'core idea seems quite sound' and that the approach 'shows great promise going forward'. The final edit even increases the score from 6 to 7. However, it's not 100 as there are several critiques and suggestions for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and limitations ('The computational limitations are understandable'). The critique is constructive and presented in a professional manner. However, it's not 100 as the language is direct rather than overtly polite, focusing on the content rather than excessive courtesy.""]"
"['The authors extend the theoretical results of a paper previously presented in the last edition of ICLR (2018), where it was demonstrated that Recurrent Neural Network can be interpreted as a tensor network decomposition based on the Tensor-Train (TT, Oseledets et al, 2011).\nWhile previous results covered the multiplicative nonlinearity only, the contribution of the current paper is the extension of the analysis of universality and depth efficiency (Cohen et al, 2016) to different nonlinearities, for example ReLU (Rectified Linear Unit), which is very important from the practical point of view.\nThe paper is well written and have a good structure. However, I found that some deep concepts are not well introduced, and maybe other more trivial results are discussed with unnecessary details. The following comments could help authors to improve the quality of presentation of their paper:\n-\tSection 3.1 (Score Functions and Feature Tensor) is a bit short and difficult to read. \no\tMaybe, a more motivating introduction could be included in order to justify the definition of score functions (eq. 2). \no\tIt would be also nice to state that, according to eq. (3), the feature tensor is a rank-1 tensor. \no\tI would suggest moving the definition of outer product to the Appendix, since most readers know it very well.\no\tIt is said that eq. 2 possesses the universal approximation property (it can approximate any function with any prescribed precision given sufficiently large M). It is not clear which is the approximation function.\n-\tA Connection with Tensor-Ring (TR) format, if possible, could be helpful: It is known that TR format (Zhao et al, 2016, arXiv:1606.05535), which is obtained by connecting the first and last units in a TT model, helps to alleviate the requirement of large ranks in the first and last the core tensors of a TT model reaching to a decomposition with an evenly distributed rank bounds. I think, it would be interesting to make a connection of RNN to TR because the assumption of R_i < R for all i becomes more natural. I would like to see at least some comment from the authors about the applicability of TR in the context of analysis of RNN, if possible. Maybe, also the initial hidden state defined in page 5 can be avoided if TR is used instead of TT.\n-\tFig 2 shows that Test accuracy of a shallow network (CP based) is lower and increases with the number of parameters approaching to the one for RNN (TT based). It would be necessary to show the results for an extended range in the number of parameters, for example, by plotting the results up to 10^6. It is expected that, at some point, the effect of overfitting start decreasing the test accuracy.\n-       When scores functions are presented (eq. 2) it is written the term ""logits"" between brackets. Could you please clarify why this term is introduced here? Usually, logit of a probability p is defined as L(p)=p/(1-p). What is the usage of this term in this work? \n-      I think the theory is presented for a model with the two-classes only but used for multiple classes in the experimental sections. It should be necessary to make some comment about this in the paper.\n-      Details about how the RNN based on TT is applied must be added. More specifically, the authors should provide answers to clarify the following questions: \n(i) Are patches overlapped or non-overlapped? \n(ii) What value of M is used? and is there any general rule for this choice? \n(iii) How the classification in the 10-classes is obtained? Are you using a softmax function in the last layer? Are you using one weight tensor W_c per class (c=1,2,...,10). Please provide these technical details. \n(iv) Please, specify which nonlinear activation sigma is used in the feature map f_\\theta(x).\n(v) How many feature maps are used? and, Are the matrix A and vector b learned from training dataset or only the TT-cores need to be learned? ', 'This paper would benefit from a meaningful and concrete toy example. \n\nThe toy example from section 3.1 eq(3) amounts to stating that the Kronecker product  of a set of eigenparts is equal to the PCA eigenpixels for  a set of complete images, or more generally that the kronecker product of a set of  image-part feature tensors is equal to the complete image-feature tensor  (assuming no pixel overlap).  Sure.  What does that buy?   Hierarchical Tucker (including Tensor Train) does indeed compute the standard Tucker mode representation of a tensor in an efficient manner using a set of sequential SVDs rather than using a single SVD per mode.   Is there anything else?  Depending on how the data is organized into a data tensor, the object representation and its properties can differ dramatically.  Section 3.1 needs further clarification.\n\nQuestions:\n1. What is data tensor organization and what tensor decomposition model are you using? Tucker but implemented as a TT? \nWhat is the resulting object representation?\n2. In the context of the toy example, please give a concrete mapping between your tensor decomposition (object representation)  and RNN.\n\nThe rest of the paper is a lot of mathematical manipulation which looks correct.\n\n\nPlease reference the first papers to employ tensor decompositions for imaging.\n\nM. A. O. Vasilescu, D. Terzopoulos, ""Multilinear Analysis of Image Ensembles: TensorFaces,""  Proc. 7th European Conference on Computer Vision (ECCV\'02), Copenhagen, Denmark, May, 2002, in Computer Vision -- ECCV 2002, Lecture Notes in Computer Science, Vol. 2350, A. Heyden et al. (Eds.), Springer-Verlag, Berlin, 2002, 447-460. \n\nM.A.O. Vasilescu, ""Multilinear Projection for Face Recognition via Canonical Decomposition "",  In Proc. Face and Gesture Conf. (FG\'11), 476-483.', ""This paper extends the work of TT-RRN [Khrulkov et al., 2018] to further analyze the connection between RNN and TT decomposition by incorporating generalized nonlinearity, i.e., RELU, into the network architectures. Specifically, the authors theoretically study the influence of generalized nonlinearity on the expressivity power of TTD-based RNN, both theoretical result and empirical validation show that generalized TTD-based RNN is more superior to CP-based shallow network in terms of depth efficiency. \nPros:\n1. This work is theoretically solid and extend the analysis of TT-RNN to the case of generalized nonlinearity, i.e. ReLU.\n\n2. The paper is well written and organized.\n \nCons:\n1. The contribution and novelty of this paper is incremental and somehow limited, since the analysis TT-RNN based on the product nonlinearity already exists, which make the contribution of this paper decreased.\n\n2. The analysis is mainly on the particular case of rectifier nonlinearity. I wonder if the nonlinearities other than the RELU hold the similar properties? The proof or discussion on the general nonlinearities is missing.\n\nOther comments:\n1. The authors said that the replacement of standard outer product with its generalized version leads to the loss of conformity between tensor networks and weight tensors, the author should clarify this in a bit more details.\n\n2. The theoretical analysis relies on grid tensor and restricts the inputs on template vectors. It is not explained why to use and how to choose the those template vectors in practice?\n\n3. A small typo: In Figure 2, ‘m' should be ‘M'""]","[60, -30, 20]","[80, 20, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by acknowledging the paper's contribution and extension of previous work, stating it is 'well written and have a good structure.' However, they also mention some areas for improvement, which prevents a higher score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'Maybe, a more motivating introduction could be included'), and phrases like 'I would suggest' and 'Could you please clarify.' The reviewer also acknowledges the paper's strengths before offering critiques, which is a polite approach. The use of bullet points for specific recommendations is professional and constructive, further contributing to the polite tone."", ""The sentiment score is -30 because the review is generally critical, pointing out several areas that need improvement or clarification. The reviewer states that the paper 'would benefit from a meaningful and concrete toy example' and asks several questions indicating a lack of clarity. However, it's not entirely negative as the reviewer acknowledges that some mathematical manipulations 'look correct'. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'would benefit' and phrase many points as questions rather than harsh statements. The reviewer also provides constructive feedback and suggestions for improvement, including specific references to add, which is a courteous approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as it being 'theoretically solid' and 'well written and organized'. However, they also point out significant cons and limitations, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present both pros and cons in a balanced manner, and their criticisms are constructive rather than harsh. The use of phrases like 'I wonder if...' and 'The authors should clarify...' indicates a respectful tone. The reviewer also points out a small typo politely at the end, which is a courteous way to address such issues.""]"
"['This paper introduces a new dataset and method for chatbots. In contrast to previous work, this paper specifically probes how well a dialogue system can use external unstructured knowledge. \n\nQuality:\nOverall, this is a very high-quality paper. The dataset is developed well, the experimental setup is well thought-through and the authors perform many ablation studies to test different model variants. The main criticism I have would be that the human evaluation is rather simple (rating 1-5), I would have expected more fine-grained categories, especially ones that relate to how much knowledge the system uses (I appreciate the ""Wiki F1"" metric, but that is an automatic metric). As it is, the human evaluation shows that most of their contributions are not appreciated by human annotators. Further, the paper ends a bit abruptly, I would have expected a more in-depth discussion of next steps.\n\nClarity:\nThe description of the work is clear in most places. I particularly like the abstract and introduction, which set up the rest of the paper nicely. In some places, perhaps due to space restrictions, method descriptions are a bit too short.\n\nOriginality:\nThe paper is fairly original, especially the aspect about specifically using external knowledge. The authors could have been more clear on how the work differs from other work on non-goal directed dialogue work though (last paragraph of related work section).\n\nSignificance:\nThe dataset is really well-developed, hence I believe many working in the dialogue systems community will re-use the developed benchmark and build on this paper.\n\nMore detailed comments:\n- Missing reference for goal-oriented dialogue datasets: Wen et al. 2017, A Network-based End-to-End Trainable Task-oriented Dialogue System, https://arxiv.org/abs/1604.04562\n- How does the proposed dataset differ from the Reddit and Wikipedia datasets discussed in the last paragraph of the related work section? This should be explained.\n- Page 3, paragraph ""Conversational Flow"": what is the maximum number of turns, if the minimum is 5?\n- Page 3, paragraph ""Knowledge Retrieval"": how were the top 7 articles and first 10 sentences choices made? This seems arbitrary. Also, why wasn\'t the whole text used?\n- Page 3, paragraph ""Knowledge Selection and Response Generation"": how do you deal with co-reference problems if you only ever select one sentence at a time? The same goes for the ""Knowledge Attention"" model described in Section 4.\n- Page 3, paragraph ""Knowledge Selection and Response Generation"": how often do annotators choose ""no sentence selected""? It would be interesting to see more such statistics about the dataset\n- Section 4.2: did you run experiments for BPE encoding? Would be good to see as this is a bit of a non-standard choice.\n- Section 4.2: it would be good to explain the Cer et al. 2018 method directly in the paper\n- Section 4.2: is there a reference for knowledge dropout? Also, it would be good to show ablation results for this.\n- Section 5.1: why did you choose to pre-train on the Reddit data? There should be some more in-depth description of the Reddit dataset to motivate this choice.\n- Section 5.1: what is the setup you use for multi-task learning on SQuAD? Is it just a hard parameter sharing model, or?\n- Section 5.3: as stated above, the human evaluation is a little bit underwhelming, both in terms of setup and results. I\'d expect a more fine-grained way of assessing conversations by humans, and also an explanation of why the retrieval performer without knowledge was assessed as being on par with the retrieval transformer memnet.\n- Section 5.3: I assume higher=better for the human scores? This should be made explicit.\n- Section 5.3: Have others used the ""F1 overlap score""? If so, cite.\n- Section 5.3: I don\'t understand the argument that the human evaluation shows that humans prefer more natural responses. How does it show that?\n- Section 5.3: The Wiki F1 score is kind of interesting because it shows to what degree the model uses knowledge. But the side-by-side comparison with the human scores shows that humans don\'t necessarily prefer chatbot models that use a lot of knowledge. I\'d expect this to be discussed, and suggestions for future work to be made accordingly.\n- Section 6: The paper ends a bit abruptly. It\'s be nice to suggest future areas of improvement.', 'This paper collects a new annotated dataset for knowledge grounded dialog task. The proposed models combine two recent neural networks, Memory Net and Transformer, for the purpose of the task. I highly appreciate the efforts to collect such a precious dialog dataset for the community. Also, the setup in data collection actually narrows down the scope of chitchat dialog into a specific topic by grounding it to a set of knowledge. \n\nHere are summaries of my concerns and questions about the paper. \n\n# applicability of the knowledgeable bot\nWhat is the basic motivation of this work? Once you develop a chatbot that can produce a response grounded by knowledge, how could it be applied to real-world applications? Are you trying to teach a student who is looking for more knowledge about a topic? If so, you should be more careful about what knowledge the student (or apprentice in the paper) knows or don’t know about the topic and how their knowledge models dynamically change over the chat. Otherwise, the proposed model seems a simple knowledge retrieval model given the dialog context. Would you please provide motivations of the work?\n\n# No explicit goal of a dialog makes the chat divergent and open-ended\nWithout a specific goal given to the annotators or a restriction in the instruction, a dialog in the current setting might diverge beyond the context. For example, if an apprentice says about her/his personal opinion about the topic (e.g., I hate the Gouda cheese) or past experience (e.g., I went to a music festival by Michael Jackson 23 years ago), then how do you control the chat between two annotators or how do you train a model not to pay much attention on out-of-topic utterances?  \n\n# Lack of further analysis of the dataset\nData collection part itself seems to be the biggest contribution to this work. Why don’t you bring one of real dialog example in Figure 3 to the main paper and say more about it? For example, what other interesting applications can you develop on this dataset? \n\nCompared to the Wizard, the role of apprentice seems unclear to me. I found from the examples in Figure 3 that most of the apprentices’ responses are a follow-up question about the knowledge, a personal agreement or feeling or their preference. Do you have any post analysis on the types of responses from the apprentices so highlighting utilities of the dataset in a real application? \n\n# Some questions on data collection\nDo you have any incentive mechanism to make annotators more engage in the dialog?\nDid you filter out some bad dialogs? Then, how did you measure the quality of a dialog? \nHow do you penalize bad annotators that often make aggressive words or don’t follow the instruction you set up? \n\n# A question on the model\nCompared to previous works such as (Zhang at al., ACL18), the proposed model seems to have the only replacement with Transformer encoder and a loss term for knowledge selection. Have you tried another way of dealing with the knowledge part? For example, a ranking loss might be better than the attention. \n\n# Questions on the Experiment section\nAny experiment to show the effect of different \\lambda value in the loss of the generative model? \n\nWhen you evaluate the generative model, have you also tried other automatic metrics such as BLEU instead of only PPL and Unigram-F1? For this task, the possible response grounded by the topic+knowledge might be too diverse to measure though. Could you possibly add some constraints to the annotators to do some clear tasks over the dialog so you can systematically evaluate the dialog w.r.t the constraint? Otherwise, evaluation of this task seems to be mostly the same as chitchat systems.\n\nIn Table 5, human evaluators only measure the likeness of the dialog which seems very naive. Why don’t you measure whether the apprentice gets new knowledge of which s/he didn’t know before, whether the knowledge provided from the model was informative, whether the dialog was fun and engaging or more? The current human evaluation seems very weak though. \n\nThis might be an auxiliary question: have you tried to train the model for apprentice and make two models chat with each other? How does the chat look like then?\n', 'This work proposes a brand new dataset to fill in the vacancy of current conversational AI community, specifically the introduced dataset aims at providing a platform to perform large-scaled knowledge-grounded chit-chat. Overall, the dataset is well-motivated and well-designed, its existence will potentially benefit the community and inspire more effective methods to leverage external knowledge into dialog system. Besides, the paper also utilizes many trending models like Transformers, Memory Networks, etc to ensure the state-of-the-art performance. The clear structure and paragraphs also makes the paper easy to read and follow.\n\nHere are some questions I want to raise about the paper:\n\n1. First of all, the design of the conversation flow though looks reasonable, but it is pretty uncommon for a human to ground his/her every sentence on external knowledges. Therefore, it would probably be better to introduce some random ungrounded turns into the conversation to make it more humanlike.\n\n2. Secondly, the whole framework is based on many modules and every one of them are prone to error. I’m afraid that such cascaded errors will accumulate and lead to compromised performance in the end. Have you thought about using REINFORCE\nalgorithm to alleviate this issue?\n\n3. Finally, it would be better to introduce some noisy or adversarial apprentice to raise unrelated turns and see how the system react. Have you thought about how to deal with such cases?']","[60, 50, 80]","[80, 70, 70]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'very high-quality' and praises several aspects, including the dataset development, experimental setup, and ablation studies. However, they also provide some criticisms, such as the simplicity of the human evaluation and the abrupt ending, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh critiques. They balance positive feedback with areas for improvement, and use phrases like 'I would have expected' or 'It would be good to' when suggesting changes, which maintains a polite and professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by appreciating the efforts to collect a valuable dataset and acknowledges the paper's contribution. However, they also express several concerns and questions, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and uses phrases like 'I highly appreciate' and 'Would you please'. The reviewer maintains a professional tone while providing constructive feedback. They offer detailed comments and suggestions for improvement without using harsh or dismissive language."", ""The sentiment score is 80 because the reviewer expresses a very positive overall view of the work, praising its motivation, design, and potential benefits to the community. They use phrases like 'well-motivated and well-designed' and 'will potentially benefit the community'. The politeness score is 70 because the reviewer uses respectful language throughout, framing their suggestions as questions rather than demands ('Have you thought about...?'). They also begin with positive feedback before offering constructive criticism. The language is professional and courteous, though not excessively formal or deferential. The reviewer maintains a balanced tone, acknowledging the paper's strengths while also providing thoughtful suggestions for improvement.""]"
"['- Summary\nThis paper proposes a residual non-local attention network for image restoration. Specifically, the proposed method has local and non-local attention blocks to extract features which capture long-range dependencies. The local and non-local blocks consist of trunk branch and (non-) local mask branch. The proposed method is evaluated on image denoising, demosaicing, compression artifacts reduction, and super-resolution.\n\n- Pros\n  - The proposed method shows better performance than existing image restoration methods.\n  - The effect of each proposed technique such as the mask branch and the non-local block is appropriately evaluated.\n\n- Cons\n  - It would be better to provide the state-of-the-art method[1] in the super-resolution task. \n    [1] Y. Zhang et al., Image Super-Resolution Using Very Deep Residual Channel Attention Networks, ECCV, 2018.\n  - The technical contribution of the proposed method is not high, because the proposed method seems to be just using existing methods.\n  - The contribution of the non-local operation is not clear to me. For example, how does the global information (i.e., long-range dependencies between pixels) help to solve image denoising tasks such as image denoising?\n\nOverall, the technical contribution of the proposed method is not so high, but the proposed method is valuable and promising if we focus on the performance.\n', 'The paper proposes a convolutional neural network architecture that includes blocks for local and non-local attention mechanisms, which are claimed to be responsible for achieving excellent results in four image restoration applications.\n\n\n# Results\nThe strongest point of the paper is that the quantitative and qualitative image restoration results appear to be very good, although they seem almost a bit too good.\n\n\n# Novelty\nI\'m not sure about the novelty of the paper, but I suspect it to be rather incremental. The paper says ""To the best of our knowledge, this is the first time to consider residual non-local attention for image restoration problems."" Does that mean non-local attention (in a very similar way) has already been used, just not in a residual fashion? If so, that would not constitute much novelty. I have to admit that I\'m not familiar with the related work on attention, but I did not understand *why* the results of the proposed method are supposed to be much better than that of previous work.\n\n\n# Clarity\nI think the paper is not self-contained enough, since it seems to implicitly assume substantial background knowledge on attention mechanisms in CNNs. \n\nFurthermore, the introduction of the paper identifies three problems with existing CNNs that I don\'t necessarily fully agree with. None of these supposed problems are backed up by (experimental) evidence.\n\nI don\'t think it is sufficient to just show superior results than previous methods. It is also important to disentangle why the results are better. However, the presented ablation experiments are not very illuminating to me.\n\nThe attempts at explaining what the novel attention blocks do and why they lead to superior results are very vague to me. Maybe they are understandable in the context of related work, but I found many statements, such as the following, devoid of meaning:\n- ""Without considering the uneven distribution of information in the corrupted images, [...]""\n- ""However, in this paper, we mainly focus on learning non-local attention to better guide feature extraction in trunk branch.""\n- ""We only incorporate residual non-local attention block in low-level and high-level feature space. This is mainly because a few non-local modules can well offer non-local ability to the network for image restoration.""\n- ""The key point in mask branch is how to grasp information of larger scope, namely larger receptive field size, so that it’s possible to obtain more sophisticated attention map.""\n\n\n# Experiments\n- The experimental results are the best part of the paper. However, it would\'ve been nice to include some qualitative results in the main paper.\n- The proposed RNAN model is trained on a big dataset (800 images with ~2 million pixels each). Are the competing methods trained on datasets of similar size? If not, this could be a major reason for improved performance of RNAN over competing methods. At least in the appendix, RNAN and FFDNet are compared more fairly since they are trained with the same/similar data.\n- The qualitative examples in the appendix mostly show close-ups/details of very structured regions (mostly stripy patterns). Please also show some other regions without self-similar structures.\n\n\n# Misc\n- Residual non-local attention learning (section 3.3) was not clear to me.\n- The word ""trunk"" is used without definition or explanation.\n- Fig. 2 caption is too short, please expand.\n\n# Update (2018-11-29)\nGiven the substantial author feedback, I\'m willing to raise my score.', 'The authors propose a residual non-local attention net (RNAN) which combines local and non-local blocks to form a deep CNN architecture with application to image restoration.\n\nThe paper has a compact description, provides sufficient details, and including the appendix has an excellent experimental validation.\n\nThe proposed approach provides top results on several image restoration tasks:  image denoising, demosaicing, compression artifacts reduction, and single image super-resolution.\n\nThe main weakness of the paper is the limited novelty, as the proposed design builds upon existing ideas and concepts. However, up to some point all the new ConvNet designs can be seen as incremental developments of the older ones, yet they are needed for the progress of the field.\n\nI would suggest to the authors the inclusion of related works such as:\nTimofte et al., ""NTIRE 2018 Challenge on Single Image Super-Resolution: Methods and Results"", CVPRW 2018\nWang et al., ""A fully progressive approach to single-image super-resolution"", CVPRW 2018\nNote that DIV2K dataset was introduced in:\nAgustsson et al., NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study, CVPRW 2017\n\nalso, the more recent related works:\nBlau et al., ""2018 PIRM Challenge on Perceptual Image Super-resolution"", ECCVW 2018\nZhang et al., ""Image Super-Resolution Using Very Deep Residual Channel Attention Networks"", ECCV 2018\n\nAlso, I would like a response from the authors on the following:\nWhy not using dilated convolutions instead of or complementary with the mask branch or other design choices from this paper?\n']","[20, -30, 70]","[50, 50, 80]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the method's better performance and appropriate evaluation, they also point out significant cons such as low technical contribution and unclear benefits of non-local operation. The overall tone suggests the method is 'valuable and promising' despite these drawbacks. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout, balancing criticism with praise, and offering constructive suggestions for improvement without using harsh or dismissive language. The reviewer maintains a respectful tone even when pointing out weaknesses in the paper."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some strengths ('The strongest point of the paper is that the quantitative and qualitative image restoration results appear to be very good'), they express significant doubts about the novelty, clarity, and depth of the paper. Phrases like 'I'm not sure about the novelty', 'I think the paper is not self-contained enough', and 'I don't think it is sufficient to just show superior results' indicate a generally critical stance. The politeness score is moderately positive (50) because the reviewer uses polite and professional language throughout, even when expressing criticism. They use phrases like 'I think', 'I found', and 'Maybe' to soften their critiques, and they offer specific suggestions for improvement. The reviewer also shows willingness to reconsider their evaluation based on author feedback, which is quite polite and open-minded."", ""The sentiment score is 70 (positive) because the reviewer praises the paper for its compact description, sufficient details, and excellent experimental validation. They also highlight that the proposed approach provides top results on several image restoration tasks. Although they mention a weakness in limited novelty, they acknowledge that such incremental developments are necessary for progress in the field. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases their suggestions and questions in a courteous manner. They use phrases like 'I would suggest' and 'I would like a response' which are polite ways of offering recommendations and asking questions. The reviewer also balances their critique with positive comments, demonstrating a considerate approach to their feedback.""]"
"['The proposed kernel recurrent learning (KeRL) provides an alternative way to train recurrent neural network with backpropagation through time (BPTT) where the propagation of gradients can be skipped over different layers. The authors directly assume the sensitivity function between two layers with a distance of tau in a form of Eq. (7). The algorithm of BPTT is then approximated due to this assumption. The model parameters are changed to learn the network dynamics. The optimization problem turns out to estimate beta and gamma of the kernel function. The learned parameters are intuitive. There are a set of timescales to describe the memory of each neuron and a set of sensitivity weights to describe how strongly the neurons interact on average. The purpose of this study is to save the memory cost and to reduce the time complexity for online learning with comparable performance. \n\nPros:\n1. KeRL only needs to compute a few tensor operations at each time step, so online KeRL learns faster than online BPTT for the case with a reasonably long truncation length.\n2. Biologically plausible statements are addressed.\n3. A prior is imposed for the temporal sensitivity kernel. The issue of gradient vanishing is mitigated.\n4. Theoretical illustration for KeRL in Sections 3 and 4 is clear and interesting.\n\nCons:\n1. The proposed method is an approximation to BPTT training. Suppose the system performance is constrained. Some guesses are made. The system performance can be further improved.\n2. The experiment on time cost due to online learning is required so that the reduction of time complexity can be illustrated.\n3. The format of tables 1 and 2 can be improved. Caption is required in Table 1. Overlarge size of Table 2 can be fixed.\n4.  A number of assumptions in Sections 3 and 4 are assumed.  When addressing Section 3, some assumptions in Section 4 are used. The organization of Sections 3 and 4 can be improved.', 'This paper proposes a simple method for performing temporal credit assignment in RNN training.  While it seems somewhat naive and unlikely to work (in my opinion), the experimental results surprisingly show reasonable performance on several reasonably challenging artificial tasks.\n\nThe core of the approach is based on equation 7, which approximates the Jacobian between different hidden states at different time-steps as a single adaptively-learned matrix times a decay factor that depends on the time gap.  While this seems like a very severe approximation to make the authors speculate that some kind of feedback alignment-like mechanism might be at play.\n\nThe presentation needs work in several areas, and the experimental results require more explanation, but otherwise this seems like a solid paper.  I would probably increase my rating if the authors could address my issues satisfactorily. \n\n\nSee below for more detailed comments:\n\nAbstract & Section 1: \n\nIs ""sensitivity tensor"" or ""credit assignment tensor"" common term?  Because I\'ve never heard them before.  Consider defining them before you discuss it, and using consistent jargon.  Later in Section 2 you seem to call this the ""RTRL tensor"" (whose meaning I can infer).  \n\nSection 2:\n\nGradient vanishing isn\'t so much a problem in itself, but a symptom that the sensitivity of the network\'s output to the action of some neuron in the past is very low. Ths gradient is just relaying this information, so I don\'t really see vanishing gradients as the problem to overcome, but rather low sensitivity on past activations.\n\nSection 3: \n\nDid you mean to write (W^out h^t + b^out) instead of (W^out h + b^out)^t ?\n\n""[equation] represents the gradient of the cost with respect to the current hidden state"".  The RHS of this equation makes no sense to me.  Not only does this not depend on the nonlinearity in any way, it doesn\'t include any consideration of future outputs on which the current h surely depends. \n\nIt would make the paper much more pleasant to read if you gave your derivation of the learning rule before you stated it in gory detail.  It feels almost completely arbitrary reading it first without any justification. This might be fine if it were compact and elegant, but it\'s not.\n\nConsider using exp(x) instead of e^x since the symbol e already means something else in your notation.\n\nSection 4:\n\nPlease define ""temporal variation""\n\n\nSection 5:\n\nYou should elaborate on the experimental setup you used.  Especially for the Addition and MNIST problems.  For example, what consistutes a ""step"" in figure 2?  Does KeRL take ""one"" step per time-step?  Or does ""step"" mean a complete gradient computation from running from t = 1 to t= T?  Is the BPTT truncated?  Are you counting one step of BPTT to be one complete forwards and backwards pass?\n\nYou should include some basic description of what an IRNN is.\n\nWhen you say that for MNIST that KeRL ""does not converge to as good of an optimum"" this seems like unjustified inference.  You don\'t really know that it is converging to a minimum of the original objective at all.  It could be converging to the minimum of some other objective it is implicitly optimizing due to your approximations (if one even exists).  Or it could be simply cycling around and failing to converge.  The fact that the loss plateaus isn\'t direct evidence of convergence in any sense.  If you wanted to measure this more directly you could look at the (true) gradient magnitude.\n\n""only requires a few tensor operations at each time step"" -> this is also true of UORO', ""The paper proposes an alternative to backprop through time for\ntraining RNN models.\n\nThe paper is reasonably well written, but somewhat dense and hard\nto follow.  The contribution seems novel.\n\nThe main issue is the empirical evaluation.  All of the tasks\n(masked addition, pixel-by-pixel MNIST, and the AnBn problem)\nare artificial.\n\nIn addition, the results on some of the tasks are mixed if not\nin favor of BPTT.  I am not convinced that these results are enough\nto showcase the practical advantages of KeRL.\n\nI am willing to increase my score, if the authors address this\nissue.\n\nDetailed comments:\n\n- The authors mention that BPTT is not biologically plausible.  Although\n  reasonable, I don't get why this would be an argument against it.""]","[50, 20, -20]","[75, 60, 50]","[""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the proposed method, followed by a balanced list of pros and cons. The positive aspects (e.g., faster learning, biologically plausible statements, clear theoretical illustration) are offset by some criticisms (e.g., approximation to BPTT, need for more experiments, formatting issues). The overall tone suggests the reviewer sees merit in the work but also areas for improvement. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout. They present criticisms as suggestions for improvement rather than harsh judgments, using phrases like 'can be improved' and 'is required'. The review maintains a respectful and constructive tone, focusing on the content of the work rather than making personal comments."", ""Sentiment score: The review starts with a somewhat skeptical tone ('seems somewhat naive and unlikely to work') but then acknowledges surprising positive results. The reviewer notes that the presentation needs work but overall calls it a 'solid paper'. The sentiment is slightly positive, hence a score of 20.\n\nPoliteness score: The language used is generally professional and constructive. The reviewer offers specific suggestions for improvement and uses phrases like 'Consider using...', 'Please define...', and 'You should elaborate...'. While there are criticisms, they are presented in a respectful manner. The tone is more polite than neutral, warranting a score of 60.\n\nThe scores are based on the overall tone, specific language used, and the balance between criticism and positive feedback in the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's novelty and reasonable writing, they express significant concerns about the empirical evaluation and are not convinced of the practical advantages of the proposed method. The reviewer is willing to increase their score if the authors address these issues, which indicates that the overall sentiment is not entirely negative.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and express willingness to reconsider their evaluation. The reviewer also provides detailed comments to help the authors improve their work. However, the score is not higher because the language, while polite, is not overly warm or encouraging.""]"
"['The paper presents a very important problem of utilizing a model on different platforms with own numerical round-offs. As a result, a model run on a different hardware or software than the one on which it was trained could completely fail due to numerical rounding-off issues. This problem has been considered in various papers, however, the classification task was mainly discussed. In this paper, on the other hand, the authors present how the numerical rounding-off issue could be solved in Latent-Variable Models (LVM).\n\nIn order to cope with the numerical rouding-off issue, the authors propose to use integer networks. They consider either quantized ReLU (QReLU) or quantized Tanh (Qtanh). Further, in order to properly train the integer NN, they utilize a bunch of techniques proposed in the past, mainly (Balle, 2018) and (Balle et al., 2018). However, as pointed out in the paper, some methods prevent training instabilities (e.g., Eqs. 18 and 19). All together, the paper tackles very important problem and proposes very interesting solution by bringing different techniques proposed for quantized NNs together .\n\nPros:\n+ The paper is well-written.\n+ The considered problem is of great importance and it is rather neglected in the literature.\n+ The experiments are properly carried out.\n+ The obtained results are impressive.\n\nCons:\n- A natural question is whether the problem could be prevented by post-factum quantization of a neural network. As pointed out in the Discussion section, such procedure failed. However, it would be beneficiary to see an empirical evidence for that.\n- It would be also interesting to see how a training process of an integer NN looks like. Since the NN is quantized, instabilities during training might occur. Additionally, its training process may take longer (more epochs) than a training of a standard (float) NN. An exemplary plot presenting a comparison between an integer NN training process and a standard NN training process would be highly appreciated.\n- (Minor remark). The paper is well-written, however, it would be helpful to set the final learning algorithm. This would drastically help in reproducibility of the paper.\n\n--REVISION--\nAfter reading the authors response and looking at the new version of the paper I decided to increase my score. The paper tackles very important problem and I strongly believe it should be presented during the conference.', 'This paper explains that range coding as a mechanism for transmitting latent-variable codes from source to target for decoding is severely sensitive to floating point errors.\n\nThe authors propose what amounts to an integer version of Balle 2018, and demonstrate that it allows for transmission between platforms without catastrophic errors due to numerical round-off differences.\n\nThe paper (and problem) is of low significance, but the authors present a neat solution.\n\nPros:\n- Well defined problem and solution.\n- Practical question relating to use of ANNs for data en/de-coding.\n\nCons:\n- Presentation needs brushing up: e.g. why give two examples for H, b, v bit widths?\n- Some approximations are not well motivated or justified.  E.g. why is it valid to replace gradient of a function that has 0 gradients with the identity?\n- Paper needs some rewriting for clarity.  E.g. where is the kernel K defined?\n- Lack of experimentation to justify the fact that the construction of (16) leads to instabilities, and is therefore less suitable than the method outlined here.  \n\n', 'This well-written paper addresses the restrictions imposed by binary communication channels on the deployment of latent variable models in practice. In order to range code the (floating point) latent representations into bit-strings for practical data compression, both the sender and receiver of the binary channel must have identical instances of the prior despite non-deterministic floating point arithmetic across different platforms. The authors propose using neural networks that perform integer arithmetic (integer networks) to mitigate this issue.\n\nPros:\n- The problem statement is clear, as well as the approach taken to addressing the issue.\n- Section 5 did a nice job tying together the relevant literature on using latent variable models for compression with the proposed integer network framework.\n- The experimental results are good; particularly, Table 1 provides a convincing case for how using integer networks remedies the issue of decompression failure across heterogeneous platforms.\n\nCons:\n- In Section 3, it wasn’t clear to me as to why the authors were using their chosen gradient approximations with respect to H’, b’ and c’. Did they try other approximations but empirically find that these worked best? Where did the special rescaling function s come from? Some justifications for their design choices would be appreciated. \n- The authors state in Section 2 that the input scaling is best determined empirically -- is this just a scan over possible values during training? This feels like an added layer of complexity when trying to train these networks. It would be nice if the authors could provide some insight into exactly how much easier/difficult it is to train integer networks as opposed to the standard floating point architectures.\n- In Section 6, the authors state that the compromised representational capacity of integer networks can be remedied by increasing the number of filters. This goes back to my previous point, but how does this “larger” integer network compare to standard floating point networks in terms of training time?\n']","[80, 20, 70]","[70, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, highlighting its importance, well-written nature, and impressive results. They use phrases like 'very important problem', 'well-written', and 'impressive results'. The reviewer also increased their score after revisions, indicating a very positive final sentiment. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They frame their suggestions as 'would be beneficiary' and 'would be highly appreciated', which is polite. The reviewer also acknowledges the authors' response positively. While very polite, it doesn't reach the highest levels of formality or deference, hence the score of 70 rather than higher."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's well-defined problem and solution, and calls it a 'neat solution'. However, they also mention it's of 'low significance' and list several cons, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral language and balances pros and cons without harsh criticism. They offer constructive feedback and use phrases like 'needs brushing up' instead of more critical language. The reviewer maintains a professional tone throughout, neither overly formal nor casual."", ""The sentiment score is 70 (positive) because the review starts with praising the paper as 'well-written' and lists several pros, including clear problem statement, good tie-in with literature, and convincing experimental results. While there are some cons mentioned, they are presented as areas for improvement rather than major flaws. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or requests for clarification (e.g., 'Some justifications for their design choices would be appreciated'). The reviewer maintains a professional and constructive tone, avoiding harsh or dismissive language.""]"
"['The paper proposes a method to find adversarial examples in which the changes are localized to small regions of the image. A group-sparsity objective is introduced for this purpose and it is combined with an l_p objective that was used in prior work to define proximity to the original example. ADMM is applied to maximize the defined objective. It is shown that adversarial examples in which all changes are concentrated in just few regions can be found with the proposed method.\n\nThe paper is clearly written and results are convincing. But what I am not sure I understand is what is the purpose of this research. Among the 4 contributions listed in the end of the intro only the last one, Interpretability, seems to have a potential in terms on the impact. Yet am not quite sure how “obtained group-sparse adversarial patterns better shed light on the mechanisms of adversarial perturbations”. I think the mechanisms of adversarial perturbations remain as unclear as they were before this paper.\n\nI am not ready to recommend acceptance of this paper, because I think the due effort to explain the motivation for research and its potential impacts has not been done in this case. \n\nUPD: the discussion and the edits with the authors convinced me that I may have been a bit too strict. I have changed my score from 5 to 6.\n', 'The paper proposes a novel approach to generate adversarial examples based on structured sparsity principles. In particular the authors focus on the intuition that adversarial examples in computer vision might benefit from encoding information about the local structure of the data. To this end, lp *group* norms can be used in contrast to standard global lp norms when constraining or penalizing the optimization of the adversarial example. The authors propose an optimization strategy to address this problem. The authors evaluate the proposed approach on real data, comparing it against state-of-the-art competitors, which do not leverage the structured sparsity idea.\n\nThe paper is well written and easy to follow. The presentation of the algorithms for i) the non-overlapping and ii) overlapping groups as well as iii) the proposed refinement are clear. The experimental evaluation is interesting and convincing (the further experiments in the supplementary material add value to the overall discussion). \n\nThe main downside of the paper is that the proposed idea essentially consists in replacing the standard \\ell_p norm penalty/constraints with a group-\\ell_p one. While this provides interesting technical questions from the algorithmic perspective, from the point of view of the novelty, the paper does not appear an extremely strong contribution, \n\n\n\n ', ""This paper proposes a method for adversarial attacks on DNNs (StrAttack), designed to exploit the underlying structure of the images. Specifically, incorporating group-sparsity regularization into the generation of the adversarial samples and using an ADMM based implementation to generate the adversarial perturbations.\n\nThe paper is structured and written well, with clear articulation of technical details. The experiments and reported results are comprehensive, and clearly showcase the efficacy of the proposed solution.  I'm not enough of an expert on the subject matter to comment about the novelty of this proposed approach. However, it would help to elaborate more on the related work (section.7) with clear contrasting of current method esp. using structural information for adversarial samples - theoretical implications, underlying rationale and importantly calling out the benefit over the previous lp - norm based approaches?\n\nRegarding group sparsity - it is unclear as to the assumed structural constraints, is the sliding mask expected to be only 2x2, 13x13 (for MNIST/CIFAR-10, ImageNET respectively) ? impact of larger/smaller or skewed sizes ? sensitivity to image types?\n\n""]","[-20, 50, 70]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is clearly written and the results are convincing, they express uncertainty about the purpose and impact of the research. The reviewer states they are 'not ready to recommend acceptance' and believes the authors haven't adequately explained the motivation for the research. However, the score isn't deeply negative because the reviewer later updates their opinion, suggesting they may have been 'a bit too strict' initially. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging positive aspects of the paper and explaining their concerns in a professional manner. They also show flexibility by updating their opinion after discussion with the authors, which demonstrates courtesy and openness to dialogue."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being well-written, easy to follow, and having clear presentations and interesting evaluations. However, they also mention a 'main downside' regarding the novelty of the contribution, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits before offering criticism. They phrase their critique in a constructive manner, avoiding harsh or dismissive language. The use of phrases like 'well written,' 'easy to follow,' and 'interesting and convincing' contribute to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper is well-structured, clearly written, and has comprehensive experiments that showcase the efficacy of the proposed solution. The reviewer also mentions that they are not an expert to comment on novelty, which slightly tempers the positive sentiment. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledges their own limitations, and frames suggestions as helpful additions rather than criticisms. The reviewer uses phrases like 'it would help to elaborate' and asks questions about unclear points, which is a polite way of requesting clarification. The overall tone is constructive and professional, without any harsh or rude language.""]"
"['The paper proposes a method to solve end-to-end learning tasks using a combination of deep networks and domain specific black-box functions. In many machine learning tasks there may be a sub-part of the task can be easily solved with a black-box function (e.g a hard coded logic).  The paper proposes to use this knowledge in order to design a deep net that mimics the black-box function. This deep net being differentiable can be utilized while training in order to perform back-propagation for the deep nets that are employed to solve the remaining parts of the task. \n\nThe paper is well written and in my opinion the experiments are solid. They show significant gains over well-designed baselines. (It should be noted that I am not super familiar with prior work in this area and may not be aware of some related baselines that can be compared with.)\n\nIn Section 3.1.2 the authors discuss offline and online methods to train the mimicking deep network of a black-box function. The offline version suffers from wasting samples on unwanted regions while the online version will have a cold-start problem. However, I believe there can be better solution than the hybrid strategy. In fact there is a clear explore/exploit trade-off  here. Therefore, one may start with a prior over the input domain of the black-box function and then as the argument extractor learns well the posterior can be updated. Then we can Thompson sample the inputs from this posterior in order to train the mimicking network.  I think such a bandit inspired approach will be interesting to try out. ', 'This paper is about training a neural network (NN) to perform regression given a dataset (x, y) *and* a black box function which we know correctly maps from some intermediate representation to y. Instead of learning a NN directly from x to y, we want to make use of this black box function and learn a mapping from x to the intermediate representation. Call this the ""argument extractor"" NN. The problem is that (i) the black box function is typically non-differentiable so we cannot learn end-to-end and (ii) we don\'t have labels for the intermediate representations in order to learn a NN to approximate the black box function. The authors propose to train in three different ways: (1) offline training: train an auxiliary NN that approximates the black box function based on data generated by sampling the input uniformly (or similar); then train both the auxiliary NN and the argument extractor NN together end-to-end using (x, y) data, (2)  online training: train the auxiliary NN and the argument extractor NN together, based on (x, y) data; data for training the auxiliary NN comes from the argument extractor NN during the main training, and (3) hybrid training: pre-train the auxiliary NN as in (1) and then train both NNs as in (2).\n\nExperimental results show:\n- this approach leads to better performance than regressing directly from x to y in the small data regime,\n- this approach leads to better generalization (being able to add more image numbers during test),\n- this approach learns faster than an actor-critic based RL agent,\n- this approach can be useful even if the functionality of the black-box function inherently cannot be estimated by a differentiable function (lookup table) - the resulting argument extractor NN is useful when used with the non-differentiable black box function,\n- hybrid training is the best; offline training is the worst,\n- penalizing low output entropy helps.\n\nIt wasn\'t quite clear to me which training procedure was used for experiments 4.1-4.3. Presumably hybrid? It would also be nice to see how much time is spent in pre-training vs main training. In figure 2, what are the update steps for EstiNet (since there are two losses + pretraining)?\n\nI found this paper to be generally well-written and results convincing.', 'This paper presents an approach, called EstiNet, to train a hybrid models which uses both neural networks and black-box functions. The key idea is that, during training, a neural network can be used to approximate the functionality of the black-box functions, which makes the whole system end-to-end differentiable. At test time, the true black-box functions are still used. The training objective composes two parts: L_bbf, the loss for approximating the black-box function and L_target, the loss for the end-to-end goal. They tried different variations of when to train the black-box function approximator or not. It is shown to outperform the baselines like end-to-end differentiable model or NALU over 4 synthetic tasks in sample efficiency. There are some analysis about how the entropy loss and label smoothing helps with the gradient flow. \n\nThe proposed model is interesting, and is shown to be effective in the synthetic tasks. The paper is well-written and easy to follow. However, some of the experiment details are missing or scattered in the text, which might make it hard for the readers to reproduce the result. I think it helps to have the experimental details (number of examples, number of offline pretraining steps, size of the neural network, etc) organized in some tables (could be put in the appendix). \n\nTwo main concerns about how generally applicable is the proposed approach: \n\n1. It helps to show how L_target depends on L_bbf, or how good the approximation of the black-box function has to be to make the approach applicable. For example, some functions, such as sorting, are hard to approximate by neural network in a generalizable way, so in those cases, is it still possible to apply the proposed approach? \n\n2.The proposed approach can be better justified by discussing some potential real world applications. Two closely related applications I can think of are visual question answering and semantic parsing. However, it is hard to find good black-box functions for VQA and people often learn them as neural networks, and the functions in semantic parsing often need to interact with a database or knowledge graph, which is hard to approximate with a neural network. \n\nSome minor issues:\n\nTable 3 isn’t very informative since k=2 and k=3 provides very similar results. It would help to show how large k needs to be for the performance to severely degrade. \n\nMissing references: \n\nThe Related Works section only reviewed some reinforcement learning work on synthetic tasks. However, with some bootstrapping, RL is also shown to achieve state-of-the-art performance on visual question answering and semantic parsing tasks (Johnson et al, 2017; Liang et al, 2018), which might be good to include here. \n\nJohnson, J., Hariharan, B., van der Maaten, L., Hoffman, J., Fei-Fei, L., Zitnick, C. L., & Girshick, R. B. (2017, May). Inferring and Executing Programs for Visual Reasoning. In ICCV (pp. 3008-3017).\nLiang, C., Norouzi, M., Berant, J., Le, Q., & Lao, N. (2018). Memory augmented policy optimization for program synthesis with generalization. arXiv preprint arXiv:1807.02322.\n']","[80, 80, 50]","[70, 70, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They state that it is 'well written' and the experiments are 'solid', showing 'significant gains over well-designed baselines'. The only slight criticism is a suggestion for improvement, which is presented constructively. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges their own potential limitations ('I am not super familiar with prior work in this area'), and offers suggestions in a constructive manner ('I think such a bandit inspired approach will be interesting to try out'). The tone is professional and courteous without being overly formal or effusive."", ""The sentiment score is 80 (positive) because the reviewer states that the paper is 'generally well-written and results convincing.' They also highlight several positive aspects of the research, such as better performance in small data regimes, improved generalization, and faster learning compared to other methods. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their suggestions as requests for clarification rather than criticisms. The reviewer acknowledges the paper's strengths while politely suggesting minor improvements, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'interesting' and 'well-written', and notes that the proposed model is 'shown to be effective'. However, they also raise 'two main concerns' and point out some missing details, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as suggestions for improvement rather than harsh criticisms. They use phrases like 'It helps to show' and 'The proposed approach can be better justified', which are polite ways of pointing out areas for improvement. The reviewer also offers helpful suggestions and additional references, which is a courteous approach to peer review.""]"
"[""This paper presents an analysis of popularly-use RNN model for structure modeling abilities by designing Tensor Product Decomposition Networks to approximate the encoder. The results show that the representations exhibit interpretable compositional structure. To provide better understanding, the paper evaluates the performance on synthesized digit sequence data as well as several sentence-encoding tasks.\n\nPros:\n1. The paper is well-written and easy to follow. The design of the TPDN and corresponding settings (including what an filler is and what roles are included) for experiments are understandable. It makes good point at the end of the paper (section 4) on how these analysis contribute to further design of RNN models, which seems useful.\n2. The experiments are extensive to support their claims. Not only synthetic data but also several popularly-used data and models are being conducted and compared. An addition of analogy dataset further demonstrate the effect of TPDN on modeling structural regularities.\n\nCons:\n1. More detailed and extensive discussion on the contribution of the paper should be included in the introduction part to help readers understand what's the point of investigating TPDN on RNN models.\n2. Some details are missing to better understand the construction. For example, on page 4, Evaluation, it is unclear of how TPDN encoder is trained, specifically, which parameters are updated? What's the objective for training? It is also unclear of whether the models in Figure 3(c) use bidirectional or unidirectional or tree decoder? In Section 3, it could be better to roughly introduce each of the existing 4 models. How do TPDN trained for these 4 sentence encoding models need to be further illustrated. More reasons should be discussed for the results in Table 2 (why bag-of-words role seem to be ok, why skip-thought cannot be approximated well).\n3. It could be better to provide the actual performance (accuracy) given by TPDN on the 4 existing tasks.\n4. Further thoughts: have you considered applying these analysis on other models besides RNN?"", 'The work proposes Tensor Product Decomposition Networks (TRDN) as a way to uncover the representation learned in recurrent neural networks (RNNs). TRDN trains a Tensor Product Representation, which additively combine tensor products of role (e.g., sequence position) embeddings and filler (e.g., word) embeddings to approximate the encoding produced by RNNs. TRDN as a result shed light into inspecting and interpreting representation learned through RNNs. The authors suggest that the structures captured in RNNs are largely compositional and can be well captured by TPRs without recurrence and nonlinearity.\n\npros:\n1. The paper is mostly clearly written and easy to follow. The diagrams shown in Figure 2 are illustrative;\n2. TRDN offers a headway to look into and interpret the representations learned in RNNs, which remained largely incomprehensible;\n3. The analysis and insight provided in section 4 is interesting and insightful. In particular, how does the training task influence the kinds of structural representation learned. \n\n\ncons:\n1. The method relies heavily on these manually crafted role schemes as shown in section 2.1; It is unclear the gap in the approximation of TPRs to the encodings learned in RNNs are due to inaccurate role definition or in fact RNNs learn more complex structural dependencies which TPRs cannot capture;\n2. The MSE of approximation error shown in Table 1 are not informative. How should these numbers be interpreted? Why normalizing by dividing by the MSE from training TPDN on random vectors?\n3. The alignment between prediction using RNN representations and TPDN approximations shown in Table 2 are far from perfect, which would contradict with the claim that RNNs only learn tensor-product representation. ', 'This paper is not standalone.  A section on the basics of document analysis would have been nice.']","[60, 50, -50]","[80, 80, 0]","[""The sentiment score is 60 (positive) because the review starts with a neutral summary and then lists more pros than cons. The pros are described as 'well-written', 'easy to follow', and 'extensive', indicating a positive view. The cons are presented as suggestions for improvement rather than severe criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as constructive suggestions (e.g., 'It could be better to...'). The reviewer also uses phrases like 'good point' and 'seems useful', showing appreciation for the authors' work."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced overview of the work and lists both pros and cons. The pros highlight the clarity of the paper, its contribution to interpreting RNNs, and interesting insights. However, the cons point out some limitations and areas for improvement. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths before presenting criticisms, and phrase their concerns as questions or suggestions rather than harsh criticisms. The use of phrases like 'The paper is mostly clearly written' and 'TRDN offers a headway' indicate a constructive and courteous approach to the review."", ""The sentiment score is -50 because the review expresses a clear criticism of the paper, stating that it is 'not standalone' and suggesting an improvement. This indicates a negative sentiment, though not extremely harsh. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact, without being particularly polite or rude. The reviewer states their opinion plainly without using overly harsh language or softening phrases. The suggestion for improvement is presented as a statement of what 'would have been nice' rather than a demand, which keeps it from being impolite, but also doesn't add extra politeness.""]"
"['This paper describes a model for vision-and-language navigation. The proposed\nmodel adds two components to the baseline model proposed by Fried et al. (2018):\n\n- a panoramic visual attention (referred to in this paper as ""visual--textual\n  co-grounding""), in which the full scene around the agent\'s current position is\n  attended to prior to selecting a direction to follow\n\n- an auxiliary ""progress monitoring"" loss which encourages the agent to to\n  produce textual attentions from which the distance to the goal can be directly\n  inferred\n\nThe two components combine to give state-of-the-art results on the Room2Room\ndataset: small improvements over existing approaches on the ""-seen"" evaluation\nset and larger improvements on the ""-unseen"" evaluation sets. These improvements\nalso stack with the data-augmentation approach of Fried et al.\n\nI think this is a reasonable submission and should probably be accepted. However, I\nhave some concerns about presentation and a number of specific questions about\nmodel implementation and evaluation.\n\nPRESENTATION AND NAMING\n\nFirst off: I implore the authors to find some descriptor other than ""self-aware""\nfor the proposed model. ""Self-aware"" is an imprecise description of the agent in\nthis paper---the agent is specifically ""aware"" of its visual surroundings and\nits distance from the goal, neither of which is meaningfully an aspect of\n""self"". Moreover, self-awareness means something quite different in adjacent\nareas of cognitive science and philosophy; overloading the term in the specific\n(and comparatively mundane) way used here creates confusion. See section 3.4 of\nhttps://arxiv.org/abs/1807.03341 for broader discussion. Perhaps something\nlike ""visual / temporal context-sensitivity"" to describe what\'s new here? A bit\nclunky, but I think it makes the contributions of this work much clearer.\n\nAs suggested in the summary above, I also think ""visual--textual co-attention""\nis also an unhelpfully vague description of this aspect of the contribution. The\ntextual attention mechanism used in this paper is the same as in all previous\nwork on the task. Representations of language don\'t even interact with the\nvisual attention mechanism except by way of the hidden state, and the salient\nnew feature of the visual attention is the fact that it considers the full\npanoramic context before choosing a direction.\n\nMODELING QUESTIONS\n\n- p4: $y_t^{pm}$ is defined as the ""normalized distance from the current\n  viewpoint to the goal"". Is this distance in units of length (as defined by the\n  simulator) or units of time (i.e. the number of discrete ""steps"" needed to\n  reach the goal)?\n\n  The authors have already clarified on OpenReview that the progress monitor\n  objective uses an MSE loss rather than a likelihood loss. Do I understand\n  correctly that ground-truth distances are in [0, 1] but model predictions are\n  in [-1, 1]? Why not use a sigmoid? Also, how does scoring beam-search\n  candidates as $p_t^{pm} \\times p_{k,t}$ work if $p_t^{pm}$ can flip the sign?\n\n- The input to the progress monitor is formed by concatenating the attention\n  vector $\\alpha_t$ to a vector of state features, and then multiplying by a\n  fixed weight matrix. How is this possible? The size of $\\alpha_t$ varies\n  depending on the length of the instruction sequence. Are attentions padded out\n  to the length of the longest instruction in the training set? If so, how can\n  the model learn when it\'s reached the end of a short instruction sequence?\n  What would happen if the agent encountered a sequence that was too long?\n\nEVALUATION QUESTIONS\n\n- The progress monitor is used both as an auxiliary training objective and as a\n  beam search heuristic. Is it possible to disentangle these two contributions?\n  (E.g. by ignoring the scores during beam search, or by doing augmented beam\n  search in a model that was trained without the auxiliary objective.)\n\n- Not critical, but it would be nice to know if the contributions here stack\n  with the pragmatic inference procedure in Fried et al.\n\n- While, as pointed out on OpenReview, it is not required to include SPL\n  evaluations, I think it would be informative to do so---the preliminary\n  results with no beam search look good!\n\nMISCELLANEOUS\n\np1: ""without a map"" If you can do beam search, you effectively have a map.\n\np1: ""...smoothly"" What does ""smoothly"" mean in this context?\n\np2: ""the position of grounded instruction can follow past and future\n    instructions"". Is the claim here that if instructions are of the form ""ACB""\n    and the agent is supposed to do ""ABC"", that the proposed model will execute\n    these instructions successfully and the baseline will not? This claim does\n    not appear to be evaluated anywhere in the body of the paper.\n\np4: ""intelligently prunes"" ""Intelligently"" is unnecessary.\n\np4: ""for empirical reasons"" What does this mean?\n\np5: ""Intuitively, an instruction-following agent is required..."" The existence\n    of non-attentive models that do reasonably well at these\n    instruction-following tasks suggest that this is not actually a requirement.', ""This submission introduces a new method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module. The method is shown to perform well on a standard benchmark. Ablation tests indicate the importance of each component of the model. Qualitative examples show that the proposed method attends to different parts of the instruction as the agent moves. \n\nHere are some comments/questions:\n- I like the underlying idea behind the method. The manuscript is written well for most parts.\n- The qualitative examples and Figure 2 are really helpful in understanding the reasons behind the improved performance.\n- There is a lot of confusion regarding the use of beam search. It's unclear from the current manuscript which results are with and without beam search. It seems like beam search was added from Ours 1 to Ours 2 in Table 2. It's not clear which rows involve beam search in Table 1. Some concerns about beam width were raised in the comments which I agree with. Please modify the submission to clearly indicate the use of beam search for each result and specify the beam width.\n- The use of beam search seems unrealistic to me as I can not think of any way a navigational model using beam search can be transferred or applied to real-world. I understand that one of the baselines uses beam search, so it's fair for performance comparison purposes, but could you provide any justification of how it might be useful in real-world? If there's no reasonable justification, could you also provide all the results (along with SPL metric) without beam search, including ablation, comparing with only methods without beam search? \n- I do not understand why the OSR in the submission is 0.64 and 0.70 for Speaker-Follower and proposed method and 0.96 and 0.97 in the comments.\n- It seems like the proposed method is tailored for the VLN task. In many real-world scenarios, an agent might be given an instruction which only describes the goal (such as in Chaplot et al. 2017 and Hermann et al. 2017) and not the path to the goal, could the authors provide their thoughts on whether the proposed would work well for such instructions? What would the progress monitor and textual attention distribution learn in such a scenario?\n\nDue to confusion about results and concerns about beam search, I give a rating of 5. I am willing to increase the rating if the authors address the above concerns."", 'The paper considers the problem of following natural language route instructions in an unknown environment given only images. Integral to the proposed (""self-aware"") approach is its ability to reason over which aspects of the instruction have been completed, which are to be followed next, which direction to go in next, as well as the agents current progress. This involves two primary components of the architecture. The first is a visual-textual module that grounds to the completed instruction, the next instruction, and the next direction based upon the visual input. The second is a ""progress monitor"" that takes the grounded instruction as input and captures the agent\'s progress towards completing the instruction.\n\n\nSTRENGTHS\n\n+ The paper describes an interesting approach to reasoning over which aspects of a given instruction have been correctly followed and which aspect to act on next. This takes the form of a visual-textual co-grounding model that identifies the instruction previously completed, the instruction corresponding to the next action, and the subsequent direction in which to move. The inclusion of a ""progress monitor"" allows the method to reason over whether the navigational progress matches the instruction.\n\n+ The paper provides a thorough evaluation on a challenging benchmark language understanding dataset. This evaluation includes detailed comparisons to state-of-the-art baselines together with ablation studies to understand the contribution of the different components of the architecture.\n\n+ The paper is well written and provides a thorough description of the framework with sufficient details to support replication of the results.\n\n\nWEAKNESSES\n\n- The paper would benefit from a more compelling argument for the importance of reasoning over which aspects of the instruction have been completed vs. which to act on next.\n\n- The paper emphasizes the use of images, the visual grounding reasons over visual features.\n\n- The paper incorrectly states that existing methods for language understanding require an explicit representation of the target. Several existing methods do not have this requirement. For example, Matuszek et al., 2012 parse free-form language into a formal logic representation for a downstream controller that interprets these instructions in unknown environments. Meanwhile, Duvallet et al., 2014 and Hemachandra et al., 2015 exploit language (together with vision and LIDAR) to learn a distribution over the unknown environment that guides grounding. Meanwhile, Mei et al., 2016 reason only over natural language text and parsed images, without knowledge of the environment or an explicit representation of the goal.\n\nC. Matuszek, E. Herbst, L. Zettlemoyer, and D. Fox, “Learning to parse natural language commands to a robot control system,” in Proceedings of the International Symposium on Experimental Robotics (ISER), 2012.\n\nS. Hemachandra, F. Duvallet, T. M. Howard, N. Roy, A. Stentz, and M. R. Walter, “Learning models for following natural language directions in unknown environments,” in Proc. IEEE Int’l Conf. on Robotics and Automation (ICRA), 2015\n\nF. Duvallet, M. R. Walter, T. Howard, S. Hemachandra, J. Oh, S. Teller, N. Roy, and A. Stentz, “Inferring maps and behaviors\nfrom natural language instructions,” in Proceedings of the International Symposium on Experimental Robotics (ISER), 2014.\n\n- While it\'s not a neural approach, the work of Arkin et al., 2017 which reasons over the entire instruction history when deciding on actions (through a statistical symbol grounding formulation)\u2060\n\nJ. Arkin, M. Walter, A. Boteanu, M. Napoli, H. Biggie, H. Kress-Gazit, and T. Howard. ""Contextual Awareness: Understanding Monologic Natural Language Instructions for Autonomous Robots,"" In Proceedings of the IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 2017\n\n- The paper misses the large body of literature on grounded language acquisition for robotics.\n\nQUESTIONS\n\n* What is the effect of using positional encoding for textual grounding as opposed to standard alignment methods such as those used by Mei et al., 2016?\n\n* Perhaps I missed it, but what happens if instructions are specified in such a way that their ordering is not consistent with the correct action ordering (e.g., with corrections interjected)?\n']","[20, -20, 50]","[60, 60, 80]","[""The sentiment score is slightly positive (20) because the reviewer states 'I think this is a reasonable submission and should probably be accepted.' However, they also express concerns and questions, tempering the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as questions or suggestions rather than harsh criticisms. For example, they say 'I implore the authors' rather than demanding changes. The reviewer also acknowledges clarifications already made by the authors on OpenReview, showing engagement and fairness. While direct in their feedback, the tone remains professional and courteous throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I like the underlying idea', 'manuscript is written well for most parts'), there are several concerns and questions raised. The overall rating of 5 given by the reviewer also indicates a somewhat negative sentiment. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, phrases criticisms as questions or suggestions, and expresses willingness to increase the rating if concerns are addressed. The reviewer also provides specific, constructive feedback and acknowledges positive aspects of the work, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced overview and lists several strengths of the paper, including its 'interesting approach', 'thorough evaluation', and being 'well written'. However, it also points out some significant weaknesses, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively as areas for improvement or questions rather than direct attacks. Phrases like 'The paper would benefit from...' and 'Perhaps I missed it, but...' contribute to the polite tone.""]"
"['The authors propose a policy transfer scheme which in the source domain simultaneously learns a family of policies parameterised by dynamics parameters and then employs an optimisation framework to select appropriate dynamics parameters based on samples from the target domain. The approach is evaluated on a number of simulated transfer tasks (either transferring from DART to MuJoCo or by introducing deliberate model inaccuracies).\n\nThis is interesting work in the context of system identification for policy transfer with an elaborate experimental evaluation. The policy learning part seems largely similar to that employed by Yu et al. 2017 (as acknowledged by the authors). This makes the principal contribution, in the eyes of this reviewer, the optimisation step conducted based on rollouts in the target domain. While the notion of optimising over the space of dynamics parameters is intuitive the question arises whether this optimisation step makes for a substantive contribution over the original work. This point is not really addressed in the experimental evaluation as benchmarking is performed against a robust and an adaptive policy but not explicitly against the (arguably) most closely related work in Yu et al. It could be argued, of course, that Yu et al. essentially use adaptive policy generation but they do explicitly learn dynamics parameters based on recent history of actions and observations. An explicit comparison therefore seems appropriate (or alternatively a discussion of why it is not required).\n\nAnother point which would, in my view, add significant value is explicit discussion of the baseline performances observed in the various experiments. For example, in the hopper experiment (Sec 5.2) the authors state that the baseline methods were not able to adapt to the new environment. Real value could be derived here if the authors could elaborate on why this is the case. The same applies in Sec 5.3-5.6. \n\n(I would add here, as an aside, that I thought the notion in Sec 5.6 of framing the learning of policies for handling deformable objects as a transfer task based on rigid objects to be a nice idea. And not one this reviewer has come across before - though this could merely be a reflection of limited familiarity with the literature).\n\nThe experimental evaluation seems thorough with the above caveat of a seemingly missing benchmark in Yu et al. I would also encourage the authors to add more detail in the experimental section in the main text specifically with regards to number of trials run to arrive at variances in the figures as well as what metric these shaded areas actually signify. \n\nA minor point: the J in equ 1 seems (to me at least) undefined. I suspect that it signifies the expected cumulative reward and was meant to be introduced in Sec 3 where the J may have been dropped from the latex?\n\nIf the above points were addressed I think this would make a valuable and interesting contribution to the ICLR community. As it stands I believe it is marginally below the acceptance threshold.\n\n[ADDENDUM: given the author feedback and addition of the benchmark experiments requested I have updated my score.]\n\n\nPros:\n———\n- interesting work\n- accessible\n- effective\n- thorough evaluation (though potentially missing a key benchmark)\n\nCons:\n———\n- potentially missing a key benchmark (and therefore seems somewhat incremental)\n- only limited insight offered by the authors in the discussion of the experimental results\n- some more details needed with regards to the experimental setup\n', 'This paper presents a novel approach for adapting a policy learned with domain randomization to the target domain. The parameters for domain randomization are explicitly used as input to the network learning the policy. When run in the target domain, CMA-ES is used to search over these domain parameters to find the ones that lead to the policy with the best returns in the target domain.\n\nThis approach is a novel one in the space of domain randomization and sim2real work. The results show that it improves over learning robust policies and over one version of doing an adaptive policy (feedforward network with history input). This approach could\n\nThe paper is well written, clearly explained, has clear results, and also explains and evaluates alternate design choices in the appendix.\n\nPros:\n- Demonstrated transfer across simulated environments\n- Outperforms basic robust and adaptive alternatives\n- Straightforward approach\nCons:\n- Requires explicit domain randomization parameters as input to network. This restricts it from applying to work where the simulator is learned rather than parameterized in this way. \n', ""This paper introduces a simple technique to transfer policies between domains by learning a policy that's parametrized by domain randomization parameters. During transfer CMA-ES is used to find the best parameters for the target domain.\n\nQuestions/remarks:\n- If I understand correctly, a rollout of a policy during transfer (i.e. an episode) contains 2000 samples. Hence, 50000 samples in the target environment corresponds to 25 episodes. Is this correct? Does fine-tuning essentially consists of performing 25 rollouts in the target domain?\n- It seems that for some tasks, there is almost no finetuning happening whereas SO-CMA still outperforms domain randomization (Robust) significantly? How can this be explained? For example, the quadruped task (Fig 6a)  has no improvement for the SO-CMA method, yet it is significantly better than the domain randomization result. It seems that during the first episodes of finetuning, domain randomization and SO-CMA should be nearly equivalent (since CMA-ES will be randomly picking parameters mu). A very similar situation can be seen in Fig 5a\n- Following up on my previous question: fig 4a does show the expected behavior (domain randomization and SO-CMA starting around the same value). However, in this case your method does not outperform domain randomization. Any idea as to why this is the case?\n- It's difficult to understand how good/bad the performance of the various methods are without an oracle for comparison (i.e. just run PPO in the target environment). \n- It seems that the algorithm in this work is almost identical to Hardware Conditioned Policies for Multi-Robot (Tao Chen et al. NIPS 2018), specifically section 5.2 in that paper seems very similar. Please comment.\n\nMinor remarks:\n- fig 5.a y-axis starts at 500 instead of 0.\n- The reward for halfcheetah seems low, but this might be due to the custom setup.""]","[-20, 80, 20]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the work interesting and acknowledges its strengths, they ultimately conclude it is 'marginally below the acceptance threshold'. They raise several concerns and request additional comparisons and details. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the work's merits, and frames criticisms constructively as suggestions for improvement. They use phrases like 'interesting work', 'elaborate experimental evaluation', and 'would add significant value' which contribute to a polite tone. The reviewer also provides a balanced view, listing both pros and cons of the work."", ""The sentiment score is 80 (positive) because the review starts with a clear description of the paper's novel approach and highlights its strengths. The reviewer uses phrases like 'novel approach', 'improves over learning robust policies', and 'well written, clearly explained'. The pros are explicitly listed and outnumber the cons. The politeness score is 50 (slightly positive) because the language is professional and respectful throughout. The reviewer provides balanced feedback, acknowledging both strengths and limitations without using harsh or overly critical language. However, the tone is more neutral than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution ('introduces a simple technique') without strong praise or criticism. The overall tone is neutral to mildly positive, with the reviewer asking questions for clarification rather than pointing out flaws. The politeness score is high (80) as the reviewer uses respectful language throughout, framing their comments as questions and remarks rather than direct criticisms. They use phrases like 'If I understand correctly' and 'Please comment,' which are polite ways to seek clarification. The reviewer also provides constructive feedback and specific points for the authors to address, which is helpful and courteous in academic discourse.""]"
"['The authors propose a benchmark for optimization algorithms specific to deep learning called DeepOBS. They provide code to evaluate an optimizer against a suite of standard tasks in deep learning, and provide well tuned baselines for a comparison. The authors discuss important considerations when comparing optimizers, including how to measure speed and tunability of an optimizer, what metric(s) to compare against, and how to deal with stochasticity.\n\nA clear, standardized optimization benchmark suite would be very valuable for the field. As the others clearly state in the introduction, there have been many proposed optimization algorithms, but it is hard to compare many of these due to differences in how the optimizers were evaluated in the original papers. In general, people have different requirements for what the expect from an optimizer. However, this paper does a good job of discussing most of the factors that people should consider when choosing or comparing optimizers. Providing a set of well tuned baselines would save people a lot of time in making comparisons with a new optimizer, as well as providing a canonical set of tasks to evaluate against. I particularly appreciated the breadth and diversity of the included tasks.\n\nI am a little worried that people will still find minor quibbles with particular choices or tasks in this suite, and therefore continue to use bespoke comparisons, but I think this benchmark would be a valuable resource for the community.\n\nSome minor comments:\n- In section 2.3, there is a recommendation for how to estimate per-iteration cost. I would mention in this section that this procedure is automated and part of the benchmark suite.\n- I wanted to see how the baselines performed on all of the tasks in the suite (not just on the 8 tasks in the benchmark sets). Perhaps those figures could be included in an appendix.\n- The authors might want to consider including an automated way of generating performance profiles (https://arxiv.org/abs/cs/0102001) across tasks as part of DeepOBS, as a way of getting a sense of how optimizers performed generally across all tasks.', ""As the paper claims there is no common accept system for benchmarking deep learning optimizer. It is also hard to repeat others' results. The paper describes a benchmarking framework for deep learning optimizer. It proposes three performance indicators, and includes 20 test problems and a core set of benchmarks. \n\nPro: \n1) It is a very relevant project. There is a need for unified benchmarking framework. In traditional optimization field, benchmarking is well studied and architectured. See an example at http://plato.asu.edu/bench.html\n2) The system is at its early stage, but its design seems complete\n3) The paper shows some performance of vanilla SGD, momentum, and Adam\n\nCon:\n1) It will take tremendous efforts to convince others to join the party and contribute\n2) It only support tensorflow right now\n3) Writing can be better\n\nIn Figure 1, make sure the names of components are consistent: either all start with nouns or verbs. The whole picture is not too illustrative. \n\n\n\nCan switch the order of Figure 2 and Figure 3?\n\nIn Table 1, the description of ALL-CNN-C has a '?'. Is it intended?\n\nWhy not explain Table 2? \n\n\n\n"", 'This paper presents a new benchmark suite to compare optimizer on deep neural networks. It provides a pipeline to help streamlining the analysis of new optimizers which would favor easily reproducible results and fair comparisons.\n\nQuality\n\nThe paper covers well the problems underlying the construction of such a benchmark, discussing the problems and models selection, runtime estimation, hyper-parameter selection and visualizations. It falls short however in some cases:\n\n1. Hyper-parameter optimization\n    While they mention the importance of hyper-parameter tuning for the benchmark, they leave it to the user to tune them without providing any standard procedure. Furthermore, they use grid search to build the baselines while this is known to be a poor optimizer [1].\n\n2. Estimated runtime\n    Runtime is estimated for a single set of hyper-parameters of the optimizer, but some optimizer may have similar or roughly similar results for a large set of hyper-parameters that widely affects the runtime. The effect of the hyper-parameters should be taken into account for this part of the benchmark.\n\n3. Interpretation\n    Such a benchmark should makes it easier for interpretation of results as the authors suggests. However, the paper does not convey much interpretation in section 4, beside the fact that results are not conclusive for any baseline. Results of the paper seem low, but they are difficult to verify since the plots are not very precise. For instance Wide ResNet-18-8 reports 1.54% test accuracy on SVHN [6] while this paper reports ~ 15% for the Wide ResNet 18-4 version. Figure 2 is a good attempt at making interpretations of sensitivity of optimizers\' hyper-parameters but has limited interpretability compared to what can be found in the literature [2].\n\n4. Problems\n    There is an effort to provide varied types of problem, including classical optimization functions, image classification, image generation and language modeling. The number of problems consists mostly of image classification however and is very limited for image generation and language modeling.\n\nClarity\n\nThe paper is well written and easy to understand in general. \n\nOn a minor note, most figures are difficult to read. Side nodes on figure 1 does not divide clearly without any capital letter or punctuation at the end of sentence. Figure 2 should be self contained with its own legend. Figure 3 is useful for a visual impression of the speed of convergence but a histogram would be necessary for a better visual comparison of the different performances.\n\nSection 2.2 has a confusing terminology for the ""train valid set"". Is it a standard validation set? \n\nOriginality\n\nThere is virtually no benchmarks for optimizers available for the community. I believe a standardized procedure for comparing optimizers can be viewed as an original contribution. \n\nSignificance\n\nReproducibility is a problem in machine learning [3, 4] and optimizers\' efficiency on deep neural networks generalization performance is still not very well understood [5]. Therefore, there is a strong need for a benchmark for sound comparisons and to favor better reproducibility.\n\nConclusion\n\nThe benchmark presented in this paper would be an important contribution to the community but lacks a few important features in my opinion, in particular, sound hyper-parameter optimization procedure and sound interpretation tools. On a skeptical note, I doubt the benchmark will be used extensively if the results it provides yield no conclusive interpretation as reported for the baselines. As I feel there is more work needed to support the goals of the paper, I would suggest this paper for a workshop. Nevertheless, I would not be upset if it was accepted because of the importance of the subject and the originality of this work.\n\n[1] Bergstra, James, and Yoshua Bengio. ""Random search for hyper-parameter optimization."" Journal of Machine Learning Research 13, no. Feb (2012): 281-305.\n[2] Biedenkapp, Andre, Joshua Marben, Marius Lindauer and Frank Hutter. “CAVE : Configuration Assessment , Visualization and Evaluation.” In International Conference on Learning and Intelligent Optimization (2018).\n[3] Lucic, Mario, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. “Are GANs Created Equal? A Large-Scale Study.” arXiv preprint arXiv:1711.10337 (2017).\n[4] Melis, Gábor, Chris Dyer, and Phil Blunsom. “On the state of the art of evaluation in neural language models.” arXiv preprint arXiv:1707.05589 (2017).\n[5] Wilson, Ashia C., Rebecca Roelofs, Mitchell Stern, Nati Srebro, and Benjamin Recht. ""The marginal value of adaptive gradient methods in machine learning."" In Advances in Neural Information Processing Systems, pp. 4148-4158. 2017.\n[6] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016\n\n-----------\nRevision\n-----------\n\nIn light of the discussion with the authors, the revision made to chapter 4 and in particular the proposed modifications to section 2.4 for a camera-ready paper, I revise my score to 6.']","[80, 50, -20]","[90, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the proposed benchmark, highlighting its value to the field and appreciating its breadth and diversity. They use phrases like 'would be very valuable' and 'I particularly appreciated'. The slight reduction from 100 is due to minor concerns expressed, such as 'I am a little worried'. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame their suggestions as 'minor comments'. The tone is professional and supportive, with no harsh criticism. The high scores in both categories reflect the overall positive and courteous nature of the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the relevance and completeness of the project, while also pointing out some cons and areas for improvement. The review starts with a neutral summary and then lists both pros and cons, indicating a balanced but slightly favorable view. The politeness score is 70 (fairly polite) because the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement without harsh criticism, and use phrases like 'Can switch' and 'Why not explain' which are polite ways of suggesting changes. The reviewer also acknowledges the potential of the project, calling it 'very relevant' and noting that its design 'seems complete', which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential importance and originality of the work, they point out several significant shortcomings and suggest the paper for a workshop rather than full acceptance. The reviewer's tone is generally constructive but expresses skepticism about the benchmark's usefulness given its current limitations. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also states they 'would not be upset if it was accepted,' showing a degree of courtesy even while recommending against acceptance.""]"
"['The paper proposes a distributed optimization method based on signSGD. Majority vote is used when aggregating the updates from different workers.\n The method itself is naturally communication efficient. Convergence analysis is provided under certain assumptions on the gradient. It also theoretically shows that it is robust up to half of the workers behave independently adversarially. Experiments are carried out on parameter server environment and are shown to be effective in speeding up training. \n\nI find the paper to be solid and interesting. The idea of using signSGD for distributed optimization make it attractive as it is naturally communication efficient. The work provides theoretical convergence analysis under the small batch setting by further assuming the gradient is unimodal and symmetric, which is the main theoretical contribution. Another main theoretical contribution is showing it is Byzantine fault tolerant. The experiments are extensive, demonstrating running time speed-up comparison to normal SGD.  \n\nIt is interesting to see a test set gap in the experiments. It remains to be further experimented to see if the method itself inherently suffer from generalization problems or it is a result of imperfect parameter tuning. \n\nOne thing that would be interesting to explore further is to see how asynchronous updates of signSGD affect the convergence both in theory and practice. For example, some workers might be lost during one iteration, how will this affect the overall convergence.\nAlso, it would be interesting to see the comparison of the proposed method with SGD + batch normalization, especially on their generalization performance. It might be interesting to explore what kind of regularization technique would be suitable for signed update kind of method.   \n\nOverall, I think the paper proposes a novel distributed optimization algorithm that has both theoretical and experimental contribution. The presentation of the paper is clear and easy to follow. \n\nSuggestions: I feel the experiments part could still be improved as also mentioned in the paper to achieve competitive results. More experiments on different tasks and DNN architectures could be performed. \n', 'This paper continues the study of the signSGD algorithm due to (Balles & Hennig, Bernstein et al), where only the sign of a stochastic gradient is used for updating. There are two main results: (1) a slightly refined analysis of two results in Bernstein et al. The authors proved that signSGD continues to converge at the 1/sqrt(T) rate even with minibatch size 1 (instead of T as in Bernstein et al), if the gradient noise is symmetric and unimodal; (2) a similar convergence rate is obtained even when half of the worker machines flip the sign of their stochastic gradients. These results appear to be relatively straightforward extensions of those in Bernstein et al.\n\nClarity: The paper is mostly nicely written, with some occasionally imprecise claims. \n\nPage 5, right before Remark 1: it is wrongly claimed that signSGD converges to a critical point of the objective. This cannot be inferred from Theorem 1. (If the authors disagree, please give the complete details on how the random sequence x_t converges to some critical point x^*. or perhaps you are using the word ""convergence"" differently from its usual meaning?)\n\nPage 6, after Lemma 1. The authors claimed that ""the bound is elegant since ... even at low SNR we still have ... <= 1/2."" In my opinion, this is not elegant at all. This is just your symmetric assumption on the noise, nothing more...\n\nEq (1): are you assuming g_i > 0 here? this inequality is false as you need to discuss the two cases. \n\n""Therefore signSGD cannot converge for these noise distributions, ..... point in the wrong direction."" This is a claim based on intuitive arguments but not a proven fact. Please refrain from using definitive sentences like this.\n\nFootnote 1: where is the discussion?\n\n\nOriginality: Compared to the existing work of Bernstein et al, the novelty of the current submission is moderate. The main results appear to be relatively straightforward refinements of those in Bernstein. The observation that majority voting is Byzantine fault tolerant is perhaps not very surprising but it is certainly nice to have a formal justification.\n\nQuality: At times this submission feels like half-baked:\n-- The theoretical results are about signSGD while the experiments are about sigNUM\n-- The adversaries must send the negation of the sign? why can\'t they send an arbitrary bit vector?\n-- From the authors\' discussion "" we will include this feature in our open source code release"", ""plan to run more extensive experiments in the immediate future and will update the paper..."", and ""should be possible to extend the result to the mini-batch setting by combining ...""\n\nSignificance: This paper is certainly a nice addition to our understanding of signSGD. However, the current obtained results are not very significant compared to the existing results: Theorem 1 is a minor refinement of the two results in Bernstein et al, while Theorem 2 at its current form is not very interesting, as it heavily restricts what an adversary worker machine can do. It would be more realistic if the adversaries can send random bits (still non-cooperated though).\n\n\n\n##### added after author response #####\nI appreciate the authors\' efforts in trying to improve the draft by incorporating the reviewers\' comments. While I do like the authors\' continued study of signSGD, the submission has gone through some significant revision (more complete experiments + stronger adversary). ', 'The authors present a distributed implementation of signSGD with majority vote as aggregation. The result is a  communication efficient and byzantine robust distributed training method. This is an interesting and relevant problem. There are two parts in this paper: first the authors prove a convergence guarantee for signSGD, and then they prove that under a weak adversary attack signSGD will be robust to a constant fraction of adversarial nodes. The authors conclude with some limited experiments.\n\nOverall, the idea of combining low-communication methods with byzantine resilience is quite interesting. That is, by limiting the domain of the gradients one expects that the power of an adversary would be limited too. The application of the majority vote on the gradients is an intuitive technique that can resolve weak adversarial attacks. Overall, I found the premise quite interesting.\n\nThere are several issues that if fixed this could be a great paper, however I am not sure if there is enough time between rebuttals to achieve this for this round of submissions. I will summarize these key issues below.\n\n\n1) Although the authors claim that this is a communication efficient technique, signSGD (on its communication merit) is not compared with any state of the art communication efficient training algorithm, for example:\n- 1Bit SGD [1]\n- QSD [2]\n- TernGrad [3]\n- Deep Gradient compression [4]\nI think it is important to include at least one of those algorithms in a comparison. Due to the lack of comparisons with state of the art it is hard to argue on the relative performance of signSGD.\n\n2) Although the authors claim byzantine resilience, this is against a very weak type of adversary, eg one that only sends back the opposite sign of the local stochastic gradient. An omniscient adversary can craft attacks that are significantly more sophisticated, for which a simple majority vote would not work. Please see the results in [b1].\n\n3) The authors although reference some limited literature on byzantine ML, they do not compare with other byzantine tolerant ML methods. For example check [eg, b1-b4] below. Again, due to the lack of comparisons with state of the art it is hard to argue on the relative performance of signSGD.\n\nOverall, although the presented ideas are promising, a substantial revision is needed before this paper is accepted for publication. I think it is extremely important that an extensive comparison is carried out with respect to both communication efficient algorithms, and/or byzantine tolerant algorithms, since signSGD aims to be competitive with both of these lines of work. This is a paper that has potential, but is currently limited by its lack of appropriate comparisons.\n\n\n\n[1] https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140694.pdf\n[2] https://papers.nips.cc/paper/6768-qsgd-communication-efficient-sgd-via-gradient-quantization-and-encoding.pdf\n[3] https://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning.pdf\n[4] https://arxiv.org/pdf/1712.01887.pdf\n\n[b1] https://arxiv.org/pdf/1802.07927.pdf\n[b2] https://arxiv.org/pdf/1803.01498.pdf\n[b3] https://dl.acm.org/citation.cfm?id=2933105\n[b4] https://arxiv.org/pdf/1804.10140.pdf\n[b5] https://arxiv.org/pdf/1802.10116.pdf\n\n########################\n\nI would like to commend the authors for making a significant effort in revising their manuscript. Specifically, I think adding the experiments for QSGD and Krum are an important addition. However, I still have a few major that in my opinion are significant:\n\n- The experiments for QSGD are only carried for the 1-bit version of the algorithm. It has been well observed that this is by far the least well performing variant of QSGD. That is, 4 or 8 bit QSGD seems to be significantly more accurate for a given time budget. I think the goal of the experiments should not be to compare against other 1-bit algorithms (though to be precise, 1-bit QSGD is a ternary algorithm) , but against the fastest low-communication algorithm. As such, although the authors made an effort in adding more experiments, I am still not convinced that signSGD will be faster than 4 or 8 bit QSGD. I want to also acknowledge in this comment the fact that these experiments do take time, and are not easy to run, so I commend them again for this effort.\n\n- My second comment relates to comparisons with state of the art algorithms in byzantine ML. The authors indeed did compare against Krum, however, as noted in my original review there are many works following Blanchard et al.  \n\nFor example as I noted https://arxiv.org/pdf/1802.07927.pdf (the Bulyan algorithm) shows that there exist significantly stronger defense mechanisms for byzantine attacks. I think it would have been a much stronger comparison to compare with Bulyan.\n\nOverall, I think the paper has good content, and the authors significantly revised their paper according to the reviews. However, several more experiments are needed for convincing a potential reader of the main claims of the paper, i.e., that signSGD is a state of the art communication efficient and byzantine tolerant algorithm. \n\nI will increase my score from 5 to 6, and I will not oppose the paper being rejected or accepted. My personal opinion is that a resubmission for a future venue would yield a much stronger and more convincing paper assuming more extensive and thorough comparisons are added.']","[80, -20, -20]","[70, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'solid and interesting' and highlights several positive aspects, including the novelty of the method, theoretical contributions, and extensive experiments. The reviewer also mentions that the paper is clear and easy to follow. While there are some suggestions for improvement, the overall tone is very positive. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or areas for further exploration rather than direct criticisms. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice addition to our understanding', 'certainly nice to have a formal justification'), they express several criticisms and concerns about the paper's novelty, significance, and completeness. Phrases like 'moderate' novelty, 'half-baked', and 'not very significant' indicate a generally critical stance. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'please refrain from' and 'I appreciate the authors' efforts'. They offer constructive criticism and suggestions rather than harsh condemnations. However, some direct criticisms ('This is not elegant at all') prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper's premise interesting and acknowledges the authors' efforts in revision, they still express significant concerns about the paper's comparisons and experiments. The reviewer suggests that 'substantial revision is needed' and that a resubmission to a future venue might yield a stronger paper. However, the score isn't deeply negative because the reviewer sees potential in the work and acknowledges the authors' efforts. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, commends the authors' efforts multiple times, and provides constructive feedback. They balance criticism with praise and use phrases like 'I would like to commend the authors' and 'I think the paper has good content'. The reviewer also acknowledges the difficulty of the experiments, showing empathy. However, it's not extremely high as the criticism, while polite, is still direct and extensive.""]"
"[""In this paper the authors focus on the problem of weakly-supervised action localization. The authors state that a problem with weakly-supervised attention based methods is that they tend to focus on only the most salient regions and propose a solution to this which reduces the difference between the responses for the most salient regions and other regions. They do this by employing marginalized average aggregation to averaging a sample a subset of features in relation to their latent discriminative probability then calculating the expectation over all possible subsets to produce a final aggregation.\n\nThe problem is interesting, especially noting that current attention methods suffer from paying attention to the most salient regions therefore missing many action segments in action localization. The authors build upon an existing weakly-supervised action localization framework, having identified a weakness of it and propose a solution. The work also pays attention to the algorithm's speed which is practically useful. The experiments also compare to several other potential feature aggregators.\n\nHowever, there are several weakness of the current version of the paper:\n\n- In parts the paper feels overly complicated, particularly in the method (section 2). It would be good to see more intuitive explanations of the concepts introduce here. For instance, the author's state that c_i captures the contextual information from other video snippets, it would be good to see a figure with an example video and the behaviour of p_i and c_i as opposed to lamba_i. I found it difficult to map p_i, c_i to z and lambda used elsewhere.\n\n- The experimental evidence does not show where the improvement comes from. The authors manage to acheieve a 4-5% improvement over STPN through their re-implemenation of the algorithm, however only have a ~2% improve with their marginalized average attention on THUMOS. I would like to know the cause in the increase over the original STPN results: is it a case of not being able to replicate the results of STPN or do the different parameter choices, such as use of leakly RELU, 20 snippets instead of 400 and only rejecting classes whose video-level probabilities are below 0.01 instead of 0.1, cause this big of an increase in results? There is also little evidence that the actual proposal (contextual information) is the reason for the reported improvement.\n\n- There seems to be several gaps in the review of current literature. Firstly, the authors refer to Wei et al. 2017 and Zhang et al. 2018b as works which erase the most salient regions to be able to explore regions other than the most salient. The authors state that the problem with these methods is that they are not end-to-end trainable, however Li et al. 2018 'Tell Me Where to Look': Guided Attention Inference Network' proposes a method which erases regions which is trainable end-to-end. Secondly, the authors do not mention the recent work W-TALC which performs weakly-supervised action localization and outperforms STPN. It would be good to have a baseline against this method.\n\n- The qualitative results in this paper are confusing and not convincing. It is true that the MAAN's activation sequence shows peaks which correspond to groundtruth and are not present in other methods. However, the MAAN activation sequence also shows several extra peaks not present in other methods and also not present in the groundtruth, therefore it looks like it is keener to predict the presence of the action causing more true positives, but also more false positives. It would be good to see some discussion of these failure cases and/or more qualitative results. The current figure could be easily compressed by only showing one instance of the ground-truth instead of one next to each method.\n\nI like the idea of the paper however I am currently unconvinced by the results that this is the correct method to solve the problem.\n"", 'Summary\nThis paper proposed a stochastic pooling method over the temporal dimension for weakly-supervised video localization problem. The main motivation is to resolve a problem of discriminative attention that tends to focus on a few discriminative parts of an input data, which is not desirable for the purpose of dense labeling (i.e. localization). The proposed stochastic pooling method addressed this problem by aggregating all possible subsets of snippets, where each subset is constructed by sampling snppets from learnable sampling distribution. The proposed method showed that such approach learns more smooth attention both theoretically and empirically.\n\nClarity:\nThe paper is well written and easy to follow. The ideas and methods are clearly presented.\n\nOriginality and significance:\nThe proposed stochastic pooling is novel and demonstrated that empirically useful. Given that the proposed method can be generally applicable to other tasks, I think the significance of the work is also reasonable. One suggestion is applying the idea to semantic segmentation, which also shares a similar problem setting but easier to evaluate its impact than videos. Similar to (Zhou et al. 2016), you can plug the proposed pooling method on top of CNN feature map instead of global average pooling, which might be doable with the more affordable computational cost since the number of hidden units for pooling is much smaller than the length of videos (N < T). \n\nOne downside of the proposed method is its computational complexity (O(T^2)). This is much higher than the one for other feedforward methods (O(T)), which can be easily parallelized (O(1)). This can be a big problem when we have to handle very long sequences too (increasing the length of snippets could be one alternative, but it is not desirable for localization at the end). Considering this disadvantage, the performance gain by the proposed method may not be considered attractive enough. \n\nExperiment:\nOverall, the experiment looks convincing to me. \n\nMinor comments:\nCitation error: Wrong citation: Nguyen et al. CVPR 2017 -> CVPR 2018\n', 'This paper considers the problem of weakly-supervised temporal action localization. It proposes a marginalized average attention network (MAAN) to suppress the effect of overestimating salient regions.  Theoretically, this paper proves that the learned latent discriminative probabilities reduce the difference of responses between the most salient regions and the others. In addition, it develops a fast algorithm to reduce the complexity of constructing MAA to O(T^2). Experiments are conducted on THUMOST14 and ActivityNet 1.3.\n\nI like the theoretical part of this paper but have concerns about the experiments. More specifically, my doubts are\n\n- The I3D network models are not trained from scratch. The parameters are borrowed from (Carreira and Zisserman 2017), which in fact make the attention averaging very easy. I don’t know whether the success is because the proposed MAAN is working or because the feature representation is very powerful.\n\n- If possible, I wish to see the success of the proposed method for other tasks, such as image caption generation, and machine translation.  If the paper can show success in any of such task, I would like to adjust my rating to above acceptance.\n\n']","[-30, 50, -20]","[60, 80, 60]","[""The sentiment score is -30 because while the reviewer acknowledges the interesting problem and some positive aspects, they express significant concerns and state they are 'unconvinced by the results'. The overall tone is more negative than positive. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledges positive aspects, and phrases criticisms constructively (e.g. 'It would be good to see...'). However, it's not extremely polite, maintaining a professional tone rather than being overtly courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, clear writing, and convincing experiments, but also points out significant downsides like computational complexity. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'well written' and 'clearly presented', and offering suggestions for improvement rather than harsh criticism. The reviewer maintains a professional and respectful tone throughout, even when discussing limitations."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses liking the theoretical part of the paper, they have significant concerns about the experiments. The reviewer suggests that the paper's success might be due to powerful feature representation rather than the proposed method, and requests additional experiments to demonstrate the method's effectiveness in other tasks. These concerns outweigh the initial positive comment.\n\nThe politeness score is moderately positive (60) because the reviewer uses polite language throughout. They start with a positive comment ('I like the theoretical part') before expressing concerns. The use of phrases like 'I wish to see' and 'If possible' when suggesting improvements indicates a respectful tone. The reviewer also offers to adjust their rating positively if additional evidence is provided, which is a constructive approach. While critical, the review maintains a professional and courteous tone throughout.""]"
"['This paper introduces a new algorithm for differential game, where the goal is to find a optimize several objective functions simultaneously in a game of n players. The proposed algorithm is an interpolation between LOLA and LookAhead, and it perserves both the stability from LOLA and the ""convergence to fixed point"" property of LookAhead. The interpolation parameter is chosen in Section 3.2.\n\nThe paper looks novel, though some notations are not completely clear to me. For example, the defintions of the ""current parameters"" \\hat{\\theta}_1 and \\hat{\\theta}_2 in Section 3.1, and the stop-gradient operator. Also, how is the diag operator in Propostion 1 is defined? Normally it only represents the diagonal entries but here it might represent the diagonal blocks.\n\n\n', 'This paper studies differential games, in which there are n players and each has a loss function. The loss function depends on all parameters. Differential games appear naturally in GANs, where the two players are the generator and the discriminator. The authors first argue why Nash equilibria should not be the right solution concept for multi-agent learning and propose “stable fixed points” (SFP) as a possible solution concept. The authors then show the LOLA algorithm (Foerster et al. (2018)) fails to preserve fixed points by explicitly constructing an instance (the tandem game). In fact in the tandem game, LOLA will converge to sub-optimal scenarios with worse losses for both agents. The authors then show that an known algorithm LookAhead (Zhang & Lesser (2010)) has local convergence to SPF. However, LookAhead does not have the capacity to exploit opponent dynamics and encourage cooperation. To alleviate this issue, the authors propose a new algorithm SOS, which can be seen as an interpolation between LOLA and LookAhead, characterized by a parameter p. The authors also discuss how to choose the parameter p and prove that SOS will have local convergence to SFP and can avoid strict saddles.  \n\nOverall, this paper is well-written and develops algorithms for a well-motivated problem. Although I am not an expert on this topic, the paper seems interesting to me. \n\nMinor Comment:\nFirst paragraph in Section 2.2, ""It is highly undesirable to converge to Nash in this game"" -> Nash equilibria \n', ""This paper focuses on the problem of convergence in multi-objective optimisation with differentiable losses. This topic is timely and relevant, given the increasing amount of recent work on multi-objective architectures, e.g. GANs, adversarial learning, multi-agent reinforcement learning. The authors focus on stable fixed points (SFP), rather than Nash equilibria, as the solution concept in the entirety of their analysis. Casting the recently proposed LOLA gradient adjustment into a general matrix form, they diagnose an example where the shaping term in LOLA prevents convergence to SFP. They also find that discarding the shaping term leads to an earlier method (which they name ''LA'') with convergence guarantees in two-player two-action games. However, this also loses the opponent shaping ability of LOLA. To address these limitation, the authors propose SOS, which interpolates between LA and LOLA, and dynamically chooses the interpolation coefficient $p$ so that their adjusted gradient preserves LOLA's shaping ability only to the extent allowed by the constraint of moving in LA's direction. The main goal of the paper is to show that SOS converges locally to SFP, and to fixed points only, while avoiding strict saddles. Experiments on synthetic games show that SOS preserves the benefit of LOLA while avoiding its theoretically-predicted issues, and a more complex Gaussian mixture GAN experiment shows SOS is empirically competitive with other gradient adjustment methods.\n\nThe main conceptual novelty consists of the dynamic interpolation term to combine advantages of LOLA and LA while avoiding pitfalls of both. The major strength of the paper lies in the clear justification for this interpolation approach. The paper contains strong theoretical results for general differentiable games, and deserves the notice of the ICLR community if valid. However, I have major concerns with the proof of Theorem 2 (i.e. Theorem D.4 in the appendix), which affects the validity of Corollary 3 and Theorem 4. \n\nIn the proof of Theorem D.4:\n1. How does the expression $u^T M^{-1}GMu$ have conformable dimensions, when $G \\in R^{d \\times d}$ while $u \\in R^{d-1}$? Was any assumption made about the matrix $M = (I + \\alpha H_d)^{1/2}$?\n2. In the middle of page 14, a unit vector $u \\in S^m$ is defined, but it is not clear what vector space is meant by $S^m$.\n3. In the second-to-last line of page 14, a quantity $S$ is used but not defined clearly in any preceding part of the proof. Remark D.5 refers to $S$ as the symmetric part of $G$, and asserts that S is not positive definite. If the quantity $S$ used in the proof is the same non-PD quantity, then $S$ does not have a Cholesky factorisation. So how is Cholesky decomposition conducted at end of page 14?\n4. In the first line of page 15, a quantity $A$ is used but not defined anywhere else in the entire paper. \n5. From the subsequent line, it appears to be the anti-symmetric part of H. Is it correct assumption? If so, $H^2$ is not $(S^T - A^T)(S + A)$. If you replace it with correct form, whole quantity does not compute to be positive or becomes meaningless.\n\nAs Theorem 2 is the crux for all the theoretical advancement presented in the paper, clarifications on above correctness questions is very important for clear acceptance of this work.\n\nWhile Definition 1 precisely defines differentiable games to have *twice* differentiable losses, why do the authors assume *thrice* differentiable losses at the start of Section 4?\n\nIn Section 2.2, the authors make a broad statement that ''Nash equilibria cannot be the right solution concept for multi-agent learning.'' They provide one example where Nash is undesirable (L^1 = L^2 = xy). However, since this example can be viewed as a fully cooperative game with joint loss L = 2xy, it does not support the broader statement that Nash is undesirable in all games. Because this statement directly motivates the authors to focus on stable fixed points, rather than Nash, as the solution concept in their subsequent analysis, it is very important to provide better justification for the claim.\n\nMinor comments:\n1. Under Proposition 1, the authors suddenly speak of ''...the policy being optimal''. Since the author's work pertains to general multi-objective settings, not solely multi-agent reinforcement learning, the word ''policy'' sounds strange in context.\n2. The statement of Proposition B.1, and the concluding line of the derivation, left out a coefficient $\\alpha$ that is present in Proposition 1 in the main text.\n3. While the authors claim and prove independence of theoretical results from choice of a and b, are there any practical implications in terms of performance or convergence?\n""]","[50, 70, -20]","[70, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty and the algorithm's positive attributes, but also points out some unclear aspects. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as personal difficulties in understanding rather than flaws in the paper (e.g., 'not completely clear to me' instead of 'poorly explained'). The reviewer also begins with positive comments before moving to suggestions for improvement, which is a polite approach in academic reviews."", ""The sentiment score is 70 (positive) because the reviewer states the paper is 'well-written' and 'develops algorithms for a well-motivated problem.' They also mention finding the paper 'interesting,' indicating a generally positive view. However, it's not a perfect score as the reviewer admits to not being an expert on the topic. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They offer praise where due and provide a minor comment for improvement without harsh criticism. The use of phrases like 'well-written' and 'interesting' contributes to the polite tone. The reviewer also acknowledges their own limitations ('Although I am not an expert'), which adds to the courteous nature of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's relevance and some strengths, they express 'major concerns' about the proof of a key theorem, which affects the validity of other important results. The reviewer also questions some broad statements and assumptions made by the authors. However, the score isn't deeply negative because the reviewer still sees value in the work if the concerns can be addressed. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or areas needing clarification rather than outright dismissals. The reviewer also provides detailed, constructive feedback to help improve the paper, which is a polite approach to peer review.""]"
"[""Paper summary:\nThe paper proposes to predict bouncing behavior from visual data. The model has two main components: (1) Physics Interface Module, which predicts the output trajectory from a given incoming trajectory and the physical properties of the contact surface. (2) Visual Interface Module, which predicts the surface properties from a single image and the impact location. A new dataset called Bounce Dataset is proposed for this task.\n\nPaper strengths:\n- The paper tackles an interesting and important problem.\n- The data has been collected in various real scenes.\n- The idea of training the physics part of the network with synthetic data and later fine-tuning it with real images is interesting.\n- The experiments are thorough and well-thought-out.\n\nPaper weaknesses:\n- It would be more interesting if the dataset was created using multiple types of probe objects. Currently, it is only a ball.\n\n- It is not clear how the evaluation is performed. For instance, the length of the groundtruth and predicted trajectories might be different. How is the difference computed?\n\n- The impact location (x,y) corresponds to multiple locations in 3D. Why not using a 3D point as input? It seems the 3D information is available for both the real and synthetic cases.\n\n- Why is it non-trivial to use a deconvolution network for predicting the output point cloud trajectory?\n\n- The length of the input trajectory can vary, but it seems the proposed architecture assumes a fixed-length trajectory. I am wondering how it handles a variable-length input.\n\n- How is the bounce location encoded in VIM?\n\n- I don't see any statistics about the objects being used for data collection. That should be added to the paper.\n\n>>>>> Final score: The authors have addressed my concerns in the rebuttal. I believe this paper tackles an interesting problem, and the experiments are good enough since this is one of the first papers that tackle this problem. So I keep the initial score. \n"", 'This paper presents a method for inferring physical properties of the world (specifically, normals and coefficients of restitution) from both visual and dynamic information.  Objects are represented as trajectories of point clouds used under an encoder/decoder neural network architecture.  Another network is then learned to predict the post bounce trajectory representation given the prebounce trajectory representation given the surface parameters.  This is used both to predict the post bound trajectory (with a forward pass) but also to estimate the surface parameters through an optimization procedure.  This is coupled with a network which attempts to learn these properties from visual cues as well.  This model can be either pretrained and fixed or updated to account for new information about a scene.\n\nThe proposed model is trained on a newly collected dataset that includes a mixture of real sequences (with RGB, depth, surface normals, etc) and simulated sequences (additionally with physical parameters) generated with the help of a physics engine.  It is compared with a number of relevant baseline approaches and ablation models.  The results suggest that the proposed model is effective at estimating the physical properties of the scene.\n\nOverall the paper is well written and thoroughly evaluated.  The problem is interesting and novel, the collected dataset is likely to be useful and the proposed solution to the problem is reasonable.', 'The authors present both a dataset of videos of a real-world foam ball bouncing and a model to learn the trajectory of the ball at collision (bounce) points in these videos.  The model is comprised of a Physics Inference Module (PIM) and a Visual Inference Module (VIM).  The PIM takes in both a vector of physical parameters (coefficient of restitution and collision normal) and a point cloud representation of the pre-bounce trajectory, and produces a point cloud representation of the post-bounce trajectory (or, rather, an encoded version of such).  The VIM takes in an image and ground-truth bounce location and produces the physical parameters of the surface at that location.\n\nI find the paper well-written and clear.  The motivation in the introduction is persuasive and the related work section is complete.  However, the authors are introducing both a new training paradigm (to my knowledge unused in the literature) and a new model, and without any existing baselines to compare against I find it a bit difficult to understand how well the model works.  \n\nOverall, the authors’ model is somewhat complicated and not as general as it initially seems.  To justify this complication I would like to see more convincing results and benchmarking or application to more than one single dataset (e.g. non-spheres bouncing).\n\nHere are some specific concerns:\n\n1)  I could not find a link to an open-sourced version of the dataset(s).  Given that the authors emphasize the dataset as a main contribution of the paper, they should open-source it and make the link prominent in the main text (apologies if I somehow missed it).\n\n2)  The authors claim in multiple places that the model is trained end-to-end, but this does not seem to be the case.  Specifically, the PIM is pre-trained on an auxiliary dataset from simulation.  The trajectory encoder also seems to be pre-trained (though I could be wrong about that, see my question below).  Furthermore, there is a bit of hand-holding:  The PIM uses ground-truth state for pre-training, and the VIM gets the ground-truth bounce location.  In light of this, the model seems a lot less general and end-to-end than implied in the abstract and introduction.\n\n3)  No comparison to existing baselines.  I would like to see how the authors’ model compares to standard video prediction algorithms.  The authors could evaluate their model with respect to pixel loss (after ground-truth rendering) and compare to a video prediction algorithm (such as PredNet by Lotter, Kreiman, & Cox, 2016).  Given that the authors’ method uses some extra “privileged” information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot.\n\n4)  Table 1 is not a very convincing demonstration of performance.  Regardless of baselines, the table does not show confidence intervals.  I would love to see training curves with errorbars of the models on the most important metrics (e.g. Dist and COR Median Absolute Error).\n\nI also was confused about a couple of things:\n\n1)  How was the PointNet trajectory encoder trained?  I did not see this mentioned anywhere.  Were gradients passed through from the PIM?  Was the same network used for both the simulation and real-world data?\n\n2)  The performance of the center-based model in Table 1 seems surprisingly low.  The center-based model should be as good at the Train core, Fix traj. enc. model, since it has access to the ball’s position.  Why is it worse?  Is the VIM at fault?  Or is the sphere-fitting sub-optimal?  How does it compare on the simulated data with ground truth physical parameters?\n\n3)  Lastly, the color-scheme is a bit confusing.  It looks like the foam ball in the videos was rainbow-colored.  However, in the model outputs in trajectory figures time is also rainbow-colored.  This was initially a bit confusing.  Perhaps grayscale for the model outputs would be clearer.\n']","[60, 80, -20]","[70, 50, 60]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's strengths, such as tackling an interesting problem, having thorough experiments, and using a novel approach. The reviewer also mentions that the authors addressed their concerns in the rebuttal. However, it's not a perfect score due to the initial weaknesses pointed out. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and provides constructive feedback. The reviewer's tone is professional and supportive, even when pointing out weaknesses. The use of phrases like 'It would be more interesting if...' and 'I am wondering how...' contribute to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'well written and thoroughly evaluated', state that the problem is 'interesting and novel', and note that the results suggest the proposed model is effective. The lack of criticism and the use of positive language throughout indicates a favorable sentiment. The politeness score is 50 (somewhat polite) because while the reviewer doesn't use overtly polite language, they maintain a professional and respectful tone throughout. They offer praise without being effusive and present their observations in a neutral, factual manner. The language is neither rude nor exceptionally polite, but leans towards politeness in its constructive and positive approach."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'well-written and clear' with 'persuasive' motivation, they express several concerns and request more convincing results. The reviewer states that it's 'difficult to understand how well the model works' and asks for more benchmarking and comparisons to baselines. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions or questions. They use phrases like 'I would like to see' and 'I find it a bit difficult' rather than making harsh judgments. The reviewer also apologizes for potentially missing information ('apologies if I somehow missed it'), which adds to the polite tone.""]"
"[""\n\nThe authors suggest a method to create combined low-dimensional representations for combinations of pairs of words which have a specific syntactic relationship (e.g. adjective - noun). Building on the generative word embedding model provided by Arora et al. (2015), their solution uses the core tensor from the Tucker decomposition of a 3-way PMI tensor to generate an additive term, used in the composition of two word embedding vectors.\n\nAlthough the method the authors suggest is a plausible way to explicitly model the relationship between syntactic pairs and to create a combined embedding for them, their presentation does not make this obvious and it takes effort to reach the conclusion above. Unlike Arora's original work, the assumptions they make on their subject material are not supported enough, as in their lack of explanation of why linear addition of two word embeddings should be a bad idea for composition of the embedding vectors of two syntactically related words, and why the corrective term produced by their method makes this a good idea. Though the title promises a contribution to an understanding of word embedding compositions in general, they barely expound on the broader implications of their idea in representing elements of language through vectors.\n\nTheir lack of willingness to ground their claims or decisions is even more apparent in two other cases. The authors claim that the Arora's RAND-WALK model does not capture any syntactic information. This is not true. The results presented by Arora et al. indeed show that RAND-WALK captures syntactic information, albeit to a lesser extent than other popular methods for word embedding (Table 1, Arora et al. 2015). Another unjustified choice by the authors is their choice of weighing the Tensor term (when it is being added to two base embedding vectors) in the phrase similarity experiment. The reason the authors provide for weighing the composition Tensor is the fact that in the unweighted version their model produced a worse performance than the additive composition. One would at least expect an after-the-fact interpretation for the weighted tensor term and what this implies with regard to their method and syntactic embedding compositions in general.\n\nArora's generative model for word embeddings, on which the current paper is largely based upon, not only make the mathematical relationship among different popular word embedding methods explicit, but also by making and verifying explicit assumptions with regard to properties of the word embeddings created by their model, they are able to explain why low-dimensional embeddings provide superior performance in tasks that implicate semantic relationships as linear algebraic relations. Present work, however interesting with regard to its potential implications, strays away from providing such theoretical insights and suffices with demonstrating limited improvements in empirical tasks."", 'The authors consider the use of tensor approximations to more accurately capture syntactical aspects of compositionality for word embeddings. Given two words a and b, when your goal is to find a word whose meaning is roughly that of the phrase (a,b), a standard approach to to find the word whose embedding is close to the sum of the embeddings, a + b. The authors point out that others have observed that this form of compositionality does not leverage any information on the syntax of the pair (a,b), and the propose using a tensor contraction to model an additional multiplicative interaction between a and b, so they propose finding the word whose embedding is closest to a + b + T*a*b, where T is a tensor, and T*a*b denotes the vector obtained by contracting a and b with T. They test this idea specifically on the use-case where (a,b) is an adjective,noun pair, and show that their form of compositionality outperforms weighted versions of additive compositionality in terms of spearman and pearson correlation with human judgements. In their model, the word embeddings are learned separately, then the tensor T is learned by minimizing an objective whose goal is to minimize the error in predicting observed trigram statistics. The specific objective comes from a nontrivial tensorial extension of the original matricial RAND-WALK model for learning word embeddings.\n\nThe topic is fitting with ICLR, and some attendees will find the results interesting. As in the original RAND-WALK paper, the theory is interesting, but not the main attraction, as it relies on strong generative modeling assumptions that essentially bake in the desired results. The main appeal is the idea of using T to model syntactic interactions, and the algorithm for learning T. Given that the main attraction of the paper is the potential for more performant word embeddings, I do not believe the work will have wide appeal to ICLR attendees, because no evidence is provided that the features from the learned tensor, say [a, b, T*a*b], are more useful in downstream applications than [a,b] (one experiment in sentiment analysis is tried in the supplementary material with no compelling difference shown).\n\nPros:\n- theoretical justification is given for their assumption that the higher-order interactions can be modeled by a tensor\n- the tensor model does deliver some improvement over linear composition on noun-adjective pairs when measured against human judgement\n\nCons:\n- no downstream applications are given which show that these higher order interactions can be useful for downstream tasks.\n- the higher-order features T*a*b are useful only when a is noun and b is an adjective: why not investigate using T to model higher-order interaction for all (a,b) pairs regardless of the syntactic relationships between a and b?\n- comparison should be made to the linear composition method in the Arora, Liang, Ma ICLR 2017 paper \n\nSome additional citations: \n- the above-mentioned ICLR paper provides a performant alternative to unweighted linear composition\n- the 2017 Gittens, Achlioptas, Drineas ACL paper provides theory on the linear composition of some word embeddings\n  ', 'The paper deals with further development of RAND-WALK model of Arora et al. There are stable idioms, adjective-noun pairs and etc that are not covered by RAND-WALK, because sometimes words from seemingly different contexts can join to form a stable idiom. \n\nSo, the idea of paper is to introduce a tensor T and a stable idiom (a,b) is embedded into v_{ab}=v_a+v_b+T(v_a, v_b,.) and is emitted with some probability p_sym (proportional to exp(v_{ab} times context)). The latter model is similar to RAND-WALK, so it is not surprising that statistical functions there are similarly concentrated. Finally, there exists an expression, PMI3(u,v,w), that shows the correlation between 3 words, and that can be estimated from the data directly. It is proved that Tucker decomposition of that tensor gives us all words embeddings together with tensor T. Thus, from the latter we will obtain a tool for finding embeddings of idioms (i.e. v_a+v_b+T(v_a, v_b,.)).\n\nTheoretical analysis seems correct (I have not checked all the statements thoroughly, but I would expect formulations to be true). The only problem I see is that phrase similarity part is not convincing. I cannot understand from that part whether T(v_a, v_b,.) addition to v_a+v_b gives any improvement or not.']","[-40, -20, 50]","[20, 50, 0]","[""Sentiment Score (-40): The review expresses several criticisms and concerns about the paper, including lack of clear presentation, insufficient support for assumptions, and unjustified claims. However, it does acknowledge the method as 'plausible' and 'interesting', preventing a more negative score. Politeness Score (20): The reviewer maintains a professional tone throughout, using phrases like 'the authors suggest' and 'one would expect', rather than direct accusations. They also acknowledge potential positives, showing respect. However, the criticism is direct and unvarnished, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also list several 'Cons' and express doubts about the work's wide appeal to ICLR attendees. The reviewer states that 'no evidence is provided that the features... are more useful in downstream applications,' which is a significant criticism. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, acknowledging the paper's strengths while also providing constructive criticism. They use phrases like 'some attendees will find the results interesting' and provide specific suggestions for improvement, which maintains a polite tone even when critiquing."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's theoretical contributions and correctness, stating 'Theoretical analysis seems correct' and describing the paper's ideas in detail. However, they also express some reservations, particularly about the phrase similarity part, which prevents a higher positive score. The politeness score is 0 (neutral) as the review uses professional, matter-of-fact language without being particularly polite or rude. The reviewer states their opinions directly without softening language, but also without any harsh criticism.""]"
"['This work refines the NAS method for efficient neural architecture search. The paper brings new methods for gradient/reward updates and credit assignment. \n\npros: \n1. An improvement on gradient calculation and reward back-propagation mechanism\n2. Good experiment results and fair comparisons\n\ncons:\n1. Missing details on how to use the gradient information to generate child network structures. In eq.2, multiplying each one-hot random variable Zij to each edge (i, j) in the DAG can obtain a child graph whose intermediate nodes are xj. However, it is still unclear how to generate the child graph. More details on generating child network based on gradient information is expected. \n2. In SNAS, P(z) is assumed fully factorizable. Factors are parameterized with alpha and learnt along with operation parameters theta. The factorization of p(Z) is based on the observation that NAS is a task with fully delayed rewards in a deterministic environment. That is, the feedback signal is only ready after the whole episode is done and all state transitions distributions are delta functions. In eq. 3, the authors use the training/testing loss directly as reward, while the previous method uses a constant reward from validation accuracy. It is unclear why using the training/testing loss can improve the results? \n', 'Summary:\nThis paper proposes Stochastic Neural Architecture Search (SNAS), a method to automatically and efficiently search for neural architectures. It is built upon 2 existing works on these topics, namely ENAS (Pham et al 2018) and DARTS (Liu et al 2018).\n\nSNAS provides nice theory and explanation of gradient computations, unites the strengths and avoid the weaknesses of ENAS and DARTS. There are many details in the paper, including the Appendix. The idea is as follows:\n+------------+---------------------+-------------------------+\n| Method | Differentiable | Directly Optimize |\n|                |                           |    NAS reward       |\n+------------+---------------------+-------------------------+\n| ENAS     |      No                |        Yes                   |\n| DARTS   |      Yes               |        No                    |\n| SNAS     |      Yes               |        Yes                   |\n+------------+---------------------+-------------------------+\nSNAS inherits the idea of ENAS and DARTS by superpositioning all possible architectures into a Directed Acyclic Graph (DAG), effectively sharing the weights among all architectures. However, SNAS improves over ENAS and DARTS as follows (Section 2.2):\n\n1. SNAS improves over ENAS in that it allows independent sampling at edges in the shared DAG, leading to a more tractable gradient at the edges of the DAG, which in turn allows more tractable Monte Carlo estimation of the gradients with respect to the architectural parameters.\n\n2. While DARTS also has the property (1), DARTS implements this by computing the expected value at each node in the DAG, with respect to the joint distribution of the input edges and the operations. This makes DARTS not optimize the direct NAS objective. SNAS, due to their smart manipulation of architectural gradients using Gumbel variables, still optimizes the same objective with NAS and ENAS, but has a smoother gradients.\n\nExperimental results in the paper show that SNAS finds architectures on CIFAR-10 that are comparable to those found by ENAS and DARTS, using a reasonable amount of computing resource. These architectures can also be transferred to learn competent models on ImageNet, like those of DARTS. Furthermore, experimental observations (Figure 3) are consistent with the theory above, that is:\n\n1. The search process of SNAS is more stable than that of ENAS (as SNAS samples with a smaller variance).\n2. Architectures found by SNAS perform better than those of DARTS, as SNAS searches directly for the NAS reward of the sampled models. \n\nStrengths:\n1. SNAS unites the strengths and avoids the weaknesses of ENAS and DARTS\n\n2. SNAS provides a nice theory, which is verified through their experimental results.\n\nWeaknesses:\nI don’t really have any complaints about this paper. Some presentations of the paper might have been improved, e.g. the discussion on the ZERO operation in other comments should have been included.\n', ""This paper improves upon ENAS and DARTS by taking a differentiable approach to NAS and optimizing the objective across the distribution of child graphs. This technique allows for end-to-end architecture search while constraining resource usage and allowing parameter sharing by generating effective reusable child graphs.\n\nSNAS employs Gumbel random variables which gives it better gradients and makes learning more robust compared to ENAS. The use of Gumbel variables also allow SNAS to directly optimize the NAS objective which is an advantage over DARTS.\n\nThe resource constraint regularization is interesting. Regularizing on the parameters that describe the architecture can help constrain resource usage during the forward pass. \n\nThe proposed method is novel but the main concern here is that there is no clear win over existing techniques in terms of performance. I can't see anywhere in the tables where you demonstrate a clear improvement over DARTS or ENAS.\n\nFurthermore, in your child network evaluation with CIFAR-10, you mention that the comparison is without fine-tuning. Do you think this might be contributing to the performance gap in DARTS?\n""]","[50, 90, 20]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the work, followed by a balanced list of pros and cons. The pros highlight improvements and good experimental results, while the cons point out areas for improvement without being overly critical. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They acknowledge the positive aspects of the work and frame their criticisms as suggestions for improvement rather than harsh critiques. Phrases like 'More details... is expected' and 'It is unclear why...' are polite ways of requesting clarification or additional information."", ""The sentiment score is 90 out of 100 because the reviewer expresses a very positive view of the paper, highlighting its strengths and innovations without any major criticisms. They state 'I don't really have any complaints about this paper' and list multiple strengths. The only minor suggestion is about improving some presentations, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 out of 100 because the reviewer uses respectful and professional language throughout, acknowledging the paper's contributions and explaining their thoughts clearly. They offer constructive feedback without any harsh or rude comments. The tone is consistently polite and academic, though not excessively formal or deferential, hence the score of 80 rather than 100."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's improvements and novel approach, but expresses concerns about the lack of clear performance improvements. The review starts with positive points about the paper's contributions, but later raises questions and concerns. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames concerns as questions rather than direct criticisms. The reviewer maintains a professional tone and offers constructive feedback without being overly critical or dismissive.""]"
"['[Summary]\n- This work proposes a new complex latent space described by convolutional manifold, and this manifold can map the image in a more robust manner (when some part of the image are to be restored).\n\n[Pros]\n- The results show that the latent variable mapped to the image well represents the image, and it will be helpful for the image restoration problem.\n- it seems novel to adapt the idea of DIP for defining complex latent space.\n\n[Cons]\n- The main concern is that there is no guarantee that the defined latent space is continuous. \nIt means that it is difficult to judge whether the interpolated point (phi_in, s_in) between two points: (phi_1, s_1) and (\\phi_2, s_2), will be matched to the image distribution. \nEquation 2 in the paper seems that it just fit the generator parameter theta to map the phi_i and x_i and memorize the mapping between the training images and the given latent convolutional variables. \nIf the proposed algorithm just memorizes the training image and map them into given the latent convolution, the result cannot justify the proposal that the author proposes a new latent space.\n\n[Summary]\n- This work proposes an interesting idea of defining complex latent space, but It is doubtful that this work just memorized the mapping between the training images and the latent convolutional parameters.\n- I want to see the (latent space) interpolation test for the proposed latent convolutional space. If the author provides a profound explanation of the problem, I would consider changing the rating.\n\n--------------------------\nSee the additional comment for the changed rating\n', '# Summary\nThe paper proposes to embed natural images in a latent convolutional space of high dimensionality to obtain a universal image prior. Concretely, each image is embedded as a custom parameter vector of a CNN, which turns random noise into the input of a universal generator network to restore the image in pixel space.\nInference for image restoration is performed by minimizing the energy of a likelihood objective while constraining the latent representation of the restored image to be part of the learned latent space. Experiments for inpainting, super-resolution, and colorization are performed to evaluate the proposed method.\n\n# Positive\nAs mentioned in the paper, I agree that the idea of learning a universal image prior is appealing, since it can be applied to (m)any image restoration tasks without adjustment.\nI am not very familiar with the related work, but if I understood correctly, the paper seems to combine deep latent modeling (GLO, Bojanowski et al., 2018) and deep image priors (Ulyanov et al., 2018). The experiments show good results which qualitatively appear better than those of related methods. A user study also shows that people mostly prefer the results of the proposed method.\nDid you try other standard restoration tasks, such as image denoising or deblurring? If not, do you think they would work equally well?\n\n# Limitations\nWhile I agree that a universal image prior is valuable, the paper should (briefly) mention what the disadvantages of the proposed approach are:\n- A limitation (at least as presented) is that the corruption process has to be known analytically (as a likelihood objective) and must be differentiable for gradient-based inference.\n- Furthermore, the disadvantage of the universal prior as presented in the paper is that restoring an image requires optimization (e.g. gradient descent). In contrast, corruption-specific neural nets typically just need a forward pass to restore the image and are thus easier and faster to use.\n\n# Restoration inference\n- How dependent is the restoration result with respect to the initialization? For example, when starting gradient descent with the degraded image vs. a random image.\n- Roughly, how many iterations and runtime is needed for inference?\n- Did you try different optimizers, such as L-BFGS?', 'This paper proposes to increase the latent space dimensionality  of images, by stacking the latent representation vectors as a tensor. Then convolutional decoder and encoder networks are used to map the original data to latent space and vice versa. The learned latent representations can then be used in a universal framework for multiple tasks such as image inpainting, superresolution and colorization.\n\nThe idea of increasing the dimensionality of the latent space, although not sophisticated, seems to be performing very good. Indeed in some of qualitative experiments, the results are surprising. The authors should clarify that how is the training procedure performed in more details. Are test images included in the training the convolutional networks?']","[-20, 60, 60]","[50, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express significant concerns ('Cons') about the work's fundamental approach and request additional evidence. The overall tone suggests skepticism about the paper's claims. The politeness score is moderately positive (50) as the reviewer uses professional language, acknowledges positive aspects, and offers constructive feedback. They express their concerns politely and provide an opportunity for the authors to address the issues raised. The reviewer also indicates a willingness to reconsider their rating if the authors can provide a 'profound explanation' of the problem."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses agreement with the paper's main idea, praises the good experimental results, and notes that people prefer the proposed method in a user study. However, they also point out some limitations, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, asks questions politely (e.g. 'Did you try...?'), and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer also acknowledges their own potential lack of familiarity with some related work, showing humility. The tone is professional and courteous throughout, without being overly deferential."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that the idea 'seems to be performing very good' and that some results are 'surprising'. The reviewer also acknowledges the effectiveness of the approach, even if it's not sophisticated. However, it's not extremely positive as the reviewer does have some questions and requests for clarification. The politeness score is 50 (somewhat polite) because the language used is professional and respectful. The reviewer acknowledges the paper's strengths and frames their questions as requests for clarification rather than criticisms. However, the tone is mostly neutral and matter-of-fact, rather than overtly polite or complimentary, which is why it's not scored higher.""]"
"['This paper proposed to use dropout to randomly choose only a subset of neural network as a potential way to perform exploration. The dropout happens at the beginning of each episode, and thus leads to a temporally consistent exploration. The paper shows that with small amount of Gaussian multiplicative dropout, the algorithm can achieve the state-of-the-art results on benchmark environments. And it can significantly outperform vanilla PPO for environments with sparse rewards.\n\nThe paper is clearly written. The introduced technique is interesting. I wonder except for the difference of memory consumption, how different it is compared to parameter space exploration. I feel that it is a straightforward extension/generalization of the parameter space exploration. But the stochastic alignment and policy space constraint seem novel and important.\n\nThe motivation of this paper is mostly about learning with sparse reward. I am curious whether the paper has other good side effects. For example, will the dropout cause the policy to be more robust? Furthermore, If I deploy the learning algorithm on a physical robot, will the temporally consistent exploration cause less wear and tear to the actuators when the robot explores. In addition, I would like to see some discussions whether this technique could be applied to off-policy learning as well.\n\nOverall, I like this paper. It is well written. The method seems technically sound and achieves good results. For this reason, I would recommend accepting this paper.', 'The authors propose a new on-policy exploration strategy by using a policy with a hierarchy of stochasticity. The authors use a two-level hierarchical distribution as a policy, where the global variable is used for dropout. This work is interesting since the authors use dropout for policy learning and exploration.  The authors show that parameter noise exploration is a particular case of the proposed policy. The main concern is the gap between the problem formulation and the actual optimization problem in Eq 12. I am very happy to give a higher rating if the authors address the following points. \n\nDetailed Comments \n(1) The authors give the derivation for Eq 10. However, it is not obvious that how to move from line 3 to line 4 at Eq 15.\nMinor:  Since the action is denoted by ""a"",  it will be more clear if the authors use another symbol to denote the parameter of q(z) instead of ""\\alpha"" at Eq 10 and 15.\n\n(2) Due to the use of the likelihood ratio trick, the authors use the mean policy as an approximation at Eq 12. Does such approximation guarantee the policy improvement? Any justification?\n\n(3) Instead of using the mean policy approximation in Eq 12, the authors should consider existing Monte Carlo techniques to reduce the variance of the gradient estimation. For example, [1] could be used to reduce the variance of gradient w.r.t. \\phi. Note that the gradient is biased if the mean policy approximation is used.\n\n(4) Are \\theta and \\phi jointly and simultaneously optimized at Eq 12?  The authors should clarify this point. \n\n(5) Due to the mean policy approximation, does the mean policy depend on \\phi? The authors should clearly explain how to update \\phi when optimizing Eq 12. \n\n(6) If the authors jointly and simultaneously optimize \\theta and \\phi, why a regularization term about q_{\\phi}(z)  is missing in Eq 12 while a regularization term about \\pi_{\\theta|z} does appear in Eq 12? \n\n(7) The authors give the derivations about \\theta such as the gradient and the regularization term about \\theta (see, Eq 18-19). However, the derivations about \\phi are missing.  For example, how to compute the gradient w.r.t. \\phi? Since the mean policy is used, it is not apparent that how to compute the gradient w.r.t. \\phi. \nMinor, 1/2 is missing in the last line of Eq 19.\n\nReference:\n[1] AUEB, Michalis Titsias RC, and Miguel Lázaro-Gredilla. ""Local expectation gradients for black box variational inference."" In Advances in neural information processing systems, pp. 2638-2646. 2015.', 'The authors introduce a  novel  on-policy  temporally  consistent  exploration  strategy, named Neural  AdaptiveDropout Policy Exploration (NADPEx), for deep reinforcement learning agents. The main idea is to sample from a distribution of plausible subnetworks modeling the temporally consistent exploration. For this, the authors use the ideas of the standard dropout for deep networks. Using the proposed  dropout transformation that is differentiable, the authors show that the KL regularizers on policy-space play an important role in stabilizing its learning. The experimental validation is performed on continuous control learning tasks, showing the benefits of the proposed. \n\nThis paper is very well written, although very dense and not easy to follows, as many methods are referenced and assume that the reviewer is highly familiar with the related works. This poses a challenge in evaluating this paper. Nevertheless, this paper clearly explores and offers a novel approach for more efficient on-policy exploration which allows for more stable learning compared to traditional approaches. \n\nEven though the authors answer positively to each of their four questions in the experiments section,  it would like that the authors provide more intuition why these improvements occur and also outline the limitations of their approach. ']","[80, -20, 70]","[70, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, stating it is 'well written', 'interesting', achieves 'good results', and recommends accepting it. They also use positive phrases like 'I like this paper' and 'achieves the state-of-the-art results'. The score is not 100 as the reviewer does raise some questions and suggests areas for further exploration. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their questions and suggestions in a courteous manner (e.g., 'I wonder', 'I am curious', 'I would like to see'). The tone is professional and encouraging without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the work interesting, they express several concerns and request significant clarifications and improvements. The phrase 'The main concern is...' indicates a critical view, and the numerous detailed comments suggest substantial revisions are needed. However, the reviewer also expresses willingness to give a higher rating if the issues are addressed, which prevents the score from being more negative.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout. They begin with positive comments about the work being 'interesting' and express willingness to give a higher rating. The detailed comments are phrased as suggestions or questions rather than harsh criticisms. Phrases like 'The authors should consider...' and 'The authors should clarify...' are polite ways of requesting changes. The reviewer also uses 'please' in their minor comment, which adds to the politeness."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'very well written' and noting that it 'clearly explores and offers a novel approach'. The reviewer acknowledges the paper's complexity but still appreciates its contribution. The score is not higher because the reviewer does suggest some improvements, such as providing more intuition and outlining limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive feedback. The reviewer's tone is professional and courteous, even when suggesting improvements. The use of phrases like 'it would like that the authors provide' instead of more direct commands contributes to the polite tone.""]"
"['The paper presents and discusses a new phenomenon that infrequent words tend to learn degenerate embeddings. A cosine regularization term is proposed to address this issue.\n\nPros\n1. The degenerate embedding problem is novel and interesting.\n2. Some positive empirical results.\n\nCons and questions\n1. The theory in Section 4 suggests that the degeneration problem originates from underfitting; i.e., there\'s not enough data to fit the embeddings of the infrequent words, when epsilon is small. However, the solution in Section 5 is based on a regularization term. This seems contradictory to me because adding regularization to an underfit model would not make it better. In other words, if there\'s not enough data to fit the word embeddings, one should feed more data. It seems that a cosine regularization term could only make the embeddings different from each other, but not better.\n2. Since this is an underfitting problem (as described in Section 4), I\'m wondering what would happen on larger datasets. The claims in the paper could be better substantiated if there are results on larger datasets like WT103 for LM and en-fr for MT. Intuitively, by increasing the amount of total data, the same word gets more data to fit, and thus epsilon gets large enough so that degeneration might not happen.\n3. ""Discussion on whether the condition happens in real practice"" below Theorem 2 seems not correct to me. Even when layer normalization is employed and bias is not zero, the convex hull can still contain the origin as long as the length of the bias vector is less than 1. In fact, this condition seems fairly strong, and surely it will not hold ""almost for sure in practice"".\n4. The cosine regularization term seems expensive, especially when the vocab size is large. Any results in terms of computational costs? Did you employ tricks to speed it up?\n5. What would happen if we only apply the cosine term on infrequent words? An ablation study might make it clear why it improves performance.\n\nUPDATE:\nI think the rebuttal addresses some of my concerns. I am especially glad to see improvement on en-fr, too. Thus I raised my score from 5 to 7.', ""This work proposes a simple regularization term which penalize cosine similarity of word embedding parameters in the loss function. The motivation comes from empirical studies of word embedding parameters in three tasks, translation, word2vec and classification, and showed that the parameters for the translation task are not distributed when compared with other tasks. The problem is hypothesized by the rare word problem especially when parameters are tied for softmax and input embedding, and proposes a cosine similarity regularization. Experiments on English/German show consistent gains over non-regularized loss.\n\nPros:\n\n-  The proposed method is well motivated from empirical studies by visualizing parameters of three tasks, and the analysis on rare words are convincing.\n\n- Good performance in language modeling and translation tasks by incorporating the proposed regularization.\n\nCons:\n\n- The visualization might be slightly miss leading in that the size of classification, e.g., the vocabulary size, is different, e.g., BPE for translation, word for word2vec and categories of MNIST. I'd also like to see visualization for comparable experiments, e.g., language modeling with or without tied parameters.\n\n- Given that BPE is used in translation, the analysis might not hold since rare words would not occur very frequently, and thus, the gain might come from other factors, e.g., tied source/target embedding parameters in Transformer.\n\n- I'd like to see experiments under un-tided parameters with the proposed regularization.\n"", 'The authors propose a new understanding of word embedding in natural language generation tasks like language model and neural machine translation. \nThe paper is clear and original. The experiment results support their argument. \n\nThe problem they raised is quite interesting, however, it is not clear why the representation degeneration problem is important in language generation performance. In Figure 1, the classification is from MNIST, which is much different from words. The authors might want to explain more clearly why the uniformly distributed singular values are helpful in language generation tasks. \n']","[50, 50, 50]","[70, 75, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and interest of the paper's topic, as well as some positive empirical results. However, they also raise several concerns and questions, indicating a balanced view. The initial score was raised from 5 to 7 (out of 10) after the rebuttal, showing overall positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges improvements in the rebuttal. The tone is professional and constructive, without any harsh or rude comments."", ""The sentiment score is 50 (slightly positive) because the review begins by acknowledging the work's contribution and highlighting its pros, such as being well-motivated and showing good performance. However, it also lists some cons, indicating a balanced view rather than overwhelmingly positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions (e.g., 'I'd like to see...') rather than direct criticisms. The reviewer also acknowledges the strengths of the work before presenting areas for improvement, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being 'clear and original' and that the 'experiment results support their argument'. However, they also raise concerns and suggest improvements, which balances out the initial positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'The authors might want to explain' instead of more direct or harsh language. The review maintains a professional and courteous tone while providing feedback.""]"
"['The authors take the control-as-inference viewpoint and learn a state-independent prior (which is typically held fixed). They claim that this leads to better exploration when actions have different importance. They relate this objective to a mutual information constrained RL objective in a limiting case. They then propose a practical algorithm, MIRL and compare their algorithm against DQN and Soft Q-learning (SQL) on 19 Atari games and demonstrate improvements over both.\n\nGenerally I found the idea interesting and at a high level the deficiency of entropy regularization makes sense. However, I had great trouble understanding the reasoning behind their method and did not find the connection to mutual information helpful. Furthermore, I had a number of questions about the experiments. If the authors can clarify their motivation and reasoning and strengthen the experiments, I\'d be happy to raise my score.\n\nIn Sec 3.1, why is it sensible to optimize the prior? Can the authors give intuition for maximizing \\log p(R = 1) wrt to the prior? This is critical for justifying their approach. Currently, the authors provide a connection to MI, but don\'t explain why this matters. Does it justify the method? What insight are we supposed to take away from that? \n\nThe experiments could be strengthened by addressing the following:\n* What was epsilon during training? Why was epsilon = 0.05 in evaluation? This is quite high compared to previous work, and it makes sense that this would degrade MIRLs performance less than DQN and SQL.\n* What is the performance of SQL if we use \\rho as the action selector in \\epsilon-greedy. This would help understand if the performance gains are due to the impact on the policy or due to the changes in the behavior policy.\n* Plotting beta over time\n* Comparing the action distributions for SQL and MIRL to understand the impact of the penalty. In general, a deeper analysis of the impact on the policy is important. \n* Are their environments we would expect MIRL to outperform SQL based on your theoretical understanding? Does it?\n* How many seeds were run per game?\n* How and why were the 19 games selected from the full set?\n\nComments:\n\nThe abstract claims state-of-the-art performance, however, what is actually shown is that MIRL outperforms DQN and SQL.\n\nWith a fixed prior, the action prior can be absorbed into the reward (e.g., Levine 2018), so it is of no loss of generality to assume a uniform prior.\n\nCould state that the stationary distribution is assumed to exist and be unique.\n\nIn Sec 3.1, why is the prior state independent?\n\nIn Sec 3.1, p(R = 1|\\tau) is defined to be proportional to exp(\\beta \\sum_t r_t). Is this well-specified? How would we compute the normalizing constant since p(R = 0 | \\tau) is not defined?\n\nThroughout, I suggest that the authors not use the phrases ""closed form"" and ""analytic"" for expressions that are in terms of intractable quantities. \n\nIt should be noted that Sec 3.2 Optimal policy for a fixed prior \\rho follows from Levine 2018 and others by transforming the fixed prior into a reward bonus.\n\nIn Sec 3.2, the last statement does not appear to be necessary for the next subsection. Remove or clarify?\n\nI believe that the connection to MI can be simplified. Plugging in the optimal \\rho into Eq 3, we can see that Eq 3 simplifies to \\max_\\pi E_q[ \\sum_t \\gamma^t r_t] - (1 - gamma)/\\beta MI_p(s, a) where p(s, a) = d^\\pi(s) * \\pi(a | s) and d^\\pi is the discounted state visitation distribution. Thus Eq 3 can be thought of as a lower bound on the MI regularized objective.\n\nIn Sec 4, the authors state the main difference between their soft operator and the typical soft operator. What other differences are there? Is that the only one?\n\nSec 5 references the wrong Haarnoja reference in the first paragraph.\n\nIn Sec 5, alpha_beta = 3 * 10^5. Is that correct?\n\n=====\n11/26\nAt this time, the authors have not responded to the reviews. I have read the other reviews and comments, and I\'m not inclined to change my score.\n\n====\n12/7\nThe authors have addressed most of my concerns, so I have raised my score. I\'m still concerned that the exploration epsilon is quite different than existing work (e.g., https://github.com/google/dopamine/tree/master/baselines).', 'This work introduces SoftQ with a learned, state-independent prior. One derivation of this objective follows standard approaches from an RL as inference to derive the ELBO objective.\n\nA more novel view derived here connects this objective with the rate-distortion problem to view the objective as an RL objective subject to a constraint on the mutual information between the state and action distribution.\n\nThey also outline a practical off-policy algorithm for optimizing this objective and compare it with Soft Q Learning (essentially, the same method but with a flat-prior) and DQN. They find that this results in small gains across most Atari games, with big gains for a few games.\n\nThis work is well-explained except in one-aspect. The rate-distortion view of the objective is not well-justified. In particular, why is it desirable in the context of RL to constrain this mutual information?\n\nEmpirical Deep RL performance is notoriously difficult to test (e.g. Henderson et al., 2017). The hyper-parameters are simply stated here, but no justification is given for how they are chosen / whether the baselines perform better under different choices. Given the gains compared with SoftQ are not that large, this information is important for understanding how much weight to place on the empirical result.\n\nThe fact that the prior does not converge in some environments (e.g. Seaquest) is noted, but it seems this bears further discussion.\n\nOverall it appears this work provides:\n- An algorithm for Soft Q learning with a learned independent prior\n- Moderate evidence for gains compared with a flat prior on Atari.\n- A connection with this approach and regularization by constraining the mutual information between state and action distributions.\n\nIt could be made a stronger piece of work by showing improvements in domains others than Atari, justifying the choice of regularization more. It would also benefit from positioning this work more clearly in relation to related approaches such as MPO (non-parametric state-dependent prior) and DistRL (state-dependent prior but shared across all games).', '** Summary: **\n\nThe authors use the reformulation of RL as inference and propose to learn the prior policy. The novelty lies in learning a state-independent prior (instead of a state-dependent one) that can help exploration in the presence of universally unnecessary actions. They derive an equivalence to regularizing the mutual information between states and actions.\n\n** Quality: **\nThe paper is mathematically detailed and correct.\n\n** Clarity: **\nThe paper is sufficiently easy to follow and explains all the necessary background.\n\n** Originality & Significance: **\nThe paper proposes a novel idea: Using a learned state-independent prior as opposed to using a learned state-dependent prior. While not a big change in terms of mathematical theory, this could lead to positive and interesting results empirically for exploration. Indeed they show promising results on Atari games: It is easy to see how Atari games could benefit as they have up to 18 different actions, many of which are redundant. \n\nMy two main points where I think the paper could improve are:\n- More experimental results, in particular, how strong are the negative effects of MIRL if we have actions that are important, but have a lower probability in the stationary action distribution?\n- A related work section comparing their approach to the many recent similar papers in Maximum Entropy RL']","[-20, 20, 70]","[60, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer found the idea interesting, they had 'great trouble understanding the reasoning' and raised several concerns about the experiments. They state they would be 'happy to raise my score' if issues are addressed, indicating current dissatisfaction. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to reconsider their assessment. They use phrases like 'I found the idea interesting', 'If the authors can clarify...', and 'I'd be happy to raise my score', which maintain a polite and professional tone despite the criticisms."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work's contributions and potential, but also points out several areas for improvement. The review begins by summarizing the work's main points and contributions, which is generally positive. However, it also highlights some significant limitations and areas where the work could be strengthened, balancing out the positive aspects.\n\nThe politeness score is moderately high (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe both the strengths and weaknesses of the work, avoiding harsh criticism. Phrases like 'This work is well-explained' and 'It could be made a stronger piece of work by...' demonstrate a constructive approach to feedback. The reviewer also acknowledges the difficulty of empirical Deep RL performance testing, showing understanding of the challenges involved.\n\nOverall, the review is balanced, offering both praise and constructive criticism in a polite and professional manner, which is reflected in the moderate positive sentiment and high politeness scores."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'mathematically detailed and correct', 'sufficiently easy to follow', and proposing a 'novel idea' with 'promising results'. The reviewer also mentions that the paper 'could lead to positive and interesting results empirically for exploration'. However, it's not a perfect score as they suggest two areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths before offering constructive suggestions for improvement. The tone is consistently courteous, using phrases like 'could improve' rather than more critical language. The reviewer also balances critique with praise, which contributes to the overall polite tone.""]"
"['The authors introduce an algorithm that addresses the problem of online policy adaptation for model-based RL. The main novelty of the proposed approach is that it defines an effective algorithm that can easily and quickly adapt to the changing context/environments. It borrows the ideas from model-free RL (MAML) to define the gradient/recursive updates of their approach, and it incorporates it efficiently into their model-based RL framework. The paper is well written and the experimental results on synthetic and real world data show that the algorithm can quickly adapt its policy and achieve good results in the tasks, when compared to related approaches. \n\nWhile applying the gradient based adaptation to the model-free RL is trivial and has  previously been proposed, in this work the authors do so by also focusing on the ""local"" context (M steps within a K-long horizon, allowing the method to  recover quickly if learning from contaminated data, and/or its global policy cannot generalize well to the local contexts. Although this extension is trivial it seems that it has not been applied and measured in terms of the adaptation ""speed"" in previous works. Theoretically, I see more value in their second approach where they investigate the application of fast parameter updates within model-based RL, showing that it does improve over the MAML-RL and non-adaptive model-based RL approaches. This is expected but  to my knowledge has not been investigated to this extent before. \n\nWhat I find is lacking in this paper is insight into how sensitive the algorithm is in terms of the K/M ratio, and also how it affects the adaptation speed vs performance (tables 3-5 show an analysis but those are for different tasks); no theoretical analysis was performed to provide deeper understanding of it. The model does solve a practical problem (reducing the learning time and having more robust model), however, it would add more value to the current state of the art in RL if the authors proposed a method for optimal selection of the recovery points and also window ratio R/L depending on the target task. This would make a significant theoretical contribution and the method could be easily applicable to a variety of tasks. where the gains in the adaptation speed are important.', 'This work addresses the problem of online adapting dynamics models in the context of model-based RL. Learning globally accurate dynamics model is impossible if we consider that environments are dynamic and we can\'t observe every possible environment state at initial training time. Thus learning dynamics models that can be adapted online fast, to deal with unexpected und never seen before events is an important research problem.\n\nThis paper proposes to use meta-learning to train an update policy that can update the dynamics model at test time in a sample efficient manner. Two methods are proposed\n- GrBAL: this method uses MAML for meta-learning\n- ReBAL: this method trains a recurrent network during meta-training such that it can update the dynamics effectively at test time when the dynamics  change\n\nBoth methods are evaluated on several simulation environments, which show that GrBAL outperforms ReBAL (on average). GrBAL is then evaluated on a real system. \n\nThe strengths of this paper are:\n\n- this work addresses an important problem and is well motivated\n- experiments on both simulated and on a real system are performed\n\nThe weaknesses:\n\n- the related work section is biased towards the ML community. There is a ton of work on adapting (inverse) dynamics models in the robotics community. This line of work is almost entirely ignored in this paper. Furthermore some important recent references for model-based RL are not provided in the related work section (PETS [3] and MPPI [2]), although MPPI is the controller that is used in this work as a framework for model-based RL. Additionally, existing work on model-based RL with meta-learning [1] has not been cited. This is unacceptable. \n- There is no significant technical contribution - the ""contribution"" is that existing meta-learning methods have been applied to the model-based RL setting. Even if no-one has had that idea before - it would be a minor contribution, but given that there is prior work on meta-learning in the context of model-based RL, this idea itself is not novel anymore.\n- Two methods are provided, without much analysis. Often authors refer to ""our approach"" - but it\'s actually not clear what they mean by our approach. The authors can\'t claim ""model-based meta RL"" as their approach. \n- While I commend the authors for performing both simulation and real-world experiments, I find the that experiments lack a principled evaluation. More details below.\n\nFeedback on experiments:\n\nSection 6.2 (sample efficiency)\n\nYou compare apples to oranges here. I have no idea whether your improvements in terms of sample-efficiency are due to using a model-based RL approach or because your deploying meta-learning. It is well known that model-based RL is more sample efficient, but often cannot achieve the same asymptotic performance as model-free RL. Since MPPI is your choice of model-based RL framework, you would have to include an evaluation that shows results on MPPI with model bootstrapping (as presented in [2]) to give us an idea of how much more sample-efficient your approach is.\n\nSection 6.3 (fast adaptation and generalization)\n\nWhile in theory one can choose the meta-learning approach independently from the choice of model-based controller, in practice the choice of the MPC method is very important. MPPI can handle model inaccuracies very well - almost to the point where sometimes adaptation is not necessary. You CANNOT evaluate MPPI with online adaptation to another MPC approach with another model-learning approach. This does not give me any information of how your meta-learning improves model-adaptation. In essence these comparisons are meaningless. To make your results more meaningful you need to use the same controller setup (let\'s say MPPI) and then compare the following:\n1. MPPI with your meta-trained online adaptation\n2. MPPI results with a fixed learned dynamics model - this shows us whether online adaptation helps\n3. results of MPPI with the initial dynamics model (trained in the meta-training phase) -without online adaptation. This will tell us whether the meta-training phase provides a dynamics model that generalizes better (even without online adaptation)\n4. MPPI with model bootstrapping (as presented in [2]). This will show whether your meta-trained online adaptation actually outperforms simple online model bootstrapping in terms of sample-efficiency\n\nThe key here is that you need to use the same model-based control setup (whether its MPPI or some other method). Otherwise you cannot detangle the effect of controller choice from your meta-learned online adaptation.\n\n6.4 Real-world: same comments as above, comparisons are not meaningful\n\n[1] Meta Reinforcement Learning with Latent Variable Gaussian Processes, UAI 2018\n[2] MPPI with model-bootstrapping: Information Theoretic MPC for Model-Based Reinforcement Learning , ICRA 2017\n[3] Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models, NIPS 2018', 'The paper proposes using meta-learning and fast, online adaptation of models to overcome the mismatch between simulation and the real world, as well as unexpected changes and dynamics. This paper proposes two model-based meta-learning reinforcement algorithms, one based on MAML and the other based on recurrence, and experimentally shows how they are more sample efficient and faster at adapting to test scenarios than prior approaches, including prior model-free meta-learning approaches.\n\nI do have an issue with the way this paper labels prior work as model-free meta-learning algorithms, since for example, MAML is a general algorithm that can be applied to model-free and model-based algorithms alike. It would be more accurate in my opinion to label the contributions of this paper as model-based instantiations of prior existing algorithms, rather than new algorithms outright.\n\nI’m a bit confused with equation 3, as the expectation is over a single environment, and the trajectory of data is also sampled from a single environment. But in the writing, the paper describes the setting as a potentially different environment at every timestep. Equation 3 seems to assume that the  subsequence of data comes from a single environment, which contradicts what you say in the text. As described, equation 3 is then not really much different from previous episodic or task based formulations.\n\nThe results themselves are not unexpected, as there has already been prior work that this paper also mentions showing that model-based RL algorithms are more sample efficient than model-free.\n\nSection 6.1, I like this comparison and showing how the errors are getting better.\n\nFor section 6.2, judging from the plots, it doesn’t seem you are doing any meta-learning in this experiment, so then are you just basically running a model-based RL algorithm? I’m very confused what you are trying to show. Are you trying to show the benefit of model-based vs model-free? Prior work has already done that. Are you trying to show that even just using a meta-learning algorithm in an online setting results in good online performance? Then you should be comparing your algorithm to just a model-based online RL algorithm. You also mention that the asymptotic performance falls behind, is this because your model capacity is low, or maybe your MPC method is insufficient? If so, then wouldn’t it be more compelling to, like prior work, combine this with a model-free algorithm and get the best of both worlds?\n\nSection 6.3 results look good.\n\nSection 6.4, I really like the fact you have results on a real robot.\n\nOverall I think the paper does successfully show the sample complexity benefits and fast adaptation of model-based meta-RL methods. The inclusion of a real world robot experiment is a plus. However the result is not particularly surprising or insightful, as prior work has already shown the massive sample complexity improvement of model-based RL methods.\n\nUPDATE (Dec 4, 2018):\n\nI have read the author response and they have addressed the specific concerns I have brought up. I am overall positive about this paper and the new changes and additions so I will slightly increase my score, though I am still concerned about the significance of the results themselves.\n']","[60, -50, 50]","[70, 20, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, praising its novelty, good writing, and effective experimental results. However, they also point out some limitations, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' contributions and providing constructive feedback. They use phrases like 'well written' and 'to my knowledge', which indicate politeness. The reviewer balances praise with suggestions for improvement in a professional manner, avoiding harsh criticism."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper (addressing an important problem, experiments on simulated and real systems), they also point out significant weaknesses. These include a biased related work section, lack of significant technical contribution, and issues with the experimental evaluation. The overall tone suggests the reviewer is not satisfied with the paper's contribution and methodology.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I commend the authors' and providing constructive feedback. However, there are some instances of more direct criticism, such as 'This is unacceptable' when discussing missing citations. The reviewer also uses strong language like 'meaningless' when describing some comparisons. While not overtly rude, these comments lower the politeness score from what could have been a higher rating."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and successful demonstrations, particularly praising the real-world robot experiment. However, they also express some concerns and confusion about certain aspects of the paper. The overall tone is constructive but not overwhelmingly positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as personal opinions or confusion (e.g., 'I'm a bit confused', 'I do have an issue'), and balances critiques with positive comments. The reviewer also acknowledges the authors' response positively in the update, showing a willingness to reconsider their initial assessment.""]"
"['The idea is nice. It is well aligned with tools that are needed to understand neural networks. However, the experiments feel like they are missing motivation as to why this method is being used. The paper does not provide very significant evidence that this method is useful. The negation example is nice but this doesn\'t seem to display the potential power of the method to understand a neural network.\n\nMore motivation for experimental section is needed. If the authors don\'t discuss a motivation then how will a reader know how to apply the tool? It seems there is no conclusion to take away from the experiments in section 5 (convolutions). \n\nThe authors should rethink the structure of the experimental section from the standpoint of convincing someone to use this method. In section 4.1 the authors have a good discussion on what is wrong with other methods in order to motivate their approach but then they don\'t deliver significant evidence in the later part of the section.\n\nThe paper needs more discussion and experiments to explain how and why to use this approach. \n\nWhile the authors say ""attributing a deep network’s prediction to its input is well-studied"" they don\'t compare directly against these methods. \n\nThere are many typos and grammar errors\n\nWhile I think the paper could be much more impactful if the experimental section was greatly reworked; I believe the first 5 pages of the paper are a very good contribution and it should be accepted.\n', 'The authors propose a notion of conductance to attribute the deep neural network’s prediction to its hidden units. The conductance is the flow of attribution via the hidden unit(s) in consideration. The paper proposes using conductance to not only evaluate importance of hidden unit to the prediction for a specific input but also over a set of inputs. The strongest part of the analysis of conductance is that conductance naturally couples  the path at the base features with that of the hidden layer.\n\nThe authors position their work well within the existing approaches in the community and generalizes the efficient use of measuring hidden activation wrt to specific input or set of inputs.\n\nThe analysis makes efficient use of mean value theorem in the context of  parametrization of the loss function.\n\nConductance seems to satisfy the completeness of hidden features. Further, it also satisfies the layer-wise conservation principle with the outputs completely redistributed  to the inputs.\n\nIt would be good to see more analysis on the axioms 1 through to 4 for the sake of completeness in the light of partial axiomatization of conductance.\n\nThe authors provide empirical evaluation of conductance over a variety of tasks. It would be good to see some more insight in order to relate to interpretability of the importance of neurons, although there has been no claims made on it as its hard to measure importance without interpretability.\n', 'This paper presents a new method to measure the importance of hidden neurons in deep neural networks. The method integrates notions of activation value, input influence to a neuron and neuron influence to the network\'s output. They provide results confirming that this measure is able to identify neurons that are important for specific tasks.\n\nQuality\n\nThe experiments are well designed to verify their hypothesis, although there could be more to make sure those results are not particular to the few selected problems. Nevertheless, the results are consistent across those experiments.\n\nClarity\n\nThe text is well written in general, but the structure could be improved. The introduction contains too much related work, which should be divided in another section. Section 2 contains mostly high level explanations of the work, which should be integrated in the introduction, and thus before the related work section, to improve readability. See minor comments for more specific suggestions.\n\nIt is difficult to understand the goal of Section 4.2. Section 2 states that section 4.2 proves that a ""path method"" must be used in order to satisfy the axioms, but why such axioms are important is not stressed enough. Also, it is not clear why those are called axioms since they are not use to build anything else. It seems to me that those are rather ""desirable properties"" than axioms.\n\nOriginality\n\nA important number of related works are cited and compared with the current work. Although the proposed measure is close to what is proposed by Datta et al., this paper makes the distinction clear and benchmarks its results properly against it.\n\nSignificance\n\nThere is an increasing need to interpretability of deep neural networks as they get more and more applied to real-world problems. Measures as the one proposed in this paper are a very important building block towards this.\n\nConclusion\n\nFor its original importance measure and the proper experiment benchmarks, I believe this paper should be accepted. There is however many minor issues that should be fixed for the camera-ready version. Although the recommended length is 8 pages, the strict limit is 10, so I would recommended to use a bit of the remaining extra space to conclude the paper properly with a discussion on the results and their consequences, as well as a conclusion to wrap up the paper.\n\n***\n\nMinor Comments\n\nIntroduction:\n- The term flow is never defined precisely, we need to infer it based on the definition of conductance and attribution.\n- First paragraph would be more clear with simple word explanation rather than maths. Also, second sentence is not a complete sentence\n- Work on image indicators of importance could be compared better with current work. Indicators can be seen as a measure of importance.\n- This sentence is not clear: ""[...]; the nature of correlations in the two models may differ"".\n\nSection 2:\n- Last paragraph of section 2 can be true for any well-performing importance measure. The statements should be put in perspective with others.\n\nSection 3:\n- Section 3 should be introduced by explaining the goal of the section otherwise it breaks the flow of reading.\n- The role of the baseline x\' should be better explained when it is presented (first paragraph of section 3).\n- The interchangeable use of the term ""conductance of neuron j"" for equations 2 and 3 is confusing. Different terms should be use, even if the context makes it possible to infer which one is being referred to.\n- Remark 1 seems trivial, but the selection of baseline x\' seems less trivial. Some explanations should be devoted to it.\n- Second paragraph of remark 1 is not clear. Why couldn\'t we take another layer\'s neuron as the neuron of interest, bounding the conductance measure on one layer as the input and the output of the model? If we make the input to be a neuron y rather than the true input x, we could take another neuron z in a subsequent layer to be the neuron of interest, resulting in conductance measure Cond^z_i(y).\n\nSection 4:\n- List of importance measure at beginning of Section 4 should probably have citations.\n- Backward reference to section 3 seems to be a mistake, should it be subsection 4.2?\n- Each of the justifications to get around the issue of distinguishing strange model behavior from bad feature importance technique should be explained briefly in paragraph before section 4.1.\n\nSubsection 4.1:\n- I do not understand the problem explained in fourth paragraph of section 4.1. g(f(1 - epsilon)) = 0, why would it be 1- epsilon?\n- Problem explained in fifth Paragraph of section is not clear unless what the influence of the unit is clearly stated. Is it simply dg/df? \n- A short explanation of what is tested in section 6 should be given at last paragraph of section 4.1. Although the results are favorable to the conductance metric, it is not clear how they precisely confirm the problem of incorrect signs presented in the caricature examples.\n\nSubsection 4.2:\n- As said in the my main comments, I am not convinced by the use of the term Axiom. They are not use as building blocks, and are rather used as desirable properties for which the authors prove that only ""path methods"" can satisfy.\n- Footnote 2 on page 5 it difficult to read.\n- Although the proof does not seem to use the axioms as a building block, which is fortunate since it would make it a circular argument otherwise, the text suggests so: ""Given these three axioms, we can show that:"".\n- The importance of section 4.2 should be clarified. More emphasis on the importance of the axioms (desirable properties) should be made.\n\nSection 5:\n- Choices for experiments should be explained. Why choosing layers mixed** rather than others? Why choosing filters?\n- Figures 1-4 are difficult to interpreted on a printed version. Since this is qualitative, I suggest to change the saturation of the images to make them easier to interpret. The absolute values are not important for a qualitative interpretation\n- Figure 4 could be more interesting if compared with other classes, like other animal faces. Anyhow, I understand that those were chosen based on the subset of classes used for the experiments.\n- Space should be added between figures to better divide the captions\n\nSection 6:\n- The difference between experiments of Figure 5 and 6 should be made more clear.\n\nSection 7-8:\n- Where are they? No discussion? No conclusion?']","[-20, 70, 60]","[50, 60, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea is 'nice' and 'well aligned with tools that are needed', they express significant concerns about the lack of motivation, insufficient evidence, and the need for major revisions to the experimental section. The overall tone suggests the paper has potential but falls short in its current form. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They balance negative feedback with positive comments and suggest improvements rather than outright dismissing the work. The reviewer even recommends acceptance based on the paper's initial sections, which demonstrates a fair and considerate approach despite the criticisms."", ""The sentiment score is 70 (positive) because the review starts with a neutral description of the authors' work, followed by several positive comments. The reviewer notes the 'strongest part' of the analysis, praises the authors for positioning their work well, and commends their efficient use of mathematical concepts. The reviewer also acknowledges that the proposed method satisfies important principles. The score is not higher because the reviewer suggests some additional analysis and insights that could improve the paper. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' contributions and framing suggestions as constructive feedback (e.g., 'It would be good to see...'). The reviewer maintains a professional tone without using overly formal or deferential language, hence the moderately positive score."", ""The sentiment score is 60 (positive) because the reviewer generally expresses approval of the paper, recommending acceptance and praising its originality, significance, and well-designed experiments. However, they also point out several areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They balance positive feedback with areas for improvement, and use phrases like 'I believe' and 'I would recommend' which maintain a courteous tone. The reviewer also acknowledges the paper's strengths while providing detailed, helpful feedback for improvement, which is a polite approach to peer review.""]"
"['This paper presents a method for distilling multiple teacher networks into a student, by linearly combining feature representations from all networks at multiple intermediate layers, and gradually forcing the student to ""take over"" the learned combination.  Networks to be used as teachers are first pretrained on various initial tasks.  A student network is then trained on a target task (possibly different from any teacher task), by combining corresponding hidden layers from each teacher using learned linear remappings and weighted combinations.  Learning this combination allows the system to find appropriate teachers for the target task; eventually, a penalty on the combination weights forces all weight onto the student network, resulting in the distillation.\n\nApplications to both reinforcement learning (atari game) and supervised image classification (cifar, svhn) are evaluated.  The reinforcement learning application is particularly fitting, since combining tasks together is less straightforward in this domain.\n\nI wonder whether any experiments were performed where the layers correspondence between teacher models was less clear --- say, using teachers with different architectures.  Figure 1(a) (different teacher archs) as well as the text (""candidate set"" on p.4) indicate this is possible, but experiment details describe combinations of same-architecture teachers only.\n\nIn addition, I would have liked to see some further exploration of the KL term and use of ""theta_old"".  This seems potentially important, and also has ties to self-ensembling through teachers with exponential weight averaging.  Could an average network also be used here?  And how important is this term in linking student to teachers as the weights change?\n\nOverall I find this a very interesting approach.  Rather than training a large joint model on multiple tasks simultaneously as a transfer initialization, this approach uses models already fully trained for different tasks.  This results in a potentially advantageous trade-off:  One no longer needs to carefully calibrate the different tasks and common task components in a joint model, but at the cost of requiring inference through multiple teachers when training the student.\n', 'This paper proposes to feed the representations of various external ""teacher"" neural networks of a particular example as inputs to various layers of a student network. \nThe idea is quite intriguing and performs very well empirically, and the paper is also well written.  While I view the performance experiments as extremely thorough, I believe the paper could possibly use some additional ablation-style experiments just to verify the method actually operates as one intuitively thinks it should.   \n\nOther Comments:\n\n- Did you verify that in Table 3, the p_w values for the teachers trained on the more-relevant C10/C100 dataset are higher than the p_w value for the teacher trained on the SVHN data?  It would be interesting to see the plots of these p_w over the course of training (similar to Fig 1c) to verify this method actually operates as one intuitively believes it should.\n\n- Integrating the teacher-network representations into various hidden layers of the student network might also be considered some form of neural architecture search (NAS)  (by including parts of the teacher network into the student architecture). \nSee for example the DARTS paper: https://arxiv.org/abs/1806.09055\nwhich similarly employs mixtures of potential connections.  \nUnder this NAS perspective, the dependence loss subsequently distills the optimal architecture network back into the student network architecture.\n\nHave you verified that this method is not just doing NAS, by for example, providing a small student network with a few teacher networks that haven\'t been trained at all? (i.e. should not permit any knowledge flow)\n\n- Have the authors considered training the teacher networks jointly with the student? This could be viewed as teachers learning how to improve their knowledge flow (although might require large amounts of memory depending on the size of the teacher networks).\n\n- Suppose we have an L-layer student network and T M-layer teacher networks.\nDoes this imply we have to consider O(L*M*T) additional weight matrices Q?\nCan you comment on the memory requirements?\n\n- The teacher-student setup should be made more clear in Tables 1 and 2 captions (took me some time to comprehend).\n\n- The second and third paragraphs are redundant given the Related Work section that appears later on. I would like to see these redundancies minimized and the freed up  space used to include more results from the Appendix in the main text. \n', ""This paper proposes a new set of heuristics for learning a NN for generalising a set of NNs trained for more specific tasks. This particular recipe might be reasonable, but the semi-formal flavour is distracting. The issue of model selection (clearly the main issue here) is not addressed. A quite severe issue with this report is that the authors don't report relevant learning results from before (+-) 2009, and empirical comparisons are only given w.r.t. other recent heuristics. This makes it for me not possible to advice publication as is.""]","[70, 70, -60]","[80, 80, -20]","[""The sentiment score is 70 (positive) because the reviewer expresses interest in the approach, calling it 'very interesting' and highlighting its potential advantages. They also provide constructive feedback and suggestions for improvement, indicating an overall positive view of the paper. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'I wonder whether...', 'I would have liked to see...'), and balances critique with praise. The reviewer also acknowledges the paper's strengths and potential contributions to the field, demonstrating a courteous and professional tone."", ""The sentiment score is 70 (positive) because the reviewer describes the paper's idea as 'quite intriguing' and 'performs very well empirically'. They also mention the paper is 'well written' and the experiments are 'extremely thorough'. However, it's not 100 as they suggest additional experiments could be beneficial. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, phrasing suggestions as questions or considerations rather than demands. They acknowledge the paper's strengths before offering constructive feedback. The tone is professional and collaborative, avoiding any harsh criticism or commanding language."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several issues with the paper, including the 'distracting' semi-formal flavor, lack of addressing model selection, and absence of relevant learning results from before 2009. The reviewer concludes that they cannot advise publication as is, which is a strong negative sentiment. However, it's not entirely negative as they do mention that the proposed heuristics 'might be reasonable'. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical without much attempt to soften the criticism. Phrases like 'quite severe issue' and the blunt statement about not advising publication come across as somewhat impolite in academic discourse. However, the reviewer does maintain a professional tone overall, preventing the score from being lower.""]"
"['Prons: \nThis paper provides an optimistic mirror descent algorithm to solving minmax optimization problem. Its global convergence is guaranteed under the coherence property. The experimental results are promising.\n\nCons: \n1.\tThe coherence property is still a strong assumption. The sufficient conditions provided in Corollary 3.2 and 3.3 to guarantee coherence property are too specific to cover existing GAN models.         \n\n2.\tThe current theoretical contribution seems incrementally. From the perspective of operator theory, the coherence property is highly related to the pseudo-monotone property. Extragradient method to solve the pseudo-monotone VIP has already existed in the literature [1]. The proposed OMD can be simply regarded a stochastic extension of [1] and simultaneously generalize the European distance in [1] to Bregman distance. \n\n3.\tThe integrating of Adam and OMD in the experiments is very interesting. To match the experiments, we highly recommend the authors to show the convergence of OMD + Adam with or without coherence condition, rather than requiring a diminishing learning rate.\n\n[1] Noor, Muhammad Aslam, et al. ""Extragradient methods for solving nonconvex variational inequalities."" Journal of Computational and Applied Mathematics 235.9 (2011): 3104-3108.\n', 'This work provides the converge proof of the last iterates of two stochastic methods (almost surely) that the author called  mirror descent and optimistic mirror descent under an assumption weaker than monotonicity called coherence. \nRoughly, the definition of coherence is the equivalence between being a  saddle point and the solution of the Minty variational inequality. \n\nOverall, I think that this paper try to tackle an interesting problem which is to prove convergence of saddle point algorithms under weaker assumption than monotonicity of the operator.\n\nHowever, I have some concerns: \n\n- I think that the properties of coherent saddle point could be more investigated. For instance is the set of coherent saddle point connected ? It would be very relevant for GANs. You claim that ""neither strict, nor null coherence imply a unique solution to (SP),"" but I do not see any proof of that statement (both provided examples have a unique SP). I agree that you can set $g$ to $0$ in some directions to get an affine space a of saddle points but is there examples where the set of solution is not an affine space (intersected with the constraints) ? \n- First of all the results are only asymptotic. (I agree that it can be mitigated saying that there is (almost) no results on non-monotone VI and it is a first step to try to handle non-convexity of the objective functions.)\n- One big pro of this work might have been new proof techniques to handle non-monotonicity in variational inequalities but the coherence assumption looks like to be the weakest condition to use the standard proof technique of convergence of the (MD) and (OMD). Nevertheless, this work is still interesting since it handles in a subtle way stochasticity (I did not have time to check Theorem 2.18 [Hall & Heyde 1980], I would be good to repeat it in the appendix for self-completeness)\n- This work could be easily extended to non zero-sum games which is crucial in practice since most of the state of the art GANs (such as WGAN with gradient penalty or non saturating GAN) are non zero-sum games. \n- Are you sure of the use of the denomination Optimistic mirror descent ? What you are presenting is the extragradient method. These two methods are slightly different, If you look at (5) in (Daskalaki et al., 2018) you\'ll notice that the updates are slightly different from you (OMD), particularly (OMD) require two gradient computations per iteration whereas (5) in (Daskalaki et al., 2018) requires only one. (it just requires to memorize the previous gradient)\n\nMinor comment: \n- For saddle point (and more generally variational inequalities) Mirror descent is no longer a descent algorithm. The name used by the literature is mirror-prox method (see Juditsky\'s paper) \n- in (C.1) U_n is not defined anywhere but I guess it is $\\hat g_n - g(X_n)$.\n- Some cited paper are published paper but cited as arXiv paper. \n- Lemma D.1 could be extended to the case (\\sigma \\neq 0) but the additional noise term might be hard to handle to get a result similar as Thm 4.1\nfor $\\sigma \\neq 0$.', 'This paper is trying to find a saddle-point of a Lagrangian using mirror descent. Mirror descent based methods use Bregman divergence to encode the convexity and smoothness of objective function beyond the euclidean structure. The main contribution of this paper is adding an extra gradient step to the standard MD, i.e., step 5 in Algorithm 2 as well as stochastic versions. Numerical experiments support their results.']","[20, -20, 50]","[50, 60, 0]","[""The sentiment score is slightly positive (20) because the review starts with positive aspects ('optimistic mirror descent algorithm', 'global convergence is guaranteed', 'experimental results are promising') but then lists several significant cons. The overall tone suggests cautious approval with substantial room for improvement. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, offers constructive criticism, and makes recommendations rather than demands. The use of phrases like 'highly recommend' and the absence of harsh or dismissive language contribute to the polite tone. However, it doesn't reach the highest levels of politeness as it maintains a direct, matter-of-fact style typical of academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper tackles an interesting problem, they express several concerns and criticisms. The reviewer states 'Overall, I think that this paper try to tackle an interesting problem,' but follows with 'However, I have some concerns:' and lists multiple issues. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, even when expressing concerns. They use phrases like 'I think that,' 'I agree that,' and 'It would be good to,' which maintain a polite tone. The reviewer also balances criticism with positive remarks, such as 'this work is still interesting.' The language is professional and constructive, avoiding harsh or rude expressions."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper's contribution and approach in a neutral to positive manner, mentioning the main contribution and noting that numerical experiments support the results. There's no explicit criticism, but also no strong praise, hence a moderately positive score. The politeness score is 0 (neutral) because the language used is purely descriptive and professional, without any particularly polite or impolite phrases. The reviewer simply states facts about the paper's content without personal comments or courtesies, maintaining a neutral, objective tone throughout.""]"
"['... I would have liked to see some more insights.\n\nThe authors present a method for distilling knowledge from individual models to train a multilingual model. The motivation stems from the fact that while most s-o-t-a multilingual models are compact (as compared to k individual models) they fall short of the performance of the individual models. The authors demonstrate that using knowledge distillation, the performance of the multilingual model can actually be better than the individual models. \n\nPlease find below my comments and questions.\n\n1) The authors have done a commendable job of validating their hypothesis on multiple datasets. Solid experimentation is definitely the main strength of this paper.\n\n2) However, this strength also makes way for a weakness. The entire experimental section is just filled with tables and numbers. The same message is repeated across these multiple tables (multi+distill > single > multi). Beyond this message there are no other insights. For example, \n\n- How does the performance depend on the divergence between source and target language?\n- Why is there more important on some languages and less on others ?\n- Why are the improvements on the TED dataset so much higher as compared to the other 2 datasets.\n- What happens when the target language is something other than English? All the experiments report results from X-->English, why not in the other direction? The model then is not really ""completely"" multilingual. It is multi-source-->single target. \n- Can you comment on the total training time ?\n- What happens when you do not stop the distillation even when the accuracy of the student crosses that of the teachers ? What do you mean by accuracy here? Only later when you mention that \\threshold = 1 BLEU it became clear that accuracy means BLEU in this context ?\n\n3) Is it all worth it? One disappointing factor is that end of all this effort where you train K individual models and one monolithic model with distillation, the performance gain for most language pairs is really marginal (except on the TED dataset). I wonder if the same improvements could have been obtained by even more carefully fine tuning the baseline models itself.\n\n4) On a positive note, I like the back-distillation idea and the experiments on top-K distillation\n\n+++++++++++++++++++\nI have updated my rating after reading author\'s responses\n\n', ""Summary: Train a multilingual NMT system using the technique of Johnson et al (2017), but augment the standard cross-entropy loss with a distillation component based on individual (single-language-pair) teacher models. Periodically compare the validation BLEU score of the multilingual model with that of each individual model, and turn off distillation for language pairs where the multilingual model is better. On three different corpora (IWSLT, WMT, TED) with into-English translation from numbers of source languages ranging from 6 (WMT) to 44 (TED), this technique outperforms standard distillation for every language pair, and outperforms the individual models for most language pairs. Supplementary experiments justify the strategy of selectively turning off distillation, and quantify the effect using only the top 8 vocabulary items in distillation.\n\nThe main idea makes sense, and the results are very convincing, especially since it appears that hyper-parameters were not tuned extensively (eg, weight of 0.5 on the distillation loss, for all language pairs). Implementation should be very straightforward, especially with the trick of pre-computing top-k probabilities from the teacher model at each corpus position. One small barrier to practical application that the authors fail to acknowledge is the requirement to train individual models, which will at least double training time compared to a single multilingual model.\n\nThe main missing experiment is higher-capacity multilingual models, which Johnson et al show to be beneficial in settings with a large number of language pairs. Using a multilingual model of the same (relatively small) size as the individual models as is done here is likely to be suboptimal, especially for the 44-language pair TED setting. A related point is that the corpora used seem to be quite small (eg 4.5M and 1M sentences for WMT Czech and German, respectively, while the available training corpora are closer to 15M and 4.5M). Although performance relative to individual models is still impressive - and seems to be better than than in previous work - this makes the experiments comparing to the multilingual baseline less meaningful.\n\nAlso missing are experiments on out-of-English translation, which would establish the viability of the proposed technique for many-to-many translation via bridging. Out-of-English is a more difficult problem than into-English. I can’t see any reason the proposed technique wouldn’t also work in this setting, but this remains to be shown.\n\nAlthough it’s great that the technique is shown to work without embellishments, there are a few obvious strategies it would have been interesting to explore, such as making the weight on the distillation loss dependent on the difference in performance between the multilingual and individual models; and allowing for the distillation loss to be turned back on if the performance of the multilingual model starts to drift back down for a particular language pair. I also wondered about the effect of the gradient accumulation strategy in algorithm 1, where individual batches from each language pair are effectively grouped into one giant batch for the purpose of parameter updates. I can see that this could stabilize training, but it would be good to know whether it’s crucial for success, especially when the number of language pairs is large.\n\nFurther details:\n\nAs aforementioned -> As mentioned\n\n(1) 2nd line: Doesn't make sense as written. You need to distinguish the gold\ny_t from hypothesized ones in the 1() function.\n\nAbove (2): is served as -> serves as\n\n3.2 First paragraph. Since D presumably consists of D^l for all languages l,\nL_ALL(D,...) should be a function of teacher parameters theta^l for all\nlanguages l rather than just one as written.\n\nIn top-K distillation, is the teacher distribution renormalized or simply\ntruncated?\n\nGeneralization analysis, pg 8: presumably you are sampling from N(0, sigma^2) -\nthis should be described as such.\n\nReference: \n\nJohnson et al, “Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation” TACL, 2017."", 'The authors apply knowledge distillation for many-to-one multilingual\nneural machine translation, first training separate models for each language\npair. For most language pairs, performance matches or improves upon\nsingle-task baselines.\n\nStrengths:\n\nImprovements upon the baselines are fairly impressive, especially for the\n44-language model.\n\nThe approach is quite simple and could be easily implemented by other groups.\n\nThe paper is well-written and easy to understand.\n\nAt inference, only a single model needs to be retained, which is memory-efficient.\n\nWeaknesses:\n\nThe authors only test distillation in a many-to-one scenario. I believe that\nproviding results for many-to-many multilingual NMT would be valuable.\n\nOverall, this approach increases training time as all single-task models\nmust have converged before beginning distillation.\n\nThe authors provide no direct comparison to other work, which makes it hard to\nknow how strong the baselines are. At least for WMT, I would suggest reporting\nresults with mteval-v13a (or SACREBLEU), so that results can be compared against\nofficial results.\n\nQuestions:\n\nFor the top-K approach, do you normalize the top K probabilities so that they\nsum to 1 or not?\n\nDid you consider applying sequence knowledge distillation (Kim and Rush, 2016)\n(using the baseline beam search output as references) instead of word knowledge\ndistillation?\n\n***\nEDIT: In my opinion, the changes made after the review period clearly improve the quality of the paper. I am increasing my rating from 6 to 7.']","[20, 50, 70]","[60, 70, 80]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths in experimentation and validation, they also express disappointment with the lack of deeper insights and marginal performance gains. The reviewer appreciates certain aspects like the back-distillation idea but feels the paper could have provided more analysis. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the 'commendable job' done by the authors and framing criticisms as questions or suggestions rather than direct attacks. The reviewer maintains a professional tone, balancing positive feedback with constructive criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the main idea makes sense and the results are convincing. They praise the implementation as straightforward and the performance as impressive. However, they also point out several missing experiments and potential improvements, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work while offering constructive criticism. They use phrases like 'it would have been interesting to explore' and 'I can't see any reason the proposed technique wouldn't also work' which maintain a collegial tone. The reviewer also provides specific, actionable feedback without using harsh or dismissive language."", ""The sentiment score is 70 (positive) because the reviewer highlights several strengths of the paper, including impressive improvements, simplicity of approach, clear writing, and memory efficiency. They do note some weaknesses, but these are presented as suggestions for improvement rather than major flaws. The overall tone is positive, especially with the final edit increasing the rating. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively as 'weaknesses' and 'questions', and acknowledges the authors' post-review improvements. The reviewer maintains a professional and courteous tone, avoiding any harsh or dismissive language.""]"
"['\nThe authors proposed to exploit hyperbolic geometry in computing the attention mechanisms for neural networks. Specifically, they break the attention read operation into two parts: matching and aggregation. In matching step, they use the hyperbolic distance to quantify the macthing between a query and a key; in the aggregation step, they use the Einstein midpoint. Their experiments results based on synthetic and real-world data shows the new method outperforms the traditional method based on Euclidean distance. This paper is acceptable.\n\n\nQuestion: In Figure 3(Center), the number of nodes 1000 and 1200 are pretty close. How about the results on 500 nodes and 2000 nodes? It seems the accuracy difference increases as the number of nodes increases. Is this true? \n\n', 'The authors propose a novel approach to improve relational-attention by changing the matching and aggregation functions to use hyperbolic geometric. By doing so the network can exploit the metric structure the functions live on.  Method was evaluated and showed improvements over baselines on wide range of tasks including translation, graph learning, and visual question answering.\n\nPros: \n* High quality paper. \n* Hyperbolic matching function is novel and interesting.\n* Even though the subject isn’t trivial, the intuition was described well. \n* The evaluation is comprehensive on several relational related tasks. \n\nCons:\n* Baselines: The authors main contribution is the matching and aggregation operator. It always feels like the multi-modal community is divided between VQA and CLEVR datasets, but there should be a lot in common between them. Specifically, what is called here the matching operator, had several variants in VQA, such as Multimodal Compact Bilinear Pooling by Fukui et al., or Multi-modal Factorized Bilinear Pooling\xa0by You et al. etc. I think the paper would benefit from adding other variants of matching functions. \n* Datasets: I think the approach might work as well in VQA dataset, which I find more interesting than clever because of the real-world nature of it. You can plug it into methods like MFB, or as pairwise potentials in Structured Attentions\xa0by Zhu et al, or High-Order attention by Schwartz et al\n\nConclusion:\nA better matching and aggregating operations are always important, it can potentially improve performance in many challenges. The proposed method is novel and interesting, therefore I will be happy to see this paper as part of ICLR. ', 'This paper replaces the dot-product similarity used in attention mechanisms with the negative hyperbolic distance, and applies this new attention to the existing Transformer model, graph attention networks (GAT), and Relation Networks (RN). Accordingly, they use Einstein midpoint to compute the aggregation weights of attention in hyperbolic space. The idea of using hyperbolic rather than Euclidean space is based on the assumption that the input embeddings (neural net activations) are on the hyperbolic manifold, which follows power-law distribution and can be seem as a smooth description of tree-like hierarchy of data points. This assumption might hold for small neural networks with relatively low dimensional output. One main reason why this paper adopts the hyperbolic space is that the volume of hyperbolic space grows exponentially with the increase of radius while that of Euclidean space grows only polynomially. Using hyperbolic distance can increase the capacity of networks and handle the complexity of data. Experiments on Transformer and relation network show that Transformer, GAT and RN with the new attention metric produce better performance than Euclidean distance.\n\nPros:\n\n1. Comparing to the existing methods using representations for shallow models in hyperbolic geometry, this paper extends the idea to deep neural networks. \n2. The proposed attention mechanism can be easily applied to many of existing networks to enhance their capacity.\n3. The experiments show several interesting results: 1) hyperbolic recursive transformer (RT) is consistently superior to Euclidean RT across the tasks in this paper; 2) hyperbolic space substantially benefits the low-capacity networks (i.e., low-dimensionality hidden state); 3) Einstein midpoint is better than Euclidean aggregation in hyperbolic space; 4) using sigmoid rather than softmax to compute attention weight may achieve better effectiveness on some tasks for the reason that the attention weights over different entities ay do not compete with each other.\n\n\nCons:\n\n1. The novelty of this paper is replacing the Euclidean metric with another existing metric, which has already been used in previous ML models. So the contribution is limited.\n2. As explicitly claimed in the paper and also reflected by the experimental results (e.g., Transformer-Big in Table 2). The hyperbolic metric only brings noticeable improvement to small neural nets with limited compacity on relatively small datasets. When applied it to most SOTA models (which are usually large/deep/wide neural networks) on larger datasets, it loses the advantage. This fact might seriously limit the application of the proposed technique.\n3. Small models are preferred for inference especially on edge devices. But model compression and knowledge distillation can make small models having similar performance as large models, which might be much better than directly training a small model with the proposed metric.\n4. Although hyperbolic metric reflects the power-law distribution, which is a very natural assumption verified on many kinds of real data (social networks and physical statistics), I am not fully convinced that it still holds on an embedding space produced by a neural net (since attention are usually applied to the outputs of a neural net). \n5. In the experiments, does the model with the proposed metric cost similar training/inference time comparing to the baselines? What is the trade-off between improvements and extra time costs? I notice that the results of the proposed attention in Table 2 are ~0.5% higher than the results from the earlier arXiv version of this paper. What is the reason for the improvements? Did you increase the training steps?']","[60, 70, -20]","[50, 80, 50]","[""The sentiment score is 60 (positive) because the reviewer states the paper is 'acceptable' and notes that the proposed method outperforms traditional methods. The overall tone is supportive of the paper's contributions. However, it's not extremely positive, as there's no effusive praise. The politeness score is 50 (somewhat polite) because the language is professional and respectful, without being overly formal or deferential. The reviewer asks a question about additional results in a neutral, curious manner, which is a polite way to request more information. The review avoids harsh criticism or demanding language, maintaining a courteous tone throughout."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its high quality, novelty, and comprehensive evaluation. They use phrases like 'High quality paper' and 'novel and interesting' to describe the work. The conclusion also states they would be 'happy to see this paper as part of ICLR'. However, it's not a perfect 100 as the reviewer does point out some cons and suggestions for improvement. The politeness score is 80 (polite) because the reviewer maintains a professional and respectful tone throughout. They balance praise with constructive criticism, using phrases like 'I think the paper would benefit from...' instead of more direct or harsh language. The reviewer also acknowledges the difficulty of the subject matter and compliments the authors on their clear explanation. The overall tone is supportive and aimed at improving the paper rather than tearing it down."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') that outweigh the positives. The reviewer questions the novelty, applicability, and assumptions of the paper, which contributes to the overall negative sentiment. However, the score is not deeply negative as the reviewer does recognize some merits of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present both pros and cons in a balanced manner, using neutral language like 'I am not fully convinced' rather than harsh criticisms. The reviewer also asks questions for clarification rather than making accusatory statements. However, the score is not extremely high as the review doesn't include overtly polite phrases or compliments beyond acknowledging the paper's strengths.""]"
"['# Summary\nThis paper proposes a new kind of spherical convolution for use in spherical CNNs, and evaluates it on rigid and non-rigid 3D shape recognition and retrieval problems. Previous work has either used general anisotropic convolution or azimuthally isotropic convolution. The former produces feature maps on SO(3), which is deemed undesirable because processing 3-dimensional feature maps is costly. The latter produces feature maps on the sphere, but requires that filters be circularly symmetric / azimuthally isotropic, which limits modeling capacity. This paper proposes an anisotropic spherical convolution that produces 2D spherical feature maps. The paper also introduces an efficient way of processing geodesic / icosahedral spherical grids, avoiding complicated spectral algorithms.\n\n\n# Strengths\nThe paper has several strong points. It is well written, clearly structured, and the mathematics is clear and precise while avoiding unnecessary complexity. Much of the relevant related work is discussed, and this is done in a balanced way. Although it is not directly measured, it does seem highly likely that the alt-az convolution is more computationally efficient than SO(3) convolution, and more expressive than isotropic S2 convolution. The most important contribution in my opinion is the efficient data structure presented in section 4, which allows the spherical convolution to be computed efficiently on GPUs for a grid that is much more homogeneous than the lat/lon grids used in previous works (which have very high resolution near the poles, and low resolution at the equator). The idea of carving up the icosahedral grid in just the right way, so that the spherical convolution can be computed as a planar convolution with funny boundary conditions, is very clever, elegant, and practical.\n\n\n# Weaknesses\nThere is however a misunderstanding about the properties of the alt-az convolution that must be cleared up before this paper can be published. To start with, the set of rotations R(phi, nu, 0) called the alt-az group in this paper is not a group in the mathematical sense. This easy to see, because a composition of rotations of the form Rz(phi) Ry(nu) is not generally of that form. For instance we can multiply Rz(phi) Ry(nu) by the element Rz(omega)Ry(0) = Rz(omega), which gives the element Rz(phi) Ry(nu) Rz(omega). As noted in the paper, this is a general element of SO(3) (and hence not in the set of alt-az rotations). So the closure axiom of a group is violated.\n\nThis matters, because the notion of equivariance really only makes sense for a group. If a layer l satisfies l R = R l  (for R a alt-az rotation), then it automatically satisfies l RR\' = RR\' l, which means l is equivariant to the whole group generated by the set of alt-az rotations. As we saw before, this is the whole rotation group. This would mean that the layer is actually SO(3)-equivariant, but it has been proven [1], that any rotation equivariant layer between scalar spherical feature maps can be expressed as an azimuthally isotropic convolution. Since the alt-az convolution is not isotropic and maps between scalars on S2, it cannot be equivariant. This also becomes apparent in the experiments section, where rotational data augmentation is found to be necessary. The paper does not contain an attempted proof of equivariance, and if one tries to give one, the impossibility of doing so will become apparent.\n\nI note that the alt-az convolution *is* equivariant to rotations in the subgroup SO(2) of rotations around the Z-axis.\n\nAnother somewhat jarring fact about the alt-az convolution is that it is not well defined on the south pole. The south pole can be represented by any pair of coordinates of the form phi in [0, 2pi], nu = +/- pi. But it is easy to see that eq. 10 will give different results for each of these coordinates, because they correspond to different rotations of the filter about the Z-axis. This is ultimately due to the fact that the set of alt-az rotations is not the same as the set of points on the sphere, topologically speaking. The set of points on the sphere can only be viewed as the quotient SO(3)/S(2).\n\nThe paragraph motivating the alt-az convolution on page 4 is not very clear, and some claims are questionable. I agree that local SO(2) invariance is too limiting. But it is not true that rotating filters is not effective in planar/volumetric CNNs, as shown by many recent papers on equivariant networks. I would suggest rewriting this paragraph to make it clearer and less speculative, and acknowledge that although rotating filters might increase computational complexity, it has often been shown very effective.\n\n\n# Other comments\n\nThe experiments show that the method is quite effective. For instance, the SHREC17 results are on par with Cohen et al. and Esteves et al., presumably at a significantly reduced computational cost. That they do not substantially outperform these and other methods is likely due to the input representation, which is lossy, leading to a maximal performance shared by all three methods. An application to omnidirectional vision might more clearly show the strength of the method, but this would be a lot of work so I do not expect the authors to do that for this paper.\n\nIt would be nice to see a more direct comparison between the three definitions of spherical convolution (general SO3, isotropic S2, and anisotropic S2). Right now, the numbers reported in Cohen et al. and Esteves et al. are copied over, but there are probably many differences between the precise setup and architectures used in these papers. It would be interesting to see what happens if one uses the same architecture on a number of problems, changing only the convolution in each case.\n\nInitially, I was a bit puzzled about why SO(3) augmentation seems to reduce accuracy in table 1. I think this is because SO(3) augmentation actually makes the classification problem harder if the input is initially aligned. Some more explanation / discussion would be good. \n\nIt would be nice to explain the spherical parameterization in more detail. Is this operation itself rotation equivariant? \n\n\nTypos & minor issues\n\n- Abstract: ""to extract non-trivial features"". The word non-trivial really doesn\'t add anything here. Similarly ""offers multi-level feature extraction capabilities"" is almost meaningless since all DL methods can be said to do so.\n- Below eq. 5, D_R^{-1} should equal D_R(-omega, -nu, -phi). The order is reversed when inverting.\n- ""Different notations of convolutions"" -> notions\n- ""For spherical functions there is no consistent and well defined convolution operators."" As discussed above, the issue is quite a bit more subtle. There are exactly two well-defined convolution operators, but they have some characteristics deemed undesirable by the authors.\n- ""rationally symmetric"" -> rotationally\n- ""exact hierarchical spherical patterns"" -> extract\n- It seems quite likely that the unpacking of the icosahedral/hexagonal grid as done in this paper has been studied before in other fields. References would be in order. Similarly, hexagonal convolution has a history in DL and outside.\n- Bottom of page 7, capitalize ""for"".\n- ""principle curvatures"" -> principal.\n- ""deferent augmentation modes"" -> different\n- ""inspite"" -> in spite\n- ""reprort"" -> report\n- ""utlize"" -> utilize\n- ""computer the convolution"" -> compute\n\n\n# Conclusion\n\nAlthough the alt-az convolution lacks the mathematical elegance of the general anisotropic and azimuthally isotropic spherical convolutions, it still seems like a practically useful operation for some kinds of data, particularly when implemented using the homogeneous icosahedral/hexagonal grid and fast algorithm presented in this paper. Hence, I would wholeheartedly recommend acceptance of this paper if the authors correct the factual errors (e.g. the claim of SO(3)-equivariance) and provide a clear discussion of the issues. For now I will give an intermediate rating to the paper.\n\n\n[1] Kondor, Trivedi, ""On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups""', '# Weaknesses\nApplications are a bit unclear.\nIt would be nice to see a better case made for spherical convolutions within the experimental section.  The experiments on SHREC17 show all three spherical methods under-performing other approaches.  It leaves it unclear to the reader when someone should choose to utilize a spherical method or when the proposed method would then be preferred compared to other spherical methods.  Is there a task that this representation significantly outperforms other spherical methods and non-spherical methods?  Or a specific useful application where spherical methods in general outperform other approaches?  \n\n# Strengths:\nThe method is well developed and explained.  \nAbility to implement in a straight-forward manner on GPU.\n', 'Deep Learning 3D Shapes using Alt-Az Anisotropic 2-Sphere Convolution\n\nThis paper presents a polar anisotropic convolution scheme on a unit sphere. The known non-shift-invariance problems of current manifold neural nets are avoided by replacing filter translation with filter rotation on a sphere. Spherical convolution are thus enabled and are rotation invariant compared to manifold convolutions. This shift also enables a proposed angular max-pooling scheme. Results are presented on mesh projections, shape classification and shape retrieval. \n\nThe paper generally reads well. Tackling the learning problem on a unit sphere has high potential, however, the proposed paper seems to be highly constrained by heuristics on a 2-sphere, such as constraining filters on a reduced rotation group to 2 rotations. This could be fine for many 3D application, but results may lack an exhaustive comparison with other spherical and manifold-based methods on the proposed experiments. Currently, several variants of data augmentations are used, and discussion may lack an explicit comparison with the state-of-the-art of spherical and spectral methods. This may impair understanding in which context the proposed method would work best.\n\n\nOther comments, possible clarification and improvements:\n\n[Method]\n- Can this be extended to unit 2-balls?\n- Isn\'t the ""alt-az rotation group"" the same as SO(3)?  If orientation is removed, what quotient group would this be?\n- What is the benefit of containing a filter on this quotient group rather than using convolution filters within the full rotation group?  Could a simple experiment convince the reader that the proposed approach is better than using convolutions in SO(3)?\n- Is there a dependence created by the spherical parameterization strategy?\n- How robust is the convolution scheme to topological defects, such as holes, noise?\n- Spherical images may induce parameterization distorsion if using a lat-lon grid, which would require complex variable filters on the spherical image. Are these variable filters burdening the computational complexity?\n- How to handle the distortion induced by the spherization process?\n- How to handle discontinuities around the sphere poles?\n- Computing geodesic may be costly - how does impact performance?\n- Does this rely on data augmentation to cover rotation invariance of filters?\n- Now icosahedrons are used - could the convolution work on an arbitrary mesh discretization, ranging from an ideal isoparametric sphere to a highly irregularly-triangulated mesh?\n- The remeshing strategy to a sphere also looses information from the original mesh connectivity - For instance, links between mesh nodes on the original surface may convey important information (e.g., brain connectivity in neuroscience), remising to a sphere would loose such connectivity information.\n\n[Results]\n- The experiments shows the proposed method with several augmented approaches - How exactly are data augmented?\n- Comparison with other spherical methods (Cohen et al 2018), or manifold-based methods (Monti et al 2018)?  Illustrating the pros and cons with these respective state-of-the-art?\n- Improvements could be better emphasized in Fig 6, Table 3 - how is the method better than others?\n']","[20, 20, -20]","[70, 50, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper, including its clear writing, balanced discussion of related work, and the clever and practical data structure introduced. However, the reviewer also points out significant weaknesses, particularly a misunderstanding about the properties of the alt-az convolution, which prevents a higher positive score. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive criticism. The reviewer uses phrases like 'I would suggest', 'It would be nice to see', and offers detailed explanations for their concerns, demonstrating a polite and helpful tone. The review concludes with a balanced statement, indicating willingness to recommend acceptance if the authors address the issues raised."", ""The sentiment score is slightly positive (20) because while the review points out some weaknesses, it also highlights significant strengths. The reviewer acknowledges that the method is well-developed, well-explained, and can be implemented easily on GPU. However, they also express concerns about unclear applications and the performance of spherical methods in experiments. The politeness score is moderately positive (50) as the reviewer uses neutral and professional language throughout, avoiding harsh criticism. They use phrases like 'It would be nice to see' and 'Is there a task that...?' which suggest constructive feedback rather than blunt criticism. The reviewer also balances critique with praise, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's potential and readability, they express several concerns and limitations of the proposed method. The reviewer points out that the approach seems 'highly constrained by heuristics', lacks 'exhaustive comparison' with other methods, and may 'impair understanding' of the method's best use cases. However, the tone isn't entirely negative, as they recognize the 'high potential' of the approach. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement or areas needing clarification. They use phrases like 'possible clarification and improvements' and pose many of their critiques as questions, which is a polite way to point out potential issues. The review maintains a professional and constructive tone, even when pointing out limitations.""]"
"['The submission builds up on recent advances in neural density estimation to develop a new algorithm for imitation learning based on a probabilistic model for predecessor state dynamics. In particular, the method trains masked autoregressive flows as a probabilistic model for state action pairs conditioned on future states. This model is used to estimate the gradient of the stationary distribution of a policies visited states. Finally, the proposed objective uses this estimate and the gradient of the log likelihood of expert actions under the policy to maximise the similarity of the expert’s and agent’s stationary state-action distributions. \n\nThe proposed method outperforms existing imitation learning approach (GAIL & BC) on 2 simulation-based manipulation tasks. It performs particularly well in terms of sample efficiency. \nThe magnitude of difference between the sample efficiencies of GAIL and the proposed approach seems quite surprising and it would be beneficial if the authors could explicitly state if the measured number of samples include the ones used for training of the probabilistic model as well as the policy (apologies if I have missed a section fulfilling this purpose).\n\nWhile the improvements on the presented experiments are clear, the experimental section represents a small shortcoming of the submitted paper. The 2 experiments (clip and peg insertion) are quite similar in type and to not take into account other common domains e.g. locomotion tasks from the original GAIL paper. Furthermore, an additional comparison to SAIL would be recommended since the approaches are closely related as the authors acknowledge. The provided comparison with different types of available expert data is quite interesting and could possibly be extended to test other state-of-the-art methods (action-free versions of GAIL, AIRL,etc.).\n\nNonetheless, the paper overall presents a strong submission based on novelty & relevance of the proposed method and is recommended for publication. \n\nMinor issues:\n- Related work: improve transitions between the section about trajectory tracking and BC.\n- Ablation studies with less flexible probabilistic models would strengthen the experiment section further. \n- Add derivation from Eq. 3 to 4 and 5 to appendix to render the paper more self-contained and easier to access.\n- A release of the code base would further strengthen the contributions of the submission.\n\nGeneral recommendation:\n- The authors are encouraged to further investigate off-policy corrections for improved convergence.\n', 'The paper proposes to use predecessor models for imitation learning to overcome the issue of only observing expert samples during imitation from expert trajectories.\n\nThe paper is very well written. But the proposed method is really not novel. The idea of using predecessor models have already been explored in multiple places [1], [2] (but not in imitation learning scenario!). Hence, the novelty comes from using the predecessor models for imitation learning. The introduction of the paper should mention this  to reflect the contribution. \n\n[1] Recall Traces: Efficient Backtracking models for efficient RL https://arxiv.org/abs/1804.00379\n[2] Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains\nhttps://arxiv.org/abs/1806.04624\n\nBoth of these papers should be cited and discussed.\n\nResults: The proposed method outperforms GAIL and behaviour cloning in terms of sample efficiency   on simulation-based manipulation tasks.\n\nRegarding experiments, I would like to see certain baselines.\n\n- What happens when you predict sequentially using predecessor models ? I understand that the sequential generation is prone to accumulating errors, but as [1] points out, using predecessor models you can sample from many states on the expert trajectory. And Hence possible to get good learning signal even while sampling shorter trajectories using predecessor models.\n\n- Comparison with Dyna based methods. For this baseline, authors would learn a forward model. And then sample from the forward model, and use the samples from the forward model for imitation learning.\n\n', 'This paper studies the problem of matching the state-action distributions of agent and expert demonstrations. In order to address this problem, the authors consider a likelihood treatment comprising a conditional probability (which is estimated from demonstrations) and a state distribution (which is estimated from sampling approximations). \n\nThe authors provide a descent result (i.e., equ. (7)) to estimate the gradient of the logarithmic state distribution. One problem is that it is unclear how the discount factor $\\gamma$ influence this result?\n\nIn addition, in (12), two scaling factors are used, so how to balance these weights?\n\nSpecifically, in (11), it seems the authors are considering the stationary joint state-action distribution, which is different from the state-action distribution generated by the agent on-line, it is suggested to clarify this issue.']","[70, 20, -20]","[80, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, stating it's a 'strong submission' and recommending it for publication. They praise the novelty and relevance of the method, and highlight its outperformance of existing approaches. However, they also point out some shortcomings in the experimental section, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'it would be beneficial if' and 'the authors are encouraged to', which are polite ways of suggesting improvements. They also apologize for potentially missing information ('apologies if I have missed a section fulfilling this purpose'), which is a particularly courteous gesture. The reviewer provides both praise and criticism in a balanced, professional manner, maintaining a polite tone even when pointing out areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer starts by praising the paper as 'very well written' and acknowledges that the proposed method outperforms existing techniques. However, they also point out that the method is not entirely novel and suggest additional comparisons and baselines, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'I would like to see' and 'I understand that', while providing constructive criticism. They also acknowledge the paper's strengths before suggesting improvements, which is a polite approach to reviewing. The reviewer maintains a professional tone without using overly harsh or negative language, even when pointing out limitations or requesting additional work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they raise several questions and issues that need clarification. The review starts with a neutral summary but then focuses on problems and unclear aspects, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They phrase their concerns as questions or suggestions rather than direct criticisms, using phrases like 'it is unclear' and 'it is suggested to clarify' which maintain a polite tone while still addressing issues.""]"
"[""RELATIONAL FORWARD MODELS FOR MULTI-AGENT LEARNING\n\nSummary: Model free learning is hard, especially in multi-agent systems. The authors consider a way of reducing variance which is to have an explicit model of actions that other agents will take. The model uses a graphical structure and the authors argue it is a) interpretable, b) predicts actions better and further forward than competing models, c) can increase learning speed.\n\nStrong Points:\n-\tThe main innovation here is that the model uses a graph conv net-like architecture which also allows for interpretable outputs of “what is going on” in a game.\n-\tThe authors show that the RFM increases learning speed in several games\n-\tThe authors show that the RFM does somewhat better at forward action prediction than a naïve LSTM+MLP setup and other competing models\n\nWeak Point\n-\tThe RFM is compared to other models in predicting forwards actions but is not compared to other models in Figure 5, so it is not clear that the graphical structure is actually required to speed up learning. I would like to see these experiments added before we can say that the RFM is adding to performance.\n-\tRelated: The authors argue that an advantage of the RFM is that it is interpretable, but I thought a main argument of Rabinowitz et. al. was that simple forward models similar to the LSTM+MLP here were also interpretable? If the RFM does not improve learning above and beyond the LSTM+MLP then the argument comes down to more accurate action prediction (ok) and more interpretability (maybe) which is less compelling.\n\nClarifying Questions\n-\tHow does the 4 player Stag Hunt work? Do all 4 agents have to step on the Stag together or just 2 of them? How are rewards distributed? Is there a negative payoff for Hunting the stag alone as in the Peysakhovich & Lerer paper?\n-\tRelated: In the Stag Hunt there are multiple equilibria, either agents learn to get plants (which is safe but low payoff) or they learn to Hunt (which is risky but high payoff). Is the RFM leading to more convergence to the Hunting state or is it simple leading agents to learn the safe but low payoff strategies faster?\n- The choice of metric in Figure 2 (# exactly correct prediction) is non-standard (not saying it is wrong). I think it would be good to also see a plot of a more standard metric such as loglikelihood of the model's for each of X possible steps ahead. It would help to clarify where the RFM is doing better (is it better at any horizon or is it just able to look further forward more accurately than the competitors?)\n\n\n"", '\nThis paper used graph neural networks to do relational reasoning of multi-agent systems to predict the actions and returns of MARL agents that they call Relational Forward Modeling. They used RFM to analyze and assess the coordination between agents in three different multi-agent environments. They then constructed an RFM-aumented RL agent and showed improved training speeds over non relational reasoning baseline methods. \n\nI think the overall approach is interesting and a novel way to address the growing concern of how to access coordination between agents in multi-agent systems. I also like how they authors immediately incorporated the relational reasoning approach to improve the training of the MARL agents. \n\nI wonder how dependent this approach is to the semantic representation of the environment. These semantic descriptions are similar to hand crafted features and thus will require some prior knowledge about the environment or task and will be harder to obtain on more difficult environment and tasks. \n\nWill this approach work on continuous tasks? For example, the continuous state and action space of the predator-prey tasks that use the multi-agent particle environment from OpenAi. \n\nI think one of the biggest selling points from this paper is using this method to assess the coordination/collaboration between agents (i.e. the social influence amongst agents). I would have liked to see\nmore visualizations or analysis into these learned representations. The bottom row of Figure 3 shows that ""when stags become available, agents care about each other more than just before that happens"". While this is very interesting and an important result, i think that this allows one to see what features of the environment (including other agents) are important to a particular agents decision making but it doesn\'t really answer whether the agents are truly coordinated, i.e. whether there are any causal dependencies between agents. \n\nFor the RFM augmented agents, I like that you are able to train the policy as well as the RFM simultaneously from scratch, however, it seems that this requires you to only train a single agent in the multi-agent environment. If I understand correctly, for a given multi-agent environment, you first pre-trained A2C agents to play the three MARL games and then you paired one of the pre-trained (expert) agents with the RFM-augmented learning agents during training. This seems to limit the practicality and usability of this method as it requires you to have pre-trained agents that have already solved the task. I would like to know why the authors didn\'t try to train two (or four) RFM-augmented agents from scratch together. When you use one of the agents as a pre-trained agent, this might make the training of the RFM module a bit easier since you have at least one agent with a fixed policy to predict actions from.  It could be challenging when trying to train both RFM modules on two learning agents as the behaviors of learning agents are changing over time and thus the learning might be unstable. \n\nOverall, i think this is an interesting approach and especially for probing what information drives agents\' behaviors. However, I don\'t see the benefit of the RFM-augmented agent provides. It\'s clearly shown to learn faster than non RFM-augmented agents (which is good), however, unless I\'m mistaken, the RFM-augmented agent requires a pre-trained agent to be able to learn in the first place. \n\n--edit:\nThe authors have sufficiently addressed my questions and concerns and have performed additional analysis.  My biggest concern of weather or not the RFM-augmented agent was capable of learning without a pre-trained agent has been addressed with additional experiments and analysis (Figure 8). \n\nBased on this, i have adjusted my rating to a 7. \n\n', ""This paper proposes to use graph neural networks in the scenario of multi-agent reinforcement learning (MARL). It tackles two current challenges, learning coordinated behaviours and measuring such coordination.\n\nAt the core of the approach are graph neural networks (a cite to Scarselli 2009 would be reasonable): acting and non-acting entities are represented by a graph (with (binary) edges between acting-acting and acting-nonacting entities) and the graph network produces a graph where these edges are transformed into a vectorial representation, which then can be used by a downstream task, e.g. a policy algorithm (as in this paper) that uses it to coordinate behavour. Because the output of the graph network is a structurally identical graph to the input, it is possible to interpret this output.\n\nThe paper is well written, the main ideas are clearly described. I'm uncertain about the novelty of the approach, at least the way the RFM is utilized in the policy is a nice idea (albeit, a-posteriori, sounds straight forward in the context of MARL). Similarly, using the graph output for interpretations is an obvious choice). Nevertheless, showing empirically that the ideas actually work gives the paper a lot of credibility for being a stepping stone in the area of MARL."", 'This paper studies predicting multi-agent behavior using a proposed neural network architecture. The architecture, called a relational forward model (RFM) is the same graph network proposed by Battaglia et al., 2018, but adds a recurrent component. Two tasks are define: predict the next action of each agent, and predict the sum of future rewards. The paper demonstrates that RFMs outperform two baselines and two ablations. The authors also show that edge activation magnitudes are correlated with certain phenomenons (e.g. an agent walking towards an entity, or an entity being “on” or “off”). The authors also show that appending the output of a pre-trained RFM to the state of a policy can help it learn faster.\n\nOverall, this paper presents some interesting ideas and is easy to follow, but the significance of the paper is not clear. The architecture is a rather straightforward extensions of previous work, and using graph networks for predictive modeling in multi-agent settings has been examined in the past, making the technical contributions not particularly novel. Examining the correlation between edge activation magnitudes and certain events is intriguing and perhaps the most novel aspect of this paper, but it is not clear how or why this information would be useful. There a few unsubstantiated claims that are concerning. There are also some odd experimental decisions and results that should be addressed.\n\nFor specific comments:\n\n1. Why would using a recurrent network help (i.e. RFM vs Feedforward)? Unless the policies are non-Markovian, the entire prediction problem should Markovian. I suspect that most of the gains are coming from the fact that the RFM method simply has more parameters than the Feedforward method (e.g. it can amortize some of the computation into the recurrent part of the network). Suggestion: train a Feedforward model that has more parameters (with appropriate hyperparameter sweeps) to see if this is the cause. If not, provide some analysis for why “memories of the relations between entities” would be any more beneficial than simply recomputing those relations.\n2. The other potential reason that the recurrent method did better is that policy actions are highly correlated (e.g. because agents move in straight lines to locations). If so, then recurrent methods can outperform feedforward methods without having to learn anything about what actually causes policies to move in certain directions. Suggestion: measure the correlation between consecutive actions. If there is non-trivial correlation, than this suggests that RFM does better than Feedforward (which is basically prior work of Battaglia et. al.) is for the wrong reasons.\n3. If I understand the evaluation metric correctly, for each rollout, it counts how many steps from the beginning of the rollout match perfectly before the first error occurs. Then it averages this “minimum time to failure” across all evaluation rollouts. If this is correct, why was this evaluation metric chosen? A much more natural metric would be to just compute the average number of errors on a test data-set (and if this is what is actually reported, please update the description to disambiguate the two). The current metric could be very deceptive:  Methods that do very well on states around the initial-state distribution but poorly near the end of trajectories (e.g. perfectly predicts the actions in the first 10 steps, but then resorts to random guessing for the last 99999 time steps) will outperform methods that have lower average error rate (e.g. a model that is correct 50% of the time). Suggestion: change the metrics to average number of errors, or report both, or provide a convincing argument why this metric is meaningful.\n4. Unless I misunderstood, the results in Section 2.2.3 seem spurious and the claims seem unsubstantiated. For one, if we look at Equations (1) and (2), when we average over s_a1 and s_a2, they should both give the same average for R_a1. Put another way: the prune graph should (in theory) marginalize out s_a2. On average, its expected output should be the same as the output of the full graph (after marginalizing out s_a1 and s_a2). Obviously, it is possible to find specific rollouts where the full graph has higher value than the prune graph (and it seems Figure 4 does this), but it should equally be possible to find rollouts where the opposite is true. I’m hoping I misunderstood this section, but otherwise this seems to invalidate all the claims made in this section.\n5. Even if concern #4 is addressed, the following sentence would still seem false: “This figure shows that teammates’ influence on each other during this time is beneficial to their return.” The figure simply shows predictions of the RFM, and not of the ground truth. Moreover, it’s not clear what “teammates’ influence” actually means.\n6. The comparison to NRI seems rather odd, since that method uses strictly less information than RFM.\n7. For Section 3, is the RFM module pretrained and then fine-tuned with the new policy? If so, this gives the “RFM + A2C” agent extra information indirectly via the pretrained weights of the RFM module.\n8. I’m not sure what to make of the correlation analysis. It is not too surprising that there is some correlation (in fact, it’d be quite an interesting paper if the findings were that there wasn’t a correlation!), and it’s not clear to me how this could be used for debugging, visualizations, etc. If someone wanted to analyze the correlation between two entities and a policy’s action, it seems like they could directly model this correlation.\n\nSome minor comments:\n - In Figure 3C, right, why isn’t the magnitude 0 at time=1? Based on the other plots in Figure 3c, it seems like it should be 0.\n - The month/year in many of the citations seems odd.\n - The use of the word “valence” seems unnecessarily flowery and distracting.\n\nMy main concern with this paper is that it is not particularly novel and the contribution seems questionable. I have some concerns over the experimental metric and Section 2.2.3, but even if that is clarified, it is not clear how impactful this paper would be. The use of a recurrent network seems unnecessary, unjustified, and not analyzed. The analysis of correlations is interesting, but not particularly compelling or surprising. And lastly, the RFM-augmented results are not very strong.\n\n--\n\nEdit: After discussing with the authors, I have changed my rating. The authors have adjusted some of the language, which I previously thought overstated the contributions and was misleading. They have added a number of experiments which valid the claim that their method is proposing a reasonable way of measuring collaboration. I also realized that I misunderstood one of the sections, and I encourage the authors to improve the presentation to (1) present the significance of the experiments more clear, (2) not overstate the results, and (3) emphasize the contribution more clearly.\n\nOverall, the paper presents convincing evidence that factors in a graph neural networks do capture some notion of collaboration. I do not feel that the paper is particularly novel, but the experiments are thorough. Furthermore, their experiments show that adding an RFM module to an agent consistently helps (albeit not by much). Given that the multi-agent community is still trying to decide how to best quantify and use metrics for collaboration, I find it difficult to access the long-term impact of this paper. However, given the thoroughness of the experiments and analysis, I suspect that this will be valuable for the community and deserves some visibility.']","[50, 60, 70, -20]","[80, 80, 80, 50]","[""The sentiment score is 50 (slightly positive) because the review begins by acknowledging the difficulty of the problem and the authors' attempt to address it. It lists several strong points, indicating a positive view of the work. However, it also includes weak points and clarifying questions, balancing the positive aspects with constructive criticism. The overall tone suggests the reviewer sees merit in the work but also areas for improvement.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They frame criticisms as 'weak points' rather than using harsh language, and pose 'clarifying questions' instead of pointing out flaws directly. The reviewer also acknowledges the authors' arguments and achievements before suggesting improvements. The language is consistently constructive and aimed at improving the paper rather than dismissing it."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the approach, calling it 'novel' and 'interesting'. They highlight several positive aspects, such as the method's ability to assess coordination between agents and improve training speeds. However, they also raise some concerns and questions, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the authors' efforts to address their concerns in the edit. The reviewer uses phrases like 'I think', 'I wonder', and 'I would like to know', which maintain a polite and constructive tone. The high politeness score is also supported by the reviewer's willingness to adjust their rating after the authors addressed their concerns."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They state that it is 'well written' and the 'main ideas are clearly described'. The reviewer also mentions that the paper has 'a lot of credibility' and could be a 'stepping stone in the area of MARL'. However, it's not a perfect score as the reviewer expresses some uncertainty about the novelty of the approach. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They offer constructive feedback and acknowledge the paper's strengths without being overly critical. The reviewer also suggests improvements (like adding a citation) in a polite manner. The tone is consistently professional and courteous, avoiding any harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas and ease of following the paper, they express significant concerns about the novelty and significance of the work. They point out several issues with the methodology and results, and state that the 'contribution seems questionable.' However, the edit at the end slightly improves the overall sentiment, as the reviewer acknowledges some value in the paper after discussion with the authors. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'interesting ideas,' 'suggestion:' for improvements, and 'I'm hoping I misunderstood' rather than making blunt criticisms. The reviewer also acknowledges their own potential misunderstandings and provides detailed explanations for their concerns, which contributes to the polite tone.""]"
"['The paper extends the PGD adversarial training method (Madry et al., 2017) to Bayesian Neural Nets (BNNs). \nThe proposed method defines a generative process that ties the prediction output and the adversarial input \npattern via a set of shared neural net weights. These weights are then assinged a prior and \nthe resultant posterior is approximated by variational inference.\n\nStrength:\n  * The proposed approach is incremental, but anyway novel.\n  * The results are groundbreaking.\n  * There are some technical flaws in the way the method has been presented, \nbut the rest of the paper is very well-written.\n\nMajor Weaknesses:\n\n  * Equation 7 does not seem to be precise. First, the notation p(x_adv, y | w) is severely misleading. If x_adv is also an input, no matter if stochastic or deterministic, the likelihood should read p(y | w, x_adv). Furthermore, if the resultant method is a BNN with an additional expectation on x_adv, the distribution employed on x_adv resulting from the attack generation process should also be written in the form of the related probability distribution (e.g. N(x_adv|x,\\sigma)).\n\n  * Second, the constraint that x_adv should lie within the \\gamma-ball of x has some implications on the validity of\nthe Jensen\'s inequality, which relates Equation 7 to proper posterior inference.\n\n  * Blundell et al.\'s algorithm should be renamed to ""Bayes-by-BACKprop"". This is also an outdated inference technique for quite many scenarios including the one presented in this paper. Why did not the authors benefit from the local reparametrization trick that enjoy much lower estimator variance? There even emerge sampling-free techniques that nullify this variance altogether and provide much more stable training experience.\n\nAnd Some Minor Issues:\n\n  * The introduction part of paper is unnecessarily long and the method part is in turn too thin. As a reader, I would prefer getting deeper into the proposed method instead of reading side material which I can also find in the cited articles.\n\n  * I do symphathize and agree that Python is a dominant language in the ML community. Yet, it is better scientific writing practice to provide language-independent algorithmic findings as pseudo-code instead of native Python.\n\nOverall, this is a solid work with a novel method and very strong experimental findings. Having my grade discounted due to the technical issues I listed above and the limitedness of the algorithmic novelty, I still view it as an accept case.', 'I have read the feedback and discussed with the authors on my concerns for a few rounds. \n\nThe revision makes much more sense now, especially by removing section 3.3 and replacing it with more related experiments.\n\nI have a doubt on whether the proposed method is principled (see below discussions). The authors responded honestly and came up with some other solution. A principled approach of adversarially training BNNs is still unknown, but I\'m glad that the authors are happy to think about this problem. \n\nI have raised the score to 6. I wouldn\'t mind seeing this paper accepted, and I believe this method as a practical solution will work well for VI-based BNNs. But again, this score ""6"" reflects my opinion that the approach is not principled.\n\n=========================================================\n\nThank you for an interesting read.\n\nThe paper proposes training a Bayesian neural network (BNN) with adversarial training. To the best of my knowledge the idea is new (although from my perspective is quite straight-forward, but see some discussions below). The paper is well written and easy to understand. Experimental results are promising, but I don\'t understand how the last experiment relates to the main idea, see comments below.\n\nThere are a few issues to be addressed in revision:\n\n1. The paper seems to have ignored many papers in BNN literature on defending adversarial attacks. See e.g. [1][2][3][4] and papers citing them. In fact robustness to adversarial attacks is becoming a standard test case for developing approximate inference on Bayesian neural networks. This means Figure 2 is misleading as in the paper ""BNN"" actually refers to BNN with mean-field variational Gaussian approximations.\n\n2. Carlini and Wagner (2017a) has discussed a CW-based attack that can increase the success rate of attack on (dropout) BNNs, which can be easily transferred to a corresponding PGD version. Essentially the PGD attack tested in the paper does not assume the knowledge of BNN, let alone the adversarial training. This seems to contradict to the pledge in Athalye et al. that the defence method should be tested against an attack that is aware of the defence.\n\n3. I am not exactly sure if equation 7 is the most appropriate way to do adversarial training for BNNs. From a modelling perspective, if we can do Bayesian inference exactly, then after marginalisation of w, the model does NOT assume independence between datapoints. This means if we want to attack the model, then we need to do \n\\min_{||\\delta_x|| < \\gamma} log p(D_adv), \nD_adv = {(x + \\delta_x, y) | (x, y) \\sim \\sim D_tr},\nlog p(D_adv) = \\log \\int \\prod_{(x, y) \\sim D_tr} p(y|x + \\delta_x, w) p(w) dw.\nNow the model evidence log p(D_adv) is intractable and you resort to variational lower-bound. But from the above equation we can see the lower bound writes as\n\\min_{||\\delta_x|| < \\gamma} \\max_{q} E_{q} [\\sum_{(x, y) \\sim D_tr} \\log p(y|x + \\delta_x, w) ] - KL[q||p],\nwhich is different from your equation 7. In fact equation 7 is a lower-bound of the above, which means the adversaries are somehow ""weakened"".\n\n4. I am not exactly sure the purpose of section 3.3. True, that variational inference has been used for compressing neural networks, and the experiment in section 3.3 also support this. However, how does network pruning relate to adversarial robustness? I didn\'t see any discussion on this point. Therefore section 3.3 seems to be irrelevant to the paper.\n\nSome papers on BNN\'s adversarial robustness:\n[1] Li and Gal. Dropout Inference in Bayesian Neural Networks with Alpha-divergences. ICML 2017\n[2] Feinman et al. Detecting Adversarial Samples from Artifacts. arXiv:1703.00410\n[3] Louizos and Welling. Multiplicative Normalizing Flows for Variational Bayesian Neural Networks. ICML 2017 \n[4] Smith and Gal. Understanding Measures of Uncertainty for Adversarial Example Detection. UAI 2018', 'After feedback: I would like to thank the authors for careful revision of the paper and answering and addressing most of my concerns. From the initial submission my main concern was clarity and now the paper looks much more clearer. \n\nI believe this is a strong paper and it represents an interesting contribution for the community.\n\nStill things to fix:\na) a dataset used in 4.2 is not stated\nb) missing articles, for example, p.5 "".In practice, however, we need a weaker regularization for A small dataset or A large model""\nc) upper case at the beginning of a sentence after question: p.8 ""Is our Adv-BNN model susceptible to transfer attack? we answer"" - ""we"" -> ""We""\n====================================================================================\n\nThe paper proposes a Bayesian neural network with adversarial training as an approach for defence against adversarial attacks. \n\nMain pro:\nIt is an interesting and reasonable idea for defence against adversarial attacks to combine adversarial training and randomness in a NN (bringing randomness into a new level in the form of a BNN), which is shown to outperform both adversarial training and random NN alone.\n\nMain con:\nClarity. The paper does not crucially lack clarity but some claims, general organisation of the paper and style of quite a few sentences can be largely improved.\n\nIn general, the paper is sound,  the main idea appears to be novel and the paper addresses the very important and relevant problem in deep learning such as defence against adversarial attacks. Writing and general presentation can be improved especially regarding Bayesian neural networks, where some clarity issues almost become quality issues. Style of some sentences can be tuned to more formal.\n\nIn details:\n1. The organisation of Section 1.1 can be improved: a general concept ""Attack"" and specific example ""PGD Attack"" are on the same level of representation, while it seems more logical that ""PGD Attack"" should be a subsection of ""Attack"". And while there is a paragraph ""Attack"" there is no paragraph ""Defence"" but rather only specific examples\n2. The claim “we can either sample w ∼ p(w|x, y) efficiently without knowing the closed-form formula through the method known as Stochastic Gradient Langevin Dynamics (SGLD) (Welling & Teh, 2011)” sounds like SGLD is the only sampling method for BNN, which is not true, see, e.g., Hamiltonian Monte Carlo (Neal’s PhD thesis 1994). It is better to be formulated as ""through, for example, the method ...""\n3. Issues regarding eq. (7):\n   a) Why there is an expectation over (x, y)? There should be the joint probability of all (x, y) in the evidence.\n   b) Could the authors add more details about why it is the ELBO given that it is unconventional with adversarial examples added?\n   c)  It seems that it should be log p(y | x^{adv}, \\omega) rather than p(x^{adv}, y | \\omega). \n   d) If the authors assume noise component, i.e., y = f(x; \\omega) + \\epsilon, then they do not need to have a compulsory Softmax layer in their network, which is important, for example, for regression models. Then the claim “our Adv-BNN method trains an arbitrary Bayesian neural network” would be more justified\n4. It would make the paper more self-contained if the Bayes by Backprop algorithm would be described in more details (space can be taken from the BNN introduction). And it seems to be a typo that it is Bayes by Backprop rather than Bayes by Prop\n5. There are missing citations in the text:\n    a) no models from NIPS 2017 Adversarial Attack and Defence competition (Kurakin et al. 2018) are mentioned\n    b) citation to justify the claim “C&W attack and PGD attack (mentioned below) have been recognized as\ntwo state-of-the-art white-box attacks for image classification task”\n    c) “we can approximate the true posterior p(w|x, y) by a parametric distribution q_θ(w), where the unknown parameter θ is estimated by minimizing KL(q_θ(w) || p(w|x, y)) over θ” - there are a variety of works in approximate inference in BNN, it would be better to cite some of them here\n    d) citation to justify the claim ""although in these cases the KL-divergence of prior and posterior is hard to compute and practically we replace it with the Monte-Carlo estimator, which has higher variance, resulting in slower convergence rate.”\n6. The goal and result interpretation of the correlation experiment is not very clear\n7. From the presentation of Figure 4 it is unclear that this is a distribution of standard deviations of approximated posterior.\n8. “To sum up, our Adv-BNN method trains an arbitrary Bayesian neural network with the adversarial examples of the same model” – unclear which same model is meant\n9. ""Among them, there are two lines of work showing effective results on medium-sized convolutional networks (e.g., CIFAR-10)"" - from this sentence it looks like CIFAR-10 is a network rather than a dataset\n10. In ""Notations"" y introduction is missing\n11. It is better to use other symbol for perturbation rather than \\boldsymbol\\delta since \\delta is already used for the Dirac delta function\n12. “via tuning the coefficient c in the composite loss function” – the coefficient c is never introduced\n\nMinor:\n1. There are a few missing articles, for example, in Notations, “In this paper, we focus on the attack under THE norm constraint…”\n2. Kurakin et al. (2017) is described in the past tense whereas Carlini & Wagner (2017a) is described in the present tense\n3. Inner brackets in eq. (2) are bigger than outer brackets\n4. In eq. (11) $\\delta$ is not bold\n5. In eq. (12) it seems that the second and third terms should have “-” rather than “+”\n6. Footnote in page 6 seems to be incorrectly labelled as 1 instead of 2\n\n\n\n\n\n']","[50, 40, 70]","[60, 80, 80]","[""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's strengths ('novel approach', 'groundbreaking results', 'very well-written'), they also point out several major weaknesses and technical flaws. The overall recommendation is positive ('I still view it as an accept case'), but with reservations. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging both strengths and weaknesses professionally. They use phrases like 'I do sympathize and agree' and 'Overall, this is a solid work', which contribute to a polite tone. However, the directness in pointing out flaws ('Equation 7 does not seem to be precise', 'This is also an outdated inference technique') prevents the score from being higher."", ""The sentiment score is 40 (slightly positive) because the reviewer expresses overall satisfaction with the revised paper, stating they 'wouldn't mind seeing this paper accepted' and that the method 'will work well'. However, they still have some reservations, noting that the approach is 'not principled' and giving it a score of 6 out of 10. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, thanking the authors for 'an interesting read', acknowledging their honest responses and willingness to think about problems, and framing criticisms constructively. They also use phrases like 'I have a doubt' and 'I'm not exactly sure' when expressing concerns, which softens the critique."", ""The sentiment score is 70 (positive) because the reviewer expresses gratitude for the revisions, states that it's a 'strong paper' and an 'interesting contribution', and notes that most concerns have been addressed. The overall tone is approving, despite some remaining minor issues. The politeness score is 80 (quite polite) due to the use of respectful language throughout, starting with thanking the authors, and phrasing criticisms constructively. The reviewer maintains a professional and courteous tone, even when pointing out areas for improvement. They use phrases like 'I believe' and 'can be improved' rather than making harsh demands, which contributes to the polite tone.""]"
"['The results are intriguing. However, similar methods like BN-LSTM [3] and Variational RNNs [4] achieve arguably the same with very similar mechanisms. We do not think they can be considered as orthogonal. This should be addressed by the authors. Also, hard long-term experiments like sequentially predicting pixels (like through MDLSTM-based PixelRNN) or language modelling should be favoured over short sentence image captions. \n\nIt is possible that we will improve our ratings once our concerns are addressed.\n\nPaper Summary:\n\nThe authors claim that the gradient along the computational path that goes through the cell state (the linear temporal path or A gradient) of an LSTM carries information about long-term dependencies. Those gradients can be corrupted by the gradient of all other computational paths (i.e. the B gradient). They claim that this makes it hard to learn long-term dependencies and has, therefore, significant negative effects on the convergence speed, training stability, and generalisation performance. They propose a method called h-detach and run experiments on the delayed copy task, sequential MNIST, permuted sequential MNIST (pMNIST), and caption generation on the MS COCO dataset. All show either somewhat improved performance or much more stable learning curves. At every step, h-detach randomly drops all gradients that flow through the h of the standard LSTM, the B gradients, and only keeps the ones from the linear temporal path, the A gradients. Experiments also suggest that the A gradients carry more long-term information than B gradients and that LSTMs with h-detach do not need gradient clipping for successful training.\n\nPositive:\n\nThe paper is written clearly. It is well structured and well motivated. H-detach is simple, effective, and somewhat novel (see below). Experiments indicate that its main benefit is training stability as well as minor performance improvements.\n\nNegative:\n\nWe are not sure how significant these results are for the following reasons:\n\n- MS COCO image caption generation is the only more challenging dataset, but it seems a bit misplaced as it has very short sentences, while the authors motivate their work through a focus on long-term dependencies. Why not apply h-detach to a language model such as [1] with official online implementations, e.g., [2]. A setting with PixelRNN [6] based on MD-LSTM [7] would also be a great testbed for h-detach.\n\n- The purpose of h-detach is to scale down the B gradients. However, methods which apply e.g. BatchNorm to the hidden state learn a scale parameter which could be learned by the network explicitly. For the backward pass, this has the effect of scaling down the B gradient. Consider e.g. [3] which also achieves similar training stability on sequential MNIST and pMNIST with little overhead. \n\n- Another very related method is [4] which properly applies a random dropout mask over the recurrent inputs that is shared across timesteps of an RNN. We think that h-detach is essentially achieving the same in a similar way.\n\nProblems with Introduction and Related Work Section:\n\n- The vanishing gradient problem was first described by Hochreiter in 1991 [5] (not by Bengio in 1994). \n\n- Intro mentions GRU as if it was separate from LSTM. Clarify that GRU is essentially a variant of vanilla LSTM with forget gates [8]. Since one gate is missing, GRU is less powerful than the original LSTM [9]. \n\n[1] Zaremba et al. ""Recurrent neural network regularization."" arXiv:1409.2329 (2014).\n[2] https://www.tensorflow.org/tutorials/sequences/recurrent\n[3] Cooijmans et al. ""Recurrent batch normalization."" arXiv:1603.09025 (2016).\n[4] Gal et al. ""A theoretically grounded application of dropout in recurrent neural networks."" NIPS 2016.\n[5] Hochreiter, Sepp. ""Untersuchungen zu dynamischen neuronalen Netzen."" Diploma thesis, TUM (1991)\n[6] Oord et al. ""Pixel recurrent neural networks."" arXiv preprint arXiv:1601.06759 (2016).\n[7] Graves et al. ""Multi-Dimensional Recurrent Neural Networks"" arXiv preprint arXiv:0705.2011 (2011).\n[8] Gers et al. “Learning to Forget: Continual Prediction with LSTM.“ Neural Computation, 12(10):2451-2471, 2000. \n[9] Weiss et al. On the Practical Computational Power of Finite Precision RNNs for Language Recognition. arXiv:1805.04908.\n\n\nComments after rebuttal:\n\nThe  paper has clearly improved. \n\nIt leaves a few questions open though. For example, it is surprising that h-detach doesn\'t work on language modelling since Dropout-LSTM and BN-LSTM clearly improve over vanilla LSTM in this case (if not every case). In the new version, the authors only reference it in one or two sentences but don\'t discuss this in detail. \n\nWhen dropout is mentioned, one should also mention that dropout is a variant of the old stochastic delta rule:\n\nHanson, S. J. (1990). A Stochastic Version of the Delta Rule, PHYSICA D,42, 265-272.  See also arXiv:1808.03578 \n\nNevertheless, we now think that this is a very interesting LSTM regularization paper that people who study this field should probably know. We are increasing the score by 2 points!\n\n', 'In this paper, the authors propose a simple modification to the training process of the LSTM. The goal is to facilitate gradient propagation along cell states, or the ""linear temporal path"". It blocks the gradient propagation of hidden states with a probability of $1-p$ independently. The proposed method is evaluated on the copying task, sequential MNIST task, and image captioning tasks. The performance is sightly boosted on those tasks.\n\nThe paper is well-written. The h-detach method is very simple and easy to implement. It seems novel in dealing with the trainability issue with recurrent networks. Since LSTM is very commonly used, if the method is proved to be effective on other tasks, it will potentially benefit a large portion of the community. However, the reviewer thinks the paper is not sufficiently motivated and the quality of the paper could be further improved by conducting a more thorough analysis of the proposed method, and discussing the connection with other existing methods.\n\nAs the motivation of the work, the authors seem to claim that if the magnitude of $B_t$ is much bigger that $A_t$, then the backpropagation will be problematic. Is there any theoretical or empirical support of this claim?\n\nIn order to damp the gradient component of $B_t$, it does not have to be stochastic. Can we simply multiply the matrix $B_t$ by a constant factor $p$ during backpropagation? Or regularize the weights $W_{*h}$ to be small so that $\\phi_t$ and $\\tilde\\phi_t$ are small?\n\nIt would be interesting to study the effect of the probability $p$ and to suggest an ""optimal"" choice of $p$, either theoretically or empirically. Is it still possible to train the model with a very small $p$?\n\nThe h-detach method seems to have a flavor of dropout, but the ""dropout"" only happens during backpropagation. The design goal also resembles the peephole LSTM, that is to disentangle the cell state and the hidden state. Is there any possible connections between the proposed method and the dropout and peephole LSTM?\n\nThe reviewer understands that a one percent difference in the accuracy on MNIST is probably not very meaningful, but it seems that the SOTA performance on pMNIST is at least 94.1% [1].\n\n[1] Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. NIPS, 2016.', 'The author introduces a simple stochastic algorithm (h-detach) that is specific to LSTM optimization and targeted towards addressing this problem. Specifically, the authors show that when the LSTM weights are large, the gradient components through the linear path (cell state) in the LSTM computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which we show empirically), their suppression can prevent the LSTM from capturing them. Our algorithm prevents the gradients flowing through this path from getting suppressed, thus allowing the LSTM to capture such dependencies better. The experimental results show that the proposed algorithm appears to be effective. Some detailed comments are listed as follows, \n\n1 The h-detach algorithm seems to be the dropout technology. However, the authors did not discuss the relation or difference between the proposed h-detach algorithm and the dropout technology. \n\n2 The proposed method can transfer the positive knowledge. However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred. So how to avoid the negative transferring? Some necessary discussions about this should be given in the manuscript.\n\n2 There are many grammar errors in the current manuscript. The authors are suggested to improve the English writing.\n']","[-20, 20, 50]","[60, 80, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('intriguing results', 'paper is written clearly'), they express significant concerns and criticisms. They question the novelty and significance of the results, suggest alternative methods that achieve similar outcomes, and recommend more challenging experiments. The overall tone suggests that substantial revisions are needed.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'We do not think' and 'It is possible that we will improve our ratings' instead of making blunt criticisms. They also acknowledge positive aspects of the paper before presenting their concerns. The language is constructive, offering specific suggestions for improvement rather than just pointing out flaws.\n\nThe follow-up comments after the rebuttal show a slight improvement in sentiment, acknowledging that the paper has 'clearly improved' and increasing their score, which further supports the polite and constructive approach of the reviewer."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written, the method is simple and easy to implement, and it has potential to benefit a large portion of the community. However, they also express concerns about insufficient motivation and the need for more thorough analysis, which prevents a higher positive score. The politeness score is high (80) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive comments. They use phrases like 'the reviewer thinks' and 'it would be interesting to study' which maintain a polite and professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the effectiveness of the proposed algorithm and its experimental results, but also points out some areas for improvement. The review starts with a neutral summary of the work and then provides both positive feedback and constructive criticism. The politeness score is 20 (slightly polite) because the reviewer uses generally respectful language and offers suggestions rather than harsh criticisms. However, the tone is mostly neutral and professional rather than overtly polite. The reviewer uses phrases like 'the authors are suggested to' which is polite, but also directly points out issues like grammar errors without much softening language.""]"
"['This paper presents a class of neural networks that does not have bad local valleys. The “no bad local valleys” implies that for any point on the loss surface there exists a continuous path starting from it, on which the loss doesn’t increase and gets arbitrarily smaller and close to zero. The key idea is to add direct skip connections from hidden nodes (from any hidden layer) to the output.\n\nThe good property of loss surface for networks with skip connections is impressive and the authors present interesting experimental results pointing out that\n* adding skip connections doesn’t harm the generalization.\n* adding skip connections sometimes enables training for networks with sigmoid activation functions, while the networks without skip connections fail to achieve reasonable performance.\n* comparison of the generalization performance for the random sampling algorithm vs SGD and its connection to implicit bias is interesting.\n\nHowever, from a theoretical point of view, I would say the contribution of this work doesn’t seem to be very significant, for the following reasons:\n* In the first place, figuring out “why existing models work” would be more meaningful than suggesting a new architecture which is on par with existing ones, unless one can show a significant performance improvement over the other ones.\n* The proof of the main theorem (Thm 3.3) is not very interesting, nor develops novel proof techniques. It heavily relies on Lemma 3.2, which I think is the main technical contribution of this paper. Apart from its technicality in the proof, the statement of Lemma 3.2 is just as expected and gives me little surprise, because having more than N hidden nodes connected directly to the output looks morally “equivalent” to having a layer as wide as N, and it is known that in such settings (e.g. Nguyen & Hein 17’) it is easy to attain global minima.\n* I also think that having more than N skip connections can be problematic if N is very large, for example N>10^6. Then the network requires at least 1M nodes to fall in this class of networks without bad local valleys. If it is possible to remove this N-hidden-node requirement, it will be much more impressive.\n\nBelow, I’ll list specific comments/questions about the paper.\n* Assumption 3.1.2 doesn’t make sense. Assumption 3.1.2 says “there exists N neurons satisfying…” and then the first bullet point says “for all j = 1, …, M”. Also, the statement “one of the following conditions” is unclear. Does it mean that we must have either “N satisfying the first bullet” or “N satisfying the second bullet”, or does it mean we can have N/2 satisfying the first and N/2 satisfying the second?\n* The paper does not describe where the assumptions are used. They are never used in the proof of Theorem 3.3, are they? I believe that they are used in the proof of Lemma 3.2 in the appendix, but if you can sketch/mention how the assumptions come into play in the proofs, that will be more helpful in understanding the meaning of the assumptions.\n* Are there any specific reasons for considering cross-entropy loss only? Lemma 3.2 looks general, so this result seems to be applicable to other losses. I wonder if there is any difficulty with different losses.\n* Are hidden nodes with skip connections connected to ALL m output nodes or just some of the output nodes? I think it’s implicitly assumed in the proof that they are connected to all output nodes, but in this case Figure 2 is a bit misleading because there are hidden nodes with skip connections to only one of the output nodes.\n* For the experiments, how did you deal with pooling layers in the VGG and DenseNet architectures? Does max-pooling satisfy the assumptions? Or the experimental setting doesn’t necessarily satisfy the assumptions?\n* Can you show the “improvement” of loss surface by adding skip connections? Maybe coming up with a toy dataset and network WITH bad local valleys will be sufficient, because after adding N skip connections the network will be free of bad local valleys.\n\nMinor points\n* In the Assumption 3.1.3, the $N$ in $r \\neq s \\in N$ means $[N]$?\n* In the introduction, there is a sentence “potentially has many local minima, even for simple models like deep linear networks (Kawaguchi, 2016),” which is not true. Deep linear networks have only global minima and saddle points, even for general differentiable convex losses (Laurent & von Brecht 18’ and Yun et al. 18’).\n* Assumption 3.1.3 looked a bit confusing to me at first glance. You might want to add some clarification such as “for example, in the fully connected network case, this means that all data points are distinct.”', 'The paper analyzes the loss landscape of a class of deep neural networks with skip connections added to the output layer. It proves that with the proposed structure of DNN, there are uncountably many solutions with zero training error, and the landscape has no bad local valley or local extrema. \n\nOverall I really enjoy reading the paper. \nThe assumptions to aid the proof are very natural and much softer than the existing literature. As far as I’m concerned, the setting is very close to real deep neural networks and the paper is a breakthrough in the area. The experiments also consolidate that the theoretical settings are natural and useful, namely, with enough skip connections and specially chosen activation functions. \nThe presentation of the paper is intuitive and easy to follow. I’ve also checked all the proof and think it’s brilliantly and elegantly written. \n\nMy only complaint is about the experiments. As we all know that both VGG and the sigmoid activation are commonly used DL tools, and why do they fail to generalize when used together? Does the network fail to converge or is it overfitting? The authors should try tuning the parameters and present a proper result. With that said, since the paper is more about theoretical findings, this issue doesn’t influence my recommendation to accept the paper.\n\n\nMinor issues:\nI think it’s better to formally define “bad local valley” somewhere in the paper. From what I read, the definition of “bad local valley” is implied by the abstract and in the proof of Theorem 3.3(2), but I did not find a formal definition anywhere else. \nIn proof number 4 (of Theorem 3.3), the statement should be “any *principle* submatrices of negative semi-definite matrices are also NSD”, and it’s not true otherwise. But this typo doesn’t influence the proof. \nAlso, it seems the proof of 3 is somewhat redundant, since local minimum is a special case of your “bad local valley”. \nIt seems the analysis could not possibly be extended to the ReLU activation, since it will break the analytical property of the function. Just out of curiosity, do the authors have some further thoughts on non-differentiable activations?\n', 'This paper shows that a class of deep neural networks have no spurious local valleys –--implying no strict local-minima. The family of neural networks studied includes a wide variety of network structure such as (a variant of) DenseNet. Overall, this paper makes some progress, improving previous results on over-parametrized networks. \n\nPros: The flexibility of the network structure is an interesting point.\nCons: CNN was covered in previous related works (so weight sharing is not a new contribution); DenseNet is not explicitly covered in this work (I mean current DenseNet does not have N skip-connections to output; correct me if wrong). \n  The simulation part is not that clear, and I have a few questions that I hope the authors can answer. \n\nSome comments/suggestions:\n1) Training error needs to be discussed.\n   Page 8 says “This effect can be directly related to our result of Theorem 3.3 that the loss landscape of skip-networks has no bad local valley and thus it is not difficult to reach a solution with zero training error”. This relation is not justified. The implication of Thm 3.3 is that getting zero training error is easier, but the tables are only for test error. Showing training error is the only way to connect to Thm 3.3. I expect to see a high training error for C-10, original VGG and sigmoid activation functions, and zero training error for both skip-SGD (rand) and skip-SGD (SGD). \n    This paper has no theory on generalization, thus if a whole section is just about “investigating generalization error”, then the connection to theoretical parts is weak --btw, one connection is the comparison of two algorithms, which fits the context well, and thus interesting (though comparison result itself probably not surprising).   \n\n2) Data augmentation.\n  “Note that the rand algorithm cannot be used with data augmentation in a straightforward way and thus we skip it for this part.” Why? \n   With data augmentation, is M still larger than N? If yes, then the number of added skip connection is different for C-10 and C-10-plus, which is not mentioned in the instruction of Table 2. \n\n3)It may be better to mention explicitly that ""it is possible to have bad local min"" –perhaps in abstract and/or introduction. \n  --Although “no sub-optimal strict local minima” is mentioned, readers, especially non-optimizers, might not notice ""strict"".\n  --In fact, in the 1st round read, I do not have a strong impression of ""strict"". Later I realized it. Mentioning this can be helpful. \n\n4) Some references I suggest to include:\n   [R1] Yu, X. and Chen, G. On the local minima free condition of backpropagation learning. 1995.  --related work. \n   [R2] Lu, H., Kawaguchi, K. Depth creates no bad local minima. 2017. --also deep nets.\n   [R3] Liang, S., Sun, R., Li, Y., & Srikant, R. ""Understanding the loss surface of neural networks for binary classification."" 2018. --Also study SoftPlus neurons.\n   [R4] Nouiehed, M., & Razaviyayn, M. Learning Deep Models: Critical Points and Local Openness. 2018. --also deep nets. \n\nMinor questions:\n  --Exact 10% test accuracy for a few cases. Why exact 10%?\n']","[-20, 90, 20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'impressive' results, 'interesting experimental results'), they express significant criticisms about the theoretical contribution. The reviewer states that 'the contribution of this work doesn't seem to be very significant' and provides several reasons for this assessment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as constructive feedback. They use phrases like 'I would say,' 'I think,' and 'I wonder,' which soften the critique. The reviewer also provides specific suggestions for improvement and asks clarifying questions, which is a polite way to address concerns."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They use phrases like 'I really enjoy reading the paper,' 'the paper is a breakthrough in the area,' and 'brilliantly and elegantly written.' The only negative point is a minor complaint about experiments, which the reviewer states doesn't influence their recommendation to accept. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They offer constructive feedback and suggestions in a polite manner, using phrases like 'I think it's better to' and 'Just out of curiosity.' The reviewer also acknowledges the paper's strengths before mentioning any criticisms, which is a polite approach. The score is not 100 as there is some direct criticism, albeit expressed politely."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper 'makes some progress' and has 'interesting' points, but also lists several cons and areas for improvement. The overall tone is constructive rather than overtly negative or enthusiastic. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'I hope the authors can answer', 'It may be better to...'), and balances critique with positive comments. The reviewer also uses polite phrases like 'please' and 'I suggest'. However, it's not extremely formal or overly deferential, maintaining a professional tone.""]"
"['There has been a lot of work on limited precision training and inference for deep learning hardware, but in most of this work, the accumulators for the multiply-and-add (FMA) operations that occur for inner products are chosen conservatively or treated as having unlimited precision. The authors address this with  an analytical method to predict the number of mantissa bits needed for partial summations during the forward, delta and gradient computation ops for convolutional and fully connected layers. They propose an information theoretic approach to argue that by using fewer bits of mantissa in the accumulator than necessary, the variance of the resulting sum is less than what it would have been if sufficient bits of mantissa were used. This is surprising to me, as quantization is usually modeled as _adding_ noise, leading to an _increase_ in variance (Mc Kinstry et al. 2018), so this is a nice counterexample to that intuition. Unfortunately the result is presented in a way that implies the variance reduction is what causes the degradation in performance, while obviously (?) it\'s just a symptom of a deeper problem. E.g., adding noise or multiplying by a constant to get the variance to where it should be, will not help the network converge. The variance is just a proxy for lost information. The authors should make this more clear.\n\nLoss of variance is regarded as a proxy to the error induced/loss of information due to reduced mantissa prevision. The authors present their metric called Variance Retention Ratio (VRR) as a function of the mantissa length of product terms, partial sum (accumulator) terms, and the length of the accumulation. Thereafter, the mantissa precision of the accumulator is predicted to maintain the error of accumulation within bounds by keeping the VRR as close to 1 as possible. The authors use their derived formula for VRR to predict the minimum mantissa precision needed for accumulators for three well known networks: AlexNet, ResNet 32 and ResNet 18. For tightness analysis they present convergence results while perturbing the mantissa bits to less than those predicted by their formula, and show that it leads to more than 0.5% loss in the final test error of the network.\n\nSome questions that the manuscript leaves open in it\'s current form:\n\n0. Does this analysis only apply to ReLu networks where all the accumulated terms are positive? Would a tanh nonlinearity, e.g. in an RNN, result in a different kind of swamping behavior? I don\'t expect the authors to add a full analysis for the RNN case if it\'s indeed different, but it would be nice to comment on it. \n1. Do the authors assume that the gradients and deltas will always be within the exponent range of representation? I do not find a mention of this in the paper. In other words, are techniques like loss scaling, etc. needed in addition? Other studies in literature analyzing IEEE fp16 seem to suggest so.\n2. The authors do not provide details on how they actually performed the experiments when running convergence experiments. It is not straightforward to change the bit width of the accumulator mantissa in CPU or GPU kernel libraries such as CUDNN or Intel MKL. So how do they model this?\n3. On page 7, the authors point out that they provide a theoretical justification of why the chunk size should neither be too small or too large - but I do not see such a justification in the paper. More detailed explanation is needed.\n\nThere are a few minor typos at a few places, e.g.\n \n1. Page 4: “… , there is a an accumulation length….”\n2. Page 6: “…floaintg-point format…""\n\nSome figures, notably 2 and 5, use text that is unreadably small in the captions. I know this is becoming somewhat common practice in conference submissions with strict pages limits, but I implore the authors to consider shaving off space somewhere else. Some of us still read on paper, or don\'t have the best eyes!', ""Quality and clarity:\nThe paper presents a theoretical framework and method to determine the necessary number of bits in a deep learning networks. The framework predicts the smallest number of bits necessary in the (multiply-add) calculations (forward propagation, backward propagation, and gradient calculation) in order to keep the precision at an acceptable level. \n\nThe statistical properties of the floating-point calculations form the basis for the approach, and expressions are derived to calculated the smallest number of bits based on, e.g., the length of the dot product and the number variance. \n\nThe paper seems theoretically correct, although I haven't studied the appendices in detail. The experimental part is good, using three networks of various sizes (CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet) as benchmarks. The experimental results support the theoretical predictions. \n\nOriginality and significance:\nThe paper seems original, at least the authors claim that no such work has been done before, despite the large amount work done on weight quantization, bit reduction techniques, etc. The paper may have some significance, since most earlier papers have not considered the statistical properties of the reduced precision calculations.\n\nPros:\n* Interesting topic\n* Theoretical predictions match the practical experiments\n\nCons:\n* Nothing particular\n\nMinor:\n* Fig 5a. The curve for m_acc = 13 does not seem to follow the same pattern as the other curves. Why?\n* Motivate why you have selected the networks that you have in the evaluation.\n"", ""The authors conduct a thorough analysis of the numeric precision required for the accumulation operations in neural network training. The analysis is based on Variance Retention Ratio (VRR), and authors show the theoretical impact of reducing the number of bits in the floating point accumulator. And through extensive benchmarks with popular vision models, the authors demonstrate the practical performance of their theoretical analysis.\n\nThere are several points that I am not particularly clear about this work:\n\n1) In section 4.4, the authors claim to use v(n) < 50 as the cutoff of suitability. This is somewhat arbitrary. As one can imagine, for an arbitrary model of VRR, we can find an empirical cutoff that seems to match benchmarks tightly. Or put it another way, this is a hyperparameter that the authors can tune to match their chosen benchmarks. It would be more interesting to see a detailed study on this cutoff on multiple datasets.\n\n2) Again the 0.5% accuracy cutoff from baseline in the experiment section is also another similar hyperparameter.\n\nIt would be more convincing if we can see a fuller picture of the training dynamics without these two hyperparameters clouding the big picture.\n\nHaving said this, I appreciate the authors' effort in formally studying this problem.""]","[50, 80, 50]","[80, 60, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and value of the work, calling it a 'nice counterexample' to existing intuitions. However, they also point out several areas for improvement and clarification. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively, and even apologizes for a common but frustrating practice ('I implore the authors to consider shaving off space somewhere else'). The reviewer balances positive feedback with specific, actionable suggestions for improvement, maintaining a professional and courteous tone throughout."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'theoretically correct,' with 'good' experimental parts, and note that the results support the theoretical predictions. The reviewer also mentions 'pros' without any significant 'cons,' indicating a positive overall assessment. The politeness score is 60 (moderately polite) because the reviewer uses neutral, professional language throughout. They offer constructive feedback and suggestions without harsh criticism. The use of phrases like 'seems theoretically correct' and 'may have some significance' shows a respectful and considerate tone. The reviewer also frames their minor points as questions rather than direct criticisms, which adds to the politeness."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the thoroughness of the analysis and appreciates the authors' efforts, but also expresses some concerns about the methodology. The opening paragraph is generally positive, praising the 'thorough analysis' and 'extensive benchmarks'. However, the reviewer then raises two main points of criticism, which temper the overall positive sentiment.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful language throughout and frames their criticisms constructively. They use phrases like 'I am not particularly clear about' and 'It would be more interesting to see' rather than making blunt criticisms. The review concludes with a positive note, saying 'I appreciate the authors' effort in formally studying this problem', which is a polite way to end even after raising concerns.""]"
"['This paper shows that deep convolutional networks (CNNs, without pooling) with a suitable prior over weights can be seen as shallow Gaussian processes (GPs) with a specific covariance function. It shows that this covariance function can be computed efficiently (when compared to previous attempts at resembling convolutional networks with GPs), with a cost that only depends linearly on the number of layers and the input dimensionality, i.e.~O(N^2 L D). \n\nTo show the equivalence between deep CNNs and shallow GPs, the paper uses similar ideas to those proposed by Matthews et al (2018a) and Lee et al (2017), i.e. using the multivariate central limit theorem in very large networks, where in the case of this paper the limit is taken as the number of channels at each layer goes to infinity. Therefore, from a theoretical perspective, these ideas have been proposed before. However, the paper presents a novel efficient way to compute the convolutional kernel, which I believe has merits on its own. \n\nHowever, the model setting for classification (where deep CNNs have been successful) and consequent evaluation on the MNIST dataset is less than convincing. One of the main motivations for Bayesian CNNs and GPs (and the paper argue for this in the intro) is to be able to provide good uncertainty estimates. However, the classification problem is framed in a regression setting, where neither probabilistic estimates are evaluated or even provided. Indeed, only the error rate is given on Table 1. To me, this is certainly not enough for a Bayesian/GP method and it is a critical deficiency of the paper in its current form. While I understand having a non-Gaussian likelihood will complicate things and conflate the kernel contribution with the approximations, I believe it is necessary to provide and evaluate such probabilistic estimates and compare them to other GP approaches (even using other less than satisfying methods such as calibration/scaling). Along a similar vein, it is unclear what objective function was used for hyper-parameter learning but, given that the authors actually “sample hyper-parameters”, I am guessing a proper probabilistic objective such as the marginal likelihood is out of the question.\n\nOther (perhaps minor) deficiencies is that the method is not scalable to large datasets (I am even surprised the authors managed to run this on full MNIST) and that no theoretical analysis is done (e.g. as in Mattews et al, 2018a). \n\nMinor comments:\n\n* In the intro, “Other methods such as Gaussian Processes”: GPs are not a method and I believe the authors really mean here Gaussian process regression. \n* The prior variance over filters in Eq (3) divides over the number of channels.  Why does a Gaussian prior with infinite precision make sense here?\n* The authors should report the state of the art of using GPs for MNIST classification using non-convolutional kernels).\n', 'This paper\n\n1) extends an argument for the GP behaviour of deep, infinitely-wide fully-connected networks to convolutional and residual deep neural networks with infinitely many channels and\n2) provides a computationally tractable approach to compute the corresponding GP kernel. This kernel has few hyper-parameters, and achieves state-of-the-art results on the MNIST dataset. \n\nWhile point (1) is a relatively straightforward adaptation of Lee et. al (2017) and Matthews et al. (2018) to a different network structure, point (2) is original and non-trivial. All in all, I think this paper makes a significant contribution that I believe will spark interesting follow-up work (hinted at in the last section of the paper).\n\nQuestions:\n\n- In my understanding, the kernels of Section 3 do not require the weight matrices W to share the same values across rows. Accordingly, their performance cannot necessarily be explained by properties of convolutional filters (in particular translation invariance). Can the authors comment on that?\n- What would be the performance of a parametric CNN trained with SGD that matches the architecture (# layers) & the squared loss function of ResNet GP? The only point of comparison is Chen & al. (2018), which I suppose optimizes a log loss? Specifically, I would like to understand the impact of the loss function and of the number of layers on the relative performance of the two approaches.\n\nThe paper is clear and easy to follow. A few suggestions:\n\n- I recommend turning the argument in section 2.2 into a formal, self-contained theorem that states a result on A_L, defined in eq. 17 (which I would move to the main text). This would make the precise claim easier to understand.\n- I suggest including a more thorough discussion of the results. Table 1 is only introduced in the related work section.\n- If space is a concern, I would move part of Section 2.2 outside of the main text, since it mostly follows Lee et al. & Matthews et al\n\nSmall questions/comments:\n\n- Eqs 1 and 2: b_j should be multiplied by the all-ones vector, just like in (5) and (6).\n- Below eq. 5: ""while the *elements of the* feature maps themselves display...""\n- Paragraph above eq. 7: ""in order to achieve an output suitable for *binary* classification or *univariate* regression""\n- Paragraph above eq. 7: ""if we only need the covariance at *certain* locations in the outputs...""\n- Algorithm 1: you might want to add a loop over g for clarity', 'The current paper considers the relation between convolutional neural networks and Gaussian processes from theoretical and practical point of view.\n\nThe main contribution of the paper as presented by the authors is 2-fold:\n1. Some theoretical justifications about the correspondence between GPs and convolutional networks with infinitely many channels are provided.\n2. The formulas for GP kernel computation for the considered network is provided and some experiments are conducted (on MNIST).\n\nI personally enjoy the ideas of the close relation between certain types of neural networks and GPs and I really like the idea of authors that kernels based on convolutional networks might be more practical compared to the ones based on fully connected networks. It might be easier to encode certain invariance for complex objects via multilayered structures then via more simple explicit kernels.\n\nHowever, I see couple of important issues:\n1. The theoretical justification provided is basically heuristic argument and, speaking rigorously, is not a theorem. The proper proof should be based not on layer-by-layer convergence, but on the convergence with all the parameters tending simultaneously to infinity (see Matthews et al, 2018). Also, I doubt that the limit with infinite number of channels is as meaningful as the limit with infinite width of layer, as wide networks are used much more often in practice than networks with many channels.\n2. The practical applicability is very limited as the kernel obtained has very high computational complexity. The authors theirselves comment that computing kernel matrix takes more time than inverting it. Thus, the applicability beyond MNIST is a big question for the proposed approach.\n\nTo sum up, I think that the present paper targets an important direction of work, but the contribution itself is somehow limited (and relative obvious based on the recent papers on relation between fully connected networks and GPs).']","[-20, 80, -20]","[60, 90, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merits of the paper, they also point out several critical deficiencies and areas for improvement. The reviewer states that the paper presents 'a novel efficient way to compute the convolutional kernel, which I believe has merits on its own.' However, they also mention that the classification problem framing is 'less than convincing' and that the lack of probabilistic estimates is a 'critical deficiency.' The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They acknowledge the paper's contributions while providing constructive criticism. The reviewer uses phrases like 'I believe' and 'I understand' to soften their critiques, and they offer specific suggestions for improvement rather than just pointing out flaws."", ""The sentiment score is 80 (positive) because the reviewer states that the paper makes a 'significant contribution' and will 'spark interesting follow-up work'. They also mention that part of the work is 'original and non-trivial'. The overall tone is very positive, with only minor suggestions for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions ('I recommend...', 'I suggest...'), and asks questions rather than making demands. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses enjoyment of the ideas and the direction of work, they also point out significant limitations and issues with the paper's theoretical justification and practical applicability. The reviewer's tone suggests that the paper's contribution is limited and somewhat obvious based on recent work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the importance of the research direction, and balances criticism with positive comments. They use phrases like 'I personally enjoy' and 'I really like the idea' before presenting their concerns, which maintains a polite tone even when critiquing the work.""]"
"['Paper’s contributions:\nThis paper considers the challenging problem of generalizing well to new RL tasks, based on having learned on a set of previous related RL tasks.  It considers tasks that differ only in their reward function (assume the dynamics are identical), and where the reward functions are constrained to be linear combinations over a set of given features.  The main approach, Universal Successor Features Approximators (USFAs) is a combination of two recent approaches:  Universal Value Function Approximators (UVFAs) and Generalized Policy Improvement (GPI).  The main claim is that while each of these methods leverages different types of regularity when generalizing to new tasks, USFAs are able to jointly leverage both types (and elegantly have both other methods as special cases).\n\nSummary of evaluation:\nOverall the paper tackles an important problem, and provides careful explanation and reasonably extensive results showing the ability of USFA to leverage structure.  I’m on the fence because I really wish the combination of generalization properties could be understood in a more intuitive way.  There are some more minor issues, such as lack of complexity analysis and a few notation details, that can be easily fixed.\n\nPros:\n-\tThe problem of generalizing to new tasks in RL is an important open problem.\n-\tThe paper is carefully written and provides clear explanation of most of the methods & results.\n\nCons:\n-\tThe authors are diligent about trying to explain what type of regularities are exploited by each of UVFAs and GPI, and how this can be combined in USFAs.  However despite reading these parts carefully, I could not get a really good intuition, either in the methods or in the results, for the nature of the regularities exploited, and how it really differs.  Top of p.4 says that GPI generalizes well when the policy \\pi(s) does well on task w’.  Can you give a specific MDP where Q is not smooth, but the policy does well?\n-\tThere is no complexity analysis.  I would like to know the computational complexity of each of the key steps in Algorithm 1 (with comparison to simple UVFA and GPI).\n-\tIt would be useful to see the empirical comparison with the approach of Ma et al. (2018), which also combines SFs and UFVAs. I understand there are differences in the details, but I would like to see confirmation of whether the claims about USFA’s superior ability to exploit structure is supported by results.\n\nMinor comments:\n-\tThe limitation to linear rewards is a reasonably strong assumption.  It would be good to support this, e.g. by references to domain that meet this assumption.\n-\tIt seems the mathematical properties in Sec.3.1 could be further developed.\n-\tP.4: “Given a deterministic policy \\pi, one can easily define a reward function r_\\pi”.  I did not think this mapping was unique (see the literature on IRL, e.g. Ross et al.).  Can you provide a proof or reference to support this statement?\n-\tThe definition of Q(s,a,w,z) is interesting. Can this be seen as a kernel between w and z?\n-\t\\theta suddenly shows up in Algorithm 1. I presume these are the parameters of Q?  Should be defined.\n-\tThe distribution used to sample policies seems to be a key step of this approach, yet not much guidance is given on how to do this in general.\n', ""This paper proposes new ideas in the context of deep multi-task learning for RL. Ideas seem to me to be a rather small (epsiilon) improvement over the cited works.\n\nThe main problem - to me - with described approach is that the Q* value now lives in a much higher dimensional space, levelling any advantage a subsequent heuristic might give. \n\nStatements as 'Although this work is superficially similar to ours, it differs a lot in the details' makes clear that this work is only of potential interest for a rather small audience, a tenet also supported by the density of presentation. I leave it to the AC to decide on relevance. \n\n"", 'The goal here is multi-task learning and generalization, assuming that the expected one-step reward for any member of the task family can be written as $\\phi(s,a,s\')^T w$. The authors propose universal successor features (USF) $\\psi$s, such that the action-value functions Q can be written as $Q(s,a,w,z)=\\psi(s,a,z)^T w$, generalizing over mutiple tasks each denoted by $w$, and multiple policies each denoted by $z$. Here, $z$ represents the optimal policy induced by a reward specified by $z$ (from the same set as $w$). Using USFs $\\psi$-s, the Q values can be interpolated across policies and tasks. Due to the disentangling of reward and policy generalizations, the training sets for $w$ and $z$ can be independently sampled. The authors further generalize a temporal difference error in these USFs $\\psi$s, using the TD error to learn to approximate the $\\psi$s by a network (USF Approximator i.e USFA). They then test the generalization capabilities of these USFAs on families of a simple task and a DeepMind Lab based task.\n\nI find this paper a good fit for ICLR as the paper significantly advances learning representations for Q values that generalize across policies and tasks.\n\nSome issues to consider:\n1. Given a policy, I would think that the reward function that induces this policy is not unique. This non-uniqueness probably doesn\'t matter for the USF development, since the policies are restricted to those induced by z-s (from the same set as w-s), but the authors should clarify this point.\n\n2. I suppose there are no convergence guarantees on the $\\psi$-learning?\n\n3. I do believe that this work goes reasonably beyond the Ma et al 2018 paper, and the authors do clarify their advance especially in incorporating generalized policy improvement. However, the authors way of writing makes it appear as if their work only differs in some details. I recommend to remove this unexplanatory sentence:\n""Although this work is superficially similar to ours, it differs a lot in the details.""\n\nMinor:\npage 3: last but one line: ""more clear"" --> ""clearer""\npage 3: ""In contrast"" --> ""By contrast"" -- but this is not a hard rule\n']","[20, -50, 80]","[60, -20, 60]","[""Sentiment Score (20): The review begins with a positive tone, acknowledging the paper's importance and careful explanation. However, it also expresses some reservations ('I'm on the fence') and lists several cons. The balance of pros and cons, with a slight lean towards positive, justifies a mildly positive score of 20.\n\nPoliteness Score (60): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I really wish' and 'It would be useful' instead of more demanding language. The cons and criticisms are presented as suggestions for improvement rather than harsh critiques. The reviewer also acknowledges the authors' efforts ('The authors are diligent about trying to explain'). However, the language is not overly formal or deferential, hence a score of 60 indicating politeness above neutral but not extremely high."", ""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper. They describe the work as a 'small improvement' and point out a 'main problem' with the approach. The phrase 'only of potential interest for a rather small audience' further indicates a negative sentiment. However, it's not extremely negative as they leave the final decision to the AC. The politeness score is -20 because while the language isn't overtly rude, there are some dismissive and blunt statements. The phrase 'Ideas seem to me to be a rather small (epsiilon) improvement' and the criticism of the paper's statement about similarity to other work are somewhat impolite. The overall tone is more critical and direct than polite, but it doesn't descend into outright rudeness."", ""The sentiment score is 80 because the reviewer states that the paper is 'a good fit for ICLR' and 'significantly advances learning representations for Q values'. This indicates a highly positive view of the paper's contribution. The score is not 100 as there are some issues and recommendations mentioned. The politeness score is 60 because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They use phrases like 'I find' and 'I recommend' which are polite ways to express opinions. However, the tone is primarily neutral and professional rather than overtly polite, hence the score is not higher. The reviewer also directly points out issues and corrections, which, while not impolite, prevents the score from being in the highest range.""]"
"[""This paper has 3 principal contributions: it proposes a different way of measuring mutual information in a neural network, proposes a compression score to compare different models, then empirically analyses different activation functions and L2 weights.\n\nThis work seems like a welcome addition to the IB thread. To me the most interesting result is simply that activation functions aren't simply about gradient flow, and that they may each have properties that are more or less desirable depending on the domain they might be used on. The authors are careful in the wording of their conclusions, I think with reason; while these results are useful in that there seem to be consistently different behaviors coming from different hyperparameters, information planes show a relatively qualitative part of the picture.\n\nQuantitatively, the proposed compression score is interesting, but as the authors say, simplistic. It seems to me that we care more about the converged models than the whole training trajectory; how does this score evolve with time?\n\nI think an important part of discussion that lacks in this paper is a more in-depth take as to how these findings relate to the Zhang et al [1] memorization vs generalization paper and its follow ups. There seem to be many links to be drawn.\n\nThis work is overall a good contribution, but I'll have to agree with the authors' conclusion that more principled analysis methods are required to have a solid grasp of the training dynamics of DNNs. The writing of the paper is good, but the writing of the captions could be improved. (the hard page limit of ICLR is 10 pages and your paper has a lot of captions, so I think investing into a bit more text would be good)\n\n\nComments:\n- It might be worth to re-explain what the information plane plots are in a figure caption, not just in the text (the text also doesn't really explain that each point is a moment in training, and each thread a different layer, this paper should be readable by someone who has never seen these plots before). \n- It's not clear what is going on in figure 5, I can guess but, again, this paper should be readable by anyone in the field. You mention different initializations, but which exactly? What makes you say that 5c has no compression but that 5a does compression first? It should be explained explicitly.\n- I believe what you say about Figure 8, but the plots are so similar that it is hard to compare them visually. Maybe a different kind of superposition into a single plot would better illustrate the compression effect of L2?\n- Typo in the x axis caption of figures 9.\n- Figure 9a is not readable in greyscale (or by a colorblind person), consider using a different symbol for the softmax scatter (and adding this symbol to the legend).\n- The first Schmidhuber citation of the paper seems a bit out of place. I think he himself would say that deep learning has been going on for much longer than since 2015. (in fact I think you could just remove the entire first paragraph, it is just unnecessary boilerplate)\n- Why should there be a direct correlation between compression and generalization? For example, it is known that training DNNs with soft targets improves test accuracy in classification, or even forcing softness in both targets and representations [2] also improves test accuracy.\n- I'm still personally not sold on binning as a strategy to evaluate MI. Did you perform experiments that show that the observed difference is consistent if more computation is done to approximate MI, and not just an artefact of max-entropy binning?\n\n[1] Zhang et al (2016) https://arxiv.org/abs/1611.03530\n[2] Verma et al (2018) https://arxiv.org/abs/1806.05236\n"", 'This paper proposes a method for the estimation of mutual information for networks with unbounded activation functions and the use of L2 regularization to induce more compression.  The use of information planes to study the training behavior of networks is not new.  This paper addresses the issue of unbounded  hidden state activities.  As the differential mutual information in DNN is ill-defined, the authors proposed to add noise to the hidden activity by using the binning process.   It is not clear in the paper that if the binning is applied just for visualizing the information plane or for computing the activities of hidden units in upper layers.   If it is the latter one, it creates unnecessary distortions to the DNN.  As the authors pointed out, different initializations can lead to different behaviour on the information plane.  It would be difficult to draw conclusions based on the experimental results, even they come from the average of 50 individual networks.  Also, the experiences are performed using a particular task, it is not sure if similar behavior is observed in other tasks.   It is, however, more important to understand what makes the compression.   For the L2 regularization, the compression is expected as the regularization tends to limit the values of the  weights. ', ""The authors of this paper studied the popular belief that deep neural networks do information compression for supervised tasks. They studied this compression behavior with tanh and ReLU (and it's variants) activation functions which are saturating and non saturating in nature respectively. \n\nThe compression score is computed using Mutual Information Estimation which when computed are usually infinite. For finite mutual information values, noise can be added to hidden activations. For this purpose, two approaches namely Entropy Based Binning(EBAB) and adaptive Kernel Density Estimation(aKDE) were explored. EBAB adds noise to the hidden activations by binning and aKDE by Gaussian noise. Their results show that both EBAB and aKDE exhibit compression in case of ReLU, although this behavior is the strongest in tanh. \n\nFinally, When compression score was plotted against accuracy, higher rates of compression did not show significant correlation with generalization. Hence showing evidence that generalization(or good performance) can be achieved even without information bottleneck(information compression).\n\nQualms:\n1. Figure 7's description that ELU, Swish and centered softplus functions doing compression is not very apparent. \n2. Figure 9b: Regression line between compression score and accuracy shows a positive correlation between them. This seems contradictory to the inference.\n3. The experiments were done on a 5-layer network with 10-7-5-4-3 nodes respectively on a toy data of 12-bit binary vectors. The study could have included bigger networks with popular datasets which would give substantial support to the trend observed on toy data.""]","[60, -20, 50]","[80, 0, 70]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as a 'welcome addition' and a 'good contribution'. They highlight interesting aspects of the work and its usefulness. However, they also point out areas for improvement and further analysis, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'I think' and 'It might be worth' when making suggestions, and acknowledge the authors' careful wording. The reviewer also provides specific, helpful feedback without being harsh or dismissive. The slightly lower score accounts for the direct nature of some comments, which is typical in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution in addressing unbounded hidden state activities, they express several concerns and uncertainties about the method and its applicability. The reviewer points out limitations such as potential distortions to the DNN, difficulty in drawing conclusions from the results, and uncertainty about the method's effectiveness in other tasks. The politeness score is neutral (0) as the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. They present their critiques in a straightforward manner without using overly harsh language or excessive praise. The review focuses on the technical aspects of the paper without personal comments or emotional language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' work and findings without strong criticism. They describe the study's methods and results in a neutral tone, showing interest in the topic. However, they do raise some 'qualms' at the end, which prevents a higher positive score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, presenting their concerns as 'qualms' rather than harsh criticisms. They describe the paper's content objectively and offer constructive suggestions for improvement. The use of neutral, academic language and the absence of personal attacks or dismissive comments contribute to the polite tone.""]"
"[""The main contribution of this paper in practice seems to be a way to initialize the Continuous Matrix Space Model so that training actually converges, followed by a slightly different contrastive loss function used to train these models. The paper explores the pure matrix model and a mixed matrix / vector model, showing that both together improve on simpler methods on many benchmark tasks.\n\nMy main concern is that the chained matrix multiplication involved in this method is not substantially simpler than an RNN or LSTM sentence encoding model, and there are no comparisons of training and inference cost between the models proposed in this paper and conceptually simpler RNNs and LSTMs. The FastSent paper, used here as a baseline, does compare against some deep models, but they choose far more complex baselines such as the NMT encoding, which is trained on a very different loss function. Indeed the models proposed here do not seem to outperform fasttext and fastsent despite having fairly similar computational costs.\n\nI think this paper could use a little more justification for when it's appropriate to use the method proposed here versus more straightforward baselines."", ""\nThe authors propose CMOW, an extension of the CBOW model that allows the model to capture word order. Instead of each word being represented as a vector, words are represented by matrices. They extend the CBOW objective to take into account word order by replacing the averaging of vectors to create the context with matrix multiplication (a non-commutative operation). This is the first time this model has been applied in a large scale unsupervised setting. They are able to do this using their objective and an initialization strategy where the matrix embeddings are set to the identity matrix with some Gaussian noise added.\n\nThe results of this paper are its main weakness. I did enjoy reading the paper, and it is nice to see some results using matrices as embeddings and matrix multiplication as a compositional function. They include a nice analysis of how word order is captured by these CMOW embeddings while CBOW embeddings capture the word content, but it doesn't seem to make much of a difference on the downstream tasks where CBOW is better than CMOW and close to the performance of the hybrid combination of CBOW and CMOW.\n\nI think it's clear that their model is able to capture word information to some extent, but other models  (RNNs etc.) can do this as well, that admittedly are more expensive, but also have better performance on downstream tasks. I think a stronger motivation for their method besides an analysis of some phenomena it captures and a slight improvement on some downstream tasks when combined with CBOW is needed though for acceptance. Could it be used in other settings besides these downstream transfer tasks?\n\nPROS:\n- introduced an efficient and stable approach for training CMSM models\n- Show that their model CMOW is able to capture word order information\n- Show that CMOW compliments CBOW and a hybrid model leads to improved results on downstream tasks. \n\nCONS\n- The results on the hybrid model are only slightly better than CBOW. CMOW alone is mostly worse than CBOW."", ""The paper presents new training schemes and experiments for a matrix-multiplicative variant of CBOW. This variant is called a CMSM (Yessenalina and Cardie, 2011; Asaadi and Rudolph, 2017) which swaps the bag of vectors to a product of square matrices for encoding context to incorporate word ordering. It seems this model has not been trained successfully before (at least with a simple approach) due to the vanishing gradient problem.\n\nThe paper's main contributions are an initialization scheme for context matrices (to I + [N(0,0.1)]) to counter the vanishing gradient problem and a modification of the CBOW objective so that the target word is drawn uniformly at random from the context window (rather than the center word). Both are shown to improve the quality of learned representations when evaluated as sentence embeddings. Concatenating CBOW and CMSM architectures is additionally helpful. \n\nI was not aware of the matrix-multiplicative variant of CBOW previously so it's possible that I don't have the expertise to judge the novelty of the approach. But the idea is certainly sensible and the proposed strategies seem to work. The main downside is that for all this work the improvements seem a little weak. The averaged fastText embeddings are clearly superior across the board, though as the authors say it's probably unfair to compare based on different training settings. But this doesn't hurt the simplicity and effectiveness of the proposed method when compared against CBOW baselines. ""]","[-20, -20, 50]","[50, 60, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express concerns about the method's complexity and lack of comparisons with simpler models. The reviewer also suggests that the proposed models don't significantly outperform simpler baselines. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, presenting their concerns as constructive criticism rather than harsh judgments. They use phrases like 'My main concern is...' and 'I think this paper could use...' which maintain a polite tone while still conveying their critiques."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('I did enjoy reading the paper', 'nice to see some results'), they express significant concerns about the results being the 'main weakness' and the need for 'stronger motivation'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balances criticism with praise ('PROS' and 'CONS' sections), and phrases criticisms constructively ('I think a stronger motivation... is needed'). The reviewer maintains a professional tone without harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and finds the ideas sensible and effective, but also notes that the improvements seem 'a little weak' compared to some baselines. The overall tone is constructive and appreciative of the work, despite some reservations. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges their potential lack of expertise in judging novelty, and frames criticisms in a balanced way. The reviewer also highlights positive aspects of the work alongside areas for improvement, maintaining a professional and courteous tone.""]"
"['Understanding the stationary equilibrium helps to understand the practical performance of stochastic gradient descent. In this paper, the authors propose two fluctuation-dissipation relation to link measurable quantities and hyperparameters in the stochastic gradient descent algorithm. An advantage over the existing study is that the results here hold for any stationary state and do not need the analogy with continuous-time differential equations. Empirical results are also reported to verify these fluctuation relation.\n\nComments:\n\n(1) I do not quite understand the second identity of (16). In particular, it seems that the authors replace the first two $\\theta(t+1)$ with $\\theta(t)$, and do not use this replacement for the third $\\theta(t+1)$ (this was addressed by (1)).\n\n(2) It would be helpful to the readers if the authors can give the deduction process of (12). It is not easy for me to understand how it holds.\n\n(3) It is not clear to me how the second fluctuation-dissipation relation helps to determine the properties of loss function landscape.\n\n(4) In Section 2.3.1, can you give some explanation for the harmonic approximation. Also the notation $\\theta^*$ seems not to be defined.', 'The authors establish a stationary fluctuation-dissipation theorem and derive two specific fluctuation-dissipation relations. The authors use the first relation to check the stationarity and the second relation to delineate the shape of the loss-function landscape.\nTo verify their claim, the authors further use the relations to set the learning-rate schedule adaptively in SGD. \n\nMy major concerns are as follows.\n\n1. The experiments in subsection 3.3 are not convincing. The authors compare the proposed adaptive training schedule with a preset training schedule. However, the improvement by the proposed schedule is insignificant.\nTo make this paper more convincing, the authors may want to compare the proposed adaptive training schedule with other approaches that have dynamic learning rates, such as those mentioned in [1].\n\n2. The derived relations are based on the stationarity assumption. However, there are few discussions on when this assumption will hold. The authors may want to analyze the conditions for the assumption to hold and explain why imposing L^2-regularization can ensure stationarity.\n\nThis paper will be more convincing if the above issues are addressed properly, and I will be happy to raise my score.\n\n[1] Sebastian Ruder. An overview of gradient descent optimization algorithms. arXiv preprint arXiv: 1609.04747, 2017.\n', 'The paper introduces the concept of fluctuation-dissipation relations to stochastic gradient descent. These relations hold for certain observables in physical systems in equilibrium. In the context of SGD as a non-equilibrium process with a stationary density, they allow to quantify how far away this process is from its stationary state. \n\nOne of the strengths of the paper is that it works in the discrete-time formalism and uses the master equation, as opposed to other recent works that used the continuous-time limit of SGD to derive related (yet different) results. Furthermore, the formalism does not even rely on a locally quadratic approximation of the loss function, or on any Gaussian assumptions of the SGD noise. To the best of my knowledge, all of this is very innovative. Ultimately, the authors propose a practical algorithm to adaptively lowering the learning rate based on testing fluctuation-dissipation relations.\n\nThis is an interesting paper which I recommend to accept. It not only shows new theoretical results, but also conforms their validity in real-world experiments.\n\nI have only a few questions / comments:\n\n1. In Eq. 17 and others where the scalar product of theta and grad(f) occurs, is it implicitly assumed that the optimum of f is at theta=0?\n2. In Fig. 2, the distinction between solid and dotted curves could be made better visible.\n3. For completeness, it would be good to add the following citation:\nStephan Mandt, Matthew D. Hoffman, and David M. Blei. ""Continuous-time limit of stochastic gradient descent revisited.""\xa0NIPS 2015 Workshop on Optimization for Machine Learning.']","[50, -20, 90]","[70, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the paper's contribution to understanding stochastic gradient descent and its advantage over existing studies. The reviewer also mentions that empirical results verify the findings, which is positive. However, the reviewer then lists several points of confusion or areas needing clarification, which balances out the initial positive sentiment.\n\nThe politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout. They frame their comments as questions or requests for clarification rather than direct criticisms. Phrases like 'It would be helpful to the readers if...' and 'can you give some explanation for...' demonstrate a constructive and courteous approach to feedback. The reviewer also acknowledges the paper's strengths before moving on to areas of improvement, which is a polite way to structure feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' work, they express 'major concerns' and suggest that the paper needs significant improvements to be more convincing. The reviewer states that they would be 'happy to raise my score' if the issues are addressed, implying the current score is not high. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to reconsider their evaluation. They use phrases like 'The authors may want to' which is a polite way of suggesting improvements, and they end on a positive note offering to raise their score if concerns are addressed."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, highlighting its strengths, innovation, and recommending acceptance. They use phrases like 'strengths of the paper', 'very innovative', and 'interesting paper which I recommend to accept'. The only reason it's not 100 is because they do have a few minor questions/comments at the end. The politeness score is 80 because the reviewer uses respectful and professional language throughout, acknowledging the authors' work positively. They frame their questions as 'I have only a few questions / comments' which is a polite way to introduce critiques. The score isn't 100 because while polite, it doesn't go out of its way to be exceptionally courteous.""]"
"['This paper talks about music translation using a WaveNet-based autoencoder architecture.  The models are trained on diverse training sets and evaluated under multiple settings.  What reported in this paper seems to be interesting and the performance sounds good. However, I have following comments/concerns. \n\n1. The paper is not clearly written. Its exposition needs significant improvement.  There are numerous inconsistent definitions and vague descriptions that make the reading sort of difficult. \n    a)  It would be very helpful if the authors can put up a figure for the description of  the WaveNet  autoencoder instead of just using words in Section 3.1\n    b) The paper itself should be self-contained instead of referring readers to other references for the details of model architectures.\n    c) The math symbols are poorly defined.  What is the definition of C in Section 3.3?   It is defined or referred to as ""domain classification network"" and also ""domain confusion network"" but nowhere to find in Fig. 1.\n   d) ""C is minimizes"" -> ""minimizes""\n   e)  In Section 4,  it says that ""Each batch is first used to train the adversarial discriminator"".  Which adversarial discriminator? Where to find in Fig. 1 as it is the only description of the network architecture?  \n\n2.  The authors mentioned a couple of observations that left unanswered.  \n    a)   I am surprised to see that without data augmentation, the training does not even converge. \n    b)  The conversion from unseen domains is more successful than the learned domains.\n    c)  The decoder starts to be creative when the size of the latent space is reduced. \n   I sense that these observations seem to point to some (serious) generalization issues of the proposed model.  I would like to hear explanations from the authors. \n\n\nAfter reading the rebuttal:\nThe authors have addressed my major concerns with regard to this paper.   I have lifted my score.  Thanks for the nice response.', '\nThe paper proposes a multi-domain music translation method. The model presents a Wavenet auto-encoder setting with a single (domain independent) encoder and multiple (domain specific) decoders.  From the model perspective, the paper builds up on several exciting ideas such as Wavenet and autoencoder based translation models that can perform the domain conversion without relying on parallel datasets. The two main modifications are the use of data augmentation, the use of multiple decoders (rather a single decoder conditioned on the output domain identity) and the use of a domain confusion loss to prevent the latent space to encode domain specific information. This last idea has been also used on prior work.\n\nUp to my knowledge, this is the first autoencoder-based music translation method. While this problem is very similar to that of speaker conversion, modeling musical audio signal (with many instruments) is clearly more challenging. \n\nSummarizing, I think that the contributions in terms of methods are limited, but the results are very interesting. The paper gives an affirmative answer to the question of whether existing models could be adapted to handle the case of music translation, which is of value. The paper would be stronger in my view, if stronger baselines would be included. This would show that the technical contributions are better than alternative methods. Please read bellow some further comments and questions.\n\nThe authors perform two ablation studies: eliminating data augmentation and the domain confusion network. In both cases, the model without this add on fails to train. However, it seems to me that different studies are important. \n\nThe paper seems to be missing baselines. The authors could compare their work with that of VQ-VAE. The authors claim that they could not make VQ-VAE work on this problem. The cited work by Dieleman et al provides some improvements to adapt VQ-VAE to be better suited to the music domain. Did you evaluate also autoregressive discrete autoencoders?\n\nThe proposed method uses an individual decoder per domain. This is unlike other conversion methods (such as the speech conversion studied in VQ-VAE). This modification is very costly and provides a very large capacity. Have you tried having a single decoder which is also conditioned on a one-hot vector indicating the domain? Is it reasonable to expect some transfer between domains or are they too different? Maybe this is the motivation behind using many decoders. It would be good to clarify. \n\nI understand that the emphasis of this work is on music translation, however, the model doesn\'t have anything specific to music. In that regard, maybe a way to compare to VQ-VAE is to run the proposed method to the voice conversion of the VQ-VAE.\n\nHave you tried producing samples using the decoder in an unconditional setting?\n\nThe authors claim that the learned representation is disentangled. Why is this the case? Normally a representation is said to be disentangled if different properties are represented in different (disjoint) coordinates. I might not be understanding what is meant here.\n\nThe loss used by the authors, encourages the latent representation to not have domain specific information. The authors should cite the work [A], which has very similar motivation. It would be interesting to report the classification accuracy of the classifier to see how much of the domain information is left in the latent codes. Is it reduced to chance?\n\nIn Section 3.1 the authors describe some modifications to nv-wavenet. I imagine that this is because it leads to better performance or faster training. It would be good to give some more information. Did you perform ablation studies for these?\n\nIn the human lineup experiment (Figure 2 b,c and d). While the listeners fail to select the correct source, many of the domains are never chosen. This could suggest that some translations are consistently poorer than others or the translations themselves are poor. This cannot be deduced from this experiment. Have you evaluated this?  Maybe it would be better to present pairs of audios with reconstruction and a translation. \n\nWhile I consider the results quite good, I tend to agree with the posted public comment. It is very hard to claim that the model is effectively transferring styles. A perceptual test should include the question: is this piece on this given style? As the authors mentioned, it is clearly very difficult to evaluate generative models. But maybe the claims could be toned down.\n\n[A] Louizos, Christos, et al. ""The variational fair autoencoder."" arXiv preprint arXiv:1511.00830 (2015). ', 'A method is presented to modify a music recording so that it sounds like it was performed by a different (set of) instrument(s). This task is referred to as ""music translation"". To this end, an autoencoder model is constructed, where the decoder is autoregressive (WaveNet-style) and domain-specific, and the encoder is shared across all domains and trained with an adversarial ""domain confusion loss"". The latter helps the encoder to produce a domain-agnostic intermediate representation of the audio.\n\nBased on the provided samples, the translation is often imperfect: the original timbre often ""leaks"" into the output. This is most clearly audible when translating piano to strings: the percussive onsets of the piano (due to the hammers hitting the strings) are also present in the translated audio, even though instruments like the violin and the cello are not supposed to produce percussive onsets. This gives the result an unusual sound, which can be interesting from an artistic point of view, but it is undesirable in the context of the original goal of the paper.\n\nNevertheless, the results are quite impressive and for some combinations of instruments/styles it works surprisingly well. The question of whether the approach is equivalent to pitch estimation followed by rendering with a different instrument is also addressed in the paper, which I appreciate.\n\nThe paper is well written and the related work section is comprehensive. The experimental evaluation is thorough and extensive as well (although a few potentially interesting experiments seemingly didn\'t make the cut, see other comments). I also like that the authors went through the trouble of doing some experiments on a publicly available dataset, to facilitate reproduction and future comparison experiments.\n\n\nOther comments:\n\n* ""autoregressive"" should be one word everywhere\n\n* In section 2 it is stated that attempts to use a unified decoder with style/instrument conditioning all failed. I\'m curious about what was tried specifically, it would be nice to discuss this.\n\n* The same goes for experiments based on VQ-VAE, the paper simply states that they were not able to get this working, but not what experiments were run to come to this conclusion.\n\n* The authors went through the trouble to modify the nv-wavenet inference kernels to support their modified architecture, which I appreciate -- will the modified kernels be made available as well?\n\n* The audio augmentation by pitch shifting is a surprising ingredient (but according to the authors it is also crucial). Some more insight as to why this is so important (rather than simply stating that it is important) would be a welcome addition.\n\n* Section 3.2: ""out off tune"" should read ""out of tune"".\n\n* The formulation on p.7, 2nd paragraph is a bit confusing: ""AMT freelancers tended to choose the same domain as the source, regardless of the real source and the presentation order."" Does that mean they got it right every time? I suspect that is not what it means, but that is how I read it initially.\n\n* I don\'t quite understand the point of the semantic blending experiments. As a baseline, the same kind of blending in the raw audio space should be done, I suspect it would probably be hard to hear the difference. This is how cross-fading is already done in practice, and it isn\'t clear to me why this method would yield better results in that respect. The paper is strong enough without them so these could probably be left out.']","[-20, 50, 60]","[50, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is interesting and the performance sounds good, they express several concerns about the clarity of writing, inconsistent definitions, and unanswered observations. The initial criticism is balanced by the more positive final paragraph where the reviewer indicates their concerns have been addressed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms as 'comments/concerns', and expresses gratitude for the authors' response. They also use polite phrases like 'I would like to hear explanations from the authors' rather than making demands. The reviewer maintains a professional tone while providing constructive feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and value of the work, stating it's 'the first autoencoder-based music translation method' and that 'the results are very interesting.' However, they also note limitations such as 'contributions in terms of methods are limited' and suggest improvements like stronger baselines. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or polite requests (e.g., 'Please read below some further comments and questions'). The reviewer maintains a professional tone, balancing praise with areas for improvement, and uses phrases like 'I think' and 'in my view' to soften critiques."", ""The sentiment score is 60 (positive) because the reviewer expresses that the results are 'quite impressive' and 'works surprisingly well' for some combinations. They appreciate the thoroughness of the paper and experiments. However, they also point out imperfections in the translation, which prevents a higher score. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts (e.g., 'I appreciate', 'I like that the authors went through the trouble'). They provide constructive feedback and suggestions in a courteous manner, using phrases like 'would be a welcome addition' instead of demanding changes. The reviewer maintains a professional and considerate tone while offering both praise and critique.""]"
"['The authors, motivated by work in topological graph analysis, introduce a new broadly applicable complexity measure they call  neural persistence--essentially a sum over norms of persistence diagrams (objects from the study of persistent homology).  The also provide experiments testing their parameter, primarily on MNIST with some work on CIFAR-10.\n\nI\'d like to preface my criticism with the following: this work is extremely compelling, and the results and experiments are sound.  I\'m very interested to see where this goes.  Figure 2 is particularly compelling!\n\nThat said, I am extremely suspicious of proposals for measures of generalization which (1) do not make contact with the data distribution being studied, and (2) which are only tested on MNIST and CIFAR-10.  Additionally, (3) it is not clear what a ""good"" neural persistence is, a priori, and (4) I\'m not entirely sure I agree with the author\'s assessment of their numerical data.\n\nIn more detail below:\n\n1. At this point, there\'s a tremendous number of different suggested ways to measure ""generalization"" by applying different norms and bounds and measures from all of the far reaches of mathematics.  A new proposed measure **really needs** to demonstrate a clear competitive measure against other candidates.  The authors make a strong case that this measure is better than competitors from TGA, but I\'m not yet convinced this measure is doing enough legwork.  For example, is it possible that a network has high neural persistence, but still has terrible test or validation error?  Why or why not?  Are there obvious counterexamples?  Are there reasons to think those obvious counterexamples aren\'t like trained neural networks?  These are all crucial questions to ask and answer if you want this sort of measure to be taken seriously.\n\n2.  Most of your numerical experiments were on MNIST, and MNIST is weird.  It\'s getting to be a joke now in the community that your idea works on MNIST, but breaks once you try to push it to something harder.  Even Cifar-10 has its quirks, and observations that are true of some networks absolutely do not generalize to others.\n\n3. While I\'m convinced that neural persistence allows you to distinguish between networks trained in different ways, it isn\'t clear why I should expect a particular neural persistence to mean anything at all w.r.t. validation loss.  Are there situations in which the neural persistence has stopped changing, but validation loss is still changing appreciably?  Why or why not?\n\n4. I\'m concerned that the early stopping procedure used as a benchmark wasn\'t tuned as carefully as neural persistence was.  I also honestly cannot determine anything from Figure 4 except that your ""Fixed"" baseline is bad, and that persistence seems to do about the same as validation loss.  It even seems that Training loss is a better early stopping criteria (better than both validation and persistence!) from this plot, because it seems to perform just as well, and systematically stop earlier.  Am I reading this plot right (particularly for 1.0 fraction MNIST)?\n\n\nThis work currently seems like a strong candidate for the workshop track.  I would have difficulty raising my score above much more than a 6 without much more numerical data, and analysis of when the measure fails.\n\nEdit: The authors have made a significant effort to address my concerns, and I\'m updating my score to 7 from 5 in response.', 'This paper proposes to analyze the complexity of a neural network using its zero-th persistent homology. Each layer is considered a bipartite graph with edge weights. As edges are being added in a monotonically decreasing order, each time a connected component is merged with others will be recorded as a new topological feature. The persistence of each topological feature is measured as the weight difference between the new edge and the maximal weight (properly normalized). Experiments show that by monitoring the p-norm of these persistence values one can stop the training a few epochs earlier than the validation-error-based early stopping strategy, with only slightly worse test accuracy.\n\nThe proposed idea is interesting and novel. However, it is needs a lot of improvement for the following reasons.\n\n1) The proposed idea can be explored much deeper. Taking a closer look, these zero-th persistence are really the weights of the maximum spanning tree (with some linear transformation). So the proposed complexity measure is really the p-norm of the MST. This raises other related questions: what if you just take all the weights of all edges? What if you take the optimal matching of the bipartite graph? How about the top K edges? I am worried that the p-norms of these edge sets might have the same effect; they converge as the training converges. These different measurements should be at least experimentally compared in order to show that the proposed idea is crucial. \n\nNote also that most theoretical proofs are straightforward based on the MST observation.\n\n2) The experiment is not quite convincing. For example, what if we stop the training as soon as the improvement of validation accuracy slows down (converges with a much looser threshold)? Wouldn’t this have the same effect (stop slightly earlier with only slightly worse testing accuracy)? Also shouldn’t the aforementioned various alternative norms be compared with?\n\n3) Some other ideas/experiments might worth exploring: taking the persistence over the whole network rather than layer-by-layer, what happens with networks with batch-normalization or dropout?\n\n\n\n', 'The paper proposes the notion of ""neural persistence"", i.e., a topological measure to assign scores to fully-connected layers in a neural network. Essentially, a simplicial complex is constructed by considering neurons as 0-simplices and connections as 1-simplices. Using the (normalized) connection weights then facilitates to define a filtration. Persistent homology (for 0-dim. homology groups) then provides a concise summary of the evolution of the 0-dim. features over the filtration in the form of a barcode. The p-norm of the persistence diagram (containing points (1,w_i)) is then used to define the ""neural persistence""  NP(G_k) of a layer G_k; this measure is averaged over all layers to obtain one final neural persistence score. Thm. 1 establishes lower and upper bounds on N(G_k); Experiments show that neural persistence, measured for small networks on MNIST, aligns well with previous observations that batch-norm and dropout are benefical for generalization and training. Further, neural persistence it can be used as an early stopping criterion without having to rely on validation data.\n\nOverall, I think this is an interesting and well-written paper with a good overview of related work in terms of using TDA approaches in machine learning. The theoretical aspects of the work (i.e., the bounds) are fairly obvious. The bounds \nare required, though, for proper normalization. Using 0-dim. persistent homology is also appropriate in this context, as I tend to agree with the authors that this aspect is the most interesting one (and also the only computationally feasible one if this needs to be done during training). \n\nThe only major concern at this point, is the experimental evaluation on small fully-connected networks. \nWhile reading the paper, I was wondering how this could be generalized, e.g., to convolution layers, as the strategy seems to be also applicable in this context as well. I do think that the results on MNIST are convincing, however, already on CIFAR-10 the early stopping criterion seems to be very sensitive to the choice of g (from what I understood). So, this raises the obvious question of how this behaves for larger networks with more layers and larger datasets. If the contribution boils down to a confirmation that dropout and batch-norm are beneficial, this would substantially weaken the paper. Specifically, I would be interested in having full-connected networks with more layers (possibly less neurons per layer). Maybe the authors can comment on that or perform experiments along this direction.\n\nMinor comments:\n\n- What is the subscript d in \\mathcal{D}_d intended to denote?\n- In Thm.1 - why should \\phi_k be unique? This is not the only choice?\n- End of Sec. 4. - ""it is beneficial to free validation data ..."" - What does that mean?']","[50, -20, 50]","[80, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by calling the work 'extremely compelling' and expresses interest in seeing where it goes. However, they also express significant concerns and criticisms, balancing out the initial positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, prefacing their criticism with positive comments, and using phrases like 'I'd like to preface my criticism' and 'I'm very interested to see where this goes.' They also provide detailed, constructive feedback rather than dismissive criticism. The reviewer maintains a professional tone even when expressing concerns, using phrases like 'I am extremely suspicious' rather than more confrontational language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'interesting and novel', they also state that it 'needs a lot of improvement' and express several concerns about the depth of exploration, convincingness of experiments, and potential alternatives that weren't considered. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and phrases suggestions as possibilities to explore rather than direct criticisms. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, instead focusing on constructive feedback and potential improvements."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper, calling it 'interesting and well-written' with a 'good overview of related work'. However, they also raise concerns about the experimental evaluation, which tempers the positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively (e.g., 'I would be interested in...'). They offer suggestions for improvement rather than harsh criticism. The use of phrases like 'I think' and 'I tend to agree' further contributes to the polite tone.""]"
"['# Positive aspects of this submission\n\n- This submission explores a very interesting problem that is often overlooked in sequence-to-sequence models research.\n\n- The methodology in Sections 4 and 5 is very thorough and useful.\n\n- Good comparison of last-h with attention representations, which gives good insight about the robustness of each architecture against adversarial attacks.\n\n# Criticism\n\n- In Section 3, even if the ""l1 + projection"" experiments seem to show that generating egregious outputs with greedy decoding is very unlikely, it doesn\'t definitely prove so. It could be that your discrete optimization algorithm is suboptimal, especially given that other works on adversarial attacks for seq2seq models use different methods such as gradient regularization (Cheng et al. 2018).\nSimilarly, the brute-force results on a simplified task in Appendix B are useful, but it\'s hard to tell whether the conclusions of this experiment can be extrapolated to the original dialog task.\nGiven that you also study ""o-greedy-hit"" in more detail with a different algorithm in Sections 4 and 5, I would consider removing Section 3 or moving it to the Appendix for consistency.', 'Main contribution: devising and evaluating an algorithm to find inputs that trigger arbitrary ""egregious"" outputs (""I will kill you"") in vanilla sequence-to-sequence models, as a white-box attack on NLG models.\n\nClarity:\nThe paper is overall clear. I found some of the appendices (esp. B and C) to be important for understanding the paper and believe these should be in the main paper. Moving parts of Appendix A in the main text would also add to the clarity.\n\nOriginality:\nThe work looks original. It is an extension of previous attacks on seq2seq models, such as the targeted-keyword-attack from (Cheng et al., 2018) in which the model is made to produce a keyword chosen by the attacker.\n\nSignificance of contribution:\nThe lack of control over the outputs of seq2seq is a major roadblock towards their broader adoption. The authors propose two algorithms for trying to find inputs creating given outputs, a simple one relying on continuous optimization this is shown not to work (breaking when projecting back into words), and another based relying on discrete optimization. The authors found that the task is hard when using greedy decoding, but often doable using sampled decoding (note that in this case, the model will generate a different output every time). My take-aways are that the task is hard and the results highlight that vanilla seq2seq models are pretty hard to manipulate; however it is interesting to see that with sampling, models may sometimes be tricked into producing really bad outputs.\nThis white-box attack applicable to any chatbot. As the authors noted, an egregious output for one application (""go to hell"" for customer service) may not be egregious for another one (""go to hell"" in MT).\n\nOverall, the authors ask an interesting question: how easy is it to craft an input for a seq2seq model that will make it produce a ""very bad"" output. The work is novel, several algorithms are introduced to try to solve the problem and a comprehensive analysis of the results is presented. The attack is still of limited practicality, but this paper feels like a nice step towards more natural adversarial attacks in NLG.\n\nOne last thing: the title seems a bit misleading, the work is not about ""detecting"" egregious outputs.', 'This paper explores the task of finding discrete adversarial examples for (current) dialog models in a post hoc manner (i.e., once models are trained). In particular, the authors propose an optimization procedure for crafting inputs (utterances) that trigger trained dialog models to respond in an egregious manner.\n\nThis line of research is interesting as it relates to real-world problems that our models face before they can be safely deployed. The paper is easy to read, nicely written, and the proposed optimization method seems reasonable. The study also seems clear and the results are fairly robust across three datasets. It was also interesting to study datasets which, a priori, seem like they would not contain much egregious content (e.g., Ubuntu ""help desk"" conversations).\n\nMy main question is that after reading the paper, I\'m not sure that one has an answer to the question that the authors set out to answer. In particular, are our current seq2seq models for dialogs prone to generating egregious responses? On one hand, it seems like models can assign higher-than-average probability to egregious responses. On the other, it is unclear what this means. For example, it seems like the possibility that such a model outputs such an answer in a conversation might still be very small. Quantifying this would be worthwhile.   \n\nFurther, one would imagine that a complete dialog system pipeline would contain a collection of different models including a seq2seq model but also others. In that context, is it clear that it\'s the role of the seq2seq model to limit egregious responses? \n\nA related aspect is that it would have been interesting to explore a bit more the reasons that cause the generation of such egregious responses. It is unclear how representative is the example that is detailed (""I will kill you"" in Section 5.3). Are other examples using words in other contexts? Also, it seems reasonable that if one wants to avoid such answers, countermeasures (e.g., in designing the loss or in adding common sense knowledge) have to be considered.\n\n\nOther comments:\n\n- I am not sure of the value of Section 3. In particular, it seems like the presentation of the paper would be as effective if this section was summarized in a short paragraph (and perhaps detailed in an appendix).\n  \n- Section 3.1, ""continuous relaxation of the input embedding"", what does that mean since the embedding already lives in continuous space?\n  \n- I understand that your study only considers (when optimizing for egregious responses)) dialogs that are 1-turn long. I wonder if you could increase hit rates by crafting multiple inputs at once.\n  \n- In Section 4.3, you fix G (size of the word search space) to 100. Have you tried different values? Do you know if larger Gs could have an impact of reported hit metrics?\n\n- In Table 3, results from the first column (normal, o-greedy) seem interesting. Wouldn\'t one expect that the model can actually generate (almost) all normal responses? Your results indicate that for Ubuntu models can only generate between 65% and 82% of actual (test) responses. Do you know what in the Ubuntu corpus leads to such a result?\n  \n- In Section 5.3, you seem to say that the lack of diversity of greedy-decoded sentences is related to the low performance of the ""o-greedy"" metric. Could this result simply be explained because the model is unlikely to generate sentences that it has never seen before? \n\n You could try changing the temperature of the decoding distribution, that should improve diversity and you could then check whether or not that also increases the hit rate of the o-greedy metric.\n\n- Perhaps tailoring the mal lists to each specific dataset would make sense (I understand that there is already some differences in between the mal lists of the different datasets but perhaps building the lists with a particular dataset in mind would yield ""better"" results).   \n']","[50, 60, 50]","[80, 80, 80]","[""The sentiment score is 50 (slightly positive) because the review begins with a section on 'Positive aspects' which highlights several strengths of the submission, including its interesting problem, thorough methodology, and good comparisons. However, this is balanced by a 'Criticism' section that points out some limitations. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work before offering constructive criticism. The criticism is presented as suggestions rather than harsh judgments, using phrases like 'I would consider' and explaining the reasoning behind the suggestions. The reviewer also uses hedging language like 'it's hard to tell' and 'it doesn't definitely prove' which softens the critique and maintains a polite tone."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper, highlighting its originality, significance, and interesting approach. They describe the work as 'novel' and 'a nice step towards more natural adversarial attacks in NLG'. However, it's not extremely positive as they also point out some limitations and suggest improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths while offering suggestions for improvement in a considerate manner. The reviewer also uses phrases like 'My take-aways are...' and 'Overall, the authors ask an interesting question...', which maintain a collegial tone. The only slightly critical comment is about the title being misleading, but it's presented politely as 'One last thing'."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the research topic and praises the paper's readability and methodology. However, they also raise significant questions and concerns about the study's conclusions and methodology, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than direct criticisms. They also acknowledge the value of the research even while pointing out areas for improvement. The reviewer's tone is professional and courteous, offering a balanced perspective on the paper's strengths and weaknesses.""]"
"[""The paper tackles a very interesting problem about representations, especially of the connectionist kind -- how do we know if the learned representations capture the compositional structure present in the inputs, and tries to come up with a systematic framework to answer that question. The framework assumes the presence of an oracle that can give us the true compositional structure. Then the author try to answer some refreshing questions about the dynamics of learning and compositionality while citing some interesting background reading.\n\nHowever, I’m a bit torn about the experiments. On the one hand, I like the pedagogical nature of the experiments. They are small and should be easy to reproduce. On the other hand, all of them seem to be fairly similar kinds of composition with very few attributes (mostly bigrams). So whether the intuitions hold for more complex compositional structures is hard to say.\n\nNevertheless, it’s a well written paper and is a helpful first step towards studying the problem of compositionality in vector representations.\n\n\nMinor points\nPg 3 “_grammar_ for composing meanings *where* licensed by derivations” seems incorrect. \nFigure 5: seems quite noisy to make the linear relationship claim\n\nEDIT: I still think the compositions under consideration are the simpler ones. Still with the new experiments the coverage seems nicer. Given the authors plan to release their source code, I expect there will be an opportunity for the rest of the community to build on these, to test TRE's efficacy on more complex compositions. I updated my scores to reflect the change."", ""Edit and a further question: Reading again Section 7, I'm wondering whether the  the high generalization is possible due to the fact that at test time only one of the two candidates is unseen, and the other is seen. Having *both* candidates to be unseen makes the problem significantly harder since the only way for the listener to get it right is to associate the message with the right candidate, rather than relying in some other strategy like whether the message is novel (thus it's the seen candidate) or new (thus it's the unseen candidate). As such, I don't think I can fully trust your conclusions due to this potential confounder. \n--------------------------------------------------------------\n\nThe authors propose a measure of compositionality in representations. Given instances of data x annotated with semantic primitives, the authors learn a vector for each of the primitive such that the addition of the vectors of the primitives is very close (in terms of cosine) to the latent representation  z of the input x. The authors find that this measure correlates with the mutual information between the input x and z, approximates the human judges of compositionality on a language dataset and finally presents a study on the relation between the proposed measure and generalizalization performance, concluding that their measure correlates with generalization error as well as absolute test accuracy.\n\nThis in an interesting study and attacks a very fundamental question; tracking compositionality in representations could pave the way towards representations that facilitate transfer learning and better generalization. While the paper is very clear with respects to results, I found the presentation of the proposed measure overly confusing (and somewhat more exaggerated that what is really going on). \n\nThe authors start with a very clean example, that can potentially facilitate clarifying in a visual way the process of obtaining the measure. However, I feel that clarity is being traded-off for formality. It needs several reads to really distill the idea that essentially the authors are simply learning vectors of primitives that when added should resemble the representation of the input. Moreover, the name of the measure is a bit misleading and not justified by the experiments and the data. The authors do not deal with trees in any of the examples, but rather with a set of primitives (apparent in the use of addition as a composition function which being commutative does not allow for word-order and the like deep syntactic properties). \n\nNow, onto the measure. I like the idea of learning basis vectors from the representations and constraining to follow the primitive semantics. Of course, this constraints quite a bit the form of compositionality that the authors are searching for. \nThe idea of additive semantics has been explored in NLP, however it's mostly applicable for primitives with intersective semantics (e.g., a white towel is something that is both white and a towel). Do the authors think that this restricts their experiments (especially the natural languages ones)? What about other composition techniques found in the literature of compositional semantics (e.g., by Baroni and Zamparelli, 2010). \nThis is good to be clarified.  Moreover, given the simplicity of the datasets in the current study, wouldn't a reasonable baseline be to obtain the basis vector of blue by averaging all the latent representations of blue?  Similarly, how sensitive are conclusions with respect to different composition functions?\n\nSection 4 is potentially very interesting, but I don't seem to understand why it's good news that TRE correlates with I(x;\\theta). Low TRE indicates high-degree of compositionality. I suspect that low MI means that input and latent representation are somewhat independent but I don't see the connection to compositional components. Can the authors clarify?\n\nSection 5 is a nice addition. The authors mention that they learn word and phrase representations. Where are the word representations used? My understanding is that you derive basis word representations by using SGD and the phrase vectors and compute TRE with these. If this is the case, an interesting experiment would be to report how similar the induced basis vectors are (either some first-order or second-order similarity) to the pre-trained ones.\n\nSection 8 presents results on discrete representations. Since this is the experiment most similar to the recent work that uses topographic similarity (and since the authors already prime the reader at section 7 about relation between the 2 measures), it would be interesting to see the empirical relation between TRE and topographic and its relation to generalization and absolute performance. \n\nBaroni and Zamparelli (2010) Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space\n"", 'This paper describes a framework - Tree Reconstruction Error (TRE) - for assessing compositionality of representations by comparing the learned outputs against those of the closest compositional approximation. The paper demonstrates the use of this framework to assess the role of compositionality in a hypothetical compression phase of representation learning, compares the correspondence of TRE with human judgments of compositionality of bigrams, provides an explanation of the relationship of the metric to topographic similarity, and uses the framework to draw conclusions about the role of compositionality in model generalization.\n\nOverall I think this is a solid paper, with an interesting and reasonable approach to quantifying compositionality, and a fairly compelling set of results. The reported experiments cover reasonable ground in terms of questions relevant to compositionality (relationship to representation compression, generalization), and I appreciate the comparison to human judgments, which lends credibility to applicability of the framework. The results are generally intuitive and reasonable enough to be credible as indicators of how compositionality relates to aspects of learning, while providing some potential insight. The paper is clearly written, and to my knowledge the approach is novel.\n\nI would say the main limitation to the conclusions that can be drawn from these experiments lies in the necessity of committing to a particular composition operator, of which the authors have selected very simple ones without comparing to others. There is nothing obviously unreasonable about the choices of composition operator, but it seems that the conclusions drawn cannot be construed to apply to compositionality as a general concept, but rather to compositionality when defined by these particular operators. Similar limitations apply to the fact that the tests have been run on very specific tasks - it is not clear how these conclusions would generalize to other tasks.\n\nDespite this limitation, I\'m inclined to say that the introduction of the framework is a solid contribution, and the results presented are interesting. I think this is a reasonable paper to accept for publication.\n\nMinor comment:\np8 typo: ""training and accuracies""\n\n------\n\nReviewer 2 makes a good point that the presentation of the framework could be much clearer, currently obscuring the central role of learning the primitive representations. This is something that would benefit from revision. Reviewer 2\'s comments also remind me that, from a perspective of learning composition-ready primitives, Fyshe et al. (2015) is a relevant reference here, as it similarly learns primitive (word) representations to be compatible with a chosen composition function. \n\nBeyond issues of presentation, it seems that we are all in agreement that the paper\'s takeaways would also benefit from an increase in the scope of the experiments. I\'m happy to adjust my score to reflect this.\n\nReference:\nFyshe et al. (2015) A compositional and interpretable semantic space.\n']","[60, 20, 70]","[80, 60, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper's topic, praises its well-written nature, and considers it a helpful first step. They also appreciate the pedagogical nature of the experiments. However, they express some reservations about the limited scope of the experiments, which prevents a fully positive score. The politeness score is 80 (very polite) due to the reviewer's constructive tone, use of phrases like 'very interesting problem' and 'refreshing questions,' and the balanced way they present both positive aspects and concerns. The reviewer also acknowledges the authors' plans to release source code and the potential for community building, which adds to the polite and collaborative tone."", ""The sentiment score is slightly positive (20) because the reviewer describes the study as 'interesting' and acknowledges its potential to address a 'very fundamental question'. However, they also express several concerns and criticisms, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, poses questions rather than making blunt criticisms, and acknowledges the merits of the work alongside suggestions for improvement. They use phrases like 'I like the idea' and 'This is good to be clarified' which maintain a constructive tone. The reviewer also provides detailed feedback and suggestions, indicating engagement with the work, which contributes to the polite and professional tone."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'solid' with an 'interesting and reasonable approach', and states it's a 'reasonable paper to accept for publication'. They mention 'compelling' results and 'appreciate' certain aspects. However, they also point out some limitations, which prevents a higher score. The politeness score is 80 (quite polite) due to the use of respectful language throughout. The reviewer uses phrases like 'I think', 'I appreciate', and 'I'm inclined to say', showing consideration for the authors. They also balance critique with praise and offer constructive feedback. The tone is professional and courteous throughout, without any harsh or rude language.""]"
"['This paper proposed an interesting idea of learning representations of sets by permutation optimizations. Through learning a permutation of the elements of a set, the proposed algorithm can learn a permutation-invariant representation of that set. To deal with the underlying difficult combinatorial optimization problem, the authors proposed to relax the optimization constraints and instead optimize over the set of doubly-stochastic matrices with reparameterization using the Sinkhorn operator. The cost function of this optimization is related to a pairwise ordering cost, which compares the order for each pair of the elements.\n\nThe idea of using pairwise comparison information to learn permutations is interesting. The total cost function utilizes the comparison information and optimization over this cost function can lead to a permutation-invariant representation of the set. The idea of using the Sinkhorn operator to reparameterize the doubly-stochastic matrices makes the optimization objective differentiable. Also, the experiment results compared with some baseline algorithms showed the success of the proposed methods in many different tasks.\n\nMy major concern of the proposed method is on whether this method can be applied to large sets. Since the algorithm compares all pairs of elements in the set, we need O(N^2) comparisons for a set of size N and hence the proposed method might be slow if N is large. Is it possible to improve the efficiency for large sets?\n\nQuestions and Suggestions:\n\n1. Since the authors wants to approximately solve the objective function in Equation (2), it is better if we can see a proof showing why this optimization problem is difficult.\n\n2. For the experiment in Section 4.2, it seems that all methods (including the proposed methods and the baseline methods) are not performing well if the images are split to at least 4 * 4 equal-size tiles. I understand that currently the authors applied their method to the case of grid permutation by simply adding all cost functions of all rows and columns. Is it possible to extend the proposed method to the grid case in another way so that the results under this setting is better? \n\n3. It will be better if the authors can propose some more insights (probably with some theoretical analysis) when can the PO-U method performs better and when can the PO-LA method performs better.\n\n4. The authors mentioned that, the proposed method can get good permutations even for only T=4 steps. What if we continue running the algorithm? Will the permutation converges stably?\n\n5. The authors proposed to update the permutation matrix parameters in an alternative way (Equation (7)) and mentioned that this update works significantly better in the experiments. It will be great if the authors can have a theoretical analysis on why this is true since P and \\tilde P can be quite different from each other for an arbitrary \\tilde P matrix.\n\n\nMinor comment:\n\nI think there is a typo in Equation (5). The entry \\tilde P_{pq} is related to not only the entry P_{pq}, but also the other entries of the matrix P. Hence, I think Equation (5) should be modified as a matrix multiplication.', 'Update: From the perspective of a ""broader ML"" audience, I cannot recommend acceptance of this paper. The paper does not provide even a clear and concrete problem statement due to which it is difficult for me to appreciate the results. This is the only paper out of all ICLR2019 papers that I have reviewed / read which has such an issue. Of course for the conference, the area chair / program chairs can choose how to weigh the acceptance decisions between interest to the broader ML audience and the audience in the area of the paper. \n\n----------------------------------------------------------------------------------------------------------------------------------\n\n This paper addresses the problem that often features are obtained as a set, whereas certain orders of these features are known to allow for easier learning. With this motivation the goal of this paper is to learn a permutation of the features. This paper makes the following three main contributions:\n1. The idea of using pairwise comparison costs instead of position-based costs\n2. The methodological crux of how to go from the pairwise comparison costs to the permutation (that is, solving Eqn. (2) using  Eqn. (1) )\n3. An empirical evaluation\n\nI like the idea and the empirical evaluations are promising. However, I have a major concern about the second contribution on the method. There is a massive amount of literature on this very problem and a number of algorithms are proposed in the literature. This literature takes various forms including rank aggregation and most popularly the (weighted) minimum feedback arc set problem.  The submitted paper is oblivious to this enormous literature both in the related work section as well as the empirical evaluations. I have listed below a few papers pertaining to various versions of the problem (this list is by no means exhaustive). With this issue, I cannot give a positive evaluation of this submitted paper since it is not clear whether the paper is just re-solving a solved problem. That said, I am happy to reconsider if the related work and the empirical evaluations are augmented with comparisons to the past literature on the methodological crux of the submitted paper (e.g., why off-the-shelf use of previously proposed algorithms may or may not suffice here.)\n\n\nUnweighted feedback arc set:\n\nA fast and effective heuristic for the feedback arc set problem, Eades et al.\n\nEfficient Computation of Feedback Arc Set at Web-Scale, Simpson et al.\n\nHow to rank with few errors, Kenyon-Mathieu et al.\n\nAggregating Inconsistent Information: Ranking and Clustering, Ailon et al.\n\n\nHardness results:\n\nThe Minimum Feedback Arc Set Problem is NP-hard for Tournaments, Charbit et al.\n\n\nWeighted feedback arc set:\n\nA branch-and-bound algorithm to solve the linear ordering problem for weighted tournaments, Charon et al.\n\nExact and heuristic algorithms for the weighted feedback arc set problem: A special case of the skew‐symmetric quadratic assignment problem, Flood\n\nApproximating Minimum Feedback Sets and Multicuts in Directed Graphs, Even et al.\n\n\nRandom inputs:\n\nNoisy sorting without resampling, Braverman et al.\n\nStochastically transitive models for pairwise comparisons: Statistical and computational issues, Shah et al.\n\nOn estimation in tournaments and graphs under monotonicity constraints, Chatterjee et al. \n\n\nSurvey (slightly dated):\n\nAn updated survey on the linear ordering problem for weighted or unweighted tournaments, Charon et al.\n\n\nConvex relaxation of permutation matrices:\n\nOn convex relaxation of graph isomorphism, Afalo et al.\n\nFacets of the linear ordering polytope, Grotschel\n\n', ""The authors introduce a method to learn to permute sets end-to-end. They define the cost of a permutation as the sum of pairwise costs induced by the permutation, where the pairwise costs are learned. Permutations are made differentiable by relaxing them to doubly stochastic matrices which are approximated with the Sinkhorn operator. In the forward pass of the algorithm, a good permutation (ie one with low cost) is obtained with a few steps of gradient descent (the forward pass itself contains an optimization procedure). This permutation is then either used directly as the output of the algorithm or is used to permute the original inputs and feed the permuted sequence to another module (such as an RNN or a CNN). The method can easily be adapted to other structures such as lattices by considering row-wise and column-wise pairwise relations.\n\nThe proposed method is benchmarked on 4 tasks:\n1. Sorting numbers, where they obtain very strong generalization results.\n2. Re-assembling image mosaics, on which they obtain encouraging results.\n3. Image classification through image mosaics.\n4. Visual Question Answering where the permuted inputs are fed to an LSTM  whose final latent state is fed back into the baseline model (a bilinear attention network). Doing so improves over feeding the inputs to an LSTM without learning the order.for which the output is the permutation itself and  classification from image mosaics and visual question answering which require to learn an implicit permutation.\n\nThe method is most similar to Learning Latent Permutations with Gumbel-Sinkhorn Networks (Mena et al) but considers pairwise relations when producing the permutation. This can have important advantages (such as taking local relations into account, as shown by the strong sorting results) but also drawbacks (inability to differentiate inputs with similar content), but in any case this represents a good step towards exploring with different cost functions.\n\nThe method can be quite unpractical (cubic time complexity in set cardinality, optimization in forward pass, having to preprocess the set into a sequence for another module can be resource expensive). \nExperimental results on toy tasks (tasks 1, 2 and 3) are encouraging. The approach improves over a relatively strong baseline (task 4) although it isn't clear that it would still hold true when controlling for number of parameters and compute.\n\nI have a few comments about the presentation (for which I would be willing to change my score to a 6):\n- When possible, please use the numbers reported by Mena et al and consider reporting error (instead of accuracy) as they do to ease comparison. The results that you report using their method are quite worse than what they report, so I think it would be fair to include both your reimplementation and the initial results in the table.\n- It would be interested to have some insights on what function f is learned (for the sorting task and re-assembling image mosaics for example).\n- Clarity would be improved with figures representing which neural networks are used at what part of the process.\n\n\n###########################################\nUpdated review:\n\nThe authors have greatly improved presentation and have addressed concerns about the increase in parameters and computation time. I have changed my score to a 6.""]","[60, -70, 80]","[80, 20, 70]","[""The sentiment score is 60 (positive) because the reviewer describes the paper's idea as 'interesting' and acknowledges the success of the proposed methods in experiments. They also mention that the experiment results showed success in many different tasks. However, it's not extremely positive as the reviewer expresses some concerns and suggests improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'My major concern...'), and offers suggestions in a courteous manner (e.g., 'It will be better if...'). The reviewer also acknowledges the positive aspects of the work before presenting concerns. The language is professional and considerate, without any rude or dismissive comments."", ""The sentiment score is -70 because the reviewer explicitly states they 'cannot recommend acceptance' and identifies a 'major concern' with the paper's second contribution. The reviewer criticizes the paper for being 'oblivious to enormous literature' on the topic, which is a significant negative point. However, the score is not at the extreme negative end because the reviewer does mention liking the idea and finding the empirical evaluations promising. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I like the idea' and 'I am happy to reconsider,' which add a polite touch. The reviewer also provides constructive feedback and extensive references, which is helpful to the authors. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, noting 'encouraging results', 'strong generalization results', and that it represents 'a good step' in the field. They also increased their score from the initial review to a 6 (out of presumably 10), indicating high approval. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as requests ('please use...', 'it would be interested to have...'). They also acknowledge the authors' efforts to improve the paper in the updated review. The reviewer maintains a professional tone while providing both positive feedback and areas for improvement.""]"
"['This paper develops a framework for evaluating the ability of neural models on answering free-form mathematical problems. The contributions are i) a publicly available dataset, and ii) an evaluation of two existing model families, recurrent networks and the Transformer. \n\nI think that this paper makes a good contribution by establishing a benchmark and providing some preliminary results. I am biased because I once did exactly the same thing as this paper, although at a much smaller scale; I am thus happy to see such a public dataset. The paper is a reasonable dataset/analysis paper. Whether to accept it or not depends on what standard ICLR has towards such papers (ones that do not propose a new model/new theory).\n\nI think that the dataset generation process is well-thought-out. There are a large variety of modules, and trying to not generate either trivial or impossible problems is a plus in my opinion. The results and discussions in the main part of the paper are too light in my opinion; the average model accuracy across modules is not an interesting metric at all, although it does show that the Transformer performs better than recurrent networks. I think the authors should move a portion of the big bar plot (too low resolution, btw) into the main text and discuss it thoroughly. Details on how to generate the dataset, however, can be moved into the appendix. I am also not entirely satisfied by using accuracy as the only metric; how about using something like beam search to build a ""soft"", secondary metric?\n\nOne other thing I want to see is a test set with multiple different difficulty levels. The authors try to do this with composition, which is good, but I am not sure whether that captures the real important thing - the ability to generalize, say learning to factorise single-variable polynomials and test it on factorising polynomials with multiple variables? And what about the transfer between these tasks (e.g., if a network learns to solve equations with both x and y and also factorise a polynomial with x, can it generalize to the unseen case of factorising a polynomial with both x and y)? Also, is there an option for ""unsolvable""? For example, the answer being a special ""this is impossible"" character for ""factorise x^2 - 5"" (if your training set does not use \\sqrt, of course).', 'Summary: This paper is about models for solving basic math problems. The main contribution is a synthetically generated dataset that includes a variety of types and difficulties of math problems; it is both larger and more varied than previous datasets of this type. The dataset is then used to evaluate a number of recurrent models (LSTM, LSTM+attention, transformer); these are very powerful models for general sequence-sequence tasks, but they are not explicitly tailored to math problems. The results are then analyzed and insights are derived explaining where neural models seemingly cope well with math tasks, and where they fall down. \n\nStrengths: I am happy to see the proposal of a very large dataset with a lot of different axes for measuring and examining the performance of models. There are challenging desiderata involved in building the training+tests sets, and the authors have an interesting and involved methodology to accomplish these. The paper is very clearly written. I\'m not aware of a comparable work, so the novelty here seems good.\n\nWeaknesses: The dataset created here is entirely synthetic, and the paper only includes one single small real-world case; it seems like it would be easy to generate a larger and more varied real world dataset as well (possibly from the large literature of extant solved problems in workbooks). It would have been useful to compare the general models here with some specific math problem-focused ones as well. Some details weren\'t clear to me. More in the comments below.\n\nVerdict: I thought this was generally an interesting paper that has some very nice benefits, but also has some weaknesses that could be resolved. I view it as borderline, but I\'m willing to change my mind based on the discussion.\n \n \nComments:\n\n- One area that could stand to be improved is prior work. I\'d like to see more of a discussion of *prior data sets* rather than papers proposing models for problems. Since this is the core contribution, this should also be the main comparison. For example, EMLNP 2017 paper ""Deep Neural Solver for Math Word Problems"" mentions a size 60K problem dataset. A more extensive discussion will help convince the readers that the proposed dataset is indeed the largest and most diverse.\n\n- The authors note that previous datasets are often specific to one type of problem (i.e., single variable equation solving). Why not then combine multiple types of extant problem sets? \n\n- The authors divide dataset construction into crowdsourcing and synthetic. This seems incomplete to me: there are tens of thousands (probably more) of exercises and problems available in workbooks for elementary, middle, and high school students. These are solved, and only require very limited validation. They are also categorized by difficulty and area. Presumably the cost here would be to physically scan some of these workbooks, but this seems like a very limited investment. Why not build datasets based on workbooks, problem solving books, etc? \n\n- How do are the difficulty levels synthetically determined?\n\n- When generating the questions, the authors ""first sample the answer"". What\'s the distribution you use on the answer? This seems like it dramatically affects the resulting questions, so I\'m curious how it\'s selected.\n\n- The general methodology of generating questions and ensuring that no question is too rare or too frequent and the test set is sufficiently different---these are important questions and I commend the authors for providing a strong methodology.\n\n- I didn\'t understand the motivation for testing only very general-purpose models (this is described in Section 3). This is certainly a scientific decision, i.e., the authors are determining which models to use in order to determine the possible insights they will derive. But it\'s not clear to me why testing more sophisticated models that are tailored for math questions would *not* be useful. In fact, assuming that such methods outperform general-purpose models, we could investigate why and where this is the case (in fact the proposed dataset is very useful for this). On the other hand, if these specialized approaches largely fail to outperform general-purpose models, we would have the opposite insights---that these models\' benefits are dataset-specific and thus limited. \n\n- Really would be good to do real-world tests in a more extensive way. A 40-question exam for 16 year olds is probably far too challenging for the current state of general recurrent models. Can you add some additional grades here, and more questions?\n\n- For the number of thinkings steps, how does it scale up as you increase it from 0 to 16? Is there a clear relationships here?\n\n- The 1+1+...+1 example is pretty intriguing, and could be a nice ""default"" question!\n\n- Minor typo: in the abstract: ""test spits"" should be ""test splits""\n', 'This paper presents a new synthetic dataset to evaluate the mathematical reasoning ability of sequence-to-sequence models. It consists of math problems in various categories such as algebra, arithmetic, calculus, etc. The dataset is designed carefully so that it is very unlikely there will be any duplicate between train/test split and the difficulty can be controlled. Several models including LSTM, LSTM + Attention, Transformer are evaluated on the proposed dataset. The result showed some interesting insights about the evaluated models. The evaluation of mathematical reasoning ability is an interesting perspective. However, the un-standard design of the LSTM models makes it unclear whether the comparisons are solid enough. \n\nThe paper is relatively well-written, although the description of the neural models can be improved. \n\nThe generation process of the dataset is well thought out. The insights from the analysis of the failure cases are intriguing, but it also points out that the neural networks models are not really performing mathematical reasoning since the generalization is very limited. \n\nOne suggestion is that it might be useful to also release the structured (parsed) form besides the freeform inputs and outputs, for analysis and for evaluating structured neural network models like the graph networks. \n\nMy main concerns are about the evaluation and comparison of standard neural models. The use of “blank inputs (referred to as “thinking steps”)” in “Simple LSTM” and “Attentional LSTM"" doesn’t seem to be a standard approach. In the attentional LSTM, the use of “parse LSTM” is also not a standard approach in seq2seq models and doesn’t seem to work well in the experiment (similar result to “Simple LSTM""). I think these issues are against the goal of evaluating standard neural models on the benchmark and will raise doubts about the comparison between different models. \n\nWith some improvements in the evaluation and comparison, I believe this paper will be more complete and much stronger. \n\ntypo:\npage 3: “freefrom inputs and outputs” -> “freeform inputs and outputs”\n']","[50, 20, 20]","[70, 80, 60]","[""Sentiment score (50): The review is generally positive, acknowledging the paper's contribution in establishing a benchmark and providing preliminary results. The reviewer expresses happiness about the public dataset and considers it a 'good contribution'. However, they also point out some areas for improvement, such as the need for more thorough discussion of results and additional metrics, which prevents the sentiment from being extremely positive.\n\nPoliteness score (70): The language used is consistently polite and professional. The reviewer uses phrases like 'I think', 'in my opinion', and 'I want to see', which soften their criticisms and suggestions. They also acknowledge their own potential bias, which shows self-awareness and fairness. The reviewer provides constructive feedback and suggestions for improvement without using harsh or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges strengths of the paper, such as the large and varied dataset, clear writing, and novelty. However, they also point out weaknesses and describe the paper as 'borderline,' indicating a mixed but slightly positive overall sentiment. The politeness score is high (80) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'I am happy to see,' 'I commend the authors,' and provide detailed, helpful suggestions for improvement without being harsh or dismissive."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the interesting aspects of the paper and its well-thought-out dataset, they also express concerns about the evaluation methods and suggest improvements. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions politely, and acknowledges the paper's strengths before discussing its weaknesses. They use phrases like 'One suggestion is...' and 'I believe this paper will be more complete and much stronger' which contribute to a polite tone. The reviewer also points out a typo in a neutral manner, further demonstrating professional courtesy.""]"
"['-- Paper Summary --\n\nThe primary contribution of this paper is the presentation of a novel ELBO objective for training BNNs which allows for more meaningful priors to be encoded in the model rather than the less informative weight priors featured in the literature. This is achieved by way of introducing a KL measure over stochastic processes which allows for priors to take the form of GP priors and other custom variations. Two approaches are given for training the model, one inspired by GANs, and a more practical sampling-based scheme. The performance of this training scheme is validated on a variety of synthetic and real examples, choosing Bayes by Backprop as the primary competitor. An experiment on contextual bandit exploration, and an illustrative Bayesian optimisation example  provided in the supplementary material showcase the effectiveness of this method in applications where well-calibrated uncertainty is particularly pertinent.\n\n-- Critique --\n\nThis paper makes important strides towards giving more meaningful interpretations to priors in BNNs. To the best of my knowledge, the KL divergence between stochastic processes that gives rise to an alternate ELBO has not been featured elsewhere, making this a rather interesting contribution that is supplemented by suitable theorems both in the main text and supplementary material. The introductory commentary regarding issues faced with increasing the model capacity of BNNs is particularly interesting, and the associated motivating example showing how degeneracy is countered by fBNN is clear and effective.\n\nThe GAN-inspired optimisation scheme is also well-motivated. Although the authors understandably do not pursue that scheme due to the longer computation time incurred (rendering its use impractical), it would have been interesting to see whether the optimum found using this technique is superior to the sampling based scheme used throughout the remainder of the paper. The experimental evaluation is also very solid, striking an adequate balance between synthetic and real-world examples, while also showcasing fBNNs’ effectiveness in scenarios relying on good uncertainty quantification.\n\nIn spite of the paper’s indisputable selling points, I have several issues with some aspects of this submission. For clarity, I shall distinguish my concerns between points that I believe to be particularly important, and others which are less significant:\n\n- Monte Carlo dropout (Gal & Ghahramani, 2016), and its extensions (such as concrete dropout), are widely-regarded as being one of the most effective approaches for interpreting BNNs. Consequently, I would have expected this method to feature as a competitor in your evaluation, yet this method does not even get a cursory mention in the text.\n\n\u2028- The commentary on GPs in the related work paints a dour picture of their scalability by mostly listing older papers. However, flexible models such as AutoGP (Krauth et al, 2017) have been shown to obtain very good results on large datasets without imposing restrictions on the choice of kernels.\n\n - The regression experiments all deal with a one-layer architecture, for which the proposed method is shown to consistently obtain better results. In order to properly assess the effectiveness of the method, I would also be interested in seeing how it compares against BBB for deeper architectures on this problem. Although the authors cite the results in Figure 1 as an indicator that BBB with more layers isn’t particularly effective, it would be nice to also see this illustrated in the cross-dataset comparison presented in Section 5.2.\n\n - Furthermore, given that all methods are run for a fixed number of iterations, it might be sensible  to additionally report training time along with the results in the table. This should reflect the pre-processing time required to optimise GP hyperparameters when a GP prior is used. Carrying out Cholesky decompositions for 1000x1000 matrices 10k times (as described in Section 5.2.2) does not sound insignificant.\n\n- The observation regarding the potential instability of GP priors without introducing function noise should be moved to the main text; while those who have previously worked with GPs will be familiar with such issues, this paper is directed towards a wider audience and such clarifications would be helpful for those seeking to replicate the paper’s results. On a related note, I would be keen on learning more about other potential issues with the stability of the optimisation procedure, which does not seem to be discussed upfront in the paper but is key for encouraging the widespread use of such methods.\n\n- The paper contains more than just a handful of silly typos and grammatical errors - too many to list here. This single-handedly detracts from the overall quality of the work, and I highly advise the authors to diligently read through the paper in order to identify all such issues.\n\n - The references are in an absolute shambles, having inconsistent citation styles, arXiv papers cited instead of conference proceedings, etc. While this is obviously straightforward to set right, I’m nonetheless disappointed that this exercise was not carried out prior to the paper’s submission.\n\n - The theory presented in Appendix A of the supplementary material appears to be somewhat ‘dumped’ there. Given that this content is crucial for establishing the correctness of the proposed method, linking them more clearly to the main text would improve its readability and give it a greater sense of purpose. I found it hard to follow in its current state.\n\n** Minor **\n\n - In the introduction there should some mention of deep Gaussian processes which are implicitly a direct competitor to BNNs, and can now also be scaled to millions and billions of observations (Cutajar et al. 2017; Salimbeni et al. 2017). The former is particularly relevant to this work since the architecture can be assimilated to a BNN with special structure for emulating certain kernels.\n\n - Experiment 5.1.1 is interesting, and the results in Figure 2 are convincing. I would also be interested in seeing how fBNN performs when the prior is misspecified however, which may be induced by using a less appropriate GP kernel. This would complement the already provided insight on using tanh vs ReLU activations.\n\n - The performance improvement for the experiment on large regression datasets is quite subdued, so it might be interesting to see how both methods compare against each other when deeper BNN architectures are considered.\u2028\n\n- With regards to Appendix C.2, which order arccosine kernel is being used here? One can easily draw similarities between the first order arccosine kernel and NN layers with ReLUs, so perhaps it would be useful to specify which order is being used in the experiment.\u2028\u2028\n\n- Given that the data used for experiments in Appendix C.3 effectively has grid structure, I would be interested in seeing how KISS-GP performs on this task. There should be easily accessible implementations in GPyTorch for testing this out. Given how GPs tend to not work very well on image completion tasks due to smoothness in the kernel, this comparison may also be in fBNNs favour.\n\n- Restating the basic architecture of the BNN being used for the contextual bandits experiment in the paper itself would be helpful in order to avoid having to separately check out Riquieme et al (2018) to find such details.\n\n- I wonder if the authors have already thought about the extendability of their proposal to more complex BNN architectures such as Bayesian ConvNets?\n\n\n-- Recommendation --\n\nWhereas several ICLR submissions tend heavily towards validation by way of empirical evaluation, I find that the theoretic contributions presented in this paper are by themselves interesting and well-developed, which is very commendable. However, there are multiple telling signs of this being a rushed submission, and I am less inclined to argue ardently for such a paper’s acceptance. Although the paper indeed has its strong points, both in terms of novelty and varied experimental evaluation, in view of this overall lack of finesse and other concerns listed above, I think that the paper is in dire need of a thorough clean-up before being published.\n\nPros/Cons summary:\n\n+   Interesting concepts that extend beyond empirical fixes.\n+   Defining more interpretable priors is a very pertinent topic in the study of BNNs.\n+   The presented ideas could potentially have notable impact.\n+   Illustrative experiments and benchmark tests are convincing.\n-   Not enough connection to MC dropout.\n-   Choice of experiments and description of stochastic processes overly similar to other recent widely-publicised papers. It feels on trend, but consequently also somewhat reductive.\n-   More than a few typos and grammatical errors.\n-   Presentation is quite rough around the edges. The references are in a particularly dire state.', 'This paper presents a new variational inference algorithm for Bayesian neural network models where the prior is specified functionally (i.e. through a stochastic process) rather than via a prior (e.g.) over weights. The paper is motivated by the maximization of the evidence lower bound defined on stochastic processes, which is itself motivated as the minimization of the KL between the approximate posterior and the true posterior processes. \n\nThe paper relies heavily on Th 1, which is proved in the appendix, which states that the KL divergence between two stochastic processes is equivalent to the supremum of the marginal KL divergence over all finite sets of input locations. This yields a GAN-like objective where the ELBO is minimized wrt the input subsets and maximized wrt the approximate posterior. Obviously, as the former minimization is unfeasible, the authors proposed two additional approximations: (1) Restrict the size of the subset to search for; (2) replace the mimimization step with a sampling/average procedure. From the theoretical standpoint, I believe ths is the major defficiency of the paper, as these approximations are not justified and it is not clear, theoretically, how they relate to the original objective. In fact, for example on the case of Gaussian process priors, it looks too good to be true that one can have a KL-divergence over low-dimensional distributions instead of handling N-dimensional (fully coupled) distributions. It is unclear what is lost here (whereas in well-known sparse variational methods such as that of Titsias, one knows how the sparse model relates to the original one). \n\nOnly the first experiment compares to a GP model, where it is shown that the solution given by fBNN (which was seeded with the GP solution) is not better (if not slightly worse than the GP’s). As recommended by Matthews et al (2018), all the experiments should compare to a base GP model.\n\nOther Comments:\nThe paper claims that the method estimates reliable uncertainties. However, there is not an objective evaluation of this claim (as in the predictive posteriors are well-calibrated). \nWhy aren’t hyper-parameters estimated using the ELBO?\nIn Figure 2, why are the results so bad for BBB? This is very surprising.\nHow does the approach relate Variational Implicit Processes (Ma et al, 2018)?\nMost of the experiments in the paper assume 1 hidden layer. In the case of deeper architectures, how can one specify a prior over functions that is “meaningful”?\nMost (all?) the experiments are specific to regression. Is there any limitation for other likelihood models?\nHow does the approach compare to inference in implicit models?\nIn the intro “practical variational BNN approximations can fail to match the predictions of the corresponding GP”. Any reference for this?\nI believe the paper should also relate to the work of Matthews et al (2015)\n\n\nReferences\n(Ma et al, 2018) Variational Implicit Processes \n(Matthews et al, 2018) Gaussian process behavior in wide deep neural networks\n(Matthews et al, 2015) On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes\n\x0c\n', 'Overall Thoughts:\n\nI found this paper to be very interesting and to address a topic that I think will be of interest to the community. The gap between theoretically advantageous stochastic processes like the GP and the computational efficiency of finite BNNs is a topic not yet fully understood and I believe this paper has some useful points to make. I would be very interested and grateful to hear the authors’ thoughts on the comments/questions below.\n\nSpecific Comments/Questions:\n\nI would prefix this discussion with the fact that this is quite a dense (and long) paper on a number of topics so while I hope that I have understood the essence of the approach I apologise if I have missed something and hope the authors will be able to correct me.\n\nI follow the point that it is less clear how finite variational deep BNNs relate to GPs and would agree that finding such an agreement would be a topic of interest. Is the approach taken in the paper not quite close conceptually to the variational sparse GP of Titsias? In that paper, effectively a functional bound is also being taken (i.e. an approximation of a full GP with another GP). So a stochastic process is approximating a full GP. In addition, the approximating GP is defined by a set of samples (the pseudo-input locations) that are optimised as variational parameters. The variational bound is defined in the function domain. There is also alignment with the Stein gradient estimation - the pseudo-input locations are used to define a Nystrom approximation to the full GP kernel. This would seem equivalent to the approximation being performed in (2) as long as the kernel used for the eigenfunctions is the same as that of the full GP. \n\nFollowing from the above, I would be very interested to directly contrast the differences to the Titsias approach - would it be possible to add it as a baseline to the experiments? In particular, there are potentially differences due to differences between the Stein kernel and the full GP kernel (it might be best to have both kernels the same if they are not already the same in all experiments - sorry, I couldn’t tell). In the variational-GP, the pseudo-input locations are optimised directly under the bound and so whilst they are sensitive to initialisation, the optimisation is stable and guaranteed to converge to a local optimum. It is unclear to me how stable the adversarial problem in Sec3.2 is. In the proposed sampling variant, it isn’t clear to me that it is a safe procedure to follow - taking a random subset from the training data and weights on c seems rather heuristic - are there any guarantees? \n\nThere would also seem to be some connections with the recent approaches on (conditional) neural processes - perhaps the authors might like to comment on this?\n\nFor a number of the GP priors in the experiments, it might be quite hard for a BNN with ReLu activations to match the posteriors? Would it be worth trying with other (more smooth) activation functions?\n\nOverall the results are interesting - would it be possible to include comparisons to the variational-GP (at least for the small-scale experiments)? It would be interesting to contrast their complexity as well if they get stuck on the large-scale ones. For some of the experiments would it be possible to include histograms rather than just error bars to check that the error distributions are similar?\n\nFor the appendix BayesOpt experiment - would it be possible to use Thompson sampling as the acquisition function? To my mind this would evaluate the predictive density more directly since it mitigates the effect of a particular choice of acquisition function on the performance. Also would a comparison with the full GP not be appropriate?']","[20, -30, 60]","[60, 50, 90]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and strengths, calling it 'interesting' and 'commendable'. However, they also express several concerns and criticisms, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits before presenting criticisms. They offer constructive feedback and suggestions rather than harsh criticism. The reviewer maintains a professional tone, even when pointing out flaws like typos and reference issues. The use of phrases like 'I would be interested in seeing' and 'I wonder if the authors have thought about' further contributes to the polite tone."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's novel approach and theoretical contributions, they express significant concerns about the method's justification, approximations, and experimental comparisons. The reviewer points out several limitations and questions that suggest the paper has notable weaknesses. However, the score is not extremely negative as the reviewer does recognize some positive aspects of the work.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I believe' and 'It is unclear' rather than making harsh accusations. The reviewer also provides constructive feedback and suggestions for improvement, such as recommending additional comparisons and references. While critical, the language is not confrontational or rude, but rather maintains a courteous academic discourse."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper, stating it addresses a topic of interest to the community and has 'useful points to make'. They describe the paper as 'very interesting' and express gratitude for the authors' potential responses. However, it's not extremely positive as the reviewer also raises several questions and suggestions for improvement. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and considerate language. They use phrases like 'I would be very interested and grateful', 'I apologise if I have missed something', and 'I hope the authors will be able to correct me'. The reviewer also frames their comments as questions or suggestions rather than criticisms, maintaining a collaborative and constructive tone throughout.""]"
"[""The paper proposes a new discriminator loss for MMDGAN which encourages repulsion between points from the target distribution. The discriminator can then learn finer details of the target distribution unlike previous versions of MMDGAN. The paper also proposes an alternative to the RBF kernel to stabilize training and use spectral normalization to regularize the discriminator. The paper is clear and well written overall and the experiments show that the proposed method leads to improvements. The proposed idea is promising and a better theoretical understanding would make this work more significant. Indeed, it seems that MMD-rep can lead to instabilities during training while this is not the case for MMD-rep as shown in Appendix A. It would be good to better understand under which conditions MMD-rep leads to stable training. Figure 3 suggests that lambda should not be too big, but more theoretical evidence would be appreciated.\nRegarding the experiments: \n- The proposed repulsive loss seems to improve over the classical attractive loss according to table 1, however, some ablation studies might be needed: how much improvement is attributed to the use of SN alone? The Hinge loss uses 1 output dimension for the critic and still leads to good results, while MMD variants use 16 output dimensions. Have you tried to compare the methods using the same dimension?\n-The generalized spectral normalization proposed in this work seems to depend on the dimensionality of the input which can be problematic for high dimensional inputs. On the other hand, Myato’s algorithm only depends on the dimensions of the filter. Moreover, I would expect the two spectral norms to be mathematically related [1]. It is unclear what advantages the proposed algorithm for computing SN has.\n- Regarding the choice of the kernel, it doesn’t seem that the choice defined in eq 6 and 7 defines a positive semi-definite kernel because of the truncation and the fact that it depends on whether the input comes from the true or the fake distribution. In that case, the mmd loss loses all its interpretation as a distance. Besides, the issue of saturation of the Gaussian kernel was already addressed in a more general case in [2]. Is there any reason to think the proposed kernel has any particular advantage?\n\nRevision:\n\nAfter reading the author's response, I think most of the points were well addressed and that the repulsive loss has interesting properties that should be further investigated. Also, the authors show experimentally the benefit of using PICO ver PIM which is also an interesting finding.\nI'm less convinced by the bounded RBF kernel, which seems a little hacky although it works well in practice. I think the saturation issues with RBF kernel is mainly due to discontinuity under the weak topology of the optimized MMD [2] and can be fixed by controlling the Lipschitz constant of the critic.\nOverall I feel that this paper has two interesting contributions (Repulsive loss + highlighting the difference between PICO and PIM) and I would recommend acceptance.\n\n\n\n\n\n\n[1]: Sedghi, Hanie, Vineet Gupta, and Philip M. Long. “The Singular Values of Convolutional Layers.” CoRR \n[2]: M. Arbel, D. J. Sutherland, M. Binkowski, and A. Gretton. On gradient regularizers for MMD GANs.\n\n\n\n"", 'This paper proposed two techniques to improve MMD GANs: 1) a repulsive loss for MMD loss optimization; 2) a bounded Gaussian RBF kernel instead of original Gaussian kernel. The experimental results on several benchmark shown the effectiveness of the two proposals. The paper is well written and the idea is somehow novel. \n\nDespite the above strong points, here are some of my concerns:\n1.The two proposed solutions seem separated. Do the authors have any clue that they can achieve more improvement when combined together, and why?\n\n2. They are limited to the cases with spectral normalization. Is there any way both trick can be extended to other tricks (like WGAN loss case or GP).\n\n3. Few missed references in this area:\na. On gradient regularizers for MMD GANs\nb. Regularized Kernel and Neural Sobolev Descent: Dynamic MMD Transport\n\nRevision: after reading rebuttal (as well as to other reviewers), I think they addressed my concerns. I would like to keep the original score.  ', ""OVERALL COMMENTS:\n\nI haven't had much time to write this, so I'm giving a low confidence score and you should feel free to correct me.\n\nI didn't think this paper was very clear. \nI had trouble grasping what the contributions were supposed to be\nand I had trouble judging the significance of the experiments. \n\nThat said, now that (I think) I understand what's going on,\nthe idea seems well motivated, the connection between the repulsion and the use of label information in other\nGAN variants makes sense to me, and the statements you are making seem (as much as I had time to check them) correct. \n\nThis leaves the issue of scientific significance. \nI feel like I need to understand what specifically contributed to the improvements in table 1 to evaluate significance. \nFirst of all, it seems like there are a lot of other 'good-scoring' models left out of this table. \nI understand that you make the claim that your improvement is orthogonal, but that seems like something that needs to\nbe tested empirically. You have orthogonal motivation but it might be that in practice your technique works for a reason\nsimilar to the reason other techniques work. I would like to see more exploration of this. \nSecond, are the models below the line the only models using spectral norm? I can't tell.\nOverall, it's hard for me to envision this work really seriously changing the course of research on GANs,\nbut that's perhaps too high a bar for poster acceptance.\n\nFor these reasons, I am giving a score of 6.\n\nDETAILED COMMENTS ON TEXT:\n\n> their performance heavily depends on the loss functions used in training.\nThis is not true, IMO. See [1]\n\n\n> may discourage the learning of data structures\nWhat does 'data structures' mean in this case?\nIt has another more common usage that makes this confusing.\n\n> Several loss functions have been proposed\nIMO this list doesn't belong in the main body of the text.\nI would move it to an appendix.\n\n> We assume linear activation is used at the last layer of D\nI'm not sure what this means?\nMy best guess is just that you're saying there is no activation function applied to the logits.\n\n> Arjovsky et al. (2017) showed that, if the supports of PX and PG do not overlap, there exists a perfect discriminator...\nThis doesn't affect your paper that much, but was this really something that needed to be shown?\nIf the discriminator has finite capacity it's not true in general and if it has infinite capacity its vacuous.\n\n\n> We propose a generalized power iteration method...\nWhy do this when we can explicitly compute the singular values as in [2]?\nGenuine question.\n\n> MS-SSIM is not compatible with CIFAR-10 and STL-10 which have data from many classes;\nJust compute the intra-class MS-SSIM as in [3].\n\n> Higher IS and lower FID scores indicate better image quality\nI'm a bit worried about using the FID to evaluate a model that's been trained w/ an MMD loss where \nthe discriminator is itself a neural network w/ roughly the same architecture as the pre-trained image classifier\nused to compute the FID. What can you say about this?\nAm I wrong to be worried?\n\n> Table 1: \nWhich models use spectral norm?\nMy understanding is that this has a big influence on the scores.\nThis seems like a very important point.\n\n\n\nREFERENCES:\n\n[1] Are GANs Created Equal? A Large-Scale Study\n[2] The Singular Values of Convolutional Layers\n[3] Conditional Image Synthesis With Auxiliary Classifier GANs""]","[60, 60, -30]","[80, 70, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'clear and well written overall' and that 'the proposed idea is promising'. They also mention that 'the experiments show that the proposed method leads to improvements'. However, it's not extremely positive as the reviewer suggests areas for improvement and further investigation. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or gentle recommendations (e.g., 'It would be good to better understand...'). The reviewer also acknowledges the authors' response positively in the revision section. The language is professional and courteous, avoiding any harsh or dismissive statements."", ""The sentiment score is 60 (positive) because the reviewer starts by highlighting the paper's strengths, describing it as 'well written' and the idea as 'somehow novel'. They also mention the effectiveness of the proposals. However, it's not extremely positive as they express some concerns. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their concerns as questions rather than criticisms. They use phrases like 'here are some of my concerns' which is a polite way to introduce critiques. The reviewer also shows flexibility by mentioning that their concerns were addressed in the rebuttal, indicating a fair and open-minded approach."", ""The sentiment score is -30 because the reviewer expresses several criticisms and doubts about the paper, including lack of clarity, difficulty understanding the contributions, and questioning the scientific significance. However, they do acknowledge some positive aspects like the idea being well-motivated and statements seeming correct, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses generally polite language and offers constructive feedback, while also acknowledging their own time constraints and potential for error. They use phrases like 'I think' and 'IMO' to soften criticisms, and offer specific suggestions for improvement. However, some direct criticisms and the overall negative tone prevent a higher politeness score.""]"
"['This work addresses the problem of learning latent embeddings of high-dimensional time series data. The paper emphasises the need of interpretable representations accounting for the correlated nature of temporal data. To this scope, the study proposes to cluster the data in a latent space estimated through an auto-encoder. The clustering is obtained by leveraging on the idea of self-organising maps (SOM). Within this setting, the data is mapped into a 2D lattice where each coordinate point represents the center of an inner cluster. \nThis construction motivates the formulation of the auto encoder through the definition of several cost terms promoting reconstruction, clustering, and consistency across latent mappings. \nThis definition of the problem allows an heuristic for circumventing the non-differentiability of the discrete mapping. The enhance consistency over time, the model is further equipped with an additional cost term enforcing transition smoothness across data points and latent embeddings. \n\nThe experiments are carried out with respect to synthetic 2D time-series, chaotic time-series from dynamical systems, and clinical data. In each case the proposed method shows promising results with respect to the proposed benchmark. \n\nThe study presents some interesting methodological and technical ideas. On the other hand the manuscript presentation is quite convoluted, at the expense of a lacks of clarity in the details about the implementation of the methodology. Moreover, motivated by practical aspects, the model optimisation relies on computational strategies not completely supported from the theoretical point of view (such as the zeroing of the gradient in backpropagation, or the approximation of the clustering function to overcome non-differentiability). The impact of these modeling choices would deserve more investigation and discussion. \n\nDetailed comments:\n\n- As also stated by the authors, the use of a 2D latent representation is completely arbitrary. It may be true that a 2D embedding provides a simple visualisation, however interpretability can be obtained also with much richer representations in a number of different ways (e.g. sparsity, parametric representations, …). Therefore the feeling is that the proposed structure may be quite ad-hoc, and one may wonder whether the algorithm would still generalise to more complex latent representations.\n- Related to the previous comment, the number of latent points seems to be crucial to the performance of the method. However this aspect is not discussed in detail, while it would be beneficial to provide experiment about the sensitivity and accuracy with respect to the choice if this parameters.\n- The method relies on several cost terms plugged together. While each of them takes care of specific consistency aspects of the model, their mutual relation and balance may be very critical. This is governed by a series of trade-off parameters whose effect is not discussed  nor explored throughout the study. I guess that the optimisation stability may be also quite sensitive to this trade-off, and it would be important to provide more details about this aspect. \n- Surprisingly, k-means seems to perform quite well in spite of its simplicity. Also, there is no mention about initialisation and choice of the parameter “k”. The authors may want to better discuss the performance of this algorithm, especially compared to its much lower modeling complexity with respect to the proposed method. \n- Still related to the comparison with respect to the state-of-art, interpretability in time series analysis can be achieved with much lesser assumptions and parameters by using standard approaches such as independent component analysis. I would expect this sort of comparison, especially in case of long-term data such as the one provided in the Lorenz system. \n- Clustering of short-term time series, such as the clinical ones, is a challenging task. The feeling is that a highly parametrised model, such as the proposed one,  may still not be superior with respect to classical methods, such as the mixture of linear regressions. This sort of comparison would be quite informative to appreciate the real value of the proposed methodology.', 'This paper proposes a deep learning method for representation learning in time series data. The goal is to learn a discrete two-dimensional representation of the time series data in an interpretable manner. The model is constructed on the basis of self-organizing maps (SOM) and involves reconstruction error in the training. In order to address the non-differentiability in the discrete representation assignment, the authors propose to include an extra reconstruction loss term w.r.t. the discrete representation. The authors conduct experiments on both static and time series data and validate that the method perform better than related methods in terms of clustering results as well as interpretability.\n\nThis paper deals with an interesting problem as learning an interpretable representation in time series data is important in areas such as health care and business. However, I am afraid the presentation of this paper is a bit difficult to follow. Some concerns/questions as below:\n\n1) As the paper is based on SOM, some illustration of this method would be helpful for readers to understand the idea and learn the major contribution;\n\n2) The authors use NMI and purity to evaluate the clustering performance. I was curious why not use the clustering accuracy as well?\n\n3) Some more explanation on Fig. 4(d) would be helpful.', ""This paper proposes a novel clustering technique that combines the self-organising map (SOM) (Kohonen, 1998) ideas with the differentiable quantized clustering ideas of VQ-VAE (van den Oord et al, 2017). The resulting algorithm is able to achieve better unsupervised clustering than either technique on its own. It also beats the k-means clustering approach. The authors also suggest augmenting their setup with a model of cluster transition dynamics for time-series data, which seems to improve the clustering further, as well as providing an interpretable 2D visualisation of the system's dynamics.\n\nThis approach addresses an important problem of easy interpretable visualisation of complex dynamics of a multi-dimensional system. This solution can have immediate wide spread real life applications, for example in fields like medicine or finance. The paper is very well written and the model clearly outperforms its baselines. The authors also include very nice evaluation of the importance of the different parts of the model for the final performance.\n\nThis is one of the best papers I have reviewed in a while. The only question I have is in terms of the medical data. The map learnt by SOM-VAE-prob presented in Fig. 4 appears to have 2 clusters with 'less healthy' patients (near the top left and top right edges). It would be good to have an analysis of what differences there are between these two clusters, and whether they are recovered consistently. \n\n\n""]","[-20, 20, 90]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the work, they express several concerns and criticisms. The review starts positively but then highlights multiple issues with the methodology, presentation, and lack of clarity. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, even when expressing criticisms. They use phrases like 'The study presents some interesting methodological and technical ideas' and 'it would be beneficial to provide' which maintain a polite tone. The reviewer also offers constructive suggestions for improvement rather than just criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting problem and the importance of the research area. However, they express concerns about the presentation and have several questions, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I am afraid' and 'I was curious', showing respect while raising concerns. They also offer constructive suggestions for improvement rather than harsh criticism. The review maintains a professional and courteous tone while providing specific feedback."", ""The sentiment score is 90 because the reviewer expresses highly positive views about the paper, calling it 'one of the best papers I have reviewed in a while' and praising its novelty, performance, and potential applications. The only slight criticism is framed as a question for further analysis, not detracting significantly from the overall positive sentiment. The politeness score is 80 because the reviewer uses respectful and professional language throughout, offering praise and constructive feedback. The tone is consistently positive and encouraging, without being overly effusive or informal. The reviewer's question at the end is posed politely as a suggestion for improvement rather than a criticism.""]"
"['This paper presents Riemannian versions of adaptive optimization methods, including ADAGRAD, ADAM, AMSGRAD and ADAMNC. There are no natural coordinates on a manifold. Therefore, the authors resort to product of manifolds and view each manifold component as a coordinate. Convergence analyses for those methods are given. The the theoretical results and their Euclidean versions coincide. An experiment of embedding a tree-like graph into a Poincare model is used to show the performance of the Riemannian versions of the four methods.\n\nThis paper is well-written except a few flaws (see below). I do not have time to read the proofs carefully. The proposed methods are potentially important in some applications. Therefore, I suggest publish this paper after addressing the comments below.\n\nRemarks:\n*) P1, line 2: it particular -> in particular.\n*) P3, line 9: Is R_x(v) = x + v most often chosen? A manifold is generally nonlinear. A simple addition would not give a point in the manifold.\n*) P5, in Assumptions and notations paragraph: what are T and [T]? Is T the number of total iterations or the number of functions in the function family. The subscript of the function f_t seems to be an index of the functions. But its notation is also related to the number of iterations, see (8) and the algorithms in Figure 1.\n*) P5, Figure 1: does a loop for the index $i$ missing?\n*) Section 5: it would be clearer if the objective function is written as L:(D^n)^m \\to R: \\theta-> , where m is the number of nodes. Otherwise, it is not obvious to see the domain. \n*) P7, last paragraph: Tables 2 and 3 -> Figures 2 and 3.\n*) Besides the application in the experiments, it would be nice if more applications, at least references, are added.\n\n', 'I have enjoyed reading this paper. The paper is accessible in most cases and provides a novel optimization technique. Having said this, I have a few concerns here,\n\n\n- I am not sure why the notion of product manifolds is required in developing the technique. To me, all the arguments follow without that. Even if the authors are only interested in manifolds that can be constructed in a product manner (say R^n from R),  the development can be done without explicitly going along that path. Nevertheless I may have missed something so please elaborate why product manifolds. I have to add that in many cases, the underlying Riemannian geometry cannot be derived as a product  space. For example, the SPD manifold cannot be constructed as a product space of lower dimensional geometries. \n\n- I have a feeling that finding the operator \\Pi in many interesting cases is not easy. Given the dependency of the developments on this operator, I am wondering if the method can be used to address problems on other manifolds such as SPD, Grassmannian or Stiefel. Please provide the form of this operator for the aforementioned manifolds and comment on how the method can be used if such an operator is not at our disposal.\n\n- While I appreciate the experiments done in the paper,  common tests (e.g., Frechet means) are not presented in the paper (see my comment below as well).  \n\n- last but not least, the authors missed the work of   Roy et. al., ""Geometry Aware Constrained Optimization Techniques for Deep Learning"", CVPR\'18 where RSGC with momentum and Riemannian version of RMSProp are developed. This reference should be considered and compared.\n\n\nAside from the above, please\n\n- define v and \\hat{v} for Eq.(5) \n\n- provide a reference for the claim at l3-p4 (claim about the gradient and Hessian)\n\n- maybe you want to mention that \\alpha -> 0 for |g_t^i| at the bottom of p4\n\n- what does [.] mean in the last step of the algorithm presented in p7\n\n- what is the dimensionality of the Hn in the experiments\n \n\n\n\n', 'The paper extends Euclidean optimization methods, Adam/Amsgrad, to the Riemannian setting, and provides theoretical convergence analysis which includes the Euclidean versions as a special case. To avoid breaking the sparsity, coordinate-wise updates are performed on product manifolds. \n\nThe empirical performance seems not very good, compared to RSGD which is easier to use.']","[60, 20, -20]","[80, 70, 0]","[""The sentiment score is 60 (positive) because the reviewer suggests publishing the paper after addressing some minor comments, indicating overall approval. They describe the paper as 'well-written' and the proposed methods as 'potentially important'. The politeness score is 80 (quite polite) due to the constructive tone of the review. The reviewer uses respectful language, acknowledges the paper's strengths, and offers specific, helpful suggestions for improvement without harsh criticism. The phrase 'I do not have time to read the proofs carefully' is honest without being rude. The reviewer's comments are framed as 'remarks' rather than demands, which contributes to the polite tone."", ""The sentiment score is 20 (slightly positive) because the reviewer starts by saying they 'enjoyed reading this paper' and mentions that it's 'accessible' and 'novel'. However, they follow this with 'Having said this, I have a few concerns', which introduces several critiques and questions. This mix of positive opening and subsequent concerns balances to a slightly positive overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I have enjoyed', 'please elaborate', and 'I appreciate'. They frame their concerns as questions or suggestions rather than direct criticisms, and use phrases like 'I may have missed something' which shows humility. The reviewer also provides constructive feedback and specific recommendations for improvement, which is considerate and helpful."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's theoretical contribution in extending optimization methods to the Riemannian setting, they express disappointment with the empirical performance. The phrase 'seems not very good' indicates a negative assessment of the practical results. The politeness score is neutral (0) as the language is neither particularly polite nor rude. The reviewer states their observations directly without using overly harsh or overly courteous language. They provide a factual summary of the paper's content and a brief critique of its empirical results without using emotional or judgmental language.""]"
"[""This paper gives the first nonvacuous generalization bounds for\nmeaningful Imagenet models.  These bounds are given in terms of the\nbit length of compressions of learned models together with a method\nfor taking into account symmetries of the uncompressed parameters.\n\nThese bounds are nonvacuous only when the compressed models are small\n--- on the order of 500 Kilobytes.  State of the art compressed models\nof this size achieve Imagenet accuracies slightly better than Alexnet,\n16% error for top 5, and this paper reports a nonvacuous\ngeneralization guarantees of 89% error for top 5.  While there is\nstill a large gap between the actual generalization and the guarantee,\nthis would still be a significant accomplishment.\n\nI have one major concern.  The generalization bound involves adding an\nempirical loss and a regularization term computed from a KL\ndivergence.  I am convinced that the authors have correctly handles\nthe KL divergence term.  But the paper does not contain sufficient\ndetail to determine if the authors correctly handle the empirical loss\nterm.  It is NOT correct to use the training loss of the\n(deterministic) compressed model.  The generalization bound requires\nthat the training loss be measured under the parameter noise of the\nposterior distribution.  The paper needs to be clear that this has\nbeen done. The comments in Appendix B on noise robustness are\ndisturbing in this regard.\n\nIf the training loss  has been calculated correctly in the bound,\nthe results are significant.\n\nAssuming correctness, I would comment that the Catoni bound, while sqeaking\nout all available tightness, is very opaque.  I might be good to\nconsider the more transparent bounds, claimed to be essentially the\nsame, given in McAllester's tutorial.  If the more transparent bounds\nachieve equivalent numerical results, they would make the nature of\nthe bounds clearer.\n\nAnother comment involves a largely ignored detail in (Dzuigaite and\nRoy 17). Their bounds become vacuous if they center their Gaussian\nprior at zero.  Instead they center the prior on the initial value of\nthe parameters.  This yields a dramatic improvement in the bound.  In\nthe context of the present paper, this suggests a modification of the\nprior distribution on the compressed model.  We represent the model by\nfirst selecting the r code values.  I think a distribution could be\ndefined on the code book that would improve its log probability, but I\nwill ignore that.  Given the r code values we can define a\ndistribution over the possible compressed representations of a weight\nw_i in terms of a prior on w_i defined in terms of its initial value.\nThis gives a probability distribution over the compressed\nrepresentation.  Using log probability of the compressed\nrepresentation should then be a significant improvement on the first\nterm in (8).  This shift in the prior on compressed models has no\neffect on the second term of (8) so things should only get better.\n"", 'The paper presents an application of PAC-Bayesian bounds to the problem of \nImangeNet classification (a deep neural network model). The authors provide \ninteresting empirical bounds for the risk of the ImageNet classifier. More specifically, \nthe authors introduce some clever choices for the prior distribution (on the \nhypothesis space) that allow one to incoperate a compression scheme and obtain \na (non-vacuous) bound for the predictor. \nOverall, This is an original work with clear presentation.\n\nMajor comments:\n1). In Theorem 2.1, why do you need \\lambda > 1 ?\nTo my knowledge, \\lambda only needs to be positive.\nWhy do you have to introduce the parameter \\alpha here? \nand consequently the additional log term?\n2) It is unclear for me, why are your bounds non-vacuous?\nProbably, a more clear explanation of Theorem 4.3 is to be required.\nAlso, some comparisions with the bounds in [Neyshabur et al 2018] and [Barlett et al 2017]\nwould make the paper more significant and interesting.\n\nMinor comments:\n1) in Theorem 2.1, after the formula (3), the \\Phi^{-1} should be  \\Phi^{-1}_{\\gamma}.\n2) in the sentence, page 4,: ""To strengthen a naïve Occam bound, we use the idea that that deep networks are insensitive to mild... ""   an extra ""that"" should be removed.\n3) in Section 5, the first paragraph, in sentence:  ""The lone exception is Dziugaite & Roy (2017), which succeeds by ....""\nshould be ""The one exception....""\n\n\n', 'This paper tries to push forward in important directions the seemingly increasingly powerful approach of using PAC-Bayesian formalism to explain low risks of training neural nets on real-life data. They take an interesting approach to evaluate these bounds by setting up a prior distribution as a mixture of Gaussians centered on possible heuristic compressions of the net  and this prior\'s variances are obtained by doing a layerwise grid search. This seems to give good risk bounds on certain known compressible nets using image data sets. \n\nLet me list out a bunch of issues that seem to be somewhat confusing in this paper (some of these were in the comment thread I had with the authors but I am repeating nonetheless for completeness) \n\n0.\nFirstly this form of the PAC-Bayes formula used here (Theorem 2.1) is of a more complicated form than what has been previously used in say these papers, https://arxiv.org/abs/1707.09564 Given this I strongly feel that there is a need for an explanation connecting this formalism to the usual one - particularly something that proves how this is stronger than the one in the paper I referred to earlier. \n\n1. \nIn the statement of Theorem 2.1 there is a \\lambda parameter over which the infimum is being taken. If I understand right in the experiments one is substituting the upperbound on KL from Theorem 4.3 into this RHS of Theorem 2.1 and evaluating this. Now there is also a \\lambda parameter in Theorem 4.3. Is this the same \\lambda as in Theorem 2.1 and when a grid-search is being done over \\lambda is the ""whole"" thing (theorem 2.1 upperbound with theorem 4.3 substituted) being minimized by choosing a good \\lambda? \n\nIf the two \\lambda s are different then is the choice of the 2 \\lambda s being optimized separately? \n\n(...the authors had earlier clarified that this is so and I strongly feel this is a very important clarification should be updated into the paper..)\n\n2. \nHow is the \\sigma of Theorem 4.3 chosen in the experiments? Am I right in thinking that this \\sigma is the posterior variance about which it is being said towards the end of page 6 that ""We add Gaussian noise with standard deviation equal to 5% of the difference between the largest and smallest weight in the filter."" ? \n\nSo am I to understand that this is an arbitrary choice? Or is this choice dictated by some need to ensure that the posterior variance sigma is chosen so that under this distribution the sampled nets approximately compute the same function on the training data? (If yes, then what in the theory is motivating this?). \n\nTo the best of my understanding the results are highly dependent on this choice of sigma but there is virtually no explanation for this choice which was not even found by grid search. (As of now this is merely reflective of the fact that trained nets often have some noise resilience but its not a priori clear as to why that should be important to the PAC-Bayes formalism here.)   \n\n3.\nThe code based compression seems a bit mysterious to me given that I do not have enough familiarity with the algorithm that is being referred to. Hence it seems a bit weird as to why there is a sum over codebooks in the proof of Theorems 4.3. Naively I would have thought that there is a fixed codebook for a given compression scheme but here it feels that the compression scheme is a randomized algorithm which also generates a new codebook in every run of it. This seems unusual and seems to need more explanation and at the very least a detailed pseudocode explaining exactly how this compression is working.  \n\nThis point ties in with a somewhat larger issue I describe next...\n\n4.\nIn the previous reply to my comment the authors had shared their anonymized code and l had a look through the code. Its pretty evident from the code there are an enormous number of tweaks and hyperparameter tunings to make this work. There is very little insight otherwise as to why ""Dynamic Network Surgery\' should work and its great that the authors have found an implementation that works on their image data. \n\nBut then the question arises that there should have been a cleanly abstracted out pseudocode explaining how the compression was done and how the dynamic network surgery was done. To my mind this implementation is the main contribution of the paper and giving the pseudocode for it in the paper seems not only important for essential completeness of the current paper but that could also then act as a springboard for many future attempts at trying to come up with theory for these mysterious procedures. \n\n\n\n\n\n\n\n\n']","[50, 70, -20]","[75, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the significance of the paper's accomplishment in providing the first nonvacuous generalization bounds for Imagenet models. However, they express a major concern about the handling of the empirical loss term, which tempers the overall positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides suggestions for improvement. They use phrases like 'I might be good to consider' and 'Another comment involves' which maintain a collegial tone. The reviewer also acknowledges the potential significance of the results, contingent on the correctness of calculations. The language is professional and objective, avoiding any harsh or dismissive statements."", ""The sentiment score is 70 (positive) because the reviewer describes the work as 'original' with 'clear presentation' and mentions 'interesting empirical bounds' and 'clever choices'. The overall tone is appreciative of the work's contribution. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'why do you need...?', 'It is unclear for me...'), and offers constructive feedback. The reviewer also balances positive comments with areas for improvement. The use of phrases like 'To my knowledge' and 'Probably' further softens the critique, maintaining a polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to advance an important approach and finds some aspects interesting, they list numerous issues and confusions with the paper. The reviewer uses phrases like 'somewhat confusing', 'need for an explanation', and 'seems a bit mysterious', indicating significant concerns with the clarity and completeness of the paper. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'Let me list out', 'If I understand right', and 'To the best of my understanding'. They also acknowledge positive aspects of the work before presenting criticisms. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a fairly neutral, academic tone overall.""]"
"['The authors splitted the features of multimodal representations to ""common"" (multimodal discriminative) and ""specific"" (modality-specific generative) factors. In this framework, their MFM can capture more detailed features. \n\nPros:\n(*) Learning the feature representations from two perspectives. \n\n(*) Even missing one modality, MFM can still achieve acceptable performance. \n\n(*) Using mutual information and gradient-based method to interpret their method. \n\nCons:\n(*) The work has some similarity to Hsu & Glass (2018), but the comparison between this work is only on CMU-MOSI.\n\n(*) In Table. 3, it shows that language is the most informative feature for prediction. However, in Table. 2, it can be seen that if audio is missing, the result it the worse compared to the other two cases. It seems the interpretation is not convincing to me. Can you give us more explanation about this phenomenon? \n\nComments:\n(*) The details of SVHN-MNIST experiment are missing. Appendix B gave some information about models but specified the targeted datasets.\n\n(*) The appendix is not clear, e.g. In Appendix B, it is said ""subsection 3.3"" but there is no section 3.3.  \n\n\n', 'Multimodality learning is an important topic in multimedia and human computer interaction.  How to efficiently leverage the additional information cross multimodality is the key to the task. Authors proposed the Bayesian latent variable model to factorize the multimodality representation into multimodal discriminative factors and modality-specific generating factors, which is interesting. Approximate inference is also proposed to learn this model via a generalised mean-field assumption. \n\nThe technical quality of the paper is sound and significant, The problem to solve in this paper is also well motivated and important.  In general, this is a well-written paper, \n\nI have a few minor questions which requires authors for further elaboration.\n1. If I understand it correctly, in the current work, the feature Xs are continuous. Does the approach apply to categorical or binary features?\n\n2. In equation(4), MMD is used. How to solve the computation complexity problem since the complexity of MMD is O(n^2)?  It is true that the batch size should be small?  How to select the hyper-parameters of kernels?\n\n ', ""This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors. This work applies 'Wassertein Auto-Encoders' by Tolstikhin et al (with proofs that this setup works in the multimodal case) for handling factorized joint distributions over the multimodal space. Can this method be considered as a generalization of the wasserstein autoencoder based method with a broader application? - the authors should discuss this more broadly in the paper.\n\nPros:\n- There has been many recent work in the area of disentangling joint representations for improving generative auto-encoding architectures using VAEs, GANs, WAE and some variants of these. This work falls in this category with many interesting experiments showing SOTA generation and discrimination results on several tasks.\n- This work is practical due to its robustness to noisy and/or missing data for one or more of the modalities in a multimodal machine learning classification (or generation) problem. Application of this technique for continuous multimodal time series data modeling and prediction for high accuracy requirement applications is very promising.\n- The methods seems to be easily portable to other tasks. The authors say that they will make the code available to other researchers.\n\nCons:\n- Some more comparison to other disentangling approaches such as beta-VAE, InfoGAN and partitioned VAE methods would have been useful for understanding the advantages and disadvantages of this techniques. (The authors do add a note about comparison with partitioned VAE method in the Appendix)\n- For generation and classification tasks, the authors have chosen the tasks for digit recognition and sentiment analysis - I wonder if the results would hold for other types of multimodal tasks.\n\nOverall the paper is very well-written with many experiments to support the claims.""]","[20, 80, 80]","[50, 70, 70]","[""The sentiment score is slightly positive (20) because the review begins by highlighting the strengths of the paper, mentioning several 'Pros' before moving on to 'Cons'. The reviewer acknowledges the novel aspects of the work and its achievements. However, the presence of significant criticisms and requests for clarification prevent a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present both positive and negative points objectively, without using harsh or overly critical language. The use of phrases like 'Can you give us more explanation' indicates a respectful approach to requesting clarification. The review maintains a constructive tone, focusing on improving the paper rather than dismissing its contributions."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe the topic as 'important', the proposed model as 'interesting', and the technical quality as 'sound and significant'. The reviewer also states it's a 'well-written paper'. The score is not 100 as there are some minor questions raised.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the authors' work positively and frame their questions as 'minor' and for 'further elaboration' rather than as criticisms. The tone is professional and courteous. The score is not 100 as it doesn't go beyond standard professional politeness to be exceptionally warm or praising."", ""The sentiment score is 80 because the review is predominantly positive. The reviewer highlights several pros, including the paper's contribution to recent work in disentangling joint representations, its practicality and robustness, and its potential for application in other tasks. The reviewer also mentions that the paper is 'very well-written' and has 'many experiments to support the claims.' While there are some cons mentioned, they are presented as suggestions for improvement rather than major criticisms. The politeness score is 70 because the reviewer uses respectful and constructive language throughout. They offer balanced feedback, acknowledging both strengths and areas for improvement. The use of phrases like 'would have been useful' and 'I wonder if' when presenting potential criticisms maintains a polite tone. The reviewer also commends the authors' intention to make their code available, which shows appreciation for their work.""]"
"['The authors combined several update steps together to achieve aggregated momentum. They showed that  it is more stable than the other momentum methods. Also, in Auto-encoder and image classification, AggMo outperforms than the other methods. \n\nPros:\n(+) Theoretical result is shown on the quadratic problem.\n\n(+) Extensive numerical experiments are shown to illustrate the stability of AggMo.\n\nCons:\n(+) The results are not convincing. For example, it said in the default setting (CM \\beta=0.9), ResNet34 on CIFAR-10 has accuracy 90.22\\%. However, it should be around 93\\%.\n\n(+)  This method is similar to multi-step gradient methods.\n\n\n\nComments:\n(+) This is no “introduction” in the paper. \n\n(+) There should be “,” after mathematical equations. \n', 'This paper proposed an aggregated momentum methods for gradient based optimization. The basic idea is instead of using a single velocity vector, multiple velocity vectors with different damping factors are used in order to improve the stability.\n\nIn term of novelty, the proposed method seems quite incremental. Using multiple velocity vectors seems interesting but not surprising, There is no theoretical guideline how to determine the number of velocity vectors and how to choose the damping factors. \n\nI would also suggest that authors should put some main theoretical results like the convergence analysis to the main paper instead of the appendix. \n\nIn terms of the clarity, I think the paper is well written and the experiments are sufficient and convincing.\n\nOne minor question is: what is \\lambda in Fig. 1?\n\n ', ""The paper introduces a variant of momentum that aggregates several velocities with different dampening coefficients. The proposed optimization algorithm can significantly decrease oscillation thus one can use much larger dampening coefficient to achieve faster convergence.\n\nThe paper does a good job of motivating the algorithm, both in terms of intuitive reasoning from physics, and some demonstrative examples. The paper also has nice analysis in the simple quadratic case where it tries to make equivalence to the Nesterov's accelerated gradients.\n\nThe experiments are also thorough and convincing since it contains various network architectures and different datasets. From the comparison, it seems AggMo consistently achieves the best or comparable performance even in test error/accuracies.\n\nThe connection to Nesterov's accelerated gradient and extragradient methods can be discussed in more details. It'll be nice to put the theoretical results in the main text as well.""]","[20, 20, 80]","[50, 50, 70]","[""The sentiment score is slightly positive (20) because the review starts with a neutral summary of the paper's content and lists both pros and cons. The pros mention theoretical results and extensive experiments, which are positive aspects. However, the cons point out some significant issues with the results and similarity to existing methods, which balance out the positives. The overall tone is more constructive than negative.\n\nThe politeness score is moderately positive (50) because the reviewer uses neutral language throughout and presents their points in a matter-of-fact manner without using harsh or judgmental language. They list both pros and cons objectively and provide specific comments for improvement. The absence of overtly polite language or praise prevents a higher score, but the review maintains a professional and respectful tone throughout."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some positive aspects of the paper (well-written, sufficient experiments), they also point out limitations in novelty and theoretical guidelines. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers suggestions politely ('I would also suggest...'), and frames criticisms constructively. They maintain a professional tone without being overly formal or informal."", ""The sentiment score is 80 (positive) because the reviewer consistently praises the paper, using phrases like 'does a good job', 'nice analysis', 'thorough and convincing experiments', and noting that the proposed algorithm 'consistently achieves the best or comparable performance'. The only slight criticism is a suggestion for more detailed discussion, which is presented constructively. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths without being overly effusive. The tone is consistently positive and constructive, with suggestions for improvement framed politely ('It'll be nice to...').""]"
"[""# overview\nThis paper focuses on multi-agent reinforcement learning tasks that require communication between the agents, and further presupposes that the communication protocol is bandwidth constrained and contentious so that a scheduling mechanism is necessary.  To address this they introduce a new learned weighting scheme based scheduler and distributed actor, centralized critic based architecture which is evaluated on a couple of communication driven multi-agent tasks.\n\nThe two evaluation tasks had their bandwidth artificially constrained, and SchedNet time to convergence was shown to fall somewhere between having no communication and full communication, and somewhat better than a purely round-robin based scheduling scheme, which doesn't seem particularly informative.  From this it is difficult to assess the significance of the contributions.\n\n# pros\n* communication in multi-agent scenarios is an important aspect to consider, and this work shines a spotlight on scenarios in which bandwidth is constrained.\n* general presentation fairly clear and easy to read\n\n# cons\n* Would have been more impactful to focus experiments on real-world scenarios in which bandwidth is constrained and naturally contentious\n\n# other comments\n* pg. 2 related work, suspect you meant to call out Foerster et al 2017b in second reference not Foerster et al 2017a twice."", ""The authors present a setting of MARL communication where only a number of agents can broadcast messages in a shared and limited bandwidth channel. The paper is well written and easy to follow, and the authors run an extensive number of baselines to illustrate the contributions.\n\nComments:\n\n1) It's not clear to me how do the authors tackle partial observability without the use of recurrent connections or time-steps?\n\n2) Do the agents know if they were chosen to be broadcasted at the previous timestep?\n\n3) Many times it's important to know who sent the message, do the agents share this information?"", 'The authors present a study on scheduling multi-agent communication. Specifically, the authors look into cases where agents share the same reward and they are in a partially observable environment, each of them with different observations. The main contribution of this work is that authors provide a model for communication scheduling for dealing with cases where only a certain number of agents is allowed to communicate.\n\nThe paper is very clear, positions the work very well in the literature of MARL and communication. The authors perform experiments in two environments and include a number of reasonable baselines (e.g., adapted DIAL for top(k))  as well as the full-communication upper bound. \nThe authors moreover provide a nice analysis on the messages in the predator-pray experiment.\n\nMy only concern is that authors report ""DIAL(1) performs worse than SchedNet-Top(1)"".  However, Figure 3a clearly shows that Dial(1) to be within the variance of Sched-Top(1) -- from this it\'s not clear that the null hypothesis can be rejected. The authors should probably verify this with a statistical test cause at the moment their claim is unsupported. Moreover, why Figure 3c does not contain the same models as Figure 3a (e.g., DIAL appears to be missing)?\n\n\n']","[-20, 70, 80]","[50, 50, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('communication in multi-agent scenarios is an important aspect', 'general presentation fairly clear and easy to read'), they also express significant concerns. The reviewer states it's 'difficult to assess the significance of the contributions' and suggests the experiments could have been more impactful. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present both pros and cons objectively, and their criticisms are constructive rather than harsh. The reviewer also uses polite phrases like 'suspect you meant to' when pointing out a potential error, which contributes to the overall polite tone."", ""The sentiment score is 70 (positive) because the reviewer starts with praise for the paper, noting it is 'well written and easy to follow' and that the authors conducted 'an extensive number of baselines'. This indicates a generally positive view of the work. The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language throughout. They don't use overly formal or polite phrases, but they also avoid any rudeness. The comments are phrased as questions or observations rather than demands, which is a polite approach. The overall tone is respectful and constructive, focusing on seeking clarification rather than criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'very clear' and praising its positioning in the literature, experiments, and analysis. The only criticism is minor and constructive. The politeness score is 90 (very polite) due to the consistently respectful and professional tone. The reviewer uses phrases like 'The authors present,' 'The paper is very clear,' and offers constructive feedback without harsh language. The high scores are not 100 because of the minor criticism and the use of 'My only concern,' which slightly tempers the overall positive tone.""]"
"['In this paper the authors distinguish between two families of training objectives for seq2seq models, namely, divergence minimization objectives and max-margin objectives. They primarily focus on the divergence minimization family, and show that the MRT and RAML objectives can be related to minimizing the KL divergence between the model\'s distribution over outputs and the ""exponentiated payoff distribution,"" with the two objectives differing in terms of the direction of the KL. In addition, the authors propose an objective using the Hellinger distance rather than the KL divergence, and they conduct experiments on machine translation and summarization comparing all the considered objectives.\n\nThe paper is written extremely clearly, and is a pleasure to read. While the discussion of the relationship between RAML and MRT (and MRT and REINFORCE) is interesting and illuminating, many of these insights appear to have been discussed in earlier papers, and the RAML paper itself notes that it differs from REINFORCE style training in terms of the KL direction.\n\nOn the other hand, the idea of minimizing Hellinger distance is I believe novel (though related to the alpha-divergence work cited by the authors in the related work section), and it\'s nice that training with this loss improves over the other losses. Since the authors\' results, however, appear to be somewhat below the state of the art, I think the main question left open by the experimental section is whether training with the Hellinger loss would further improve state of the art models. Even if it would not, it would still be interesting to understand why, and so I think the paper could be strengthened either by outperforming state of the art results or, perhaps through an ablation analysis, showing what aspects of current state of the art models make minimizing the Hellinger loss unnecessary.\n\nIn summary,\n\nPros:\n- well written and interesting\n- a new loss with potential for improvement over other losses\n- fairly thorough experiments\n\nCons:\n- much of the analysis is not new\n- unclear if the proposed loss will improve the state of the art, and if not why \n\nUpdate after author response: thanks for your response. I think the latest revision of the paper is improved, and even though state of the art BLEU scores on IWSLT appear to be in the mid 33s, I think the improvement over the Convolutional Seq2seq model is encouraging, and so I\'m increasing my score to 7. I hope you\'ll include these newer results in the paper.', 'The authors have updated the paper and clarified some things, and now my impression of the paper has improved. It still feels a little incremental to me, but the potential application areas of these sorts of models are quite large and therefore incremental improvements are not insignificant. This paper suggests some natural follow-up work in exploring Hellinger distance and other variations for these models.\n\n----- original review follows: ------\n\nThis paper discusses loss functions for sequence generation tasks that take into account cost functions that reflect the task-specific evaluation metric. They compare RAML and risk (MRT) formally and empirically, and also test a loss based on Hellinger distance. They compare these to some standard max-margin losses. MRT and the Hellinger distance loss perform best in NMT and summarization experiments. \n\nPros:\n\nThere are some interesting aspects of this paper:\n\n- It is interesting to note that RAML and MRT are (similar to) different directions of KL divergences between the same two distributions. (Caveat: the entropy regularizer, which I discuss in ""Cons"" below.)\n- The new Hellinger-distance-based loss seems promising. \n- The empirical comparison among losses for standard NMT/summarization tasks is a potentially valuable contribution.\n\nCons:\n\nA.\nThe focus/story of the paper need some work. It is unclear what the key contributions are. I think the Hellinger distance loss is potentially the most important contribution, but the authors don\'t spend much time on that.. it seems that they think the comparison of divergence and max-margin losses is more central. However, I think the authors\' conclusion (that the divergence losses are better than the max-margin losses) is not the main story, because RAML is not much better than the max-margin losses. Also, I have some concerns about some of the details of the max-margin losses (listed and discussed below), so I\'m not sure how reliable the empirical comparison is. \n\nB.\nAs for the connections and comparison between RAML and MRT: \n\nIt does not seem that MRT corresponds to a divergence of the form given at the start of Sec. 4. There is also an entropy regularizer in Eq. (9). Sec. 4.3 states: ""By comparing the above two methods, we find that both RAML and MRT are minimizing the KL divergence between the model output distribution and the exponentiated payoff distribution, but with different directions of D_KL."" However, this statement ignores the entropy regularizer in Eq. (9). \n\nMaybe I\'m being dense, but I didn\'t understand where Equation (10) comes from. I understand the equations above it for RAML, but I don\'t understand the MRT case in Eq. (10). Can you provide more details?\n\nI also don\'t understand the following sentence: ""It turns out that the hyperparameter \\tau in RAML and \\alpha in MRT have the same effect."" What does this mean mathematically? Also, does this equivalence also require ignoring the entropy regularizer? As formulated, L_{RAML} necessarily contains a \\tau, but L_{MRT} does not necessarily contain an alpha. It is only when moving to the sample approximation does the alpha become introduced. (MRT does not require this sample approximation; Some older work on MRT developed dynamic programming algorithms to exactly compute the gradients for structured output spaces like sequences, so samples were not used in those cases.) So I think the paper needs to clarify what exactly is meant by the connection between tau and alpha, under what conditions there is a connection between the two, and what exactly is the nature of this connection. If more space is needed for this, many of the details in Sec 3 can be cut or moved to appendices because those are standard and not needed for what follows. \n\nIn the experimental results (Sec. 7), MRT outperforms RAML consistently. The authors discuss the impact of the directionality of the KL divergence, but what about the entropy regularizer? It would be interesting to compare MRT both with and without the entropy regularizer. Without the regularizer, MRT would actually correspond to the KL that the authors are describing in the discussion. As it currently stands, two things are changing between MRT and RAML and we don\'t know which is responsible for the sizable performance gains. \n\nC. \nThere are several technical issues with the writing (and potentially with the claims/conclusions), most of which are potentially flexible with some corrections and more exposition by the authors:\n\nIs L_{RAML} to be maximized or minimized? Looks like maximized, but clearly both L_{MLE} and L_{MRT} are supposed to be minimized, so the use of L for all of these seems confusing. If different conventions are to be used for each one, it should be explicitly mentioned in each case whether the term is to be maximized or minimized.\n\nAt the end of Sec. 4.1, q\' is not defined. I can guess what it is, but it is not entirely clear from the context and should be defined. \n\nIn Equation 6, please use different notation for the y in the denominator (e.g., y\') to avoid collision with the y in the numerator and that on the left-hand side. \n\nThe discussion of max-margin losses in Sec. 5 has some things that should be fixed. \n\n1. In Sec. 5, it is unclear why \\Delta is defined to be the difference of two r() functions. Why not just make it -r(y, y^*)? Are there some implied conditions on \\Delta that are not stated explicitly? If \\Delta is assumed to be nonnegative, that should be stated. \n\n2. In Eq. (11), F appears to be a function of y and theta, but in the definition of F, it has no functional arguments. But then further down, F appears to be a function of y only. Please make these consistent.\n\n3. Eq. (11) is not only hard for structured settings; it is also hard in the simplest settings (binary classification with 0-1 loss). This is the motivation for surrogate loss functions in empirical risk minimization for classification settings. The discussion in the paper makes it sound as if these challenges only arise in the structured prediction setting. \n\n4. I\'m confused by what the paper is attempting to communicate with Equations 12 and 13. In Eq. 12, y on the left-hand side is not bound to anything, so it is unclear what is being stated exactly. Is it for all y? For any y? In Eq. 13, the \\Delta on the right-hand side is outside the max over y -- is that really what was intended? I thought the max (the slack-rescaled loss-augmented inference step) should take into account \\Delta. Otherwise, it is just doing an argmax over the score function. \n\n5. If the authors are directly optimizing the right-hand side of the inequality in Equation 12 (as would be suggested for the formula for the gradient), then there is no global minimum of the loss. It would go to negative infinity. Typically people use a ""max(0, )"" outside the loss so that the global minimum is 0. \n\n\n\nTypos and minor issues follow:\n\nSec. 1:\n""the SEARN"" --> ""SEARN""\n""the DAGGER"" --> ""DAGGER""\n\nSec. 2:\n""genrally"" --> ""generally""\n""took evaluation metric into training"" --> ""incorporated the evaluation metric into training""\n""consistant"" --> ""consistent""\n\nSec. 3:\nUse \\exp instead of exp.\n""a detail explanation"" --> ""a detailed explanation""\n\nSec. 4.1:\n""predition"" --> ""prediction""\n\nSec. 4.2:\n""only single sample"" --> ""only a single sample""\n\nSec. 6.1:\n""less significant than"" --> ""less significantly than""\n', ""This paper compares several well known methods and illustrates some connections among these methods, and proposes one new method based on Hellinger distance for seq2seq models' training, experimental results on machine translation and sentence summarization show that the method based on Hellinger distance gives the best results. \n\nHowever the originality and significance of this work are weak.""]","[60, 20, -20]","[80, 60, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, such as it being 'well written and interesting' and having 'fairly thorough experiments'. They also mention a 'new loss with potential for improvement'. However, they do point out some cons, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. They use phrases like 'a pleasure to read' and 'interesting and illuminating'. Even when pointing out limitations, they do so in a considerate manner, suggesting ways to strengthen the paper. The update after the author's response further demonstrates politeness, thanking the authors and acknowledging improvements."", ""Sentiment score (20): The review starts with a positive note about the paper's improvement, but still expresses some reservations about its incremental nature. However, it acknowledges the potential significance of even small improvements in the field. The rest of the review provides a balanced mix of pros and cons, suggesting a slightly positive overall sentiment.\n\nPoliteness score (60): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'It is interesting to note' and 'The empirical comparison... is a potentially valuable contribution,' which show appreciation for the authors' work. Even when pointing out issues, the language is constructive rather than harsh, using phrases like 'need some work' and 'I think the paper needs to clarify.' The reviewer also asks questions and suggests improvements, indicating a collaborative approach rather than a purely critical one."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (comparing methods, illustrating connections, proposing a new method), they ultimately conclude that 'the originality and significance of this work are weak.' This final statement carries significant weight and shifts the overall sentiment to the negative side. The politeness score is slightly positive (20) as the reviewer uses neutral, professional language and begins with positive observations before offering criticism. They avoid harsh or personal language, instead focusing on the work itself. The criticism, while direct, is presented matter-of-factly without inflammatory language.""]"
"['This paper proposes a Dynamic Parameter Generator (DPG) that given a test input modifies the parameters of a classification model. They also propose to regularize the training using a Data Generator (DG) to slow down catastrophic forgetting. DG is used to constrain the training that the internal representations of data generated by DG does not rapidly change. DG removes the need for storage of data or labels.\n\nPositives:\n- Both ideas of DPG and DG are novel in preventing catastrophic forgetting.\n- DG is novel because it does not require storage of data and does not depend on labels.\n- Experimental results are significantly better than the previous state-of-the-art.\n\nSuggestions and clarification requests:\n- Figures are very small and equations are cramped because of reduced spacing.\n- There are some vague explanations in the intro that could be reduced. It would be nice to first introduce concrete math then give the intuitions. That saves some space.\n- It would nice to compare to the recent Progress & compress [1]. Unfortunately, they have not provided results on benchmark MNIST tasks.\n- This work is related to a recently proposed idea in architecture search [2] that learns to predict the weights of a network given its architecture.\n- Can you clarify whether you have used DG at test time?\n- Can you report results without using DG? It is not clear whether DPG is accountable for preventing the catastrophic forgetting or the sluggishness enforced by DG.\n- Questions 1 and 2 need more formalization if the authors want to clearly prove a statement.\n- As the answer to Question 1 suggests, have you explored enforcing a Lipschitz constraint?\n- The answer to Question 2 is interesting. Could you rewrite it more formally? It seems like you can argue that DG’s objective encourages the employment of unused parameters which is important in tackling catastrophic forgetting.\n- Can you elaborate on how much forgetting happens for DG?\n- It seems that in figure 3.f and 3.c the MA method is unable to reach the best possible performance on the last task. Can you also report the table of accuracies on the last task?\n\n[1] Schwarz, Jonathan, et al. ""Progress & Compress: A scalable framework for continual learning."" arXiv preprint arXiv:1805.06370 (2018).\n[2] Brock, Andrew, et al. ""SMASH: one-shot model architecture search through hypernetworks."" arXiv preprint arXiv:1708.05344 (2017).', 'Summary: \n- In this paper, an algorithm to improve the catastrophic forgetting of the model is proposed. The key idea consists of 1) introducing the dynamic parameter generator (DPG) for ""model\'s adaptation"" to data at test time and 2) data generator (DG) for remembering previously trained dataset. \n\nPros: \n- Empirical results seem strong. The proposed result outperforms existing algorithms by quite large margin.\n\nCons:\n- In general, I felt that the paper is unorganized and hard to read. Clarity should be definitely improved if this paper is to be published as a conference paper.\n\n- Output of dynamic parameter generator is very high dimensional (it requires weight with dimension of input dim x NN weight dim). I think this approach is not scalable to higher dimension and typically requires even more memory than storing the whole dataset. \n\n- Although auto-encoder and generative replay was considered to reduce memory consumption, there is no description of how much memory is saved by them. In order to make the argument more convincing, the authors should explicitly describe the amount of memory consumed by each algorithms. \n\n- There seems to be a lot of ideas introduced, i.e, DPG for generation of weights, auto-encoders for generation of data and layer output constraint, i.e., Equation (7).  I think each of introduced method deserves some amount of empirical evaluation to validate its contribution to the performance.  \n\n- Experiments only consider 2~3 tasks, which does not seem very representative for the lifelong learning tasks.\n', 'This paper proposes a method for continual learning. The model has three components: a) a data generator to be used at training time to replay past examples, b) a parameter generator that takes the input observation to produce parameters for c) the actual classifier. The authors demonstrate the method on simple datasets with a stream of 2 or 3 tasks.\n\nStrenghts:\n- the combination of components is novel\n- the method does not rely on task descriptors neither at training nor test time\nWeaknesses:\n- the paper needs a major rewrite to improve fluency and to better organize and describe the proposed approach\n- the empirical validation is weak.\n\nRelevance\nLearning in a continual setting is certainly very relevant for this venue.\n\nNovelty\nWhile each component is by itself not very novel (replay methods for continual learning have already been used, networks predicting parameters have also become a fairly common approach in meta-learning literature), the proposed combination is novel in this sub-field.\n\nClarity\nClarity is very poor and definitely does not meet the acceptance bar for this conference. I believe that the authors would need to make a major revision to address this issue. While ICLR allows authors to revise papers, I think the revision needed to fix this draft goes beyond the acceptable limit, as reviewers would then need to make a whole new revision.\nFirst, fluency is very poor. There are lots of grammatical errors (see first sentence of introduction ""neural networks suffers..""),  a plethora of un-necessary acronyms which force the reader to go back and forth to figure out what they refer to (MA, DG, DPG, DPG&S, ...), and several sentences are not well formed (e.g., read first sentence of introduction).\nSecond, some statements are contradictory; e.g., the authors define ""basic unit"" as ""simple MLP with one hidden layer"", but then say it ""is an activation function plus a matrix transformation""..\nThird, graphics and formulas are too small and not legible.\nFourth, the organization of the paper is poor, it is very wordy yet vague. For instance, the authors should precisely describe how the data generator is trained in sec. 2.3. The authors should provide an algorithm summarizing how the different components interplay both at training and test time. At present, I am making educated guesses about how this system works.\nFor instance, how are real and generated examples interleaved? how is forgetting prevented in the data generator?   \n\nReferences to prior work\nWhile there are lots of references in sec. 4, they are not sufficiently well described - see third paragraph of sec. 4 where the authors cite almost 20 papers by simply saying they are ""some other approaches"". \nAlso, I did not find mention to methods predicting parameters in the meta-learning community but also others like:\nDenil et al. ""Predicting network parameters in deep learning"" NIPS 2013\n \nEmpirical validation\nThe empirical evaluation does show an advantage of the proposed approach on some simple streams composed by up to three tasks. However, a) the tasks are really simple because of the small number of tasks considered and b) the baselines are weak. For instance, EWC is now a bit out-dated as there are variants that work a bit better, like:\nChaundry et al. ""Riemannian Walk ..."" ECCV 2018\nand there are other methods like ""Progress and Compress"" Schwartz ICML 2018 the authors could have compared against.\nBesides, the authors do not mention anything about memory and time cost both at training and test time, possibly including the time to cross validate all the hyper-parameters of this method.\nOverall, I am left with the sense that the proposed approach will be hard to scale to many more tasks and more realistic images (for which we do not quite know how to train efficiently and well generators).\n\nOther comments\nI did not find the formalization in eq. 9 very useful. The first and last term in that equation can be very big and there is no sense of how lose this bound is.\nAlso, it is not clear whether there is a general principle to partition the set of parameters (to determine which ones should be shared).']","[70, -20, -50]","[80, 50, 20]","[""The sentiment score is 70 (positive) because the reviewer starts by highlighting the novelty and effectiveness of the proposed methods, noting 'significantly better' results than state-of-the-art. The positives are clearly stated. While there are suggestions and requests for clarification, these are presented as opportunities for improvement rather than criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing suggestions as requests ('Can you clarify...', 'It would be nice to...') rather than demands. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach. The use of phrases like 'nice to compare' and 'interesting' when discussing potential improvements further contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths ('Empirical results seem strong'), they list more cons than pros and express concerns about the paper's organization, clarity, and scalability. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'I felt that' and 'I think' to soften their critiques, and provide constructive feedback for improvement rather than outright dismissal of the work."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths ('the combination of components is novel'), they highlight significant weaknesses, particularly in clarity and empirical validation. The review is predominantly critical, stating the paper 'needs a major rewrite' and the empirical validation is 'weak'. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I believe' and 'I am left with the sense that', which soften the criticism. They also balance negative feedback with positive points. However, some direct criticisms ('Clarity is very poor') prevent a higher politeness score. The reviewer provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score.""]"
"['The authors consider the problem of learning from positive and unlabeled data in which only a subset of the true positives is labeled. While the common assumption (eg Elkan & Noto, du Plessis et al.) prescribes that the labeled set is picked independently at random from the positive set, this paper assumes that a (positive) example x is more likely to be labeled the more it exhibits positive features: formally, the higher Pr(y=1 | x), the higher Pr(o=1 | x). For instance, in the case of anomaly detection, the more likely an example is anomalous, the more likely it would get manually flagged (labeled) as positive. The authors refer to this assumption as Invariance of Order.\n\nThe proposed method requires the knowledge of the positive class prior Pr(y=1), and can be summarized in the following three steps: (i) estimate r(x)=Pr(x | y=1, o=1`)/Pr(x); (ii) find the threshold \\theta such that the number of datapoints x with r(x) > \\theta is a fraction Pr(y=1); (iii) train a classifier on sign(r(x) - \\theta). Conceptually, the Invariance of Order assumption allows to use the order on r(x) as a proxy for an order on Pr(y=1|x), so then the knowledge of Pr(y=1) is enough to find \\theta, and to port the original problem to a vanilla binary classification problem.\n\nConcerns:\n- He et al. 2018 use a very similar assumption and no comparison with that work is provided. The authors briefly mention that work in the introduction but don\'t perform due diligence in assessing differences/novelties with respect to that work, neither as a discussion or in the experiments.\n- The requirement of knowing the fraction of positive examples is hard to justify in practice. Have you tried using the estimate obtained by Elkan et al, or other related work?\n- Experiments are confusing and not convincing: apart from the very last experiment, all datasets are synthetic. No comparison with previous work is presented, except for ""unbiased PU learning (PU)"", which I assume is Elkan et al ? If that is indeed the case, which one of their methods are you comparing against? Even more troublesome is the fact that in all experiments you\'re providing your algorithm with the correct class-prior Pr(y=1), but it\'s not clear if this is provided to PU as well. You may want to consider estimating Pr(y=1) using methods from related work to see how it affects the accuracy.\n- Related work discussion is completely missing apart from one paragraph in the introduction.\n\nMinor:\n- The acronym SCR is not very conventional; I would suggest IID which is often used as shorthand for independently identically distributed.\n- Invariance of Order: when introducing it, you may want to add a sentence providing the intuition behind the assumption.\n- Example 2 (Face recognition) is not very convincing and not very clear. Please rephrase.\n- Pseudo-classification risk: why was the log-loss used? Can other losses be used as well?\n- Theorem 3: add some intuition and explain tradeoff on \\epsilon\n- Experiments section: help the reader by adding a reminder on equations, as it\'s difficult to flip back and forth to their definitions. Eg, ""we trained a classifier minimizing (4) and (7) with the model (10)"" is difficult to digest and follow.\n- Experiments: confusing commas in {800,1,600,3,200} => {800, 1600, 3200}\n- Too many acronyms and abbreviations.\n\n', 'The paper proposes an approach to learning from positive and unlabelled data with a sample selection bias. Specifically, it is assumed that the observed positive instances are not necessarily drawn iid from the true positive distribution: rather, there is some bias as to which positive examples are selected. Under an assumption on the selection probability being proportional to the true probability, it is established that one may equally rank instances based on their probability of being labelled. Two algorithms are proposed for this task.\n\nLearning under sample selection bias is an important and interesting problem. It is also arguably more realistic than the classic PU learning setting. The paper proposes a reasonable solution, which builds on some recent advances in the literature on PU learning.\n\nMy only critique is that the results are somewhat unsurprising in light of existing work on this topic (the idea of constructing unbiased risk estimators), and also on the topic of learning from label loans. Further, I believe some clarifications would better position the contributions of the paper, both in terms of strengths and limitations. More specifically:\n\n- it seems the problem could be cast as a (interesting) special case of learning from instance dependent label noise. The assumption of the selection (i.e., label flip) probability preserving the ordering of the true class probability has a fair amount of precedent in these works; see, e.g.,\n\nBylander \'97, Learning probabilistically consistent linear threshold functions\nDu and Cai \'15, Modelling class noise with symmetric and asymmetric distributions\nBootkrajang \'16, A generalised label noise model for classification in the presence of annotation errors\n\nIt is in light of these works that I do not find Theorem 1 surprising. I note that the sample-selection bias setting could be seen as an interesting special case, but some discussion on the connection seems prudent.\n\n- like in the above works, the proposed approach does not construct an unbiased estimator to the underlying risk. Instead, what is shown in e.g. Theorem 3 is that the Bayes-optimal solution to the risk is sensible. This is of course a minimal desiderata for any learning method, but unlike approaches for the classic PU learning setting, the lack of unbiasedness implies that minimizing over a restricted function class F may result in quite different solutions than if we had access to the true labels. Again, this isn\'t a limitation unique to this particular work, but I did feel the point could be made a little more explicit.\n\n- also like the above work, there isn\'t a clear way of estimating P(y = 1). As this is crucial for the final risk estimate, it somewhat restricts the universality of the approach.\n\n- with regards to the two algorithms proposed, both go about estimating the underlying ""noisy"" class probability (i.e., the probability of an instance being selected for labeling), just with different losses. While the logistic or ""LSIF"" loss are certainly valid choices, one could use any number of other similar loss (e.g., the exponential loss from class-probability estimation, or the ""KLIEP"" loss from density ratio estimation). Of course the specific choice of LSIF e.g. can be motivated since it has a closed-form solution, but the basic point is that the two approaches really boil down to changing the underlying loss function. This point could also be clarified.\n\n\nOther comments:\n\n- I believe the Elkan & Noto paper operates in the censoring rather than case-controlled setting.\n\n- there are a few grammatical issues: e.g.., ""Several recent researches"", ""is to find anomaly data""\n\n- I don\'t follow how the case-controlled setting is ""more general"" than the censoring setting, as claimed in Sec 2; do you mean it is more practically realistic?\n\n- it is correct to say in 2.1 that one cannot estimate p(y = 1 | x) from only PU data without assumptions. The next sentence states that a typical assumption that is thus made is SCR. However, this also does not guarantee that we can estimate the probability, since estimating p(y = 1) is also not possible without even further assumptions (see e.g. the mutually contaminated distribution work of Scott et al., 2013).\n\n- in Defn 1, it would be clearer to explicate the dependence of all quantities on r.\n\n- it is interesting that one achieves the BEP with the choice of threshold given by (2). But given that p(y = 1) is in general hard to estimate, it seems one could equally cast the problem of estimating p(y = 1) as the problem of choosing a good threshold? (This of course ignores the fact that we ostensibly need p(y = 1) when constructing the risk estimate.)\n\n- restricting attention to scorers with output in [eps, 1 - eps] is a little strange. I assume this is in order to avoid solutions at +- infinity, which is a well-known problem with the logistic loss. It may be more natural to simply state that you operate with the extended real numbers.\n\n- in the proof of Thm 3, I don\'t see the need to go through an infinite dimensional Lagrangian route. Since one is optimizing over all possible measurable functions, can one not (under suitable regularity conditions on the distribution & loss) simply compute the minimizer point wise for each x? This optimization would be a one-dimensional problem over predictions the domain [eps, 1 - eps]. The ""inner risk"" to be optimized (in the sense of Steinwart \'06, ""How to compare different loss functions and their risks"") would I believe be a convex function, admitting exactly the minimizer claimed in the statement of the theorem.\n\n- it is a bit confusing to move from F to \\hat{F} as the function class.\n', 'In this paper, the authors present a new technique to learn from positive and unlabeled data. Specifically they are addressing the issues that arise when the positive and unlabeled data do not come from the same distribution. The way to achieve this is to learn a scoring function which preserves -the order- of the label posteriors. In other words, the authors are not making assumptions and then learning the exact posterior of p(y|...) but rather just a function r(x) with the property that if p(y_i) < p(y_j) then r(x_i) < r(x_j).\n\nI am not super familiar in the area but I didn\'t see any fundamental flaws. The approach makes sense and although I cannot judge the novelty of this paper, it is a useful tool in the PU learning toolbox addressing an arguably important problem (selection bias). Except for section 5.3, the experiments are not that interesting as they are made up artificially by the authors.\n\nThoughts:\n- In example 1, be specific about what p(y|...) and p(o|...) are.\n- In example 2, I wasn\'t sure what p(o|...) exactly would be.\n- Assumption 1, the first sentence I understand. The ""if and only if"" part I don\'t see. Can you clarify?\n']","[-50, -20, 50]","[50, 60, 70]","[""The sentiment score is -50 because while the reviewer acknowledges the novelty of the approach, they express several significant concerns about the paper. These include lack of comparison with similar work, practical issues with the method's requirements, and problems with the experiments. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They frame their criticisms as 'concerns' and use phrases like 'you may want to consider' when making suggestions. The reviewer also provides constructive feedback and specific recommendations for improvement, which is a polite approach to peer review. However, the score is not higher as the review is quite direct in its criticisms, without much softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance and interest of the topic, they express several critiques and concerns about the paper's contributions and clarity. The reviewer states that the results are 'somewhat unsurprising' and suggests multiple areas for improvement or clarification. However, the tone is not entirely negative, as the reviewer also recognizes the paper's reasonable approach and builds on recent advances. The politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They frame critiques as suggestions for improvement rather than harsh criticisms, using phrases like 'I believe some clarifications would better position the contributions' and 'it seems one could'. The reviewer also balances critiques with positive acknowledgments of the paper's merits. The language is professional and academic throughout, avoiding any rudeness or overly blunt statements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's usefulness and doesn't see any fundamental flaws, but also notes that some experiments are not very interesting. The politeness score is 70 (fairly polite) as the reviewer uses respectful language, acknowledges their own potential lack of expertise ('I am not super familiar in the area'), and frames their suggestions as 'thoughts' rather than demands. The reviewer also balances critique with positive feedback, which contributes to the polite tone.""]"
"['The paper presents a combination of evolutionary search methods (CEM) and deep reinforcement learning methods (TD3). The CEM algorithm is used to learn a Diagional Gaussian distribution over the parametes of the policy. The population is sampled from the distribution. Half of the population is updated by the TD3 gradient before evaluating the samples. For filling the replay buffer of TD3, all state action samples from all members of the population are used. The algorithm is compared against the plane variants of CEM and TD3 as well as against the evoluationary RL (ERL) algorithm. Results are promising with a negative result on the swimmer_v2 task.\n\nThe paper is well written and easy to understand. While the presented ideas are well motivated and it is certainly a good idea to combine deep RL and evoluationary search, novelty of the approach is limited as the setup is quite similar to the ERL algorithm (which is still on archive and not published, but still...). See below for more comments:\n- While there seems to be a consistent improvement over TD3, this improvement is in some cases small (e,g. ants). \n- We are learning a value function for each of the first half of the population. However, the value function from the previous individual is used to initialize the learning of the current value function. Does this cause some issues, e.g., do we need to set the number of steps so high that the initialization does not matter so much any more? Or would it make more sense to reset the value function to some ""mean value function"" after every individual?\n- The importance mixing does not seem to provide a better performance and could therefore be shortened in the paper\n\n\n\n', 'Gradient-free evolutionary search methods for Reinforcement Learning are typically very stable, but scale poorly with the number of parameters when optimizing highly-parametrized policies (e.g. neural networks). Meanwhile, gradient-based deep RL methods, such as DDPG are often sample efficient, particularly in the off-policy setting when, unlike evolutionary search methods, they can continue to use previous experience to estimate values. However, these approaches can also be unstable.\n\nThis work combines the well-known CEM search with TD3 (an improved variant of DDPG). The key idea of of this work is in each generation of CEM, 1/2 the individuals are improved using TD3 (i.e. the RL gradient). This method is made more practical by using a replay buffer so experience from previous generations is used for the TD3 updates and importance sampling is used to improve the efficiency of CEM.\n\nThis work shows, on some simple control tasks, that this method appears to result in much stronger performance compared with CEM, and small improvements over TD3 alone. It also typically out-performs ERL.\n\nIntuitively, it seems like it may be possible to construct counter-examples where the gradient updates will prevent convergence. Issues of convergence seem like they deserve some discussion here and potentially could be examined empirically (is CEM-TD3 converging in the swimmer?).\n\nThe justification that the method of Khadka & Tumer (2018) cannot be extended to use CEM, since the RL policies do not comply with the covariance matrix is unclear to me. Algorithm 1, step 20, the covariance matrix is updated after the RL step so regardless of how the RL policies are generated, the search distribution on the next distribution includes them. In both this work, and Khadka & Tumer, the RL updates lead to policies that differ from the search distribution (indeed that is the point), and there is no guarantee in this work that the TD3 updates result in policies close to the starting point. It sees like the more important distinction is that, in this approach, the information flows both from ES to RL and vice-versa, rather than just from RL to ES.\n\nOne view of this method would be that it is an ensemble method for learning the policy [e.g. similar to Osband et al., 2016 for DQN]. This could be discussed and a relevant control would be to keep a population (ensemble) of policies, but only update using RL while sharing experience across all actors. This would isolate the ensemble effect from the evolutionary search.\n\nMinor issues:\n\n- The ReLU non-linearity in DDPG and TD3 prior work is replaced with tanh. This change is noted, but it would be useful to make a least a brief (i.e. one sentence) comment on the motivation for this change.\n\n- The paper is over the hard page limit for ICLR so needs to be edit to reduce the length.\n\nOsband I, Blundell C, Pritzel A, Van Roy B. Deep exploration via bootstrapped DQN. InAdvances in neural information processing systems 2016 (pp. 4026-4034).', 'The contributions of this paper are in the domain of policy search, where the authors combine evolutionary and gradient-based methods. Particularly, they propose a combination approach based on cross-entropy method (CEM) and TD3 as an alternative to existing combinations using either a standard evolutionary algorithm or a goal exploration process in tandem with the DDPG algorithm. Then, they show that CEM-RL has several advantages compared to its competitors and provides a satisfactory trade-off between performance and sample efficiency.\n\nThe authors evaluate the resulting algorithm, CEM-RL, using a set of benchmarks well established in deep RL, and they show that CEM-RL benefits from several advantages over its competitors and offers a satisfactory trade-off between performance and sample efficiency.  It is a pity to see that the authors provide acronyms without explicitly explaining them such as DDPG and TD3, and this right from the abstract.\n\nThe parer is  in general interesting, however the clarity of the paper is hindered  by the existence of several typos, and the writing in certain passages can be improved. Example of typos include  “an surrogate gradient”, “""an hybrid algorithm”,  “most fit individuals are used ” and so on… \n\nIn the related work the authors present the connection between their work and contribution to the state of the art in a detailed manner.  Similarly, in section 3 the authors provide an extensive background allowing to understand their proposed method.\n\nIn equation 1, 2 the updates of  \\mu_new and \\sigma_new uses \\lambda_i, however the authors provide common choices for \\lambda without any justification or references.\n\nThe proposed method is clearly explained and seems convincing. However the theoretical contribution is poor. And the experiment uses a very classical benchmark providing simulated data.\n\n1. In the experimental study, the authors present the value of their tuning parameters (learning rate, target rate, discount rate…) at the initialisation phase without any justifications. And the experiments are limited to simulated data obtained from MUJOCO physics engine - a very classical benchmark. \n2. Although the experiments are detailed and interesting they support poor theoretical developments and use a very classical benchmark\n']","[50, 50, 20]","[75, 75, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'well written and easy to understand' and notes that the results are 'promising'. However, they also point out limitations in novelty and some areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They acknowledge the merits of the work while providing specific, helpful feedback for improvement. The tone is professional and courteous, avoiding any rude or dismissive language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strengths of the proposed method, noting it shows 'much stronger performance' and 'small improvements' over existing approaches. However, they also raise some concerns and suggest areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as possibilities rather than demands (e.g., 'It seems like it may be possible...'). The reviewer also acknowledges the work's contributions before offering critiques. The language is professional and objective, avoiding any harsh or dismissive tones."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting contributions and clear explanations, but also points out several shortcomings. The reviewer mentions that the paper is 'generally interesting' and the method is 'clearly explained and seems convincing'. However, they also note issues with clarity, typos, lack of theoretical contribution, and limited experimental scope. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'it is a pity to see' rather than harsh criticism. They provide constructive feedback and balance positive aspects with areas for improvement. The reviewer doesn't use overly formal or polite language, but also avoids rudeness, maintaining a neutral to slightly polite tone.""]"
"['This paper analyzed the global convergence property of SGD in deep learning based on the star-convexity assumption. The claims seem correct and validated empirically with some observations in deep learning. The writing is good and easy to follow.\n\nMy understanding of the analysis is that all the claims seem to be valid when the solution is in a wide valley of the loss surface where the star-convexity holds, in general. This has been observed empirically in previous work, and the experiments on cifar10 in Fig. 2 support my hypothesis. My questions are:\n\n1. How to guarantee the star-convexity will be valid in deep learning?\n2. What network or data properties can lead to such assumption?\n\nAlso, this is a missing related work from the algorithmic perspective to explore the global optimization in deep learning: \n\nZhang et. al. CVPR\'18. ""BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning"".\n', 'This paper attempts to account for the success of SGD on training deep neural networks. Starting from two empirical observations: (1) deep neural networks can almost achieve zero training loss; (2) the path of iterates generated by SGD on these models follow approximately the “star convex path”, under the assumptions that individual functions share a global minima with respect to which the path of iterates generated by SGD satisfies the star convexity properties, the papers shows that the iterates converges to the global minima. \n\nIn terms of clarity, I think the paper can definitely benefit if the observations/assumptions/definitions/theorems are stated in a more formal and mathematically rigorous manner. For example:\n- On page 3, “fact 1”: I don’t think “fact” is the right word here. “Fact” refers to what has been rigorously proved or verified, which is not the case for what is in the paper here. I believe “observation” is more appropriate. Also the assumption that l_i is non-negative should be formally added.\n- On page 3, section 3.1: the x^* here is the last iteration produced by SGD. Then how can it be called the “global minima”? The caption of Figure 1 on page 4 is simply misleading.\n- On page 4, the statement in definition 1 is more like a theorem than a definition. It is giving readers the impression that any path generated by SGD satisfies the star-convex condition, which is not the case here. A definition should look like “we call a path generated by SGD a star-convex path if it satisfies …”. Definition 2 on page 6 has the similar issue.\n\nIn terms of quality, while I believe the paper is technically correct,  I have one minor question here:\nPage 3, Fact 1: How can you conclude that the set of common global minimizers are bounded? In fact I don’t believe this is true at all in general. If you have a ReLu network, you can scale the parameters as described in [1], then the model is invariant. Therefore, the set of common minimizer is definitely NOT bounded. \n\nIn terms of significance, I think this paper is very interesting as it attempts to draw the connection between the aforementioned observations and the convergence properties of SGD. Unfortunately I think that this paper is less significant than it has appeared to be, although the analysis appears to be correct. \n\nFirst of all, all the analysis of this paper is based on one very important and very strong assumption, namely, all individual functions $l_i$ share at least one common global minimizer. The authors have attempted to justify this assumption by empirical evidences (figure 1). However, achieving near-zero loss is completely different from achieving exact zero because only when the model achieves exact zero can you argue that a common global minimizer exists. \n\nSecondly, the claim that the iterate converges to the global minima is based on the assumption that the path follows an “epoch-wise star-convex” property. From this property, it only takes simple convex analysis to reach the conclusion of theorem 1 and 2. Meanwhile, the assumption that the path does follow the “epoch-wise start-convex” properties is not at all informative. It is not clear why or when the path would follow such a path. Therefore theorem 1 and 2 are not more informative than simply assuming the sequence converges to a global minimizer. \n\nIn fact, it is well-known that SGD with constant stepsize converges to the unique minimizer if one assumes the loss function F is strongly convex and the variance of the stochastic gradient g_k is bounded by a multiple of the norm-square of the true gradient:\nVar(g_k) <= M ||∇F(x_k)||^2\nWhich is naturally satisfied if all individual functions share a common minimizer. Therefore, I don’t think the results shown in the paper is that surprising or novel. \n\nWith respect to the empirical evidence, the loss function l_i is assumed to be continuously differentiable with Lipschitz continuous gradients, which is not true for networks using ReLU-like activations. Then how can the paper use models like Alexnet to justify the theory? Also, if what the authors claim is true, then the stochastic gradient would have vanishing variance as it approaches x^*. Can the authors show this empirically?\n\nIn summary, I think this paper is definitely interesting, but the significance is not as much as it would appear.\n\nRef: \n[1] Dinh, L., Pascanu, R., Bengio, S., & Bengio, Y. (2017). Sharp minima can generalize for deep nets. arXiv preprint arXiv:1703.04933.', ""The paper proposes a new approach to explain the effective behavior of SGD in training deep neural networks by introducing the notion of star-convexity. A function h is star-convex if its global minimum lies on or above any plane tangent to the function, namely h* >= h(x) + < h'(x), x*-x> for any x. Under such condition, the paper shows that the empirical loss goes to zero and the iterates generated by SGD converges to a global minimum. Extensive experiments has been conducted to empirically validate the assumption. \n\nThe paper is very well organized and is easy to follow. The star-convexity assumption is very interesting which provides new insights about the landscape of the loss function and the trajectory of SGD. It is in general difficult to theoretically check this condition so several empirical verifications has been proposed. My main concern is about these empirical verifications.\n\n1) The minimum of the cross entropy loss lies at infinity \nThe experiments are performed respect to the cross entropy loss. However, cross entropy loss violates Fact 1 since for any finite weight, cross entropy loss is always strictly positive. Thus the zero is never attained and the global minimum always lies at infinity. As a result, the star-convexity inequality h* >= h(x) + < h'(x), x*-x> hardly makes sense since x* is at infinity and neither does the theorem followed. \nIn this case, a plot of the norm of xk is highly suggested since it is a sanity check to see whether the iterates goes to infinity. \n\n2) The phenomenon may depend on the reference point, i.e last iterate\nSince the minimum is never attained, the empirical check of the star-convexity maybe biased. More precisely, it might be possible that the behavior of the observed phenomenon depends on the reference point, i.e. the last iterate. Therefore, it will be interesting to see if the observed phenomenon still holds when varying the stopping time, for instance plot the star convexity check using the iterates at 60, 80, 100, 120 epochs as reference point. \n\nIn fact, the experiments shown in Figure 4 implicitly supports that the behavior may change dramatically respect to different reference point. The reason is that the loss in these experiments are far away from 0, meaning that we are far from the minimum, thus checking the star-convexity does not make sense because the star-convexity is only defined respect to the minimum. \n\nOverall, the paper provides interesting idea but the empirical results may be biased due to ill-posed problem ""]","[60, -30, -20]","[70, 60, 60]","[""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper's analysis, claims, and writing. They state that the claims seem correct and validated, and the writing is good and easy to follow. However, it's not extremely positive as they raise some questions and point out a missing related work. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their questions and suggestions constructively. They use phrases like 'My understanding' and 'My questions are', which show consideration for the authors. The reviewer also provides a specific suggestion for additional related work in a helpful manner, rather than criticizing its absence harshly."", ""The sentiment score is -30 because while the reviewer acknowledges the paper as 'interesting' and 'technically correct', they express significant concerns about its clarity, assumptions, and overall significance. The reviewer states that the paper is 'less significant than it has appeared to be' and questions the novelty of the results. However, the score is not extremely negative as the reviewer does find some value in the paper's attempt to connect observations with SGD convergence properties. The politeness score is 60 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I think' and 'I believe' to soften criticisms. They also acknowledge positive aspects before presenting concerns. The reviewer offers constructive feedback and specific suggestions for improvement, which contributes to the polite tone. However, the score is not extremely high as the criticism, while politely phrased, is still direct and substantial."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-organized and provides interesting insights, they express significant concerns about the empirical verifications. The reviewer points out potential flaws in the experimental setup and interpretation, which outweigh the initial positive comments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'My main concern is...' and 'it will be interesting to see...' which maintain a constructive tone. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"['\nThe authors present a GAN based framework for Graphic Layouts. Instead of considering a graphic layout as a collection of pixels, they treat it as a collection of primitive objects like polygons. The objective is to create an alignment of these objects that mimics some real data distribution.\n\nThe novelty is a differentiable wireframe rendering layer allowing the discriminator to judge alignment. They compare this with a relation based discriminator based on the point net architecture by Qi et al. The experimentation is thorough and demonstrates the importance of their model architecture compared to baseline methods. \n\nOverall, this is a well written paper that proposes and solves a novel problem. My only complaint is that the most important use case of their GAN (Document Semantic Layout Generation) is tested on a synthetic dataset. It would have been nice to test it on a real life dataset.', '\x0c\nSummary: This paper presents a novel GAN framework for generating graphic layouts which consists of a set of graphic elements which are geometrically and semantically related. The generator learns a function that maps input layout ( a random set of graphic elements denoted by their classes probabilities and and geometric parameters) and outputs the new contextually refined layout. The paper also explores two choices of discriminators: (1) relation based discriminator which directly extracts the relations among different graphic elements in the parameter space, and (2) wireframe rendering discriminator which maps graphic elements to 2D wireframe images using a differentiable layer followed by a CNN for learning the discriminator. The novel GAN framework is evaluated on several datasets such as MNIST, document layout comparison and clipart abstract scene generation  \n\nPros:\n- The paper is trying to solve an interesting problem of layout generation. While a large body of work has focussed on pixel generation, this paper focuses on graphic layouts which can have a wide range of practical applications. \n- The paper presents a novel architecture by proposing a generator that outputs a graphic layout consisting of class probabilities and polygon keypoints. They also propose a novel discriminator consisting of a differentiable layer that takes the parameters of the output layout and generates a rasterized image representing the wireframe. This is quite neat as it allows to utilize a CNN for learning a discriminator for real / fake prediction. \n- Qualitative results are shown on a wide variety of datasets - from MNIST to clipart scene generation and tangram graphic design generation. I found the clipart scene and tangram graphic design generation experiments quite neat. \n\nCons:\n- While the paper presents a few qualitative results, the paper is missing any form of quantitative or human evaluation on clip-art scene generation or tangram graphic design generation. \n- The paper also doesn’t report results on simple baselines for generating graphic layouts. Why not have a simple regression based baseline for predicting polygon parameters? Or compare with the approach mentioned in [1]\n- Even for generating MNIST digits, the paper doesn’t report numbers on previous methods used for MNIST digit generation. \nInterestingly, only figure 4 shows results from a traditional GAN approach (DCGAN). Why not show the output on other datasets too? \n\nQuestions / Remarks:\n- Why is the input to the GAN not the desired graphic elements and pose the problem as just predicting the polygon keypoints for those graphic elements. I didn’t quite understand the motivation of choosing a random set of graphic elements and their class probabilities as input.  \n    - How does this work for the case of clip-art generation for example? The input to the gan is a list of all graphic elements (boy, girl glasses, hat, sun and tree) or a subset of these?\n    - It is also not clear what role the class probabilities are playing this formulation. \n- In section 3.3.2, it’s mentioned that the target image consist of C channels assuming there are C semantic classes for each element. What do you mean by each graphic element having C semantic classes? Also in the formulation discusses in this section, there is no further mention of C. I wasn’t quite clear what the purpose of C channels is then. \n- I found Figure 3b quite interesting - it would have been nice if you expanded on that experiments and the observations you made a little more. \n\n[1] Deep Convolutional Priors for Indoor Scene Synthesis by Wang et al\n', 'Summary:\nThe paper proposed to use GAN to synthesize graphical layouts. The generator takes a random input and generates class probabilities and geometric parameters based on a self-attention module. The discriminator is based on a differentiable wireframe rendering component (proposed by the paper) to allow back propagation through the rendering module. I found the topic very interesting and the approach seems to make sense.\n\nQuality:\n+ The idea is very interesting and novel.\n\nClarity:\n+ The paper is clearly written and is easy to follow.\n\nOriginality:\n+ I believe the paper is novel. The differentiable wireframe rendering is new and very interesting.\n\nSignificance:\n+ I believe the paper has value to the community.\n- The evaluation of the task seems to be challenging (Inception score may not be appropriate) but since this is probably the first paper to generate layouts, I would not worry too much about the actual accuracy.\n\nQuestion:\nWhy not ask the generator to generate the rendering instead of class probabilities?']","[80, 50, 80]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well written' and praises its novelty, thorough experimentation, and successful problem-solving. The only criticism is minor, regarding the use of a synthetic dataset. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively. The critique is presented constructively as a suggestion rather than a harsh criticism. The reviewer's tone is professional and appreciative, avoiding any rude or dismissive language."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary and lists both pros and cons. The reviewer acknowledges the interesting problem, novel architecture, and neat qualitative results as positives. However, they also point out significant limitations such as lack of quantitative evaluation and comparisons to baselines. The overall tone is constructive rather than overtly positive or negative.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They frame criticisms as 'cons' rather than direct attacks, and use phrases like 'I found... quite neat' to express positive opinions. The questions and remarks section is phrased politely, using 'Why not...' and 'It would have been nice if...' rather than demanding changes. The reviewer also acknowledges the paper's contributions before suggesting improvements, which is a polite approach to criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses strong interest in the topic and approach, highlighting several positive aspects such as novelty, clarity, and significance. They use phrases like 'very interesting', 'novel', and 'clearly written'. The only mild criticism is about evaluation, but it's presented as a minor concern. The politeness score is 70 (polite) because the reviewer maintains a respectful and constructive tone throughout. They offer balanced feedback, acknowledging both strengths and potential areas for improvement. The language is professional and courteous, avoiding harsh criticism. The question at the end is posed in a curious, non-confrontational manner, further demonstrating politeness.""]"
"[""The authors propose a new weight re-parameterization technique called Equi-normalization (ENorm) inspired by the Sinkhorn-Knopp algorithm. The authors show that the proposed method preserve functionally equivalent property in respect of the output of the functions (Linear, Conv, and Max-Pool) and show also that ENorm converges to the global optimum through the optimization. The experimental results show that ENorm performs better than baseline methods on CIFAR-10 and ImageNet datasets.\n\npros)\n(+) The authors provide a theoretical ground.\n(+) The theoretical analysis of the convergence of the proposed algorithm is well provided.\n(+) The computational overhead reduced by the proposed method compared with BN and GN looks good.\n\ncons)\n(-) There is no comparison with other weight reparameterization methods such as Weight Normalization, Normalization propagation, Instance Normalization, or Layer Normalization. \n(-) The evidence why functionally equivalence is connected to the performance or generalization ability is not clarified.  \n(-) The experimental results cannot consistently show the effectiveness of the proposed method in test accuracy. In Table 4, the proposed method outperforms BN, but In Table 2 and 3, BN is mostly better than the proposed method.\n(-)  The batch size shown in Table 2 and 3 may be intended to show the batch-independent property of the proposed method, but BN is also doing well in those tables. Therefore, Table 2 and 3 are not adequate to show the batch-independent property.\n(-) The proposed method should evaluate with deeper networks (e.g., ResNet-50, ResNet101, or DenseNet-169) to support the superiority over BN and GN.  \n(-) Adjusting c does not seem to be promising. In Table 2 and 3, ENorm-1 is better than ENorm-1.2, and also in Table 4, only the result of ENorm-1 is provided. The authors should do a parameter study with c to make all the experiments more convincing.\n\nComments) \n- The experimental settings are not consistent. The authors should provide the reason why they set those settings or should include some studies about the parameters (for example about the paramter c). \n- Section 3.7 is not clear to me.  How's the performance going on when adjusting c < 1?\n- It is better for the authors to provide the Sinkhorn-Knopp algorithm (SK algorithm), which gave them an inspiration for this work, for better readability. \n- Why eq.(4) is necessary? For iterative optimization? If so, the authors should incorporate a detailed explanation about this in the corresponding section.\n- The authors should provide a detailed description of the parameter c. It is not clear why c is necessary, and please make sure the overall derivation does not need to be modified due to the emergence of c.\n- It seems that the authors could compact the paper by highlighting key ideas. \n- Typo: Annex A (on p.5).\n\nThe paper is written well and provides a sound theoretical analysis to show the main idea, but unfortunately, the experimental results do not seem to support the effectiveness of the proposed method."", 'Summary:\nThis paper introduces equi-normalization (ENorm): a normalization technique that relies on the scaling invariance properties of the ReLU, similarly to Path-SGD. Their method explicitly use this property to balance the weights of the network, without changing the function computed by the network. The main difference with Path-SGD is that the network is explicitly balanced, while Path-SGD uses a regularizer to implicitly balance the network. Since it doesn’t rely on mini-batch to normalize the network, Equi-normalization could be a good alternative to BN in small mini-batch regime. The method is validated on 3 tasks (MLP on CIFAR10, CNN on CIFAR10, Reidual Network on ImageNet).\n\nClarity:\nThe paper is quite clear, although a bit long (10 pages). The related work section is particularly nice. I really appreciated the “positioning” paragraph, which really explains how the method differs from others.\n\nNovelty:\nThe paper is quite incremental, due to its similarities with Path-SGD. It seems quite close to what Weight Normalization is doing as well (see detailed comments).\n\nPros and Cons:\n+ Clearly written\n+ Clearly motivated\n+ Nice review of literature\n- Quite incremental (close to Path-SGD / Weight Normalization), and missing actual comparison with Weight Normalization, which seems to be the direct competitor of ENorm (see detailed comments)\n- Some flaws in the experimental setup (see detailed comments), particularly in the fully-connected experiment.\n- Doesn’t scale (yet) to deeper architectures, which is precisely where small batch sizes become a problem for BN and thus where ENorm would be needed.\n\nDetailed Comments:\n1. Differences with Weight Normalization:\nI have trouble seeing the difference between the proposed method and Weight Normalization (WN), or the more advanced Normalization Propagation (NP). It seems that both methods are performing quite similar normalization: WN reparameterize the network such that ||W[:,j]||_2 = 1, so it seems that you wouldn’t need to re-balance the network when using WN. Could the authors elaborate on this? Moreover WN is simple to implement, fast, and also works in the small batches settings as well. Finally, since those methods are quite similar, the authors should compare their method against WN in their experimental setup.\n2. Initialization of the Weights:\nThe Xavier initialization you are using in the CIFAR10 experiments is designed to work with Tanh activations functions. For ReLUs, one should use the Kaiming initialization, which has been proven to work way better for ReLUs (He et al., 2015a).  This certainly explains the poor performances of your baseline when you increase the number of layers in Figure 4, and probably explains why you need to add a BN layer at the end of your network to help with the training of the baselines. I suggest the authors to re-run the baselines using proper initialization for ReLUs.\n3. Fully-Connected Layers Benchmark:\nI think the fully-connected benchmark you used is quite poor. A baseline with 1 layer only reaches ~54 % test accuracy and your method needs a 11 layer model to increase this baseline performance of about ~0.5 % only. The deep autoencoder on MNIST (see e.g. Desjardins et al., Natural neural networks, NIPS 2015), would probably be a better benchmark for fully-connected layers (of course using ReLUs in place of Sigmoids).  It would also reinforce your empirical results by adding a 3rd dataset.\n4. ImageNet Experiment:\nDo you use Ghost Batch Normalization in this experiments (i.e. calculating the BN statistics on each GPU separately)? It would certainly explain the poor performances of BN with tiny batch size (32 examples on 8 GPUs means only 8 examples per GPU).\n5. Computation Time performances:\nIt is stated in the conclusion that “using ENorm during training adds a much smaller computational overhead than BN or GN …”. I can see that Table 1 gives an overview of the number of elements accessed during normalization, but I do think that a proper plot showing the accuracy versus the wall-clock time would be a better way of showing how your method compares in practice with BN or GN. Moreover, as stated previously, comparison with WN (and / or NP) need to be performed as well, especially because WN and NP are also way faster to compute than BN and GN.\n6. Shortening the paper:\nThe recommended paper size for ICLR is 8 pages. Here would be a few pointers that could help you reduce a bit the length of the paper: Introduction and Related Work takes up 3 pages already and I think there is quite some overlap between the 2 (about BN in particular), so there is probably quite a lot of space to gain here if the authors were to reduce a bit the introduction or make the related work a sub-section of the introduction. The ENorm presentation is 4 pages long (which is quite a lot). Section 3.6 might be totally discarded since it is vanilla application of the chain rule. The extension to convolution layers and max pooling could be transferred to the appendix.\n\nMinor Comments:\nYou should add “Optimizing neural networks with kronecker-factored approximate curvature” in the literature review about optimization landscape, as it is an important research direction on natural gradient.\n\nConclusion:\nAll in all, I find that this work is a bit too incremental, missing some important comparisons with other techniques and its experimental setup could definitely be improved. Also, the speedup claims should also be supported with empirical experimentation.\n\nRevision:\nI thank the authors for the all the extra experiments they performed. The paper looks good to me, and increased my evaluation accordingly.', ""The authors propose a new regularization method for neural networks. The main idea is to reparametrize the neural network after each update by rescaling the weights, without changing the encoded function. The proposed algorithm is proved to converge to a unique canonical representation of the weights. \n\nThe paper is clear and well written. The proof structure in the appendix seems coherent even though I haven't checked all the details.  Moreover, the authors detail the application of the method to all the different building blocks of modern architectures. \n\nUp to my knowledge, the idea is novel. Moreover, it can have a high impact on the robustness of training. However, the results are somewhat disappointing.  While the authors present the method as an alternative to batch normalization, most of the reported results show a better performance for BN. \n\nOne of the drawbacks of batch normalization is it's incompatibility with other regularizers such as Dropout. Did the authors try to combine ENorm with Dropout? \nAnother direction that can be worth to investigate, in the same space of improving the robustness of training, is to try to combine this reparametrization with natural gradient updates. \nAnother question that remains open is the following: Even though the algorithm converges to a unique minimizer, it is not guaranteed that the obtained minimizer is good. Indeed, the authors note in their discussion that the criterion they optimize might be not optimal.   \n\nTo summarize, the idea and theoretical contribution is significant, but the work can be improved.\n\n==================\nAfter rebuttal\n==================\nThe authors provided new experiments supporting the proposed method. I am happy to increase my rating. ""]","[-20, 20, 50]","[60, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros') of the paper, there are more substantial criticisms ('cons') that outweigh the positives. The reviewer concludes that the experimental results do not support the effectiveness of the proposed method, which is a significant drawback. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, balancing positive and negative feedback, and offering constructive suggestions for improvement. The reviewer acknowledges the paper's strengths before detailing its weaknesses, and uses phrases like 'It is better for the authors to...' which maintain a polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer points out several pros of the paper (e.g., 'Clearly written', 'Clearly motivated', 'Nice review of literature'), they also highlight significant cons and areas for improvement. The overall tone suggests the paper has merit but needs substantial revisions. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' efforts in the revision. Phrases like 'I really appreciated', 'Could the authors elaborate on this?', and 'I thank the authors' contribute to the polite tone. The reviewer balances critique with positive feedback and provides detailed, helpful suggestions for improvement, which is characteristic of a polite and professional review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity, novelty, and potential impact, but also expresses disappointment with some results and suggests areas for improvement. The initial paragraphs are mostly positive, but the critique becomes more apparent in the middle. The final 'After rebuttal' note indicates an increase in rating, which further supports a positive sentiment.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before presenting criticisms, and phrase suggestions as questions or potential directions for investigation rather than demands. The reviewer also shows willingness to adjust their opinion based on new information, which is a polite and professional approach.""]"
"['This is an interesting paper that studies the latent variable modeling from an information theoretic perspective. Specifically, the authors argue that the rate-distortion theory for lossy compression provides a natural toolkit for studying latent variable models, and they propose a lower bound (also a gap function) that could be used to assess the goodness of data fitting given a pair of prior distribution over latent factor and a likelihood function. Overall the paper is very well-written, clear to follow, and the authors did a great job in not overclaiming their results. \n\nSeveral questions follow: \n1.  In Eq. (3), why the R.H.S. is an upper bound of the L.H.S.? Under the assumption of (1) should this be equal? \n2.  In section 2, ""must use at use"" -> ""must use at least"". \n3.  Since the mutual information is convex in the conditional distribution Q(Z|X), when considering the Lagrangian, since \\alpha is constrained to be positive, should the sign before \\alpha be positive instead of negative? \n4.  In section 3.3, ""An very common"" -> ""A very common"". \n\nTo me the most interesting result in this paper is in Thm. 1, Eq. (9), where the authors show that the optimization over the prior in latent variable modeling is exactly equivalent to the optimization of the channel in rate-distortion theory. Following this line the authors propose a gap function that could be used to assess the goodness of a model. One drawback of the current framework is that it only links the optimization of the prior, rather than the likelihood function, to rate-distortion theory, while in practice it is usually the other way around. Although the authors argue in section 3.3 that similar conclusion could be achieved for a family of likelihood functions, the analysis is only possible under the very restrictive (in my personal view) assumption that relies on the existence of a smooth and invertible mapping. This assumption usually does not hold in practice, e.g., the ReLU network, and as a result the analysis here is only of theoretical interest. \n\nThe experimental validation basically shows the usefulness of the proposed gap function in assessing the goodness of model fitting in latent variable models. It would be great if there are more direct use of the proposed lower bound, but I appreciate the novelty in this paper on bridging the two subfields. \n', '(Please find my response to the rebuttal and updated version in a comment below)\nThe paper analyses latent-variable modeling from a rate-distortion point-of-view in a novel and interesting fashion, highlighting important fundamental connections. In particular, the paper presents a novel theorem (inspired by how the rate-distortion function is computed) that gives a lower bound on the negative log likelihood. This lower bound allows to quantify by how much a latent-variable model could be improved by either modifying the prior or the likelihood function. The latter is important, since the paper shows a duality between improving one while keeping the other fixed and vice versa. Finally, the paper derives a practical implementation/approximation (founded on solid theoretical analysis) of quantifying the improvement potential of a latent-variable model. These, so called “glossy statistics” are quantitatively analyzed in a set of experiments with different variational autoencoder architectures (various likelihood models and priors) on a number of datasets.\n\nThe main contribution of this paper is to provide novel proofs and theoretical analysis that connect latent-variable modeling with rate-distortion on a very fundamental level. While similar attempts have been reported in the recent literature (perhaps a bit more focused on the empirical aspects), the analysis and results in the paper follow a very fundamental treatment of rate-distortion theory and in particular of computation of the rate-distortion function. The central idea underlying rate-distortion, i.e. lossy compression by discarding irrelevant information, seems very suitable as a guiding principle for representation learning. In particular, learning representations that generalize well is essentially another instance of a lossy compression problem. The paper thus addresses an important and timely topic which should be of broad interest to the representation learning community. The paper is well written and mathematically rigorous. I have checked most parts of the proofs, though there still is a chance that I missed something. I am not entirely convinced by the practical impact of the experimental section of the paper (though the experiments are beyond toy-level and I do not doubt the results), but I also believe that this is not the main contribution of the paper, which is rather laying the mathematical groundwork for future work. I vote and argue for accepting the paper for presentation at the conference. My criticism below is aimed at giving some pointers for potentially improving the paper.\n\n1) As the paper acknowledges, there is a risk of overfitting when improving likelihood functions under fixed priors (and vice versa). While the glossy statistics certainly allow making approximate statements of whether the model can be improved further or not, there is no “threshold value” or other guideline that would indicate a modeling expert that they are entering an over-fitting regime if the model-class is further enriched. Therefore, I am not sure about the practical impact of the experiments: the glossy statistics seem to be indicative of the margin for improvements in the negative log-likelihood - but whether all of these improvements are really desirable is unclear. To test this, one might resort to tasks other than generative modeling, such that models that overfit can easily be “spotted” (by degrading test-set performance).\n\n2) Rate-Distortion can be “made more robust” against overfitting by different choices of \\alpha (essentially limiting channel capacity). Maybe I am missing something, but shouldn’t the \\alpha carry over into the computation of the ratios for c(z)? Was it just assumed to be 1? The same question for Theorem 2 and the equation just above Theorem 2 - does the alpha drop (is it absorbed into the likelihood) or was it set to one? It might be interesting to see how the glossy statistics behave if \\alpha is considered a hyper-parameter of the model, e.g. under “low capacity” do the glossy statistics “flatten out” very early?\n\n3) I would have been excited to see how the glossy statistics evolve during training of a model - it would be interesting to show that the statistics initially predict a large margin of improvement that reduces and slowly flattens out as training converges.\n\n4) In the paragraph after Eq. 14: the argument hinges on the possibility of having an invertible (and continuously differentiable) g(z). To me it is not straightforward that a neural network would necessarily implement such a function (particularly the invertibility might be problematic). Is this just a technical condition required for the formal statement, or do you think that this issue could become problematic in practice as well such that the duality between improving prior and likelihood does not hold any longer?\n\nMinor:\n5) I think the Alemi et al. reference (first reference) has been published under a different name (Fixing a Broken ELBO) at this years’ ICML.\n\n6) Consider calling the quantity l(x|z) below Eq. 1 “the likelihood of the latent variable given the data” (since the data is given, even though the data is not in the conditional, which is why it is a likelihood function).\n\n7) Rather than using “the KL divergence between”, use “the KL divergence from … to” which nicely reflects its asymmetry. \n\n8) Page 4, last Equation: square brackets for E_X missing\n', ""This paper considers the optimization of the prior in the latent variable model and the selection of the likelihood function. The authors propose criteria for these problems based on a lower-bound on the negative log-likelihood, which is derived from rate-distortion theory.\n\nThere are some interesting points in the derivation of the proposed quantities and how to compute them while the main criterion c(z) has already been examined in some prior works. Although the results of experiments are promising, they are somewhat weak enough to demonstrate the usefulness of the proposed quantities.\n\n- The note right after Eq.(7) is unclear. It would be nicer to discuss more clearly the property of c(z) about overfitting.\n\n- The derived quantity c(z) in Eq.(6), appearing in the optimality condition (the equation following Eq.(13)), has been pointed out since early times, e.g. in\nLindsay, B. G. (1983). The geometry of mixture likelihoods: A general theory. The Annals of Statistics, 11(1), 86–94.\nIt was used in the machine learning community too:\nNowozin, S., Bakir, G. (2008). A decoupled approach to exemplar-based unsupervised learning. In Proc. ICML.\n, and its connection to rate-distortion theory was pointed out:\nWatanabe, K., Ikeda, S. (2014). Entropic risk minimization for nonparametric estimation of mixing distributions. Machine Learning, 99(1), 19–136.\nHowever, little is discussed on these related works.  \n\n- Section 2: Shannon's rate-distortion theory is formulated by a general source distribution of X. It would be better to mention that the authors consider the empirical distribution of the data sample as the source distribution.\n\n- The results of experiments only show the potential of glossy statistics in some variational auto-encoder models. Isn't it possible or better to demonstrate its practicality more concretely using small toy models? \n\nPros:\n- nice connection between the optimization of the prior (or likelihood function) and rate-distortion theory\n\nCons: \n- lack of discussion on important related works\n- weakness of the experiments\n\n""]","[80, 80, -20]","[90, 70, 50]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and 'very well-written', and praises the authors for 'not overclaiming their results'. They also mention that the most interesting result is in Theorem 1 and appreciate the novelty of bridging two subfields. The slight reduction from 100 is due to some criticisms, such as the drawback mentioned in the analysis. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms diplomatically. They use phrases like 'it would be great if' and 'I appreciate' when suggesting improvements. The reviewer also provides specific, helpful feedback for minor corrections. The high scores in both categories reflect a generally positive and courteous review."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'novel and interesting' and recommending acceptance. They highlight the paper's contributions and theoretical foundations positively. The few criticisms are presented constructively as suggestions for improvement. The politeness score is 70 (polite) due to the reviewer's respectful tone throughout. They use phrases like 'I am not entirely convinced' rather than harsh criticism, and offer suggestions politely. The reviewer also acknowledges the possibility of their own oversight ('though there still is a chance that I missed something'). The language is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'interesting points' and 'promising' results, they also point out significant weaknesses such as 'lack of discussion on important related works' and 'weakness of the experiments'. The overall tone suggests that the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'It would be nicer to discuss' and 'It would be better to mention' which are polite ways of pointing out areas for improvement.""]"
"[""The paper presents a novel model for neural speed reading. In this new model, the authors combined several existing ideas in a nice way, namely, the new reader has the ability to skip a word or to jump a sequence of words at once. The reward of the reader is mixed of the final prediction correctness and the amount of text been skipped. The problem is formulated as a reinforcement learning problem. The results compared with the existing techniques on several benchmark datasets show consistently good improvements.\n\nIn my view, one important (also a little surprising) finding of the paper is that the reader can make jump choices successfully with the help of punctuations. And, blindly jumping a sequence of words without even lightly read them can still make very good predictions.\n\nThe basic idea of the paper, the concepts of skip and jump, and the reinforcement learning formulation are not completely new, but the paper combined them in an effective way. The results show good improvements majorly in FLOPS.\n\nThe way of defining state, rewards and value function are not very clear to me. Two value estimates are defined separately for the skip agent and the jump agent. Why not define a common value function for a shared state? Two values will double count the rewards from reading. Also, the state of the jump agent may not capture all available information. For example, how many words until the end of the sentence if you make a jump. Will this make the problem not a MDP? \n\nOverall, this is a good paper.\n\nI read the authors' response. The paper should in its final version add the precise explanation of how the two states interact and how a joint state definition differs from the current one."", 'The paper proposes a fast-reading method using skip and jump actions. The paper shows that the proposed method is as accurate as LSTM but uses much less computation.\n\n* pros: \n- very fast reading model (?). \n\n* cons: \n- although the paper is well written, the jump is not described in details. \n- using \'structural-jump\' is a little misleading. The model will jump to "".,!"" or end of sentence. What is called ""structural""? Note that those punctuation marks are not 100% correlated to sentence structure. For example, ""He hate fruits such as apples, pears, and oranges."" The mode should jump to the end of sentence rather than the first "","" when reading ""such"". \n- maybe the authors should say a little bit about the used computation-cost-reduction method. (I.e. in an appendix). ', 'The paper proposes a Structural-Jump-LSTM model to speed up machine reading, which is an extension of the previous speed reading models, such as LSTM-Jump, Skim-LSTM and LSTM-Shuffle. The major difference, as claimed by the authors, is that the proposed model has two agents instead of one. One agent decides whether the next input should be fed into the LSTM (skip) and the other determines whether the model should jump to the next punctuation (jump). The sentence-wise jumping makes the jumping more structural than models like LSTM-Jump, while the word-wise skipping operation has a finer skimming decision. The reinforcement learning algorithm in this paper is also different from LSTM-Jump, where LSTM-Jump uses REINFORCE, while this paper applies actor-critic approach. \n\nEmpirical studies show that Structural-Jump-LSTM is (slightly) better than state-of-the-art methods in terms of both accuracy and speed over most but few datasets. My feeling is that the proposed model should work much better than the previous models in very long texts, which I suggest the author should try on. Otherwise, the performance gain looks marginal and it is thus questionable whether the complicated modeling is necessary. \n\nI am confused by Figure 1: why are the “yes/no” placed in front of the “skipped”? “Previous LSTM” is confusing as well, which should be “Previous Output/hidden state”.\n\nMinor comment: The LSTM-Jump takes word2vec as the initialization in CBT, while this paper uses GLOVE. I wonder if this results in the performance difference in accuracy. From my experience, GLOVE is usually better than word2vec in most of the tasks. If this effect also applies to CBT, the experiment is not fair.\n']","[70, -20, 20]","[80, 50, 60]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'good' and praising its 'consistently good improvements' and 'effective' combination of ideas. They also mention 'important' findings. However, it's not 100 as there are some critiques and requests for clarification. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'in my view' and 'overall, this is a good paper,' which are polite ways to express opinions. The reviewer also acknowledges the authors' response and provides suggestions for improvement without harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very fast reading model'), they list more cons than pros and point out several areas for improvement. The overall tone suggests the paper needs significant revisions. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers constructive criticism without harsh or rude phrasing. They use phrases like 'maybe the authors should' and 'the paper is well written', which maintain a respectful tone while providing feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and improvements over previous models, but also expresses some concerns and suggestions for improvement. The reviewer notes that the proposed model performs slightly better than state-of-the-art methods in most cases, which is positive. However, they also question whether the complicated modeling is necessary given the marginal performance gain, which tempers the overall positive sentiment.\n\nThe politeness score is moderately high (60) because the reviewer uses respectful and constructive language throughout. They offer suggestions and express confusion without being harsh or dismissive. The use of phrases like 'I suggest' and 'I am confused by' indicate a polite approach to giving feedback. The reviewer also acknowledges the potential strengths of the model, such as its possible better performance on very long texts, which shows a fair and considerate evaluation. The minor comment at the end is presented as a question rather than a criticism, further demonstrating politeness.""]"
"['Summary\nThe paper focuses on pruning neural networks. They propose to identify the nodes to be pruned even before training the whole network (conventionally, it is done as a separate step after the nn was trained and involves a number of iterations of retraining pruned nn). This initial step that identifies the connections to be pruned works off a mini-batch of data.\n\nAuthors introduce  a criterion to be used for identifying important parts of the network (connection sensitivity), that does not depend on the magnitude of the weights for neurons: they start by introducing a set of binary weights (one per a weight from a neuron) that indicate whether the connection is on or off and can be removed. Reformulating the optimization problem and relaxing the constraints on the binary weights, they approximate the sensitivity of the loss with respect to these indicator variables via the gradient. Then the normalized magnitude of these gradients is used to chose the connections to keep (keeping top k connections)\n\nClarity:\nWell written, easy to follow\n\nDetailed comments\nOverall, very interesting. Seemingly very simple idea that seem to work well. \nTable 2 does look impressive and it seems that it also reduces the overfiting, and the experiment with random labels on mnist seem to demonstrate that the method indeed preserves only connections relevant to the real labels, simplifying the architecture to a point when it cant just memorize the data\n\nSeveral questions/critiques:\n- When you relax the binary constraints, it becomes an approximation to an optimization problem, any indication of how far you are off solving it this way? \n- For the initialization method of the weights, you seem to state that VS-H is the one to use. I wonder if it actually task dependent and architecture dependent. If yes, then the propose method still has a hyperparameter - how to initialize the weights initially\n- How does it compare with just randomly dropping the connections or dropping them based on the magnitude of the initial weights.  It seems that the meat comes from the fact that you are able to use the label and good initial values, i wonder if just doing a couple of iterations of forward-backprop and then dropping the weights based on their magnitude can give you comparable results \n- How does it compare to a distillation - it does not involve many cycles of retraining and can speed up inference time too\n-Can it replace the architecture search - initialize a large architecture, use the method to prune the connections and here you go. Did you try that instead of using already pre-tuned architectures like AlexNet.\n\n', 'This work introduces SNIP, a simple way to prune neural network weights before training according to a specific criterion. SNIP identifies prunable weights by the normalised gradient of the loss w.r.t. an implicit multiplicative factor “c” on the weights, denoted as the “sensitivity”. Essentially, this criterion takes two factors into account when determining the relevance of each weight; the scale of the gradient and the scale of the actual weight. The authors then rank the weights according to their sensitivity and remove the ones that are not in the top-k. They then proceed to train the surviving weights as normal on the task at hand. In experiments they show that this method can offer competitive results while being much simpler to implement than other methods in the literature.\n\nThis paper is well written and explains the main idea in a clear and effective manner. The method seems to offer a viable tradeoff between simplicity of implementation and effective sparse models. The experiments done are also extensive, as they cover a broad range of tasks: MNIST / CIFAR 10 classification with various architectures, ablation studies on the effects of different initialisations, visualisations of the pruning patterns and exploration of regularisation effects on a task involving fitting random labels.\n\nHowever, this work has also an, I believe important, omission w.r.t. prior work. The idea of using that particular gradient as a guide to selecting which parameters to prune is actually not new and has been previously proposed at [1]. The authors of [1] considered unit pruning but the modification for weight pruning is trivial. It is worth pointing out that [1] is also discussed in one of the other citations of this work, namely [2]. For this reason, I believe that the main contribution of this paper is more on the thorough experimental evaluation of an existing idea rather than the proposed sensitivity metric.\n\n\nAs for other general comments:\n\n- The authors argue that SNIP can offer training time speedups by only optimising the remaining parameters. In this spirit, the authors might also want to discuss about other works that seem relevant to this task, e.g.  [3, 4]. They also allow for pruned and sparse networks during training (thus speeding it up), without needing to conform to a specific sparsity pattern. \n\n- SNIP seems to be a good candidate for applying it to randomly initialised networks; nevertheless, a lot of times we are also interested in pruning pre-trained networks. Given that SNIP is relying on the magnitude of the gradient to determine relevance, how good does it handle this particular case (given that the magnitude of the gradients is close to zero at convergence)?\n\n- Why is the normalisation of the magnitude of the gradients necessary? The normalisation doesn’t change the relative ordering so we could simply just rank according to |g_j(w; D)|.\n\n- While the experiment at section 5.6 is interesting, the result is still dependent on the a-priori chosen cut-off point “k”. For this reason it might be worthwhile to plot the behaviour of the network as a function of “k”. Furthermore, the authors should also refer to [5] as they originally did the same experiment and showed that they can obtain the same behaviour without any hyper parameters.\n\n[1] Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment.\n[2] A Simple Procedure for Pruning Back-Propagation Trained Neural Networks.\n[3] Learning Sparse Neural Networks through L_0 Regularization.\n[4] Generalized Dropout.\n[5] Variational Dropout Sparsifies Deep Neural Networks.', 'Post rebuttal update/comment:\n\nI thank the authors for the revision and have updated the score (twice!)\n\nOne genuinely perplexing result to me is that the method behaves better than random pruning, yet after selecting the salient neurons the weights can be reinitialized, as per the rebuttal:\n\n> # Initialization procedure\n- It is correct that the weights used to train the pruned model are possibly different from the ones used to compute the connection sensitivity. Given (variance scaled) initial weights, SNIP finds the architecturally important parameters in the network, then the pruned network is established and trained in the standard way.\n\nFirst, there is work which states quite the opposite (e.g. https://arxiv.org/abs/1803.03635). Please relate to it.\n\nFundamentally, if you decouple weight pruning from initialization it also means that:\n- the first layer will be pruned out of connections to constant pixels (which is seen in the visualizations), this remains meaningful even after a reinitialization\n- the second and higher layers will be pruned somewhat randomly - even if the connections pruned were meaningful with the original weights, after the reinitialization the functions computed by the neurons in lower layers will be different, and have no relation to pruned weights. Thus the pruning will be essentially random (though possibly from a very specific random distribution). In other words - then neurons in a fully connected layer can be freely swapped, each neuron in the next layer behaves on al of them anyway we are thinking here about the uninitialized neurons, with each of them having a distribution over weights and not a particular set of sampled weights, this is valid because we will reinitialize the neurons). Because of that, I wouldn\'t call any particular weight/connection architecturally important and find it strange that such weights are found.\n\nI find this behavior really perplexing, but I trust that your experiments are correct. however, please, if you have the time, verify it.\n\nOriginal review:\n\nThe paper presents an intriguing result in which a salient, small subset of weights can be selected even in untrained networks given sensible initialization defaults are used. This result is surprising - the usual network pruning procedure assumed that a network is pretrained, and only then important connections are removed.\n\nThe contributions of the paper are two-fold:\n1) it reintroduces a multiplicative sensitivity measure similar to the Breiman garotte\n2) and shows which other design choices are needed to make it work on untrained networks, which is surprising.\n\nWhile the main idea of the paper is clear and easy to intuitively understand, the details are not. My main concern is that paper differentiates between weights and connections (both terms are introduced on page iv to differentiate from earlier work). However, it is not clear what are the authors referring to:\n- a conv layer has many repeated applications of the same weight. Am I correct to assume that a conv layer has many more connections, than weights? Furthermore, are the dramatic sparsities demonstrated over connections counted in this manner? This is important - on MNIST each digit has a constant zero border, all connections to the border are not needed and can be trivially removed (one can crop the images to remove them for similar results). Thus we can trivially remove connections, without removing weights.\n- in paragraph 5.5 different weight initialization schemes are used for the purpose of saliency estimation, but the paragraph then says ""Note that for training VS-X initialization is used in all the cases."" Does it mean that first a set of random weights is sampled, then the sensitivities are computed, then a salient set of connections is established and the weights are REINITIALIZED from a distribution possibly different than the one used to compute the sensitivity? The fact that it works is very surprising and again suggests that the method identifies constant background pixels rather than important weights.\n- on the other hand, if there is a one-to-one correspondence between connections and weights, then the differentiation from Karnin (1990) at the bottom of p. iv is misleading.\n\nI would also be cautious about extrapolating results from MNIST to other vision datasets. MNIST has dark backgrounds. Let f(w,c) = 0*w*c. Trivially, df/dw = df/dc = 0. Thus the proposed sensitivity measure picks non-background pixels, which is also demonstrated in figure 2. However, this is a property of the dataset (which encodes background with 0) and not of the method! This should be further investigated - a quick check is to invert MNIST (make the images black-on-white, not white-on-black) and see if the method still works. Fashion MNIST behaves in a similar way. Thus the only non-trvial experiments are the ones on CIFAR10 (Table 2), but the majority of the analysis is conducted on white-on-black MNIST and Fashion-MNIST.\n\nFinally, no experiment shows the benefit of introducing the variables ""c"", rather than using the gradient with respect to the weights. let f be the function computed by the network. Then:\n- df/d(cw) is the gradient passed to the weights if the ""c"" variables were not introduced\n- df/dw = df/d(cw) d(cw)/dw = df/d(cw) * c = df/d(cw)\n- df/dc = df/d(cw) d(cw)/dc = df/d(cw) * w\n\nThus the proposed change seems to favor a combination of weight magnitude and the regular df/dw magnitude. I\'d like to see how using the regular df/dw criterion would fare in single-shot pruning. In particular, I expect using the plain gradient to lead to similar selections to those in Figure 2, because for constant  pixels 0 = df/d(cw) = df/dc = df/dw.\n\nSuggested corrections:\nIn related work (sec. 2) it is pointed that Hessian-based methods are unpractical due to the size od the Hessian. In fact OBD uses a diagonal approximation to the hessian, which is computed with complexity similar to the gradient, although it is typically not supported by deep learning toolkits. Please correct.\n\nThe description of weight initialization schemes should also be corrected (sec. 4.2). The sentence ""Note that initializing neural networks is a random process, typically done using normal distribution with zero mean and a fixed variance."" is wrong and artificially inflates the paper\'s contribution.  Variance normalizing schemes had been known since the nineties (see efficient backprop) and are the default in many toolkits, e.g. Pytorch uses the Kaiming rule which sets the standard deviation according to the fan-in: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L56.\n\nPlease enumerate the datasets (MNIST, Fashion-MNIST, CIFAR10) in the abstract, rather than saying ""vision datasets"", because MNIST in particular is not representative of vision datasets due to the constant zero padding, as explained before.\n\nMissing references:\n- Efficient Backprop http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf discusses variance scaling initialization, and approximations to the hessian. Since both are mentioned in the text this should be cited as well.\n- the Breiman non-negative garotte (https://www.jstor.org/stable/1269730) is a similar well-known technique in statistics\n\n\nFinally, I liked the paper and wanted to give it a higher score, but reduced it because of the occurrence of many broad claims made in the paper, such as: 1) method works on MNIST => abstract claims it generally works on vision datasets 2) paper states ""typically used is fixed variance init"", but the popular toolkits (pytorch, keras) actually use the variance scaling one by default 3) the badly explained distinction between connection and weight and the relation that it implies to prior work. I will revise the score if these claims are corrected.']","[70, 50, -20]","[80, 80, 60]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'very interesting' and noting that the results 'look impressive'. They also mention that the paper is well-written and easy to follow. However, it's not a perfect score as the reviewer does raise several questions and critiques. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their critiques as questions or suggestions rather than direct criticisms. They also begin with positive comments before moving to their questions. The use of phrases like 'I wonder if' and 'Did you try' further contribute to the polite tone. The reviewer maintains a professional and constructive approach throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being well-written, clear, and offering extensive experiments. However, they also point out an important omission regarding prior work, which tempers the overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively. They use phrases like 'I believe' to soften critiques and offer suggestions for improvement rather than harsh criticism. The review maintains a professional and courteous tone while providing both positive feedback and areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('intriguing result', 'surprising'), they express several concerns and criticisms. The reviewer points out issues with clarity, methodology, and overgeneralization of results. They also request significant revisions and additional experiments. However, the tone is not entirely negative, as the reviewer expresses interest in the work and offers constructive feedback. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as suggestions or questions rather than harsh judgments. Phrases like 'I thank the authors', 'I trust that your experiments are correct', and 'I liked the paper' contribute to the polite tone. The reviewer also provides detailed explanations for their concerns, which is a courteous approach to academic critique.""]"
"['In this papers, the authors introduce a new technique to output uncertainty estimates from any family of neural nets. The key insight in this paper is that when considering existing SGD methods the following behavior occurs: if we think of ""easy"" and ""hard"" to classify datapoints, a NN trained with SGD will output good uncertainty estimates early on in training, but once the network focusses on tuning the parameters for the hard cases, the uncertainty estimates for the easy datapoints deteriorates. The algorithms proposed by the authors takes an existing uncertainty method (or confidence score function) and uses intermediate snapshots of SGD training to improve the final uncertainty estimates. Note that the focus in this work is on ranking uncertainties (and the authors suggest to leave calibrating uncertainties to existing methods).\n\nThe paper generally is well written (e.g. section 5) although I found section 3 to be a bit hard to follow. I\'m not very familiar with the area itself but I was surprised to see in Section 7 that the results are not compared to full Bayesian methods (possibly on a dataset that lends itself well to that).\n\nNotes:\n- Section 3, ""A selective classifier ..."" -> I think this section could use some additional untuition to make the explanation more understandable.\n- Section 3, ""defined to be the selective risk as a function of coverage."" -> do you mean as a sequence of functions g?\n- ', '-- Paper Summary --\n\nThe proposed methodology draws on the connection between boosting in ensemble learning and SGD for training DNNs, whereby misclassified instances are implicitly targeted in later training iterations once easier examples have been classified correctly. The authors observe that this incurs a trade-off in which easily-classified examples become susceptible to overfitting at later stages in the training procedure when the network parameters adapt to fit more complex examples. Two early stopping algorithms are proposed in order to mitigate this issue. The first approach, PES, is more robust, but too computationally expensive to be applied in practice; on the other hand, AES approximates the former procedure by directly assuming that easier training examples will be learnt earlier on in the training procedure. The proposed technique is shown to calibrate the confidence scores obtained from state-of-the-art approaches for training deep nets, resulting in substantial performance improvements with respect to the proposed E-AURC metric. \n\n-- General Commentary --\n\n- The paper isolates itself from other post-calibration methods by stating that ‘our focus here is only on the core task of ranking uncertainties’. In doing so, there is no comparison to other calibration methods, which makes it difficult to properly assess the impact of this work in comparison to other papers addressing the poor calibration of uncertainty typically associated with deep nets. The authors immediately dismiss PES as being too computationally expensive, so I’d be interested in at least seeing AES be compared to more lightweight calibration methods.\n\n - This paper champions the use of an alternative metric (E-AURC) for assessing model quality, which is the sole quantity of interest in the experimental evaluation. While the E-AURC metric is indeed well-motivated in Section 3, I could see there being some scepticism as to why more traditional metrics such as log likelihood aren’t used here. This would also facilitate comparison to other post-calibration methods. In this regard, the authors should consider supplementing their experiments with more widely-used metrics not limited to uncertainty ranking.\n\n- I would be interested in seeing the analysis shown in Figure 2 extended to each of the baseline models discussed in the paper. Such examples would give a clearer perspective of which methods are particularly susceptible to the overfitting problem targeted by the methodology proposed in this work.\n\n- Some of the notation in the problem statement is a bit confusing, with i being simultaneously  used as the training iteration number as well as an index for Y. This needs to be updated.\u2028\n\n- There’s a lot of whitespace in Figure 1 which could be avoided by giving additional examples of how the metric works.\n\n- ‘Early Stopping without a Validation Set (Mahsereci et al, 2017)’ warrants a citation here.\n\n- The paper is otherwise generally well-written and a pleasure to read. Some spotted typos:\n\nP1: for highly confident instance(s)\nP3: which borrows element(s)\nP3: ‘unit-less’ : this is unhyphenated in another part of the text\nP5: Final reference to Figure 2(b) should refer to Figure 2(c) instead   \nP7: which (is) initialized\n\n-- Recommendation --\n\nI admit to feeling fairly ambivalent about this paper - on one hand, the paper is well-written and its contributions are effectively communicated. While myopic, the experiments also convincingly showcase the performance improvements obtained by applying AES over the baseline methods. On the downside, this paper limits itself to comparing the proposed approaches to baseline methods where no other calibration is carried out. Lack of direct comparison against other post-calibration methods results in the paper adding little to the overall literature on DNNs other than asserting that calibration through early stopping is better than not doing anything else.\n\nPros/Cons: \n\n+ Properly-motivated contributions and well-written paper.\n+ The two early stopping algorithms are explained well, even if the appealing connection to boosting gets lost somewhere along the way.\n+ Results show that AES improves the results of several DNN training approaches.\n\n- Use of E-AURC as the sole metric for assessing quality in the Experiments section exposes this paper to instant criticism.\n- The notion of preserving model snapshots can be problematic when training requires thousands of epochs.\n- No comparison to other post-calibration techniques. \n\n\n** Post-rebuttal\n\nScore increased to a 7 following rebuttal and paper revision.', ""This paper presents an improved method for uncertainty estimation in deep neural networks, based on  their observations that the confidence scores based on highly confident points and low confidence points would be quite different. \n\nThe paper is in general well presented. The proposed method is well motivated (as in section 5). The results of the AES algorithm support well the proposed idea, which nevertheless looks simple. \n\nSection 3 needs further improvement in clarity. \n\nFigure 1 needs to be better presented. \n\nFigure 2(a) - please make the curves color-blind friendly. \n\nSGD (stochastic gradient descent?) needs to be defined, and you can't assume everybody knows what it is. ""]","[50, 20, 60]","[70, 70, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novel technique and its well-written sections, but also points out some areas for improvement, such as the difficulty in following Section 3 and the lack of comparison to full Bayesian methods. The overall tone is constructive and appreciative of the work, while offering suggestions for enhancement. The politeness score is 70 (quite polite) as the reviewer uses respectful language throughout, acknowledging their own potential lack of familiarity with the field, and framing criticisms as suggestions or observations rather than direct attacks. The use of phrases like 'I found' and 'I think' further softens the critique, maintaining a courteous tone."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some ambivalence and points out several limitations, they also note many positives like the paper being well-written, having properly-motivated contributions, and showing convincing performance improvements. The overall tone is constructive rather than dismissive. The politeness score is fairly high (70) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. They describe the paper as 'a pleasure to read' and use polite phrases like 'I'd be interested in seeing' when making recommendations. The reviewer also provides helpful specifics on typos and areas for improvement in a neutral, professional manner."", ""The sentiment score is 60 (positive) because the reviewer generally praises the paper, calling it 'well presented' and stating that the results 'support well the proposed idea'. However, it's not extremely positive as there are some suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'needs further improvement' and 'please make' which are polite ways of requesting changes. The reviewer also acknowledges the strengths of the paper before suggesting improvements, which is a polite approach to feedback.""]"
"['This paper analyzes that the Integral Probability Metric (IPM) can be a good approximation of Wasserstein distance under some mild assumptions. They first showed two theorems based on simple cases (Gaussian Distribution and Exponential Families). Then, they proved that, for an invertible generator, a special designed neural network can approximate Wasserstein distance with IPM. The main contribution is that, for a stable generator (i.e., invertible generator), a discriminator can reversely “re-visit” inner status of the generator, then use this information to make a decision. \n\nIn the appendix, several numerical examples are presented to support their theoretical bound. \n\nQ: Assumption 1, \\sigma(t) is twice differentiable. However, Leaky ReLU is not twice differentiable at t=0. Do I misunderstand some part?\n\nQ: The invertible generator assumption is not held in practice. Is that possible to extend the theorem to this case, even with a shallow network (e.g. 2 layers)?\n\nQ: The numerical examples are all based on synthetic data. Did you have any results based on the real dataset?\n', '\n[pros]\nThis paper proposes the notion of restricted approximability, and provides a sample complexity bound, polynomial in the dimension, for GANs.\nThe proposal is especially useful in investigating possible cause of the lack of diversity in GANs.\n\n[cons]\nWhether it proposes use of properly-designed discriminator architecture in GAN learning is not clear enough.\nThe claimed ability of the proposed method to avoid mode collapse is not directly addressed in the experiments presented in the appendices.\n\n[quality]\nThe contents of Section 3 may be useful as case studies but are not used in the following sections on neural network generators. It would thus be better to include experimental results into the main part of the paper rather than the current contents in Section 3.\n\n[clarity]\nIn most parts of this paper, the authors seem to propose designing a proper discriminator architecture according to the generator class, and the discriminator architecture is to be used in GAN learning. It seems, however, that a ""properly-designed discriminator architecture"" is not used at all in the experiments in Appendix F. A comparison between a ""properly-designed discriminator architecture"" and a ""vanilla fully-connected distriminator"" is found in Appendix G.4, where the advantage of the former seems marginal. The authors also seem to use the proposal not to improve GAN learning but rather as a tool for evaluation, in order to see whether the lack of diversity in GANs comes either from failure of properly evaluating the Wasserstein distance or from insufficient optimization in learning. These two distinct subjects are discussed in a mixed way, which reduces clarity of the presentation.\nIn the experiments in Appendix G, it is claimed that a discriminator with the architecture specified in Lemma 4.1 is used in GAN learning, but either weight clamping or gradient penalty is used as well. It is unclear how the specifications in Lemma 4.1 for the parameter $\\phi$ are combined with weight clamping or gradient penalty.\nSome statements include forward reference, which obscure readability. For example, in the last paragraph of Section 1.1 ""the statistical properties of GANs"" are mentioned without an explicit statement as to what they mean, which are given later in page 3, lines 6-12. As another example, in the third paragraph of Section 1.3 the authors start discussing the KL-divergence, but at this point it is not evident at all why they do it. It is not until Section 4.1 that the reader can understand the reason by observing that the main theorem (Theorem 4.2) is proved by making use of KL-divergence.\n\n[originality]\nThe idea of introducing the notion of restricted approximability and discussing a sample complexity bound, polynomial in the dimension, for GANs are considered original.\n\n[significance]\nThe whole arguments in this paper are based on the assumption that both $p$ and $q$ are in the class $\\mathcal{G}$. In the context of GAN learning, it poses no problem for the generator since we explicitly parameterize it, for example using a neural network, but in practice there is no guarantee that the target distribution also belongs to the same class, and this point would affect significance of the proposal. One may argue that when one employs a certain neural network architecture for the generator one expects that the target distribution is well expressed by a network with the prescribed architecture. But the question as to what will happen when the target distribution does not belong to the class $\\mathcal{G}$ remains. In any case, no discussion is presented in this paper as for this question.\n\n[minor points]\nPage 3, line 45: for low-dimensional (dimensions -> distributions)\n\nPage 4, line 8: Remove the parentheses enclosing Lopez-Paz & Oquab, 2016.\n\nPage 4, lines 20-21: Duplicate parentheses.\n\nPage 4, line 7: the true and estimated distribution(s) exist.\n\nPage 5, line 33: the lower and upper bound(s) differ\n\nPage 7, line 9: What do ""some assumptions"" refer to?\n\nPage 8, line 44: The(re) exists a discriminator class\n\nPage 19, line 1: there exi(s)ts a coupling', 'This paper explores how discriminators can be designed against certain generator classes to reduce mode collapse. The strength of the paper is on establishing the sample complexity bounds for learning such distributions to show why they can be effectively learned. The work is important in understanding the behaviour of GANs. The work is original and significant. A few comments that need to be addressed are listed as below:\n\n1. I found the paper is a bit hard to follow in the beginning, due to its structure. In Section 1, it first gives introduction and then talks about the novelty of the paper; it then shows more background work followed by more introduction of the proposed work; after that, Section 1.4 talks more related work. It makes reading confusing in the beginning.\n\n2. The authors wrote that ""In practice, parametric families of functions F such as multi-layer neural networks are used for approximating Lipschitz functions, so that we can empirically optimize this objective eq. (2) via gradient-based algorithms as long as distributions in the family G have parameterized samplers. (See Section 2 for more details.)"" I am not sure how Section 2 gives more details.\n\n3. There are some typos and the references are not very carefully edited. For example, in Theorem 4.5, ""the exists a ..."" -> ""there exists a ...""; in reference, gan -> GAN.']","[50, -20, 60]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and theoretical work, presenting a balanced view with both positive aspects and questions. They mention the main contribution and the supporting numerical examples, which indicates a generally favorable view. However, they also raise several questions, suggesting areas for improvement or clarification.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout. They present their questions in a non-confrontational manner, using phrases like 'Do I misunderstand some part?' and 'Is that possible to extend...?' which show consideration for the authors. The reviewer also doesn't use any harsh or critical language, maintaining a constructive tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros' section mentions usefulness of the proposal), there are more criticisms and concerns raised throughout the review. The 'cons' section points out unclear aspects and lack of direct addressing of claims. The 'quality' and 'clarity' sections highlight several issues with the paper's structure and presentation. The 'significance' section raises questions about the applicability of the paper's assumptions. These criticisms outweigh the positive elements, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms (e.g., 'it would be better to', 'it is unclear how'), avoid personal attacks, and provide constructive feedback. The reviewer also acknowledges positive aspects of the paper in the 'pros' and 'originality' sections, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer states that the work is 'important', 'original', and 'significant'. They also mention the 'strength of the paper'. However, it's not extremely positive as they do have some criticisms. The politeness score is 50 (somewhat polite) because the reviewer uses neutral language and frames their criticisms as 'comments that need to be addressed' rather than outright flaws. They also use phrases like 'I found' and 'I am not sure' which soften the critique. The review maintains a professional tone throughout, but doesn't go out of its way to be overly polite either.""]"
"['This paper studies the weak supervision setting of learning a general binary classifier from two unlabeled (U) datasets with known class balances. The authors establish that this is possible by constructing an unbiased estimator, analyze its convergence theoretically, and then run experiments using modern image classification models.\n\nPros:\n- This work demonstrates, theoretically and empirically, a simple way to train generic models using only the known class balances of several sets of unlabeled data (having the same conditional distributions p(x|y))---a very interesting configuration of weak supervision, an increasingly popular and important area\n\n- The treatment is thorough, proceeding from establishing the minimum number of U datasets, constructing the estimator, analyzing convergence, and implementing thorough experiments\n\nCons:\n- This is a crowded area (as covered in their related work section). As they cite, (Quadrianto et al., 2009) proposed this setting and considered linear models for k-wise classification.  Moreover, the two U datasets with known class balances can equivalently be viewed as two weak / noisy label sources with known accuracies.  Thus this work connects to many areas- both in noisy learning, as they cite heavily, but also in methods (in e.g. crowdsourcing and multi-source weak supervision) where several sources label unlabeled datasets with unknown accuracies (which are often estimated in an unsupervised fashion).\n\n- The overall clarity of the paper\'s writing could be improved. For example, the introduction and related work sections take up a large portion of the paper, but are very dense and heavy with jargon that is not internally defined upfront; for example ""risk rewrite"" is introduced in paragraph 2 with no internal definition and then used subsequently throughout the paper (this defn would be simple enough to give: in the context of this paper, ""risk rewrite"" means a linear combination of the class-conditional losses; or more generally, the expected loss w.r.t. distribution over classes...).  Also intuition could be briefly given about the theorem proof strategies.\n\n- The difference between the two class distributions over the U datasets seems like an important quantity (akin, in e.g. weak supervision / crowd source modeling papers, to quantity of how bounded away from random noise the labelers are). This is treated empirically, but would be stronger to have this show up in the theory somewhere.\n\n- Other prior work here has handled k classes with k U sets; could have extended to cover this setting too, since seems natural\n\nOverall take: This learning from label proportions setting has been covered before, but this paper presents it in an overall clean and general way, testing it empirically on modern models and datasets, which is an interesting contribution.\n\nOther minor points:\n- The argument for / distinction between using eqns. (3) and (4) seems a bit ad hoc / informal (""we argue that..."").  This is an important point...\n- Theorem 1 proof seems fine, but some intuition in the main body would be nice.\n- What does ""classification calibrated"" mean?\n- Saying that three U sets are needed, where this includes the test set, seems a bit non-standard?  Also I\'m confused- isn\'t a labeled test set used?  So what is this third U set for?\n- The labels l_+ and l_- in Defn. 3 seem to imply that the two U sets are positive vs. negative; but this is not the case, correct…?\n- Stating both Lemma 5 and Thm 6 seems unnecessary\n- In Fig. 2, seems like could have trained for longer and perhaps some of the losses would have continued decreasing?  In particular, small PN?  Also, a table of the final test set accuracies would have been very helpful.\n- More detail on experimental protocol would be helpful: what kind of hyperparameter tuning was done? repeated runs averaging?  It seems odd, for example in Fig. 3, that the green lines are so different in (a) vs. (c), and not in the way that one would expect given the decrease in theta\n', 'Summary: \nThe authors introduce the task of learning from unlabeled data clearly and concisely with sufficient reference to background material. They propose a learning approach, called UU, from two unlabeled datasets with known class priors and prove consistency and convergence rates. Their experiments are insightful to the problem, revealing how the two datasets must be sufficiently separated and how UU learning outperforms state-of-the-art approaches. The writing is clear and the idea is an original refinement of earlier work, justified by its exceeding state-of-the-art approaches. However, the paper needs more experimentation.  \n\nFurther details:\nWhile the introduction and set-up is long, it positions the paper well by making it approachable to someone not directly in the subject area and delineating how the approach differs from existing theory. The paper flows smoothly and the arguments build sequentially. A few issues are left unaddressed:\n- How does the natural extension of UU learning extend beyond the binary setting? \n- As the authors state, in the wild the class priors may not be known. Their experiment is not completely satisfying because it scales both priors the same. It would be more interesting to experimentally consider them with two different unknown error rates. If this were theoretically addressed (even under the symmetrical single epsilon) this paper would be much better. \n- In Table 2, using an epsilon greater than 1 seems to always decrease the error with a seeming greater impact when theta and theta\' are close. This trend should be explained. In general, the real-world application was the weakest section. Expounding up on it more, running more revealing experiments (potentially on an actual problem in addition to benchmarks), and providing theoretical motivation would greatly improve the paper. \n- In the introduction is is emphasized how this compares to supervised learning but the explanation is how this compares to unsupervised clustering is much more terse. Another sentence or two explaining why using the resulting cluster identifications for binary labeling is inferior to the ""arbitrary binary classifier"" would help. It\'s clear in the author\'s application because one would like to use all data available, including the class priors, for classification. \n\nMinor issues: \n-At the bottom of page 3 the authors state, "" In fact, these two are fairly different, and the differences are reviewed and discussed in Menon et al. (2015) and van Rooyen & Williamson (2018). "" It would be clearer to immediately state the key difference instead of waiting until the end of the paragraph. \n- In the first sentence of Section 3.1 ""imagining"" is mistyped as ""imaging.""\n- What does ""classifier-calibrated"" mean in Section 3.1? \n- In Section 3.1, ""That is why by choosing a model G, g∗ = arg ming∈G R(g) is changed as the target to which"" was a bit unclear at first. The phrase ""is changed as the target to which"" was confusing because of the phrasing. Upon second read, the meaning was clear. \n- In the introduction it was stated ""impossibility is a proof by contradiction, and the possibility is a proof by construction."" It would be better to (re)state this with each theorem. I was immediately curious about the proof technique after reading the theorem but no elaboration was provided (other than see the appendix). The footnote with the latter theorem is helpful as it alludes to the kind of construction used without being overly detailed.\n- In section 5.2, in the next to last sentence of the first paragraph there are some issues with missing spaces. \n- Some more experiment details, e.g. hyperparameter tuning, could be explained in the appendix for reproducibility. ', ""This paper proposes a methodology for training any binary classifier from only unlabeled data. They proved that it is impossible to provide an unbiased estimator if having only a single set of unlabeled data, however, they provide an empirical risk minimization method for only two sets of unlabeled data where all the class priors are given. Some experiments and comparisons with state-of-the-art are provided, together with a study on the robustness of the method.\n\npros:\n\n- The paper is clear, and it provides an interesting proven statement as well as a methodology that can be applied directly. Because they show that only two sets with different (and known) priors are sufficient to have an unbiased estimator, the paper has a clear contribution.\n- The impact of the method is a clear asset, because learning from unlabeled data is applicable to a large number of tasks and is raising attention in the last years.\n- The large literature on the subject has been well covered in the introduction.\n- The importance made on the integration of the method to state-of-the-art classifiers, such as the deep learning framework, is also a very positive point.\n- The effort made in the experiments, by testing the performance as well as the robustness of the method with noisy training class priors is very interesting. \n\nremarks:\n\n- part 4.1 : the simplification is interesting. However, the authors say that this simplification is easier to implement in many deep learning frameworks. Why is that?\n- part 4.2 : the consistency part is too condensed and not clear enough.\n- experiments : what about computation time?\n- More generally, I wonder if the authors can find examples of typical problems for classification from unlabeled data with known class priors and with at least two sets?\n\nminor comments:\n- part 1: 'but also IN weakly-supervised learning'\n- part 2. related work : post- precessing --> post-processing\n- part 2. related work : it is proven THAT the minimal number of U sets...\n- part 2. related work : In fact, these two are fairly different --> not clear, did you mean 'Actually, ..' ?\n- part 4.1 : definition 3. Why naming l- and l+ the corrected loss functions? both of them integrate l(z) and l(-z), so it can be confusing.\n- part 5.1 Analysis of moving ... closer: ... is exactly THE same as before.\n- part 5.2 : Missing spaces : 'from the webpage of authors.Note ...' and 'USPS datasetsfor the experiment ...' "", 'The authors propose an unbiased estimator that allows for training models with weak supervision on two unlabeled datasets with known class priors. The theoretical properties of the estimator are discussed and an empirical evaluation shows promising performance.\n\nThe paper provides a thorough overview of the related work.\nThe experiments compare to the relevant baselines.\n\nMinor remarks:\n\nThe writing seems like it could be improved in multiple places and the main thing that makes some sections of the paper hard to follow is that the concepts often get mentioned and discussed before they are formally defined/introduced. Concepts that are introduced via citations should also be explained even if not in-depth.\n\nFigure 2: the curves suggest that the models should have been left to train for a longer time - some of the small PN and small PN prior-shift risks are still decreasing\n\nFigure 2: the scaling seems inconsistent - the leftmost subplot in each row doesn’t start at (0,0) in the lower left corner, unlike the other subplots in each row - and it should probably be the same throughout - no need to be showing the negative space.\n\nFigure 2: maybe it would be good to plot the different lines in different styles (not just colors) - for BW print and colorblind readers\n\nFor small PN and small PN prior-shift, the choice of 10% seems arbitrary. At what percentage do the supervised methods start displaying a clear advantage - for the experiments in the paper?\n\nWhen looking into the robustness wrt noise in the training class priors, both are multiplied by the same epsilon coefficient. In a more realistic setting the priors might be perturbed independently, potentially even in a different direction. It would be nice to have a more general experiment here, measuring the robustness of the proposed approach in such a way.\n\n5.2 typo: benchmarksand ; datasetsfor']","[20, 50, 80, 50]","[60, 75, 70, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and thoroughness, calling it an 'interesting contribution.' However, they also point out several cons and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses professional language throughout, balances pros and cons, and offers constructive criticism. They use phrases like 'could be improved' and 'would be helpful' rather than harsh criticisms. The reviewer also acknowledges the paper's strengths and concludes with a generally positive overall take, which contributes to the polite tone."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's strengths, such as clear writing, original ideas, and outperforming state-of-the-art approaches. However, they also point out areas for improvement, particularly in experimentation. The overall tone is constructive and balanced. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'would be more interesting' and 'would greatly improve the paper' instead of more negative phrasing. The reviewer also takes care to explain their reasoning for each point of feedback, which adds to the politeness of the review."", ""The sentiment score is 80 (positive) because the review starts with a clear summary of the paper's contributions and lists several pros, indicating a generally positive view. The reviewer acknowledges the paper's clarity, interesting proven statement, and potential impact. The remarks and minor comments are constructive rather than critical. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions (e.g., 'I wonder if the authors can find examples...'). The reviewer also balances positive feedback with areas for improvement. The use of phrases like 'interesting' and 'very positive point' further contributes to the polite tone. The score is not higher as the review maintains a professional, somewhat neutral tone rather than being overly deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and thorough overview, while also providing constructive feedback. The overall tone is encouraging, with phrases like 'promising performance' and 'thorough overview'. However, it's not overwhelmingly positive due to the various suggestions for improvement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as 'minor remarks' and suggestions rather than demands. The use of phrases like 'it would be nice' and 'maybe it would be good' further contribute to the polite tone. The reviewer also balances critique with positive observations, maintaining a professional and courteous approach.""]"
"['This paper proposes an auxiliary variable MCMC scheme involving variational inference for efficient MCMC. Given a target distribution p(x), the authors introduce an auxiliary variable a, and learn conditional distributions p(a|x) and q(a|x) by minimizing the KL divergence between p(x)p(a|x) and q(a)q(x|a), with q(a) something simple (the authors use Gaussian). A MH proposal step involves simulating x givea the current MCMC sample x (from p(a|x), taking a step in A-space, and then returning back to the X space (using q(x|a)).  The authors show how to calculate the acceptance probability. \n\nI think the idea is nice and useful (I\'m surprised people haven\'t thought of this before), though I think the paper presents this in a less clear way (as an extension of ideas from Agakov and Barber\'s ""Auxiliary variational method""). While this is correct and perhaps more general, in my mind it slightly obscures the main idea, as well as the strong ties with variational autoencoders: express a complex distribution as a (learnt) transformation of a simple distribution (this is the actual approach taken in the experiments). \n\nThe motivation of the approach is that the nonlinear encoding network can transform the complex p(x) into a simpler q(a). \nFor this reason, I think an important baseline is the independent MH sampler from equation 8 (I think this essentially uses a trained VAE generative model as a proposal distribution). The authors talk about how producing independent proposals can be sub-optimal, yet it seems to me that if the encoder and decoder neural networks are powerful enough, this should do a good job. I think excluding this baseline hurts the paper a bit.\n\nThe proof of correctness while correct is a bit unclear, can perhaps be simplified if you view the MCMC algorithm as operating on an augmented space (x,a,x\') with stationary distribution p(x)q(a|x)q(x\'|a) (writing writing q for \\tilde(q)). This clearly has the right distribution over x. Each MCMC iteration starts with x and proceeds as follow:\n  1) Given x, sample a and x\' from q(a|x) and q(x\'|a)\n  2) Make a deterministic proposal on the augmented space to swap (x,x\'). The acceptance probability is now equation 2.\n  3) Discard a,x\'.\n\nIn figure 4, the authors use HMC as an ""improved MCMC algorithm"", yet this is not an algorithm that deals with multimodality well. More useful would be to include some tempering algorithm like serial or parallel tempering.\n\nWhile I like the idea, I unfortunately don\'t think the experiments are very convincing (and the authors barely discuss their results). Other than mixture of Gaussians, HMC (which involves no training) appears to be superior. With some tempering, I expect it to outperform the proposed method for the MoG case\n\nTable 2 left: since HMC involves no training, does this mean that, taking training time into account, HMC is 5-6 orders of magnitude more efficient. L?ke I mentioned earlier, these results need more discussion. \n\nIt would also help to provide absolute training and run times, so the reader can better understand whether the proposed method of ANICE is better.\n\nFigure 3: why don\'t the authors also plot the histogram of values in the auxiliary space, p(a). It would be interesting to see how Gaussian this is (this is what variational inference is trying to achieve). Also, does Figure 3(a) mean that conditioned on x, p(a|x) is basically a delta function? This would suggest that the encoder is basically learning a deterministic transformation to a simpler low-dimensional space? There is some work in this direction in the statistics literature, e.g. \n""Variable transformation to obtain geometric ergodicity in the random-walk Metropolis algorithm""\n\nThe authors some refers to the distribution of a|x as q(a|x) sometimes (in section 2.1) and sometimes as p(a|x) which is a bit confusing.\n\nFigure 2: the labels are wrong.', 'In my opinion, the paper contains very interesting novel ideas.\nHowever, some parts needs a future clarification and the state-of-the-art must be improved.\n\n- First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified. For instance, I believe you can create a unique section with title "" Choice of Proposal density "" and then schematically describe each proposal from the simplest to the more sophisticated one.\n\n- At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.\n\n- Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates where, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way. This is more general that your scheme but very related. Please see\n\nQin, Z.S., Liu, J.S., 2001. Multi-point Metropolis method with application to hybrid Monte Carlo. Journal of Computational Physics 172, 827–840.\n\nL. Martino, V. P. Del Olmo, J. Read, ""A multi-point Metropolis scheme with generic weight functions"", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.\n\nL. Martino, ""A Review of Multiple Try MCMC algorithms for Signal Processing"", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.\n\n- Related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed. If I have properly understood, you also adapt a mixture via variational inference. Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,\n\nP. Giordani and R. Kohn, “Adaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,” Journal of Computational and Graphical Statistics, vol. 19, no. 2, pp. 243–259, September 2010.\n\nTran, M.-N., M. K. Pitt, and R. Kohn. Adaptive Metropolis–Hastings sampling using reversible dependent mixture proposals. Statistics and Computing, 26, 1–21, 2014.\n\nD. Luengo, L. Martino, ""Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm"", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.\n\nRoberts, G. O. and J. S. Rosenthal (2009). Examples of adaptive MCMC. Journal of Computational and Graphical Statistics 18, 349–367.\n\n\n', 'This paper proposes a clever and sensible approach to using the structure learned by the auxiliary variational method to accelerate random-walk MCMC. The idea is to learn a low-dimensional latent space that explains much of the variation in the original parameter space, then do random-walk sampling in that space (while also updating a state variable in the original state, which is necessary to ensure correctness).\n\nI like this idea and think the paper merits acceptance, although there are some important unanswered questions. For example:\n- How does the method work on higher-dimensional target distributions? I would think it would be hard for a low-dimensional auxiliary space to have high mutual information with a much higher-dimensional space. In principle neural networks can do all sorts of crazy things, but phenomena like VAEs with low-dimensional latent spaces generating blurry samples make me suspect that auxiliary dimension should be important.\n- How does the method work with hierarchical models, heavy-tailed models, etc.? Rings, MoGs, and flat logistic regressions are already pretty easy targets.\n- Is it really so valuable to not need gradients? High-quality automatic differentiation systems are widely available, and variational inference on discrete parameters with neural nets remains a pretty hard problem in general.\n\nSome other comments:\n\n* It’s probably worth citing Ranganath et al. (2015; “Hierarchical Variational Models”), who combine the auxiliary variational method with modern stochastic VI. Also, I wonder if there are connections to approximate Bayesian computation (ABC).\n\n* I think you could prove the validity of the procedure in section 2.1 more succinctly by interpreting it as alternating a Gibbs sampling update for “a” with a Metropolis-Hastings update for “x”. If we treat “a” as an auxiliary variable such that\np(a | x) = \\tilde q(a | x)\np(x | a) \\propto p(x) \\tilde q(a | x)\nthen the equation (2) is the correct M-H acceptance probability for the proposal\n\\tilde q(a’, x’) = δ(a’-a) \\tilde q(x’ | a).\nAlternating between this proposal and a Gibbs update for “a” yields the mixture proposal in section 2.1.\n\n* It’s also possibly worth noting that this procedure will have a strictly lower acceptance rate than the ideal procedure of using the marginal\n\\tilde q(x’|x)\nas a M-H proposal directly. Unfortunately that marginal density usually can’t be computed, which makes this ideal procedure impractical. It might be interesting to try to say something about how large this gap is for the proposed method.\n\n* ""We choose not to investigate burn-in since AVS is initialized by the variational distribution and therefore has negligible if any burn-in time.” This claim seems unjustified to me. It’s only true insofar as the variational distribution is an excellent approximation to the posterior (in which case why use MCMC at all?). It’s easy to find examples where an MCMC chain initialized with a sample from a variational distribution takes quite a while to burn in.']","[-20, 20, 60]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'nice and useful', they express several criticisms and concerns about the paper's presentation, experiments, and results. The reviewer states that the experiments are 'not very convincing' and that the baseline methods seem to outperform the proposed method in some cases. However, the score is not deeply negative as the reviewer still sees merit in the core idea.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think' and 'It would help' to soften criticisms, and they offer specific suggestions for improvement. The reviewer also acknowledges positive aspects, such as calling the idea 'nice and useful'. However, the score is not extremely high as the review is still quite direct in its criticisms and doesn't use overly polite language."", ""The sentiment score is slightly positive (20) because the reviewer starts by stating the paper contains 'very interesting novel ideas', which is a positive comment. However, this is immediately followed by mentions of areas needing improvement, which tempers the positivity. The overall tone is constructive rather than overtly negative or positive. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'please' and 'I believe', and frames criticisms as suggestions rather than demands. The reviewer also acknowledges the authors' work positively before offering improvements. The language is professional and respectful, without any rudeness, but also not excessively formal or deferential."", ""The sentiment score is 60 (positive) because the reviewer starts by calling the approach 'clever and sensible' and states that 'the paper merits acceptance'. However, they also raise several important questions and concerns, which tempers the overall positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions rather than criticisms. They also use phrases like 'I like this idea' and 'It's probably worth citing', which are polite ways of offering suggestions. The reviewer maintains a professional and courteous tone while providing detailed feedback.""]"
"['The paper studies the problem of generating synthetic datasets (while ensuring differential privacy) via training a GAN. One natural approach is the teacher-student framework considered in the PATE framework.  In the original PATE framework, while the teachers are ensured to preserve differential privacy, the student model (typically a GAN) requires the presence of publicly data samples. The main contribution of this paper is to get around the requirement of public data via using uniformly random samples in [0,1]^d.\n\nDifferentially private synthetic data generation is clearly an important and a long-standing open problem. Recently, there has been some work on exploiting differentially private variants of GANs to generate synthetic data. However, the scale of these results is far from satisfactory. The current paper claims to bypass this issue by using the PATE-GAN approach.\n\nI am not an expert on deep learning. The idea of bypassing the use of public data by taking uniformly random samples seems interesting. In my view, these random vectors are used in the GAN as some sort of a basis. It is interesting to see if this result extends to high-dimensional settings (i.e., where d  is very large).', ""[Post revision update] The authors' comments addressed my concerns, especially on the experiment side. I changed the score.\n\nThis paper applies the PATE framework to GAN, and evaluates the quality of the generated data with some predictive tasks. The experimental results on some real datasets show that the proposed algorithm outperforms DPGAN, and the generated synthetic data is quite useful in comparison with real data.\nThe presentation is clear and easy to follow. However, I think the paper needs to be improved in its novelty, and the techniques and experiments need to be more thorough.\n\nMore details:\n- It might be necessary to consider using Gaussian noise[24] in replace of the Laplace noise, which, according to [24], would improve privacy and accuracy.\n- This paper:\n“Privacy-preserving generative deep neural networks support clinical data sharing” by Brett K. Beaulieu-Jones, Zhiwei Steven Wu, Chris Williams, Casey S. Greene\nseems quite relevant. If so, you may want to add some discussion in the related work section or compare with their result.\n- The last paragraph of the related works section mentioned some related work with shortcomings as working only on low-dimensional data and features of specific types, yet the experiments are also mostly done on low-dimensional datasets. I think it would be better to do a thorough evaluation on data of different kinds, such as image data. \n- If the two evaluation metrics for private GAN is considered an important contribution of the paper, it might be better to make it a separate section and elaborate more on the motivation and method.  \n- It might be better to move some details (for example, instead of presenting the results of the 12 predictive models, presenting only the average, as it’s not very important how each of them performs) of the credit card fraud detection dataset to the appendix and bring the results of the other datasets to the main body. \n"", 'This paper considers using a GAN to generate synthetic data in a differentially private manner [see also https://www.biorxiv.org/content/early/2018/06/05/159756 ]. The key novelty is the integration of the PATE differential privacy framework from recent work. Specifically, rather than a single distinguisher as is usual in a GAN, there is a ""student distinguisher"" and several ""teacher distinguishers"". The student distinguisher is used as usual except that it does not have access to the real data, only the teacher distinguishers have access to the real data (as well as the synthetic data). The data is partitioned amongst the teacher distinguishers and their output is aggregated in a differentially private manner (and gradients are not revealed). The role of the teacher distinguishers is solely to correct the student distinguisher when it errs.\n\nWhat is strange about this setup is that the generator\'s only feedback is from the gradients of the student distinguisher, which is never exposed to the real data. The entire training process relies on the generator producing realistic data by chance at which point the teacher distinguishers can provide positive feedback. (The paper remarks about this in the middle of page 5.) It\'s surprising that this works, but there are experimental results to back it up.\n\nI think it would be appropriate to remark that generating private synthetic data is known to be hard in the worst case [ https://eccc.weizmann.ac.il/report/2010/017/ ] and therefore it is necessary to use techniques like GANs.\n\nOverall, I think the paper is interesting, well written, novel, and therefore appropriate for ICLR.']","[50, 50, 80]","[75, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the problem and finds the paper's approach interesting, while also expressing some reservations about their expertise in deep learning and questioning the scalability of the results. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames their concerns as questions rather than criticisms. The reviewer also uses phrases like 'clearly an important' and 'interesting to see' which contribute to a polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the authors have addressed their concerns and improved the paper. The initial paragraph mentions that the presentation is clear and easy to follow, and the results show that the proposed algorithm outperforms others. However, the reviewer still suggests improvements in novelty and thoroughness of techniques and experiments, which prevents a higher positive score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'It might be necessary,' 'you may want to,' and 'It might be better' indicate a polite and considerate tone. The reviewer also acknowledges the authors' efforts to address previous concerns, which adds to the politeness."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper is 'interesting, well written, novel, and therefore appropriate for ICLR'. They also mention that the experimental results back up the surprising effectiveness of the method. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive suggestions. They don't use overly formal or deferential language, but maintain a professional and courteous tone. The reviewer also provides helpful context and suggestions for improvement without being critical or dismissive.""]"
"[""This paper considers the compression of the model parameters in deep neural networks. The authors propose minimal random code learning (MIRACLE), which uses a random sample of weights and the variational framework interpreted by the bits-back argument. The authors introduce two theorems characterizing the properties of MIRACLE, and demonstrate its compression performance through the experiments.\n\nThe proposed approach is interesting and the performance on the benchmarks is good enough to demonstrate its effectiveness. However, since the two main theorems are based on the existing results by Harsha et al. (2010) and Chatterjee & Diaconis (2018), the main technical contribution of this paper is the sampling scheme in Algorithm 1.\n\nAlthough the authors compare the performance trade-offs of MIRACLE with that of the baseline methods quoted from source materials, isn't it possible or desirable to include other competitors or other results for the baseline methods? Are there any other methods, in particular, achieving low error rate (with high compression size)? Little is discussed on why the baseline results are only a few. \n\nminor comment: \n- Eq.(4) lacks p(D) in front of dD.    \n\nPros:\n- Interesting approach based-on the bits back argument\n- Good performance trade off demonstrated through experiments\nCons:\n- Only a few baseline results, in particular, at high compression size\n"", 'In this paper the authors propose to use MLD principle to encode the weights of NNs and still preserve the performance of the original network. The main comparison is from Han 2016, in which the authors use ad-hoc techniques to zero some coefficient and prune some connection + Huffman coding. In this case , the authors uses as a regularizer (See equation 3) a constraints that the weights are easy to compress. The results seem significant improvement with respect to the state of the art. \n\n', 'The authors come up with a surprisingly elegant algorithm (""minimal random coding"") which encodes samples from a posterior distribution, only using a number of bits that approximates the KL divergence between posterior and prior, while Shannon-type algorithms can only do this if the posterior is deterministic (a delta distribution). It can also be directly used to sample from continuous distributions, while Shannon-type algorithms require quantization. In my opinion, this is the main contribution of the paper.\n\nThe other part of the paper that is specifically concerned with weight compression (""MIRACLE"") turns out to be a lot less elegant. It is somewhat ironic that the authors specifically call attention to the their algorithm sending random samples, as opposed to existing algorithms, which quantize and then send deterministic variables. This is clearly true for the basic algorithm, but, if I understand correctly, not for MIRACLE. It seems clear that neural networks are sensitive to random resampling of their weights -- otherwise, the authors would not have to fix the weights in each block and then do further gradient descent for the following blocks. What would happen if the distributions were held constant, and the algorithm would be run again, just with a different (but identical) random seed in both sender and receiver? It seems this would lead to a performance drop, demonstrating that (albeit indirectly), MIRACLE also makes a deterministic choice of weights.\n\nOverall, I find the paper somewhat lacking in terms of evaluation. MIRACLE consists of a lot of parts. It is hard to assess how much of the final coding gain presented in table 1 is due to the basic algorithm. What is the effect of selecting other probability models, possibly different ones than Gaussians? Choosing appropriate distributions can have a significant impact on the value of the KL divergence. Exactly how much is gained by applying the hashing trick? Are the standard deviations of the priors included in the size, and how are they encoded?\n\nThis could be assessed more clearly by directly evaluating the basic algorithm. Theorem 3.2 predicts that the approximation error of algorithm 1 asymptotically zero, i.e. one can gain an arbitrarily good approximation to the posterior by spending more bits. But how many more are practically necessary? It would be fantastic to actually see some empirical data quantifying how large the error is for different distributions (even simple toy distributions). What are the worst vs. best cases?\n']","[20, 80, 20]","[50, 50, 50]","['The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting approach and good performance of the proposed method. However, they also point out limitations, such as the lack of comparison with other competitors and limited baseline results. The politeness score is moderately positive (50) as the reviewer uses respectful language, phrases criticisms as questions or suggestions, and provides a balanced view with both pros and cons. The reviewer avoids harsh language and presents their concerns in a constructive manner.', ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, noting 'significant improvement with respect to the state of the art' and describing the authors' approach in detail without criticism. The politeness score is 50 (somewhat polite) because the language is professional and neutral, without overtly polite phrases but also without any rudeness. The reviewer objectively describes the paper's content and findings without using personal or emotional language, maintaining a respectful tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer starts by praising the 'surprisingly elegant algorithm' and its main contribution. However, they also express concerns about the MIRACLE part of the paper and the lack of thorough evaluation, which tempers the overall positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the authors' work while offering constructive criticism. They use phrases like 'in my opinion' and 'if I understand correctly,' which show consideration. The reviewer also provides specific suggestions for improvement without using harsh or dismissive language.""]"
"['The paper design a low variance gradient for distributions associated with continuous or discrete random variables. The gradient is designed in the way to approximate the  property of reparameterization gradient.  The paper is comprehensive and includes mathematical details. \n\nI have following comments/questions\n\n1. What is the \\kappa in “variable-nabla” stands for? What is the gradient w.r.t. \\kappa?\n\n2. In Eq(8), does the outer expectation w.r.t . y_{-v} be approximated by one sample? If so, it is using the local expectation method. How does that differs from Titsias & Lazaro-Gredilla(2015) both mathematically and experimentally? \n\n3. Assume y_v is M-way categorical distribution, Eq(8) evaluates f by 2*V*M times which can be computationally expensive. What is the computation complexity of GO? How to explain the fast speed shown in the experiments?\n\n4. A most simple way to reduce the variance of REINFORCE gradient is to take multiple Monte-Carlo samples at the cost of more computation with multiple function f evaluations. Assume GO gradient needs to evaluate f N times, how does the performance compared with the REINFORCE gradient with N Monte-Carlo samples? \n\n5. In the discrete VAE experiment, upon brief checking the results in Grathwohl(2017), it shows validation ELBO for MNIST as (114.32,111.12), OMNIGLOT as (122.11,128.20) from which two cases are better than GO. Does the hyper parameter setting favor the GO gradient in the reported experiments? Error bar may also be needed for comparison. What about the performance of GO gradient in the 2 stochastic layer setting in Grathwohl(2017)?\n\n6. The paper claims GO has less parameters than REBAR/RELAX. But in Figure 9, GO has more severe overfitting. How to explain this contradicts between the model complexity and overfitting?\n\n', '* Summary\n\nThe paper proposes an improved method for computing derivatives of the expectation. Such problems arises with many probabilistic models with noises or latent variables. The paper proposes a new gradient estimator of low variance applicable in certain scenarios, in particular it allows training of generative models in which observations and/or latent variables are discrete. \nThe submission clearly improves the state-of-the-art, experimentally demonstrates the method on several problems comparing with the alternative techniques. In what concerns the optimization, the method achieves a better objective value much faster, confirming that it is a lower variance gradient estimator. \nThe clarity of the presentation (in particular the description of when the method is applicable) and the technical correctness of the paper are somewhat lacking. In terms of applicability, it seems that many cases where discrete latent variables would be really interesting are not covered (e.g. sigmoid belief networks); the paper demonstrates experiments with discrete images (binary or 4-bit) not particularly motivated in my opinion. It also contains lots of additional technical details and experiments in the appendix, which I unfortunately did not review.\n\n* Clarity\n\nIn the abstract the paper promises more than it delivers. Many problems can be cast as optimizing an expectation-based objective. The result does not at all apply to all of them. The reparameterization trick does not apply to all continuous random variables, only to such that the reparameterization satisfies certain smoothness conditions. Discrete variables are supported by the method only in the case that the distribution factors over all discrete variables conditionally on any additional “continuous variables” (to which the reparameterization trick is applicable). This very much limits the utility of the method. In particular it is not applicable to learning e.g. sigmoid belief networks [Neal, 92] (with conditional Bernoulli units) and many other problems. \n\n“reparametrizable distributions”\nA Bernoulli(p) random variable is discrete, yet it is reparametrizable as [Z>p] with Z following standard logistic distribution, whose density and cdf is smooth. \n\nBecause of the above many discussions about discrete vs. continuous variables are missleading.\n\nSection 2. The notation of the true distribution as “q” the model as p and the approximate posterior of the model as “q” again is inconsistent. I find the background on ELBO and GANs unnecessary occluding the clarity at this point. For the purpose of introduction, it might be better to give examples of expectation objectives such as: \n- dropout: q is the distribution of NN outputs given the input image and integrating out latent dropout noises, gamma are parameters of this NN.\n- VAE, GAN: q is the generative model defined as a mapping of a standard multivariate normal distribution by a NN.\n- sigmoid belief networks: q is a Bayesian network where each conditional distribution is a logistic regression model.\nThen to state to which of these cases the results of the paper are applicable, allow for an improvement of the variance and at what additional computational cost (considering the cost of evaluating the discrete derivatives).\n\nSection 3.\nContrary to the discussion, there are examples of non-negative distributions to which the reparameterization trick can be applied, including log-Normal and Gamma distributions.\n\nMethod:\nIn the case when Rep trick is applicable, is it identical to GO? The difference seems to be only in that the mapping tau may be different from Q^-1. However, this only affects the method of drawing the samples from a fixed known distribution and should have no more effect on the results than say a choice of a pseudo-random number generator. Yet, in Fig.1 some difference is observed between the methods, why is that so?\n\nSec 7.1\n“We adopt the sticking approach hereafter”. Does it mean it is applied with all experiments with GO?\n\n* Related Work\n\nThe state of the art allows combining differentiable and non-differentiable pieces of computation:\n[Schulman, J., Heess, N., Weber, T., Abbeel, P.: Gradient estimation using stochastic computation graphs.]\nI believe it should be discussed in related work. Limitations / where the proposed method brings an improvement should be highlighted.\n\n* Technical Correctness\nEquations (5) and (6) require a theorem of differentiating under integral (expectation), such as Leibnitz rule, which in case of (6) requires q_gamma(y)f(y) to be continuous in y and q_gamma(y) continuously differentiable in gamma.\nEquation (7) (integration by parts) holds only with some additional requires on f.\nTheorem 1 does not take account for the above conditions.\n\n', 'This paper presents a gradient estimator for expectation-based objectives, which is called Go-gradient. This estimator is unbiased, has low variance and, in contrast to other previous approaches, applies to either continuous and discrete random variables. They also extend this estimator to problems where the gradient should be ""backpropagated"" through a nested combination of random variables and a (non-linear) functions. Authors present an extensive experimental evaluation of the estimator on different challenging machine learning problems. \n\n\nThe paper addresses a relevant problem which appears in many machine learning settings, as it is the problem of estimating the gradient of an expectation-based objective. In general, the paper is well written and easy to follow. And the experimental evaluation is extensive and compares with relevant state-of-the-art methods.  \n\nThe main problem with this paper is that it is difficult to identify its main and novel contributions. \n\n1. In the case of continuous random variables, Go-gradient is equal to Implicit Rep gradients (Figurnov et al. 2018) and pathwise gradients (Jankowiack & Obermeyer,2018). Furthermore, for the Gaussian case, Implicit Rep gradients (and Go-gradient too) are equal to the standard reparametrization trick estimator (Kingma & Welling, 2014). This should be made crystal-clear in the paper. What happens is that the authors arrive at this solution using a different approach. \n\nIn this sense, claims about the low-variance of GO-gradient wrt to other reparametrization baed estimators should be removed, as they are the same. Moreover, I don\'t think some of the presented experiments are necessary. Simply because for continuous variables similar experiments have been reported before (Figurnov et al. 2018, Jankowiack & Obermeyer,2018). \n\n2. It seems that the main novel contribution of the paper is to extend the ideas of (Figurnov et al. 2018, Jankowiack & Obermeyer,2018) to discrete variables. And this is a relevant contribution.  And the experimental evaluations of this part are convincing and compare favourably with other state-of-the-art methods.   \n\n3. Authors should be much more clear about which is their original contribution to the problems stated in Section 4 and Section 5. As authors acknowledge in Section 6. <<Stochastic back-propagation (Rezende et al., 2014; Fan et al., 2015), focusing mainly on re-parameterizable Gaussian random variables and deep latent Gaussian models, exploits the product rule for an integral to derive gradient backpropagation through several continuous random variables.>> This is exactly what authors do in these sections. Again it seems that the real contribution of this paper here is to extend this stochastic back-propagation (Rezende et al., 2014; Fan et al., 2015) ideas to discrete variables. Although this extension seems to be easily derived using the contributions made at point 2. \n\nSummarizing, the paper addresses a relevant problem but they do not state which their main contributions are, and reintroduce some ideas previously published in the literature. ']","[20, 20, -20]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's comprehensiveness and mathematical detail in the first paragraph. However, the bulk of the review consists of questions and comments, indicating areas for improvement or clarification, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses neutral, professional language throughout. They frame their points as questions or comments rather than direct criticisms, and use phrases like 'I have following comments/questions' which maintains a respectful tone. The absence of harsh or dismissive language also contributes to the politeness score. The reviewer's approach of asking for clarifications and comparisons with other work suggests a constructive attitude, further supporting the positive politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's improvements to the state-of-the-art and its experimental demonstrations. However, they also point out several limitations and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They acknowledge the paper's strengths while also providing detailed critiques in a respectful manner. The reviewer uses phrases like 'somewhat lacking' and 'missleading' instead of more confrontational language, indicating a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's relevance and extensive experimental evaluation, they express significant concerns about the clarity of the paper's novel contributions and the reintroduction of previously published ideas. The reviewer states that 'The main problem with this paper is that it is difficult to identify its main and novel contributions' and suggests removing certain claims and experiments. However, the score is not deeply negative as the reviewer does recognize some value in the work, particularly in extending ideas to discrete variables.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments about the paper's relevance and writing quality. Even when expressing criticisms, the language remains constructive and objective, using phrases like 'Authors should be much more clear' rather than using harsh or dismissive language. The reviewer also acknowledges the paper's strengths and the validity of some of its contributions, demonstrating a balanced approach.""]"
"['Summary: This paper observes that a major flaw in common image-classification networks is their lack of robustness to common corruptions and perturbations. The authors develop and publish two variants of the ImageNet validation dataset, one for corruptions and one for perturbations. They then propose metrics for evaluating several common networks on their new datasets and find that robustness has not improved much from AlexNet to ResNet. They do, however, find several ways to improve performance including using larger networks, using ResNeXt, and using adversarial logit pairing.\n\nQuality: The datasets and metrics are very thoroughly treated, and are the key contribution of the paper. Some questions: What happens if you combine ResNeXt with ALP or histogram equalization? Or any other combinations? Is ALP equally beneficial across all networks? Are there other useful adversarial defenses?\n\nClarity: The novel validation sets and reasoning for them are well-explained, as are the evaluation metrics. Some explanation of adversarial logit pairing would be welcome, and some intuition (or speculation) as to why it is so effective at improving robustness.\n\nOriginality: Although adversarial robustness is a relatively popular subject, I am not aware of any other work presenting datasets of corrupted/perturbed images.\n\nSignificance: The paper highlights a significant weakness in many image-classification networks, provides a benchmark, and identifies ways to improve robustness. It would be improved by more thorough testing, but that is less important than the dataset, metrics and basic benchmarking provided.\n\nQuestion: Why do authors do not recommend training on the new datasets? ', 'This paper introduces new benchmarks for measuring the robustness of computer vision models to various image corruptions. In contrast with the popular notion of “adversarial robustness”, instead of measuring robustness to small, worst-case perturbations this benchmark measures robustness in the average case, where the corruptions are larger and more likely to be encountered at deployment time. The first benchmark “Imagenet-C” consists of 15 commonly occurring image corruptions, ranging from additive noise, simulated weather corruptions, to digital corruptions arising from compression artifacts. Each corruption type has several levels of severity and overall corruption score is measured by improved robustness over a baseline model (in this case AlexNet). The second benchmark “Imagenet-P” measures the consistency of model predictions in a sequence of slightly perturbed image frames. These image sequences are produced by gradually varying an image corruption (e.g. gradually blurring an image). The stability of model predictions is measured by changes in the order of the top-5 predictions of the model. More stable models should not change their prediction to minute distortions in the image. Extensive experiments are run to benchmark recent architecture developments on this new benchmark. It’s found that more recent architectures are more robust on this benchmark, although this gained robustness is largely due to the architectures being more accurate overall. Some techniques for increasing model robustness are explored, including a recent adversarial defense “Adversarial Logit Pairing”, this method was shown to greatly increase robustness on the proposed benchmark. The authors recommend future work benchmark performance on this suite of common corruptions without training on this corruptions directly, and cite prior work which has found that training on one corruption type typically does not generalize to other corruption types. Thus the benchmark is a method for measuring model performance to “unknown” corruptions which should be expected during test time.\n\nIn my opinion this is an important contribution which could change how we measure the robustness of our models. Adversarial robustness is a closely related and popular metric but it is extremely difficult to measure and reported values of adversarial robustness are continuously being falsified [1,2,3]. In contrast, this benchmark provides a standardized and computationally tractable benchmark for measuring the robustness of neural networks to image corruptions. The proposed image corruptions are also more realistic, and better model the types of corruptions computer vision models are likely to encounter during deployment. I hope that future papers will consider this benchmark when measuring and improving neural network robustness. It remains to be seen how difficult the proposed benchmark will be, but the authors perform experiments on a number of baselines and show that it is non-trivial and interesting. At a minimum, solving this benchmark is a necessary step towards robust vision classifiers. \n\nAlthough I agree with the author’s recommendation that future works not train on all of the Imagenet-C corruptions, I think it might be more realistic to allow training on a subset of the corruptions. The reason why I mention this is it’s unclear whether or not adversarial training should be considered as performing data augmentation on some of these corruptions, it certainly is doing some form of data augmentation. Concurrent work [4] has run experiments on a resnet-50 for Imagenet and found that Gaussian data augmentation with large enough sigma (e.g. sigma = .4 when image pixels are on a [0,1] scale) does improve robustness to pepper noise and Gaussian blurring, with improvements comparable to that of adversarial training. Have the authors tried Gaussian data augmentation to see if it improves robustness to the other corruptions? I think this is an important baseline to compare with adversarial training or ALP.\n\nFew specific comments/typos:\n\nPage 2 “l infinity perturbations on small images”\n\nThe (Stone, 1982) reference is interesting, but it’s not clear to me that their main result has implications for adversarial robustness. Can the authors clarify how to map the L_p norm in function space of ||T_n - T(theta) || to the traditional notion of adversarial robustness?\n\n1. https://arxiv.org/pdf/1705.07263.pdf\n2. https://arxiv.org/pdf/1802.00420.pdf\n3. https://arxiv.org/pdf/1607.04311.pdf\n4. https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57', ""This paper introduces two benchmarks for image classifier robustness, ImageNet-C and Image-P. The benchmarks cover two important cases in classifier robustness  which are ignored by most current researchers. The authors' evaluations also show that current deep learning methods have wide room for improvement. To our best knowledge, this is the first work that provides systematically a common benchmarks for the deep learning community.  The reviewer believes that these two benchmarks can play an important role in the research of image classifier robustness.""]","[70, 80, 90]","[80, 70, 70]","[""The sentiment score is 70 (positive) because the reviewer generally speaks favorably about the paper, highlighting its thorough treatment of datasets and metrics, and noting its significance in addressing a weakness in image-classification networks. The reviewer also mentions the paper's originality and its contribution to the field. While there are some suggestions for improvement, they are presented as opportunities to enhance an already valuable work rather than criticisms.\n\nThe politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and frame their suggestions as questions or areas for potential expansion rather than direct criticisms. The tone is professional and supportive, with phrases like 'well-explained' and 'thoroughly treated' demonstrating respect for the authors' work. The reviewer also uses polite phrasing when asking for additional information or clarification, such as 'Some explanation... would be welcome.'"", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'an important contribution' that 'could change how we measure the robustness of our models'. They express hope that future papers will consider this benchmark, indicating strong approval. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive suggestions, and frames criticisms as questions or gentle recommendations rather than harsh critiques. For example, they say 'Have the authors tried...' instead of demanding changes. The reviewer also acknowledges the value of the work multiple times, showing courtesy. The slightly lower politeness score compared to sentiment is due to the directness of some comments, which is typical in academic reviews but slightly less overtly polite than the overall tone."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, highlighting its novelty and potential impact. They use phrases like 'first work that provides systematically a common benchmarks' and 'can play an important role', indicating high value placed on the research. The politeness score is 70 (polite) as the language is professional and respectful throughout. The reviewer uses phrases like 'To our best knowledge' and 'The reviewer believes', which show consideration and avoid overly assertive language. While not excessively formal or deferential, the tone maintains a courteous and constructive approach typical of academic peer reviews.""]"
"['The authors present a deep reinforcement learning approach that uses a “self-attention”/“transformer”-style model to incorporate a strong relational inductive bias. Experiments are performed on a synthetic “BoxWorld” environment, which is specifically designed (in a compelling way) to emphasize the need for relational reasoning. The experiments on the BoxWorld environment clearly demonstrate the improvement gained by incorporating a relational inductive bias, including compelling results on generalization. Further experimental results are provided on the StarCraft minigames domain. While the results on StarCraft are more equivocal regarding the importance of the relational module—the authors do set a new state of the art and the results are suggestive of the potential utility of relational inductive biases in more general RL settings.\n\nOverall, this is a well-written and compelling paper. The model is well-described, the BoxWorld results are compelling, and the performance on the StarCraft domain is also quite strong. The paper clearly demonstrates the utility of relational inductive biases in reinforcement learning.\n\nIn terms of areas for potential improvement:\n\n1) With regards to framing, a naive reader would probably get the impression that this is the first-ever work to consider a relational inductive bias in deep RL, which is not the case, as the NerveNet paper (Wang et al., 2018) also considers using a graph neural network for deep RL. There are clear differences between this work and NerveNet—most prominently, NerveNet only uses a relational inductive bias for the policy network by assuming that a graph-structured representation is known a priori for the agent. Nonetheless, NerveNet does also incorporate a relational inductive bias for deep RL and shows how this can lead to better generalization. Thus, this paper would be improved by properly positioning itself w.r.t. NerveNet and highlighting how it is different. \n\n2) As with other work using non-local neural networks (or fully-connected GNNs), there is the potential issue of scalability due to the need to consider all input pairs. A discussion of this issue would be very useful, as it is not clear how this approach could scale to domains with very large input spaces. \n\n3) Some details on the StarCraft experiments could be made more rigorous and quantitative. In particular, the following instances could benefit from more experimental details and/or clarifications: \n\nFigure 6: The performance of the control model and relational model seem very close. Any quantitative insight on this performance gap would improve the paper. For instance, is the gap between these two models significantly larger than the average gap between runs over two different random seeds? It would greatly strengthen the paper to clarify that quantitive aspect. \n\nPage 8: ”We observed that—at least for medium sized networks—some interesting generalization capabilities emerge, with the best seeds of the relational agent achieving better generalization scores in the test scenario” — While there is additional info in the appendix, without quantitative framing this statement is hard to appreciate. I would suggest more quantitive detail and rigorous statistical tests, e.g.,  something like “When examining the best 10 out of ??? seeds, the relational model achieved an average performance increase of ???% compared to the control model (p=???, Wilcoxon signed-rank test). However, when examining all seeds ???? was the case.” \n\nPage 8: “while the former adopted a ""land sweep strategy"", controlling many units as a group to cover the space, the latter managed to independently control several units simultaneously, suggesting a finer grained understanding of the game dynamics.” This is a great insight, and the paper would be greatly strengthened by some quantitive evidence to back it up (if possible). For instance, you could compute the average percentage of agents that are doing the same action at any point in time or within some distance from each other, etc. Adding these kinds of quantitative statistics to back up these qualitative insights would both strengthen the argument, while also making it more explicit how you are coming to these qualitative judgements. \n\nFigure 8 caption: “Colored bars indicate mean score of the ten best seeds” — how bad is the drop to the n-10 non-best seeds? And how many seeds where used in total?\n\nPage 13: “following Table 4 hyperparameter settings and 3 seeds” — if three seeds are used in these experiments, how are 10+?? seeds used for the generalization experiments? The main text implies that the same models for the “Collect Mineral Shards” were re-used, but it appears that many more models with different seeds were trained specifically for the generalization experiment. This should be clarified. Alternatively, it is possible that “seeds” refers to both random seeds and hyperparameter combinations, and it would improve the paper to clarify this. It is possible that I missed something here, but I think it highlights the need for further clarification. ', 'This work presents a quantitative and qualitative analysis and evaluation of the self-attention (Vaswani et al., 2017) mechanism combined with relation network (Santoro et al., 2017) in the context of model-free RL. Specifically, they evaluated the proposed relational agent and a control agent on two sets of tasks. The first one “Box-World” is a synthetic environment, which requires the agent to sequential find and use a set of keys in a simple “pixel world”. This simplifies the perceptual aspect and focuses on relational reasoning. The second one is a suite a StarCraft mini-games. The proposed relational agent significantly outperforms the control agent on the “Box-World” tasks and also showed better generalization to unseen tasks. Qualitative analysis of the attention showed some signs of relational reasoning. The result on StarCraft is less significant besides one task “Defeat Zerglings and Banelings"". The analysis and evaluation are solid and interesting. \n\nPresentation: \nThe paper is well written and easy to follow. The main ideas and experiment details are presented clearly (some details in appendix). \n\nOne suggestion is that it would help if there can be some quantitive characteristics for each StarCraft task to help the readers understand the amount of relational reasoning required, for example, the total number of objects in the scene, the number of static and moving objects in the scene, etc. \n\nEvaluation:\nThe evaluation is solid and the qualitative analysis on the “Box-world” tasks is insightful. Two specific comments below:\n\n1. The idea is only compared against a non-relational ""control agent”. It would be interesting to compare with other forms of relation networks, for example, the ones used in (Santoro et al, 2017). This could help evaluate the effectiveness of self-attention for capturing interactions. \n\n2. The difference between relational and control agent is quite significant on the synthetic task but less so on the StarCraft tasks, which poses the question of what kind of real-world tasks requires the relational reasoning, and what type of relational reasoning is already captured by a simple non-relational agent.  \n\nQuestion about novelty:\n\nThis paper claims it presents “a new approach for representing and reasoning…”. However, the idea of transforming feature map into “entity vectors” and self-attention mechanism are already introduced and the proposed approach is more like a combination of both. That being said, the analysis and evaluation of these ideas in RL are new and interesting. \n\nOne minor question: since a level will terminate immediately if a distractor box is opened, does the length of the distractor branches still matter? \n\nDespite the question about novelty, I think the analysis in the paper is solid and interesting. So I support the acceptance of this paper. \n\nMissing references: \nIn the conclusion section, several related approaches for complex reasoning are discussed. It might be also worth exploring the branch of work (Reed & Freitas, 2015; Neelakantan et al, 2015; Liang et al, 2016) that learns to perform multi-step reasoning by generating compositional programs over structured data like tables and knowledge graph. \n\nReed, Scott, and Nando De Freitas. ""Neural programmer-interpreters."" arXiv preprint arXiv:1511.06279 (2015).\nNeelakantan, Arvind, Quoc V. Le, and Ilya Sutskever. ""Neural programmer: Inducing latent programs with gradient descent."" arXiv preprint arXiv:1511.04834 (2015).\nLiang, C., Berant, J., Le, Q., Forbus, K. D., & Lao, N. (2016). Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. arXiv preprint arXiv:1611.00020.\n\n\nTypo:\npage 1: ""using using sets...""', ""The goal of this paper is to enhance model-free deep reinforcement techniques with relational knowledge about the environment such that the agents can learn interpretable state representations which subsequently improves sample complexity and generalization ability of the approach. The relational knowledge works as an inductive bias for the reinforcement learning algorithm and provides better understanding of complex environment to the agents.\nTo achieve this, the authors focus on distributed advantage actor-critic algorithm and propose a shared relational network architecture for parameterizing the actor and critic network. The relational network contains a self-attention mechanism inspired from recent work in that area. Using these new modules, the authors conduct evaluation experiments on  two different environment - synthetic Box World and real-world StarCraft-II minigames where they analyze the performance against non-relational counterparts, visualize the attention weights for interpretability and test on out-of-training tasks for generalizability.\n\nOverall, the paper is well written and provide good explanation of proposed method. The experimental evaluation adequately demonstrates superior performance in terms of task solvability (strong result) and generalizability (to some extent). The idea of introducing relational knowledge into deep reinforcement learning algorithm is novel and timely considering the usefulness of relational representations. However, there are several shortcomings that makes this paper weak:\n\n1.) While it is true that relational representations help to achieve more generalizable approach and some interpretability to learning mechanism, however comparing it to model-based approaches seems a stretch. While the authors themselves present this speculatively in conclusion, they do mention it in abstract and try to relate to model-based approaches. \n2.) The relational representation network using pairwise interaction itself is not novel and has been studied extensively. Similarly the self-attention mechanism used in this paper is already available. \n3. ) Further, the author chose a specific A2C algorithm to add their relational module. But how about other model-free algorithms? Is this network generalizable to any such algorithm? If yes, will they see similar boost in performance? A comparison/study on using this as general module for various model-free algorithms would make this work strong.\n4.) I have some concerns on generalizability claims fro Box World tasks. Currently, the tasks shown are either on levels that require a longer path of boxes than observed or using a key lock combination never used before. But this appears to be a very limited setting. What happens if one just changes the box with a gem between train and test? What happens if the colors of boxes are permuted while keeping the box as it is. I believe the input are parts of scene so how does change in configuration of the scene affect the model's performance?\n5.) What is the role of extra MLP g_theta after obtaining A?\n\nOverall it is very important that the authors present some more analysis on use of relational module to generalize across different algorithms or explain the limitations with it. Further it is not clear what are the contributions of the paper other than parameterizing the actor-critic networks with an already known relational and attention module.""]","[70, 70, -30]","[80, 80, 60]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'well-written and compelling' and states that it 'clearly demonstrates the utility of relational inductive biases in reinforcement learning'. The reviewer also mentions that the results are 'compelling' and the performance is 'quite strong'. However, it's not a perfect 100 as the reviewer does provide several areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive criticism in a professional manner. Phrases like 'areas for potential improvement' and 'the paper would be improved by' indicate a polite approach to feedback. The reviewer also acknowledges the strengths of the paper before suggesting improvements, which is a polite review practice."", ""The sentiment score is 70 (positive) because the reviewer expresses support for the paper's acceptance, describes the analysis as 'solid and interesting', and provides mostly positive feedback. However, they do raise some questions about novelty and suggest additional comparisons, preventing a higher score. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as 'would be interesting' rather than demands. They also acknowledge the paper's strengths while providing feedback. The tone is professional and courteous, though not excessively formal or deferential."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'well written', 'good explanation', 'novel and timely'), they also list several significant shortcomings that make the paper 'weak'. The overall tone is more critical than positive. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'Overall, the paper is well written' and frame their criticisms as suggestions or concerns rather than harsh judgments. However, the score is not higher because the review is still quite critical in content, even if politely expressed.""]"
"['The paper proposes two approximations to the Shapley value used for generating feature scores for interpretability. Both exploit a graph structure over the features by considering only subsets of neighborhoods of features (rather than all subsets). The authors give some approximation guarantees under certain Markovian assumptions on the graph. The paper concludes with experiments on text and images.\n\nThe paper is generally well written, albeit somewhat lengthy and at times repetitive (I would also swap 2.1 and 2.2 for better early motivation). The problem is important, and exploiting graphical structure is only natural. The authors might benefit from relating to other fields where similar problems are solved (e.g., inference in graphical models). The approximation guarantees are nice, but the assumptions may be too strict. The experimental evaluation seems valid but could be easily strengthened (see comments).\n\nComments:\n\n1. The coefficients in Eq. (6) could be better explained.\n\n2. The theorems seem sound, but the Markovian assumption is rather strict, as it requires that a feature i has an S that ""separates"" over *all* x (in expectation). This goes against the original motivation that different examples are likely to have different explanations. When would this hold in practice?\n\n3. While considering chains for text is valid, the authors should consider exploring other graph structures (e.g., parsing trees).\n\n4. For Eqs. (8) and (9), I could not find the definition of Y. Is this also a random variable representing examples?\n\n5. The authors postulate that sampling-based methods are susceptible to high variance. Showing this empirically would have strengthened their claim.\n\n6. Can the authors empirically quantify Eqs. (8) and (9)? This might shed light as to how realistic the assumptions are.\n\n7. In the experiments, it would have been nice to see how performance and runtime vary with increased neighborhood sizes. This would have quantified the importance of neighborhood size and robustness to hyper-parameters.\n\n8. For the image experiments, since C-Shapley considers connected subsets, it is perhaps not surprising that Fig. 4 shows clusters for this method (and not others). Why did the authors not use superpixels as features? This would have also let them compare to LIME and L-Shapley.\n\n', ""This paper provides new methods for estimating Shapley values for feature importance that include notions of locality and connectedness. The methods proposed here could be very useful for model explainability purposes, specifically in the model-agnostic case.  The results seem promising, and it seems like a reasonable and theoretically sound methodology.  In addition to the theoretical properties of the proposed algorithms, they do show a few quantitative and qualitative improvements over other black-box methods.  They might strengthen their paper with a more thorough quantitative evaluation.\n\nI think the KernelSHAP paper you compare against (Lundberg & Lee 2017) does more quantitative evaluation than what’s presented here, including human judgement comparisons.  Is there a way to compare against KernelSHAP using the same evaluation methods from the original paper?\n\nAlso, you mention throughout the paper that the L-shapley and C-shapley methods can easily complement other sampling/regression-based methods.  It's a little ambiguous to me whether this was actually something you tried in your experiments or not.  Can you please clarify?"", 'This paper proposes two methods for instance-wise feature importance scoring, which is the task of ranking the importance of each feature in a particular example (in contrast to class-wise or overall feature importance).  The approach uses Shapely values, which are a principled way of measuring the contribution of a feature, and have been previously used in feature importance ranking.\n\nThe difficulty with Shapely values is they are extremely (exponentially) expensive to compute, and the contribution of this paper is to provide two efficient methods of computing approximate Shapely values when there is a known structure (a graph) relating the features to each other.\n\nThe paper first introduces the L(ocal)-Shapely value, which arises by restricting the Shapely value to a neighbourhood of the feature of interest.  The L-Shapely value is still expensive to compute for large neighbourhoods, but can be tractable for small neighbourhoods.\n\nThe second approximation is the C(onnected)-Shapely value, which further restricts the L-Shapely computation to only consider connected subgraphs of local neighbourhoods.  The justification for restricting to connected neighbourhoods is given through a connection to the Myerson value, which is somewhat obscure to me, since I am not familiar with the relevant literature.  Nonetheless, it is clear that for the graphs of interest in this paper (chains and lattices) restricting to connected neighbourhoods is a substantial savings.\n\nI have understood the scores presented in Figures 2 and 3 as follows:\n\nFor each feature of each example, rank the features according to importance, using the plugin estimate for P(Y|X_S) where needed.\nFor each ""percent of features masked"" compute log(P(y_true | x_{S\\top features})) - log(P(y_true | x)) using the plugin estimate, and average these values over the dataset.\n\nBased on this understanding the results are quite good.  The approximate Shapely values do a much better job than their competitors of identifying highly relevant features based on this measure.  The qualitative results are also quite compelling, especially on images where C-Shapely tends to select contiguous regions which is intuitively correct behavior.\n\nComparing the different methods in Figure 4, there is quite some variability in the features selected by using different estimators of Shapley values.  I wonder is there some way to attack the problem of distinguishing when a feature is ranked highly when its (exact) Shapley value is high versus when it is ranked highly as an artifact of the estimator?\n']","[50, 60, 70]","[75, 80, 50]","[""Sentiment Score (50): The review begins with a neutral summary of the paper's content, followed by a generally positive assessment. The reviewer notes that the paper is 'well written' and addresses an 'important' problem. They also praise the 'nice' approximation guarantees. However, they suggest some improvements and point out potential weaknesses, balancing the positive aspects. This mix of praise and constructive criticism indicates a moderately positive sentiment.\n\nPoliteness Score (75): The language used throughout the review is professional and respectful. The reviewer offers suggestions and critiques in a constructive manner, using phrases like 'The authors might benefit from...' and 'It would have been nice to see...'. They also acknowledge the paper's strengths before offering criticisms. The tone is not overly formal or deferential, but maintains a polite and collegial approach typical of academic peer reviews."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper provides new and potentially useful methods, with promising results and a sound methodology. They also mention some improvements over other methods. However, it's not extremely positive as they suggest strengthening the paper with more thorough evaluation. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions rather than direct criticisms. For example, they say 'They might strengthen their paper...' and 'Is there a way to compare...?' instead of demanding changes. The tone is professional and courteous throughout."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They describe the approach as 'principled', the results as 'quite good' and 'quite compelling', and acknowledge the paper's contribution in providing efficient methods for a difficult problem. The politeness score is 50 (somewhat polite) because the reviewer uses respectful and professional language throughout, avoiding harsh criticism. They offer constructive feedback and suggestions, such as questioning the justification for C-Shapely values and proposing a potential area for further investigation. The tone is academic and objective, without overly effusive praise or unnecessary criticism.""]"
"[""This paper proposed Whitening and Coloring (WC) transform to replace batch normalization (BN) in generators for GAN. WC generalize BN by normalizing features with decorrelating (whitening) matrix, and then denormalizing (coloring) features by learnable weights. The main advantage of WC is that it exploits the full correlation matrix of features, while BN only considers the diagonal. WC is differentiable and is only 1.32x slower than BN. The authors also apply conditional WC, which learn the parameters of coloring conditioned on labels, to conditional image generation.  Experimental results show WC achieves better inception score and FI distance comparing to BN on CIFAR-10, CIFAR-100, STL-10 and Tiny Imagenet. Furthermore, the conditional image generation results by WC are better than all previous methods.\n\nI have some detailed comments below.\n\n+ The paper is well written, and I generally enjoyed reading the paper.\n+ The experimental results look sufficient, and I appreciate the ablation study sections. \n+ The score on supervised CIFAR-10 is better than previous methods. \n\n- The main text is longer than expectation. I would suggest shorten section 3.1 Cholesky decomposition, section 4 conditional color transformation and the text in section 5 experiments.\n- The proposed WC transform is general. It is a bit unclear why it is particularly effective for generator in GAN. Exploiting the full correlation matrix sounds reasonable, but it may also introduce unstability. It would help if the authors have an intuitive way to show that whitening is better than normalization.\n- It is unclear why conditional WC can be used for generation conditioned on class labels. In Dumoulin 2016, conditional instance normalization is used for generating images conditioned on styles. As image styles are described by Gram matrix (correlation) of features, changing first order and second order statistics of features is reasonable for image generation conditioned on styles. I cannot understand why conditional WC can be used for generation conditioned on class labels. I would like the authors to carefully explain the motivation, and also provide visual results like using the same random noise as input, but only changing the class conditions. \n- It is unclear to me why the proposed whitening based on Cholesky decomposition is better than ZCA-based in Huang 2018. Specifically, could the authors explain why WC is better than W_{aca}C in Table 3? \n- The authors claim progressive GAN used a larger generator to achieve a better performance than WC. The WC layer is generally larger than BN layer and has more learnable parameters. Could the authors compare  the number of parameter of generator in BN-ResNet, WC-ResNet, and progressive GAN?\n- In Table 3, std-C is better than WC-diag, which indicates coloring is more important. In Table 6, cWC-diag is better than c-std-C, which indicates whitening is more important. Why? \n- What is the batch size used for training? For conditional WC, do the samples in each minibatch have same label?\n- Having ImageNet results will be a big support for the paper.\n\n\n===========  comments after reading rebuttal ===========\n\nI appreciate the authors' feedback. I raised my score for Fig 7 showing the conditional images, and for experiments on ImageNet. \n\nI think WC is a reasonable extension to BN, and I generally like the extensive experiments. However, the paper is still borderline to me for the following concerns.\n\n- I strongly encourage the authors to shorten the paper to the recommended 8-page. \n\n- The motivation of WC for GAN is still unclear. WC is general extension of BN, and a simplified version has been shown to be effective for discrimination in Huang 2018. I understand the empirically good performance for GAN. But I am not convinced why WC is particularly effective for GAN, comparing to discrimination. The smoothness explanation of BN applies to both GAN and discrimination. I actually think it may be nontrivial to extend the smoothness argument from BN to WC.\n\n- The motivation of cWC is still unclear. I did not find the details of cBN for class-label conditions, and how they motivated it in (Gulrajani et al. (2017) and (Miyato et al. 2018). Even if it has been used before, I would encourage the authors to restate the motivation in the paper. Saying it has been used before is an unsatisfactory answer for an unintuitive setting.\n\n- Another less important comment is that it is still hard to say how much benefits we get from the more learnable parameters in WC than BN. It is probably not so important because it can be a good trade-off for state-of-the-art results. In table 3 for unconditioned generation, it looks like the benefits come a lot from the larger parameter space. For conditioned generation in table 6, I am not sure if whitening is conditioned or not, which makes it less reliable to me. If whitening is conditioned, then the samples in each minibatches may not be enough to get a stable whitening. If whitening is unconditioned, then there seems to be a mismatch between whitening and coloring. \n\n====== second round after rebuttal =============\nI raise the score again for the commitment of shortening the paper and the detailed response from the authors. That being said, I am not fully convinced about motivations for WC and cWC. \n\n- GAN training is more difficult and unstable, but that does not explain why WC is particularly effective for GAN training. \n\n- I have never seen papers saying cBN/cWC is better than other conditional generator conditioned on class labels. I think the capacity argument is interesting, but I am not sure if it applies to convolutional net (where the mean and variance of a channel is used), or how well it can explain the performance because neural nets are overparameterized in general. I would encourage authors to include these discussions in the paper. \n"", 'This paper tends to address the instability problem in GAN training by replacing batch normalization(BN) with whitening and coloring transform(WC) to provide a full-feature decorrelation. This paper consider both uncondition and condition cases.\nIn general, the idea of replacing BN with WC is interesting and well motivated. \n\nThe proposed method looks novel to me. Compared with ZCA whitening in Huang et al. 2018, the Cholesky decomposition is much faster and performs better. The experiments show the promising results and demonstrate the proposed method is easily to integrate with other advanced technic. The experimental results also illustrate the role of each components and well supports the motivation of proposed method.\n\nMy only concern is that the proposed WC algorithm seems to have capability of applying to many tasks including discriminative scenario. This paper seems to have potential to be a more general paper about the WC method. Why just consider GAN? What is the performance of WC compared with BN/ZCA whiten in other tasks. It would be better if the authors can elaborate the motivation of choosing GAN as the application. ', 'This paper proposes to generalize both BN and cBN using Whitening and Coloring based batch normalization. Whitening is an enhanced version of mean subtraction and normalization by standard deviation. Coloring is an enhanced version of per-dimension scaling and shifting.\nEvaluation experiments are conducted on different datasets and using different GAN networks and training protocols. Empirical results show improvements over BN and cBN.\n\nThe proposed method WC is interesting, but there are some unclear issues.\n\n1. Two motivations for this paper: BN improves the conditioning of the Jacobian, stability of GAN training is related to the conditioning of the Jocobian. These motivate the paper to develop enhanced versions of BN/cBN, as said in the introduction. More discussions why WC can further improve the conditioning over ordinary BN would be better.\n\n2. It is not clear why WC performs better than W_zca C (Table 3), though the improvement is moderate. The difference is that WC uses Cholesky decomposition and ZCA uses eigenvalue decomposition. Compared to W_zca C, WC seems to be an incremental contribution.\n\n3. It is not clear why the proposed method is much faster than ZCA-based whitening.\n\n===========  comments after reading response ===========\n\nThe authors make a good response, which clarifies the unclear issues from my first review. I remove the mention of the concurrent submission.\n\nSpecially, the new Appendix D with the new Fig. 4 clearly explains and shows the benefit of WC over W_zca.']","[50, 80, 50]","[80, 70, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses overall positive sentiment about the paper, praising its writing and experimental results, while also providing constructive criticism and raising several concerns. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as suggestions or questions rather than harsh judgments. The reviewer also appreciates the authors' feedback in the rebuttal sections, showing a collaborative attitude. The polite tone is maintained even when expressing remaining concerns after the rebuttal."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the idea as 'interesting and well motivated', the method as 'novel', and the results as 'promising'. The only criticism is framed as a suggestion for potential expansion, not a flaw. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'interesting', 'well motivated', and 'promising'. They frame their suggestion politely with 'It would be better if...' rather than demanding changes. The review maintains a professional and constructive tone throughout, without any harsh or rude language."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the proposed method as 'interesting' and acknowledges improvements over existing methods, but also raises several concerns and requests for clarification. The initial review is somewhat critical, but the reviewer's response after reading the authors' clarifications is more positive, indicating an overall balanced but slightly favorable view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as requests for clarification rather than direct attacks, and acknowledges the authors' good response to the initial review. The reviewer also uses phrases like 'would be better' instead of more demanding language, maintaining a courteous tone.""]"
"['After reading the authors\' response, I\'m revising my score upwards from 5 to 6.\n\nThe authors propose a defense against adversarial examples, that is inspired by ""non local means filtering"". The underlying assumption seems to be that, at feature level, adversarial examples manifest as IID noise in feature maps, which can be ""filtered away"" by using features from other images. While this assumption seems plausible,  no analysis has been done to verify it in a systematic way. Some examples of verifying this are:\n\n1. How does varying the number of nearest neighbors change the network behavior?\n2. At test time, a fixed number of images are used for denoising - how does the choice of these images change accuracy or adversarial robustness?\n3. Does just simple filtering of the feature map, say, by local averaging, perform equally well? \n4. When do things start to break down? I imagine randomly replacing feature map values (i.e. with very poor nearest neighbors) will cause robustness and accuracy to go down - was this tested?\n\nBased on the paper of Athalye et. al., really the only method worth comparing to for adversarial defense, is adversarial training. It is hard to judge absolute adversarial robustness performance without a baseline of adversarial training.', 'The paper presents a an interesting novel approach to train neural networks with so called peer regularization which aims to provide robustness to adversarial attacks. The idea is to add a graph neural network to a spatial CNN. A graph is defined over similar training samples which are found using a Monte Carlo approximation.\n\nThe regularization using graphs reminds me of recent work at ICML on semi-supervised learning (Kamnitsas et al. (2018) Semi-supervised learning via compact latent space clustering) which is using a graph to approximate cluster density which acts as a regularizer for training on labelled data.\n\nThe main problem I see with these approaches is that they rely on sufficiently large batch sizes which could be (currently) problematic for many real-world applications. Memory and computation limitations are mentioned, but not sufficently discussed. It would be good to add further details on practical limitations.\n\nExperiments are limited to benchmark data using MNIST, CIFAR-10, CIFAR-100. Comprehensive evaluation has been carried out with insightful experiments and good comparison to state-of-the-art. Both white- and black-box adversarial attacks are explored with promising results for the proposed approach.\n\nHowever, it is difficult to draw conclusions for real-world problems of larger scale. The authors state that proposed framework can be added to any baseline model, but miss to clearly mention the limitations. It is stated that future work will aim at scaling PeerNets to benchmarks like ImageNet, but it is unclear how this could be done. Is there any hope this could be applied to problems like 3D imaging data or videos?\n']","[20, 50]","[50, 75]","[""The sentiment score is 20 (slightly positive) because the reviewer starts by mentioning they've revised their score upwards, indicating a somewhat positive view. However, they also point out several areas where the authors' work could be improved or lacks analysis, which tempers the positivity. The politeness score is 50 (moderately polite) because the reviewer uses neutral, professional language throughout. They offer constructive criticism and suggestions for improvement without using harsh or negative language. The reviewer asks questions and makes recommendations in a respectful manner, maintaining a collegial tone throughout the review."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'interesting' and 'novel', with 'promising results' and 'comprehensive evaluation'. However, they also point out limitations and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively suggesting improvements. They use phrases like 'it would be good to add' and 'it is difficult to draw conclusions' rather than making blunt criticisms. The reviewer also asks thoughtful questions at the end, showing engagement with the work.""]"
"['This paper proposes a dynamical neural network for sparse coding where all the interactions terms are learned.  In previous approaches (Rozell et al.) some weights were tied to the others.  Here the network consists of feedforward, lateral, and feedback weights, all of which have their own learning rule.  The authors show that the learned weights converge to the desired solution for solving the sparse coding objective.  This seems like a nice piece of work, an original approach that solves a problem that was never really fully resolved in previous work, and it brings things one step closer to both neurobiological plausibility and hardware implementation.\n\nOther comments:\n\nWhat exactly is being shown in Figure 2 is still not clear to me.\n\n It would be nice to see some other evaluations, for example sparsity vs. MSE tradeoff (this is reflected in the objective function in part but it would be nice to see the tradeoff).  \n\nThere is recent work from Mitya Chklovskii\'s group on ""similarity matching"" that also addresses the problem of developing a fully local learning rule.  The authors should incorporate a discussion of this in their final paper.\n', 'The seminal work of Olshausen and Field on sparse coding is widely accepted as one of the main sources of inspiration for dictionary learning. This contribution makes the connection from dictionary learning back to a neuronal approach. Building on the Local Competitive Algorithm (LCA) of Rozell et al. and the theoretical analysis of Tang et al., this submission revisits the dictionary learning under two constraints that the gradient is learned locally and that the neural assemblies maintain consistent weight in the network. These constraints are relevant for a better understanding of the underlying principles in neuroscience and for applicative development on neuromorphic chipsets.\n\nThe proposed theorems extend the previous work of sparse coding with spiking neurons and address the update of dictionary using only information available from local neurons. The submission cares as well for the possible implementation on parallel architectures. The numerical experiments are conducted on three datasets and show the influence of weight initialization and the convergence on each dataset. An example of image denoising is provided in appendix. ', 'The authors study sparse coding models in which unit activations minimize a cost that combines: 1) the error between a linear generative model and the input data; an 2) the L1 norm of unit activations themselves. They seek models in which both the inference procedure -- generating unit activations in response to each input data example -- and the learning procedure -- updating network connections so that the inferences minimize the cost function -- are local. By ""local"" they mean that the update to each unit\'s activation, and the updates to the connection weights, rely only on information about the inputs and outputs from that unit / connection. In a biological neural network, these are the variables represented by pre- and post-synaptic action potentials and voltages, and in hardware implementations, operations on these variables can be performed without substantially coordinating between different parts of the chip, providing strong motivation for the locality constraint(s). \n\nThe authors achieve a local algorithm that approximately optimizes the sparse coding objective function by using feedback: they send the sparse coding units\' activities ""back"" to the input layer through feedback connections. In the case where the feedback connection matrix is the transpose of the sparse coding dictionary matrix (D), the elementwise errors in the linear generative model (e.g., the non-local part of the sparse coding learning rule obtained by gradient descent) are represented by the difference between the inputs and this feedback to the input layer: that difference can be computed locally at the input units and then sent back to the coding layer to implement the updates. The feedback connections B are updated in another local process that keeps them symmetric with the feedforward weights: B= D= F^T throughout the learning process. \n\nThe authors provide several theorems showing that this setup approximately solves the sparse coding problem (again, using local information), and show via simulation that their setup shows similar evolution of the loss function during training, as does SGD on the sparse coding cost function.\n\nI think that the paper presents a neat idea --  feedback connections are too often ignored in computational models of the nervous system, and correspondingly in machine learning. At the same time, I have some concerns about the novelty and the presentation. Those are described below:\n\n1. The paper is unnecessarily hard to read, at least in part due to a lack of notational consistency. As just one example, with B=D, why use two different symbols for this matrix? This just makes is so that your reader needs to keep track mentally of which variable is actually which other variable, and that quickly becomes confusing. I strongly recommend choosing the simplest and most consistent notation that you can throughout the paper.\n\n2. Other recent studies also showed that feedback connections can lead to local updates successfully training neural networks: three such papers are cited below. The first two papers do supervised learning, while the third does unsupervised learning. It would be helpful for the authors to explain the key points of novelty of their paper: application of these feedback connection ideas to sparse coding. Otherwise, readers may mistakenly get the impression that this work is the first to use feedback connections in training neural networks.\n\nGuerguiev, J., Lillicrap, T.P. and Richards, B.A., 2017. Towards deep learning with segregated dendrites. ELife, 6, p.e22901.\n\nSacramento, J., Costa, R.P., Bengio, Y. and Senn, W., 2018. Dendritic cortical microcircuits approximate the backpropagation algorithm. arXiv preprint arXiv:1810.11393.\n\nFederer, C. and Zylberberg, J., 2018. A self-organizing short-term dynamical memory network. Neural Networks.\n\n3. Given that the performance gains of the locality (vs something like SparseNet) are given such emphasis in the paper, those should be shown from the numerical experiments. This could be quantified by runtime, or some other measure.\n\n4. The discussion of prior work is a little misleading -- although I\'m sure this is unintentional. For example, at the top of p. 3, it is mentioned that the previous local sparse coding models do not have rigorous learning objectives. But then the appendix describes the learning objectives, and the approximations, made in the prior work. I think that the introduction should have a more transparent discussion of what was, and was not, in the prior papers, and how the current work advances the field.\n\n5. The paper -- and especially appendix C2 -- makes strong emphasis of the importance finding local implementations of true gradient descent, as opposed to the approximations made by prior authors. I\'m not sure that\'s such a big deal, given that Lillicrap et al. showed nicely in the paper cited below that any learning rule that is within 90 degrees of true gradient descent will still minimize the cost function: even if an algorithm doesn\'t move down the steepest path, it can still have updates that always move ""downhill"", and hence minimize the loss function. Consequently, I think that some justification is needed showing that the current model, being closer to true gradient descent, really outperforms the previous ones. \n\nLillicrap, T.P., Cownden, D., Tweed, D.B. and Akerman, C.J., 2016. Random synaptic feedback weights support error backpropagation for deep learning. Nature communications, 7, p.13276.']","[80, 80, -20]","[60, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'a nice piece of work' and 'an original approach' that solves a previously unresolved problem. They also mention it brings things 'one step closer to both neurobiological plausibility and hardware implementation', indicating a positive view of the paper's contributions. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions without harsh criticism. They use phrases like 'It would be nice to see' and 'The authors should incorporate' which are polite ways of suggesting improvements. The review maintains a professional tone while providing both praise and areas for improvement."", ""The sentiment score is 80 (positive) because the review begins by acknowledging the importance of the work being reviewed, describing it as a 'seminal work' and highlighting its relevance to neuroscience and neuromorphic chipsets. The reviewer also praises the proposed theorems for extending previous work and addressing important constraints. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, acknowledging the contributions of the authors without using overly effusive praise. The reviewer focuses on the merits of the work and provides a balanced overview of its contents without any critical or negative comments, maintaining a courteous and constructive tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents a 'neat idea', they express several concerns about novelty and presentation. The review begins positively but then lists multiple criticisms and suggestions for improvement, indicating an overall slightly negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms constructively. They use phrases like 'I think', 'I recommend', and 'It would be helpful', which maintain a polite tone while offering feedback. The reviewer also assumes good intentions, noting that any misleading aspects are 'unintentional'. However, the directness of some criticisms prevents a higher politeness score.""]"
"['Summary\n=======\nThis paper introduces a method for learning neural networks with quantized weights and activations. The main idea is to stochastically – rather than deterministically – quantize values, and to replace the resulting categorical distribution over quantized values with a continuous relaxation (the ""concrete distribution"" or ""Gumbel-Softax distribution""; Maddison et al., 2016; Jang et al., 2016). Good empirical performance is demonstrated for LeNet-5 applied to MNIST, VGG applied to CIFAR-10, and MobileNet and ResNet-18 applied to ImageNet.\n\nReview\n======\nRelevance:\nTraining non-differentiable neural networks is a challenging and important problem for several applications and a frequent topic at ICLR.\n\nNovelty:\nConceptually, the proposed approach seems like a straight-forward application/extension of existing methods, but I\'m unaware of any paper which uses the concrete distribution for the express purpose of improved efficiency as in this paper. There is a thorough discussion of related work, although I was missing Williams (1992), who used stochastic rounding before Gupta et al. (2015), and Soudry et al. (2014), who introduced a Bayesian approach to deal with discrete weights and activations.\n\nResults:\nThe empirical work is thorough, achieving state-of-the-art results in several classification benchmarks. It would be interesting to see how well these methods perform in other tasks (e.g., compression or even regression), even though the literature on quantization seems to focus on classification.\n\nClarity:\nThe paper is well written and clear.', ""Quality:\nThe work is well done. Experiments cover a range of problems and a range of quantization resolutions. Related work section in, particular, I thought was very nicely done. Empirical results are strong. \n\nIn section 2.2, it bothers me that the amount of bias introduced by using the local grid approximation is never really assessed. How much probability mass is left out by truncating the Gumbel-softmax, in practice?\n\nClarity:\nWell presented. I believe I'd be able to implement this, as a practitioner. \n\nOriginality:\nNice to see the concrete approximation having an impact in the quantization space. \n\nSignificance:\nQuantization has obvious practical interest. The regularization aspect is striking (quantization yielded slightly improved test error on CIFAR-10; is that w/in the error bars?). A recent work [https://arxiv.org/abs/1804.05862] links model compressibility to generalization; while this work is more focused on activations, there is no reason that it couldn't be used for weights as well.\n\nNits:\ntop of pg 6 'reduced execution speeds' -> times, or increased exec speeds\n'sparcity' misspelled"", 'The authors proposes a unified and general way of training neural network with reduced precision quantized synaptic weights and activations. The use case where such a quantization can be of use is the deployment of neural network models on resource constrained devices, such as mobile phones and embedded devices.\n\nThe paper is very well organized and systematically illustrates and motivates the ingredients that allows the authors to achieve their goal: a quantization grid with learnable position and range, stochastic quantization due to noise, and relaxing the hard categorical quantization assignment to a concrete distribution.\nThe authors then validate their method on several architectures (LeNet-5, VGG7, Resnet and mobilnet) on several datasets (MNIST, CIFAR10 and ImageNet) demonstrating competitive results both in terms of precision reduction and accuracy. \n\nMinor comments:\n- It would be interesting to know whether training with the proposed relaxed quantization method is slower than with full-precision activations and weights. It would have been informative to show learning curves comparing learning speed in the two cases.\n- It seems that this work could be generalized in a relatively straight-forward way to a case in which the quantization grid is not uniform, but instead all quantization interval are being optimized independently. It would have been interesting if the authors discussed this scenario, or at least motivated why they only considered quantization on a regular grid.\n']","[70, 80, 90]","[80, 70, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They note its relevance, novelty, and thorough empirical work achieving state-of-the-art results. The reviewer also praises the paper's clarity and writing. However, it's not a perfect score as they mention some minor points for improvement, such as missing references and suggesting additional areas for testing. The politeness score is 80 (very polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths and offer constructive feedback without harsh criticism. The tone is consistently courteous, using phrases like 'well written and clear' and 'thorough discussion'. Even when pointing out potential improvements, the language remains polite and suggestive rather than demanding."", ""The sentiment score is 80 (positive) because the reviewer starts with praise, stating 'The work is well done' and mentioning strong empirical results and a well-done related work section. They also note the significance and practical interest of the work. The few criticisms are minor and presented constructively. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering praise where due and framing criticisms as suggestions or questions rather than harsh judgments. They use phrases like 'I thought was very nicely done' and 'Nice to see', which contribute to a polite tone. The reviewer also offers helpful suggestions and points out minor errors ('nits') in a non-confrontational manner."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, describing it as 'very well organized' and praising its systematic approach. The reviewer also highlights the paper's competitive results and thorough validation across multiple architectures and datasets. The politeness score is 80 (quite polite) due to the respectful and constructive tone throughout. The reviewer offers praise where due and frames their minor comments as suggestions rather than criticisms. The language used is professional and courteous, avoiding any harsh or negative phrasing. The reviewer's comments are presented as opportunities for improvement rather than flaws, which contributes to the polite tone.""]"
"['Summary\n\nThis paper derives a new policy gradient method for when continuous actions are transformed by a\nnormalization step, a process called angular policy gradients (APG). A generalization based on\na certain class of transformations is presented. The method is an instance of a \nRao-Blackwellization process and hence reduces variance.\n\n\nDetailed comments\n\nI enjoyed the concept and, while relatively niche, appreciated the work done here and do believe it has clear applications. I am not convinced that the measure theoretic perspective is always\nnecessary to convey the insights, although I appreciate the desire for technical correctness. Still,\nappealing to measure theory does reduces readership, and I encourage the authors to keep this in\nmind as they revise the text.\n\nGenerally speaking it seems like a lot of technicalities for a relatively simple result:\nmarginalizing a distribution onto a lower-dimensional surface.\n\nThe paper positions itself generally as dealing with arbitrary transformations T, but really is \nabout angular transformations (e.g. Definition 3.1). The generalization is relatively \nstraightforward and was not too surprising given the APG theory. The paper would gain in clarity\nif its scope was narrowed. \n\nIt\'s hard for me to judge of the experimental results of section 5.3, given that there are no other \nbenchmarks or provided reference paper. As a whole, I see APG as providing a minor benefit over PG.\n\nDef 4.4: ""a notion of Fisher information"" -- maybe ""variant"" is better than ""notion"", which implies there are different kinds of Fisher information \nDef 3.1 mu is overloaded: parameter or measure?\n4.4, law of total variation -- define \n\n\nOverall\n\nThis was a fun, albeit incremental paper. The method is unlikely to set new SOTA, but I appreciated\nthe appeal to measure theory to formalize some of the concepts.\n\n\nQuestions\n\nWhat does E_{pi|s} refer to in Eqn 4.1?\nCan you clarify what it means for the map T to be a sufficient statistic for theta? (Theorem 4.6)\nExperiment 5.1: Why would we expect APG with a 2d Gaussian to perform better than a 1d Gaussian\non the angle?\n\n\nSuggestions\n\nParagraph 2 of section 3 seems like the key to the whole paper -- I would make it more prominent.\nI would include a short \'measure theory\' appendix or equivalent reference for the lay reader.\n\nI wonder if the paper\'s main aim is not actually to bring measure theory to the study of policy\ngradients, which would be a laudable goal in and of itself. ICLR may not in this case be the right\nvenue (nor are the current results substantial enough to justify this) but I do encourage authors to\nconsider this avenue, e.g. in a journal paper.\n\n= Revised after rebuttal =\n\nI thank the authors for their response. I think this work deserves to be published, in particular because it presents a reasonably straightforward result that others will benefit from. However, I do encourage further work to\n1) Provide stronger empirical results (these are not too convincing).\n2) Beware of overstating: the argument that the framework is broadly applicable is not that useful, given that it\'s a lot of work to derive closed-form marginalized estimators.\n', 'This paper introduces policy gradient methods for RL where the policy must choose a direction (a.k.a., the navigation problem).\n\nMapping techniques from ""non-directional"" problems (where the action space is not a direction) and then projeting on the sphere is sub-optimal (the variance is too big). The authors propose to sample directly on the sphere, using the fact that the likelyhood of an angular Gaussian r.v. has *almost* a closed form and its gradient can almost be computed, up to some normalization term (the integral which is constant in the standard Gaussian case).\n\n\nThis can be seen as a variance reduction techniques.\n\nThe proofs are not too intricate, for someone used to variance reduction (yet computations must be made quite carefully).\n\n\nThe result is coherent, interesting from a theoretical point of view and the experiment are somehow convincing. The main drawback would be the rather incrementality of that paper (basically sample before projecting is a bit better than projecting after sampling) and that this directional setting is quite limited...\n', 'In this paper the authors proposed a new policy gradient method, which is known as the angular policy gradient (APG), that aims to provide provably lower variance in the gradient estimate. Here they presented a stochastic policy gradient method for directional control. Under the set of parameterized Gaussian policies, they presented a unified analysis of the variance of APG and showed how it theoretically outperform (in terms of having lower variance) than other state-of-the art methods. They further evaluated the APG algorithms on a grid-world navigation domain as well as the King of Glory task, and showed that the APG estimator significantly out-performs the standard policy gradient.\n\nIn general I think this paper addressed an important issue in policy gradient in terms of deriving a lower variance gradient estimate. In particular the authors showed that under the parameterized marginal distribution, such as the angular Gaussian distribution, the corresponding APG estimate has a lower variance estimate than that of CAPG. Furthermore, I also appreciate that they evaluated these results in realistic experiments such as the RTS game domains. \n\nMy only question is on the possibility of deriving realistic APG algorithms beyond the class of angular Gaussian policy. In terms of the layout of the paper, I would also recommend including the exact algorithm pseudo-code used in the main paper.\n']","[50, 60, 80]","[75, 50, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses enjoyment of the concept and appreciation for the work, calling it a 'fun' paper. However, they also note that it's incremental and unlikely to set new state-of-the-art results, which tempers the positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I enjoyed', 'I appreciated', and 'I encourage the authors', which are polite ways of giving feedback. The reviewer also thanks the authors for their response in the revised section, showing courtesy. While critical at times, the criticism is presented in a professional and considerate manner."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's coherence, theoretical interest, and convincing experiments. They describe the work as 'interesting' and 'coherent'. However, they also mention drawbacks like incrementality and limited scope, which prevents a higher score. The politeness score is 50 (slightly polite) as the reviewer maintains a professional tone throughout, avoiding harsh criticism. They use neutral language to describe both strengths and weaknesses, such as 'The main drawback would be...' instead of more critical phrasing. The review doesn't contain overtly polite language, but it's respectful and constructive, hence the slightly positive score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, praising its approach to an important issue and its evaluation in realistic experiments. The reviewer uses phrases like 'I think this paper addressed an important issue' and 'I also appreciate that they evaluated these results in realistic experiments,' indicating a favorable opinion. The only slight criticism is phrased as a question about future work, not detracting significantly from the overall positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. The reviewer frames their only criticism as a question rather than a direct critique, which is a polite approach. The recommendation for including algorithm pseudo-code is presented as a suggestion, not a demand. The overall tone is professional and courteous, without being overly formal or effusive.""]"
"['This paper presents a new code-to-sequence model called code2seq that leverages the syntactic structure of programming languages to encode source code snippets, which is then decoded to natural language using a sequence decoder. The key idea of the approach is to represent a program using a set of randomly sample k paths in its abstract syntax tree. For each path, the path is encoded using a recurrent network and concatenated with the embeddings of the two leaf terminal values of the path. The path encodings are then averaged to obtain the program embedding, which is then used to initialize a sequence decoder that also attends over the path embeddings. The code2vec model is evaluated over two tasks: 1) Code summarization: predicting a method’s name from its body, and 2) Code captioning: generating a natural language sentence from method’s body depicting its functionality. The code2seq model significantly outperforms the other baseline methods, and the ablation study shows the importance of various design choices.\n\nThis paper presents an elegant way to represent programs using a set of paths in the AST, which are then weighted using an attention mechanism to attend over relevant path components. The code2seq model is extensively evaluated over two domains of code summarization and code captioning, and results show significant improvements.\n\nThe novelty of the code2seq model is somewhat limited compared to the model presented in code2vec (Alon et al. 2018a) paper. In code2vec, a program is encoded as a set of paths, where each path comes from a fixed vocabulary. The code2seq model instead uses an LSTM to encode individual paths, which allows it to generalize to new paths. This is a more natural choice for embedding paths, but it doesn’t appear to be a big conceptual advance in the model architecture. The use of subtoken embeddings for encoding/decoding identifier names is different in code2seq, but it has been proposed earlier in other code embedding models.\n\nFor the code summarization evaluation, would it be possible to evaluate the code2seq model on the dataset used by the code2vec paper? On that dataset, the code2vec approach gets a precision score of 63.1, recall of 54.4, and F1 score of 58.4, [Table 3 on page 18] which are comparable to overall scores of the code2seq model.\n\nOne of the key findings of the paper is that syntactic structure of programs is important to encode. Similar observations have been made in other program embedding papers that use for example Tree-RNN [1] or graph neural networks (GNN) [Allamanis et al. 2018]. It would be quite valuable to compare the current results with the Tree-RNN or GNN models (without performing additional dataflow and control-flow post processing) to see how well the paths-based embeddings work in comparison to these models.\n\nThe value of k=200 seems a bit large for the examples presented in the paper. What happens when smaller values of k are used (e.g. k=10, 20?) What are the average number of paths in the java programs in the dataset?\n\n1. Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, Mehran Sahami, Leonidas Guibas. Learning Program Embeddings to Propagate Feedback on Student Code\nICML 2015\n', 'This paper introduces an AST-based encoding for programming code and\nshows the effectivness of the encoding in two different task of code\nsummarization:\n\n1. Extreme code summarization - predicting (generating) function name from function body (Java)\n2. Code captioning - generating a natural language sentence for a (short) snippet of code (C#)\n\nPros:\n- Simple idea of encoding syntactic structure of the program through random paths in ASTs\n- Thorough evaluation of the technique on multiple datasets and using multiple baselines\n- Better results than previously published baselines\n- Two new datasets (based on Java code present in github) that will be made available\n- The encoding is used in two different tasks which also involve two different languages\n\nCons:\n- Some of the details of the implementation/design are not clear (see some clarifying questions below)\n- More stats on the collected datasets would have been nice\n- Personally, I\'m not convinced ""extreme code summarization""\nis a great task for code understanding (see more comments below)\n\nOverall, I enjoyed reading this paper and I think the authors did a\ngreat job explaining the technique, comparing it with other baselines,\nbuilding new datasets, etc.\n\nI have several clarifying questions/points (in no particular order):\n\n* Can you provide some intuition on why random paths in the AST encode\n  the ""meaning"" of the code? And perhaps qualitatively compare it with\n  recording some other properties from the tree that preserve its\n  structure more?\n\n* When you perform the encoding of the function body, one sample in a\n  training step contains all the k (k = 200) paths and all the 2*k\n  terminals (end of Section 2)? Or one path at a time (Section 3.2)?\n  I\'m guessing is the latter, but not entirely sure. Figure 3 could\n  improve to make it clear.\n\n* Can you explain how you came up with k = 200? I think providing some\n  stats on the dataset could be helpful to understand this number.\n\n* The results for the baselines - do you train across all projects?\n  (As you point out, ConvAttention trained separately, curious whether\n  it makes a difference for the 2 datasets med and large not present\n  in the original paper).\n\n* I\'m not sure I understand parts of the ablation study. In particular\n  for point 1., it seems that instead of the AST, only the terminal\n  nodes are used. Do you still use 200 random pairs of terminal? Is\n  this equivalent to a (randomly shuffled) subset of the tokens in the\n  program? Also could you explain why you do the ablation study on the\n  validation set of the medium dataset? In fact, the caption of Table\n  3 says it\'s done on the dev set. This part was a bit confusing.\n\n* I would have liked to see more details on the datasets introduced,\n  in particular wrt metrics that are relevant for training the model\n  you describe (e.g., stats on the ASTs, stats on the number of random\n  paths in ASTs, code length in tokens, etc.)\n\n* I\'m not convinced that the task of ""extreme code summarization"" is a\n  meaningful task. My main problem with it is that the performance of\n  a human on this task would not be that great. On one hand humans\n  (I\'m referring to ""programming humans"" :) ) have no problem in\n  coming up with a name for a function body; however, I\'m not\n  convinced they could predict the ""gold"" standard. Or, another way of\n  thinking about this, if you have 3 humans who provided names for the\n  same function, my guess it that there will be a wide degree of\n  (dis)agreement. Some of the examples provided in the supplementary\n  material can serve as confirmation bias to my thought :): Fig 7. I\n  claim ""choose random prime"" and ""generate prime number"" are\n  semantically close, however, the precision and recall for this\n  example are both low. All this being said, I understand that it\'s a\n  task for which data can be generated fairly quickly to feed the\n  (beast) NN and that helps pushing the needle in understanding code\n  semantics.\n\n* It would be nice to see ""exact match"" as one of the metrics (it is\n  probably low, judging by F1 scores, but good to be reported).\n\n* Most likely the following paper could be cited in the related work:\nNeural Code Comprehension: A Learnable Representation of Code Semantics\nhttps://arxiv.org/abs/1806.07336\nhttps://nips.cc/Conferences/2018/Schedule?showEvent=11359\n\nPage 5 first phrase at the top, perhaps zi is a typo and it is\nsupposed to be z1?\n\n----\n\nUpdate: after all the discussion, I\'m lowering my score a bit while still hoping the paper will get published. I\'m satisfied with the results and the improvement of the paper. I still find it a bit surprising that the pairs of literals/leaves in the tree are a good approximation for the program itself (as shown in one of the ablation study).\n', 'The authors present a method for generating sequences from code. To achieve this, they parse the code and produce a syntax tree. Then, they enumerate paths in the tree along leaf nodes. Each path is encoded via an bidirectional LSTM and a (sub)token-level LSTM decoder with attention over the paths is used to produce the output sequence.  The authors compare their model with other models and show that it outperforms them on two code-to-sequence tasks. An ablation study shows how different components affect the model\'s performance.\n\nOverall, the task seems very interesting and the results positive. My main concern is wrt the novelty of this work: the novelty of the proposed model seems limited compared to code2vec (Alon 2018b). To my understanding the core idea of both code2vec and code2seq is similar in many respects. The core difference is that paths, instead of treated as single units (code2vec), they are treated as sequences whose representation is computed by an LSTM.\n\nTo understand the work better, additional evaluation seem be necessary:\n\nQ1: Could the authors compare code2seq with an ablation of a 2-layer BiLSTM where the decoder predicts the output as a single token (similar to the ""no decoder"" ablation of code2vec)?\n\nComparing this result to the ""no decoder"" ablation of code2seq will show the extent to which code2seq\'s performance is due to its code encoding or if code2vec with an LSTM decoder output would have sufficed.\n\nQ2: Using the BiLSTM and the Transformer as baselines seems reasonable but there are other existing models such as Tree LSTMs, Graph Convolutional Neural Networks [a] and TBCNNs [b] that could also be strong baselines which take tree structure into account. Have the authors experimented with any of those?\n\nQ3: I find the results in Table 1 very confusing when comparing them with those reported in Alon et al(2018b): code2vec achieves the best performance in Alon et al (2018b) but it seems to be performing badly in this work. The empirical comparisons to the same baseline methods used in Alon et al. (2018b) yield very different results. Why is that so? It would be worth performing an additional evaluation on the datasets of Alon et al (2018b) using the code2seq model. This would clarify if the results observed here generalize to other datasets.\n\nQ4: The strategy of enumerating paths in the tree seems to be problematic for large files of code. It is unclear how the authors (a) do an unbiased sample of the paths. Do they need to first enumerate all of them and pick at uniform? (b) since the authors pick $k$ paths for each sample, this may imply that the larger the tree, the worse the performance of code2seq. It would be useful to understand if code2seq suffers from this problem more/less than other baselines.\n\n[a] Kipf, T.N. and Welling, M., 2016. Semi-supervised classification with graph convolutional networks.\n[b] Mou, L., Men, R., Li, G., Xu, Y., Zhang, L., Yan, R. and Jin, Z., 2015. Natural language inference by tree-based convolution and heuristic matching.']","[50, 60, 20]","[75, 80, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer praises the paper as 'elegant' and notes significant improvements over baselines, but also points out limitations in novelty. The politeness score is 75 (quite polite) due to the use of respectful language throughout, constructive feedback, and suggestions phrased as questions rather than demands. The reviewer acknowledges the paper's strengths before offering critiques, and uses phrases like 'would it be possible' and 'it would be quite valuable' when making suggestions, indicating a polite and collegial tone."", ""The sentiment score is 60 (positive) because the reviewer expresses overall enjoyment of the paper, praising the authors' work in explaining the technique, comparing it with baselines, and building new datasets. They mention several pros and state that they 'enjoyed reading this paper'. However, they also list some cons and have several clarifying questions, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts positively, and frames their criticisms and questions constructively. Phrases like 'I think the authors did a great job' and 'I enjoyed reading this paper' contribute to the polite tone. Even when expressing doubts or asking for clarifications, the reviewer maintains a professional and courteous demeanor."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting task and positive results, but expresses concerns about novelty and requests additional evaluations. This indicates a mix of positive and critical feedback. The politeness score is high (80) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the work's merits. The reviewer consistently uses polite phrasing like 'Could the authors...', 'It would be useful...', and 'Have the authors experimented...', which maintains a constructive and courteous tone even while raising concerns and requesting clarifications.""]"
"['The paper introduces an iterative method to generate deformed images for adversarial attack. The core idea is to perturb the correctly classified image by iteratively applying small deformations, which are estimated based on a first-order approximation step, until the image is misclassified. Experimental results on several benchmark datasets (MNIST, ImageNet) and commonly used deep nets (CNN, ResNet, Inception) are reported to show the power of adversarial deformations. \n\nThe idea of gradually adding deformations based on gradient information is somewhat interesting, and novel as far as the reviewer knows about. The method is clearly presented and the results are mostly easy to access.  However, the intuition behind the proposal does not make strong sense to the reviewer: since the main focus of this work is on model attack, why not directly (iteratively or not) adding random image deformations to fool the system? Particularly, the first-order approximation strategy (as shown in Eq.4 and Eq.5) is quite confusing. On one side (see Eq.4), the deformation \\tau should be small enough in scale to make an accurate approximation. On the other side (see Eq. 5), \\tau is required to be sufficiently large in order to generate misclassification. Such seemingly conflicting rules for estimating the deformation makes the proposed method less rigorous in math. \nAs another downside, the related adversarial training procedure is not fully addressed. The authors briefly discussed this point in the experiment section and provided a few numerical results in Table 2. These results, as acknowledged by the authors, do not well support the effectiveness of deformation adversarial attack and defense. In the meanwhile, the mentioned adversarial training framework follows straightforwardly from PGD (Madry et al. 2018), and thus the novelty of this contribution is also weak. More importantly, it is not clear at all, both in theory and algorithm, whether the advocated gradual deformation attack and defense can be unified inside a joint min-max/max-min learning formulation, as what PGD is rooted from.\n\nPros: \n\n- The way of constructing deformation adversarial is interesting and novel\n- The paper is mostly clearly organized and presented.\n\nCons:\n\n- The motivation of approach is questionable. \n- The related adversarial training problem remains largely unaddressed.\n- Numerical study shows some promise in adversarial attack, but is not supportive to the related defense capability. ', 'In this paper, the authors proposed a new attack using deformation. The results are quite realistic to the naked eyes (at least for the example shown).  The idea is quite simple, generate small displacement and resample (interpolate) image until the label flips.\n\n- I think this is a good contribution, It is a kind of attack we should consider.\n- One thing which is good to consider is the type of interpolation. I believe the success rate would be different for linear versus say B-spline interpolation. Also, the width of the smoothing applied to the deformation field has an impact. The algorithm is straightforward, there is no reason to experiment with those.\n\n- It is useful to report pixel displacement in Table 1. The reported values are not intuitive, the **average** displacement for Inception-v3 is 0.59.  Here is my back of envelope conversion of 0.59 which is probably off:\n\n299 (# pixels of the smaller axis 299 for the Inception) x 1/2 (image are centered) x 0.59 =  88 pixels\n\nThis is huge! I think I am calculating something incorrectly because in Fig3,4 those displacements are not big. \n\n- The results of Table 2 is interesting. Why a networked trained with PGD is more robust to ADef attack that a network trained adversarially with Adef?\n\n\n\n\nMinor:\n- The paper is a bit nationally convoluted for no good reason, the general idea is straightforward. \n', 'The paper proposes a new way to construct adversarial examples: do not change the intensity of the input image directly, but deform the image plane (i.e. compose the image with Id + tau where tau is a small amplitude vector field).\n\nThe paper originates from a document provably written in late 2017, which is before the deposit on arXiv of another article (by different authors, early 2018) which was later accepted to ICLR 2018 [Xiao and al.]. This remark is important in that it changes my rating of the paper (being more indulgent with papers proposing new ideas, as otherwise the novelty is rather low compared to [Xiao and al.]).\n\nPros:\n- the paper is well written, very easy to read, well explained (and better formalized than [Xiao and al.]);\n- the idea of deforming images is new (if we forget about [Xiao and al.]) and simple;\n- experiments show what such a technique can achieve on MNIST and ImageNet. Interestingly, one can see on MNIST the parts of the numbers that the adversarial attack is trying to delete/create.\n\nCons:\n- the paper is a bit weak, in that it is not very dense, and in that there is not much more content than the initial idea;\n- for instance, more discussions about the results obtained could have been appreciated (such as my remark above about MNIST);\n- for instance, a study of the impact of the regularization would have been interesting (how does the sigma of the Gaussian smoothing affect the type of adversarial attacks obtained and their performance -- is it possible to fool the network with [very] smooth deformations?);\n- for instance, what about generating adversarial examples for which the network would be fully (wrongly) confident? (instead of just borderline unsure); etc.\n- The interpolation scheme (how is defined the intensity I(x,y) for a non-integer location (x,y) within the image I) is rather important (linear interpolation, etc.) and should be at least mentioned in the main paper, and at best studied (it might impact the gradient descent path and the results);\n- question: does the algorithm converge? could there be a proof of this? This is not obvious, as the objective potentially changes with time (selection of the current m best indices k of |F_k - F_l|). Also, the final overshoot factor (1+eta) is not very elegant, and not guaranteed to perform well if tau* starts being not small compared to the second derivative (i.e. g\'\'.tau^2 not small) while I guess that for image intensities, spatial derivatives can be very high if no intensity smoothing scheme is used.\n- note: the approximation tau* = sum_i tau_i (section 2.3) does not stand in the case of non-small deformations.\n- still in section 2.3, I do not understand the statement ""given that \\nabla f is moderate"": where does this property come from? or is ""given"" meant to be understood as ""provided..."" (i.e. under the assumption that...)?\n- computational times could have been given (though I guess they are reasonable).\n\nOther remarks:\n- suggestion: I find the ""slight abuse of notation"" (of confusing the derivative with the gradient) a bit annoying and suggest to use a different symbol, such as \\nabla g. This could be useful in particular in the following perspective:\n- Mathematical side note: the ""gradient"" of a functional is not a uniquely-defined object in that it depends on the metric chosen in the tangent space. More clearly: the space of small deformations tau comes with an inner product (here L2, but one could choose another one), and the gradient \\nabla g obtained depends on this inner product choice M, even though the derivative Dg is the same (they are related by Dg(tau) = < \\nabla_M g | tau >_M for any tau). The choice of the metric can then be seen as a prior over desired gradient descent paths. In the paper, the deformation fields get smoothed by a Gaussian filter at some point (eq. 7), in order to be smoother: this can be interpreted as a prior (gradient descent paths should be made of smooth deformations) and as an associated inner product change (there do exist a metric M such that the gradient for that metric is \\nabla_M g = S \\nabla_L2 g). It is possible to favor other kind of deformations (not just smooth ones, but for instance rigid ones, etc. [and by the way this could make the link with ""Manitest: Are classifiers really invariant?"" by Fawzi and Frossard, BMVC 2015, who observe that a rigid motion can affect the classifier output]). If interested, you can check ""Generalized Gradients: Priors on Minimization Flows"" by Charpiat et al. for general inner products on deformations (in particular favoring rigid motion), and ""Sobolev active contours"" by Sundaramoorthi et al. for inner products more dedicated to smoothing (such as with the H1 norm).\n- Note: about the remark in section 3.2: deformation-induced transformations are a subset of all possible transformations of the image (which are all representable with intensity changes), so it is expected that a training against attacks on the intensity performs better than a training against attacks on spatial deformations.\n\n']","[-30, 60, 20]","[50, 70, 60]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('somewhat interesting', 'novel', 'clearly presented'), they express significant concerns about the method's motivation, mathematical rigor, and effectiveness in adversarial defense. The cons outweigh the pros in the review. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms as professional observations rather than personal attacks. They use phrases like 'as far as the reviewer knows' and 'it is not clear' which maintain a polite tone while expressing concerns."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is a 'good contribution' and the idea is 'quite simple' but effective. They also mention that the results are 'quite realistic' and it's an attack 'we should consider'. The tone is generally positive, with some constructive feedback. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering suggestions and observations without harsh criticism. They use phrases like 'It is useful to report' and 'One thing which is good to consider', which are polite ways of offering feedback. The reviewer also asks a question at the end, showing engagement with the work. The minor criticism about the paper being 'nationally convoluted' is presented gently as a minor point."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several pros of the paper, including its readability, novelty of idea, and interesting experimental results. However, the reviewer also lists multiple cons and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides suggestions for improvement rather than harsh criticisms. The reviewer also acknowledges the paper's strengths and the authors' priority in proposing the idea. The language is professional and objective, avoiding any personal attacks or overly negative phrasing.""]"
"['\nThe authors provide a clean and easily understood sufficient\ncondition for spurious local minima to exist in networks with\na hidden layer using ReLUs or leaky ReLUs.  This condition,\nthat there is not linear transformation with zero loss,\nis satisfied for almost all inputs with more examples than\ninput variables.\n\nThe construction is elegant.  The mathematical writing in the paper,\nespecially describing the proof of Theorem 1, is very nice -- they\nexpose the main ideas effectively.\n\nI do not know of another paper using a similar proof, but I have not\nstudied the proofs of the most closely related papers prior to doing\nthis review, so I have limited ability to vouch for this paper\'s\ntechnical novelty.\n\nThe authors also show that networks using many other popular\nactivation functions have spurious local minima for a very\nsimple dataset.  All of these analysis are unified using a\nsimple, if technical, set of conditions on activation function.\n\nFinally, the authors prove a somewhat technical theorem about\noptima in deep linear networks, which generalizes some\nearlier treatments of this topic, providing an checkable\ncondition for global minimality.\n\nThere is extensive discussion of related work.  I am not aware of\nrelated work not covered by the authors.\n\nIn some cases, when the authors discuss previous work, they write as\nif restriction to the realizable case is an assumption, when it seems\nto me to be more of a constraint.  In other words, it seems harder to\nprove the existence of spurious minima in the realizable case.\nThey seem to acknowledge this after their statement of their Theorem 2,\nwhich also uses a realizable dataset.\n\nAlso, a few papers, including the Venturi, et al paper cited by\nthe authors, have analyzed whether spurious local minima exist\nin subsets of the parameter space, including those likely to\nbe reached during training with different sorts of initializations.\nIn light of this work, the authors might want to tone down claims\nabout how their work shows that results about linear networks do\nnot generalize to the non-linear case.  In particular, to make\ntheir construction work in the case of wide networks, they\nneed an overwhelming majority of the hidden units to be ""dead"",\nwhich seems as it is unlikely to arise from training with\ncommonly used initializations.\n\nOverall, I think that this paper makes an interesting and\nnon-obvious contribution on a hot topic.', 'Paper represents theoretical analysis of the loss surface of neural networks. The authors supplied interesting results about local minima properties of neural networks. The paper is written quite well and easy to follow. Furthermore, authors made a comprehensive literature survey and connected their paper to already existing literature. The proofs seem correct (please note that paper is quite long and it requires more time then conference review period, hence, I stated “seem correct”). \nAlthough, paper provides novel theorems, I have several concerns, and these are:\n•\tIsn’t it clear that (generally speaking) a non-convex problem will have many local minima? Previous paper in neural network community is (in my opinion) not theorems. I believe one should read those statements such that in practice (please note here practice means that architectures, e.g. resnet50, inceptionv3, used in day to day life) researchers don’t not observe those “really bad” local minima.\n•\tIn ML literature, we have convex machines which are guaranteed to converge to global optimum. Given image dataset, or text datasets supervised deep learning in in general much better than convex methods e.g. SVMs. The paper clearly shows that there exist, in some cases, exponentially many local minima however  current training methods are able to find better solutions than convex methods (I am completely aware that functions classes are different however success metric, accuracy, is the same). Hence, how relevant are the results without taking in to account architectural choices or optimization methods for deep learning? May be structural risk minimisation is a better approach than empirical risk minimization for quantifying the performance of deep neural networks,\nIn conclusion, paper is interesting however I believe it need to be improved. \n', ""The authors present some theoretical results on the loss surface of neural networks. Their main results are:\n\n(1) They consider a 1 layer hidden neural network where the single nonlinearity is ReLU / ReLU-like. Here they prove that as long as a linear model cannot fit the data, then there exits a local minimum strictly inferior to the global one (They can then scale the parameters to get infinitely many local optima).\n\nThe key idea is to construct a local minima whose risk value is the same as the local least squares solution. Then to construct a set of parameters that has smaller risk value than this local optima. The proof technique is interesting.\n\n(2) They construct a particular dataset for which a one hidden layer neural net with other nonlinear activations (sigmoid, tanh, etc.) also has local optima.\n\nI think this theorem is a bit less interesting since the dataset given has only two data points. I think it is less interesting to prove suboptimality of neural nets in small sample size settings. \n\n(3) Global optimailty of linear networks. The authors show that deep linear networks (i.e. y = W1 W2 W3...W5 x) have only global minima or saddle points.\n\nI'm not familiar enough with the field to know the significant of this result. The deep linear network  just seems like an artificial construction (i.e. in practice one would simply condense W1...W5 to one W) to study nonconvexity / local optima, no one would use it in practice.""]","[70, 20, 20]","[80, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its 'clean and easily understood' approach, 'elegant' construction, and 'very nice' mathematical writing. They also mention that the paper makes an 'interesting and non-obvious contribution on a hot topic'. However, it's not a perfect score as the reviewer does raise some concerns and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively, and framing criticisms constructively. Phrases like 'The authors might want to tone down claims' show a polite way of suggesting improvements. The reviewer also admits their own limitations ('I have limited ability to vouch for this paper's technical novelty'), which adds to the overall polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting results, comprehensive literature survey, and well-written nature. However, they also express significant concerns, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms, and uses phrases like 'please note' and 'I believe' to soften their critiques. The reviewer also concludes with a constructive suggestion for improvement rather than outright rejection, maintaining a polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting aspects of the research, particularly the proof technique in the first result. However, they express less enthusiasm for the second and third results, which tempers the overall positivity. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, offering constructive criticism without using harsh language. They use phrases like 'I think' to soften their critiques and acknowledge their own potential lack of familiarity with certain aspects. The review is balanced, highlighting both strengths and limitations of the work without being overly critical or dismissive.""]"
"['The method proposes to use physiological signals to improve performance of reinforcement learning algorithms. By measuring heart pulse amplitude the authors build an intrinsic reward function that is less sparse that the extrinsic one. It helps to be risk averse and allows getting better performances than the vanilla RL algorithm on a car-driving task. \n\nI found the paper well written and the idea is quite nice. I like the idea that risk aversion is processed as a data-driven problem and not as an optimisation problem or using heuristics. I think this general idea could be pushed further in other cases (like encourage fun, surprise, happiness etc. ). \n\nThere are some issues with this paper yet. First, modifying the reward function also modifies the optimal policy. In the specific case of car driving, it may not be bad to modify the policy so that it makes passenger less stressed but in general, it is not good. This is why most of works based on intrinsic motivation also schedule the lambda parameter to decrease with time. This is not something explored in this paper. Also, this work is well suited to the car-driving scenario because stress is closely related to risk and accident. But it may not work with other applications. I would thus suggest that the title of the paper reflects the specific case of risk aversion. ', 'Starting from the hypothesis that humans have evolved basic autonomic visceral responses that influence decision making in a meaningful way and that these are at work in driving a car, the authors propose to use such signals within the RL framework. This is accomplished by augmenting the RL reward function with a model learned directly from human nervous system responses. This leads to a \nconvex combination of extrinsic rewards and visceral responses, with the goal to maximize extrinsic rewards and minimizing the physiological arousal response. The authors first show that they can train a CNN to predict systolic peaks from the pulse waveform based on the input images. The output of this network is then used with parametrically altered weightings in combination with the task related reward to evaluate performance on different driving tasks. The authors show that for different weightings performance on a number of driving tasks performance as measured by the collected extrinsic rewards is better.\n\nOverall, this is an interesting application of RL. It is OK to be inspired by biology, neuroscience, or psychology, but further reaching claims or interpretations of results in these fields need to be chosen carefully. The discussion of neuroscience and psychology are only partially convincing, e.g. there is extensive evidence that autonomic responses are highly dependent on cognition and not just decisions dependent on visceral, autonomic responses of the SNS. Currently, the manuscript is rather loosely switching between inspirations, imprecise claims, and metaphorical implementations with relation to neuroscience. The authors are encouraged to relate their work to some of the multi-criteria and structural credit assignment literature in RL, given the convex combination of rewards.  It may also be important to relate this work to imitation learning, given that the physiological measurements certainly also reflects states and actions by the human agents. While one indication for the reasons of higher extrinsic rewards with the augmented system is mentioned by the authors, namely that the autonomic signal is continuous and while the extrinsic rewards are sparse is convincing, it is not at all clear, why the augmented system performs better as shown in figure 5. \n', 'Summary:\nThis submission proposes a reinforcement learning framework based on human emotional reaction in the context of autonomous driving. This relies on defining a reward function as the convex combination of an extrinsic (goal oriented) reward, and an intrinsic reward. This later reward is learnt from experiments with humans performing the task in a virtual environment, for which emotional response is quantified as blood volume pulse wave (BVP). The authors show that including this intrinsic reward lead to a better performance of a deep Q networks, with respect to using the extrinsic reward only. \nEvaluation:\nOverall the proposed idea is interesting, and the use of human experiments to improve a reinforcement learning algorithm offers interesting perspectives. The weakness of the paper in my opinion is the statistical analysis of the results, the lack of in depth evaluation of the extrinsic reward prediction and the rather poor baseline comparison.\nDetailed comments:\n1.\tStatistical analysis\nThe significance of the results should be assessed with statistical methods in the following results:\nSection 4.1: Please provide and assessment of the significance of the testing loss of the prediction. For example, one could repetitively shuffle blocks of the target time series and quantify the RMSE obtained by the trained algorithm to build an H0 statistic of random prediction.\nSection 4.2: the sentence “improves significantly when lambda is either non-zero or not equal to 1” does not seem valid to me and such claim should in any case be properly evaluated statistically (including correction for multiple comparison etc…).\nError bars: please provide a clear description in the figure caption of what the error bars represent. Ideally in case of small samples, box plots would be more appropriate.\n2.\tTime lags in BVP\nIt would be interesting to know (from the literature) the typical latency of BVP responses to averse stimuli (and possible the latency of the various mechanisms, e.g. brain response, in the chain from stimuli to BVP). Moreover, as latency is likely a critical factor in anticipating danger before it is too late, it would important to know how the prediction accuracy evolves when learning to predict at different time lags forward in time, and how such level of anticipation influence the performance of the Q-network.\n3.\tPoor baseline comparison\nThe comparison to reward shaping in section 4.4 is not very convincing. One can imagine that what counts is not the absolute distance to a wall, but the distance to a wall in the driving direction, within a given solid angle. As a consequence, a better heuristic baseline could be used. \nMoreover, it is unclear whether the approaches should be compared with the same lambda: the authors need to provide evidence that the statistics (mean and possibly variance) of the chosen heuristic is match to the original intrinsic reward, otherwise it is obvious that the lambda should be adapted.\n4.\tBetter analysis of figure 5-6(Minor)\nI find figure 5-6 very interesting and I would suggest that the authors fully comment on these results. E.g. : (1) why the middle plot of Fig. 6 mostly flat, and why such differences between each curve from the beginning of the training. (2) Why the goal oriented task leads to different optimal lambda, is this just a normalization issue?\n']","[50, -20, -20]","[80, 60, 60]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses appreciation for the paper's idea and writing quality, calling it 'well written' and the idea 'quite nice'. However, they also point out some issues, which prevents the score from being higher. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I like the idea' and 'I think this general idea could be pushed further', which are encouraging and positive. The reviewer also balances praise with constructive feedback, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting', they express several concerns and criticisms. They mention that the neuroscience and psychology discussions are 'only partially convincing' and that the manuscript is 'loosely switching between inspirations, imprecise claims, and metaphorical implementations'. The reviewer also points out areas where the authors need to improve or clarify their work. However, the score is not deeply negative as the reviewer does recognize the potential of the work and offers constructive feedback. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, even when critiquing. They use phrases like 'The authors are encouraged to...' and 'It may also be important to...', which are polite ways of suggesting improvements. The reviewer also acknowledges the interesting aspects of the work before delving into criticisms, which is a courteous approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper, they also point out several weaknesses and areas for improvement. The review begins with a positive note about the interesting idea and perspectives, but then focuses on the paper's shortcomings in statistical analysis, evaluation depth, and baseline comparison. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'interesting perspectives' and 'please provide' which are polite ways of giving feedback. The reviewer also offers specific suggestions for improvement rather than just criticizing, which is a polite approach to peer review. However, the score is not extremely high as the language, while not rude, is also not overly deferential or excessively polite.""]"
"['PROS:\n- The text is very well written, with a good balance between mathematical details and intuitions.\n- I really like the high-level description of the algorithms and proof techniques\n\nCONS:\nto be completely honest, I am not sure I have learnt anything new from the paper. \n1) the proof techniques are very standard\n2) although there must be some small innovations, I thought that all the results had more or less been proven by Dupuis and co-authors:\na. large deviation principles\nb. the larger the swapping rate, the better (which motivated Dupuis & al to consider the infinite swapping limit.)\n\nand\nc. Bakri & al methodology to prove convergence relying on the carre du champ is by now very standard and the proofs of the paper are only minor adaptations.\n\nI must probably be missing something, and I encourage the authors to clarify what the main novelties are when compared to the several papers by Dupuis & al. \n\nREMARKS:\n1) I do not really understand the emphasis on optimisation while all the proofs are related to the convergence to the stationary distributions.\n\n', 'This paper gives a theoretical analysis of an interesting statistical physics technique known as replica exchange. The basic idea is that Langevin dynamics at low temperature is slow to converge, and that one could potentially boost the convergence by alternating between low and high temperature. At the extreme one could imagine running in parallel a random search and a gradient descent, and ``teleporting"" the gradient descent algorithm whenever the random search algorithm finds a point with better value. This makes a lot of sense and it is nice to see a theoretical analysis of this. The mathematics are sound, but I do not know whether it is an appropriate submission for ICLR.\n\nOne comment from the math side: it would be interesting (albeit probably difficult) to study kappa in (3.10) as a function of a. In particular at face value it looks like one only benefits from taking a larger, so why not study the limiting behavior of a->infty? What is the limiting value of kappa? Can you perform those calculations in the convex case at least?', ""The paper considers 'replica exchange' Langevin dynamics. These methods are very popular among practitioners, and developing some theory backing the empirical successes is an important goal.\nUnfortunately this paper offers only weak results. \n- The first 6 pages set up the general formalism. This is textbook material adapted to the current problem.\n- Page 7 offers a result (expression for the Dirichlet form), which is hardly more than an exercise for anybody familiar with Markov Chains theory. \n- Page 8 gives a Poincare inequality. Again, this follows from known results. More importantly: (1) It does not show any advantage of replica exchange over standard dynamics; (2) It does not provide any quantitative insight for high-dimensional problems.\n- Similar comments hold for the following pages. They are an exercise in applying standard formalism to this problem, without really showing any significative advantage of replica exchange.""]","[-30, 50, -70]","[50, 75, -20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('very well written', 'good balance', 'I really like'), they express significant concerns about the novelty of the work ('not sure I have learnt anything new', 'all the results had more or less been proven'). This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses polite language throughout ('I really like', 'I must probably be missing something', 'I encourage the authors'), even when expressing criticisms. They also frame their concerns as personal opinions ('I am not sure', 'I thought') rather than absolute statements, which adds to the politeness. However, the directness of some criticisms ('to be completely honest') prevents a higher politeness score."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'interesting' and 'nice to see a theoretical analysis', and states that the mathematics are sound. However, they express uncertainty about its appropriateness for ICLR, which tempers the positivity. The politeness score is 75 (quite polite) due to the use of respectful language throughout, positive acknowledgments of the paper's merits, and constructive suggestions for improvement. The reviewer avoids harsh criticism and frames their comment as an interesting addition rather than a flaw."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper offers 'only weak results' and repeatedly criticizes the content as being basic, unoriginal, or lacking significant insights. The few positive comments (e.g., acknowledging the importance of the topic) are overshadowed by the criticisms. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'hardly more than an exercise' and 'without really showing any significative advantage' come across as somewhat condescending. The reviewer doesn't use any softening language or acknowledge potential merits, which contributes to the slightly impolite tone.""]"
"[""In this paper, the authors derive exact formulas for computing singular values of convolutional layers of deep neural networks. By appealing to fast FFT transformations, they show that computing the singular values can be done much faster than computing the full SVD of the convolution matrix. This obviates the needs to approximate the singular values. They use these results to then devise regularization schemes for DNN layers, and show that employing this regularization helps with model performance. \n\nThey show that the algorithm with the operator norm regularization can be solved via an alternating projection scheme. They also postulate that since this might be expensive and unnecessary, one can also perform just 2 projections after every few SG iterations, and claim that this acts as a 'warm start' for subsequent iterations. Experiments reveal that this does not degrade the performance too much. \n\n\nThe paper is well written and easy to understand. The proofs follow from standard linear algebra methods, and are easy to follow. "", 'This paper studies the problem on computing the spectrum of singular values of linear convolutional layers. This is an important problem with abundant applications on regularizing deep neural networks. However, there are several technical issues need to be addressed in its current form. \n\nFirst, in the section ""Summary of Results"", at first read of the paper I found it very confusing why the time complexity of computing the spectrum is a function of n, where n is the size of the input feature map. Intuitively, since the size of the convolutional kernel is m x m x k x k, it is expected that the time complexity is expressed as a function of (m, k). Later I realized that this is due to the unnecessary and redundant 0 padding in section 2.1 that leads to this artifact. I understand that in order to apply the described Fourier transform technique it is necessary to introduce the large nxn filter, which is of the same size as the input, but it also introduces redundant computation. This fact further emerges in the introduction of matrix A in Eq (1). \n\nMore importantly, I think the authors didn\'t perform a detailed analysis on using the basic definition of convolutional filter to compute its spectrum, and this is the reason why they reached a misleading conclusion that simple SVD takes O(n^6 m^3) time. Specifically, each convolution operation corresponds to a inner product operation, so we can reshape the input 3D tensor with shape m x n x n into a 2D matrix, with shape n^2 x mk^2, denoted as X. Note that this creates a unnecessary redundancy in the input feature map, but it does not create redundant weight for the convolutional kernel. As a comparison, the introduced matrix A in the paper is heavily redundant. Similarly, for m channels, we can reshape the 4D convolutional kernel with shape m x m x k x k into a 2D matrix, with shape mk^2 x m, denoted as K. Then the usual convolution layer can be described as the following linear system: Y = X K, where Y with shape n^2 x m is the output, and can be easily reshaped into size m x n x n. Hence to compute the spectrum of the convolution layer corresponds to computing the singular values of the 2D matrix K with size mk^2 x m. Hence a naive application of SVD directly gives us the solution in time O(m^3 k^2) (Note that the time complexity of SVD for matrix with size a x b is O(min{a^2 b, a b^2})), which is much smaller than the one given in the paper O(m^3 n^2) since k << n. \n\nIn experiment the authors made unfair comparison between their proposed method and the full matrix method: the full matrix A is fully redundant, due to its circulant pattern. As this implies a highly redundant information, nobody will form and compute matrix A explicitly in practice. So the time improvements demonstrated in the experiment section are meaningless. A valid baseline would be to compare the proposed method with the one introduced above. But in this case I would imagine the proposed method to be worse due to its unnecessary 0 padding leading to the worst time complexity. ', 'The paper is dedicated to computation of singular values of convolutional layers. While singular values of convolutional layers represent sufficient interest for researchers, huge computational complexity made it difficult to investigate their properties in the case of layers of deep neural networks. Using the fact that operator matrix of the convolutional layer has a special form (i.e. can be represented as block-matrix, which blocks are doubly block circulant matrices) the authors proposed a more efficient method of computation of singular values. I really enjoyed reading this paper and I think that it opens a lot of interesting applications. As one of the possible applications the authors proposed a regularization method based on bounding of singular values.\n\nThe paper from my point of view has two main drawbacks:\n\n1.  Diversity of experiments. While the paper has strong theoretical component, the part dedicated to experiments is not broad enough. It would be interesting to see regularization on other architectures and other datasets.\n\n2.The system of references. I would recommend to add not only references to the sources, but also to the theorem numbers or the chapters. For example, I would recommend to replace ‘Poposition 9 ((Lefkimmiatis et al., 2013))’ with ‘Poposition 9 ((Lefkimmiatis et al., 2013, Proposition 1))’. In pure math papers, it is a standard rule to add such additional information since many papers contain a lot of theorems and it significantly simplifies reading and understanding the paper.\n\nDespite these disadvantages this is a great work with huge potential.\n']","[80, -60, 80]","[50, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'well written and easy to understand' and note that the proofs are 'easy to follow'. The reviewer also highlights the paper's contributions, such as deriving exact formulas and showing improved performance with their regularization scheme. There are no explicit criticisms mentioned.\n\nThe politeness score is 50 (somewhat polite) because the language used is professional and respectful, without any harsh or negative comments. The reviewer focuses on describing the paper's content and contributions objectively. While not overly effusive or using explicitly polite language, the tone is consistently neutral to positive, which contributes to a polite overall impression."", ""The sentiment score is -60 because the review is predominantly critical. The reviewer points out several technical issues and suggests that the authors' conclusions are misleading. They also state that the experimental comparisons are unfair and the time improvements are 'meaningless'. However, it's not entirely negative as the reviewer acknowledges the importance of the problem being studied. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and provide detailed explanations for their concerns. They use phrases like 'I understand that...' and 'I think...', which soften the critique. The reviewer also offers constructive suggestions, such as a more valid baseline for comparison, which contributes to a more polite tone overall."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, using phrases like 'I really enjoyed reading this paper' and 'it opens a lot of interesting applications'. They also describe it as 'a great work with huge potential' despite mentioning two drawbacks. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'recommendations'. They also use phrases like 'from my point of view' to soften their critique. The tone is professional and courteous throughout, without being overly formal or deferential.""]"
"['Summary: \nThe paper proposes to add to the original GAN (2014) loss a zero-centered gradient penalty as the one defined in the WGAN-GP paper. It also provides an analysis on the mode collapse and lack of stability of classical GANs. The authors compare results using their penalty on a few synthetic examples and on image net dogs generations to results using the classical GAN loss with or without gradient penalties. \n\nPositive points:\nThe paper is interesting to read and well illustrated. \nAn experiment on imagenet illustrates the progress that can be achieved by the proposed penalty.\n\nPoints to improve: \n\nIf I understood correctly, the main contribution resides in the application of the GP proposed by WGAN-GP to the original setting. Why not compare results to WGAN-GP in this case? Since the proposal of GANs, many papers addressed the mode collapse problem. WGAN-GP, VEEGAN, or Lucas et al arXiv:1806.07185, ICML 2018 to name only a few. \nThe related work section looks incomplete with some missing related references as mentioned above, and copy of a segment that appears in the introduction. \nThe submission could maybe improved by segmenting the work into intro / related / background (with clear equations presenting the existing GP) / analysis / approach / experiments\nThe experiments on synthetic data could be improved: for reproducibility, many works on GANs used the same synthetic data as VEEGAN. \nThe imagenet experiment lacks details.   ', ""The paper discusses the generalization capability of GAN especially from the discriminator's perspective. The explanation is clear and the method is promising. The proposed gradient penalty method that penalizes the unseen samples is novel and reasonable from the explanation, although these methods has been proposed before in different forms. \n\nPros:\n1. Nice explanation of why the training of GAN is not stable and the modes often collapse.\n2. Experiments show that the new 0-gradient penalty method seems promising to improve the generalization capability of GAN and helps to resist mode collapsing.\n\nCons:\n1. The paper does not have a clear definition of the generalization capability of the network.\n2. The straight line segment between real and fake images seems not a good option as the input images may live on low-dimensional manifolds. \n3. Why samples alpha in (7) uniformly? It seems the sampling rate should relate with its value. Intuitively, the closer to the real image the sampling point is, the larger the penalty should be.\n"", ""The primary innovation of this paper seems focused towards increasing the generalization of GANs, while also maintaining convergence and preventing mode collapse.\n\nThe authors first discuss common pitfalls concerning the generalization capability of discriminators, providing analytical underpinnings for their later experimental results. Specifically, they address the problem of gradient explosion in discriminators. \n\nThe authors then suggest that a zero-centered gradient penalty (0-GP) can be helpful in addressing this issue. 0-GPs are regularly used in GANs, but the authors point out that the purpose is usually to  provide convergence, not to increase generalizability. Non-zero centered penalties can give a convergence guarantee but, the authors, assert, can allow overfitting. A 0-GP can give the same guarantees but without allowing overfitting to occur.\n\n\nThe authors then verify these assertions through experimentation on synthetic data, as well as MNIST and ImageNet. My only issue here is that very little information was given about the size of the training sets. Did they use all the samples? Some portion? It is not clear from reading. This would be a serious impediment to reproducibility.\n\nAll in all, however, the authors provide a convincing  combination of analysis and experimentation. I believe this paper should be accepted into ICLR.\n\nNote: there is an error on page 9, in Figure 3. The paragraph explanation should list that the authors' 0-GP is figure 3(e). They list (d) twice.\n\n""]","[20, 60, 80]","[60, 70, 70]","[""The sentiment score is slightly positive (20) because the review begins with positive points, noting that the paper is 'interesting to read and well illustrated' and that it demonstrates progress on ImageNet. However, the majority of the review focuses on areas for improvement, which tempers the overall sentiment. The politeness score is moderately high (60) as the reviewer uses neutral language and frames criticisms as suggestions for improvement ('Points to improve:', 'The submission could maybe improved by...'). The reviewer also acknowledges the positive aspects before moving to critiques, which is a polite approach. The language throughout is professional and constructive, avoiding harsh or dismissive tones."", ""The sentiment score is 60 (positive) because the reviewer starts with a positive overall assessment, praising the paper's clear explanation and promising method. They list two specific pros before mentioning any cons. The cons are presented as constructive criticism rather than severe flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering suggestions for improvement. They use phrases like 'nice explanation' and 'seems promising,' which contribute to a polite tone. The reviewer also frames their criticisms as questions or suggestions rather than harsh criticisms, maintaining a courteous approach."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, stating that it provides 'a convincing combination of analysis and experimentation' and recommends that it 'should be accepted into ICLR'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the authors' contributions, and provides constructive feedback. The reviewer points out a minor error in a figure caption politely and offers a specific suggestion for improvement regarding the training set information. The overall tone is professional and supportive, with no harsh criticisms or rude language.""]"
"['Summary: This paper mixes automated theorem proving with machine learning models. The final goal, of course, is to be able to train a model that works in conjunction with an automated theorem proving system to efficiently prove theorems, and, ideally, in a way that resembles the way humans prove theorems. This is a distant goal, and the authors instead focus on several tractable tasks that are required for future progress in this direction. They start by integrating the Coq theorem proving environment with ML frameworks, allowing for the creation of models that perform various tasks related to theorem proving. In particular, they focus on two tasks. One is to estimate how many steps are left to complete the proof given a current proof state. The other is to determine what is a good choice of next step. Finally, they also consider issues surrounding representations of the various data structures involved in proofs (i.e., the proof tree, variables, etc.). They test various models on a synthetic nearly trivial logical expression proof, along with a more complicated (and meaningful real world) group theory result.\n\nStrengths: This is a very important area. Automated theorem proving has a potentially very significant impact, and being able to take advantage of some of the recent successes in ML would be excellent. The main environment proposed here, integrating PyTorch with Coq could potentially be a very useful platform for future research in this area. The paper exposes many interesting questions, and I generally think we need more exploratory papers that open up an area (as opposed to seeking to finalize existing areas) \n\nWeaknesses: The paper is pretty tough to understand without a lot of background in all of the existing theorem proving work (which might be fine for a conference in this area, but for this venue it would be nice to be more self-contained). The organization could also use some work, since it\'s often tough to figure out what the authors actually did. The experimental results seem very preliminary---although it\'s hard to say, as there is no easy way to compare the results to anything else out there. In general a lot of details seem missing.\n\nVerdict: The authors admit this is a preliminary work, and I agree with that. The paper certainly introduces many more questions than it answers. However, I think that in this case it\'s a good thing, and this type of paper has the potential to inspire a lot of new and exciting research, so I voted for acceptance.\n\nComments and questions:\n\n- As mentioned, a lot of the terminology is introduced very quickly and could stand to be more self-contained, i.e., ""tactics"" could be defined as being simple transformations that are applied to a current proof state to obtain another proof state, and each language has a library of tactics available.\n\n- Probably the major contribution of the work is the integration of the CoQ and Pytorch, so a bit more content describing how the Python data structures that wrap around Coq structures would be interesting here.\n\n- I didn\'t really understand one of the major contributions: the embedding function for the M_i conditioned on the environment. How does the sampled Gaussian vector work here? In general this section is pretty confusing, it would be great to include a schematic to show how the different levels of embeddings for different structures work here.\n\n- How does the real-world dataset work? Does the dataset contain one automated proof of the entire theorem, or several different proofs (ultimately produced by different user choices)? Are you measuring accuracy on the proofs of individual lemmas?', ""In the paper, the authors describe how machine learning techniques can be used to help build proofs in the widely-used interactive theorem prover Coq. They do so by explaining the experience with their system called GamePad, which converts various proof-related objects of Coq to python data structures so that python-based machine learning tools can be applied to those data structures. \n\nAlthough the word, GamePad, appears in the title of the paper, the paper focuses mostly on how Coq works, which aspects of proving in Coq can be aided by machine learning techniques, and what challenges they experienced when using machine learning techniques to the Feit-Thompson data set, an impressive big Coq proof of a famous theorem in group theory. I wasn't impressed by the GamePad tool, which seems to be just a translator of Coq internal data structures to python data structures. But I liked the authors' general exposition about the opportunities and the issues in using machine learning techniques to theorem proving in Coq. They explain that one key difficulty of the tactic prediction problem is the need to synthesize a term parameter to a tactic. They also point out the issue of choosing the granularity of tactic when approaching this problem. \n\nI give positive score mainly because some other audience in ICLR may learn about a new problem domain and get excited about it by interacting with the authors of the paper.\n\nHere are some minor comments.\n\n* Caption of Figure 1: its goal that the statement ===> its goal the statement\n\n* p3: function K ===> function M\n\n* p5: In the interpreter-inspired embedding of a dependent product, are you drawing a real number from a normal distribution for every occurrence of v in the proof once, and using the drawn real number for the occurrence whenever the occurrence is referred to later? Or when it is referred to later, are you drawing a new real number?\n\n* p6: How did you generate the training data for the experiment reported in Section 6?"", ""The submission describes a system for applying machine learning to interactive theorem proving. The paper focuses on two tasks: tactic prediction (e.g. attempting a proof by induction) and position evaluation (the number of  remaining steps required for a proof). Experiments show that a neural model outperforms an SVM on both tasks, using proof states sampled from a proof of the Feit-Thompson theorem as a dataset. It's great to see work on applying neural networks to symbolic reasoning. The paper is clearly written, and provides helpful background on interactive theorem proving.\n\nThe main weakness of the paper is the limited experiments, which only really show that neural methods outperform an SVM (with only a high level description of the features) - and only on the proof of a single theorem. The paper doesn't explore relevant interesting questions, such as whether the model is helpful for guiding humans or machines in making proofs, or perhaps if the approach can be used to find more human-understandable proofs than those found without training on human data. What are the trade-offs in learning from human proofs instead of automated proofs?\n\nOverall, the paper explores an interesting direction, but I think the current experiments are too preliminary for acceptance.\n\n\n""]","[50, 60, -20]","[80, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the research area and the potential impact of the work, while also pointing out weaknesses and areas for improvement. The reviewer states that the paper 'has the potential to inspire a lot of new and exciting research' and voted for acceptance, indicating a generally positive view despite the noted limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. The reviewer acknowledges the preliminary nature of the work without being dismissive and offers specific suggestions for improvement in a helpful manner. The use of phrases like 'it would be nice' and 'it would be great' when suggesting changes further contributes to the polite tone."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses appreciation for the authors' exposition on opportunities and issues in using machine learning for theorem proving in Coq, despite not being impressed by the GamePad tool itself. The reviewer also mentions giving a positive score due to the potential for other ICLR audience members to learn about and get excited about this problem domain. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the authors' work, and provides constructive feedback. The reviewer's comments are framed as 'minor' and include specific suggestions for improvements, which is a polite way to offer criticism. The overall tone is professional and courteous, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('It's great to see work...', 'The paper is clearly written...'), they ultimately conclude that the paper's experiments are too preliminary for acceptance. This indicates an overall negative sentiment towards the paper's current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and providing constructive criticism without harsh or dismissive language. They use phrases like 'It's great to see...' and frame their criticisms as suggestions for improvement rather than outright dismissals.""]"
"['This paper investigates batch normalization from three points of view. i) Loss decomposition, ii) learning rate selection, iii) generalization. If carefully read, I believe authors have interesting results and insightful messages. However, as a whole, I found the paper difficult to follow. Too much content is packed into too little space and they are not necessarily coherent with each other. Many of the technical terms are not motivated and even not defined. Overall, cleaning up the exposition would help a lot for readability. \n\nI have a few other technical comments.\n1) Theorem 1 is not acceptable for publication. It is not a rigorous statement. This should be fixed.\n2) Effective and maximum learning rate is not clear from the main body of the paper. I can intuitively guess what they are but they lack motivation and definition (as far as I see).\n3) In Section 3 I believe random data is being assumed (there is expectation over x in some notation). This should be stated upfront. Authors should broadly comment on the applicability of the learning rates calculated as N->\\infty in the finite N,P regime?', 'This is a thought provoking paper that aims to understand the regularization effects of batch-normalization (BN) under a probabilistic interpretation. The authors connect BN to population normalization (PN) and a gamma-decay term that penalizes the scale of the weights. They analyze the generalization error of BN for a single-layer perceptron using ideas in statistical physics.\n\nDetailed comments:\n\n1. Theorem 1 uses the loss function of a single-layer perceptron in the proof. This is not mentioned in the main writeup. This theorem is not valid in general.\n\n2. The main contribution of this paper is Theorem 1 which connects BN to population normalization and weight normalization. It shows that the regularization of BN can be split into two components that depend on the mini-batch mean and variances: the former penalizes the magnitude of activations while the latter penalizes their correlation.\n\n3. Although the theoretical analysis is conducted under simplistic models, this paper corroborates a number of widely-known observations about BN in practice. It validates these predictions on standard experiments.\n\n4. The scaling of BN regularization with batch-size can be easily seen from Teye et al., 2018, so I think the experiments that validate this prediction are not strictly necessary.\n\n5. It is difficult to use these techniques for deep non-linear networks.\n\n6. The predictions in Section 3.3 are very interesting: it is often seen that fully-connected layers (where BN helps significantly) need small learning rates to train without BN; with BN one can use larger learning rates.\n\n7. The experimental section is very rough. In particular the experiments on CIFAR-10 and downsampled-ImageNet with CNNs seem to have very high errors and it is difficult to understand whether some of the predictions about generalization error apply here. Why not use a more recent architecture for CIFAR-10?\n\n8. There is a very large number of grammatical and linguistic errors in the narrative.\n\n9. The presentation of the paper is very dense, I would advise the authors to move certain parts to the appendix and remove the inlining of important equations to improve readability.', ""This is an interesting paper on a statistical analysis of batch normalization. It takes a holistic approach, \ncombining techniques and ideas from various fields, and considers multiple endpoints, such as tuning of learning rates and estimation of generalization error. Overall it is an interesting paper.\n\nSome aspects of the paper that could be improved:\n\n1) Theorem 1 is not particularly compelling, and may be misleading at a first reading. It considers the simple model of Equation (1) in a straightforward bias-variance decomposition, and may not be useful in general. Some aspects of the theorem are not technically correct or unclear. E.g., \\gamma is a single parameter, what does it mean to have a Fisher information matrix?\n\n2) The problem is not motivated well. It may be a good idea to bring some discussions from Section 6 early in the introduction of the paper. When does BN work well? And what is the current understanding (prior to the paper) and how does the paper compare/contribute? I think the paper does a good job on that front, but it follows a disordered narration flow which makes it hard to read. I understand there is a lot of material to cover, but it would help a lot to reorganize the paper in a more linear way.\n\n3) What about alternatives, such as implicit back propagation that stabilizes learning?  [1]\n\n4) I don't find Figure 1 (and 3) particularly useful on how it handles vanilla SGD. In practice, it would be straightforward to avoid the mentioned pathologies. Overall, the experiments are interesting but it may be hard to generalize the findings to non-linear settings.\n\n\n[1] Implicit back propagation, Fagan & Iyengar, 2017\n\n""]","[-20, 50, 50]","[60, 60, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges 'interesting results and insightful messages', they also express significant concerns about the paper's readability, organization, and lack of clarity on key points. The overall tone suggests the paper needs substantial revisions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I believe', 'I found', and 'would help' which maintain a polite tone while conveying their concerns. The reviewer also balances criticism with positive acknowledgments of the paper's strengths."", ""The sentiment score is 50 (slightly positive) because the review starts with calling the paper 'thought provoking' and acknowledges its contributions, but also lists several criticisms and areas for improvement. The overall tone is balanced between positive aspects and constructive criticism. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. They acknowledge the paper's strengths and frame most criticisms as areas for improvement or clarification. However, the score is not higher due to the direct nature of some comments, particularly regarding grammatical errors and presentation density."", ""The sentiment score is 50 (slightly positive) because the review starts with positive comments like 'interesting paper' and 'takes a holistic approach', indicating overall interest. However, it also lists several areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. Phrases like 'could be improved' and 'it may be a good idea' suggest a polite tone. The reviewer also acknowledges the paper's strengths, showing respect for the authors' work.""]"
"['Cons\n\n1.\tIt’s unclear why LABC produces lower scores than ‘normal’ training on ‘normal’ testing.\n2.\tThe text says nothing I can find to explain why in Fig 5 the ‘entity’ vectors have all 0s except in one dimension, which seems to make the problem considerably easier.\n3.\tIn a sense, there is no cross-domain adaptation required in the symbolic task: min is min, whether it operates on dimension k of the source vectors or dimension j of the target vectors. On the other hand, dimensions are processed independently in the model, as far as I can tell, so there’s no free transfer of learning min on dimension k to knowing min on dimension j. It would be good to comment on this issue.\n4.\tThere seem to be obvious analogies (so to speak) to GANs, and it is very curious that this is not mentioned anywhere that I can see. This is particularly glaring in Sec. 5.3.\n5.\tThe quantitative results are scattered throughout the prose; it would be challenging, but worthwhile, to gather them into an actual table.\n\nPros\n\n6.\tThe basic idea (“We should aspire to select as negative examples those examples that are plausible considering the most abstract principles that describe the data”, p. 14) is very intuitive, common-sensical, bordering on obvious. But it is not at all obvious that the idea has as much power as is demonstrated in the experiments. The transfer to novel domain combinations, novel domains, and novel values of dimensions is impressive and surprising.\n7.\tThe result that the proposed training, designed to promote generalization on analogy tasks, also seems to promote improved sensory processing is interesting. Whether it really instantiates the parallel connection argued for by the High-Level Perception view from psychology/philosophy is debatable, but that is itself an interesting connection that the authors should be praised for identifying.\n8.\tIn general, the connection to the cognitive literature is creative and tantalizing and provides good scientific grounding for the work.\n9.\tThe linking to the flexibility of word meanings in the final paragraph pushes the limit of the plausibility of connection to broader cognitive issues, but I’m inclined to indulge the authors for at least bringing up this important and relevant issue.  \n', 'The paper describes an approach to train neural networks for analogical reasoning tasks.\n\nGeneral analogical reasoning is quite a significant milestone in Machine learning. Therefore, the paper tackles an extremely challenging problem.  The paper does a good job of constructing various tasks to show that analogies can be learned in different scenarios which are complex analogy tasks. Specifically, visual analogy and symbolic analogies are considered. The main idea is to choose training examples such that the model is forced to learn the relational structure rather than simply learn superficial features. One weakness is that we need to hand code the training examples to force it to have contrasting relational structure for different tasks. Is this realistic in different problems? That is maybe a limiting factor of this work. An automated method for generating such examples is given, but there is not too much detail on this (5.3). Maybe this needs to be expanded.\n\nAlso, is the idea of LABC different from SMT. The novelty may be a bit weak in this aspect. If LABC  can be described in a more general manner, it would help a reader not familiar with the other related work.  Since the baseline comparison is with a very weak method (randomly chosen examples), it is hard to judge the impact of the proposed approach. In summary, I think the paper has nice ideas, particularly, if we can automatically generate examples using LABC. but maybe there is a need to work on better organizing the ideas, more general formulation of LABC and a more convincing experimental evaluation that includes a state-of-the-art method if available', 'This work investigates the ability of a neural network to learn analogy. They showed that a simple neural network is able to solve analogy problems with image or abstract input, given that the training data is selected to contrast abstract relational structures. \n\nThe paper is relatively well-written with rich discussions. Some details about the experiments are missing like how many examples are used for training and testing. It is also important to show how much variations are in the dataset, and there should be some external baselines like those proposed in (Barrett et al, 2018). \n\nAlthough the performance is relatively high, some error analysis will provide more insights into what the neural network is missing and if it makes mistakes similar to human. \n\nSection 4 claims that “For a model trained via LABC, we found that these activities clustered according to relation type (e.g. progression ) more-so than domain”. However, it is unclear whether Figure 4 can support this. Some quantitive measure should help, for example, the average distance within the clusters between clustering based on relation type and domain. \n\nThe novelty of the proposed approach is limited. The difference between the proposed method and baseline in performance seems to be a result of whether there is a difference between train and test setting. For example, if trained in “contrasting” will have better test performance on “contrasting” but worse on “normal” and vice versa. \n\nThe problem is very interesting and the discussion is extensive. However, the proposed approach isn’t very novel and the evaluation and analysis should be improved to provide a stronger support. \n\nBarrett, David GT, et al. ""Measuring abstract reasoning in neural networks."" arXiv preprint arXiv:1807.04225 (2018).\n\n------\n\nScore updated after reading authors\' response. ']","[50, 20, -20]","[70, 60, 50]","[""The sentiment score is 50 (slightly positive) because while the review lists several cons, it also provides significant praise in the pros section. The reviewer acknowledges the power and impressiveness of the results, the interesting connections to cognitive literature, and the creative aspects of the work. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and explicitly praises certain aspects of the work. The reviewer also uses phrases like 'it would be good to comment on this issue' and 'I'm inclined to indulge the authors', which indicate a polite and considerate tone. The criticism is presented in a factual manner without harsh language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the significance of the problem and praises certain aspects of the paper ('does a good job', 'nice ideas'), while also pointing out weaknesses and areas for improvement. The overall tone is constructive rather than overtly critical. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions rather than demands, and balances criticism with praise. The reviewer's language is professional and constructive, avoiding harsh or dismissive statements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('relatively well-written with rich discussions', 'interesting problem'), they also point out several limitations and areas for improvement. The overall tone suggests that the paper needs significant work before it can be considered strong.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms ('Some details... are missing', 'it is unclear whether...') and balance negative points with positive ones. The reviewer also offers constructive suggestions for improvement rather than just pointing out flaws.\n\nThe language used is not overly formal or deferential, but it's consistently polite and constructive, avoiding any harsh or dismissive statements. This approach maintains a respectful tone while still providing clear and honest feedback.""]"
"[""This paper is one of a sequence of works trying to learn heuristics for solving combinatorial optimisation problems. Compared to its predecessors, its contributions are three-fold. First, it introduces a tweak on the REINFORCE learning algorithm, outperforming more complicated methods. Second, it introduces a new model for combinatorial tasks which delivers interesting results on several tasks which are varied though related. Finally, it evaluates this model on many tasks.\n\n****Quality and clarity****\nThis is a very high-quality paper. \nThe writing is clear and sharp, and the reading experience is quite enjoyable (the witty first paragraph sets the tone for what is to follow), even if the text is at times a bit verbose. \nAnother point to commend is the honesty of the paper (see e.g. the comment on the performance of the model on TSP vs specialised solvers such as Concord).\nThe related work section is complete and well documented.\nFinally, the experimental results are clearly presented and well-illustrated.\n\n****Originality and significance****\nOn the theoretical side, the contributions of this paper are interesting but not ground-breaking. The REINFORCE tweak is close to other algorithms that have been tried in the last few years (such as indeed the one presented in Rennie et al, 2016). The model architecture, while successful, is not a large departure from the Transformer presented in Vaswani et al, 2017.\n\nMore significant is the complete set of experiments on a varied subset of combinatorial tasks, which showcases one of the promises of using machine learning for combinatorial optimisation: reusability of a single model for many tasks.\n\n****Conclusion****\nOverall, this is a nice, very well-written paper. Its contributions, though not ground-breaking, are significant to the field, and constitute another step in the right direction.\n\nPros\n- high-quality writing\n- very clear\n- complete experiments on a variety of tasks, some of which do not have optimal solvers\n- honest assessment of the model\n\nCons\n- the theoretical contributions are not ground-breaking (either the the tweak on REINFORCE or the model architecture)\n- the model is still far from obtaining meaningful results on TSP (although it's interesting to compare to previous learned models, only solving problems with 100 nodes also illustrates how far we have to go...)\n\nDetails\n- Dai et al has been published at NIPS and is no longer an arxiv preprint\n- the comparison to AlphaGo should either be expanded upon or scratched. Although it could be quite interesting, as it is it's not very well motivated."", ""The paper presents an attention-based approach to learning a policy for solving TSP and other routing-type combinatorial optimization problems. An encoder network computes an embedding vector for each node in the input problem instance (e.g., a city in a TSP map), as well as a global embedding for the problem instance. The encoder architecture incorporates multi-head attention layers to compute the embeddings. The decoder network then uses those embeddings to output a permutation of the nodes which is used as the solution to the optimization problem. The encoder and decoder are trained using REINFORCE to maximize solution quality. Results are shown for four problem types -- TSP, vehicle routing, orienteering problem, and stochastic prize collecting TSP. \n\nPositive aspects of the paper: The problem of learning combinatorial optimization algorithms is definitely an important one as it promises the possibility of automatically generating special purpose optimizers. Showing experimental results for different problem types is useful as it gives evidence for broad applicability. The paper is well-written, the related work section is nice, and the background material is explained well enough to make it a self-sufficient read. \n\nI have two main criticisms:\n1. Scalability of the approach: Focusing on the TSP experiments, the problem sizes of 20, 50, and 100 are really trivial for a state-of-the-art exact solver like Concorde or heuristic algorithm like LKH. And there have already been many papers showing that RL can be used for small-scale TSP and other problems (many are cited in this paper). At this point the interesting question is whether an RL approach can scale to much bigger problem instances, both in terms of solution quality as well as inference running time. For example, the DIMACS TSP Challenge problem instances have sizes up to 10^7 cities. New heuristics used with LKH (e.g. POPMUSIC) can scale to such sizes and empirically show complexity that is nearly linear with respect to the number of cities. It seems that the proposed approach would have quadratic complexity, which would not scale to much bigger problem instances. Table 2 also suggests that the solution quality (optimality gap) becomes worse for bigger sizes. If there was strong evidence that the approach could scale to much larger instances, that would have added to the novelty of the paper.\n\n2. Insufficient comparisons: \na. The comparison to Gurobi's running time in Table 1 is misleading because in addition to outputting a solution, it also outputs a certificate of optimality. It is possible that Gurobi finds the optimal solution very quickly but then spends a large amount of time proving optimality. Since RL approaches don't prove optimality, it would be more fair to report Gurobi's time to first reach the optimal solution (and disregard proving time). This may turn out to be much smaller than the times reported in Table 1. \nb. It would be good to compare against the state-of-the-art TSP-specific algorithms (Concorde, LKH) as well. Even if a general-purpose RL approach does not beat them, it would be good to assess how much worse it is compared to the best expert-designed custom algorithms so that the tradeoff between human expertise and solution quality / running time is clear. \n\nIt would also be useful to give insight into what does attention buy for the kinds of problems considered. Why do we expect attention to be helpful, and do the results match those expectations?\n"", 'This paper proposes an alternative deep learning model for use in combinatorial optimization. The attention model is inspired by the Transformer architecture of Vaswani et al. (2017). Given a distribution over problem instances (e.g. TSP), the REINFORCE update is used to train the attention model. Interestingly, the baseline used in the REINFORCE update is based on greedy rollout using the current model. Experimentally, four different routing problems are considered. The authors show that the proposed method often outperforms some other learning-based methods and is competitive with existing (non-learned) heuristics.\n\nOverall, this is a good piece of work. Next, I will touch on some strengths and weaknesses which I hope the authors can address/take into account. My main concern is the lack of comparison with Deudon et al. (2018).\n\nStrengths:\n- Writing: beautifully written and precise even with respect to tiny technical details; great job!\n\n- Versatility: the experimental evaluation on four different routing problems with different kinds of objectives and constraints, different baseline heuristics, etc., is quite impressive (irrespective of the results). The fact that the proposed model can be easily adapted to different problems is encouraging, since many real-world operational problems may be different from textbook TSP/VRP, and hard to design algorithms for; a learned algorithm can greatly expedite the process. This versatility is shared with the model in Dai et al. (2017) which applied to different graph optimization problems.\n\n- Choice of baseline: the use of the greedy policy is definitely the right thing to do here, as one wants to beat ""simpler"" baselines.\n\n- Results: the proposed method performs very well and does not seem hard to tune, in that the same model hyperparameters work well across different problems.\n\nWeaknesses:\n- Comparison to Deudon et al. (2018): I believe the authors should do more work to compare against Deudon et al. (2018). This includes expanding the sentence in related work, describing the differences in more detail; perhaps a side-by-side graphical comparison of the two models in the appendix would help; reporting results from or running the code of that paper for the relevant problems (TSP?). This is crucial, since that paper also builds on the Transformer architecture, attention, etc. Its code is also online and seems to have been up for a while (https://github.com/MichelDeudon/encode-attend-navigate). There is quite some overlap, and the reader should be able to understand how the two models/papers differ.\n\n- Intuition: One thing that is lacking here is some intuitive explanation of *why* this particular attention model is a reasonable choice for guiding a combinatorial algorithm. For instance, earlier work such as Pointer networks or S2V-DQN each addressed certain issues with other models of the time (e.g. capturing graph structure in S2V-DQN). If the choice of the model is purely performance-driven, that is completely fine, but then it makes sense to walk the reader through the process that got you to the final model. You do some of that in the ablation study in 5.2, for the baseline. Additionally, I am wondering about why this attention model is good for a combinatorial problem.\n\nQuestions/suggestions:\n- Performance metric: if I understand correctly, Table 1 reports objective values. Could you additionally report optimality gaps compared to the best solution found *across* methods (including Gurobi, especially when it solves to optimality for the smaller problems/all of TSP)? Otherwise, it is very hard to interpret the differences in absolute objective values across methods.\n\n- Baseline: could you use a non-learned baseline (e.g. 2-opt for the case of TSP) at the beginning of the training (then go to your learned but greedy baseline)? Might this give a stronger baseline at the beginning and accelerate training?']","[80, -20, 70]","[90, 60, 90]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'very high-quality', 'clear and sharp', and 'enjoyable'. They commend the honesty and completeness of the work, and while noting that the theoretical contributions are not ground-breaking, they still consider them significant. The overall tone is very positive, with only minor criticisms. The politeness score is 90 (very polite) due to the consistently respectful and constructive language used throughout. The reviewer offers praise generously ('very high-quality', 'clear and sharp', 'enjoyable') and frames criticisms gently ('not ground-breaking' rather than 'unoriginal'). They also balance critiques with positive aspects, showing consideration for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they raise two significant criticisms that outweigh the positives. The reviewer points out issues with scalability and insufficient comparisons, which are presented as major weaknesses of the work. However, the tone is not entirely negative, as the reviewer recognizes the importance of the problem and some strengths of the paper. The politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They begin by highlighting positive aspects before moving on to criticisms, which is a polite approach. The criticisms are presented as constructive feedback rather than harsh judgments. The reviewer also uses phrases like 'it would be good to' and 'it would be useful to' when making suggestions, which maintains a courteous tone."", ""The sentiment score is 70 (positive) because the reviewer begins by calling it 'a good piece of work' and highlights several strengths including 'beautifully written', 'impressive' evaluation, and 'very well' performance. The weaknesses mentioned are relatively minor and presented constructively. The politeness score is 90 (very polite) due to the consistently respectful tone, use of phrases like 'I hope the authors can address', and framing of critiques as suggestions rather than demands. The reviewer also compliments the authors' work multiple times. The language is professional and courteous throughout, without any rudeness.""]"
"[""The paper is interesting and I like it. I draws parallels from biological learning and the well known critical learning phases in biological systems to artificial neural network learning. \nA series of empirical simulation experiments that all aim to disturb the learning process of the DNN and to artificially create criticality are presented. They are providing food for thought, in order to introduce some quantitative results, the authors use well known Fisher Information to measure the changes. So far so good and interesting.\nI was disappointed to see Tishby's result (2017) only remotely discussed, an earlier work than the one by Tishby is by Montavon et al 2011 in JMLR. Also in this work properties of successive compression and dimensionality reduction are discussed, perhaps the starting point of quantitative analysis of various DNNs. \n\nTo this point the paper presents no theoretical contribution, rather empirical findings only, that may or may not be ubiquitous in DNN learning systems. The latter point may be worthwhile to discuss and analyse. \nOverall, the paper is interesting with its nice empirical studies but stays somewhat superficial. To learn more a simpler toy model may be worthwhile to study. \n\n"", 'The authors analyze the learning dynamics in deep neural networks and identify an intriguing phenomenon that reflects what in biological learning is known as critical period: a relatively short time window early in post-natal development where organisms become particularly sensitive to particular changes in experience. The importance of critical periods in biology is due to the fact that specific types of perturbations to the input statistic can cause deficits in performance which can be permanent in the sense that later training cannot rescue them.\n\nThe authors did a great job illustrating the parallelism between critical periods in biological neural systems and the analogous phenomenon in artificial deep neural networks. Essentially, they showed that blurring the input samples of the cifar10 dataset during the initial phase of training had an effect that is very reminiscent of the result of sensory deprivation during the critical periods of visual learning in mammals, resulting in a long-term impairments in visual object recognition that persists even if blurring is removed later in training. The authors go as far as characterizing the effects of the length of the ""sensory deprivation"" window and its onset during training, and comparing the results to classic neuroscience monocular deprivation experiments in kittens, pointing out very striking phenomenological similarities.\n\nNext, the authors establish a connection between critical periods in deep neural networks and the amount of information that the weights of the trained model contain about the task by looking at the Fisher Information Matrix (FIM). With this method they obtain a host of interesting insights. One insight is that there are two phases in learning: an initial one where the trace of the FIM grows together with a rapid increase in classification accuracy, and a second one where accuracy keeps slightly increasing, but Fisher Information trace globally decreases. They then go into detail and look at how this quantity evolves within individual layers of the deep learning architecture, revealing that the deficit caused by the blurring perturbation during the early epochs training is accompanied by larger FIM trace in the last layers of the architecture at the expense of the intermediate layers.\nBesides the fact that deep neural network exhibit critical periods, another important result of this work is the demonstration that pretraining, if done inappropriately can actually be deleterious to the performance of the network.\n\nThis paper is insightful, and interesting. The conceptual and experimental part of the paper is very clearly presented, and the methodology is very appropriate to tease apart some of the mechanisms underlying the basic phenomenological observations. Here are some detailed questions meant to elucidate some points that are still unclear.\n\n- Presumably, early training on blurred images prevents the initial conv filters from learning to discriminate high-frequency components (first of all, is this true?). The crucial phenomenon pointed out by the authors is that, even after removing the blur, the lower convolutions aren\'t able to recover and learn the high-frequency components. In fact, the high FIM trace in the latest layers could be due to the fact that they\'re trying to compensate for the lack of appropriate low-level feature extractors by composing low-frequency filters so as ""build"" high-frequency ones. If this makes sense, one would assume that freezing the last layers and only maintaining plasticity in the lower ones could be a way of ""reopening"" the critical period. Is that indeed the case?\n- The authors show that their main results are robust to changes in the learning rate annealing schedule. However, it is not clear how changing the optimizer might affect the presence of the critical period. What would happen for instance using Adam or another optimization procedure that relies on the normalization of the gradient?\n- On a related note, the authors point out the importance of forgetting, in particular as the main mechanism behind the second learning phase. They also point out that the deficit in learning the task after sensory deprivation is accompanied by large FIM trace in the last layers. What would happen in the presence of a standard regularizer like weight decay? Assuming that large FIM trace in the last layers is correlated with large weighs, that might mitigate the negative effect of early sensory deprivation.\n- In neuroscience the opening of the critical period window if thought to be mechanistically mediated by the maturation of inhibition. Is that view compatible with the results presented in this paper? This is sort of complementary to the FIM analysis, since is mostly about net average input to a neuron, i.e. about the information contained in the activations, rather than the weights.', ""Let's be frank: I have never been a fan of comparing real brains with back-prop trained multilayer neural networks that have little to do with real neurons.  For instance, I am unmoved when Figure 1 compares multilayer network simulations with experimental data on actual kitten. More precisely, I see such comparisons as cheap shots.\n\nHowever, after forgetting about the kitten,  I can see lots of good things in this paper.  The artificial neural network experiments designed by the authors show interesting phenomena in a manner that is amenable to replication. The experiments about the varied effects of different kinds of deficits are particularly interesting and could inspire other researchers in creating mathematical models for these striking differences.  The authors also correlate these effects with the two phases they observe in the variations of the trace of the Fisher information matrix.  This is reminiscent of Tishby's bottleneck view on neural networks, but different in interesting ways. To start with, the trace of the Fisher information matrix is much easier to estimate than Tishby's mutual information between patterns, labels, and layer activation. It also might represent something of a different nature, in ways that I do not understand at this point.\n\nIn addition the paper is very well written, the comments are well though, and the experiments seem easy to replicate.\n\nGiven all these qualities, I'll gladly take the kitten as well..\n""]","[20, 90, 60]","[50, 80, 70]","[""The sentiment score is slightly positive (20) because the reviewer expresses interest in the paper and finds it thought-provoking, using phrases like 'interesting' and 'providing food for thought'. However, they also express disappointment and note that the paper 'stays somewhat superficial', which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits while offering constructive criticism. They avoid harsh language even when expressing disappointment, and suggest improvements in a professional manner. The reviewer maintains a balanced tone, neither overly effusive nor unduly critical, which contributes to the politeness of the review."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, using phrases like 'great job,' 'insightful,' and 'interesting.' They praise the clarity of presentation and appropriateness of methodology. The politeness score is 80 (quite polite) due to the respectful tone throughout. The reviewer offers constructive feedback and asks questions to further improve the work, rather than criticizing. They use phrases like 'presumably' and 'if this makes sense' when suggesting ideas, showing respect for the authors' expertise. The overall tone is professional and encouraging, with no harsh or rude language."", ""The sentiment score is 60 (moderately positive) because while the reviewer starts with skepticism ('I have never been a fan...'), they quickly transition to praising the paper's merits ('I can see lots of good things in this paper'). They highlight several positive aspects, including interesting experiments, potential to inspire other researchers, and good writing. The initial criticism is outweighed by the subsequent praise. The politeness score is 70 (quite polite) due to the reviewer's respectful tone throughout. Even when expressing initial skepticism, they use phrases like 'Let's be frank' rather than harsh language. They acknowledge their own biases and use phrases like 'I'll gladly take the kitten as well' to soften their critique. The overall tone is constructive and appreciative, maintaining professionalism while offering both critique and praise.""]"
"['Summary:\nThis work tackles few-shot (or meta) learning from a probabilistic inference viewpoint. Compared to previous work, it uses a simpler setup, performing task-specific inference only for single-layer head models, and employs an objective based on predictive distributions on train/test splits for each task (rather than an approximation to log marginal likelihood). Inference is done amortized by a network, whose input is the task training split. The same network is used for parameters of each class (only feeding training points of that class), which allows an arbitrary number of classes per task. At test time, inference just requires forward passes through this network, attractive compared to non-amortized approaches which need optimization or gradients here.\n\nIt provides a clean, decision-theoretic derivation, and clarifies relationships to previous work. The experimental results are encouraging: the method achieves a new best on 5-way, 5-shot miniImageNet, despite the simple setup. In general, explanations in the main text could be more complete (see questions). I\'d recommend shortening Section 4, which is pretty obvious.\n\n- Quality: Several interesting differences to prior work. Well-done experiments\n- Clarity: Clean derivation, easy to understand. Some details could be spelled out better\n- Originality: Several important novelties (predictive criterion, simple model setup, amortized inference network). Closely related to ""neural processes"" work, but this happened roughly at the same time\n- Significance: The few-shot learning results are competitive, in particular given they use a simpler model setup than most previous work. I am not an expert on these kind of experiments, but I found the comparisons fair and rather extensive\n\nInteresting about this work:\n- Clean Bayesian decision-theoretic viewpoint. Key question is of course whether\n   an inference network of this simple structure (no correlations, sum combination\n   of datapoints, same network for each class) can deliver a good approximation to\n   the true posterior.\n- Different to previous work, task-specific inference is done only on the weights of\n   single-layer head models (logistic regression models, with shared features).\n   Highly encouraging that this is sufficient for state-of-the-art few-shot classification\n   performance. The authors could be more clear about this point.\n- Simple and efficient amortized inference model, which along with the neural\n   network features, is learned on all data jointly\n- Optimization criterion is based on predictive distributions on train/test splits, not\n   on the log marginal likelihood. Has some odd consequences (question below),\n   but clearly works better for few-shot classification\n\nExperiments:\n- 5.1: Convincing results, in particular given the simplicity of the model setup and\n   the inference network. But some important points are not explained:\n   - Which of the competitors (if any) use the same restricted model setup (inference\n      only on the top-layer weights)? Clearly, MAML does not, right? Please state this\n      explicitly.\n   - For Versa, you use k_c training and 15 test points per task update during\n      training. Do competitors without train/test split also get k_c + 15 points, or\n      only k_c points? The former would be fair, the latter not so much.\n- 5.2: This seems a challenging problem, and both your numbers and reconstructions\n   look better than the competitor. I cannot say more, based on the very brief\n   explanations provided here.\n   The main paper does not really state what the model or the likelihood is. From\n   F.4 in the Appendix, this model does not have the form of your classification\n   models, but psi is input at the bottom of the network. Also, the final layer has\n   sigmoid activation. What likelihood do you use?\n   One observation: If you used the same ""inference on final layer weights"" setup\n   here, and Gaussian likelihood, you could compute the posterior over psi in closed\n   form, no amortization needed. Would this setup apply to your problem?\n\nFurther questions:\n- Confused about the input to the inference network. Real Bayesian inference would\n   just see features h_theta(x) as inputs, not the x\'s. Why not simply feed features in\n   then?\n   Please do improve the description of the inference network, this is a major\n   novelty of this paper, and even the appendix is only understandable by reading\n   other work as well. Be clear how it depends on theta (I think nothing is lost by\n   feeding in the h_theta(x)).\n- The learning criterion based on predictive distributions on train/test splits seem\n   to work better than ELBO-like criteria, for few-shot classification.\n   But there are some worrying aspects. The marginal likelihood has an Occam\'s\n   razor argument to prevent overfitting. Why would your criterion prevent overfitting?\n   And it is quite worrying that the prior p(psi | theta) drops out of the method\n   entirely. Can you comment more on that?\n\nSmall:\n- p(psi_t | tilde{x}_t, D_t, theta) should be p(psi_t | D_t, theta). Please avoid a more\n   general notation early on, if you do not do it later on. This is confusing\n', 'This paper presents two different sections:\n1. A generalized framework to describe a range of meta-learning algorithms.\n2. A meta-learning algorithm that allows few shot inference over new tasks without the need for retraining. The important aspect of the algorithm is the context independence assumption between posteriors of different classes for learning weights. This reduces the number of parameters to amortize during meta-training. More importantly, it makes it independent of the number of classes in a task, and effectively doing meta-training across class inference instead of each task. The idea sounds great, but I am skeptical of the justification behind the independence assumption which, as per its justifications sounds contrived and only empirical. \n\nOverall, I feel the paper makes some progress in important aspects of meta-learning.', 'This paper proposes both a general meta-learning framework with approximate probabilistic inference, and implements an instance of it for few-shot learning. First, they propose Meta-Learning Probabilistic inference for Prediction (ML-PIP) which trains the meta-learner to minimize the KL-divergence between the approximate predictive distribution generated from it and predictive distribution for each class. Then, they use this framework to implement Versatile Amortized Inference, which they call VERSA. VERSA replaces the optimization for test time with efficient posterior inference, by generating distribution over task-specific parameters in a single forward pass. The authors validate VERSA against amortized and non-amortized variational inference which it outperforms. VERSA is also highly versatile as it can be trained with varying number of classes and shots.\n\nPros\n- The proposed general meta-learning framework that aims to learn the meta-learner that approximates the predictive distribution over multiple tasks is quite novel and makes sense.\n- VERSA obtains impressive performance on both benchmark datasets for few-shot learning and is versatile in terms of number of classes and shots.\n- The appendix section has in-depth analysis and additional experimental results which are quite helpful in understanding the paper.\n\nCons\n- The main paper feels quite empty, especially the experimental validation parts with limited number of baselines. It would have been good if some of the experiments could be moved into the main paper. Some experimental results such as Figure 4 on versatility does not add much insight to the main story and could be moved to appendix.\n- It would have been good if there was some validation of the time-performance of the model as one motivation of meta-learning is rapid adaptation to a test-time task. \n\nIn sum, since the proposed meta-learning probabilistic inference framework is novel and effective I vote for accepting the paper. However the structure and organization of the paper could be improved by moving some of the methodological details and experimental results in the appendix to the main paper. \n']","[70, 50, 60]","[80, 20, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the work, highlighting its strengths such as 'clean, decision-theoretic derivation', 'encouraging' experimental results, and achieving 'a new best on 5-way, 5-shot miniImageNet'. The reviewer also notes the work's originality and significance. However, it's not a perfect score as the reviewer does point out some areas for improvement and has some questions.\n\nThe politeness score is 80 (quite polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting about this work', 'convincing results', and 'I'd recommend', which are constructive and courteous. The reviewer also frames criticisms as suggestions or questions rather than direct attacks, such as 'Please do improve the description...' and 'Can you comment more on that?'. The language is consistently respectful and aimed at improving the paper rather than dismissing it."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the paper 'makes some progress in important aspects of meta-learning' and describes the idea as sounding 'great'. However, they also express skepticism about the justification for a key assumption, which tempers the overall positivity. The politeness score is 20 (slightly polite) because the reviewer uses neutral, professional language without any harsh criticism. They express their concerns in a respectful manner, using phrases like 'I am skeptical' rather than more confrontational language. The review maintains a balanced tone, acknowledging both strengths and potential weaknesses of the paper."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its novelty and effectiveness, and recommends acceptance. However, they also point out some cons and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges both pros and cons, and offers constructive criticism. They use phrases like 'it would have been good if' rather than more direct criticisms. The reviewer also balances negative points with positive ones, maintaining a professional and courteous tone throughout the review.""]"
"[""This paper introduces a novel architecture for sequence modeling, called the trellis network. The trellis network is in a sense a combination of RNNs and CNNs. The authors give a constructive proof that the trellis network is a special case of a truncated RNN. It also resembles CNNs since the neurons at higher levels have bigger receptive fields. As a result, techniques from RNN and CNN literature can be conveniently brought in and adapted to trellis network. The proposed method is evaluated on benchmark tasks and shows performance gain over existing methods.\n\nThe paper is well-written and easy to follow. The experimental study is extensive. The reviewer believes that this paper will potentially inspire future research along this direction. However, the novelty of the proposed method compared to the TCN seems limited: only weight sharing and input injection. It would be great to include the performance of the TCN on the PTB dataset, on both word and character levels in Table 1 and 2.\n\nAccording to Theorem 1, to model an M-truncated L-layer RNN, a trellis network needs M + L − 1 layers. When M is large, it seems that a trellis network needs to be deep. Although this does not increase to model size due to weight sharing, does it significantly increase computation time, both during training and inference?\n\nThe review might have missed it, but what is the rationale behind the dotted link in Figure 1a, or the dependence of the activation function $f$ on $z_t^{(i)}$? It seems that it is neither motivated by RNNs nor CNNs. From RNN's point of view, as shown in the proof of Theorem 1, $f$ only depends on its first argument. From CNN's point of view, the model still gets the same reception field without using $z_t^{(i)}$.\n\nMinor comments:\nThe authors might want to give the full name of TCN (temporal convolutional networks) and a short introduction in Section 2 or at the beginning of Section 4."", 'The authors propose a new type of neural network architecture for sequence modelling : Trellis Networks. A trellis network is a special case of temporal convolutional network with shared weights across time and layers and  with input at each layer. As stated by the authors, this architecture does not seem really interesting. The authors show that there exists  an equivalent Trellis Network to any truncated RNN and therefore that truncated RNN can be represented by temporal convolutional network. This result is not surprising since  truncated RNN can be  unrolled and that their time dependency is bounded.  The construction of the Trellis Network equivalent to a truncated RNN involves sparse weight matrices, therefore using full weight matrices provides a greater expressive power. One can regret that the authors do not explain what kind of modelling power one can gain with full weight matrices. \n\nThe author claim that bridging the gap between recurrent and convolutional neural networks with  Trellis Network allows to benefit from techniques form both kinds of networks. However, most of the techniques are already used with  convolutional networks.  \n\nExperiments are conducted with LSTM trellis network on several sequence modelling tasks : word-level and character-level language modelling, and sequence modelling in images (sequential MNIST, permuted MNIST  and sequential CIFAR-10). Trellis network yield very competitive results compare to recent state of the art models. \n\nThe ablation  study presented in Annex D Table 5 is interesting since it provides some hints on what is really useful in the model. It seems that full weight matrices are not the most interesting aspect (if dense kernel really concerns this aspect) and that the use if the input at every layer has most impact.\n', 'The authors propose a family of deep architecture (Trellis Networks ) for sequence modelling. Paper is well written and very well connected to existing literature. Furthermore, papers organization allows one to follow easily.  Trellis Networks bridge truncated RNN and temporal convolutional networks. Furthermore, proposed architecture is easy to extend and couple with existing RNN modules e.g. LSTM Trellis networks. Authors support their claims with an extensive empirical evidence. The proposed architecture is better than existing networks.\nAlthough the proposed method has several advantages, I would like to see what makes proposed architecture better than existing methods.\n']","[60, -20, 80]","[80, 20, 70]","[""The sentiment score is 60 (moderately positive) because the reviewer expresses that the paper is well-written, easy to follow, and has extensive experimental study. They believe it will inspire future research. However, they also point out some limitations in novelty and request additional comparisons, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms constructively. They use phrases like 'It would be great to include' and 'The reviewer believes' which maintain a polite tone. The reviewer also asks questions rather than making blunt statements about potential issues, which contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because the reviewer expresses skepticism about the novelty and usefulness of the proposed architecture. Phrases like 'this architecture does not seem really interesting' and 'This result is not surprising' indicate a lack of enthusiasm. However, the reviewer does acknowledge some positive aspects, such as competitive results in experiments, which prevents the score from being more negative. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using neutral language and avoiding harsh criticism. They offer constructive feedback and use phrases like 'One can regret' instead of more direct criticism. The reviewer also acknowledges the interesting aspects of the study, which contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'well written,' 'very well connected to existing literature,' and easy to follow. The reviewer also praises the extensive empirical evidence and states that the proposed architecture is better than existing networks. The only slight criticism is in the last sentence, where the reviewer requests more information on what makes the architecture better, which slightly reduces the score from being maximally positive.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise without being overly effusive and present their request for additional information in a constructive manner ('I would like to see...'). The tone is consistently courteous and appropriate for academic discourse. However, it doesn't reach the highest levels of politeness as it doesn't include explicitly polite phrases or personal warmth, maintaining a more neutral professional tone.""]"
"['The paper proposes a code completion task that given the rest of a program, predicts the content of an expression. This task has similarity to code completion tasks in the code editor of an IDE. The paper proposes an interesting problem, but the paper would benefit if writing and evaluation are significantly improved.\n\nThe work builds on prior research by Allamanis et al. 2018b that performs such completions of single variables by picking from the variables in the scopes. The difference here is that portions of parse trees are predicted as opposed to a single variables, where the algorithm from the prior research is used to predict single variables.\n\nWriting-wise the paper is hard to read on the technical part with many unclear details and this portion needs a good amount of extra explanations. The Epsilon set includes triples which are not described and need understanding equation (2). The first element of this triple is an edge label <edge>($a$, $v$) where $a$ is an AST and $v$ is a node. Thus, edges of the graph end up between entire ASTs and nodes? While I can see how could this make sense, there is certainly lack of explanation going on here. Overall, this part is hard to parse and time-consuming to understand except at high level. Furthermore, the text has many functions without signatures and they seem to be used before they are defined (e.g. getRepresentation).\n\nTechnically, the approach also seems very similar to N3NN by Parisotto et al, ICLR 2017. There should be more elaboration on what is new here. Otherwise, the novelty of the paper really is just combining this work with Allamanis et al. 2018b.\n\nIn terms of evaluation, the task seems to be on a different set of expressions than the one explained in the exposition. How many expressions where there in the evaluation programs and how many were chosen to evaluate on and based on what criteria. It seems from the exposition that expressions with field accessed and function calls are not possible to be generated, but then some completions show method calls. How much of the full task is actually solved? In particular, several of the cited prior works solve specific problems like constants that are ignored here.\n\nThe evaluation is mostly an ablation studies of the proposed approach by removing edges from the final idea. \nBesides this, the paper also introduces a new dataset for showcasing the technique and does not report sizes and running times, essentially not answering basic questions like what is the trade-off between the different techniques. Comparison to actual prior works on similar tasks is also lacking (some TODO is left in the paper), but there is the claim that existing neural techniques such as seq2seq perform ""substantially worse"". I guess the authors have extra experiments not included for lack of space or that the evaluation was not ready at submission time.\n', ""The paper introduces a 'code generation as hole completion' task and associated dataset, ExprGen. The authors proposed a novel extension of AST code generation which uses what they call Neural Attribute Grammars. They show the proposed method does well on this task, compared to ablations of their model (which are similar to previous AST approaches).\n\nThe task and dataset are interesting, and the comparison of the proposed method to baselines seems thorough. \n\n*Details to Improve*\nThe authors have a qualitative evaluation section describing the differences in errors made by various methods. Making this more quantitative by categorizing the errors and computing their frequency would be quite interesting."", 'In this paper, authors propose a conditional generative model which predicts the missing expression given the surrounding code snippet. Authors represent programs as graphs and use some off-the-shelf encoder to obtain representations for all nodes. Inspired from the attribute grammar, authors augment every node in AST with two new nodes which contain inherited and synthesized information. Based on GGNN, a grammar-driven decoder is further proposed to sequentially generate the AST and the corresponding program. Authors also propose a large dataset which is built from open sourced projects. Experimental results on this dataset show that the proposed method achieves better predictive performance compared to several recent work. \n\nStrength:\n\n1, The problem this paper tries to tackle, i.e., building generative models of code, is very challenging and of great significance. \n\n2, The overall model is a novel and successful attempt to incorporate the structure information of the program into neural networks. I think it will be inspiring for other machine learning based programming applications.\n\n3, The results are very promising and impressive, especially given the large size of the proposed dataset. For example, the top 5 accuracy of predicting correct expression on unseen projects is 57%.\n\nWeakness:\n\n1, I think it would be great to provide more statistics of the proposed dataset, e.g., the average number of tokens, the average size of ASTs. \n\n2, Given the dynamic nature of the graph generation process, I am curious about the efficiency of the proposed method. It would be great to provide some run time information. Also, since recurrent networks are heavily used throughout the model, I wonder how difficult the training process is. \n\n3, It would be great to also compare the log likelihood on the test set.\n\n4, It is unclear from the paper that whether authors use a pre-trained GGNN as encoder or train the encoder end-to-end with the decoder from scratch.\n\n5, It would be great to improve figure 2 as it is not easy to read. Maybe draw another graph to illustrate the temporal evolution of AST?\n\nOverall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for ICLR.\n']","[-30, 70, 80]","[20, 80, 70]","[""The sentiment score is -30 because while the reviewer acknowledges that the paper 'proposes an interesting problem', they also point out significant issues with writing, evaluation, and lack of clarity in technical details. The reviewer suggests that the paper 'would benefit if writing and evaluation are significantly improved', indicating a generally negative sentiment. However, it's not entirely negative as they recognize some positive aspects.\n\nThe politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'the paper would benefit if...' and 'there should be more elaboration on...', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects before critiquing, which is a polite approach. However, the score is not higher because the review is quite direct in its criticisms, though not impolite."", ""The sentiment score is 70 (positive) because the reviewer expresses interest in the task and dataset, and notes that the comparison to baselines seems thorough. The overall tone is appreciative of the work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the merits of the work, and offers a constructive suggestion for improvement rather than criticism. The phrase 'Details to Improve' is used instead of a more negative framing, and the suggestion is presented as something that 'would be quite interesting' rather than as a demand or criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, highlighting multiple strengths and recommending acceptance. The overall tone is very positive, with phrases like 'very promising and impressive' and 'great progress'. The politeness score is 70 (polite) due to the constructive and respectful language used throughout. The reviewer offers suggestions for improvement without being harsh, using phrases like 'It would be great to' and 'I am curious about'. The review maintains a professional and courteous tone while providing both praise and constructive criticism.""]"
"['* Summary\nThis paper proposes batch normalization for learning RNNs with binary or ternary weights instead of full-precision weights. Experiments are carried out on character-level and word-level language modeling, as well as sequential MNIST and question answering.\n\n\n* Strengths\n- I liked the variety of tasks used evaluations (sequential MNIST, language modeling, question answering).\n- Encouraging results on specialized hardware implementation.\n\n\n* Weaknesses\n- Using batch normalization on existing binarization/ternarization techniques is a bit of an incremental contribution.\n- All test perplexities for word-level language models in table 3 underperform compared to current vanilla LSTMs for that task (see Table 4 in https://arxiv.org/pdf/1707.05589.pdf), suggesting that the baseline LSTM used in this paper is not strong enough.\n- Results on question answering are not convincing -- BinaryConnect has the same size while achieving substantially higher accuracy (94.66% vs 40.78%). This is nowhere discussed and the paper\'s major claims ""binaryconnect method fails"" and ""our method [...] outperforms all the existing quantization methods"" seem unfounded (Section 5.5).\n- In the introduction, I am lacking a distinction between improvements w.r.t. training vs inference time. As far as I understand, quantization methods only help at reducing memory footprint or computation time during inference/test but not during training. This should be clarified.\n- In the introduction on page 2 is argued that the proposed method ""eliminates the need for multiplications"" -- I do not see how this is possible. Maybe what you meant is that it eliminates the need for full-precision multiplications by replacing them with multiplications with binary/ternary matrices? \n- The notation is quite confusing. For starters, in Section 2 you mention ""a fixed scaling factor A"" and I would encourage you to indicate scalars by lower-case letters, vectors by boldface lower-case letters and matrices by boldface upper-case letters. Moreover, it is unclear when calculations are approximate. For instance, in Eq. 1 I believe you need to replace ""="" with ""\\approx"". Likewise for the equation in the next to last line on page 2. Lastly, while Eq. 2 seems to be a common way to write down LSTM equations, it is abusive notation.\n\n\n* Minor Comments\n- Abstract: What is ASIC? It is not referenced in Section 6.\n- Introduction: What is the justification for calling RNNs over-parameterized? This seems to depend on the task. \n- Introduction; contributions: Here, I would like to see a distinction between gains during training vs test time.\n- Section 3.2 comes out of nowhere. You might want to already mention why are introducing batch normalization at this point.\n- The boldfacing in Table 1, 2 and 3 is misleading. I understand this is done to highlight the proposed method, but I think commonly boldfacing is used to highlight the best results.\n- Figure 2b. What is your hypothesis why BPC actually goes down the longer the sequence is?\n- Algorithm 1, line 14: Using the cross-entropy is a specific choice dependent on the task. My understanding is your approach can work with any differentiable downstream loss?', 'This work proposes a method for reducing memory requirements in RNN models via binary / ternary quantisation. The authors argue that binarising RNNs is due to a covariate shift, and address it with stochastic quantised weights and batch normalisation.\nThe proposed RNN is tested on 6 sequence modelling tasks/datasets and shows drastic memory improvements compared to full-precision RNNs, with almost no loss in test performance.\nBased on the more efficient RNN cell, the authors furthermore describe a more efficient hardware implementation, compared to an implementation of the full-precision RNN.\n\nThe core message I took away from this work is: “One can get away with stochastic binarised weights in a forward pass by compensating for it with batch normalisation”.\n\nStrengths:\n- substantial number of experiments (6 datasets), different domains\n- surprisingly simple methodological fix \n- substantial literature review\n- it has been argued that char-level / pixel-level RNNs present somewhat artificial tasks — even better that the authors test for a more realistic RNN application (Reading Comprehension) with an actually previously published model.\n\nWeaknesses:\n- little understanding is provided into _why_ covariance shift occurs/ why batch normalisation is so useful. The method works, but the authors could elaborate more on this, given that this is the core argument motivating the chosen method.\n- some statements are too bold/vague , e.g. page 3: “a binary/ternary model that can perform all temporal tasks”\n- unclear: by adapting a probabilistic formulation / sampling quantised weights, some variance is introduced. Does it matter for predictions (which should now also be stochastic)? How large is this variance? Even if negligible, it is not obvious and should be addressed.\n\n\nOther Questions / Comments\n-  How dependent is the method on the batch size chosen? This is in particular relevant as smaller batches might yield poor empirical estimates for mean/var. What happens at batch size 1? Are predictions of poorer for smaller batches?\n- Section 2, second line — detail: case w_{i,j}=0 is not covered\n- equation (5): total probability mass does not add up to 1\n- a direct comparison with models from previous work would have been interesting, where these previous methods also rely on batch normalisation\n- as I understand, the main contribution is in the inference (forward pass), not in training. It is somewhat misleading when the authors speak about “the proposed training algorithm” or “we introduced a training algorithm”\n- unclear: last sentence before section 6.\n\n\n\n', 'The paper proposes a method to achieve binary and ternary quantization for recurrent networks. The key contribution is applying batch normalization to both input matrix vector and hidden matrix vector products within recurrent layers in order to preserve accuracy. The authors demonstrate accuracy benefits on a variety of datasets including language modeling (character and word level), MNIST sequence, and question answering. A hardware implementation based on DaDianNao is provided as well.\n\nStrengths\n- The authors propose a relatively simple and easy to understand methodology for achieving aggressive binary and ternary quantization.\n- The authors present compelling accuracy benefits on a range of datasets.\n\nWeaknesses / Questions\n- While the application of batch normalization demonstrates good results, having more compelling results on why covariate shift is such a problem in LSTMs would be helpful. Is this methodology applicable to other recurrent layers like RNNs and GRUs? \n- Does applying batch normalization across layer boundaries or at the end of each time-step help? This may incur lower overhead during inference and training time compared to applying batch normalization to the output of each matrix vector product (inputs and hidden-states). \n- Does training with batch-normalization add additional complexity to the training process? I imagine current DL framework do not efficiently parallelize applying batch normalization on both input and hidden matrix vector products.\n- It would be nice to have more intuition on what execution time overheads batch-normalization applies during inference on a CPU or GPU. That is, without a hardware accelerator what are the run-time costs, if any.\n- The hardware implementation could have much more detail. First, where are the area and power savings coming from. It would be nice to have a breakdown of on-chip SRAM for weights and activations vs. required DRAM memory. Similarly having a breakdown of power in terms of on-chip memory, off-chip memory, and compute would be helpful. \n- The hardware accelerator baseline assumes a 12-bit weight and activation quantization. Is this the best that can be achieved without sacrificing accuracy compared to floating point representation? Does adding batch normalization to intermediate matrix-vector products increase the required bit width for activations to preserve accuracy?\n\nOther comments\n- Preceding section 3.2 there no real discussion on batch normalization and covariate shift which are central to the work’s contribution. It would be nice to include this in the introduction to guide the reader.\n- It is unclear why DaDianNao was chosen as the baseline hardware implementation as opposed to other hardware accelerator implementations such as TPU like dataflows or the open-source NVDLA. \n']","[-20, 50, 50]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer notes some strengths like the variety of tasks used for evaluation, they also point out several significant weaknesses. These include the incremental nature of the contribution, underperforming results compared to baselines, and potentially unfounded claims. The reviewer's tone suggests they are not fully convinced by the paper's approach and results. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames weaknesses as suggestions for improvement rather than harsh criticisms. They use phrases like 'I liked', 'I am lacking', and 'I would encourage you to' which maintain a polite and professional tone even when pointing out issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several strengths of the paper, such as the substantial number of experiments, simple methodological fix, and comprehensive literature review. However, they also point out some weaknesses and areas for improvement, balancing the overall sentiment. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing weaknesses, and framing criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a professional tone, using phrases like 'the authors could elaborate more' instead of more confrontational language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as proposing a 'relatively simple and easy to understand methodology' and presenting 'compelling accuracy benefits'. However, they also list several weaknesses and questions, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions for improvement rather than direct criticisms. Phrases like 'It would be nice to have' and 'It would be helpful' contribute to the polite tone. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach in academic reviews.""]"
"['Summary\n\nThis paper decomposes the image restoration task in two part: the restoration part handled by a restoration RNN, and the number of steps to apply the RNN is determined using a policy unit. \nState of the art results are achieved on blind grey level Gaussian noise denoising on the BSD68 dataset.\n\nThe approach is novel to my knowledge, the paper is well written, the results are good and well illustrated.\n\nQuestions:\n-It would be nice to present results on color images, and on datasets that contains natural noises.  \n-Lowering the learning rate on plateaus during training is done by hand or is there an automatic criterion to define the plateaus?\n\nMinor:\npage 1: extra "")"" after ref to Bredies et al 2010\ncould cite Chen, Zu, Koltun ICCV17 in deep models for restoration\nSeveral ""L"" have been replaced by ""_\' e.g. under review at IC_R, R_-based, etc in the whole paper\np.4: rain-> train\ngreatly influence -> greatly influences\np5: typo performace\nmake a uniform bib: whole first name or abbr. , no URL, etc.\np6: the weight -> the set of weights \nadd the specification that the noise is Gaussian\nthe sentence ""the training set and testing set of ..."" is used twice, remove one.\np7 Table 1: the perf of DnCNN-B is 29.16 and not 29.15 for sigma 25, right?', 'Summary:\n\nThe authors proposes a new image restoration method that becomes particularly useful for blind restoration setting, e.g., the unknown noise variance setting for denoising. They utilized the moving endpoint control methodology, which essentially is applying reinforcement learning to the image restoration, and devised a method that adaptively decides the unfolding steps for given noisy image. The experimental results show encouraging results. \n\nPros:\nIn the experimental result, the proposed DURR outperforms DnCNN-B, a current state-of-the-art. Particularly, while DnCNN-B suffers for the noise level that it was not trained for, DURR can still denoise much better. (Table 2) A similar result is obtained for the JPEG deblocking problem as well. \n\nCons:\n- Since the Deep Q-learning is used to train the policy unit, I suspect the training time could be quite long. How does the reward curve look like while training? How stable is the training? Showing such details should make the paper stronger. \n- It will be interesting to see more details on the model. For example, what is the mean/std for the number of folds that model applies for BSD68? What is the distribution (histogram?) of the folds for BSD68? Currently, the paper just simply shows the results and seems to hide many details. \n- What was the choice for \\lambda in Eq. (3),(4)? How do you choose it?\n- How does the result look like on other benchmark datasets other than BSD68? It seems like the specific number of looks for each noise level is important for training. Do the choices of (25,4),(35,6),(45,9),(55,12) generalize well to other datasets as well?\n\nOverall, I think the paper should add more details mentioned above to make the paper stronger. ', 'The paper proposes a restoration method based on deep reinforcement learning. It is the idea of trainable unfolding that motivates the use of Reinforcement learning, the restoration unit is a SoA U-Net. \n\nRemarks\n\n* The author seems to make strong assumptions on the nature of the noise and made no attempt to understand the nature of the learning beyond a limited set of qualitative example and PSNR. \n\n* Even if the experimental protocol has been taken from prior work, it would have been appreciated to make it explicit in the paper, especially as ICLR is not a conference of image processing. Indeed, It would have made the paper more self-sufficient. \n\n* Second 2 describing the method is particularly hard to understand and would require more details. \n\n* In the experimental section, the authors claim that ""These results indicate that the restoration unit has the potential to generalize on unseen degradation levels when trained with good policies"". It would have been important to mention that such generalization capability seems to occur for the given noise type used in the experiments. I didn\'t see any explicit attempt to variate the shape of the noise to evaluate the generalization capability of the model.\n\nIn conclusion, the paper proposes an interesting method of image denoising through state of the art deep learning model and reinforcement learning algorithm. The main difference with the SoA on the domain is the use of a diffusion dynamics. IMHO, the paper would need more analysis and details on the mentioned section.\n']","[80, 50, -20]","[70, 60, 50]","[""The sentiment score is 80 (positive) because the reviewer states that the paper is novel, well-written, and achieves state-of-the-art results. The reviewer also mentions that the results are 'good and well illustrated'. These are all strong positive indicators. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as questions or polite requests (e.g., 'It would be nice to...'). The reviewer also provides a mix of positive feedback and helpful suggestions for improvement, which is a polite approach to peer review. The minor corrections are presented matter-of-factly without harsh criticism. The overall tone is professional and supportive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as outperforming state-of-the-art methods, while also pointing out areas for improvement. The review begins with a neutral summary and lists both pros and cons, indicating a balanced perspective. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offers constructive criticism, and suggests improvements without harsh criticism. The phrases 'I think the paper should add more details' and 'should make the paper stronger' indicate a supportive tone aimed at improving the work rather than dismissing it."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper proposes an 'interesting method,' they also point out several limitations and areas needing improvement. The reviewer mentions the need for more analysis, details, and explicit explanations in various sections. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'it would have been appreciated' and 'IMHO' (in my humble opinion), which maintain a polite tone while expressing concerns. The reviewer also acknowledges the potential of the method and its interesting aspects, balancing criticism with positive remarks.""]"
"[""This paper trains a neural network to solve the satisfiability problems. Based on the message passing neural network, it presents NeuroSAT and trains it as a classifier to predict satisfiability under a single bit of supervision. After training, NeuroSAT can solve problems that are larger and more difficult than it ever saw during training. Furthermore, the authors present a way to decode the solutions from the network's activations. Besides, for unsatisfiable problems, the paper also presents NeuroUNSAT, which learns to detect the contradictions in the form of UNSAT cores.\n\nRelevance: this paper is likely to be of interest to a large proportion of the community for several reasons. Firstly, satisfiability problems arise from a variety of domains. This paper starts with a new angle to solve the SAT problem. Secondly, it uses neural networks in the SAT problem and establishes that neural networks can learn to perform a discrete search. Thirdly, the system used in this paper may also help improve existing SAT solvers.\n\nSignificance: I think the results are significant. For the decoding satisfying assignments section, the two-dimensional PCA embeddings are very clear. And the NeuroSAT's success rate for more significant problems and different problems has shown it's generalization ability. Finally, the sequences of literal votes in NeuroUNSAT have proved its ability to detect unsatisfied cores.\n\nNovelty: NeuroSAT’s approach is novel. Based on message passing neural networks, it trains a neural network to learn to solve the SAT problem. \n\nSoundness: This paper is technically sound. \n\nEvaluation: The experimental section is comprehensive. There are a variety of graphs showing the performance and ability of your architecture. However, the theoretical analysis isn't very sufficient. For instance, why does the change of the dataset from the original SR(n) to SRC(n,u) lead to the change of the behavior of the network from searching for a satisfying assignment indefinitely to detecting the unsatisfiable cores?\n\nClarity: As a whole, the paper is clear. The definition of the problem, the model structure, the data generation, the training procedure, and the evaluation are all well organized. However, there is still a few points requiring more explanation. For instance, in figure 3, I am not sure whether darker value means larger value or smaller value because the authors only mentioned that white represents zero, blue negative and red positive. Also, in figure 7, I am not sure whether those black grids represent higher positive values or lower negative values.\n\nA few questions:\n\nWhat's the initialization of the two vectors the authors use for tiling operation? Does the initialization differ for different types of SAT problems?\n\nHow do the authors decide the number of iterations necessary for solving a particular SAT problem?\n\n"", 'This paper presents the NeuroSAT architecture, which uses a deep, message passing neural net for predicting the satisfiability of CNF instances. The architecture is also able to predict a satisfiable assignment in the SAT case, and the literals involved in some minimal conflicting set of clauses (i.e. core) in the UNSAT case. The NeuroSAT architecture is based on a vector space embedding of literals and clauses, which exploits (with message passing) some important symmetries of SAT instances (permutation invariance and negation invariance). This architecture is tested on various classes of random SAT instances, involving both unstructured (RS) problems, and structured ones (e.g. graph colorings, vertex covers, dominating sets, etc.).\n\nOverall the paper is well-motivated, and the experimental results are quite convincing. Arguably, the salient characteristic of NeuroSAT is to iteratively refine the confidence of literals voting for the SAT - or UNSAT - output, using a voting scheme on the last iteration of the literal matrix. This is very interesting, and NeuroSAT might be used to help existing solvers in choosing variable orderings for tackling hard instances, or hard queries (e.g. find a core).\n\nOn the other hand, the technical description of the architecture (sec. 3) is perhaps a little vague for having a clear intuition of how the classification task - for SAT instances - is handled in the NeuroSAT architecture. Namely, a brief description of the initial matrices (which encode the literal en clause embeddings) would be nice. Some comments on the role played by the multilayer perceptron units and the normalization units would also be welcome. The two update rules in Page 3 could be explained in more detail. For the sake of clarity, I would suggest to provide a figure for depicting a transition (from iteration t-1 to iteration t) in the architecture. As a minor comment, it would be nice (in Section 2) to define the main parameters $n$, $m$, and $d$ used in the rest of the paper.\n\nConcerning the experimental part of the paper, Sections 4 & 5 are well-explained but, in Section 6,  the solution decoding method, inspired from PCA is a bit confusing. Specifically, we don’t know how a satisfying assignment is extracted from the last layer, and this should be explained in detail. According to Figure 4 and the comments above, it seems that a clustering method (with two centroids) is advocated, but this is not clear. In Table 1, the correlation between the accuracy on SAT instances, and the percent of SAT instances solved is not clear. Is the ratio of 70% measured on the CNF instances which have been predicted to be satisfiable? Or, is this ratio measured on the whole set of test instances? Finally, for the results established in Table 1, how many training instances and test instances have been used?\n\nIn Section 7, some important aspects related to experiments, are missing. In Sec 7.1, for SR(200) tasks, was NeuroSAT tested on the same conditions as those for SR(40) tasks? Notably, what is the input dimension $d$ of the embedding space here? (I guess that $d = 128$ is too small for such large instances). Also, how many training and test instances have been used to plot the curves in Figure 5? For the 4,888 satisfiable instances generated in Sec. 7.2, which solver have been used to determine the satisfiability of those instances (I guess it is Minisat, but this should be mentioned somewhere). \n\nIn Section 8, I found interesting the the ability of NeuroSAT in predicting the literals that participate in an UNSAT core. Indeed the problem of finding an UNSAT core in CNF instances is computationally harder than determining the satisfiability of this instance. So, NeuroSAT might be used here to help a solver in finding a core. But the notion of “confidence” should be explained in more detail in this section, and more generally, in the whole paper. Namely, it seems that in the last layer of each iteration, literals are voting for SAT (red colors) with some confidence (say $\\delta$)  and voting for UNSAT (blue colors) with some confidence (say $\\delta’$). Are $\\delta$ and $\\delta’$ correlated in the neural architecture? And, how confidences for UNSAT votes are updated?\n\nFinally, I found that the different benchmarks where relevant, but I would also suggest (for future work, or in the appendix) to additionally perform experiments on the well-known random 3-SAT instances ($k$ is fixed to 3). Here, it is well-known that a phase transition (on the instances, not the solver/learner) occurs at 4.26 for the clause/variable ratio. A plot displaying the performance of NeuroSAT (accuracy in predicting the label of the instance) versus the clause/variable ratio would be very helpful in assessing the robustness of NeuroSAT on the so-called “hard” instances (which are close to 4.26). By extension, there have been a lot of recent work in generating “pseudo-industrial” random SAT instances, which incorporate some structure (e.g. communities) in order to mimic real-world structured SAT instances. To this point, it would be interesting to analyze the performance of NeuroSAT on such pseudo-industrial instances.\n', 'The paper describes a general neural  network architecture for predicting satisfiability. Specifically, the contributions include an encoding for SAT problems, and predicting SAT using a message passing method, where the embeddings for literals and clauses are iteratively changed until convergence.\n\nThe paper seems significant considering that it brings together SAT solving and neural network architectures. The paper is very clearly written and quite precise about its contributions. The analysis especially figures 3,4, and 7 seems to give a nice intuitive ideas as to what the neural network is trying to do. However, one weakness is that the problems are run on a specific type of SAT problem the authors have created. Of course, the authors make it clear that the objective is not really to create a. State-of-the-art solver but rather to understand what a neural network trying to do SAT solving is capable of doing. On this front, I think the paper succeeds in doing this. One thing that was a little confusing is that why should all the literals turn to SAT (turn red) to prove SAT (as it is shown in figure 3). Is it that the neural network does not realize that it has found a SAT solution with a smaller subset of SAT literals. In other words, is it not capable of taking advantage of the problem structure.\n\nIn general though, this seemed to be an interesting paper though its practical implications are quite hard to know either in the SAT community or in the neural network community.']","[80, 60, 60]","[70, 80, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, highlighting its relevance, significance, novelty, and soundness. They use phrases like 'likely to be of interest', 'results are significant', and 'approach is novel'. The few criticisms are minor and constructive. The politeness score is 70 (polite) as the reviewer maintains a professional and respectful tone throughout. They offer praise where due and frame criticisms as suggestions or questions rather than direct attacks. The language is formal and courteous, with no harsh or rude expressions. The reviewer also acknowledges the authors' work positively, which contributes to the polite tone."", ""The sentiment score is 60 (moderately positive) because the reviewer begins by stating the paper is 'well-motivated' and the results are 'quite convincing'. They describe the work as 'very interesting' and suggest potential applications. However, they also provide several critiques and suggestions for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing critiques as suggestions (e.g., 'I would suggest', 'it would be nice') and acknowledging the paper's strengths. They provide detailed, constructive feedback without harsh criticism, maintaining a professional and courteous tone."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is significant, clearly written, and succeeds in its objectives. They describe the analysis as giving 'nice intuitive ideas' and call it an 'interesting paper'. However, they also mention some weaknesses and uncertainties about practical implications, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'seems significant', 'clearly written', and 'the paper succeeds', which are polite ways of giving positive feedback. Even when pointing out weaknesses, the reviewer does so in a gentle manner, using phrases like 'one weakness is' and 'a little confusing', rather than harsh criticism.""]"
"['The paper addresses the latent space distribution mismatch in VAEs and GANs. The authors try to solve the issue by optimal transport theory and the proposed method on the latent space yields better quality in the generated samples.\n\nTo me, the motivation is not very strong. In DCGAN, amazingly, latent space linear operations can carry over to the generated images. But it’s not something people are usually concerned with in GANs.  I understand that latent space operations can provide insights into how the trained generator works. But how can it improve the actual GAN training? Choosing Gaussian or uniform distribution for the latent variable is mainly for ease of computation and I am not sure if the motivation to match the distributions is very strong in GAN applications. Perhaps it more important in the context of VAEs.\n\nAt the first glance, the proposed form of transformation is not surprising. Though optimal transport is a very powerful theoretical tool, it serves more like an explanation or validation, rather than the motivation. I felt the theory part could be simper. \n\nIn the quantitative comparisons with other methods, all simulations seem to be in the context of GAN. The difference in 2-point cases (table 2) is not significant and the author only compares with linear interpolation but not SLERP. I would like to see more quantitative comparisons with other methods and also some empirical studies in the context of VAEs. ', ""This paper considers the issue of distribution mismatch between the input data used for training generative models and the new data for new instance generation. Given a sample operation, the authors propose to use the so-called optimal transport to map the distribution of the new data to that of the input data that were used training. The optimal transport is essentially a monotonic transformation as the composite of the inverse of the target distribution and the source distribution.\n\nThe paper is in general well written. However, I am concerned with two issues here, which are related to the motivation and performance evaluation, respectively. First, the authors didn't make it clear what data generation of the trained generative model suffers from the distribution mismatch issue, although there was some discussion on this in the literature, as the authors mentioned. To me, once the generative model is successfully trained, it is something like a physical process, and new data, which are contained in the support of the training data, can always be used as input to generate new data. (Personally, I think this is very different from covariate shift correction in domain adaptation, in which the correction is necessary because simpler models, instead of flexible, nonparametric ones, are used to make prediction.) Second, the authors used the Inception Score for performance evaluation. Please give this score in the paper and make its definition clear. To me, it is not surprising at all that the proposed method had a better Inception Score: roughly speaking, when we use interpolated values of the training input data to generate images, the Inception Score is expected to decrease, compared to that evaluated on the training data. Intuitively, a very high Inception Score may indicate that we are not trying to generalize, but just memorize the training input data. An explanation about this point would be highly appreciated."", ""Noticing that widely used latent code interpolations for exploring the generative capabilities of VAEs and GANs have distribution mismatch problems, this paper proposes to utilize monotone transport map to exactly eliminate the distribution mismatch between modified interpolated codes and a prior distribution, assuming I.I.D. code components and a L1 code distance. More precisely, a transformation of the latent space operation is learnt with the objective that the distribution of the transformed variable match the prior distribution used in training the generative models. Optimal transport is used as a measure to minimize the two distributions. By restricting the class of cost functions used in the optimal transport formulation, the solution to the optimal transport problem (and hence the transformation function) has been shown to take a simple form (closed form in cases where cdf has a analytical form). Experiments on CIFAR-10, LLD-icon, LSUN, CelebA datasets show that, the minimally modified interpolated codes for several different interpolations produce samples with higher Inception Scores and better visual effects under an improved Wasserstein GAN than the original interpolated codes.\n\nThis paper is well written, the studied problem is highly important, and the approach presented has potentially wide applications. \n\nHowever, there are some concerns about the experimental evaluations,\n\n1. Although the quantitative evaluations for 2-point and 4-point interpolations are important, it is hard to assess these interpolations in a semantically meaningful way. Extensive quantitative (FID and IS) and qualitative evaluations should be conducted for analogy interpolations. For example, adding glasses, adding mustache, and many others. It is much easier to assess the quality of the generated images from the minimally modified interpolated code for this category in a meaningful way.\n\n2. Another concern is that how big the effect of the transformation function inducing on the latent space operations will be. For example, a linear interpolation is no longer linear after getting transformed. So, are there transformations that drastically transform the original latent space operations? In that case, will the transformed variable make any sense with respect to the original latent space operations? Extensive experiments for analogy interpolations are required to answer these questions.\n\n3. Experiments have been shown only on GAN architectures, however, the framework can be easily extended to VAEs. Experiments on VAEs will be informative.\n\nMinor:\n\nSection 1.1, in the second paragraph, (SLERP) should be moved a correct position.\n\nFigure 2: it's better to use a different color for midpoint linear other than blue\n\nProblem 1, f* ---> f*:""]","[-20, -20, 50]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to address an issue and its potential benefits, they express several concerns and criticisms. The reviewer questions the strength of the motivation, suggests the theory part could be simpler, and points out limitations in the comparisons. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'To me,' and 'I understand,' which soften their criticisms. The reviewer also provides specific suggestions for improvement rather than outright dismissing the work. However, the score isn't higher because the review doesn't include explicitly polite language or praise, maintaining a more neutral, academic tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'in general well written', they express significant concerns about two major issues related to motivation and performance evaluation. The reviewer uses phrases like 'I am concerned' and 'it is not surprising at all', indicating skepticism about some aspects of the paper. However, the tone is not entirely negative, as the reviewer also offers constructive feedback and requests for clarification.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use polite language such as 'Please give this score in the paper' and 'An explanation about this point would be highly appreciated.' The reviewer also acknowledges positive aspects of the paper before presenting their concerns, which is a courteous approach. While expressing criticisms, the reviewer frames them as requests for clarification or further explanation rather than outright dismissals, which contributes to the overall politeness of the review."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the paper as 'well written' and addressing an 'important' problem with 'potentially wide applications'. However, this is balanced by 'some concerns' about the experimental evaluations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'it is hard to assess' and 'another concern is' are used instead of more direct criticisms. The reviewer also offers specific recommendations for improvement, which is a polite way to provide feedback.""]"
"['This paper proposes a variant of GEM called A-GEM that substantially improves the computational characteristics of GEM while achieving quite similar performance. To me the most interesting insight of this work is the proof that an inner product between gradients can suffice instead of needing to solve the quadratic program in GEM – which I have found to be a major limitation of the original algorithm.  The additional experiments using task descriptors to enable zero shot learning are also interesting.  Moreover, the discussion of the new evaluation protocol and metrics make sense with further clarification from the authors. Overall, I agree with the other reviewers that this paper makes a clear and practical contribution worthy of acceptance. \n', 'Summary of the paper:\n\nThis paper focuses on the problem of lifelong learning for multi-task\nneural networks. The goal is to learn in a computationally and memory\nefficient manner new tasks as they are encountered while at the same\ntime remembering how to solve previously seen tasks with a focus on\nhaving only one training pass through all the training data. The paper\nbuilds on the GEM method introduced in the paper ""Gradient episodic\nmemory for continuum learning"", NIPS 2017.\n\nThe main novelty over the original GEM paper is that A-GEM simplifies\nthe constraints on what constitutes a feasible update step during its\nSGD training so that GEM\'s QP problem is replaced by a couple of\ninner-products (and thus makes A-GEM much more computationally\nefficient). This simplification also means that only one gradient\nvector (the average gradient computed from the individual gradients of\nthe task loss of the previously seen tasks) has to be stored at each\nupdate as opposed to GEM where each task specific gradient vector has\nto be stored. Thus the memory requirements of A-GEM is much less than\nGEM and is independent of the number of already learnt tasks.\n\nThe paper then presents experimental evidence that A-GEM does run much\nfaster and uses less memory and results in performance similar to the\noriginal GEM strategy. The latter point is important as the simplified\nA-GEM algorithm - which adjusts the network\'s parameter to improve\nperformance on the current task while ensuring the average performance\non the previously seen tasks should not decrease - does not guarantee\nas stringently as GEM that the network does not forget how to perform\nall the previous tasks.\n\nThe paper also introduces an extra performance metric is introduced\n  called the ""Learning Curve Area"" which measures how quickly a new\n  task is learnt when it is presented with new material.\n\n\nPros and Cons of the paper:\n\n+/- The paper presents a simple intuitive extension to the original GEM\npaper that is much more computationally efficient and is thus more\nsuited and feasible for real lifelong learning applications. And it\nshows that performance exceeds other methods that have similar\ncomputational demands. The paper can be viewed as somewhat incremental\nbut the increment is probably crucial for any real-world practical\napplication.\n\n+ The validity of the approach is demonstrated experimentally on\n  standard datasets in the field.\n\n\n- Some of the presentation of the material is somewhat vague, in\n  particular section 5. In this section a joint embedding model is\n  described that helps facilitate zero-shot learning. However, not\n  enough detail is given to fully understand or appreciate this\n  contribution, see below for details.\n\n\nRationale for my evaluation:\n\nThe method is somewhat incremental, however, this increment could be\nquite practically important. The presentation is lacking in some regard and would benefit\n from some re-working i.e. section 5. \n \n\nUnclear in the paper:\n\nSection 5 describing the ""Joint Embedding Model Using Compositional Task descriptors"" is very sparse on detail.  Here are some of the details that I feel are missing:\n- In the experiments how is the matrix description (via attributes) of the different tasks $t^k$ learnt/discovered?\n- The size of this attribute matrix is able to vary from one task to the next. How does the function $\\psi_{\\omega}$ deal with this problem?\n- What functions are used in the experiments to represent $\\psi_{\\omega}$?\n- In the second last line of paragraph 2 should $C$ be $C_k$? If it should be $C$ how is $C$ chosen?\n- In equation (12) should the $c$th column of $\\psi_{\\omega}$ be extracted as opposed to the $k$th column?\n\nRepresentative labelled samples from each task are stored in memory\nand these are used when learning for a new task. The system\nhas a fixed memory so when a new task is added then the number of\nimages stored for each task has to be reduced. Then uniform sampling is\nused to randomly decide which images to keep. Could this selection\nprocess be improved upon and would any such improvement have any large\nimpact on performance?\n\nTypos and minor errors spotted:\n\nIn the third paragraph of section 2 it is stated $T^{CV} \\ll T$ in the\nexperiments performed this is not case. I don\'t think 3 is much less\nthan 10 or 20.\n\nIn figures 4 and 5 it is not entirely clear which curves correspond to\nA-GEM and A-GEM-JE from the legend. In the legend the dashed line with\nthe triangle looks the same the non-dashed line with the triangle. I\npresuming A-GEM is the non-dashed line, but only because that makes\nthings consistent with the previous figures.', 'The paper is well-written, with the main points supported by experiments.  The modifications to GEM are a clear computational improvement.\n\nOne complaint: the ""A"" in A-GEM could stand for ""averaging"" (over all task losses) or ""approximating"" (the loss gradient with a sample).  Both ideas are good.  However, the paper does not address the question: how well does GEM do when it uses a stochastic approximation to each task loss?  (Note I\'m not talking about S-GEM, which randomly samples a task constraint; rather, approximate each task\'s constraint by sampling that task\'s examples).\n\nAnother complaint: reported experimental results lack any associated idea of uncertainty, confidence interval, empirical variation, etc.  Therefore it is unclear whether observed differences are meaningful.']","[80, 50, 50]","[70, 80, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, describing it as making a 'clear and practical contribution worthy of acceptance'. They highlight several positive aspects, including the improved computational characteristics, interesting insights, and valuable additional experiments. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout. They acknowledge the authors' work positively without using overly effusive praise, and they present their opinions in a constructive manner. The tone is collegial, as evidenced by phrases like 'To me the most interesting insight' and 'I agree with the other reviewers', which show engagement and consideration."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and practical importance, while also pointing out some limitations. The reviewer notes that the method is 'somewhat incremental, however, this increment could be quite practically important.' They also highlight the paper's experimental validation and its superiority to other methods with similar computational demands. However, they mention some presentation issues, particularly in section 5, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance positive feedback with areas for improvement, and phrase criticisms as suggestions or questions rather than harsh judgments. For example, they say 'The presentation is lacking in some regard and would benefit from some re-working' instead of using more negative phrasing. The reviewer also provides detailed, helpful feedback on unclear aspects and even points out typos, which is considerate and aimed at improving the paper."", ""The sentiment score is 50 (slightly positive) because the review starts with a positive statement about the paper being well-written and the modifications being a clear improvement. However, it also includes two complaints, which balance out the initial positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, framing their criticisms as 'complaints' rather than harsh criticisms, and uses phrases like 'the paper does not address' instead of more accusatory language. The reviewer also acknowledges that both ideas in the paper are 'good'. The tone remains professional and constructive throughout, even when pointing out areas for improvement.""]"
"['This paper proposes a novel method to perform meta-learning for stochastic gradient MCMC. They utilize a general family of SDEs that guarantees preservation of the target density with somewhat loose constraint on the drift and diffusion functions (from Ma et al. (2015)). Then, they propose learning these functions on a set of training tasks and evaluating on unseen, different tasks, in a meta-learning fashion.\n\nThis paper is well written and easy to follow. They do a very good job presenting the motivation for their work as well as seminal work in SG-MCMC. The idea is fairly natural, especially in light of recent success of meta-learning and learning optimizers. They do a thorough survey of related work and also do a good job presenting their method in context of very modern work on MCMC and SG-MCMC.\n\nI am not completely convinced by the meta-training objective; both losses seem natural but quite intractable to compute in practice. The use of Stein indicates that the kernel must probably be *very* carefully crafted and given that the whole method relies on this objective, it seems like this could be a breaking point. I am also curious to know how you diagnostic/evaluate the choice of these kernels.\n\nIn terms of evaluation, the experimental results are not the most convincing given that across the board, they are (except in one case) in 4 case within 0.2% of SGHMC and in the two others, within 0.5% and 0.8% respectively. This seems a bit weak, especially considering the compute invested both at training time and for each SG-MCMC step (i.e. getting the outputs from the neural networks vs simply doing HMC). Is there really a case for using the method over SG-HMC? I would have also very much liked to see a run-time evaluation.', 'TITLE\nMeta-learning for stochastic gradient mcmc\n\nREVIEW SUMMARY\nA wonderful paper with many great ideas and insights. Main weakness is the complexity of the algorithms and many design choices wich are well argued for but not theoretically or empirically well founded.  \n\nPAPER SUMMARY\nThe main idea (based on the result of Ma et al.\'s ""complete recipe for stochastic gradient mcmc"") is to parameterize the diffusion and curl matrices by neural networks and (meta-)learn/optimize an sg-mcmc algorithm. \n\nQUALITY\nThe technical quality of the paper appears to be good. Due to the complexity of the algorithm and lack of access to authors code at review time, it is not feasible for me to validate empirical results.\n\nMy main critisism of this work is that the proposed procedure is quite complicated, and there are a lot of steps and design choices that are made in the paper which are not backed up by theory or experiment. For example, the structure and parametrization of D and Q. I would like to have seen e.g. empirical results on full matrices compared to the particular ""diagonal"" struture used, to give an idea of how much we loose by that design choise. Similarly, the choice of meta learning objective is not (to me at least) obvious, and this could be examined further. Also, the use of the Stein gradient estimator is known sometimes to be problematic (maybe particularly with an rbf kernel) but this is not explored.\n\nAll in all, the paper leaves me wanting more, but of course there is only so much space in a conference paper. My conclusion here is that I recommend that the paper is published as it is, and I hope the authors will continue their work in future research (as also outlined in the paper). \n\nCLARITY\nThe paper is clear and well written, notation is consistent, and everything is fairly easy to follow.\n\nORIGINALITY\nThe idea of meta learning sg-mcmc is not something I have seen before, so to my knowledge the idea is original. \n\nSIGNIFICANCE\nI think the whole line of research in which this paper falls has a very high potential, and i strongly welcome any new results. This paper develops new interesting ideas of broad interest.\n', 'In the paper ""Meta-Learning for Stochastic Gradient MCMC"", the authors present a meta-learning approach to automatically design MCMC sampler based on Hamiltonian dynamics to mix faster on problems similar to the training problems. The approach is evaluated on simple multidimensional Gaussians, and Bayesian neural networks (including fully connected, convolutional, and recurrent networks).\n\nMCMC samplers in general, and Hamiltonian Monte Carlo sampler in particular, are very powerful tools to perform Bayesian inference in high-dimensional spaces. Combined with stochastic gradients, methods like Stochastic Gradient MCMC (SGMCMC), or Stochastic Gradient Langevin Dynamics (SGLD) have been successfully used to apply these methods in the large data regime, where only noisy estimates of the gradients are feasible. Even though, many different samplers exists, and they are provably correct (meaning they converge to the correct distribution), fast mixing and low auto-correlation within the chain can heavily depend on the problem at hand and the hyperparameters of the sampler used.  The work presented here, uses the general framework for SG-MCMC samplers of Ma et al., parametrizes it with a neural network and learns its weights on representative training problems.\n\nThe paper is well written, although occasional minor mistakes and typos can be found.\nIt seems however, that the method is still quite laborious and some care needs to be taken to train the meta-sampler.\nThe overall narrative is easy to follow, but could benefit from more detail in certain parts. In general, I argue for acceptance of the paper, but have the following questions/comments:\n\n- Below Eq. (7), an interpretation of the parametrizations Q_f and D_f is given. I greatly appreciate this, but the phrase \'Q_f is\nresponsible for the acceleration of \\theta\' is not really instructive. By definition, the change in \\theta is mostly driven by the momentum p. Therefor, Q_f looks like an inverse mass (at least in the second line of (7)), but maybe that is not a very helpful analogy either.\n- at the beginning of section 3.2, the term \'particles\' is used. While I am fully aware of what that is supposed to mean, a reader less familiar with the topic could be confused, because there is no explanation of it.\n- It is unclear to me how the stochastic estimate \\tilde{U}(\\theta) in equation (10) is computed exactly. Is it estimated using the current mini-batch at time t, or is it estimated using a \'holdout-test set\'?\n- I was wondering how the correlation between the chains due to thinning for the In-chain loss affects the results. The text, does not address this at all.\n- The experiments are very thorough and I appreciate the comparison to the tuned baselines, but I am missing some details in the paper:\n     (a) Did you tune the SGHMC method in Figure 2, as well? It is not mentioned in the text, and the sample path looks very volatile, which could indicate a poor combination of step length and noise.\n     (b) How was the tuning of the base line methods performed?\n     (c) Are the results in Figure 3 based on single runs, or do you show the mean over 10 independent runs (as in table 1).\n- The insets in Figure 6 are helpful, but I think you could shrink the \'outer y axis\' and have the inset in the top right corner instead. That way, the zoomed-out plot would show more details on its own.\n']","[50, 70, 60]","[80, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, good motivation, thorough survey) but also expresses some concerns (not completely convinced by meta-training objective, experimental results not very convincing). The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms as questions or personal opinions (e.g., 'I am not completely convinced', 'I am also curious to know') rather than harsh statements. The reviewer also uses phrases like 'They do a very good job' and 'This paper is well written', which contribute to the polite tone."", ""The sentiment score is 70 (positive) because the review begins with 'A wonderful paper with many great ideas and insights,' indicating a very positive overall impression. The reviewer also recommends publication and expresses hope for future research. However, it's not 100 because the reviewer mentions some weaknesses and criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I would like to have seen' and 'My conclusion here is that I recommend' demonstrate a polite and considerate tone. The reviewer also expresses personal opinions using 'I' statements, which is a polite way to offer feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, recommending acceptance and praising aspects like thorough experiments and well-written content. However, they also point out areas for improvement, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'I greatly appreciate this' and 'I appreciate the comparison', and framing criticisms as questions or suggestions rather than direct criticisms. The reviewer maintains a professional and respectful tone throughout, even when pointing out areas for improvement.""]"
"[""This paper introduces a domain adaptation approach based on the idea of Cyclic GAN. Two different algorithms are proposed. The first one incorporates a semantic consistency loss based on domain-specific classifiers acting on full cycles of the of the generators. The second one also makes use of domain-specific classifiers, but acting either directly on the training samples or on the data mapped from one domain to the other.\n\nStrengths:\n- The different terms in the proposed loss functions are well justified.\n- The results on low-resources supervised domain adaptation indicate that the method works better than the that of Motiian et al. 2017.\n\nWeaknesses:\n- Novelty is limited: The two algorithms are essentially small modification of the semantic consistency term used in Hoffman et al. 2018. They involve making use of both the source and target classifiers, instead of only the source one, and, for the relaxed version, making use of complete cycles instead of just one mapping from one domain to the other. While the modifications are justified, I find this a bit weak for ICLR.\n\n- It is not clear to me why it is worth presenting the relaxed cycle-consistency object, since it always yields worse results than the augmented one. In fact, at first, I though both objectives would be combined in a single loss, and was thus surprised not to see Eq. 5 appear in Algorithm 1. It only became clear when reading the experiments that the authors were treating the two objectives as two different algorithms. Note that, in addition to not performing as well as the augmented version, it is also unclear how the relaxed one could work in the unsupervised scenario.\n\n- Experiments:\n* In 4.1, the authors mention that 10 samples per class are available in the target domain. Are they labeled or unlabeled? If labeled, are additional unlabeled samples also used?\n* In Table 1, and in Table 3, is there a method that corresponds to CyCADA? I feel that this comparison would be useful considering the similarity. That said, I also understand that CyCADA uses both a reconstruction term (as in Eq. 4) and a semantic consistency one, whereas here only a semantic reconstruction term is used. I therefore suggest the authors to also compare with a baseline that replaces their objective with the semantic consistency one of CyCADA, i.e., CyCADA without reconstruction term.\n* In 4.2, it is again not entirely clear if the authors use only the few labeled samples, or if this is complemented with additional unlabeled samples. In any event, does this reproduce the setting used by Motiian et al. 2017?\n* As the argument is that the proposed loss is better than the reconstruction one and that of Hoffman et al. 2018 for low-resource supervised adaptation, it would be worth demonstrating this empirically in Table 2.\n\nSummary:\nThe proposed objective functions are well motivated, but I feel that novelty is too limited and the current set of experiments not sufficient to warrant publication at ICLR.\n\nAfter Response:\nAfter the authors' response/discussion, while I appreciate the additional results provided by the authors, I still feel that the contribution is a bit weak for ICLR.\n"", 'The authors propose an extension of cycle-consistent adversarial adaptation methods in order to tackle domain adaptation in settings where a limited amount of supervised target data is available (though they also validate their model in the standard unsupervised setting as well). The method appears to be a natural generalization/extension of CycleGAN/CyCADA. It uses the ideas of the semantic consistency loss and training on adapted data from CyCADA, but ""fills out"" the model by applying these techniques in both directions (whereas CyCADA only applied them in the source-to-target direction).\n\nThe writing in this paper is a little awkward at times (many omitted articles such as ""the"" or ""a\'), but, with a few exceptions, it is generally easy to understand what the authors are saying. They provide experiments in a variety of settings in order to validate their model, including both visual domain adaptation and speech domain adaptation. The experiments show that their model is effective both in low-resource supervised adaptation settings as well as high-resource unsupervised adaptation settings. An ablation study, provided in Section 4.1, helps to understand how well the various instantiations of the authors\' model perform, indicating that enforcing consistency in both methods is crucial to achieving performance beyond the simple baselines.\n\nIt\'s a little hard to understand how this method stands in comparison to existing work. Table 3 helps to show that the model can scale up to the high-resource setting, but it would also be nice to see the reverse: comparisons against existing work run in the limited data setting, to better understand how much limited data negatively impacts the performance of models that weren\'t designed with this setting in mind.\n\nI would\'ve also liked to see more comparisons against the simple baseline of a classifier trained exclusively on the available supervised target data, or with the source and target data together—in my experience, these baselines can prove to be surprisingly strong, and would give a better sense of how effective this paper\'s contributions are. This corresponds to rows 2 and 3 of Table 1, and inspection of the numbers in that table shows that the baseline performance is quite strong even relative to the proposed method, so it would be nice to see these numbers in Table 2 as well, since that table is intended to demonstrate the model\'s effectiveness across a variety of different domain shifts.\n\nWhile it\'s nice that the model is experimentally validated on the speech domain, the experiment itself is not explained well. The speech experiments are hard to understand—it\'s unclear what the various training sets are, such as ""Adapted Male"" or ""All Data,"" making it hard to understand exactly what numbers should be compared. Why is there no CycleGAN result for ""Female + Adapted Male,"" or ""All Data + Adapted Male,"" for example? The paper would greatly benefit from a more careful explanation and analysis of this experimental setting.\n\nUltimately, I think the idea is a nice generalization of previous work, and the experiments seem to indicate that the model is effective, but the limited scope of the experiments prevent me from being entirely convinced. The inclusion of additional baselines and a great deal of clarification on the speech experiments would improve the quality of this paper enormously.\n\n---\n\nUpdate: After looking over the additional revisions and experiments, I\'m bumping this to a weak accept. I agree with reviewer 3 that novelty is not the greatest, but there is a useful contribution here, and the demonstration of its effectiveness on low resource settings is valuable, since in a practical setting it is usually feasible to manually label a few examples.\n\nI\'m still not convinced by the TIMIT experiments, now that I better understand them, since the F+M baseline is quite strong and very simple to run. It simply doesn\'t seem worthwhile to introduce all of this extra machinery for such a marginal improvement, but the experiment does serve the job of at least demonstrating an improvement over existing methods.', '\nI am putting ""weak accept"" because I think the paper addresses an important problem (domain adaptation) and has an interesting approach.  As the other reviewers pointed out, it\'s maybe not *super* novel.  But it\'s still interesting, and pretty readable for the most part.  \n\nI do question the statistical significance of the TIMIT experiments: TIMIT has a very tiny test set to start with, and by focusing on the female portion only you are further reducing the amount.\n\nSmall point: I don\'t think GANs are technically nonparametric, as the neural nets do have parameters.\n\nI am a little skeptical that this method would have as general applicability or usefulness as the authors seem to think.  The reason is that, since the cycle constraint no longer exists, there is nothing to stop the network from just figuring out the class label of the input (say) image, and treating all the rest of the  information in that image as noise the same way a regular non-cyclic GAN would treat it.  Of course, one wouldn\'t expect a convolutional network to behave like this, but in theory it could happen in general cases.  This is just speculation though.  Personally I would have tended to accept the paper, but I\'m not going to argue with the other reviewers, who are probably more familiar with GAN literature than me.\n\n--\nI am changing from ""marginally above acceptance threshold"" to ""clear accept"" after reading the response and thinking about the paper a bit more.  I acknowledge that the difference from previously published methods is not that large, but I still think it has value as it\'s getting quite close to being a practical method for generating fake training data for speech recognition.\n']","[-60, 20, 60]","[50, 60, 70]","[""The sentiment score is -60 because the review is generally negative, pointing out limited novelty, weaknesses in the experimental setup, and concluding that the contribution is not sufficient for ICLR publication. However, it's not entirely negative as it acknowledges some strengths. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement. They avoid harsh or personal criticisms, instead focusing on the work itself. The reviewer maintains a balanced tone, acknowledging both strengths and weaknesses, which contributes to the politeness of the review."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and effectiveness, they also express several reservations and suggestions for improvement. The review begins positively, noting the method is a 'natural generalization/extension' and that experiments show the model is 'effective'. However, the reviewer also points out areas needing clarification, additional comparisons, and better explanations, particularly for the speech experiments. The update at the end moves to a 'weak accept', which further supports a mildly positive sentiment. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They offer critiques but phrase them as suggestions for improvement rather than harsh criticisms. Phrases like 'It would be nice to see' and 'The paper would greatly benefit from' demonstrate a polite approach to feedback. The reviewer also acknowledges the paper's strengths alongside its weaknesses, showing a balanced and respectful evaluation."", ""The sentiment score is 60 (positive) because the reviewer initially gives a 'weak accept' and later changes to a 'clear accept', indicating overall positive sentiment towards the paper. They mention the paper addresses an important problem and has an interesting approach, despite some concerns. The change from 'marginally above acceptance threshold' to 'clear accept' after reading the response further reinforces the positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and expresses their concerns in a constructive manner. They also show willingness to reconsider their initial assessment, demonstrating respect for the authors' response. The reviewer's tone is professional and courteous, avoiding harsh criticism and instead offering balanced feedback.""]"
"[""This work is concerned with the problem of batch contextual bandits, in which a target contextual bandit policy is optimized on the data generated by a different logging policy. The main problem is to come up with a low-variance low-bias estimator for the value of the target policy. Many of the known techniques are based on an unbiased estimator known as inverse propensity scoring (IPS), which uses the distribution over actions of the logging policy, conditioned on the observed contexts. However, IPS suffers from large variance. The paper's idea is to do a maximum likelihood fit of a simple surrogate policy to the logged data, and then use the conditional distribution over actions of the surrogate policy to compute inverse propensity scores.\nThe theoretical results show that the bias of this estimator vanishes asymptotically, whereas the variance is smaller than IPS. Experiments using known/unknown logging policies on artificial/real-world bandit data show that the IPS scores computed with the proposed technique are empirically better than those computed directly using the logging policy. Moreover, the advantage increases when the distribution extracted from the surrogate policy is used to compute more sophisticated estimators than IPS.\n\nThe off-policy evaluation in contextual bandits is an important problem, and this paper appears to make some progress. However, the theoretical analysis is a bit disappointing, as it does not shed much light on the reasons why using a surrogate policy should help. Some additional discussion would add value to the paper.\n\nThe result about the decrease in variance depends on assumptions that are not clearly justified, and is expressed in terms of abstract quantities that hard to connect to concrete scenarios. In the end, one does not get many new insights from the theory.\n\nIn Assumptions 3.3-3-4, what is the variable w.r.t the asymptotic notations are understood? By that I mean, the variable n such that f(n) = O(g(n)).\n\nThe experiments are competent and quite elaborated. However, the statistical significance of the improvements in Table 1 is unclear.\n\nThe evaluation criterion for the Criteo experiment is unclear. As a consequence it is hard to appreciate the significance of the improvements in this case."", 'Summary:\nThe paper considers the problem of learning from logged bandit feedback, and focuses on the problem of the ratio of the target policy and the logged policy (the basis of algorithms such as inverse propensity scoring). The paper proposes a surrogate policy to replace the logged policy with known parametrization, with a policy obtained by maximum likelihood estimation on the observed data. The authors present theoretical arguments that the variance of the value function estimate is reduced. Empirical experiments show that the surrogate policy can be used to improve IPS and POEM, and also works when the logging policy is unknown.\n\nThe paper analyses an important and interesting problem which is critical to many practical applications today. The proposed solution is modular, and the empirical experiments point to its usefulness. The theoretical analysis, while not fully explaining the proposed approach, provides comfort that there is reduced variance when using the maximum likelihood surrogate.\n\nOverall comments:\n- page 3, Section 3: It is unclear why the assumption that we know the logging policy, as well as its optimal parameter is a sensible one. In particular, the first paragraph seems to indicate that the surrogate policy some somehow the same parameterization and $\\hat{\\beta}$ is in the same space as $\\beta^*$, and just a different parameter. On one hand the authors seem to indicate that they know everything about the logging. On the other hand they seem to want to claim that not knowing the logging policy is ok. What happens when there is a model mismatch between the logging policy and the surrogate policy? Please expand on these two assumptions.\n- page 4, Section 3.1: It might be useful to have a toy example which exactly matches the requirements of Theorem 3.9, such that you can present empirical intuition about the terms in (3.13). In particular: what is the effect of assuming a deterministic reward? How does (3.14) grow? Why is the reduction of MSE greater than $\\xi(n)$?\n- Theorem 3.9: Please present the result that MLIPS is asympotically unbiased explicitly. Furthermore, the current proof of this main theorem should be structured better, so that it can be properly checked.\n\nMinor issues/typos:\n- page 3, above (3.1): In specific, we --> In particular, we\n- Figure 1: the legend is very confusing, making it totally unclear what the text is talking about. Please match text, caption and legend.\n- Section 4.3: please say that the data is the multilabel datasets of Swaminathan and Joachims in Table 1.\n', ""The paper proposes to fit a model of the logging policy that generates bandit feedback data, and use this model's propensities when performing off-policy optimization. When the model is well-specified (i.e. the logging policy indeed lies within the parametric class of models we are fitting), and we use maximum likelihood estimation to fit the model, this approach can yield a lower error when evaluating a policy's performance using off-policy data. The paper then shows how this improved off-policy estimation can also yield better off-policy optimization, and demonstrate this in semi-synthetic experiments.\n\nSpecific Comments:\nEq2.4: Lambda is overloaded (context distribution vs. regularization hyper-parameter).\nEq3.3: E[.] is used before defining it (i.e., E[.] should be interpreted as E_(x,a)~mu(.|beta*) [.])\nEq3.5: I^-1(beta*) makes sense, but the second term E[ d/d beta (S(x,a; beta*)) ] uses a notation that needs to be introduced (you mean || (E[ d/d beta (S(x,a; beta)) ] |_at beta=beta* )^-1 ||).\n\nAfter Eq3.7: It will be instructive to specify some examples of logging policies mu which satisfy these assumptions (and how big the O(.) constants are for those examples).\nSection 3.2: In practical considerations, expected a discussion of how robust things are when the logging policy class is mis-specified (i.e. assuming there is a beta* such that mu(.|beta*) created the data is unlikely to be true).\nFor ML- approaches, was a clipping constant M still used? If so, was it crucial and why?\nLemma D.1: The lemmas in appendix should be accompanied by a proof. E.g. what is C_beta? I don't immediately see why D.3 suggests that the inverse of the Fisher matrix has bounded norm (for instance, if x=0 the inverse is undefined).\n\nGeneral Comments:\nClarity: Good. The paper is easy to follow. Some examples from the Appendix can be moved to the main text (especially to provide a firm grounding for the constants appearing in Section3.1)\nCorrectness: I did not step through Appendix A-C. In Appendix D, there was a questionable claim. The stated theorems in the main text are believable [not surprising that asymptotic bias vanishes when the logging policy model is well-specified].\nOriginality: This builds on several previous works on off-policy optimization in bandit settings, and proposes a simple addition to improve performance.\nSignificance: The paper seems to have missed an opportunity; it can be substantially stronger with a more careful study of when fitting the logging policy will help vs. hurt, and what kinds of regularization or alternatives to maximum likelihood estimation can yield similar improvements (e.g. regularizing propensities close to uniform, ensure no small propensities). ""]","[20, 60, 50]","[50, 70, 75]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem and the paper's contribution, stating it 'appears to make some progress.' However, they express disappointment with the theoretical analysis and request additional discussion. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the competence of the experiments and use phrases like 'Some additional discussion would add value' rather than making demands. The reviewer also asks for clarification on certain points rather than making accusations, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as addressing 'an important and interesting problem' and notes that the proposed solution is 'modular' with empirical experiments showing its usefulness. The theoretical analysis is also praised for providing 'comfort'. However, it's not extremely positive as there are several suggestions for improvement and clarification. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'It might be useful to...' and 'Please expand on...' indicate a polite tone. The reviewer also balances positive comments with areas for improvement, maintaining a professional and courteous approach."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential improvements, while also providing constructive criticism. The review begins with a neutral summary of the paper's approach and findings, followed by specific comments that are mostly focused on clarifications and suggestions for improvement, rather than major criticisms. The general comments are largely positive, noting good clarity and believable theorems, while also suggesting areas for enhancement. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct attacks. The reviewer acknowledges the paper's strengths and uses phrases like 'It will be instructive to...' and 'expected a discussion of...' which maintain a collegial tone. The review also balances critique with praise, demonstrating respect for the authors' work.""]"
"['Summary:\n\nThis paper addresses the computational aspects of Viterbi-based encoding for neural networks. \n\nIn usual Viterbi codes, input messages are encoded via a convolution with a codeword, and then decoded using a trellis. Now consider a codebook with n convolutional codes, of rate 1/k. Then a vector of length n is represented by inputing a message of length k and receiving n encoded bits. Then the memory footprint (in terms of messages) is reduced by rate k/n. This is the format that will be used to encode the row indices in a matrix, with n columns.  (The value of each nonzero is stored separately.)  However, it is clear that not all messages are possible, only those in the ""range space"" of my codes. (This part is previous work Lee 2018.) \n\nThe ""Double Viterbi"" (new contribution) refers to the storage of the nonzero values themselves. A weakness of CSR and CSC (carried over to the previous work) is that since each row may have a different number of nonzeros, then finding the value of any particular nonzero requires going through the list to find the right corresponding nonzero, a sequential task. Instead, m new Viterbi decompressers are included, where each row becomes (s_1*codeword_1 + s_2*codeword2 + ...) cdot mask, and the new scalar are the results of the linear combinations of the codewords. \n\nPros:\n - I think the work addressed here is important, and though the details are hard to parse and the new contributions seemingly small, it is important enough for practical performance. \n - The idea is theoretically sound and interesting.\n\nCons: \n - My biggest issue is that there is no clear evaluation of the runtime benefit of the second Viterbi decompressor. Compressability is evaluated, but that was already present in the previous work. Therefore the novel contribution of this paper over Lee 2018 is not clearly outlined.\n - It is extremely hard to follow what exactly is going on; I believe a few illustrative examples would help make the paper much clearer; in fact the idea is not that abstract. \n - Minor grammatical mistakes (missing ""a"" or ""the"" in front of some terms, suggest proofread.)\n\n', 'This paper presents a new way to represent a dense matrix in a compact format. First, the method prunes a dense matrix based on the Viterbi-based pruning. Then, the pruned matrix is quantized with alternating multi-bit quantization. Finally, the binary vectors produced by the quantization algorithm are further compressed with the Viterbi-based algorithm. It spots the problem of each existing approach and solve the problems by combining each method. The combination is new and the result is encouraging.\n\nI find this paper is interesting and I like the strong results. It is an interesting combination of methods. However, the experiments are not enough to show that the proposed method is really needed to achieve the results. If these are answered well, I\'d be happy to change my evaluation.\n\n1. The method should be compared with other combinations of components. At least, it should be compared with ""Multi-bit quantization only (Xu et al., 2018)"" and ""Multi-bit-quantization + Viterbi-based binary code encoding"".\n\n2. The experiments with ""Don\'t Care"" should go to the experiment section, and the end-to-end results should be present but not the ratio of incorrect bits.\n\n3. Similarly, the paper will become stronger if it has some experimental results that compare quantization methods. In Section 3.3., it mentions that the conventional k-bit quantization was tried and significant accuracy drops were observed. I feel that this is a kind of things which support the proposed method if it is properly assessed.\n\n4. When you say ""slow"" form something and propose a method to address it, I\'d like to see some benchmark numbers. There is an experiment with simulation, but that does not seem to simulate the slow ""sequential sparse matrix decoding process"".\n\nMinor comments:\n\n* It was a bit hard to understand how a matrix is processed through the flowchart in Fig. 1 at first glance. It would help readers to understand it better if it has a corresponding figure which shows how a matrix is processed through the flowchart.', 'The paper proposes two additional steps to improve the compression of weights in deep neural networks. The first is to quantize the weights after pruning, and the second is to further encode the quantized weights.\n\nThere are several weaknesses in this paper. The first one is clarity. The paper is not very self-contained, and I have to constantly go back to Lee et al. and Xu et al. in order to read through the paper.\n\nThe paper can be made more mathematically precise. The input and output types of each block in Figure 1. should be clearly stated. For example, in Section 3.2, it can be made clear that the domain of the quantization function is the real and the codomain is a sequence k bits. Since the paper relies so heavily on Lee et al., the authors should make an effort to summarize the approach in a mathematically precise way.\n\nThe figures are almost useless, because the captions contain very little information. For example, the authors should at least say that the ""D"" in Figure 2. stands for delay, and the underline in Figure 4. indicates the bits that are not pruned. Many more can be said in all the figures.\n\nThe second weakness is experimental design. There are two conflicting qualities that need to be optimized--performance and compression rate. When optimizing the compression rate, it is important not to look at the test set error. If the compression rate is optimized on the test set, then the compressed model is nothing but a model overfit to the test set. The test set is typically small compared to the training set, so it is no surprise that the compression rate can be as high as 90%.\n\nOptimizing compression rates should be done on the training set with a separate development set. The test set should not used before the best compression scheme is selected. Both the results on the development set and on the test set should be reported for the validity of the experiments. I do not see these experimental settings mentioned anywhere in the paper, and this is very concerning. Lee et al. seem to make similar mistakes, and it is likely that their experimental design is also flawed.']","[20, 50, -70]","[60, 80, -20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the work and finds the idea theoretically sound and interesting. However, they also point out significant cons, including lack of clear evaluation of the novel contribution and difficulty in following the content. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, presenting both pros and cons in a balanced manner. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The use of phrases like 'I think' and 'My biggest issue' shows a personal, considerate approach to the review."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper and likes the strong results, but also points out several areas for improvement. The overall tone is constructive rather than overly critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'I find this paper is interesting' and 'I'd be happy to change my evaluation.' The reviewer also frames their suggestions as recommendations rather than demands, using phrases like 'The method should be compared' instead of more forceful language. The minor comments are presented in a neutral, helpful manner."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several weaknesses in the paper, including lack of clarity, mathematical precision, and experimental design issues. The reviewer uses phrases like 'There are several weaknesses' and 'The figures are almost useless,' indicating a strong negative sentiment. However, it's not at the extreme end of the scale as the reviewer does acknowledge the paper's proposal of additional steps to improve compression.\n\nThe politeness score is -20 because while the reviewer is not overtly rude, the language used is quite direct and critical without much attempt to soften the criticism. Phrases like 'The figures are almost useless' and 'this is very concerning' come across as somewhat harsh. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or extremely impolite language, which is why the score is not lower.""]"
"['The submission analyzes parameter averaging in GAN training, positing that using the exponential moving average (EMA) leads to more well-behaved solutions than using moving averages (MA) or no averaging (None). \n\nWhile reading the submission, the intuitively given explanations for using EMA (cycling, mainly) seem reasonable. However, I do not think there is sufficient understanding of the (non-)convergence behavior in real-world GAN settings, and this submission does not contribute much to it.\nThe theoretical underpinnings in Section 3.1 are quite thin, and focus on describing one particular example of a bilinear saddle problem, which is quite far from a typical GAN, as used e.g. in computer vision problems. Although interesting to read, I would not draw any wider-reaching conclusions from this carefully constructed example.\n\nInstead, the submission serves mainly as an experimental study on why EMA works better in some of the tested cases than MA/None. Main quantitative measures are the often-used IS and FID. It is clear from both the provided quantitative values as well as the provided qualitative images that either averaging method is likely better then no averaging.\n\nUnfortunately, IS and FID contradict each other somewhat for EMA vs. MA in Table 2, which is attributed to IS being [more] flawed [than FID]. Neither measure is flawless, however, which diminshes the usefulness of the numeric results somewhat. Well designed human studies may be complicated to set up and costly to conduct, but these could demonstrate additional confirmation of the usefulness of the proposed method.\n\nEMA introduces an additional hyperparameter, beta, which is only discussed very briefly, and only in the context of qualitative results. I missed a more thorough discussion of the impact of beta.\n\nOverall, the submission makes an interesting proposition (usage of EMA during GAN training), but falls short in convincing me that this is a useful thing to do in broader contexts. Overall originality is minor; projected significance is minor to medium.\n\nEDIT: After the rebuttal, resulting in several changes and additions to the paper, I am changing my rating from 5 -> 6.', 'This paper tries to adapt the concept of averaging, well known is the game literature, to GAN training. In a simple min-max example the iterates obtained by gradient method do not converge to the equilibrium of the game but their average does. This work first provides intuitions on the potential benefits of exponential moving average (EMA) on a simple illustrative example and explore the effect of averaging on GAN.\n\nIn think that the approach of this paper is interesting. I particularly like the experiments on Celeb-A (Fig 6 and 7) that seem to show that the averaged iterates change more smoothly (with respect to the attributes of the faces) during the training procedure. Nevertheless, I have some concerns about the claims of the paper and the experimental process.\n\nI\'m surprised by the values of the inception score provided in Table 2 which do not seem to correlate with the sample quality in Fig. 3. Why did not you use the standard implementation of the inception score provided in Salimans et al. [2016]\'s paper ?\n\nI think that the effectiveness of EMA over uniform averaging is a bit overclaimed. \n- From a theoretical point of view uniform averaging works better (at least in your example in 3.1): If you (uniformly) average the periodic orbit you get a converging iterate. Moreover, concerning to this toy example, note that this continuous analysis has been already introduced in [Goodfellow et al., 2016] and the Hamiltonian interpretation has been already provided in [Balduzzi et al. 2018].\nHowever I think that the intuition on the vanishing magnitude of the oscillation provided by EMA is interesting.\n- The continuous dynamics is actually different from the discrete one, I think that an analysis on the discrete case that is used in practice might be more insightful.\n- The comparison with uniform averaging is not fair in the sense that uniform averaging has no hyperparameter to tune: In figure 6 uniform averaging performs better than a not well tuned EMA. A fair comparison would be for instance to propose a parametrized online averaging $\\theta_{MA}^t = \\frac{t - \\alpha}{t} \\theta_{MA}^{t-1} + \\frac{\\alpha}{t} \\theta_t$ and to tune it the same way $\\beta$ is tuned in EMA.\n\nRefs:\nSalimans, Tim, et al. ""Improved techniques for training gans."" Advances in Neural Information Processing Systems. 2016.\nGoodfellow, I. (2016). NIPS 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:1701.00160.\nBalduzzi, David, et al. ""The Mechanics of n-Player Differentiable Games."" ICML (2018).\n\nMinor comments: \n- In the introduction ""gradient vector fields of the game may not be conservative (Mescheder et al. 2017)"" and the related work ""Mescheder et al. (2017) states that a reason for non-convergence is the non-conservative gradient\nvector of the players."": the notion of conservative vs. non-conservative vector field is never mentioned in [Mescheder et al. 2017]. I think you are actually referring to the blog post on that paper https://www.inference.vc/my-notes-on-the-numerics-of-gans/ .\n- In the Related work ""can not""\n- ""In fact, it has recently been established that the smooth (continuous-time) analogues of first order methods such as online gradient descent (follow-the-regularized leader) in bilinear zero-sum games are recurrent (i.e. effectively periodic)\nwith trajectories cycling back into themselves. "" can you provide a citation ?\n- Some published papers are refereed as arxiv paper ( for instance (Mescheder et al. 2017) and (Mescheder et al. 2018)), you should cite the published version.\n', 'The paper evaluates two moving average strategies for GAN optimization. Since exact theoretical analysis is difficult for this case, some informal consideration are provided for explanation of performance gain. Experiments confirmed high performance of averaging.\n\nThe basic idea seems to be reasonable. Moving average-based strategy would stabilize optimization process. \n\nThe obvious weakness of the paper is technical novelty. Although the experimental improvement is confirmed, I would have to say just comparing two known averaging methods would not have strong novelty.\n\nSection 3.1 would be most important part of the paper, but it only mentions quite general tendency of averaging (seems not specific to GAN).']","[-20, 20, -20]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting proposition', 'interesting to read'), they express several criticisms and doubts about the paper's contributions and significance. Phrases like 'falls short in convincing me', 'theoretical underpinnings... are quite thin', and 'projected significance is minor to medium' indicate an overall negative sentiment, though not strongly so. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positives alongside criticisms, and employs phrases like 'Unfortunately' and 'I missed' to soften negative feedback. The tone is professional and constructive, avoiding harsh or rude language."", ""The sentiment score is slightly positive (20) because the reviewer expresses interest in the paper's approach and appreciates certain aspects, particularly the experiments on Celeb-A. However, they also raise several concerns and criticisms, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I think' and 'I'm surprised' rather than making blunt statements. The reviewer also offers constructive feedback and suggestions for improvement, which contributes to the polite tone. The balance of positive comments, constructive criticism, and the use of courteous language justifies these scores."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The basic idea seems to be reasonable', 'Experiments confirmed high performance'), they also point out significant weaknesses ('The obvious weakness of the paper is technical novelty', 'just comparing two known averaging methods would not have strong novelty'). The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses neutral language and softens criticism with phrases like 'I would have to say' and 'seems not specific'. They also acknowledge positive aspects before presenting criticisms, which is a polite approach. The review avoids harsh or rude language, maintaining a professional tone throughout.""]"
"['This paper presents a mixed integer programming technique for verification of piecewise linear neural networks. This work uses progressive bounds tightening approach to determine bounds for inputs to units. The authors also show that this technique speeds up the bound determination by orders of magnitude as compared to other complete and incomplete verifiers. They also compare the advercerial accuracies on MNIST and CIFAR and improve on the lower bounds as compared to PGD and upper bounds as compared to SOA. The paper is well written and presents a valuable technique for evaluating robustness of classifiers to adversarial attacks. \n', 'This paper studies a Mixed Integer Linear Programming (MILP) approach to verifying the robustness of neural networks with ReLU activations. The main contribution of the paper is a progressive bound tightening approach that results in significantly faster MILP solving. This in turn allows for verifying the robustness of larger networks than previously studied, and even larger datasets such as CIFAR-10.\n\nThis paper is a solid contribution and should be accepted to ICLR. It is quite well-written, addresses an important problem using a principled method, and achieves strong experimental results that were previously elusive, despite the large body of work in adversarial learning. In particular, the paper has the following strengths:\n\n- Clarity: the paper is well-written and easy to read. Tables, figures and pseudocode are nice and easy to understand.\n- Methodology: the authors take care of a number of bottlenecks in the scalability of MIP solvers for the verification problem. This is the standard approach in the Operations Research (OR) community, and I am really glad to see it in an ICLR submission!\n- Results: the efficiency of the MIP on the tightened model, and the improvements in the bounds on the adversarial error as compared to very recent methods from the literature are both very strong points in favor of the paper.\n\nI do not have any further questions for the authors - good job!', 'The authors perform a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations. They propose three enhancements to MILP formulations of neural network verification: Asymmetric bounds, restricted domain and progressive bound tightening, which lead to significantly more scalable verification algorithms vis-a-vis prior work. They study the effectiveness of MILP solvers both in terms of verifying robustness (compared to other complete/incomplete verifiers) and generating adversarial attacks (compared to PGD attacks) and show that their approach compares favorable across a number of architectures on MNIST and CIFAR-10. They perform careful ablation studies to validate the importance of the \n\nQuality: The paper is very well written and organized. The problem is certainly of great interest to the deep learning community, given the difficulty of properly evaluating (and then improving) defenses against adversarial attacks. The experiments are done carefully with convincing ablation studies.\n\nClarity: The authors explain the relevant concepts carefully and all the experimental results are clearly written and explained.\n\nOriginality: The authors propose conceptually simple but practically significant enhancements to MILP formulations of neural network verification. However, the novelty wrt https://arxiv.org/pdf/1711.00455.pdf is not discussed carefully in my view (the  asymmetric bounds were already studied in this paper, as well as a novel branch and bound strategy). The progressive bound tightening is a novel idea as far as I can see - however, the ablation experiments show that this idea is not significant in terms of performance improvement. In terms of experiments, the authors indeed obtain strong results on verified adversarial error rates and generate attacks that PGD is unable to - however, again the results do not outperform latest results (in terms of the  best achievable upper bounds on verified error rates) available well before the ICLR deadline - https://arxiv.org/pdf/1805.12514.pdf . It would be great if the authors addressed these issues in a revised version of the paper.\n\nSignificance: The work does establish a strong algorithm for complete verification of neural networks along with several ideas that are critical to obtain strong performance with this approach. \n\nQuestion:\n1. I am unclear on the ""restricted domain"" contribution claimed in the paper - is this just exploiting the fact that the inputs to the classifier are normalized to a given range, in addition to being no more than eps away from the nominal input? \n\nCons\n1. The authors do not compare their approach to that of https://arxiv.org/pdf/1711.00455.pdf , both in terms of conceptual novelty and in terms of experimental results. In particular, it is not clear to me whether the authors\' approach remains superior on domains where tight bounds on the neural networks inputs are not available, like the problems studied in the ACAS system in the ReLuPlex paper.\n\n2. The authors\' MILP solution approach relies on having access to the state of the art commercial MILP solver Gurobi. While Gurobi is free for academic research use, for large scale neural network verification applications, this does restrict use of the approach (particularly due to limited licenses being available). It would be interesting to see a comparison that uses a freely available MILP solver (like scip.zib.de) to see how critical the approach\'s scalability depends on the quality of the MILP solver.\n\n3. The authors do not outperform the latest SOA numbers in terms of verified adversarial error rates on MNIST and CIFAR classifers. It would be good to see a comparison on results from https://arxiv.org/pdf/1711.00455.pdf  (I believe the training code and trained networks are available online).']","[80, 90, 50]","[50, 80, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a clearly positive view of the paper. They describe it as 'well written' and presenting a 'valuable technique'. The reviewer also highlights the paper's contributions, such as speeding up bound determination and improving on lower and upper bounds compared to existing methods. There are no negative comments or criticisms mentioned.\n\nThe politeness score is 50 (slightly polite) because the language used is professional and respectful, without being overly formal or effusive. The reviewer provides a straightforward assessment of the paper's merits without using particularly polite phrases or expressions. The tone is neutral and objective, focusing on the paper's content and contributions rather than on praising the authors directly."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer states that the paper is a 'solid contribution' that 'should be accepted', and highlights several strengths without mentioning any weaknesses. The phrase 'good job!' at the end further reinforces the positive sentiment. The politeness score is 80 because the language used is consistently respectful and encouraging. The reviewer uses phrases like 'I am really glad to see it' and 'good job!', which are polite and supportive. The review maintains a professional tone while being notably positive and courteous throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being well-written, organized, and addressing an important problem. They praise the careful experiments and convincing ablation studies. However, they also point out some limitations, such as lack of comparison to certain prior work and not outperforming state-of-the-art results. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively as suggestions for improvement. They use phrases like 'It would be great if...' and 'It would be interesting to see...' when suggesting changes, maintaining a courteous tone.""]"
"['Paper summary: The paper presents a robust Analysis by Synthesis classification model that uses the input distribution within each class to achieve high accuracy and robustness against adversarial perturbations. The architecture involves training VAEs for each class to learn p(x|y) and performing exact inference during evaluation. The authors show that ABS and binary ABS outperform other models in terms of robustness for L2, Linf and L0 attacks respectively. \n\nThe paper in general is well written and clear, and the approach of using generative methods such as VAE for better robustness is good. \n\nPros: \nUsing VAEs for modeling class conditional distributions for data is an exhaustive approach. The authors show in Fig 4 that ABS generates adversarials that are semantically meaningful for humans, which is not achieved by Madry et al and other models. \n\nCons: \n1) The main concern with this work is that it is heavily tailored towards MNIST and the authors do mention this. Scaling this to other datasets does not seem easy. \n2) Using VAEs to model the conditional class distributions is a nice idea, but how does this scale for datasets with large number of classes like imagenet? This would result in having 1000s of VAEs. \n3) It would be nice to see this model behaves for skewed datasets. \n\n', 'In this paper, the authors argued that the current approaches are not robust to adversarial attacks, even for MNIST. They proposed a generative approach for classification, which uses variational autoencoder (VAE) to estimate the class specific feature distribution. Robustness guarantees are derived for their model. Through numeric studies, they demonstrated the performance of their proposal (ABS). They also demonstrated that many of the adversarial examples for their ABS model are actually meaningful to humans, which are different from existing approaches, such as SOTA.\n\nOverall this is a well written paper. The presentation of their methodology is clear, so are the numerical studies.\n\nSome comments:\n1) it was not very clear to me that the authors were estimating the p(x) for each y. The transition from p(x|y) to p(x) at the end of page 3 was astute and confused me. The authors should make it more clear.\n2) it would be beneficial if the authors could comment on the how strict/loose the lower bound of (2) is, as it is critical in estimating the class specific density.', 'This paper shows that the problem of defending MNIST is still unsuccessful. It hereby proposes a model that is robust by design specifically for the MNIST classification task. Unlike conventional classifiers, the proposal learns a class-dependent data distribution using VAEs, and conducts variational inference by optimizing over the latent space to estimate the classification logits. \n\nSome extensive experiments verify the model robustness with respect to different distance measure, with most state-of-the-art attacking schemes, and compared against several baselines. The added experiments with rotation and translation further consolidate the value of the work. \n\nOverall I think this is a nice paper. Although being lack of some good intuition, the proposed model indeed show superior robustness to previous defending approaches. Also, the model has some other benefits that are shown in Figure 3 and 4. The results show that the model has indeed learned the data distribution rather than roughly determining the decision boundary of the input space as most existing models do.\n\n\nHowever, I have the following comments that might help to improve the paper:\n\n1. It would be more interesting to add more intuition on why the proposed model is already robust by design. \n\n2. Although the paper is designed for MNIST specifically, the proposed scheme should apply to other classification tasks. Have you tried the models on other datasets like CIFAR10/100? It would be interesting to see whether the proposal would work for more complicated tasks. When the training data for each label is unbalanced, namely, some class has very few samples, would you expect the model to fail?\n\n3. Equation (8) is complicated and still model-dependent. Without further relaxation and simplification, it’s not easy to see if this value is small or large, or to understand what kind of message this section is trying to pass. \n\n4. Although the main contribution of the paper is to propose a model that is robust without further defending, the proposed model could still benefit from adversarial training. Have you tried to retrain your model using the adversarial examples you have got and see if it helps?\n']","[50, 70, 70]","[70, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with a neutral summary of the paper, followed by a statement that the paper is 'well written and clear,' and the approach is 'good.' They also list some pros before mentioning cons, indicating a generally positive view despite some criticisms. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'concerns' rather than harsh judgments. They use phrases like 'it would be nice to see' when suggesting improvements, which is a polite way to offer feedback. The reviewer also balances positive and negative comments, which contributes to a courteous tone."", ""The sentiment score is 70 (positive) because the reviewer starts by stating it's a 'well written paper' and praises the clear presentation of methodology and numerical studies. The overall tone is appreciative and constructive. However, it's not 100 as there are some critiques mentioned. The politeness score is 80 because the language used is respectful and constructive throughout. The reviewer uses phrases like 'it would be beneficial' and 'the authors should' which are polite ways of suggesting improvements. The critiques are presented as 'comments' rather than demands, maintaining a courteous tone. The score isn't 100 as there's room for even more politeness, but it's certainly well above neutral."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'nice' and highlights its strengths, such as showing superior robustness and learning data distribution effectively. The overall tone is appreciative, although there are some suggestions for improvement. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and framing suggestions as questions or possibilities rather than demands. The reviewer acknowledges the paper's value and uses phrases like 'I think' and 'it would be interesting' to soften their recommendations, maintaining a courteous and professional tone.""]"
"[""This paper seeks to answer the question of whether models which process sequences, but are not strictly classical RNNs, are Turing complete.\n\nThe authors present proofs that both the Transformer and Neural GPU are turing complete, under certain conditions. I do not consider myself qualified to properly verify the proof but it seems to be presented clearly. The authors note that the conditions involved are not how these models are used in the real world. Given the complex construction required for this more theoretically based proof, it seems reasonable that this should be published now, rather than waiting until the further work discussed in the final section is completed.\n\nI have a number of questions where if a brief answer is possible, this would enhance the manuscript. The main question is, of the simplifications and approximations used for the proof, how much does that take the model away from what is used in practice? For example, the assumption of the piecewise linear sigmoid seems like a quite big change, as there are large regions of the space which now have zero gradients. If you run a real implementation of these models, with the normal sigmoid replaced by this one, does training still work? If not, what are the implications for the proof?\n\nThe rational numbers assumption is interesting - again I wonder how this would affect the model in reality, obviously all floating points on a computer represent rationals, but it would be interesting to get a better understanding on how the lack of infinite precision rationals on real hardware affects the main results.\n\nDoes the proof rely on the input and output dimensionality being the same? Eg in the preliminaries, x_i and y_i are both d-dimensional - could this be changed?\n\nOverall this paper is novel and interesting, I have to give a slightly low confidence score because I'm unfamiliar with a lot of the background here (eg the Siegelamnn & Sontag work). The paper does seem concise and well written.\n\ntypos and minor points:\n\nCircular convolution definition only appears to define the values directly adjacent to the border, would it be more appropriate to define S_{h+n, :, :} = S{n, :, :}?\n\nparagraph above equation 5, 'vectores' -> 'vectors'"", 'This paper presents interesting theoretical results on Turing completeness of the Transformer and Neural GPU architectures, as modern architectures based on attention and convolutions, under particular assumptions. The basis of proofs in the paper relies on Turing completeness of the seq2seq architecture, which is Turing complete since it contains Turing complete RNNs. Turing completeness of the Transformer and the Neural GPU is proven by showing they can simulate seq2seq architecture.\n\nThe Transformer, using additive hard attention and residual connections, is Turing complete in the case when positional encoding is used. Otherwise, if no positional encoding is used, the model is order-invariant which makes it not Turing complete.\n\nA version of the Neural GPU, dubbed Uniform Neural GPU is proven to be Turing complete. Moreover, the presented theoretical results are backed by a recent publication by Karlis and Liepins. Interestingly, Neural GPUs using circular convolutions are not Turing complete, while the ones using zero padding are.\n\nThe repercussion of the paper for similar architectures is the not just in the theoretical section but also in a set of discoveries of practical importance, like the importance of the use of residual connections, positional coding in Transformers, and zero padding in Neural GPUs.\n\nAlbeit the paper presents an original and significant theoretical progress and is well written, it is not fit for ICLR, primarily as the paper is impossible to review and verify without a thorough perusal and analysis of the appendix. Although the results and the proof sketches fit the body of the paper, the necessity of verifying proofs makes this paper 23 pages long and makes it a better fit for a journal and not a conference.', 'The paper shows Turing completeness of two modern neural architectures, the Transformer and the Neural GPU. The paper is technically very heavy and gives very little insight and intuition behind the results. Right after surveying the previous work the paper starts stacking definitions and theorems without much explanations.\n\nWhile technical results are potentially quite strong I believe a major revision to the paper might be necessary in order to clarify the ideas. I would even suggest to split the paper into two, one about each architecture as in the current form it is quite long and difficult to follow. \n\nResults are claimed to hold without access to external memory, relying just on the network itself to represent the intermediate results of the computation. I am a bit confused by this statement -- what if the problem at hand is, say EXPSPACE-complete? Then the network would have to be of exponential size (or more generally of arbitrary size which is independent of the input). In this case the claim about not using external memory seems to be kind of vacuous as the network itself has unbounded size. The whole point of Turing-completeness is that the program size is independent of the input size so there seems to be some confusion here.\n']","[60, 50, -20]","[80, 75, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'novel and interesting' and recommends publication, despite some reservations. They describe the proof as 'presented clearly' and the paper as 'concise and well written'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I do not consider myself qualified to properly verify the proof'), and frames criticisms as questions or suggestions for improvement rather than direct criticisms. The reviewer also provides constructive feedback and points out typos in a helpful manner. The slightly lower confidence score mentioned is explained politely as due to the reviewer's unfamiliarity with some background, not as a fault of the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting theoretical results, original and significant theoretical progress, and well-written nature. However, they also state that it's not fit for ICLR due to its length and the necessity of verifying proofs in the appendix. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before providing constructive criticism. They use phrases like 'interesting theoretical results,' 'original and significant theoretical progress,' and 'well written' before explaining why it might not be suitable for the conference. The reviewer maintains a professional and courteous tone while providing both positive feedback and suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential strength of the technical results, they express significant concerns about the paper's clarity, structure, and some conceptual issues. The reviewer suggests major revisions and even splitting the paper into two, indicating substantial dissatisfaction with the current form. However, the score is not deeply negative as the reviewer still recognizes the potential value of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'I believe' and 'I am a bit confused' to soften their critiques, and offer constructive suggestions for improvement rather than outright dismissal. The tone is professional and considerate, even while pointing out significant issues with the paper.""]"
"['Summary: the authors propose a new algorithm, APL, for a few-shot and a life-long learning based on an external memory module. APL uses a surprise-based signal to determine which data points to store in memory and an attention mechanism to the most relevant points for prediction. The authors evaluate APL on a few-shot classification task on Omniglot dataset and on a number analogy task.\n\nQuality: the authors consider interesting approach to life-long learning and I really liked the idea of a surprise-based signal to choose the data to store. However, I am not convinced by the learning setting that authors study. While a digit-symbol task from the introduction is interesting to study the properties of APL, I fail to see any real world analogy where it is useful. The same happens in a few-shot omniglot classification. The authors decided to shuffle the labels within episodes that, I guess, is supposed to represent different tasks in a typical life-long learning scenario. Again, it maybe interesting to study the behaviour of the algorithm, but I don\'t see any practical relevance here. It would make more sense to study the algorithm in a life-long learning setting, for example, considered in [1] and [2].\n\nClarity: the paper is well-written in general. I failed to decode the meaning behind the paragraph under Figure 3 on page 4 and would advise the authors to re-write it. The same goes to the first paragraph on page 3.\n\nOriginality: the paper builds on the prior work of Kaiser et al., 2017 and Santoro et al., 2016, but the proposed modifications are novel to my best knowledge.\n\nSignificance: below average: the paper combines interesting ideas that potentially can be used in different learning contexts and with other algorithms, however, the evaluation does not show the benefit in an obvious way.\n\nOther comments: \n* throughout the whole paper it is not clear if the embeddings are learned or not. I suppose they are, but what then happens to the ones in memory? If they are not, like in ImageNet example, where do they come from?\n* the hyperparameter \\sigma: the authors claim ""the value of \\sigma seems to not matter too much"". Matter for what? It\'s great if the performance is stable for a wide range of \\sigma, but it seems like it should have a great influence over the memory footprint of APL. I feel this is an important point that needs more attention.\n* it would be interesting to see how APL performs with a simple majority vote instead the decoder layer. This would count for an ablation study and could emphasize the role of the decoder.\n* Figure 4, b) plots are completely unreadable on black-and-white print, the authors might like to address that\n* In conclusion, the first claim about state-of-the-art accuracy with smaller memory footprint: I don\'t think that the results of the paper justify this claim.\n\n[1] Yoon et al, Lifelong Learning with Dynamically Expandable Networks, ICLR 2017\n[2] Rebuffi et al,  iCaRL: Incremental Classifier and Representation Learning, CVPR 2017\n\n********************\nAfter authors response:\n\nThanks to the authors for a detailed response. The introduction led me to believe that the paper solves a different task from what it actually does. I still like the algorithm and, given that the scope of the paper is limited to a few-shot learning, I tend to change my evaluation and recommend to accept the paper. It was a good idea to change the title to avoid possible confusion by other readers. The introduction is still misleading though. It creates the impression that APL solves a more general problem where it would be good enough to limit the discussion to a few-shot learning setting and explain it in greater detail for an unfamiliar reader. Some details also seem to be missing, e.g. I didn\'t get that the memory is flushed after each episode and could not find where this is mentioned in the paper.', 'In this paper, authors present an algorithm to generalize learned properties from few observations by using a memory store and a memory controller. The experiments show comparable results on few-shot classification task and better performance and scalability for when the number of labels is unknown .\n\n- The paper is well-written and easy to follow in general. The notations and model specifications are clear. \n\n- The idea of incorporating an external memory store to save previous experiences is interesting especially without the need to backpropagate through the memory at each step. It is done by alignment of a query with the embeddings that are stored in the memory using k-nearest neighbor with Euclidean distance measures.  However, I am not quiet sure about how this is done in practice. It is stated in the paper that this alignment needs to emerge as a byproduct of training which is achieved by getting optimized to be as class-discriminative as possible. Isn\'t this implicitly optimizing part of the memory? I think more clarification would help a lot in understanding of this part.\n\n-  I liked using a memory controller that decides whether a point is \'surprising\'. Authors defined surprise to be negative log of prediction for label. I was wondering if they considered other measures, and investigated the effects that they might have. I think a brief discussion would be helpful.\n\n- I am not an expert in this area but the experiments look convincing in general. Results in table one corresponding to 423-way are convincing since the proposed algorithm is the only candid that is able to perform the task with relatively good performance. On imagenet data set, the results are comparable to Inception-ResNet-v2 for fixed label case. However, more in-depth experiments or settings such as top-5 accuracy are needed to justify the performance of algorithm on this data set.  For the number analogy task the algorithm performs well in achieving high accuracy.\n\n- Title of the paper is too generic. From the looks of it, adaptive posterior learning should cover wider set of tasks or probabilistic models, but it does not. So to avoid confusion (and the expectation that comes with this name), I strongly suggest that the authors change the title or make it more specific to actually represent what is discussed in the paper.\n\n- In figure 4 c, I think x label should be ""class number"" not ""number of classes"". ', 'The paper proposes a novel model that reads in information, decide whether this information is surprising and hence whether or not to keep it in memory and also utilizing information in the memory to quickly adapt or reason. The authors experimented with few-shot Omniglot classification and meta learning reasoning tasks. \n\nNovelty:\n\nThe authors introduced a novel self-contained model that decides what to write to the external memory and making use of the external memory for different tasks.\n\nMy comments are mostly as follows: \n\n1. The paper is well written, the problems are clearly stated, the solution is presented in a clear way, overall very easy to follow.\n\n2. This is an interesting paper that combines a novel technique for writing to external memory based on surprisal and using it for more difficult tasks such as deductive reasoning.  I really like the surprisal mechanism, there are cognitive/ neuroscience materials that supports this approach (that the brain tends to write to memory things that are surprising). This also makes total sense from a machine learning perspective. \n\n3. Could another objective  be used for surprisal? Also, instead of a determinstic encoder, decoder, is it possible to use a variational objective?\n\n4. The experiments look convincing.\n\nOverall a very nice paper, nice idea, could show more resul']","[-20, 50, 90]","[60, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting approach', 'liked the idea'), they express significant doubts about the practical relevance and significance of the work. The reviewer states they are 'not convinced' by the learning setting, don't see 'practical relevance', and rate the significance as 'below average'. However, the score isn't deeply negative because the reviewer does find some value in the ideas presented. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges positive aspects, and provides constructive feedback. They use phrases like 'I really liked', 'it's great if', and thank the authors for their response. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. The language is professional and objective, avoiding any harsh or personal criticisms."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being well-written, presenting interesting ideas, and showing convincing experiments. However, they also point out areas for improvement and clarification. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'I liked' and 'I think more clarification would help,' and the balance of positive feedback with suggestions for improvement. The reviewer maintains a respectful and professional tone throughout, even when suggesting changes or expressing uncertainty."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer uses phrases like 'novel model', 'interesting paper', 'very nice paper', and 'nice idea'. They also mention that the paper is well-written, clear, and easy to follow. The only slight criticism is the suggestion that more results could be shown, but this is presented as a minor point. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout. They offer constructive suggestions rather than harsh criticisms, and use phrases like 'I really like' to express approval. The tone is professional and courteous, without being overly formal or effusive.""]"
"['This paper empirically explores heuristics commonly used in deep learning: learning rate restarts, warmup and distillation. The authors utilize two recently proposed tools for neural network analysis: mode connectivity (MC) finding a low loss pathway between two given points in the space of DNN parameters and CCA measuring the correlation of  DNN layer activations. Conducting a set of experiments and analyzing the results the authors refine the intuition behind the considered heuristics and dynamics of corresponding training procedures. \n\nStrengths:\n\n+ The authors conduct experiments ensuring robustness of MC framework.\n+ In the chosen settings the experimental methodology of the paper sounds reasonable. I find the idea of DNN analysis from both perspectives of weight space and activations important.\n+ Paper is well-written and organized clearly. All the used methods and experiments are adequately described.\n+ The authors draw connections between obtained results and hypotheses introduced in prior work.\n\nWeaknesses:\n\n- There is a possible flaw in the choice of experimental settings. Authors mention Batch Normalization (BN) among heuristics widely used in deep learning. It is known that properties of both loss surface and activations are different between DNN architectures which include BN layers and those which do not. To emphasize generality of obtained results, it would be beneficial to conduct experiments for both types of DNN architectures as at the moment the majority of the results are presented for VGG architecture which typically does not include BN. Impact of other architecture modifications (e.g. skip connections) might be considered as well.\n\n- I find the significance of the results unclear. Although the particular insights of the learning procedures are revealed there is not enough attention paid to their value for possible improvements of the procedures and their applications. There is only one idea proposed by the authors based on the experimental results – fixing the deeper layers during the warmup phase, but the practical implications of this idea are not discussed.\n\nOther comments:\n\n* The scale used in Figure 3 and similar figures in the appendix is not easily comprehensible. I recommend to comment further on the scale or possibly adjust it.\n', ""Summary:\nThis paper uses the recently proposed techniques of mode connectivity and CCA to analyze two different popular heuristics in deep learning: \n(1) SGDR (stochastic gradient descent with restarts/cosine annealing of learning rate) \n(2) Learning rate warmup\n(3) Model distillation\n\nFor (1) they visualize 1d and 2d slices of the loss surface either using mode connectivity, or parameter points immediately before restarts to try and understand if the parameters sit in different local minima. For (2), they study the effect of learning rate warmup using CCA, coming to the conclusion that learning rate warmup helps stabilize the fully connected layers. (3) They also study model distillation with CCA, finding out that the higher layers are the most similar to the teacher model. \n\nClarity: The paper is clearly written, cites lots of relevant work, and describes the experiments in detail.\n\nOriginality: This paper seems original, while the techniques used are established, they conduct thorough experiments on phenomena in deep learning that haven't been studied.\n \n\nComments on Significance and Quality:\nI liked parts (2), (3) of the paper most, as it seemed like conclusions from these parts were fairly clear: \n\nFigures 4, 5 make the effect of warm restarts in the large batch setting on FC layers clear: the restarts help the layers stabilize better. I really liked the experiment in 4(d), where they tested this hypothesis by freezing the fully connected layers for the duration of the warmup.  It was interesting to see that this had no effect on the remainder of the trajectory. This seemed to be a good demonstration and investigation of the effect of warm restarts, and I appreciate the tests on different architectures in the supplementary material. I'd be curious to see if there's some way to further incorporate this into learning rate schedules.\n\nI also liked Figure 6, exploring Model distillation, which showed that the higher layers of the shallower network were the most affected by the teacher network. The authors cite related work which suggests only training higher layers, and I'd be curious to see how only training higher layers affects accuracy.\n\nWhile I thought the experiments for part (1) SGD with Restarts were thorough, and appreciated Figure 1, which experimentally validated the use of mode connectivity, I felt there was some difficulty in interpreting the results. \n\nFirstly, in Figure 2, the claim is that SGD with Restarts does possibly bridge local minima as the mode connectivity curves increase between the two convergence points. However, we see in both 2(b) and 2(c) that the linear interpolation between both convergence points does *not* increase in loss. In which case is there any reason to believe that the increase of MC in the middle means that SGDR is climbing a basin? How do we know that the linear combination isn't closer to the path followed by SGDR? \n\nFor additional comparisons, it would be good to have the linear combination plots for Figure 1 also.\n\nIn general, it seems hard to make meaningful conclusions with low dimensional projections of a very high dimensional loss surface. We'd have to know some kind of theoretical property of MC to be able to do so.\n\nMinor Comments\n\nI think the figures in this paper could be much clearer. In Figure 2 for example, the legend blocks some of the main areas of interest of the plot. I would recommend cutting some of the raw learning rate figures and making all figures much bigger.\n\nIn figure 4(d), the text describes the process in training steps (200 training steps), but the plot is in epochs -- it would be better if the text and axis were consistent in units.\n\nConclusion:\nDespite my concerns on the first part of this paper, I think the very thorough experiments, clear presentation and the interesting results on learning rate warmups and model distillation merit its acceptance. \n\n\n"", 'In this paper, authors propose a set of  control experiments in order to get a better understanding of different deep learning heuristics: stochastic gradient with restart (SGDR),  warmup and distillation. Authors leverage the recently proposed mode connectivity (which fits a simple piecewise linear curve to obtain a low loss path that connect two points in parameter space) and CCA is a way to compute a meaningful correlation of the networks activations. All the experiments are done using a VGG-16 networks on CIFAR10.\n\nFor SGDR, authors observe that the solutions found by SGDR or SGD does not appears to be in different basins. While this contradict previous claim, it goes in the same direction than recent works which  have similar observations for the small batch/large batch case [1]. Authors also identify that warmup tends to avoid large change the top-layers at the beginning of training and that you can achieve similar effect than warmup by freezing the top-layer. Finally authors show that most of the benefit of distillation happen by impacting the last deep layers of a network.\n \nWhile I find all those findings valuable, it is not straightforward to see how they connect to a better understanding of training deep network and how significant they are. In particular,  it is still unclear to me why heuristics such as SGDR is successful in practice or why freezing the top layer of a network improve trainability in a large batch setting?\n\nDoing control experiments in order to better understand the current practice in deep learning is extremely important, however, I don’t think that the paper in its current shape is ready for publication. \n\n[1] Empirical Analysis of the Hessian of Over-Parametrized Neural Networks (Sagun et al., 2017).\n\n\n']","[50, 70, -20]","[80, 80, 50]","[""The sentiment score is 50 (slightly positive) because the review begins by highlighting the paper's strengths, including robust experiments, reasonable methodology, clear organization, and connections to prior work. However, it also points out significant weaknesses, such as potential flaws in experimental settings and unclear significance of results. This balance of positive and negative feedback suggests a moderately positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms constructively. Phrases like 'I find' and 'It would be beneficial' soften the critique, while the 'Strengths' and 'Weaknesses' structure provides a balanced and professional tone. The reviewer also offers suggestions for improvement, which is a polite way to address shortcomings."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, particularly praising parts (2) and (3), and recommends acceptance despite some concerns about part (1). The reviewer uses phrases like 'I liked', 'I really liked', and 'I appreciate', indicating a positive sentiment. The politeness score is 80 (polite) because the reviewer maintains a respectful and constructive tone throughout. They offer specific praise, provide detailed feedback, and phrase criticisms as suggestions or areas for improvement rather than harsh judgments. The use of phrases like 'I'd be curious to see' and 'it would be good to have' further contribute to the polite tone. The reviewer also acknowledges the paper's strengths even while pointing out areas for improvement, which is a hallmark of polite academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the value of the findings, they express concerns about the paper's readiness for publication and its ability to provide a clear understanding of deep network training. The reviewer states, 'I don't think that the paper in its current shape is ready for publication,' which indicates a negative overall sentiment. However, the reviewer also mentions 'I find all those findings valuable,' which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the importance of the work ('Doing control experiments in order to better understand the current practice in deep learning is extremely important') and framing criticisms as personal observations ('it is not straightforward to see', 'it is still unclear to me') rather than direct attacks. The reviewer also provides constructive feedback and references to support their points, which contributes to the polite tone.""]"
"['This paper focuses on multi-choice QA and proposes a coarse-to-fine scoring framework. Where the coarse-grained answer scoring model computes the scores with the attention over the whole passages, and the fine-grained one only uses local contexts for each answer option (candidate).\n\nThe proposed approach was evaluated on the only dataset of WikiHop, and achieved large improvement over the other methods on the leaderboard. However, I found the paper lack of motivation about the designs of the coarse and fine scoring models. For example, why using self-attention after GRU and co-attention in the two answer scoring models?\n\nAnother concern I have is about the novelty. Besides the complicated model designs, the coarse and fine scoring models are both following some common ideas in previous work. And each model could achieve on-par results compared to previous baselines. This makes me feel that the whole approach looks more like model combination of two not-so-novel (and not very well-motivated) models.\n\nThirdly, the only evaluation on WikiHop brings more problems to the above two points. Since the motivation of the architecture design is not very clear, I am not sure whether the architectures could generalize to other benchmarks. Similar concern for the model combination approach.\n\nMoreover, the proposed approach is a general architecture for multiple-choice datasets requiring multiple evidence. To verify its generalizability, I suggest the authors add further experiments on one dataset from the following ones: either multi-choice QA datasets like ARC and RACE/RACE-open, or other open-domain QA datasets like TriviaQA, by treating the re-ranking of answer predictions as multi-choice QA problems (like the approach in Evidence Aggregation for Open-Domain QA from ICLR2018).\n\nA minor question: why the CFC w/o encoder could still work so well? At least the fine-grained scoring model should heavily rely on encoders. Otherwise, according to Eq (17), the fine-grained model cannot use any contextual information.', 'This paper proposes an interesting coarse-grain fine-grain coattention network architecture to address multi-evidence question answering and achieves the new state-of-the-art results on the Qangaroo WikiHop dataset.  The main idea is to divide the task across the coarse-grain and fine-grain modules in a complimentary manner such that the coarse-grain module learns from efficient modeling of support documents and the query whereas the fine-grain module learns from associations of candidate mentions in the support documents with the query. \n\nThe major strength of the model is observed with learning effective representations of larger numbers of long support documents and the state-of-the-art results are achieved without the use of pretrained contextualized embeddings. The main novelty lies in how the coattention and self-attention strategies are combined hierarchically to learn relevant representations in a complimentary fashion (rather than serial). Overall, the paper is very well-written and presents solid results with meaningful ablation study, quantitative and qualitative analyses. I have a few comments/suggestions:\n\n- It would be interesting to see how the inclusion of pretrained contextualized embeddings such as ELMo, ULMFit, BERT would help the current model. \n\n- ""This is likely because coreference resolution captures intra-document and inter-document dependencies more accurately than hierarchical attention."" --> Please clarify why this is the case.\n\n- ""We hypothesize that ways to reduce this type of error include using more robust pretrained contextual encoders (McCann et al., 2017; Peters et al., 2018) and coreference resolution."" --> I agree; also, it would be worth considering some commonsense knowledge to alleviate this issue, because the fact that Scotland is a part of UK and has a border with England should be learned. Here is a relevant work: ""Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge"" by Mihaylov and Frank, 2018.\n\n- ""The second type (28% of errors) results from questions that are not answerable. For example, the support documents do not provide the narrative location of the play “The Beloved Vagabond” for the query narrative location the beloved vagabond."" --> It would be great if you could release the set of unanswerable questions for the community.\n\n- Please include the memory network-based QA works in the related work section because they involve some forms of reasoning. Also, I would suggest to cover the query-focused multi-document summarization area in the related work section because they also require evidence synthesis from multiple documents to address a query. It would be very interesting if authors can apply their model for the query-focused multi-document summarization task as well, as this would further validate the effectiveness of the proposed architecture for reasoning across multiple documents.', ""This paper proposes a method for multi-hop QA based on two separate modules, which are called coarse-grained and fine-grained modules. The coarse-grained module reads all of the supporting documents for QA, whereas the fine-grained one reads the local context surrounding each candidate entity's mentions. Both modules are used to predict the score of a candidate entity being the answer, with the final result being the sum of the two scores.\n\nThis is a fine paper and achieves a new state of the art on the Qangaroo multi-hop QA dataset. The paper is clearly written, presents the models intuitively, while not foregoing technical detail should that be interesting to a reader. I appreciated the ablation results, as well as the qualitative analyses. The overall idea of encoding different levels of context is an important one, and I am glad that this paper shows that this approach works for a complex QA task.\n\nThere are two downsides to the paper. The first is that I am not sure it is really accurate to call the coarse-grained model as such, as it still seems to require passing every word in the supporting documents to an encoder. It seems to be more aimed at capturing global information from the supporting documents, rather than to make a quick, high-level pass at inference. The second weakness is that the coarse- and fine-grained modules barely interact at all, as their prediction scores are simply summed at the output layer. It is nice that even such a simple method of interaction already works so well, but I would have expected some exploration or comment on how more interactions could be enabled.""]","[-30, 80, 80]","[50, 90, 90]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's focus and improvement over other methods, they express several concerns about motivation, novelty, and generalizability. The reviewer suggests additional experiments and questions some aspects of the model, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, presenting their concerns as suggestions and questions rather than harsh criticisms. They use phrases like 'I found', 'I suggest', and 'Another concern I have' which maintain a polite tone while still conveying their points."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and 'very well-written', highlights its 'major strength', and mentions it achieves 'state-of-the-art results'. The reviewer also provides constructive suggestions for improvement, indicating overall positive sentiment. The politeness score is 90 (very polite) due to the reviewer's use of respectful language throughout, such as 'It would be interesting to see', 'Please clarify', and 'I would suggest'. The reviewer offers criticisms and suggestions in a constructive manner, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 80 (positive) because the reviewer describes it as a 'fine paper' that achieves state-of-the-art results, is clearly written, and presents important ideas. They appreciate the ablation results and qualitative analyses. The reviewer does mention two downsides, but these are presented as minor concerns rather than major flaws. The politeness score is 90 (very polite) because the reviewer uses respectful and appreciative language throughout, such as 'I appreciated' and 'I am glad'. They present criticisms constructively and balance them with positive comments. The tone is professional and courteous throughout, avoiding any harsh or dismissive language.""]"
"[""The paper studies the problem of representation learning in the context of hierarchical reinforcement learning by building on the framework of  HIRO (Nachum et al. (2018)). The papers propose a way to handle sub-optimality in the context of learning representations which basically refers to the overall sub-optimality of the entire hierarchical polity with respect to the task reward. And hence, the only practical different from the HIRO paper is that the proposed method considers representation learning for the goals, while HIRO was directly using the state space.\n\n\nI enjoyed reading the paper. The paper is very *well* written. \n\nExperimental results:  The authors perform the series of experiments on various high dimensional mujoco env, and  show that the representations learned using the proposed method outperforms other methods (like VAEs, E2C etc), and can recover the controllable aspect of the agent i.e the x, y co-ordinate. This is pretty impressive result.\n\nSome questions:\n\n[1] Even though the results are very interesting, I'm curious as to how hard authors try to fit the VAE baseline. Did authors try using beta VAEs (or variants like InfoVAE) ?  Since the focus of the entire paper is about representation learning (as well as the focus of the conference), it is essential to make sure that baselines are strong. I would have suspected that it would have been possible to learn x,y co-ordinate in some cases while using improved version of VAE like beta VAE etc.\n\n[2] One of the major intuitions behind sub-optimality is to learn representations that can generalize, as well as can be used for continual learning (or some variant of it!). This aspect is totally missing from the current paper. It would be interesting to show that the representations learned using the proposed method can transfer well to other scenarios or can generalize in the presence of new goals, or can be sample efficient in case of continual learning. \n\nI think, including these results would make the paper very strong.  (and I would be happy to increase my score!).\n\n"", 'The problem setting considered in this paper is that of the recent wave of ""goal-conditioned"" formulations for hierarchical control in Reinforcement Learning. In this problem, a low-level controller is incentivized to reach a goal state designated by a higher-level controller. This goal is represented in an abstract (embedding) multi-dimensional vector space. Establishing ""closeness to goal"" entails the existence of some distance metric (assumed to be given an fixed) and a function $f$ which can project states to their corresponding goal representation. The ""representation learning"" problem referred to by the authors pertains to this function. The paper is built around the question: how does the choice of $f$ affects the expressivity of the class of policies induced in the lower level controller, which in turn affects the optimality of the overall system. The authors answer this question by first providing a bound on the loss of optimality due to the potential mismatch between the distribution over next states under the choice of primitive actions produced by a locally optimal low-level controller. The structure of the argument mimics that of model compression methods based on bisimulation metrics. The model compression here is with respect to the actions (or behaviors) rather than states (as in aggregation/bismulation methods). In that sense, this paper is a valuable contribution to the more general problem of understanding the nature of the interaction between state abstraction and temporal abstraction and where the two may blend (as discussed by Dietterich and MAXQ or Konidaris for example). Using the proposed bounds as an objective, the authors then derive a gradient-based algorithm for learning a better $f$. While restricted to a specific kind of temporal abstraction model, this paper offers the first (to my knowledge) clear formulation  of ""goal-conditioned"" (which I believe is an expression proposed by the authors) HRL fleshed out of architectural and algorithmic considerations. The template of analysis is also novel and may even be useful in the more general SMDP/options perspective. I recommend this paper for acceptance mostly based on this: I believe that these two aspects will be lasting contributions (much more than the specifics of the proposed algorithms). \n\n\n# Comments and Questions\n\nIt\'s certainly good to pitch the paper as a ""representation learning"" paper at a Representation Learning conference, but I would be careful in using this expression too broadly. The term ""representation"" can mean different things depending on what part of the system is considered. Representation learning of the policies, value functions etc. I don\'t have specific recommendations for how to phrase things differently, but please make sure to define upfront which represention you are referring to. \n\nRepresentation learning in the sense of let\'s say Baxter (1995) or Minsky (1961) is more about ""ease of learning"" (computation, number of samples etc) than ""accuracy"". In the same way, one could argue that options are more about learning more easily (faster) than for getting more reward (primitive options achieve the optimal). Rather than quantifying the loss of optimality, it would be interesting to also understand how much one gains in terms of convergence speed for a given $f$ versus another. I would like to see (it\'s up to you) this question being discussed in your paper. In other words, I think that you need to provide some more motivation as to why think the representation learning of $f$ should be equated with the problem of maximizing the return. One reason why I think that is stems from the model formulation in the first place: the low-level controller is a local one and maximizes its own pseudo-reward (vs one that knows about other goals and what the higher level controller may do). It\'s both a feature, and limitation of this model formulation; the ""full information"" counterpart also has its drawbacks.\n\nA limitation of this work is also that the analysis for the temporally extended version of the low-level controller is restricted to open-loop policies. The extension to closed-loop policies is important. There is also some arbitrariness in the choice of distance function which would be important to study. \n\nRelevant work (it\'s up to you to include or not): \n\n- Philip Thomas and Andrew Barto in ""Motor Primitive Discovery"" (2012) also talk about options-like abstraction in terms of compression of action. You may want to have a look. \n\n- Still and Precup (2011) in ""An information-theoretic approach to curiosity-driven reinforcement learning"" also talk about viewing actions as ""summary of the state"" (in their own words). In particular, they look at minimizing the mutual information between state-action pairs. \n\n- More generally, I think that the idea of finding ""lossless"" subgoal representations is also related to ideas of ""empowerment"" (the line of work of Polani).', ""-- Summary --\n\nThe authors proposes a novel approach in learning a representation for HRL. They define the notion of sub-optimality of a representation (a mapping from observation space to goal space) for a goal-conditioned HRL that measure the loss in the value as a result of using a representation. Authors then state an intriguing connection between representation learning and bounding the sub-optimality which results in a gradient based algorithm. \n\n-- Clarity --\n\nThe paper is very well written and easy to follow.\n\n-- novelty --\nTo the best of my knowledge, this is the first paper that formalizes a framework for sub-optimality of goal-conditioned HRL and I think this is the main contribution of the paper, that might have lasting effect in the field. This works mainly builds on top of Nachum et al 2018 for Data Efficient HRL.\n\n-- Questions and Concerns --\n\n[1] Authors discussed the quality of the representation by comparing to some near optimal representation (x,y) in section 7. My main concern is how really “good” is the representation?, being able to recover a representation like x,y location is very impressive, but  I think of a “good” representation as either a mapping that can be generalized or facilitate the learning (reducing the sample complexity). For example Figure 3 shows the performance after 10M steps, I would like to see a learning curve and comparison to previous works like Nachum et al 2018 and see if this approach resulted in a better (in term of sample complexity) algorithm than HIRO. Or an experiment that show the learned representation can be generalized to other tasks.\n\n[2] What are author's insight toward low level objective function? (equation 5 for example) I think there could be more discussion about equation 5 and why this is a good objective to optimize. For example third term is an entropy of the next state given actions, which will be zero in the case of deterministic environment, so the objective is incentivizing for actions that reduce the distance, and also has more deterministic outcome (it’s kind of like empowerment - klyubin 2015). I’m not sure about the prior term, would be great to hear authors thoughts on that. (a connection between MI is partially answering that question but I think would be helpful to add more discussion about this)\n\n[3] Distance function : In section C1 authors mention that they used L2 distance function for agent’s reward. That’s a natural choice, although would be great to study the effect of distance functions. But my main concern is that author's main claim of a good representation quality is the fact that they recovered similar to XY representation, but that might simply be an artifact of the distance function, and that (x,y) can imitate reward very well. I am curious to see what the learned representation would be with a different distance function.\n\n-- \nI think the paper is strong, and interesting however i’d like to hear authors thoughts on [2], and addressing [1] and [3] would make the paper much stronger.\n""]","[60, 80, 60]","[80, 70, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses enjoyment in reading the paper, praises the writing quality, and finds the experimental results 'impressive'. However, it's not extremely positive as the reviewer suggests improvements and asks questions. The politeness score is 80 (quite polite) due to the use of positive language ('enjoyed reading', 'well written'), constructive feedback, and the polite phrasing of questions and suggestions. The reviewer also expresses willingness to increase their score if certain improvements are made, which is encouraging. The language throughout is respectful and professional, without any rudeness or harsh criticism."", ""The sentiment score is 80 (positive) because the reviewer recommends the paper for acceptance, praising it as a 'valuable contribution' and stating that aspects of it 'will be lasting contributions'. The overall tone is supportive and appreciative of the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or areas for improvement rather than direct attacks. The reviewer also acknowledges the authors' potential choices ('it's up to you') and offers additional resources politely. The language is professional and courteous, avoiding any harsh or rude phrasing."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'very well written', 'novel', and stating that it 'might have lasting effect in the field'. They also describe the paper as 'strong, and interesting'. However, it's not extremely positive as the reviewer does raise some concerns and questions. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames their concerns as questions or areas for improvement rather than criticisms. They use phrases like 'I would like to see', 'would be great to hear authors thoughts', which are polite ways of suggesting improvements. The reviewer also ends on a positive note, encouraging the authors to address the concerns to make the paper 'much stronger'.""]"
"['This paper presents two new ideas on leveraging program semantics to improve the current neural program synthesis approaches. The first idea uses execution based semantic information of a partial program to guide the future decoding of the remaining program. The second idea proposes using an ensembling approach to train multiple synthesizers and then select a program based on a majority vote or shortest length criterion. The ideas are evaluated in the context of the Karel synthesis domain, and the evaluation shows a significant improvement of over 13% (from 77% to 90%).\n\nThe idea of using program execution information to guide the program decoding process is quite natural and useful. There has been some recent work on using dynamic program execution in improving neural program repair approaches, but using such information for synthesis is highly non-trivial because of unknown programs and when the DSL has complex control-flow constructs such as if conditionals and while loops. This paper presents an elegant approach to handle conditionals and loops by building up custom decoding algorithms for first partially synthesizing the conditionals and then synthesizing appropriate statement bodies.\n\nThe idea of using ensembles looks relatively straightforward, but it hasn’t been used much in synthesis approaches. The evaluation shows some interesting characteristics of using different selection criterion such as shortest program or majority choice can have some impact on the final synthesized program.\n\nThe evaluation results are quite impressive on the challenging Karel domain. It’s great to see that execution and ensembling ideas lead to practical gains.\n\nThere were a few points that weren’t clear in the paper:\n\n1. Are the synthesis models still trained on original input-output examples like Bunel et al. 2018? Or are the models now trained on new dataset comprising of (partial-inputs-->final-output) pairs obtained from the partial execution algorithm?\n\n2. In algorithm 2, the algorithm generates bodies for if and else branches until generating the else and fi tokens respectively. It seems the two bodies are being generated independently of each other using the standard synthesizer \\Tau. Is there some additional context information provided to the two synthesis calls in lines 8 and 9 so that they know to produce else and fi tokens?\n\n3. Is there any change to the beam search? One can imagine a more sophisticated beam search with semantic information can help as well (e.g. all partial programs that lead to the same intermediate state can be grouped into 1).\n', 'This paper proposes guiding program synthesis with information from partial/incomplete program execution. The idea is that by executing partial programs, synthesizers can obtain the information of the state the (partial) program ended in and can, therefore, condition the next step on that (intermediate) state. The paper also mentions ensembling synthesizers to achieve a higher score, and by doing that it outperforms the current state-of-the-art on the Karel dataset program synthesis task.\n\nIn general, I like the idea of guiding synthesis with intermediate executions, and the evaluation in the paper shows this does make sense, and it outperforms the SOTA. The idea is original and the evaluation shows it is significant (enough). However, I have two major concerns with the paper, its presented contribution, and the clarity.\n\nFirst, I cannot accept ensembling as a contribution to this paper. There is nothing novel about the ensemble proposed, and ensembling, as a standard method that pushes models that extra few percentage points, is present in a lot of other research. I have nothing against achieving SOTA results with it, while at the same time showing that the best performing model outperforms previous SOTA, which this paper orderly does. However, I cannot accept non-novel ensembling as a contribution of the paper.\n\nSecond, the clarity of the paper should be substantially improved:\n- my main issue is that it is not clear how the Exec algorithm (see next point too) is trained. From what I understand Exec is trained on supervised data via MLE. What is the supervised data here?  Given the generality claims and the formulation in Algorithm 1/2, and possible ways one could use the execution information, as well as the fact that the model should be end-to-end trainable via MLE, it seems to me that the model is trained on prefixes (defined by Algorithm 1/2) of programs. Whether this is correct or not, please provide full details on how one can train Exec without using RL.\n- By looking at Table 3, it seems that the generalization boost coming from Exec (I’m ignoring ensembling) is higher enough, and that’s great. However, it’s obvious that the exact match gain by Exec is minute, implying that the proposed algorithm albeit great on the generalization metric, does not improve the exact match at all. Do you have any idea why is that? Is that because Exec is trained via MLE and the Exec algorithm doesn’t add anything new to the training procedure?\n- how do algorithm 1 and 2 exactly relate? I guess there is a meaning of ellipses in Lines 1 and 13, however, that is not mentioned anywhere. Is the mixture of algorithm 1 and 2 (and a non-presented algorithm for while loops) the Exec algorithm? How exactly are these algorithms joined, i.e what is the final algorithm?\n- while on one side, I find some formalizations (problem definitions, definition 1, semantic rules in table 2) nicely done, I do not see their necessity nor big gains from them. In my opinion, the understanding of the rest of the paper does not depend on them, and they are well-described in the text.\n- the paper says that the algorithm “helps boost the performance of different existing training algorithms”, however, it does so only on the Bunel et al model (and the MLE baseline in it), and albeit there’s mention of the generality, it has not been shown on anything other than those two models and the Karel dataset.\n- do lines 6-7 in Algorithm 2 recurse? Does the model support arbitrarily nested loops/if statements?\n- The claim that the shortest principle is most effective is supported by 2 data points, without any information on the variance of the prediction/dependence on the seed. Did you observe this for #models > 10 too? Up to what number?\n- In table 3, is Exec on MLE? Could you please, for completeness, present the results of Exec + RL + ensemble in the table too?\n- summarization, point 3 - what are the different modules mentioned here? Exec/RL/ensemble?\n\nMinor issues, remarks, typos:\n- table 1 position is very unfortunate\n- figure 1 is not self-explanatory - it takes quite a lot of space to explain the network architecture, yet it fails to deliver meaning to parts of it (e.g. what is h_t^x, why is it max-pooled, what is g_t, etc)\n- abstract & introduction - “Reducing error rate around 60%” absolute percentage points seem like a better evaluation measure (that the paper does use). Why is the error rate reduction necessary here?\n- figure 2 - why is the marker in one of the corners, and not in the cell itself?\n- Algorithm 1, step 4, is this here just as initialization, so S is non-empty to start with?\n- Table 2 rule names are unclear (e.g. S-Seq-Bot ?)\n- Table 3 mentions what Exec indicates twice', 'The authors introduce two techniques:\n\nOne is (old school) forward search planning https://en.wikipedia.org/wiki/State_space_planning#Forward_Search\nfor input/output-provided sequential neural program synthesis on imperative Domain Specific Languages with an available partial program interpreter (aka transition function)(from which intermediate internal states can be extracted, e.g. assembly, Python). \nPrevious work did:\n  which_instruction, next_neural_state = neural_network(encoding(input_output_pairs), neural_state)\nThis technique:\n  which_instruction = neural_network(encoding(current_execution_state_output_pairs))\n  next_execution_state = vectorized_transition_function(current_execution_state, which_instruction)\n\nThe second one is ensembles of program synthesizers (only ensembled at test-time). \n\n\nGuiding program synthesis by intermediate execution states is novel, gets good results and can be applied to popular human programming languages like Python.\n\nPros\n+ Using intermediate execution states\nCons\n- State space planning could be done in a learnt tree search fashion, like e.g. Monte Carlo Tree Search\n- Ensembling synthesizers at test time only\n- why not have stochastic program synthesizers, see them as a generative model, and evaluate top-k generalization?\n\nPage 7\nTable 3 line 3: ""exeuction"" -> ""execution""']","[80, -20, 60]","[70, 50, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper's ideas and results. They describe the ideas as 'natural and useful', 'elegant', and the evaluation results as 'quite impressive'. The reviewer also notes that the paper presents 'significant improvement' and 'practical gains'. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and contributions before presenting their questions. The questions are framed as points that 'weren't clear' rather than criticisms. The reviewer also uses phrases like 'It's great to see' which further contributes to the polite tone. The score is not 100 as the review maintains a professional, slightly formal tone rather than being excessively polite."", ""The sentiment score is slightly negative (-20) because while the reviewer likes the main idea and acknowledges its originality and significance, they express two major concerns about the paper's contribution and clarity. The reviewer also lists several issues and questions that need to be addressed, indicating a mix of positive and negative feedback with a slight lean towards the negative.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like the idea' and 'I have nothing against achieving SOTA results,' which show appreciation for aspects of the work. Even when expressing concerns, the language is constructive rather than harsh, using phrases like 'please provide full details' and 'Could you please, for completeness...'. The reviewer also offers suggestions and asks questions to improve the paper, which is a polite way of addressing issues."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the novelty and good results of the authors' techniques, particularly praising the use of intermediate execution states. The reviewer also lists some pros, which contribute to the positive sentiment. However, the score is not higher due to the presence of cons and suggestions for improvement. The politeness score is 50 (slightly polite) because the reviewer maintains a professional and objective tone throughout, offering both praise and constructive criticism. The language is not overly formal or deferential, but it's respectful and avoids harsh criticism. The reviewer also politely points out a typo at the end, which is a courteous way to address such issues.""]"
"['This paper proposes N-ball embedding for taxonomic data. An N-ball is a pair of a centroid vector and the radius from the center, which represents a word.\n\nMajor comments:\n\n- The weakness of this paper is lack of experimental comparisons with other prominent studies. The Poincare embedding and the Lorentz model are recently proposed and show a good predictive performance in hypernymy embedding.\n- WordNet concepts are actually structed in DAG. Recent studies on structure embedding can hadle DAG data. It is not clear how to extend N-ball embedding for handling DAT structures. \n\n- Related work is not sufficiently described.\n\n- It is not clear why N-ball embedding is suitable for hierarchical structures.\n', 'Attention!!! This submission contains Github and Google Drive links to author-related accounts (see e.g. the abstract). I do not think this is permitted or standard. I leave the decision regarding ""automatic rejection"" of the submission to meta-reviewers of the paper.\n------------------------------------------------\nThe paper presents a method for tweaking existing vector embeddings of categorical objects (such as words), to convert them to ball embeddings that follow hierarchies. Each category is represented as a Eucldiean norm ball in high dimensional space, with center and radii adaptable to data. Next, inclusion and exclusion constraints on each pair of  balls are imposed based on the hierarchical structure. These constraints are imposed via an algorithmic approach.  The empirical study includes investigating the consistency of the representation with the hierarchy and demonstrating nearest neighbors for a set of words.\n\nOn the positive side, the paper addresses an important problem. It is readable and well organized. The related work could be improved by adding a number of representative related works such as [3,4].  \n\nThe major concern about the paper is the originality of the method. Encoding hierarchies with high dimensional balls and encoding inclusion and exclusion as constraints on those balls is a neat and powerful idea from modeling perspective. However, it is not novel, since the approach is already established for example in [1, 2 Chapter 5]. \nThe next major concern is regarding the evaluation of the quality of embeddings.\nThe empirical evaluation does not sufficiently evaluate the quality of tweaked embeddings. In contrast, the quantitative evaluation is more concerned with if the embeddings being consistent with the given hierarchy. In particular, not enough quantitative evidence that the proposed embeddings are actually effective in capturing semantics or in prediction tasks is provided. It should be noted that, the first aspect, ie consistency of the feasible solutions with hierarchy, can be theoretically established (see e.g. [1]).  The first paragraph of 3.2 seems unclear or wrong. See for example [2] for a gradient based solution for the problem.\nFinally, using an algorithmic approach as opposed to learning method for constructing embeddings, makes the method not directly related to the topic of ICLR conference.\n\nOverall, due to the above reasons, I vote the paper to be rejected. (The poor anonymization makes it a strong case for a reject.)\n\n[1] Mirzazadeh, F., Ravanbakhsh S., Ding N., Schuurmans D.,  ""Embedding inference for structured multilabel prediction"", NIPS 2015.\n[2] Mirzazadeh, F.""Solving Association Problems with Convex Co-embedding"", PhD thesis, 2017. (Chapter 5)\n[3] Vilnis, Luke, and Andrew McCallum. ""Word representations via gaussian embedding."", ICLR 2015.\n[4] Vendrov, I., Kiros, R., Fidler, S., Urtasun, R. ""Order-embeddings of images and language."" ICLR 2016.', 'This paper focuses on adjusting the pretrained word embeddings so that they respect the hypernymy/hyponymy relationship by appropriate n-ball encapsulation. They propose to do so by augmenting the word embeddings with information from a resource like Wordnet and applying 3 kinds of geometric transformations to enforce the encapsulation.\n\nThe motivation of doing this is not very clear and experimental results are mainly qualitative (and subjective) showing that hypernymy relation can be predicted and preserved by their adjustment. Since, this work relies on Wordnet, the coverage of vocabulary is severely limited and as the authors discus in the results with the section titled ""Experiment 3: Method 2"", they had to remove many words in the standard semantic similarity datasets which casts shadow on the usefulness of the proposed approach. It is unclear what the main contribution of such an approach.\n\nApart from this, the paper is diffcult to read and some parts (especially those pertaining to Figure 3) encode a simple concept that has been expressed in a very complicated manner.\n\nOverall, I give a score of 4 because of the limited coverage of the approach because of reliance on Wordnet and inadequate empirical evidence of usefulness of this approach.']","[-50, -70, -60]","[0, 20, 20]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several weaknesses of the paper such as lack of experimental comparisons, unclear extension to DAG structures, and insufficient related work. However, it's not entirely negative as it acknowledges the paper's proposal of a new embedding method. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact, without being overtly polite or rude. The reviewer states criticisms plainly without using harsh language, but also doesn't employ particularly courteous phrasing."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses major concerns about the originality of the method, the quality of the empirical evaluation, and the relevance to the conference. The reviewer explicitly states 'I vote the paper to be rejected' and cites 'poor anonymization' as a 'strong case for a reject'. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as addressing an important problem and being readable and well-organized. The politeness score is 20 because while the reviewer maintains a professional tone throughout and offers constructive criticism with specific references, the overall message is quite critical. The reviewer uses polite phrases like 'On the positive side' and provides specific suggestions for improvement, which adds to the politeness. However, the directness of the criticism and the strong recommendation for rejection prevent the score from being higher."", ""The sentiment score is -60 because the review is generally negative. The reviewer points out several issues with the paper, including unclear motivation, limited experimental results, and reliance on WordNet which limits vocabulary coverage. The overall score given by the reviewer is 4, which is quite low. However, it's not entirely negative as the reviewer acknowledges some aspects of the work. The politeness score is 20 because while the reviewer is critical, the language used is professional and not personally attacking. The reviewer uses phrases like 'It is unclear' and 'The motivation... is not very clear' rather than more aggressive language. The reviewer also balances criticism with some positive remarks, such as acknowledging the authors' discussion of limitations.""]"
"['Summary:\nProposes Counterfactual Guided Policy Search (CF-GPS), which uses counterfactual inference from sampled trajectories to improve an approximate simulator that is used for policy evaluation. Counterfactual inference is formalized with structural causal models of the POMDP. The method is evaluated in partially-observed Sokoban problems. The dynamics model is assumed known, and a learned model maps observation histories to a conditional distribution on the starting state. CF-GPS outperforms model-based policy search and a ""GPS-like"" algorithm in these domains. GPS in MDPs is shown to be a particular case of CF-GPS, and a connection is also suggested between stochastic value gradient and CF-GPS.\n\nReview:\nThe work is an interesting approach to a relevant problem. Related literature is covered well, and the paper is well-written in an approachable, conversational style. \n\nThe approach is technically sound and generally presented clearly, with a few missing details. It is mainly a combination of existing tools, but the combination seems to be novel. \n\nThe experiments show that the method is effective for these Sokoban problems. A weakness is that the setting is very ""clean"" in several ways. The dynamics and rewards are assumed known and the problem itself is deterministic, so the only thing being inferred in hindsight is the initial state. This could be done without all of the machinery of CF-GPS. I realize that the CF-GPS approach is domain-agnostic, but it would be useful to see it applied in a more general setting to get an idea of the practical difficulties. The issue of inaccurate dynamics models seems especially relevant, and is not addressed by the Sokoban experiment. It\'s also notable that the agent cannot affect any of the random outcomes in this problem, which I would think would make counterfactual reasoning more difficult.\n\nComments / Questions:\n* Please expand on what ""auto-regressive uniformization"" is and how it ensures that every POMDP can be expressed as an SCM\n* What is the prior p(U) for the experiments? \n* ""lotion-scale"" -> ""location-scale""\n\nPros:\n* An interesting and well-motivated approach to an important problem\n* Interesting connections to GPS in MDPs\n\nCons:\n* Experimental domain does not ""exercise"" the approach fully; the counterfactual inference task is limited in scope and the dynamics and rewards are deterministic and assumed known\n* Work may not be easily reproducible due to the large number of pieces and incomplete specification of (hyper-)parameter settings ', 'Summary: by assuming a correct, strongly factored environment model, improved estimators useful for policy search can be derived by ""counterfactual reasoning"", where data sampled from experience is used to refine initial conditions in the model; this translates into improved estimators of policy values, which improves policy search.\n\nMajor comments:\n\nI enjoyed this paper.  I think that model-based RL deserves more work, and I think that this is a simple, reasonably workable approach with some nice theoretical benefits.  I like the idea of SCMs; I like the idea of counterfactual reasoning; I like the idea of leveraging models in this unique way.\n\nOn the negative side, I felt that the paper makes some rather strong assumptions - specifically, that the agent has access to a perfect model with no mismatch, and that the model decomposes neatly into noise variables plus deterministic functions.  Given such a model, one wonders if there are other techniques, say, from classical planning, that could also be used for some sort of policy search.\n\nI have a few questions about approximations.  First, I see that probabilistic inference is a core element of each algorithm (where p(u|h) must be computed).  For large, complex models, I assume this must be approximate inference.  This leads naturally to questions about accuracy (does approximate inference result in biased estimators? [probably yes]), efficacy (do the inaccuracies inherent in approximate inference outweigh the benefits of using p(u|h) vs. p(u)?) and scalability (how large of a model can we reasonably cope with before degradation is unacceptable, or no better than non-CF algorithms?).  As far as I can tell, none of this was addressed in the paper, although I do not expect every paper to answer every question; this is a first step.\n\nI wish the experiments were a little more varied.  The experimental results really only show marginal improvement in one small task.  While I understand that this is not an empirical paper, neither does it fit strongly into the category of ""theory paper"".  For example, there are no theory results indicating what sort of benefit we might expect from using the methods outlined here, and in the absence of such theory, we might reasonably look to various experiments to demonstrate its effectiveness.\n\nPros:\n+ Integration with SCMs is interesting\n+ Counterfactual variants of algorithms are clearly motivated and interesting\n+ Paper is generally well-written\n\nCons:\n- Assumption that the agent is given a model with no mismatch is very strong\n- Model class (noise variables + deterministic functions) seems potentially restrictive\n- Questions about impact of approximate inference\n- Experiments could have been more varied\n\n', 'Summary:\n\nThis paper proposes a policy evaluation and search method assisted by a counterfactual model, in contrast previous work using vanilla (non-causal) models. With “no model mismatch” assumption the policy evaluation estimator is unbiased. Empirically, the paper compares Guided Policy Search with counterfactual model (CF-GPS) with vanilla GPS, model based RL algorithm and show benefit in terms of (empirical) sample complexity.\n\nMain comments:\n\nThis paper studies several interesting problems: 1) policy learning with off-policy data; 2) model based RL and how to use model to help policy learning. By capturing a nice connection between causal models and MDP/POMDP model with off-policy data, this paper can leverage SCMs to help the model guided policy search in POMDP. The combination of those ideas is novel and enjoyable.\n\nOn the negative side, I find I met several confused points as a reader with more RL background and less causal inference background. It would be better if the authors could clarify what is the prior distribution P(u) and posterior distribution P(u|h) exactly means in terms of CF-PE algorithm and MB-PE algorithm. I would also appreciate if a more detailed proof of corollary 1 and 2 are included in the appendix, and a higher level intuition/justification about those two results in main body. Maybe I am missing these points due to my limited background in causal inference, but I think those clarification can definitely be helpful for RL audience without that much knowledge in causal inference.\n\nThe main theoretical result seems to be based on the assumption of no model mismatch, and I guess here how the model is estimated from sample are ignored, unless I missed anything. Thus I assume the main contribution of this paper should be algorithmic and empirical. I expect to see the empirical study in more domains with more informative results about how this CF model get the benefit of sampling from p(u|h) rather than p(u) (as an evidence to support motivation paragraph on page 5). ']","[20, 60, 50]","[70, 80, 75]","[""For the sentiment score, I assigned 20 (slightly positive) because the review begins with positive comments about the work being 'interesting' and 'well-written', and acknowledges its technical soundness and novelty. However, it also points out significant weaknesses, particularly in the experimental setup, which balances out the positive aspects. For the politeness score, I assigned 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its limitations. The critique is presented constructively, using phrases like 'it would be useful to see' rather than making demands. The reviewer also asks questions for clarification rather than making accusations about missing information. The overall tone is professional and courteous, avoiding harsh or dismissive language."", ""The sentiment score is 60 (positive) because the reviewer expresses enjoyment of the paper, appreciation for the ideas presented, and sees value in the approach. They use phrases like 'I enjoyed this paper' and 'I like the idea of...' multiple times. However, the score is not higher due to the significant criticisms raised, such as strong assumptions and limited experiments. The politeness score is 80 (quite polite) because the reviewer maintains a respectful and constructive tone throughout. They balance positive feedback with criticisms, use phrases like 'I wish' instead of demanding changes, and acknowledge the paper's limitations without being harsh. The reviewer also uses phrases like 'I understand that...' showing empathy towards the authors' choices."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper's novel ideas and combination of concepts, calling it 'enjoyable'. However, they also raise several concerns and areas for improvement, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging their own potential knowledge gaps ('Maybe I am missing these points due to my limited background...') and framing criticisms as suggestions for improvement rather than direct attacks. The reviewer also begins with positive comments before moving to critiques, which is a polite approach in academic reviews.""]"
"['Summary:\nThe authors propose a network for VQA incorporating hand-crafted modules and their hierarchy, each of which is a network for a high-level vision task. Some modules may share the same sub-modules at a different level in the module hierarchy. Each module is individually (not end-to-end) trained with a dataset containing a dedicated annotation for their high-level tasks. The proposed model shows comparable scores to the existing models.\n\nPresentation and clarity:\nThe paper is well written and easy to follow and contains reasonable experiments for understanding the proposed method.\n\nOriginality and significance:\nI mainly do not agree that this work generalizes NMN. Instead, I believe that this work is a special case of NMN where the modules and their hierarchy are manually defined based on the authors\' intuition. Meanwhile, the proposed network architecture is static, and thus the main idea of having multiple modules in a network is not novel as other approaches using static network architectures such as [A] also facilitate multiple modules for different sub-procedures (e.g., RNN for questions and CNN for image) and sometimes share modules in multiple stages too. The main difference between this and previous works is that the modules in this work deal with high-level tasks chosen by the authors. I am not convinced that designing the modules with high-level tasks is a better choice over designing modules that are less task-specific. Rather, I see more drawbacks as the proposed method requires multiple datasets with diverse task-specific annotation. Also, the modules and their connectivity are less scalable and extendable as they are not learned.\n\nConsidering all the model and dataset complexities, the improvements over black-box models are mostly marginal. The main benefits we get from all these complexities are the interpretability. However, for many modules, the interpretability comes from indirect signals that are often not clear how to interpret for the question answering. On the other hand, the manually designed sub-tasks may cause error propagation in the network as these modules are not directly optimized for the final objective.\n\nSome questions and comments:\nI do not understand why it is necessary to have the image captioning module as it does not directly relate to the question answering. Moreover, the caption itself is generated without conditioning on the question.\n\n[A] Yang, Zichao, et al. ""Stacked attention networks for image question answering."" CVPR 2016.\n\n\n== After discussion phase\nBased on the rebuttal and additional experiments that clarified and resolved my questions, I change my initial rating.', 'The paper proposes to learn task-level modules progressively to perform the task of VQA. Such task-level modules include object/attribute prediction, image captioning, relationship detection, object counting, and finally VQA model. The benefit of using modules for reasoning allows one to visualize the reasoning process more easily to understand the model better. The results are mainly shown on VQA 2.0 set, with a good amount of analysis.\n\n- I think overall this is a good paper, with clear organization, detailed description of the approach, solid analysis of the approach and cool visualization. I especially appreciate that analysis is done taking into consideration of extra computation cost of the large model; the extra data used for visual relationship detection. I do not have major comments about the paper itself, although I did not check the technical details super carefully.\n\n- One thing I am confused about is the residual model, which seems quite important for the pipeline but I cannot find details describing it and much analysis on this component. \n\n- I am in general curious to see if it will be beneficial to fine-tune the modules themselves can further improve performance. It maybe hard to do it entirely end-to-end, but maybe it is fine to fine-tune just a few top layers (like what Jiang et al did)? \n\n- One great benefit of having a module-based model is feed in the *ground truth* output for some of the modules. For example, what benefit we can get if we have perfect object detection? Where can we get if we have perfect relationships? This can help us not only better understand the models, but also the dataset (VQA) and the task in general. ', '[Summary]\nThis paper presents a multi-task learning approach for VQA that represent a solver for each task as a neural module that calls existing modules in a program manner. The authors manually design the task hierarchy and propose a progressive module network to recursive calls the lower modules and gather the information by soft-attention. The final prediction uses all the states and question to infer the final answers. The authors verify the effectiveness of the proposed method on the performance of different tasks and modules. Experiment on VQA shows the proposed model benefits from utilizing different modules. The authors also qualitatively show the model\'s reasoning process and human study on judging answering quality.\n\n[Strength]\n1. The proposed method is novel and explores to use the existing modules as a black box for visual question answering.  This is different from most existing work. \n\n2: By examing different modules, the proposed method is more interpretable compare to canonical methods. \n\n3: The experiment results are good, especially for the counting problem. \n\n[Weakness] \n1. The title of the paper is ""visual reasoning by progressive module networks."" The title may be a little overstated since the major task is focused on visual question answering (VQA).  \n\n2. Annotation is not clear in this paper. For example, on page 3, Query transmitter and receiver, ""the output o_k = M_k(q_k) received from M_k is modified using receiver function as v_k = R_{k->n}(s^t, o_k). "" There are multiple new variables in this paragraph, without specifying the dimension and meaning for each attribute, it\'s really hard to understand. On page 4, State update function, what is the meaning of variable ""Epsilon"" in the equation? From the supplementary, it seems Epsilon means the environment? \n\n3. On the object counting task, the query transmitter needs to produce a query for a relationship module. The authors mentioned that this is softly calculated by softmax on the importance score. Since q_rel require one hot vector as input, how to sample the q_rel given the importance score and how backprob the gradient in this case? \n\n4. The cider score of image captioning is 109 compared to the baseline 108. The explanation is the COCO dataset has a fixed set of 80 object categories and does not benefit from training the diverse data. Since the input visual feature is the same, the only difference is the proposed model has additional label embedding as input. My assumption is the visual feature already contains the label information for image captioning. \n\n5. On relational detection task, is there a way to compare with the STOA method on some specific data split? This will leads to much more convincing results. \n\n6. Similar as above question, on the object counting task, is there a way to compare with previous counting methods? \n\n7. In Table 4, the accuracy of number on Zhang et.al is 49.39, which is higher than other methods, while on test-dev, the accuracy is 51.62, which is lower than others. Is the number right? ']","[-20, 80, 50]","[60, 90, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is well written and easy to follow'), they express significant criticisms and doubts about the novelty and effectiveness of the proposed method. The reviewer disagrees with the authors' claims of generalizing NMN and questions the necessity of certain modules. They also point out that improvements over existing models are 'mostly marginal' given the complexity involved.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I mainly do not agree' and 'I am not convinced' rather than harsh or dismissive language. The reviewer also acknowledges positive aspects of the paper and provides constructive feedback and specific questions. The final paragraph indicating a change in rating after discussion also shows a willingness to reconsider their initial assessment, which is a polite and open-minded approach."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'a good paper' with clear organization, detailed description, solid analysis, and cool visualization. They appreciate the analysis considering extra computation costs and data usage. The reviewer states they don't have major comments, which is a strong positive indicator. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I think overall this is a good paper' and 'I especially appreciate,' showing respect for the authors' work. They also frame their questions and suggestions politely, using phrases like 'I am curious to see' and 'One great benefit,' which encourages further exploration rather than criticizing. The reviewer also acknowledges their own potential oversight ('I did not check the technical details super carefully'), which shows humility and fairness in their assessment."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting several strengths of the paper, including its novelty, interpretability, and good experimental results. However, it also lists multiple weaknesses and areas for improvement, balancing out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses neutral, professional language throughout and frames criticisms as suggestions or questions rather than harsh statements. They acknowledge the paper's merits before discussing areas for improvement, which is a polite approach. The reviewer also uses phrases like 'is there a way to' when suggesting comparisons, which comes across as constructive rather than demanding.""]"
"['Following recent work on Hindsight Experience Replay (Andrychowicz et al. 2017), the authors extend the idea to policy gradient methods. They formally describe the goal-conditioned policy gradient setup and derive the extensions of the classical policy gradient estimators. Their key insight to deriving a computationally efficient estimator is that for many situations, only a small number of goals will be ""active"" in a single trajectory. Then, they conduct extensive experiments on a range of problems and show that their approach leads to improvements in sample efficiency for goal-conditioned tasks.\n\nAlthough the technical novelty of the paper is not high (many of the estimators follow straightforwardly from previous results, however, the goal subsampling idea is a nice contribution), the paper is well written, the topic is of great interest, and the experiments are extensive and insightful. I expect that this will serve as a nice reference paper in the future, and launching point for future work. \n\nThe only major issue I have is that there is no comparison to HER. I think it would greatly strengthen the paper to have a comparison with HER. I don\'t think it diminishes their contributions if HER outperforms HPG, so I hope the authors can add that.\n\nComments:\n\nIn Sec 6.1, it seems surprising that GCPG+B underperforms GCPG. I understand that HPG+B may underperform HPG, but usually for PG methods a baseline helps. Do you understand what\'s going on here?\n\nIn Sec 6.2, it would be helpful to plot the average return of the optimal policy for comparison (otherwise, it\'s hard to know if the performance is good or bad). Also, do you have any explanations for why HPG does poorly on the four rooms?\n\n====\n\nRaising my score after the authors responded to my questions and added the HER results.', ""The authors present HPG, which applies the hindsight formulation already applied to off-policy RL algorithms (hindsight experience replay, HER, Andrychowicz et al., 2017) to policy gradients.\nBecause the idea is not new, and formulating HPG from PG is so straightforward (simply tie the dynamical model over goals), the work seems incremental. Also, going off policy in PG is known to be quite unstable, and so I'm not sure that simply using the well known approach of normalized importance weights is in practice enough to make this a widely useful algorithm for hindsight RL.\n\n\nEvaluation      3/5 How does HPG compare to HER? The only common experiment appears to be bit-flipping, which it appears (looking back at the HER paper, no reference to HER performance in this paper) to signifcantly underperform HER. In general I think that the justification for proposing HPG and possible advantages over HER need to be discussed: why should we generalize what is considered an on-policy algorithm like PG to handle hindsight, when HER seems ideally suited for such scenarios? Why not design an experiment that showcases the advantages of HPG over HER? \nClarity              4/5 Generally well explained.\nSignificance    3/5 The importance of HPG relative to off-policy variants of hindsight is not clear. Are normalized importance weights, a well established variance reduction technique, enough to make HPG highly effective? Do we really want to be running separate policies for all goals? With the practical need to do goal sub-sampling, is HPG really a strong algorithm (e.g. compared to HER)? Why does HPG degrade later in training sometimes when a baseline is added? This is strange, and warrants further investigation.\nOriginality     2/5 More straightforward extension of previous work based on current presentation. \n\nOverall I feel that HPG is a more straightforward extention of previous work, and is not (yet at least) adequately justified in the paper (i.e. over HER). Furthermore, the experiments seem very preliminary, and the paper needs further maturation (i.e. more discussion about and experimental comparision with previous work, stronger experiments and justification).\nRating          5/10 Weak Reject\nConfidence      4/5\n\nUpdated Review: \n\nThe authors have updated the appendix with new results, comparing against HER, and provided detailed responses to all of my concerns: thank you authors.\n\nWhile not all of my concerns have been addressed (see below), the new results and discussion that have been added to the paper make me much more comfortable with recommending acceptance. The formuation, while straightforward and not without limitations, has been shown in preliminary experiments to be effective. While many important details (e.g. robust baselines and ultimate performance) still need to be worked out, HPG is almost certainly going to end up being a widely used addition to the RL toolbox. Good paper, recommend acceptance.\n\nEvaluation/Clarity/Originality/Significance: 3.5/4/3/4\n\nRemaining concerns: \n- The poor performance of the baselines may indeed be due to lack of hindsight, but this should really be debugged and addressed by the final version of the paper.\n- Results throughout the paper are shown for only the first 100 evaluation steps. In many of the figures the baselines are still improving and are highly competitive... some extended results should be included in the final version of the paper (at least in the appendix).\n- As pointed out, it is difficult to compare the HER results directly, and it is fair to initially avoid confounding factors, but Polyak-averaging and temporal difference target clipping are important optimization tricks. I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks.\n\n\n"", 'This paper extends the work of Hindsight Experience Replay to (goal-conditioned) policy gradient methods. Hindsight, which allows one to learn policies conditioned on some goal g, from off-policy experience generated by following goal g’, is cast in the framework of importance sampling. The authors show how one can simply rewrite the goal-conditioned policy gradient by first sampling a trajectory, conditioned on some goal $g’$ and then computing the closed form gradient in expectation over all goals. This gradient is unbiased if the rewards are off-policy corrected along the generated trajectories. While this naive formulation is found to be unstable , the authors propose a simple normalized importance sampling formulation which appears to work well in practice. To further reduce variance and computational costs, the authors also propose goal subsampling mechanisms, which sample goals which are likely along the generated trajectories. The method is evaluated on the same bit-flipping environment as [1], and a variety of discrete environments (grid worlds, Ms. Pac-Man, simulated robot arm) where the method appears highly effective. Unfortunately for reasons which remain unclear, hindsight policy gradients with value baselines appear unstable.\n\nQuality:\nThis paper scores high wrt. quality. The theoretical contributions of the method are solid, the experiments are well designed and highlight the efficacy of the method, as well as areas for improvement. In particular, I commend the authors for the rigorous analysis (bootstrapped error estimates, separate seeds for hyper-parameters and reporting test error, etc.), including the additional results found in the appendix (sensitivity and ablative analyses). That being said, the paper could benefit from experiments in the continuous control domain and a direct head-to-head comparison with HER. While I do not anticipate the proposed method to outperform HER in terms of data-efficiency (due to the use of replay) the comparison would still be informative to the reader.\n\nClarity:\nThe paper is well written and easy to follow. If anything, the authors could have abridged sections 2 and 3 in favor of other material found in the Appendix, as goal-conditioned policy gradients (and variants) are straightforward generalizations of standard policy gradient methods.\n\nOriginality:\nNovelty is somewhat low for the paper as Hindsight Experience Replay already presented a very similar off-goal-correction mechanism for actor-critic methods (DDPG). The method is also very similar to [2], the connection to which should also be discussed.\n\nSignificance.\nDespite the low novelty, I do believe there is value in framing “hindsight” as importance sampling in goal-conditioned policy gradients. This combined with the clear presentation and thorough analysis in my opinion warrants publication and will certainly prove useful to the community. Significance could be improved further should the paper feature a more prominent discussion / comparison to HER, along with a fix for the instabilities which occur when using their method in conjunction with a value baseline.\n\n[1] Hindsight Experience Replay. Marcin Andrychowicz et al.\n[2] Data-Efficient Hierarchical Reinforcement Learning. Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine.\n\nDetailed Comments:\n* Section 2: “this formulation allows the probability of a state transition given an action to change across time-steps within an episode”. I do not understand this statement, as $p(s_{t+1} \\mid s_t, a_t)$ is the same transition distribution found in standard MDPs, and appears stationary wrt. time.\n* Theorems 3.1 - 3.1 (and equations). A bit lengthy and superfluous. Consider condensing the material.\n* Section 5: I found the change in notation (from lower to upper-case) somewhat jarring. Also, the notation used for empirical samples from the mini-batch is confusing. If $A^{(i)}_t}$ is meant to be the action at time-step $t$ for the $i$-th trajectory in the minibatch, then what does $G^{(i)} = g$ mean ? I realize this means evaluating the probability by setting the goal state to $g$, but this is confusing especially when other probabilities are evaluated conditioned on $G^{(i)}$ directly.\n* Section 6. “Which would often require the agent to act after the end of an episode”. Do you mean that most episodes have length T’ < T, and as such we would “waste time” generating longer trajectories ?\n* RE: Baseline instabilities. Plotting the loss function for the value function could shed light on the instability.\n']","[80, -20, 70]","[70, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, praising its writing, topic relevance, and extensive experiments. They state it will serve as a 'nice reference paper' and a 'launching point for future work'. The only major criticism is the lack of comparison to HER, which they suggest adding. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. They use phrases like 'I expect' and 'I hope' which maintain a collegial tone. The reviewer also raises questions in a non-confrontational manner, asking for explanations rather than pointing out flaws. The final note about raising their score after author responses further indicates a positive and cooperative attitude."", ""The sentiment score is slightly negative (-20) because the reviewer initially expresses skepticism about the novelty and effectiveness of the proposed method, using phrases like 'the work seems incremental' and 'I'm not sure that simply using the well known approach...is in practice enough'. However, in the updated review, the tone becomes more positive, recommending acceptance, which balances out some of the initial negativity. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, acknowledges the authors' responses ('thank you authors'), and provides constructive feedback. The reviewer also uses polite phrases like 'I feel that' and 'I think' when expressing opinions. While critical, the feedback is delivered in a respectful manner, avoiding harsh or rude language."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, praising its quality, theoretical contributions, well-designed experiments, and thorough analysis. They state that the paper 'scores high wrt. quality' and 'warrants publication'. However, it's not 100 because they also mention some areas for improvement and note that the novelty is 'somewhat low'. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They 'commend the authors' for their rigorous analysis and provide detailed, helpful feedback. The tone is professional and supportive, offering suggestions for improvement without being harsh or dismissive. The use of phrases like 'I do believe there is value' and 'will certainly prove useful to the community' further demonstrates a polite and encouraging tone.""]"
"[""last time i had two comments:\n1. the real data motifs did not look like what i'd expect motifs to look like. now that the authors have thresholded the real data motifs, they do look as i'd expect.\n2. i'm not a fan of VAE, and believe that simpler optimization algorithms might be profitable.  i acknowledge that SCC requires additional steps; i am not comparing to SCC. rather, i'm saying given your generative model, there are many strategies one could employ to estimate the motifs.  i realize that VAE is all the rage, and is probably fine.  in my own experiments, simpler methods often work as well or better for these types of problems.  i therefore believe this would be an interesting avenue to explore in future work."", 'The paper proposes a VAE-style model for identifying motifs from calcium imaging videos. As opposed to standard VAE with Gaussian latent variables it relies on Bernouli variables and hence, requires Gumbel-softmax trick for inference. Compared to methods based on matrix factorization, the proposed method has the advantage of not requiring any preprocessing on the imaging videos. My main comments are as follows:\n\n- How sensitive is the method to the choice of beta and other hyperparameters?  Compared to SCC which has fewer hyperparameters, how robust is the method?\n- How does it perform on real data compared to methods based on spike time matrices? Do they generate similar motifs? \n- The application of the method seems quite limited to calcium imaging videos and it does not provide comparison with other deep generative models for videos. Methods such as Johnson et al. NIPS 2016 (Composing graphical models with neural networks for structured representations and fast inference) can also be applied to calcium imaging datasets and can potentially infer the motifs.\n\nI believe the problem of inferring the neural motifs is an interesting problem; however, I think this paper requires more work to it shows its advantages over other deep generative models for video data and also it’s performance on real data compared to SCC (or some other matrix factorization based approach). \n-----------------------------------------------------------------------\nThe authors have addressed my comments about other deep generative models and hyperparameter sensitivity. However, I still think the paper is more suitable for other venues with readers from the neuroscience community. Hence, I change my rating to 5. ', 'Thank you for a pleasurable and informative read, I consider the writing and structure of the paper to be coherent and well written. \n\nGiven an end-to-end learning of neural motifs, a great deal of time can be avoided, reducing the several intermediary steps required to detect motifs from calcium imaging. This paper may very well improve researchers efficiency, in particular when working with calcium imaging. The question remain to what extent these ideas may be useful in other imaging modalities, i.e. fMRI.\n\nMy main critique would be to be more explicit about why the VAE you propose, is superior to other models in the generative modelling domain.']","[50, -20, 80]","[75, 50, 90]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that their previous concerns have been addressed (e.g., 'now that the authors have thresholded the real data motifs, they do look as I'd expect'). However, they still express some reservations about the methods used (VAE). The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts to address previous comments, and frames their remaining concerns as suggestions for future work rather than criticisms. The reviewer also uses phrases like 'I acknowledge' and 'I realize' which show consideration for the authors' perspective."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting nature of the problem, they express several concerns and suggest that the paper requires more work. The final statement about changing the rating to 5 (presumably out of 10) also indicates a somewhat negative sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and acknowledges the interesting aspects of the work. The reviewer maintains a professional tone without using overly harsh language, even when expressing concerns.', ""The sentiment score is 80 (positive) because the reviewer expresses gratitude for a 'pleasurable and informative read' and praises the paper's writing and structure. They also highlight the potential benefits of the research, indicating a positive view. The slight reduction from 100 is due to the critique mentioned at the end. The politeness score is 90 (very polite) due to the use of phrases like 'Thank you' and the overall constructive and respectful tone. The reviewer offers praise before providing a gentle critique, which is a polite approach. The language throughout is professional and courteous.""]"
"['Summary: the paper proposes a method for Deep Neural Networks (DNN) that identifies automatically relevant features of the set of the classes, enriching the predictions made with the visual features that contributed to that class, supporting, thus, interpretation (understanding what the model has learned) and explanation (justification of the predictions/classifications made by the model). This scheme does not rely on additional annotations, like earlier techniques do.\n\nThe contributions of this paper are relevant to, I would say, a large segment of the AI community, since interpretability and explainability of AI (XAI) is the focus of many current works in the area, and there are still many unresolved issues. I consider this paper suitable for ICLR 2019, in particular, it fits the call for papers topic “visualization or interpretation of learned representations”.\n\nThe authors also present a new dataset (am8Flower) that can be used by the community for future evaluations of explanation methods for DNN. From my point of view, this is a significant contribution, since there is a lack of datasets that can be used for evaluation.\n\nThe authors motivate properly the need for this research/study, addressing the main weakness of the two more common strategies for interpreting DNN, (1) manually inspecting visualizations of every single filter or (2) comparing the internal activations produced by a given model w.r.t. a dataset with pixel-wise annotations of possibly relevant concepts.\n\nI would encourage the authors to write the limitations and weakness of their proposal w.r.t. similar approaches they reviewed. I am aware that the space is limited, but in p.8, section 4.3, when Table 1 is introduced and the authors confirm that their proposal has higher IoU than other methods, the authors could explain, in brief, what are the weaknesses of their method w.r.t. the other approaches analyzed.\n\nAnother clarification concerns the initialization of input parameters, such as sparsity; e.g., p.6 sparsity is initialized with 10 for all datasets, why? How has this value been selected and how sensitive is the performance regarding variations of this value?\n\nOnce again, I know that the space is limited, but I would like to be able to see some of the figures better (since this is an essential part of the paper). The additional material complements very well the paper and shows larger figures, but I think that the paper itself should be self-sufficient, and figures like Fig. 5 should be enlarged so it is easier to see some details.\n\nJust a concern or something that I quite did not understand about one of the arguments the authors use to justify the evaluation carried out: the authors claim that they want to avoid the subjectivity introduced by humans (citing Gonzalez-Garcia et al. 2017), and prefer to avoid user studies, presenting a more objective approach in their evaluation. Ok, but then, the analysis presented in, for example, page 7, is based mainly in their interpretation of the results, a qualitative analysis of the images (we can see fur patterns, this and that, etc.). So aren’t they interpreting the results obtained as users? So after all, aren’t the visual explanations and feedback intended for users? Why should we claim that we want to avoid the subjectivity introduced by humans in the evaluation when the method proposed here is actually going to be used by users –with their inherent subjectivity? I do not mean that the evaluation carried out is not interesting per se, but it could be motivated differently, or it could be complemented later on with future user studies (that would make an interesting addition to the paper). Moreover, I also wonder whom the authors see as intended users for the proposed scheme.\n\nSmall comments:\nP.1 “useful insights on the internal representations” \uf0e0 insights into the internal representations.\nP. 2: space needed in “back-propagation methods.Third,”\nP. 3: Remove “s” in verb (plural authors): “Similarly, Bach et al. (2015) decomposes the classification” \uf0e0 decompose or decomposed\nP.3: n needed “Chattopadhyay et al. (2018) exteded” \uf0e0 extended\nP.3: “This saliency-based protocol assume that” \uf0e0 protocol assumes\nP.3: “highlighted by the the explanations” \uf0e0 remove one “the”\nP. 5: “space. As as result we get” \uf0e0 remove one “as”\nP. 5: “and compensate this change” \uf0e0 compensate for this change\nP. 6: “In this experiment we verify” \uf0e0 In this experiment, we verify\nP. 6: “To this end, given a set of identified features we” \uf0e0 To this end, given a set of identified features, we\nP. 6: “Note that the OnlyConv method, makes the assumption” \uf0e0 remove “,” after method\nP. 7: “In order to get a qualitative insight of the type of” \uf0e0 insight into the\nP. 7: I would write siamese and persian cat with capital “S” and “P” (Siamese, Persian)\nP. 7: others/ upper “Some focus on legs, covered and uncovered, while other focus on the upped body part.” \uf0e0 while others focus on the upper body part\nP. 7: “These visualizations answers the question” \uf0e0 answer\nP. 7:  “In this section we assess” \uf0e0 In this section, we\nP. 7: Plural “We show these visualization for different” \uf0e0 these visualizations\nP. 7: In “Here our method reaches a mean difference on prediction confidence” \uf0e0 difference in prediction …\nP. 7: “This suggest that our method is able” \uf0e0 This suggests that\nP. 8: state-of-the-art\nP. 8: “has higher mean IoU” \uf0e0 has a higher mean IoU\nWhole document: when using “i.e.” add “,” after: i.e.,\n\nReferences: Some of the references in the list have very little information to be able to find it/proper academic citation, e.g. , Yosinski et al. 2015; Vedaldi and Lenc, 2015:\n\nJason Yosinski, Jeff Clune, Anh Mai Nguyen, Thomas J. Fuchs, and Hod Lipson. Understanding neural networks through deep visualization. 2015.\n\nA. Vedaldi and K. Lenc. Matconvnet: Convolutional neural networks for matlab. In MM, 2015.\n\nRef Doersch et al.: What makes paris look like paris? \uf0e0 Paris\n', ""In this paper, the authors proposed a novel scheme to interpret deep neural networks’ prediction by identifying the most important neurons/activations for each category using a Lasso algorithm.\n\nFirstly, the authors produce a 1-dimensional descriptor for each filter in each convolutional layer for each image. Then these descriptors are concatenated as a new feature vector for this image. A feature selection algorithm (u-Lasso) is then trained to minimize the classification loss between the prediction from the new feature vector and the original prediction from DNN (formula (1)). Finally, the importance of each filter is identified by the weights of the lasso for each category.\n\nThe authors also improved the visual feedback quality over the deconvolution+guided back-propagation methods, and release a new synthetic dataset for benchmarking model explanation.\n\nThe paper is well-written, however, I have several concerns about this paper:\n\n1.      How to verify the importance of the identified relevant features is a problem. In the experiments, the authors removed features in the network by setting their corresponding layer/filter to zero. The authors only compared their method with randomly removing features. And in Fig 4, the differences seem small for ImageNet. The results are not convincing enough to me. It is a bit baffling randomly removing features did almost as well as the proposed approach.\n\n2.      I don't think one should get away with only showing some results from the synthetic dataset without showing any quantitative results on any real datasets. I like the idea of having a synthetic dataset where all the parameters are controllable. However in this case it is very simple and maybe lacking enough distracting features that can really test the capability of the algorithm. I would believe quantitative results on a realistic dataset are still necessary for the pubilcation of this paper.\n\n3.      Recently several papers pointed out some significant issues in Guided BP, \n\nXie et al. A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations. ICML 2018\nAdebayo et al. Sanity Checks for Saliency Maps. NIPS 2018\nKindermans et al. The (Un)reliability of saliency methods. NIPS workshop 2017\n\ncan the authors comment on that? Based on those papers I don't seem to think Guided BP is actually doing anything that is relevant to the classification, but is just finding prominent gradients. This, unfortunately would lead to reasonably good behavior on the synthetic dataset created by the authors. "", ""Pros:\n\nThis paper\n - Proposes a method for producing visual explanations for deep neural network outputs,\n - Improves quality of the guided backprop approach for strided layers by converting stride 2 layers to stride 1 and resampling inputs (improving on a longstanding difficulty with such approaches),\n - Shows fairly rigorous experimentation demonstrating the applicability and properties of the proposed approach, and\n - Releases a new synthetic dataset and benchmark for visual explanation methods.\n\nAlthough producing visual explanations is a task fraught with difficulty for many reasons, including that explanations for complex decisions may not necessarily be communicable via one or a small number of saliency maps over the image pixels, this paper strives valiantly in this admittedly difficult direction.\n\nThe experimentation is fairly rigorous, which is a welcome departure from and improvement on the norm for this type of paper. I hope such more quantitative evaluation will become more common in papers evaluating visual explanations.\n\nCons:\n\nWhat about features that are very important but not linearly predictive on their own? This approach (and many others) would not work in that case; recognizing this, extending the an8Flower dataset to include such images and labels may be motivating for the field. For example, flowers where the class is determined not by a specific single color or feature (thorns or spots) but by the combination. In these cases, it’s not clear what the right answer would even be in the form of a saliency map, so the first task for researchers would be to determine in what format the answer should even be provided! So: less a benchmark than a motivating open question.\n\n\nSmaller notes:\n\nI found the presentation of the stride 1 resampling approach a little confusing. When performing the backward pass through the network from, say, layer 20, is the approach followed at every stride 2 layer on the way back? If so, I don’t think I saw this mentioned. If not, wouldn’t artifacts be introduced and compounded at any stride 2 layer during the backward pass?\n\n\n====== Update 12/12/18 ======\n\nThanks for your notes in reply. I'll just add that if the dataset can be extended to slightly greater complexity either for this version or for submission to a subsequent venue, it would be impactful. Simple extensions could include scenes with multiple flowers and classes where the explanatory factor is tricker to uncover. For example, a dataset could be created with scenes of three flowers: two of one color and one of another color, with the class determined by the color of the lone flower. The correct explanation (the color of the lone flower) is still clear, and it would be great to see if the proposed LASSO approach (or a future approach) could correctly identify those pixels.""]","[80, -30, 70]","[70, 60, 80]","[""The sentiment score is 80 because the reviewer expresses a very positive view of the paper, stating it makes relevant contributions, is suitable for the conference, and presents a significant new dataset. They use phrases like 'relevant to a large segment of the AI community' and 'significant contribution'. The score is not 100 as the reviewer does suggest some improvements. The politeness score is 70 because the reviewer uses respectful language throughout, often using phrases like 'I would encourage' and 'I would like to', showing consideration. They also acknowledge space limitations. However, the score isn't higher as the review is primarily focused on the content rather than being overtly polite, and includes direct critiques. The reviewer also points out several grammatical errors, which, while helpful, slightly reduces the overall politeness tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('The paper is well-written', 'I like the idea of having a synthetic dataset'), they express several significant concerns about the paper's methodology and results. The reviewer states that the results are 'not convincing enough' and that certain aspects are 'baffling'. They also suggest that additional work is necessary for publication. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their criticisms as 'concerns' rather than outright flaws. They use phrases like 'can the authors comment on that?' which invites dialogue rather than making accusations. The reviewer also acknowledges positive aspects of the paper before presenting their concerns, which is a polite approach to criticism."", ""The sentiment score is 70 (positive) because the review begins by listing several pros of the paper, praising its rigorous experimentation and contributions to the field. The reviewer uses phrases like 'fairly rigorous', 'welcome departure', and 'improvement on the norm' to express approval. While some cons are mentioned, they are presented more as suggestions for improvement rather than major flaws. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the difficulty of the task and praising the authors' efforts ('strives valiantly'). Even when offering critiques, the tone remains constructive and encouraging, suggesting improvements for future work rather than harshly criticizing the current paper. The use of phrases like 'I hope' and 'Thanks for your notes' further contributes to the polite tone.""]"
"['EDIT: I thank the authors for providing all clarifications. I think this paper is a useful contribution. It will be of interest to the audience in the conference.\n\nSummary:\nThis paper provides a method to jointly learn from crowdsourced worker labels and the actual data. The key claimed difference is that previous works on crowdsourced worker labels ignored the data. At a higher level, the algorithm comprises maximizing the mutual information gain between the worker labels and the output of a neural network (or more generally any ML model) on the data. \n\nEvaluation:\nI like the idea behind the algorithm. However there are several issues on which I ask the authors to provide some clarity. I will provide a formal ""evaluation"" after that. (For the moment, please ignore the ""rating"". I will provide one after the rebuttal.) \n\n(1) As the authors clarified, one key aspect of the ""information intersection"" assumption is that the crowdsourced labels are statistically independent from the data when conditioned on the ground truth. How strongly does this coincide with reality? Since the work is primary empirical, is there any evidence on this front?\n\n(2) In the abstract, introduction etc., what does it mean to say that the algorithm is an ""early algorithm""?\n-- Thanks for the clarification. I would suggest using the term ""first algorithm"" in such cases. However, is this the first algorithm towards this goal? See point (3).\n\n(3) The submitted paper misses an extremely relevant piece of literature: ""Learning From Noisy Singly-labeled Data"" (arXiv:1712.04577). This paper also aims to solve the label + features problem together. How do the results of this paper compare to that of this submission?\n\n(4) ""Model and assumptions"" Is the i.i.d. assumption across the values of ""i""? Then does that not violate the earlier claim of accommodating correlated mistakes?\n\n(5) Recent papers on crowdsourcing (such as Achieving budget-optimality with adaptive schemes in crowdsourcing arXiv:1602.03481 and  A Permutation-based Model for Crowd Labeling: Optimal Estimation and Robustness arXiv:1606.09632) go beyond restricting workers to have a common confusion matrix for all questions. In this respect, these are better aligned with the realistic scenario where the error in labeling may depend on the closeness to the decision boundary. How do these settings and algorithms relate to the submission?\n\n(6) Page 5: ""Later we will show....""   Later where? Please provide a reference.\n\n(7) Theorem 3.4, The assumption of existence of experts such that Y^S is a sufficient statistic for Y: For instance, suppose there are 10 experts who all have a 0.999 probability of correctness (assume symmetric confusion matrices) and there are 5 non-experts who have a 0.001 probability of correctness and even if we suppose all are mutually independent given the true label, then does this satisfy this sufficient statistic assumption? This appears to be a very strong assumption, but perhaps the authors have better intuition?\n\n(8) The experiments comprise only some simulations. The main point of experiments (particularly in the absence of any theoretical results) towards bolstering the paper is to ensure that the assumptions are at least somewhat reasonable. I believe there are several datasets collected from Amazon Mechanical Turk available online? Otherwise, would it be possible to run realistic experiments on some crowdsourcing platforms?\n', 'Update after feedback: I would like to thank the authors for their detailed answers, it would be great to see some revisions in the paper also though (except new experimental results).\nEspecially thank you for providing details of a training procedure which I was missing in the initial draft. I hope to see them in the paper (at least some of them).\n\nI have increased the rating to 6. Given new experimental results both on real data and forecaster comparison I would like to increase the rating to 7. However, I am not sure that this is fair to other authors who would might not be physically able to provide new experimental results due to computational constraints, please note that the experiments in this paper are rather \'light\' in the standards of modern deep learning experiments and can be done within the rebuttal period.  \n====================================================\n\n\nThe paper finds a practical implementation of ideas from Kong & Schoenebeck (2018) for the learning with crowd problem. It proofs the claims from Kong & Schoenebeck (2018) for the specific family of data classifiers and crowd aggregators. From the general perspective, the papers proposes a method for joint training a classifier and a crowd label aggregator with particular consideration of correlated crowd labels. \n\nThe paper is fairly well-written and well-balanced between theoretical and empirical justification of the method. I see 1 major and 1 big issues with the paper.\n\nMajor issue: I am missing details of the actual procedure of training the model. Is MIG set as a loss function for the data classifier NN? Is crowd aggregator trained also as an NN with MIG as a loss function? How do the authors find the optimal p? Also, in order all the provided theory to work all the found data classifier NN, the aggregator and p should be exact maximisers of MIG as far as I understand. How do the author ensure that they find the exact maximisers? Also related to understanding how training works: on p.15 the authors claim “Note that our method can handle this simple correlated mistakes case and will give all useless experts weight zero based on Theorem 3.4.” I have trouble understanding why the proposed method should find these zero weights rather than it is just able to find them?\n\nI am willing to change my judgement if the authors provide convincing details on the training procedure.\n\nBig issue: Experimental settings. \na) Though it is interesting to see the analysis of the method under controlled environments of synthetic crowd labels with different properties that show benefits of the proposed method (such as dealing with correlated crowd labels), it would be also appealing to see the results with real labels, for example, Rodrigues & Pereira (2017) provide Amazon MTurk crowd labels for the LabelMe data\nb) Is the proposed data-crowd forecaster the only method that uses crowd labels on the test data? While it can be argued that it is not straightforward in the test regime to include crowd labels into Crowd Layer, for example, without retraining the neural net, AggNet can use crowd labels without retraining the neural net part. In the presented format, it is unfair to compare the forecaster with the other methods because it uses more information, and essentially, the forecaster is not compared with anything (that uses the same information). It can be compared, at least, with pure Majority Voting, or more advanced pure crowdsourcing aggregation methods. Yes, they won’t use image data, but at least they can use the same amount of crowd label information, which would make a nice comparison with the presented related work and proposed NN: this is what you can get using just image data during test (Crowd Layer, Max-MIG, and others from the current paper), this is what you can get using just crowd labels during test (Majority Voting or, preferably, more advanced pure crowdsourcing aggregators), and this is what you can get using both image and crowd labels during test (the proposed forecaster and AggNet, for example)\n\nQuestions out of curiosity: \ni). Does Max-MIG handle missing crowd labels for some data points? Did the author use missing labels in the experiments?\nii). Both the Dogs vs. Cats and CIFAR-10 datasets have more or less balanced data, i.e., the number of data points belonging to each ground truth class is similar between classes. Is this true for the LUNA16 dataset? If yes, have the authors tried their method with heavily imbalanced data? In my experience, some crowdsourcing methods may suffer with imbalanced data, for example, Crowd Layer does so on some data. This tendency of Crowd Layer is kind of confirmed on the provided Dogs vs. Cats in the naïve majority case, where based on crowd labels the first class dominates the second.\n\nOther questions/issues/suggestions:\n1. Until the formal introduction of the forecaster on page 4, it is not entirely clear what is the difference between the data classifier and data-crowd forecaster. It should be explained more clearly at the beginning that the 3 concepts (data classifier, crowd label aggregator and ""data-crowd forecaster"") are separated. Also some motivation why we should care about forecaster would be beneficial because one can argue that if we could train a NN that would make good enough predictions why we should waste resources on crowd labels. For example, the provided empirical results can be used as an argument for this.\n2. From the introduction it is unclear that there are methods in crowdsourcing that do not rely on the assumption that data and crowd labels are independent given the ground truth labels. As mentioned in related works there are methods dealing with difficulty of data points, where models assume that crowd labels maybe biased on some data points due to their difficulty, e.g., if images are blurred, which violates this assumption.\nAlso the note that considering image difficulty violates the independence assumption could be added on page 3 around ""[we] do not consider the image difficulty""\n3. The beginning of page 4. I think it would be more clear to replace ""5 experts\' labels:"" by $y^{[5]}=$\n4. I suggest to move the caption of Figure 3 into the main text.  \n5. p.3 ""However, these works are still not robust to correlated mistakes"" - Why? \n6. Data-crowds forecaster equation. It would be good to add some intuition about this choice. The product between the classifier and aggregator predictions seems reasonable, division on p_c is not that obvious. This expression presumably maximises the information gain introduced below. Some link between this equation and the gain introduction would be nice. Also, minor point – it is better to enlarge inner brackets ()_c\n7. The formulation “To the best of our knowledge, our approach is a very early algorithm”, and namely “a very early algorithm” is unclear for me\n8. Dual usage of “information intersection” as an assumption and as something that Max-MIG finds is confusing\n9. Any comments how the learning rates were chosen are always beneficial\n10. Proof of Proposition C.3: “Based on the result of Lemma C.2, by assuming that h ∗ ∈ H_{NN} , we can see (h ∗ , g∗ ,p ∗ ) is a maximizer of max_{h∈H_{NN} ,g∈G_{W A},p∈∆_C} MIGf (h, g,p)” – is expectation missing in the max equation? Is this shown below on page 13? If yes, then the authors should paraphrase this sentence as it does not imply that this is actually shown below\n11. p.12 (and below) – what is $\\mathbf{C}^m$? Is it $\\mathbf{W}^m$?\n12. p.15 (at the end of proof) $p \\log q$ and $p \\log p$ are not formally defined\n\nMinor:\n1. p.1 ""of THE data-driven-based machine learning paradigm""\n2. ""crowds aggregator"" -> ""crowd aggregator""?\n3. p.2 (and below) ""between the data and crowdsourced labels i.e. the ground truth labelS""\n4. Rodrigues & Pereira (2017) has a published version (AAAI) of their paper\n5. p.2 ""that model multiple experts individually and explicitly in A neural network""\n6. p.3 ""model the crowds by A Gaussian process""\n7. p.3 ""We model the crowds via confusion matriCES""\n8. p.3 ""only provide A theoretic framework and assume AN extremely high model complexity""\n9. p.4 ""forecast"" for h and g -> ""prediction""?\n10. p.6 “between the data and the crowdsourced labelS”?\n11. p.6 “However, in practice, with A finite number of datapoints”\n12. p.6 “the experiment section will show that our picked H_{NN} and G_{W A} are sufficientLY simple to avoid over-fitting”\n13. p.6 “We call them A Bayesian posterior data classifier / crowds aggregator / data-crowds forecaster, RESPECTEVILY”\n14. p.6 “Theorem 3.4. With assumptionS 3.1, 3.3”\n15. p.7 “DoctOr Net, the method proposed by Guan et al. (2017)”\n16. p.7 “including the naive majority case since naive expert is independent with everything” – rephrasing is required, unclear what “independent with everything” means and who is “naïve expert”\n17. Please capitalised names of conferences and journals in References\n18. p.10 “she labels the image as “dog”/“cat” with THE probability 0.6/0.8 respectively”, “(e.g. B labels the image as “cat” with THE probability 0.5 and “dog” with THE probability 0.5 when the image has cats or dogs)”\n19. p.12 “Lemma C.2. (Kong & Schoenebeck, 2018) With assumptionS 3.1, 3.3”, “Proposition C.3. [Independent mistakes] With assumptionS 3.1, 3.3”\n\n\n\n', 'Top pros:\n- Well motivated approach with good examples from clinical setting\n- Sound proof on why information theoretical approach is better than MLE based approaches\n- Experiments on diversified data sets to show their approach\'s performance, with good implementation details. \n\nTop cons:\n- Fairly strong assumption on the existence of mutually independent senior experts in the labeling process\n- Hard-to-check assumption for Theorem 3.4 for real world problems, on the sufficiency of senior expert\'s info to predict the true class label\n\nThe paper is in general well written, and builds upon existing work on crowdsourced data mining and co-training. I believe this line of work will benefit the community in taking a more information theoretical approach with relaxed assumptions on the data collection process. My main feedback is how to check the existence of senior experts in real-world applications. In particular,\n- If the labels are collected from an unknown setup (e.g. on AMT), where it is hard to establish the dependency structure of the experts, how can we use such approaches effectively? \n- Even if there exists a clear line between senior/junior experts in the labeling process, how do we know or check that the senior experts\' opinion can sufficiently estimate the true labels? \n\nIn the experiment section, the label data was collected with a build-in assumption of senior/junior labelers, and we also know exactly who are senior/junior experts. So it is not surprising that the proposed approach outperforms other approaches. It\'s also interesting to see that AggNet isn\'t that bad in general compared to the proposed approach (except on LUNA16). What if we combine all experts in one setting and apply the proposed approach without prior knowledge of who are senior/junior? Also, did you require all experts to label ALL the data points or only a subset of training data points? \n\nMinor points:\n- I don\'t believe ""Naive majority"" is an interesting setting - we can easily detect those junior experts that always label cases with one class, and remove these experts from the system, in practice. \n- I wouldn\'t call this an ""early"" algorithm as it indicates it\'s somewhat pre-mature. Just call this a novel approach that is in the early phase, and more sophisticated approach can be further developed. ']","[50, 20, 50]","[75, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by thanking the authors and stating that the paper is a useful contribution. However, they also raise several issues and questions, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, such as 'I thank the authors', 'I like the idea', and 'please provide some clarity'. They frame their criticisms as questions or requests for clarification rather than direct criticisms. The reviewer also acknowledges the authors' clarifications and suggests improvements in a constructive manner. The overall tone is professional and courteous, even when pointing out potential issues or missing references."", ""The sentiment score is 20 (slightly positive) because the reviewer begins by thanking the authors for their detailed answers and expresses appreciation for new experimental results. They also increased their rating from 6 to 7, indicating overall satisfaction with the improvements. However, the review still contains several critiques and suggestions for further improvement, which prevents a higher positive score. The politeness score is 60 (moderately polite) because the reviewer consistently uses respectful language, expresses gratitude, and frames criticisms constructively. They use phrases like 'thank you,' 'I hope to see,' and 'It would be great to see,' which contribute to a polite tone. The reviewer also acknowledges the authors' efforts and provides detailed, constructive feedback. However, the score is not higher as the review maintains a professional, somewhat formal tone rather than being excessively polite or deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting several pros of the paper, including its well-motivated approach, sound proof, and diverse experiments. However, they also point out significant cons and areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as constructive feedback or questions rather than harsh judgments. Phrases like 'I believe this line of work will benefit the community' and the use of questions to suggest improvements contribute to the polite tone. The reviewer also offers specific, actionable feedback without being overly critical or dismissive.""]"
"['1) Summary\nThis paper proposes a hierarchical reinforcement learning (HRL) method for visual motor control of humanoid agents. The method is decomposed into a high-level controller that takes in visual input and proprioceptive information, and a low-level controller (they compare may ways of doing this) that takes care of the agent’s motor control. In experiments, the proposed method is tested on a variety of RL tasks where the many low-level controllers presented in the paper are compared against each other.\n\n2) Pros:\n+ Novel high-level controller that takes in front-view visual information\n+ Novel multi-policy low level controller\n+ Interesting experimental section\n\n3) Cons:\nNumerical comparison to previous methods:\n- The only issue I found with this paper is that there is no comparison with other methods. Even if the other methods do not take in front-view visual input, it would be nice to compare with them. Maybe visual inputs results in better high-level controller? Or even show that performance is similar would be an interesting result.\n\n4) Comments:\nJerky transitions in switching controller:\n- Due to the fact that one policy takes over after each other based on the high-level controller choice, there is a jerk artifact that shows when the policies are being changed/executed. Did you guys try to add a connection in feature space between policies rather than only passing the state of the agent? This may be able to help with that artifact that sampling noise adds to the actions. Can the authors comment on this?\n\nSteerable controller limited rotation:\n- From observing the steerable controller policy in action, it seems the policy learned a steering that is somewhat independent of what the limbs are doing. Maybe adding a mechanism where the leg motion intensity depends more on the direction of movement could be a way to fix the issue where this policy moves to fast for the turning it tries to do. Maybe an energy based objective to minimize the torques or something in that line.\n\n4) Conclusion:\nTo the best of my knowledge, this paper proposes a novel interesting method for modeling humanoid motor skills with front-view visual input. However, as mentioned above, the paper lacks of numerical comparisons with other methods, and only compares against its own variations which is more of an ablation study. I am willing to increase my review score if the authors successfully address the concerns mentioned above', 'The paper proposes a control architecture for learning task oriented whole body behaviors  in simulated humanoid robots bootstrapped with motion capture data.\n\nThe authors use a hierarchical approach, where the low-level controllers are trained to follow motion captured data whereas the high-level control combines them. \nThe topic of the paper is interesting and the language is understandable. \n\nThe paper discusses and compares different ways to achieve such a higher level control.\nIt probably won’t be useful for real robots, but will be possibly useful for computer graphics.\nI suspect that code will not be published anytime soon, and I am afraid it will be hard to reproduce without. There is a solid software engineering involved and the system has many parameters.  \n\nThe related work section (or lack thereof) can be improved. What is the advantage of this work over the multi-skill integration in Peng et al 2018? Please explain explicitly in the paper.\n\nThe end-to-end approach seems a bit too weak to me. The video shows more artifacts than other similar papers, (cf. Heess et al. 2017). What’s the detail of the training for the end-to-end baseline?\n\nAre the environments randomized in each rollout? If not then this would need an ablation study which ablates memory/vision to prove its claim of integrating vision and memory. \nHow much is the memory used in the tasks where nothing needs to be memorized?\nIs there any noise in the simulations?\n\nOne weakness is that the low-level controllers are not adapted any further. That is probably why the fragments outperformed the transition policies etc., because the higher level policy has more flexibility.\n\nOverall, from the perspective of deep learning, I think the paper is novel and provides some insights into different approaches to the problem.\n', '1) Summary\nThe authors propose an interesting hierarchical reinforcement learning method that makes use of visual inputs as well as proprioception for locomotion of humanoid agents. The low-level controllers make use of “motion capture” data and are expected to form a set of movement primitives that can be used by a higher-level controller that has vision and memory. Their method is tested on a variety of tasks and different choices of low-level controller are explored.\n\n2) Pros\n+ Combining vision, memory, and motor control\n+ Allows the high-level controller to operate at a coarser time scale\n+ The set of low-level movement primitives can be extended by using more mocap data\n\n3) Cons\n- No comparison to earlier work\n- Highly unnatural motions even though it makes use of mocap data\n- Sample inefficient: more than 1 billion time-steps to train the high-level controller\n\n4) Comments\nShowing that the agent can provide suitable solutions for these tasks using raw vision input is indeed interesting, however it is not clear what the main contribution of the paper is as the authors fail to compare their results with earlier work. It would be useful if the authors could cover the related work in more depth in order to motivate their method and contrast it with the existing solutions. As an example, DeepLoco (Peng et al. 2017) solves a similar problem in which they use an egocentric heightmap instead of direct visual input, hence a formal consideration of the trade-offs would be informative.\n\nIn addition, the appeal of using hierarchical reinforcement learning is to divide up the task into easier chunks that can be solved easier, however it is not obvious how well this method succeeds at this task, keeping in mind that the high-level controller takes in the order of 1 billion time-steps to learn most tasks (5 billion in the case of “Heterogeneous Forage”).\n\nIn the end, an ablation study could be useful since the authors make plenty of novel design decision, yet their effect on the final performance is not clear.\n\n\n6) Questions\n- Is is possible to entirely remove proprioception from the input to the high-level controller or at least use just a small portion of it? How do the results compare in this case?\n\n- How robust is “cold-switching” between control fragments? Is it possible to transition between most fragments without losing balance or does the high-level controller have to be extremely careful as to which combination it should use? The former case would suggest that this method is indeed useful as a hierarchical method. However the latter case might imply that the hierarchical method is failing and the higher level controller’s task has not been made much easier than the original problem itself.\n\n- Table 2 describes the mocap clips used to train the low-level controllers in each task. What is the effect of choosing different sets of motions? Specifically how well does the steerable controller work if walking motions were used for the “Go To Target” and “Walls” tasks rather than running motions? Presumably, this can result in a more flexible controller which allows sharper turns without loosing balance.\n\n- The network in Figure A.1 gets the last action as an input. Why is this required? Especially since the LSTM unit can learn to remember any information related to the previous actions.\n\n- How does the supervised pre-training described in section 2.1 effect the training of low-level controllers? Is it used as a speed-up mechanism or a way of escaping local minima?\n\n- In section 2.1 the authors mention that the episodes are “terminated when the pose deviates too far from the trajectory”. I believe this termination criteria was not present in the earlier works (Peng et al. 2018), then what is the effect of adding such a criterion? Can this make the learned agent less robust as it will not learn to recover from larger perturbations?\n\n\n7) Conclusion\nThe method and the results are interesting but further comparison with existing work is required.']","[50, 20, -20]","[80, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and interesting aspects of the paper, listing several pros. However, they also point out a significant con (lack of comparison to previous methods) and suggest improvements, indicating a balanced but generally favorable view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively, and expresses willingness to increase their review score if concerns are addressed. They also use phrases like 'to the best of my knowledge' and ask the authors to comment on certain aspects, showing consideration and openness to dialogue."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting topic and understandable language. They also mention its novelty and potential insights. However, they express several concerns and point out weaknesses, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism without using harsh language. They balance positive comments with areas for improvement, and use phrases like 'I suspect' and 'I think' to soften their critiques. The reviewer also provides specific suggestions for improvement, which is a polite way to offer feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting method', 'allows high-level controller to operate at a coarser time scale'), they also point out significant shortcomings ('no comparison to earlier work', 'highly unnatural motions', 'sample inefficient'). The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as questions or suggestions rather than direct criticisms. They use polite phrases like 'it would be useful if' and 'could be useful', maintaining a professional and courteous tone even when pointing out weaknesses in the work.""]"
"['PAPER SUMMARY:\n\nThis paper proposes a new POVI method for posterior inference in BNN. Unlike existing POVI techniques that optimize particles in the weight space which often yields sub-optimal results on BNN due to its over-parameterized nature, the new POVI method aims to maintain and update particles  directly on the space of regression functions to overcome this sub-optimal issue.\n\nNOVELTY & SIGNIFICANCE:\n\nIn general, I am inclined to think that this paper has made an important contribution with very promising results but I still have doubts in the proposed solution technique (as detailed below) and am not able to converge to a final rating at this point.\n\nTECHNICAL SOUNDNESS:\n\nThe authors claim that the new POVI technique operates directly on the function-space posterior to sidestep the over-parameterized issue of BNN but ultimately each function particle is still identified by a weight particle (as detailed in Eq. (2)). In terms of high-level ideas, I am not sure I understand the implied fundamental differences between this work and SVGD and how significant is it.\n\nOn the technical level, the key difference between the proposed work and SVGD seems to be the particle update equation in (2): The gradient flow is multiplied with the derivative of the BNN evaluated at the corresponding weight particle (in SVGD, the gradient flow was used alone). The authors then mentioned that this update rule results from minimizing the difference between f(X, theta) and f(X, theta) + \\epsilon * v(f(., theta))(X). I do not follow this step -- please elaborate.\n\nThe theoretical justification that follows Eq. (3) is somewhat incoherent: What is \\Epsilon(q(f(x)))? This has not been defined before or anywhere in the main text. Furthermore, the paragraph that follows the theoretical justification implies the computation of the gradient flow in (3) involves the likelihood term -- why is that?\n\nIn Algorithm 1, why do we sample from both the training set and some measure \\mu? I am sure there must be a reason for this but I could not find it anywhere except for a short statement that ""for convenience, we choose \\mu in such a way that samples from \\mu always consists a mini-batch from X"". Please elaborate.\n\nWill the proposed POVI converge?\n\nCLARITY:\n\nI think this paper has clarity issue with the technical exposition. The explanation tends to be very limited and even appear coherent at important points. For example, see\nmy 3rd point above. \n', 'This paper considers particle optimization variational inference methods for Bayesian neural networks.  To avoid degeneracies which arise when these algorithms are applied to the weight space posterior, the authors consider applying the approach in the function space.  A heuristic motivation is given for their algorithm and it seems to have good empirical performance.\n\nI find the paper well-motivated and the suggested algorithm original and interesting.  As the authors mention at one point the derivation is rather heuristic, so much depends on the empirical assessment of their approach.  I was wondering if it was worthwhile to include an architecture search of some kind in the empirical comparisons in the examples?  This is because if wider than needed hidden layers are used this will worsen some of the degeneracies of the weight space posterior which could make the weight space algorithms perform worse.  Also the authors use a Gaussian process approximation in part of their algorithm and wide hidden layers make that approximation more reasonable and may advantage their approach for that reason too.  The authors discuss in Appendix B other approaches to improving weight space POVI.  I wonder also if parameter constraints would be helpful for improving the performance of the weight space methods, such as order constraints on the hidden layer biases for example to remove at least some of the sources of unidentifiability.  The authors talk in the introduction about the difficulties of exploring a complex high-dimensional posterior, the curse of dimensionality, and the limitations of current variational families but only 20 points are used to represent the posterior in the examples.   Are many more particles required to obtain good performance in more complex models and does the approach scale well in terms of its computational requirements in that sense?', ""Based on the revision, I am willing to raise the score from 5 to 7.\n\n========================================== \n\nThe authors address the problems of variational inference in over-parameterized models and the problem of the collapse of particle-optimization-based variational inference methods (POVI). The authors propose to solve these problems by performing POVI in the space of functions instead of the weight space and propose a heuristic approximation to POVI in function spaces.\n\nPros:\n1) I believe that this work is of great importance to the Bayesian deep learning community, and may cause a paradigm shift in this area.\n2) The method performs well in practice, and alleviates the over-parameterization problem, as shown in Appendix A.\n3) It seems scalable and easy to implement (and is similar to SVGD in this regard), however, some necessary details are omitted.\n\nCons:\n1) The paper is structured nicely, but the central part of the paper, Section 3, is written poorly; many necessary details are omitted.\n2) The use of proposed approximations is not justified\n\nIn order to be able to perform POVI in function-space, the authors use 4 different approximations in succession. The authors do not check the impact of those approximations empirically, and only assess the performance of the final procedure. I believe it would be beneficial to see the impact of those approximations on simple toy tasks where function-space POVI can be performed directly. Only two approximations are well-motivated (mini-batching and approximation of the prior distribution), whereas the translation of the function-space update and the choice of mu (the distribution, from which we sample mini-batches) are stated without any details.\n\nMajor concerns:\n1) As far as I understand, one can see the translation of the function-space update to the weight-space update (2) as one step of SGD for the minimization of the MSE \\sum_x (f(x; \\theta^i) - f^i_l(x) - \\eps v(f^i_l)(x))^2, where the sum is taken over the whole space X if it is finite, or over the current mini-batch otherwise. The learning rate of such update is fixed at 1. This should be clearly stated in the paper, as for now the update (2) is given without any explanation.\n\n2) I am concerned with the theoretical justification paragraph for the update rule (3) (mini-batching). It is clear that if each marginal is matched exactly, the full posterior is also exactly matched. However, it would usually not be possible to match all marginals using parametric approximations for f(x). Moreover, it is not clear why would updates (3) even converge at all or converge to the desired point, as it is essentially the update for an optimization problem (minimization of the MSE done by SGD with a fixed learning rate), nested into a simulation problem (function-space POVI). This paragraph provides a nice intuition to why the procedure works, but theoretical justification would require more rigor.\n\n3) Another approximation that is left unnoted is the choice of mu (the distribution over mini-batches). It seems to me from the definition of function-space POVI that we need to use the uniform distribution over the whole object space X (or, if we do not do mini-batching, we need to use the full space X). However, the choice of X seems arbitrary. For example, for MNIST data we may consider all real-values 28x28 matrices, where all elements lie on the segment [0,1]. Or, we could use the full space R^28x28. Or, we could use only the support of the empirical distribution. I have several concerns here:\n3.1) If the particles are parametric, the solution may greatly depend on the choice of X. As the empirical distribution has a finite support, it would be dominated by other points unless the data points are reweighted. And as the likelihood does not depend on the out-of-dataset samples, all particles f^i would collapse into prior, completely ignoring the training data.\n3.2) If the prior is non-parametric, f(x) for all out-of-dataset objects x would collapse to the prior, whereas the f(x) for all the training objects would perfectly match the training data. Therefore we would not be able to make non-trivial predictions for the objects that are not contained in the training set unless the function-space kernel of the function-space prior somehow prevents it. This poses a question: how can we ensure the ability of our particles to interpolate and extrapolate without making them parametric? Even in the parametric case, if we have no additional regularization and flexible enough models, they could overfit and have a similar problem.\nThese two concerns may be wrong, as I did not fully understand how the function-space prior distribution works, and how the function-space kernel is defined (see concern 4).\n\n4) Finally, it is not stated how the kernels for function-space POVI are defined. Therefore, it is not clear how to implement the proposed technique, and how to reproduce the results. Also, without the full expression for the weight-space update, it is difficult to relate the proposed procedure to the plain weight-space POVI with the function value kernel, discussed in Appendix B.\n\nMinor comments:\n1) It is hard to see the initial accuracy of different models from Figure 3 (accuracy without adversarial examples). Also, what is the test log-likelihood of these models?\n2) It seems that sign in line 5 on page 4 should be '-'\n\nI believe that this could be a very strong paper. Unfortunately, the paper lacks a lot of important details, and I do not think that it is ready for publication in its current form.""]","[-20, 70, -30]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'important contribution with very promising results', they express significant doubts and concerns about the technical aspects and clarity of the paper. The reviewer states they are 'not able to converge to a final rating at this point' due to these issues. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I am inclined to think' and 'please elaborate' which are polite ways of expressing concerns or requesting more information. The reviewer also balances criticism with positive acknowledgments of the paper's contributions. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, professional tone overall."", ""The sentiment score is 70 (positive) because the reviewer finds the paper 'well-motivated' and the algorithm 'original and interesting'. They also mention 'good empirical performance'. However, it's not a perfect score as they raise some questions and suggest potential improvements. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They phrase their critiques as questions or wonderings, which is a polite way to express concerns. The reviewer also acknowledges the authors' work and insights, showing respect for their efforts."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('great importance', 'performs well', 'scalable and easy to implement'), they express significant concerns and state that the paper is not ready for publication in its current form. The overall tone is more critical than positive. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges the potential importance of the work, and provides constructive feedback. They use phrases like 'I believe' and 'It seems' to soften criticisms, and offer specific suggestions for improvement. However, the review is not overly deferential, maintaining a professional tone while clearly expressing concerns.""]"
"['The main contribution of the paper are methods for propagating approximate uncertainty in neural networks through max and argmax layers. The proposed methods are explained well. The paper is clearly written. The methods are validated in small scale experiments and seem to work well.\n\nThe proposed approach is not much more accurate than Monte Carlo dropout, but is more computationally efficient. The standard way of efficiently predicting at test time with a dropout-trained network is to simply scale the weights. Could the authors try calibration on networks of this type and compare against the proposed method with calibration? (i.e. scale the predicted logits of the standard test-time network to be on the same scale as the logits under your approach)', 'This paper revisits the feed-forward propagation of mean and variance in neurons. In particular, it addresses the problem of propagating uncertainty through max-pooling layers and softmax. This is important since previous methods on probabilistic neural networks have not handled these challenges, hence preventing them from using max-pooling and softmax in a principled way.\n\nIn general, the authors did a good job approximating the mean and variance for the output of max-pooling and softmax. I have several concerns:\n\nThe authors claimed that they derived new approximation for leaky ReLU as well. It seems the approximation in Eq. (22)-(25) is exactly the same as Gast and Roth, 2018, both leveraging the results on obtaining the maximum of two Gaussian random variables.\n\nThe Bayesian formulation is not clear enough and seems a bit problematic in Sec. 2. For example, in Eq. (2), the authors mentioned p(X^k | x_0) as the posterior distribution. In this case, what is the corresponding prior? Besides, it should be made clear from the beginning that the network parameters W is not treated as random variables.\n\nIt is an interesting idea to incorporate the Gumbel distribution’s variance into the approximation in Eq. (10). Do you have any empirical results on how accurate the approximation in Eq. (10) is?\n\nSimilarly, the approximation from Eq. (13) to Eq. (14)-(15) seems a bit ad-hoc. It is good to know that the approximation is exact in the case of two input variables. However, it would be more convincing if the authors could investigate more about the accuracy of the approximation (either empirically or theoretically) when there are more than two variables.\n\nThe organization of the paper could be improved. The notion of nonlinearity is not mentioned until Sec. 3. When reading Sec. 2, one would wonder where the nonlinear transformation happens. It would help to clarify a bit at the start of Sec. 2.\n\nIn terms of experiments, one important benefit of feed-forward propagation is that it avoid the multi-pass MC estimates. However, it seems the performance boost on NLL mainly comes from the calibration, where \\sigma^* needs to be computed using multi-pass MC estimates.\n\nThe noise level (std of 10^-4 and 0.01) seems quite small in Table 1. According to the results, it seems the error of \\sigma_2 increases a lot as the noise level goes from 10^-4 to 0.01, suggesting that the approximation does not work well when the input noise is large. How is the accuracy when the noise level further increases?\n\nUnlike the natural-parameter networks (NPN) in Wang et al. (2016), the proposed work assumes zero variance in the parameters W. It would be interesting to see whether the proposed methods could also improve NPN.\n', '* Summary\n\nThe authors focus on the problem of uncertainty propagation DNN. The authors claim two main contributions: they revisit the assumptions of the feed forward method (proposed by several authors as an inference method for BNNs based on ADF/EP) and proposed a new approximation for argmax/max based functions that allows to propagated the first two moments analytically. \n\n* Comments:\n\nThe authors claim two main contributions: an analysis for the feed forward method (sections 2 and 3) previously proposed by several authors as an inference method for BNN based on ADF/EP, and a new method to propagate the uncertainty through argmax/max based operations (section 4).\n\nRegarding the first contribution, I was expecting some new insights about the method that I did not find. I would suggest to focus on the second contribution and refactor this section as a background section. I would make it shorter, focusing on the representation of probabilities as latent variables trough a function, which is the important bit to understand the real contribution of the paper described in section 4. I would also remove some examples that do not seem critical to understand the rest of the paper and just increase its length.\n\nThe second contribution is quite novel. The authors propose a new approximation of argmax/max operations. The firstly proposed an approximation for argmax operations, e.g. latent variable view of the softmax, that avoids resorting to the normal cdf function that has numerical stability issues. Secondly, they suggest an approximation for max based operations, e.g. leaky relu, that again, does not depend on the gaussian cdf. \n\nIn the experimental section, the authors test:\na)\tThe accuracy of the proposed method approximating the posterior of the neurons\nb)\tEnd-to-end training benefits\n\nIn a) they use MC to collect the ground truth statistics and compare the proposed method (AP2) with a classical NN (AP1). The analysis is nice but I miss a comparison with other state-of-the-art methods. In particular, the authors claim that the novelty of their method compared to other feed-forward methods is that they can propagate the uncertainty through argmax/max operations analytically. They do not compare with these other feed forwards methods to show the benefit of this.  This is shown in the end-to-end training experiments; however, I would like to see a direct comparison with the classical paper (Hern´andez-Lobato & Adams, 2015). Finally, one of the justifications of the approximations that they propose is to avoid the numerical issues of the standard cdf. Have the authors compared with this, e.g. eq 18a, 18b? Using a robust implementation of the normal cdf/pdf function and further truncating them to avoid negative variances?\n\ntypo: Shortly before eq. 12, Should not S_{n-1} be defined as the softmax operation?\n']","[70, 20, -20]","[80, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer starts with praising the paper's main contribution, clarity of explanation, and validation through experiments. The phrase 'seem to work well' indicates a positive outcome. The reviewer also mentions that the paper is 'clearly written,' which is a strong positive point. However, it's not a perfect 100 as the reviewer does point out that the proposed approach is not much more accurate than an existing method (Monte Carlo dropout). The politeness score is 80 (very polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their suggestion for improvement as a question ('Could the authors try...?') rather than a demand. The tone is professional and courteous, avoiding any harsh criticism or negative language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' good job in approximating mean and variance for max-pooling and softmax outputs. However, they also express several concerns and suggest improvements, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively, and asks questions rather than making blunt statements. They use phrases like 'It is an interesting idea' and 'It would be more convincing if' which maintain a polite tone while providing feedback. The review is detailed and specific in its recommendations, which is professional and helpful, further contributing to the politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the second contribution, they express disappointment with the first contribution and suggest significant changes to the paper's structure. They also point out missing comparisons and analyses. However, it's not entirely negative as they do recognize some positive aspects of the work. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. They use phrases like 'I would suggest' and 'I miss' instead of more confrontational language. The reviewer also provides constructive feedback and even points out a typo in a helpful manner.""]"
"[""Revision: The authors addressed most of my concerns and clearly put in effort to improve the paper. The paper explains the central idea better, is more precise in terminology in general, and the additional ablation gives more insight into the relative importance of the advantage weighting. I still think that the results are a bit limited in scope but the idea is interesting and seems to work for the tasks in the paper. I adjusted my score to reflect this.\n\nSummary:\nThe paper proposes an HRL system in which the mutual information of the latent (option) variable and the state-action pairs is approximately maximized. To approximate the mutual information term, samples are reweighted based on their estimated advantage. TD3 is used to optimize the modules of the system. The system is evaluated on continuous control task from OpenAI gym and rllab.\n\nFor the most part, the paper is well-written and it provides a good overview of related work and relevant terminology. The experiments seem sound even though the results are not that impressive. The extra analysis of the option space and temporal distribution is interesting. \n\nSome parts of the theoretical justification for the method are not entirely clear to me and would benefit from some clarification. Most importantly, it is not clear to me why the policy in Equation 7 is considered to be optimal. Given some value or advantage function, the optimal policy would be the one that picks the action that maximizes it. The authors refer to earlier work in which similar equations are used, but in those papers this is typically in the context of some entropy maximizing penalty or KL constraint. A temperature parameter would also influence the exploration-exploitation trade-off in this ‘optimal’ policy. I understand that the rough intuition is to take actions with higher advantage more often while still being stochastic and exploring but the motivation could be more precise given that most of the subsequent arguments are built on top of it. However, this is not the policy that is used to generate behavior. In short, the paper is clear enough about how the method is constructed but it is not very clear to me *why* the mutual information should be optimized with respect to this 'optimal' policy instead of the actual policy one is generating trajectories from.\n\nHRL is an interesting area of research with the potential to learn complicated behaviors. However, it is currently not clear how to evaluate the importance/usefulness of hierarchical RL systems directly and the tasks in the paper are still solvable by standard systems. That said, the occasional increase in sample efficiency over plain TD3 looks promising. It is somewhat disappointing that the number of beneficial option is generally so low. To get more insight in the methods it would have been nice to see a more systematic ablation of related methods with different mutual information pairings (action or state only) and without the advantage weighting. Could it be that the number of options has to remain limited because there is no parameter sharing between them? It would be interesting to see results on more challenging control problems where the hypothesized multi-modal advantage structure is more likely to be present.\n\nAll in all I think that this is an interesting paper but the foundations of the theoretical motivation need a bit more clarification. In addition, experiments on more challenging problems and a more systematic comparison with similar models would make this a much stronger paper.\n\nMinor issues/typos:\n- Contributions 2 and 3 have a lot of overlap.\n- The ‘o’ in Equation 2 should not be bold font. \n- Appendix A. Shouldn’t there be summations over ‘o’ in the entropy definitions?\n\n\n"", 'The authors propose an HRL algorithm that attempts to learn options that maximize their mutual information with the state-action density under the optimal policy.\n\nSeveral key terms are used in ways that differ from the rest of the literature. The authors claim options are learned in an ""unsupervised"" manner, but it is unclear what this means. Previous work (none of which is cited) has dealt with unsupervised option discovery in the context of mutual information maximization (Variational intrinsic control, diversity is all you need, etc), but they do so in the absence of reward, unlike this paper. ""Optimal policy"" is similarly abused, with it appearing to mean optimal from the perspective of the current model parameters, rather than optimal in any global sense. Or at least I think that is what the authors intend. If they do mean the globally optimal policy, then its unclear how to interpret Equation 8, with its reference to a behavior policy and an advantage function, neither of which would be available if meant to represent the global optimum.\n\nEquation 10 comes out of nowhere. One must assume they meant ""maximize mutual information"" and not ""minimize"", but who knows. Why is white-noise being added to the states and actions? Is this some sort of noise-contrastive estimation approach to mutual information estimation? It doesn\'t appear to be, but it is unclear what else could motivate it. Even the appendices fail to shine light on this equation.\n\nThe algorithm block isn\'t terribly helpful. The ""t"" variable is used outside of its for loop, which draws into question the exact nesting structure of the underlying algorithm (which isn\'t obvious for HRL methods). There aren\'t any equations referenced, with the option policy network\'s update not even referencing the loss nor data over which the loss would be evaluated.\n\nSome of the experimental results show promise, but the PPO Ant result raises some questions. Clearly the OpenAI implementation of PPO used would have tuned for the OpenAI gym Ant implementation, and the appendix shows it getting decent results. But it never takes off in the harder RlLab version -- were the hyper-parameters adjusted for this new environment?\n\nIt is also odd that no other HRL approaches are evaluated against, given the number cited. Running these methods might be too costly, but surely a table comparing results reported in those papers should be included.\n\nA minor point: another good baseline would be TD3 with the action repeat adjusted to be inline with the gating policy.\n\nI apologise if this review came off as too harsh -- I believe a good paper can be made of this with extensive rewrites and additional experiments. But the complete lack of clarity makes it feel like it was rushed out prematurely.\n\nEDIT: Now this is a paper that makes sense! With the terminology cleared up and the algorithm fully unpacked, this approach seems quite interesting. The experimental results could always be stronger, but no longer have any holes in them. Score 3-->6', 'The paper considers the problem of hierarchical reinforcement learning, and proposes a criterion that aims to maximize the mutual information between options and state-action pairs.\n\nThe idea of having options partition the state-action space is appealing, because this allows options visit the same states, so long as they act differently, which is natural. The authors show empirically that the learned options do indeed decompose the state-action space, but not the state space.\n\nThere is a lot in the paper already, but the exposition could be much improved. Many of the design choices appear very ad hoc, and some are outright confusing. Some detailed comments:\n\n* I got really confused in Section 3 re: advantage-weighted importance sampling. Why do this? If the option policies are trying to optimize reward, won’t they become optimal eventually (or so we usually hope in RL)? This section seems to assume that the advantage function is somehow given. It also doesn’t look like this gets used in the actual algorithm, and in fact on page 5 it is stated that “we decided to use the on-policy buffer in our implementation”. Then why introduce the off-policy bit at all, and list it as a contribution?\n* Please motivate the choices. The paper mentions that one of its contributions are options with deterministic policies. This isn’t a contribution unless it addresses some problem that stochastic policies fail at. For example, DPG allows one to address continuous control problems.\nSame with using information maximization. The paper literally states that “an interpretable representation can be learned by maximizing mutual information”. Representation of what? MI between what?\n* Although the qualitative results are nice (separation of the state-action space), empirical results are modest at best. This may be ok, because based on the partition of the state-action space it seems that the option policies learn diverse behaviors in the same states. Maybe videos visualizing different options from the same states would be informative.\n* Please add more discussion on why the options are switched at every step']","[50, -50, -20]","[70, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the authors addressed most concerns and improved the paper, showing an overall positive tone. However, they still express some reservations about the limited scope of results and the need for clarification on theoretical aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive feedback. They use phrases like 'I still think' and 'it would be interesting' which maintain a collegial tone. The reviewer balances praise with critique in a professional manner, avoiding harsh language even when pointing out areas for improvement."", ""The sentiment score is -50 because the review starts with critical observations and points out several issues with the paper, such as unclear terminology, unexplained equations, and questionable experimental results. However, the reviewer does acknowledge some promise in the results and suggests that a good paper could be made with revisions. The final edit indicates a significant improvement, which slightly mitigates the overall negative sentiment. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I apologise if this review came off as too harsh' and offer constructive suggestions for improvement. The reviewer also acknowledges the potential for a good paper with revisions, showing a degree of politeness and encouragement despite the criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The idea of having options partition the state-action space is appealing'), they also express several criticisms and concerns. The reviewer states that 'the exposition could be much improved' and that 'Many of the design choices appear very ad hoc, and some are outright confusing.' They also mention that 'empirical results are modest at best.' These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer maintains a professional tone throughout. They use phrases like 'Please motivate the choices' and 'Please add more discussion,' which are polite ways of requesting improvements. The reviewer also acknowledges positive aspects of the work and provides detailed, constructive feedback, which is a polite approach to peer review. However, some direct criticisms prevent the score from being higher.""]"
"['In this paper, the authors presented a large experimental study of curiosity-driven reinforcement learning on various tasks. In the experimental studies, the authors also compared several feature space embedding methods, including identical mapping (pixels), random embedding, variational autoencoders and inverse dynamics features. The authors found that in many of the tasks, learning based on intrinsic rewards could generate good performance on extrinsic rewards, when the intrinsic rewards and extrinsic rewards are correlated. The authors also found that random features embedding, somewhat surprisingly, performs well in the tasks.\n\nOverall, the paper is well written with clarity. Experimental setup is easy to understand. The authors provided code, which could help other researchers reproduce their result.\n\nWeaknesses: \n\n1) as an experimental study, it would be valuable to compare the performance of curiosity-based learning versus learning based on well-defined extrinsic rewards. The author is correct that in many tasks, well-behaved extrinsic rewards are hard to find. But for problems with well-defined extrinsic rewards, such a comparison could help readers understand the relative performance of curiosity-based learning and/or how much headroom there exists to improve the current methods.\n\n2) it is surprising that random features perform so well in the experiments. The authors did provide literature in classification that had similar findings, but it would be beneficial for the authors to explore reasons that random features perform well in reinforcement learning.', ""This paper studies the dynamics-based curiosity intrinsic reward where the agent is rewarded highly in states where the forward dynamic prediction errors are high in an embedding space (either due to complexity of the state or unfamiliarity).\n\nOverall I like the paper, it's systematic and follows a series of practical considerations and step-by-step experimentations.\n\nOne of the main area which is missing in the paper is the comparison to two other class of RL methods: count-based exploration and novelty search. While the section 4 has a discussion on related papers, there's no systematic experimental comparison across these methods. In sec. 4, there's a reference to an initial set of experiments with count-based methods without much details.\n\nAnother area of improvement is the experiments around VAE. While the paper shows experimentally that they aren't as successful as the RFs or IDFs, there's no further discussion on the reasons for poor performance. \n\nAlso it's not clear from the details in the paper what are the architectures for the VAE and RFs (there's a reference to the code but would've been better to have sufficient details in the paper).\n\nAn interesting area for future work could be on early stopping techniques for embedding training - it seems that RFs perform well without any training while in some scenarios the IDFs work overall the best. So it would be interesting to explore how much training is needed for the embedding model. RFs are never trained and IDFs are continuously trained. So maybe somewhere in between could be the sweet spot with training for a short while and then fixing the features."", 'The authors consider the setting of a RL agent that exclusively receives intrinsic reward during training that is intended to model curiosity; technically, ‘curiosity’ is quantified by the ability of the agent to predict its own forward dynamics [Pathak, et al., ICML17]. This study primarily centers around an initially somewhat surprising result that non-trivial policies can be learned for many ’simpler’ video games (e.g., Atari, Super Mario, Pong) using just curiosity as reward. While this is primarily an empirical study, one aspect considered was the observation representation (raw pixels, random features, VAE, and inverse dynamics features [Pathak, et al., ICML17]). In examining reward curves (generally extrinsic during testing), ‘curiosity-based’ reward generally works with the representation effectiveness varying across different testbeds. They also conduct more in-depth experiments on specific testbeds to study the dynamics (e.g., Super Mario, Juggling, Ant Robot, Multi-agent Pong) — perhaps most interestingly showing representation-based transfer of different embeddings across levels in Super Mario. Finally, they consider the Unity maze testbed, combining intrinsic rewards with the end-state goal reward to generate a more dense reward space. \n\nFrom a high level perspective, this is an interesting result that ostensibly will lead to a fair amount of discussion within the RL community (and already has based on earlier versions of this work). However, it isn’t entirely clear if the primary contribution is showing that ‘curiosity reward’ is a potentially promising approach or if game environments aren’t particularly good testbeds for practical RL algorithms — given the lack of significant results on more realistic domains, my intuition leans toward the later (the ant robot is interesting, but one can come up with ‘simulator artifact’ based explanations). And honestly, I think the paper reads as if leaning toward the same conclusion. Regardless, given the prevalence of these types of testbed environments, either is a useful discussion to have. Maybe the end result could minimally be a new baseline that can help quantify the ‘difficulty’ of a particular environment. \n\nFrom the perspective of a purely technical contribution, there are fewer exciting results. The basic method is taken from [Parthak, et al., ICML17] (modulo some empirical choices such as using PPO). The comparison of different observation representations doesn’t include any analytical component, the empirical component is primarily inconclusive, and the position statements are fairly non-controversial (and not really conclusively supported). The testbeds all existed previously and this is mostly the effort of pulling then together. Even the ‘focused experiments’ can be explained with the intuitive narrative that in the state/action space, there is always more uncertainty the farther one goes from the starting point and this is more of a result of massive computation being applied primarily to problems that are designed to provide some level of novelly (the Roboschool examples are a bit more interesting, but also less conclusive). Finally, Figure 5 is interesting in showing that ‘curiosity + extrinsic’ improves over extrinsic rewards — although this isn’t particularly surprising for maze navigation that has such sparse rewards and can be viewed as something like ‘active exploration’. With respect to this specific setting, the authors may want to consider [Mirowski, et al., Learning to Navigate in Complex Environments, ICLR17] with respect to auxiliary loss + RL extrinsic rewards to improve performance (in this case, also in maze environments).\n\nIn just considering the empirical results, they clearly entail a fair amount of effort and just a dump of the code and experiments on the community will likely lead to new findings (even if they are that game simulators are weaker testbeds than previously thought). It is easy to ask for additional experiments (i.e., other mechanisms of uncertainty such as the count-based discussed in related work, other settings in 2.2) — but the quality seems high enough that I basically trust the settings and findings. Beyond the core findings, the other settings are less convincingly supported by seem more like work in progress and this paper is really just a scaling-up of [Pathak, et al., ICML17] without generating any strong results regarding questions around representation, what to do about stochasticity (although the discussion regarding something like ‘curiosity honeypots’ is interesting). Thus, it reads like one interesting finding around curiosity-driven RL working in games plus a bunch of preliminary findings trying to grasp at some explanations and potential future directions.\n\nEvaluating the paper along the requested dimensions:\n\n= Quality: The paper is well-written with a large set of experiments, making the case that exclusively using curiosity-based reward is very promising for the widely-used game RL testbeds. Modulo a few pointers, the work is well-contextualized and makes reasonable assumptions in conducting its experiments. The submitted code and videos result in a high-quality presentation and trustworthiness of the results. (7/10)\n\n= Clarity: The paper is very clearly written. (7/10)\n\n= Originality: The algorithmic approach is a combination of [Parthak, et al., ICML17] and [Schulman, et al. 2017] (with some experiments using [Kingma & Welling, 2013]). All of the testbeds have been used previously. Other than completely relying on curiously-based reward exclusively, there is little here. In considering combining with extrinsic rewards, I would also consider [Mirowski, et al., ICLR17], which is actually more involved in this regard. (4/10)\n\n= Significance: Primarily, this ‘finishes’ [Parthak, et al., ICML17] to its logical conclusion for game-based environments and should spur interesting conversations and further research. In terms of actual technical contributions, I believe much less significant. (5/10)\n\n=== Pros ===\n+ demonstrates that curiosity-based reward works in simpler game environments\n+ (implicitly) calls into question the value of these testbed environments\n+ well written, with a large set of experiments and some interesting observations/discussions\n\n=== Cons ===\n- little methodological innovation or analytical explanations\n- offers minimal (but some) evidence that curiosity-based reward works in more realistic settings\n- doesn’t answer the one question regarding observation representation that it set out to evaluate\n- the more interesting problem, RL + auxiliary loss isn’t evaluated in detail\n- presumably, the sample complexity is ridiculous\n\nOverall, I am ambivalent. I think that more casual ML/RL researchers will find these results controversial and surprising while more experienced researchers will see curiosity-driven learning to be explainable primarily by the intuition of the “The fact that the curiosity reward is often sufficient” paragraph of page 6, demanding more complex environments before accepting that this form of curiosity is particularly useful. The ostensible goal of learning more about observation representations is mostly preliminary — and this direction holds promise of for a stronger set of findings. Dealing with highly stochastic environments seems a potential fatal flaw of the assumptions of this method. However, as I said previously, this is probably a discussion worth having given the popularity and visibility of game-based testbeds — so, coupled with the overall quality of the paper, I lean toward a weak accept.\n']","[60, 60, -20]","[80, 70, 60]","[""The sentiment score is 60 (positive) because the reviewer starts with a neutral summary of the paper's content, then explicitly states that the paper is 'well written with clarity' and praises the authors for providing code. The reviewer does point out two weaknesses, but frames them as suggestions for improvement rather than severe criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' correct assertions, and frames criticisms as constructive suggestions using phrases like 'it would be valuable' and 'it would be beneficial'. The reviewer also balances critiques with positive comments, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer starts by saying 'Overall I like the paper' and describes it as 'systematic' with 'step-by-step experimentations'. The reviewer also suggests areas for improvement and future work, which indicates a balanced but overall positive view. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or negative phrasing. The reviewer acknowledges the paper's strengths before pointing out areas for improvement, which is a polite approach to feedback. The use of phrases like 'One of the main area which is missing' and 'Another area of improvement' are diplomatic ways of suggesting changes."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects and effort in the paper, they express significant reservations about the novelty, significance, and broader applicability of the results. The reviewer uses phrases like 'ambivalent', 'weak accept', and points out several cons, indicating an overall lukewarm reception. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout, acknowledging the paper's strengths and the authors' efforts. They use polite language like 'interesting result', 'well-written', and provide balanced feedback with both pros and cons. The reviewer also offers constructive suggestions and additional references, which is a courteous approach in academic reviewing.""]"
"['The paper proposes to use a differentiable drawing environment to synthesize images and provides information about some initial experiments. \n\nNot yet great about this paper: \n - the paper feels premature: There is a nice idea, but restricting the drawing environment to be \n - Some of the choices in the paper are a bit surprising, e.g. the lines in the drawing method are restricted to be at most 16 points long. If you look at real drawing data (e.g. the quickdraw dataset: https://quickdraw.withgoogle.com/data) you will find that users draw much longer lines typically. \nEDIT: the new version of the paper is much better but still feels like a bit incomplete. I personally would prefer a more complete evaluation and discussion of the proposed method. \n - the entire evaluation of this paper is purely qualitative (and that is not quite very convincing either). I feel it would be important for this paper to add some quantitative measure of quality. E.g. train an MNIST recognizer synthesized data and compare that to a recognizer trained on the original MNIST data. \n - a proper discussion of how the proposed environment is different from the environment proposed by Ganin et al (Deepmind\'s SPIRAL) \n\nMinor comments: \n - abstract: why is it like ""dreaming"" -> I do agree with the rest of that statement, but I don\'t see the connection to dreaming\n - abstract: ""upper agent"" -> is entirely unclear here. \n - abstract: the footnote at the end of the abstract is at a strange location\n - introduction: and could thus -> and can thus \n - introduction: second paragraph - it would be good to add some citations to this paragraph. \n - resulted image-> resulting image\n - the sentence: ""We can generate....data is cheap"" - is quite unclear to me at this time. Most of it becomes clearer later in the paper - but I feel it would be good to put this into proper context here (or not mention it)\n - we obtained -> we obtain\n - called a generator -> call a generator \n - the entire last paragraph on the first page is completely unclear to me when reading it here. \n - equations 1, 2: it\'s unclear whether coordinates are absolute or relative coordinates. \n- fig 1: it\'s very confusing that the generator, that is described first is represented at the right. \n - sec 3.2 - first line: wrong figure reference - you refer to fig 2 - but probably mean fig 1\n - page 3 bottom: by appending the encoded color and radius data we have a feature with shape 64x64xn -> I don\'t quite see how this is true. The image was 64x64 -> and I don\'t quite understand why you have a color/radius for each pixel. \n - sec 3.3 - it seem sthat there is a partial sentence missing \n - sec 3.4 - is it relevant to the rest of the paper that the web application exists (and how it was implemented). \n - fig 2 / fig 3: these figures are very hard to read. Maybe inverting the images would help. Also fig 3 has very little value.  ', 'Revision:\n\nThe authors have taken my advice and addressed my concerns wholeheartedly. It is clear to me that they have taken efforts to make notable progress during the rebuttal period. Summary of their improvements:\n\n- They have extended their methodology to handle multiple strokes\n- The model has been converted to a latent-space generative model (similar to Sketch-RNN, where the latent space is from a seq2seq VAE, and SPIRAL where the latent space is used by an adversarial framework)\n- They have ran addition experiments on a diverse set of datasets (now includes Kanji and QuickDraw), in addition to omniglot and mnist.\n- Newer version is better written, and I like how they are also honest to admit limitations of their model rather than hide them.\n\nI think this work is a great companion to existing work such as Sketch-RNN and SPIRAL. As mentioned in my original review, the main advantage of this is the ability to train with very limited compute resources, due to the model-based learning inspired by model-based RL work (they cited some work on world models). Taking important concepts from various different (sub) research areas and synthesizing them into this nice work should be an inspiration to the broader community. The release of their code to reproduce results of all the experiments will also facilitate future research into this exciting topic of vector-drawing models.\n\nI have revised my score to 8, since I believe this to be at least in the better half of accepted papers at ICLR based on my experience of publishing and attending the conference in the past few years. I hope the other reviewers can have some time to reevaluate the revision.\n\nOriginal review:\n\nSummary: they propose a differentiable learning algorithm that can output a brush stroke that can approximate a pixel image input, such as MNIST or Omniglot. Unlike sketch-pix2seq[3] (which is a pixel input -> sketch output model based on sketch-rnn[2]), their method trains in an unsupervised manner and does not require paired image/stroke data. They do this via training a ""world model"" to approximate brush painting software and emulate it. Since this emulation model is differentiable, they can easily train an algorithm to output a stroke to approximate the drawing via back propagation, and avoid using RL and costly compute such in earlier works such as [1].\n\nThe main strength of this paper is the original thought that went into it. From reading the paper, my guess is the authors came from a background that is not pure ML research (for instance, they are experts in Javascript, WebGL, and their writing style is easy to read), and it\'s great to see new ideas into our field. While research from big labs [1] have the advantage of having access to massive compute so that they can run large scale RL experiments to train an agent to ""sketch"" something that looks like MNIST or Omniglot, the authors probably had limited resources, and had to be more creative to come up with a solution to do the same thing that trains in a couple of hours using a single P40 GPU. Unlike [1] that used an actual software rendering package that is controlled by a stroke-drawing agent, their creative approach here is to train a generator network to learn to approximate a painting package they had built, and then freeze the weights of this generator to efficiently train an agent to draw. The results for MNIST and Omniglot look comparable to [1] but achieved with much fewer resources. I find this work refreshing, and I think it can be potentially much more impactful than [1] since people can actually use it with limited compute resources, and without using RL.\n\nThat being said, things are not all rosy, and I feel there are things that need to be done for this work to be ready for publication in a good venue like ICLR. Below are a few of my suggestions that I hope will help the authors improve their work, for either this conference, or if it gets rejected, I encourage the authors to try the next conference with these improvements:\n\n1) multiple strokes, longe strokes. I don\'t think having a model that can output only a single stroke is scalable to other (simple) datasets such pixel versions of KangiVG [4] or QuickDraw [5]. The authors mentioned the need for an RNN, but couldn\'t the encoder just output the stroke in a format that contains the pen-down / pen-up event, like the stroke format suggested in [2]? Maybe, maybe not, but in either case, for this work to matter, multiple stroke generation is needed. Most datasets are also longer than 16 points, so you will need to show that your method works for say 80-120 points for this method to be comparable to existing work. If you can\'t scale up 16 points, would like to see a detailed discussion as to why.\n\n2) While I like this method and approach, to play devil\'s advocate, what if I simply use an off the shelf bmp-to-svg converter that is fast and efficient (like [6]), and just build a set of stroke data from a dataset of pixel data, and train a sketch-rnn type model described in [3] to convert from pixel to stroke? What does this method offer that my description fails to offer? Would like to see some discussion there.\n\n3) I\'ll give a hint for as to what I think for (2). I think the value in this method is that it can be converted to a full generative model with latent variables (like a VAE, GAN, sketch-rnn) where you can feed in a random vector (gaussian or uniform), and get a sketch as an output, and do things like interpolate between two sketches. Correct me if I\'m wrong, but I don\'t think the encoder here in the first figure outputs an embedding that has a Gaussian prior (like a VAE), so it fails to be a generative model (check out [1], even that is a latent variable model). I think the model can be easily converted to one though to address this issue, and I strongly encourage the authors to try enforcing a Gaussian prior to an embedding space (that can fit right between the 16x16x128 average pooling op to the fully connected 1024 sized layer), and show results where we can interpolate between two latent variables and see how the vector sketches are interpolated. This has also been done in [2]. If the authors need space, I suggest putting the loss diagrams near the end into the appendix, since those are not too interesting to look at.\n\n4) As mentioned earlier, I would love to see experimental results on [4] KangiVG and [5] QuickDraw datasets, even subsets of them. An interesting result would be to compare the stroke order of this algorithm with the natural stroke order for human doodles / Chinese characters.\n\nMinor points:\n\na) The figures look like they are bitmap, pixel images, but for a paper advocating stroke/vector images, I recommend exporting the diagrams in SVG format and convert them to PDF so they like crisp in the paper.\n\nb) Write style: There are some terms like ""huge"" dataset that is subjective and relative. While I\'m happy about the writing style of this paper, maybe some reviewers who are more academic types might not like it and have a negative bias against this work. If things don\'t work out this time, I recommend the authors asking some friends who have published (successfully) at good ML conferences to proof read this paper for content and style.\n\nc) It\'s great to see that the implementation is open sourced, and put it on github. Next time, I recommend uploading it to an anonymous github profile/repo, although personally (and for the record, in case area chairs are looking), I don\'t mind at all in this case, and I don\'t think the author\'s github address revealed any real identity (I haven\'t tried digging deeper). Some other reviewers / area chairs might not like to see a github link that is not anonymized though.\n\nSo in the end, even though I really like this paper, I can only give a score of 6 (edit: this has since been revised upward to 8). If the authors are able to address points 1-4, please do what you can in the next few weeks and give it your best shot. I\'ll look at the paper again and will revise the score upwards by a point or two if I think the improvements are there. If not, and this work ends up getting rejected, please consider improving the work later on and submitting to the next venue. Good luck!\n\n[1] SPIRAL https://arxiv.org/abs/1804.01118\n[2] sketch-rnn https://arxiv.org/abs/1704.03477\n[3] sketch-pix2seq https://arxiv.org/abs/1709.04121\n[4] http://kanjivg.tagaini.net/\n[5] https://quickdraw.withgoogle.com/data\n[6] https://vectormagic.com/\n', 'Revision:\n\nThe addition of new datasets and the qualitative demonstration of latent space interpolations and algebra are quite convincing. Interpolations from raster-based generative models such as the original VAE tend to be blurry and not semantic. The interpolations in this paper do a good job of demonstrating the usefulness of structure.\n\nThe classification metric is reasonable, but there is no comparison with SPIRAL, and only a comparison with ablated versions of the StrokeNet agent. I see no reason why the comparison with SPIRAL was removed for this metric.\n\nFigure 11 does a good job of showing the usefulness of gradients over reinforcement learning, but should have a better x range so that one of the curves doesn\'t just become a vertical line, which is bad for stylistic reasons.\n\nThe writing has improved, but still has stylistic and grammatical issues. A few examples, ""there’re"", ""the network could be more aware of what it’s exactly doing"", ""discriminator loss given its popularity and mightiness to achieve adversarial learning"". A full enumeration would be out of scope of this review. I encourage the authors to iterate more on the writing, and get the paper proofread by more people.\n\nIn summary, the paper\'s quality has significantly improved, but some presentation issues keep it from being a great paper. The idea presented in the paper is however interesting and timely and deserves to be shared with the wider generative models community, which makes me lean towards an accept.\n\nOriginal Review:\n\nThis paper deals with the problem of strokes-based image generation (in contrast to raster-based). The authors define strokes as a list of coordinates and pressure values along with the color and brush radius of a stroke. Then the authors investigate whether an agent can learn to produce the stroke corresponding to a given target image. The authors show that they were able to do so for the MNIST and OMNIGLOT datasets. This is done by first training an encoder-decoder pair of neural networks where the latent variable is the stroke, and the encoder and decoder have specific structure which takes advantage of the known stroke structure of the latent variable.\n\nThe paper contains no quantitative evaluation, either with existing methods or with any baselines. No ablations are conducted to understand which techniques provide value and which don\'t. The paper does present some qualitative examples of rendered strokes but it\'s not clear whether these are from the training set or an unseen test set. It\'s not clear whether the model is generalizing or not.\n\nThe writing is also very unclear. I had to fill in the blanks a lot. It isn\'t clear what the objective of the paper is. Why are we generating strokes? What use is the software for rendering images from strokes? Is it differentiable? Apparently not. The authors talk about differentiable rendering engines, but ultimately we learn that a learnt neural network decoder is the differentiable renderer.\n\nTo improve this paper and make it acceptable, I recommend the following:\n\n1. Improve the presentation so that it\'s very clear what\'s being contributed. Instead of writing the chronological story of what you did, instead you should explain the problem, explain why current solutions are lacking, and then present your own solutions, and then quantify the improvements from your solution.\n\n2. Avoid casual language such as ""Reason may be"", ""The agent is just a plain"", ""since neural nets are famouse for their ability to approximate all sorts of functions"".\n\n3. Show that strokes-based generation enables capabilities that raster-based generation doesn\'t. For instance, you could show that the agent is able to systematically generalize to very different types of images. I\'d also recommend presenting results on datasets more complex than MNIST and OMNIGLOT.']","[-50, 80, -20]","[20, 90, 50]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several areas where the paper falls short or needs improvement. The reviewer uses phrases like 'Not yet great about this paper', 'feels premature', and 'entirely evaluation of this paper is purely qualitative (and that is not quite very convincing either)'. However, it's not entirely negative as the reviewer acknowledges there's a 'nice idea' and that the new version is 'much better', hence not giving it the lowest possible score. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language. They offer constructive feedback and suggestions for improvement rather than harsh criticism. Phrases like 'I personally would prefer' and 'it would be good to' indicate a respectful tone. However, the directness of the criticism prevents a higher politeness score."", ""The sentiment score is 80 because the reviewer expresses very positive views about the paper, especially after the revisions. They describe the work as 'great', 'refreshing', and 'potentially much more impactful' than previous work. They increased their score to 8, indicating strong approval. However, it's not 100 as they still had some suggestions for improvement in the original review. The politeness score is 90 because the reviewer uses consistently respectful and encouraging language, offering constructive criticism in a positive manner. They use phrases like 'I hope', 'I encourage', and 'Good luck!', showing support for the authors. The reviewer also acknowledges the authors' efforts and improvements. The score isn't 100 as the language, while very polite, doesn't reach an extreme level of formality or deference."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges improvements and finds the idea interesting, they still point out significant issues with the paper, such as lack of comparisons, presentation problems, and writing quality. The overall tone leans towards acceptance but with reservations. The politeness score is moderately positive (50) as the reviewer uses respectful language, offers constructive criticism, and provides specific suggestions for improvement. They avoid harsh criticism and use phrases like 'I encourage the authors' and 'I recommend', which contribute to a polite tone. However, the reviewer doesn't go out of their way to be overly polite or complimentary, maintaining a professional and somewhat neutral stance.""]"
"[""This paper presents a dialogue response generation model based on the framework of adversarial autoencoder. Specifically, the proposed model uses an autoencoder to encode and decode a response in a dialogue, conditioning on the context of the dialogue. The RNN encoded context is used as the prior of the latent variable in the autoencoder, and the whole dialogue (context + response) is used to infer the posterior of the latent variable. The inference is done by the adversarial training to match the prior and the posterior of the latent variable. Besides constructing the prior with a single Gaussian, the variant of the proposed model is also proposed where the prior is constructed with a Gaussian mixture model.\n\nMy comments are as follows:\n\n1. The paper is well-written and easy to follow.\n\n2. The experiments seem quite strong and the compared models are properly selected. I'm not an expert in the specific area of the dialogue generation. But to me, the results seem convincing to me. \n\n3. The usage of the Wasserstein distance in the proposed model does not make sense to me. Both the adversarial training in AAE and minimising the Wasserstein distance are able to match the prior and posterior of the latent variable. If the former is used in the proposed model, then how is the Wasserstein distance used at the same time? I also checked Algorithm 1 and did not find how the Wasserstein distance comes in. This is the first question that needs the authors to clarify.\n\n4. To me, the significance of this paper mainly goes to combining several existing frameworks and tricks into the specific area of dialogue generation. Although the empirical results show the proposed model outperforms several existing models, my concern is still on the originality of the paper. Specifically, one of the main contributions goes to using the Gaussian mixture to construct the prior, but this is not a whole new idea in VAE or GAN, nor using the Gumbel trick. \n\n5. It is good to see that the authors showed some comparisons between DialogWAE and DialogWAE-GMP, letting us see GMP does help the performance. But a minor concern is that it seems hard to identify which part makes DialogWAE get superior performance than others. Are all the models running with the same experiment settings including the implementation of the RNNs?"", ""This paper proposes a novel dialogue modeling framework DialogWAE, which adopts conditional Wasserstein Auto-Encoder to learn continuous latent variables z that represents the high-level representation of responses. To enrich the diversity of the latent representations and capture multiple modes in the latent variables, the authors propose an advanced version (DialogWAE-GMP) of DialogWAE and models the prior distribution with a mixture of Gaussian distributions instead one. \n\nStrength: The idea is clear and the paper is very well written. The authors evaluate the proposed models on a variety of reasonable metrics and compare against seven recently-proposed baselines.  Results show that both DialogWAE and DialogWAE-GMP generate responses that are both more similar to the references (BLEU and BOW embeddings) and more diverse (inter-dist). Human evaluations also show that the proposed models generate better responses than two representative baselines.\n\nMinor comments/questions: \n\n1) Missing citation, the optimization problem of this paper (Equation 5) is similar to the Adversarially Regularized Autoencoders (ICML 2018). \n\n2) The authors use Gumbel-Softmax re-parametrization to sample an instance for the Gaussian Mixture prior network. Are you using the Straight-Through estimator or the original one? If the original Gumbel-Softmax estimator is used, it is better to show a comparison between simply using the Softmax with Gumbel softmax. Since the discrete sampling is not crucial in this case, a mixture of weighted representation may also work.\n\n3) The DialogWAE-GMP with Gaussian Mixture prior network achieves great evaluation results and is better than the non-mixture version. I'd be interested to see some analysis on what each Gaussian model has captured. Will different Gaussian model generate different types of responses? Are the differences interpretable? "", 'This paper uses Wasserstein GAN in conditional modeling of the dialog response generation. The main goal is to learn to use two network architecture to approximate the posterior distribution of the prior network. Instead of a KL divergence, like in VAE training, they use adversarial training and instead of using softmax output from the discriminator, they use Wasserstein distance. They also introduce a multi-modal distribution, GMM, while sampling from a the posterior during training, prior during the test time. The multi-modal sampling is based on gumbel-softmax over K possible G-distributions. They experiment on Daily Dialog and Switchborad datasets and show promising improvements on qualitative measures like BLEU and BOW embedding similarities, as well as qualitative measures including human evaluations comparing againsts substantial amount of baselines.\n\nThe paper presents a marriage of a few ideas together. First of, it uses the conditional structure presented in the ACL 2017 paper ""Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders"". It\'s great that they used that paper as their baseline. The extension is to use a GAN objective function (the discriminator) as critic and use Wasserstein GAN to to resolve the gradient vanishing issue and produce smooth gradients everywhere. In ACL 2017 paper they use KL divergence to make the posterior from the prior and rec-networks as close to each other so at test time the prior network can generate the samples similar to the true data features distribution. In this paper instead of KL, they use a Discriminator as in \'Adversarial AutoEncoders\' paper. This paper extends AAE, instead uses the Wasserstein distance instead (1-Lipschitz function instead of softmax for the discriminator). The W-GAN has been shown to produce good results in text generation in this year\'s ICML 2018 with the paper \'Adversarially Regularized GAN\' (AARE). The idea was to resolve VAE posterior collapse issue by using a discriminator as a regularizer instead of KL divergence with a stronger sampler from the output of the generator to map from noise sampler into the latent space. Interestingly, AARE paper is not cited in this work, which i think is an issue. I understand that paper was just for generation purpose not specific to the dialog modeling, but it makes the claims in the paper misleading such as: ""Unlike VAE conversation models that impose a simple distribution over latent variables, DialogWAE models the data distribution by training a GAN within the latent variable space"".\n\nThe part that i liked is the fact that they used multimodal gaussian distributions. I agree with the authors that using Gaussian for the approximating distribution only limits the sampling space and can weaken the models capability of variation. Although it is not proven for text, in image, the gaussian posteriors during training converge together into a single gaussian, causing blurry images. In this text this might correspond to dull responses in dialog. I would like the authors to comment on the interpretability of the components. Perhaps show a sample from each component (in the end the model decides which modal to choose before generation. Are these GMMs overlapping and how much ? Can you measure the difference between the means ? \n\nI find the experiments extensive except the datasets are weaker. \nI like the fact that they included human evaluations. \n']","[20, 80, 50]","[80, 70, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths (well-written, strong experiments, convincing results) but also expresses concerns about originality and some technical aspects. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging their own potential lack of expertise in the field, and framing criticisms as questions or concerns rather than direct attacks. The reviewer also starts with positive comments before moving to more critical points, which is a polite approach in academic reviews."", ""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, highlighting its strengths such as clarity, good writing, and strong evaluation results. The reviewer uses phrases like 'The idea is clear' and 'the paper is very well written,' indicating a positive sentiment. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They offer constructive feedback and frame their comments as 'Minor comments/questions,' which is a polite way to suggest improvements. The reviewer also expresses interest in further analysis, showing engagement with the work. The language used is consistently courteous and academic, without any harsh criticism or rudeness."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and innovative aspects, while also pointing out some limitations and areas for improvement. The reviewer appreciates the extensive experiments and human evaluations but notes that the datasets used are weaker. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions in a considerate manner. The reviewer also compliments aspects of the paper they liked, such as the use of multimodal Gaussian distributions and the inclusion of human evaluations. The language is professional and academic, avoiding any harsh or rude expressions.""]"
"['The paper introduces RCPO, a model-free deep RL algorithm for learning optimal policies that satisfy some per-state constraint on expectation. The derivation of the algorithm is quite straightforward, starts from the definition of constrained optimization problem, and proceed by forming and optimizing the Lagrangian. Additionally, a value function for the constraint is learned. The algorithm is only compared to a baseline optimizing the Lagrangian directly using Monte-Carlo sampling.\n\nThe paper has two major problems. First, while the derivation of the method makes intuitively sense, it is supported by vaguely stated theorems, which mixes rigorous guarantees with practical approximations. For example, Equation 4 assumes strong duality. How would the result change if weak duality was used instead? The main result in Theorem 1 makes the assumption that dual variable is constant with respect the policy, which might be true in practice, but it is not obvious how the approximation affects the theory. Further, instead of simply referring to prior convergence results, I would strongly suggest including the exact prior theorems and assumptions in the appendix.\n\nThe second problem is the empirical validation, which is incomplete and misleading. Constrained policy optimization is not a new topic (e.g. work by Achiam et al.), so it is important to compare to the prior works. It is stated in the paper that the prior methods cannot be used to handle mean value constraints. However, it would be important to include experiments that can be solved with prior methods too, for example the experiments in Achiam at al. for proper comparison. The results in Table 2 are confusing: what makes the bolded results better than the others? If the criterion is highest return and torque < 25%, then \\lambda=0.1 should be chosen for Hopper-v2. Also, The results seem to have high variance, and judging based on Table 2 and Figure 3, it is not obvious how well RCPO actually works.\n\nTo summarize, while the topic is undoubtedly important, the paper would need be improved in terms of better differentiating the theory from practice, and by including a rigorous comparison to prior work.\n\nMinor points:\n- What is exactly the difference between discounted sum constraint and mean value constraint?\n- Could consider use colors in Table 1.\n- Section 4.1.: What does “... enables training using a finite number of samples” exactly mean in this case?\n- Table 2: The grid for \\lambda is too sparse. \n- Proof of Theorem 1: What does it mean \\theta to be stable?\n- Proof of Theorem 2: “Theorem C” -> “Theorem 1”\n', ""This work tackles the difficult problem of solving Constrained Markov Decision Processes. It proposes the RCPO algorithm as a way to solving CMDP. The benefits of RCPO is that it can handle general constraints, it is reward agnostic and doesn't require prior knowledge. The key is that RCPO trains the actor and critic using an alternative penalty guiding signal.\n\nPros:\n- the motivations for the work are clearly explained and highly relevant\n- comprehensive overview of related work \n- clear and consistent structure and notations throughout\n- convergence proof is provided under certain assumptions\n\n\nCons:\n- no intuition is given as to why RCPO isn't able to outperform reward shaping in the Walker2d-v2 domain\n\nminor remarks:\n- in Table 2, it would be good if the torque threshold value appeared somewhere \n- in Figure 3, the variable of the x-axis should appear either in the plots or in the legend\n- in appendix B, r_s should be r_step and r_T should be r_goal to stay consistent with notation in 5.1.1"", ""This paper proposed a general framework for policy optimization of constrained MDP. Compared with the traditional methods, such as Lagrangian multiplier methods and trust region approach, this method shows better empirical results and theoretical merits. \n\nMajor concerns: \nMy major concern is about the time-scales. RCPO algorithm, by essence, is multi-scale, which usually has a stringent requirement on the stepsizes and is difficult to tune in practice to obtain the optimal performance. The reviewer would like to see how robust the algorithm is if the multi-time-scale condition is violated, aka, is the algorithm's performance robust to the stepsizes? \n\nMy second concern is the algorithm claims to be the first one to handle mean-value constraint without reward shaping. I did not get the reason why (Dalal et al. 2018) and (Achiam et al., 2017) cannot handle this case. Can the authors explain the reason more clearly? \n\nSome minor points: \nThe experiments are somewhat weak. The author is suggested to compare with more baseline methods. Mujoco domain is not a very difficult domain in general, and the authors are suggested to compare the performance on some other benchmark domains. \n\nThis paper needs to consider the cases where the constraints are the squares of returns, such as the variance. In that case, computing the solution often involves double sampling problem. Double sampling problem is usually solved by adding an extra variable at an extra time scale (if gradient or semi-gradient methods are applied), such as in many risk-sensitive papers.\u200b""]","[-50, 70, 20]","[20, 80, 60]","[""The sentiment score is -50 because the review identifies two major problems with the paper and suggests significant improvements are needed. The reviewer acknowledges the importance of the topic but expresses concerns about the theoretical foundations and empirical validation. The tone is not entirely negative, as the reviewer sees potential in the work if improved.\n\nThe politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would strongly suggest' and 'it would be important to include' rather than making harsh demands. The critique is direct but not personal or rude. The reviewer also acknowledges the importance of the topic, which adds a positive note. However, the score is not higher because the review is primarily focused on criticisms and doesn't include many positive comments or encouragement."", ""The sentiment score is 70 (positive) because the review starts with a clear acknowledgment of the work's importance and difficulty. It lists several pros, including clear motivations, comprehensive overview, and consistent structure. The cons are minimal, with only one main criticism. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement rather than harsh critiques. The use of 'Pros' and 'Cons' sections provides a balanced perspective, and the 'minor remarks' are presented as helpful suggestions rather than mandatory changes. The overall tone is constructive and supportive of the authors' work."", ""The sentiment score is slightly positive (20) because the review starts with acknowledging the paper's merits and its better empirical results compared to traditional methods. However, the reviewer then raises several concerns, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases concerns as suggestions or questions rather than direct criticisms, and uses polite phrases like 'The reviewer would like to see' and 'The author is suggested to'. The reviewer also balances criticism with positive feedback, which contributes to the polite tone. The language is professional and constructive throughout, without any rude or harsh statements.""]"
"[""Revision post-discussion: The paper's notation and model has been clarified, and my concerns about the paper have been addressed. Proposing a latent tree structure on the latent space of generative models is a strong contribution, the model performs well and seems to find meaningful and interpretable structure in the latent space.\n\n\nThe paper proposes a latent tree superstructure for the latent space of VAE’s. The idea itself is novel and interesting, and could have major impact in learning structured manifolds.\n\nThe overall presentation of the method is direct but slightly confusing. It seems that the zb grouping corresponds to different dimensions of the full z_i-vector of a single data point x_i. This should be made more explicit. \n\nThe method itself has three levels of groupings: the zb’s, the conditioned variables Yb, and the connections between the Y’s. The method is also called a  Bayesian Network, but the paper seems to avoid defining it as a BN. I wonder if the method could be presented in a simpler form, if all the structure is necessary, and if the method could be defined directly as a BN. For instance, why do the Y’s have to have a hierarchical tree structure, wouldn’t a “flat” grouping into zb's be sufficient? \n\nIn eq 2 the p(z) is defined as a mixture of Y-conditioned Gaussians, while in eq 4 its defined in the conventional encoder form N(z ; mu_x, sigma_x). These forms don’t seem to be compatible with each other. The term H seems to be entropy, but its not explained. It can’t be computed if we use the eq 2 definition of p(z). The interplay between these two structures is unclear. Furthermore, in fig 1 the tree is showed as a network (no arrows), while in fig 2 its a tree. I can’t find the definition for the dependencies P(Y | Y’), are these simply conditional density tables, or are they implicit? I also can’t see how are the \\Sigma_{yb} defined. Are they of full rank? What is their dimension?\n\nThe inference sections are well motivated and efficient techniques are used. \n\nThe synthetic experiment has 4 dimensional “z”, but the “W” matrix is 10x2, these do not match. What is the connection between Y_1 and Y_2 (in fig4 there is a dependency between)? Why is the dependency undirected if the model is a tree? The fig4b does not show ground truth to assess how well the model fits. The experiment should also include comparisons to the mentioned earlier works, and show how they perform. Why is there an arrow from the green scatter to the z3/z4? The main problem of the synthetic example is that it does not demonstrate why the tree structure learning is useful. The experiment should highlight a case where there is a natural latent tree structure corresponding to some realistic phenomena in real datasets.\n\nThe section 4.3. shows that the proposed method does find better representations of the MNIST than VAE, but does not mention that there are numerous extended VAE methods (and others) that would perform better than the LTVAE here. Those should be at least acknowledged, and preferably compared to.\n\nThe main results of the paper are very good with great performance in clustering, and the facets and clusters look great. The system has clearly learnt meaningful latent structures.\n\nThere are no learning curves or running time analyses. One would expect the proposed method to be slow with multiple levels of inference (tree structure, tree parameters, AE networks), and this should be discussed. How large datasets can it handle?\n\nOverall the paper proposes a BN-style structure on VAE latent space with great performance, but somewhat incomplete experimental section, and some presentation issues."", 'The authors propose to augment the Variational AutoEncoder [1] with a latent prior modeled by a Gaussian Latent Tree Model [2], allowing to introduce a hierarchical structure of clusters in the learned representation. The LT-VAE not only learns the location of each cluster to best represent the data, but also their number and the hierarchical structure of the underlying tree. This is achieved by a three-step learning algorithm. Step 1 is a traditional training of the encoder and decoder neural networks to improve their fitting of the data. Step 2 is an EM-like optimization to better fit the parameters of latent prior to the learned posterior. And step 3 adapts the structure of the latent prior to improve its BIC score [3], which balances a good fit of the latent posterior with the number of parameter (and thus complexity) of the latent prior.\n\nExperiments on synthetic data confirms the ability of the model to discover latent multifaceted clustering, and tests on 4 datasets shows it to be competitive with other unsupervised clustering models. Qualitative interpretation of samples from the learned model shows that the model learns a clustering that is clearly relevant to the data, while maybe not obvious to interpret.\n\nThe paper is well written and easy to follow (I however found a few typos and small mistakes that I\'ll list at the end of this review). The idea of using a structure on the latent prior of a VAE to learn a clustering of the data is not new, but the authors propose here an interesting approach to it, with a clearly described algorithm.\n\nHowever, I would have liked to see a more in-depth analysis of the behavior of the model on the various datasets, and my reading of this paper raised several questions that found no answer:\n\n1. What gains does the hierarchical structure on the Y variables provide? The paper does not analyze whether the models they trained actually learned conditional dependencies on the Y_i variables. How would this compare to the same model, with the only difference that the Y_i are fixed to be independent of each other (but still learning the number of Y_i and how the z_j are distributed between them) ?\n\n2. This is linked to the previous one. On the tests of the dataset, how do the different facets interact with each other? How are the samples from the different clusters of facet 2 when facet 1 is fixed to a particular cluster? Assuming the learned dependency is that Y_1 is the parent of Y_2, does the interpretation of each value of Y_2 change depending on the value of Y_1?\n\n3. The VAE with diagonal gaussian latent has a natural tendency to achieve sparcity in its latent space [4], making it robust to having too many latent neurons. Does this property hold with LT-VAE? If so, are the ""unused"" neurons organized in a particular way among the different learned facets?\n\nI\'d be reluctant to accept this paper without answers to points 1 and 2, which in my opinion are needed to justify the ""tree"" part of the ""latent tree model"" choice for the latent space. I\'d also be very interested in an answer to point 3, which would give good insights regarding the design choices for applying this model to new problems (how important is the choice of the size of the latent space?), but I\'m not considering it blocking acceptance.\n\n[1] https://arxiv.org/abs/1312.6114\n[2] http://jmlr.org/papers/volume5/zhang04a/zhang04a.pdf\n[3] https://projecteuclid.org/euclid.aos/1176344136\n[4] https://arxiv.org/abs/1706.05148\n\n--------------------------------\n\nNotes and typos:\n\n- In the introduction, ""Deep clustering network network (DCN)"", the word ""network"" is repeated \n- After equation 5, ""... where \\pi( . ) denotes the parent node ..."", the ""pi"" symbol does not appear in the equation at all, neither in the following equation, so I guess this part of the sentence should be removed\n- In section 3.3, you write that you define 5 operators, but follow by listing 7 (NI, ND, SI, SD, NR, PO and UP)\n- In section 4.1, I believe W lives in R^(10x4) not R^(10x2)\n- In section 4.5 the acronym ""MoG"" (""Mixture of Gaussian"" I guess) is used without being introduced previously', 'This paper introduces a new VAE model, the latent tree VAE (LTVAE), which aims to learn models with multifaceted clustering, that is separate clusterings are enforced on different subsets of the latent features.  This is achieved using a tree-structured prior on a set of discrete ""super latent variables"" (Y_1,...,Y_L) that identify which cluster the datapoint falls into for each separate facet (i.e. there is a separate clustering associated with each Y_n).  The subset of the standard latent variables z then form a Gaussian mixture model (GMM) for each Y_n.   Both the structure of this setup (i.e. the associated graphical model) and the parameters (i.e. means and variances of the clusters) are learned during training.  This introduces a number of computational challenges not usually seen in for VAE training, for which, seemingly well thought through, novel schemes are introduced, most notably a message passing scheme for calculating gradients of the log marginal p(z).\n\nOverall I think this is a very good paper.  The exposition of the work is, for the most part, very good - the paper was a pleasure to read.  I think that the key idea is novel and adds something unique and useful to the literature, I thus think it is work which will be of substantial interest to the ICLR community.  The quality of the paper is also very good: algorithmic details seem to have been well thought through and the experimental evaluation is above average, both in terms of apparent performance and in the breadth of experiments considered.  I would very much like to see this work accepted to ICLR and I think that the extra use of space over 8 pages in the submission is justified.  However, I do have some questions and concerns that I would like to see addressed in the rebuttal period and I may lower my score if they are not.\n\nThe key issues I would like to see addressed further discussion on are:\na) There is no discussion about what is done for the encoder in the paper.  This is surely a very important consideration here as if the encoder is not expressive enough, this will impact the learned models.  For example, the dependency structures of the latent space induce particular dependencies in the posterior that must be carefully handled to avoid harming the learning (see e.g. https://arxiv.org/abs/1712.00287).\nb) I would like to see some numerical results for the similarity between the different clusterings that are learned.  A lot of the novelty of the work rests on being able to pick up different clusterings with the different facets.  However, the results suggest that the clusterings may actually have very significant overlap and so this should be quantified.\nc) The approach is presuming substantially slower than a setup where the structure is pre-fixed.  I think it is fine even if there is a big slow down, but I would like to see timing information so that the reader can assess how much higher the time cost is.\nd) As far as I can tell (sorry if I have made a mistake), the presented results are from single runs.  I would like to see information about the variability across different runs so that the fragility of the approach can be assessed.\ne) I would like to see more justification for having a dependency structure between the Y\'s, ideally both in motivating this choice and in experimental evaluation to check it (more generally ablation studies for different components of the algorithm would improve the paper).  Might it be possible to use this in a way the encourages the different clusterings to be distinct from one another?\n\nOther comments:\n1) Though the writing is generally very good, there are a few exceptions:\n- The second paragraph in the intro becomes a list of related work from the point where DEC is introduced.  This should be moved to the related work to improve the flow (just cite those papers at the end of the first sentence in the third paragraph) and it would be good for it to be less of a list of separate things and more something that puts the current work in the context of other approaches.\n- The paragraph after Eq 3 needs some rewriting\n- The explanations around and including equations 5 and 6 were quite poor: \\pi is referred to but not used, it is not made clear that that g is the gradient of log p(z) instead of p(z), use brackets for the log in Eq 6 to avoid ambiguity\n2) The reference formatting is wrong (i.e. cite is used everywhere instead of citep)\n3) I thought the motivation for the approach in the intro was very good\n4) As the seemingly most related work, it would be good to elaborate more on the Goyal et al paper and the differences of your approach to theirs.  Is there a reason this is not used as a baseline in the experiments?\n5) I could not understand the step from the gradient to the gradient of the log in Eq 6.  Is this because p(y_b|z) = f(y_b) Norm(..)?\n6) The text in figures 2 and 3 is too small and difficult to make out.\n7) I think it is misleading to talk about p(z) as being a marginal likelihood and would use the term marginal prior, or just marginal, instead.\n8) I thought Figure 4b provided a nice demonstration.\n9) Is there a reason that log likelihood / ELBO scores are only provided on MNIST and only for the LTVAE / VAE?  I might be wrong, but I thought at least some of the other baselines provide this and those results presumably already exist as a side effect from calculating the clustering scores?  Relatedly, I\'m aware that a previous version of this work included estimates of the normalized mutual information -- is there any reason these are no longer included?\n10) Did the larger dimensional latent spaced used for the qualitative results improve or worsen the performance of previous metrics?\n\nMinor points / typos\n- mehod -> method\n- of generation network -> of the generation network\n- brackets in eq 7\n- MoG not defined in section 4.5']","[50, 50, 80]","[75, 80, 70]","[""The sentiment score is 50 (slightly positive) because the review starts with a positive note about the paper's improvements and contributions, but also includes several critiques and suggestions for improvement. The overall tone is constructive and acknowledges the strengths of the paper while pointing out areas that need clarification or expansion. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the positive aspects of the work. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, and focuses on the content of the paper rather than the authors themselves."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's merits, describing it as 'well written and easy to follow' with an 'interesting approach'. However, they also express significant concerns and are 'reluctant to accept this paper' without further clarification. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions rather than direct criticisms. They also provide helpful notes on typos and offer additional references, showing consideration for the authors' work. The reviewer maintains a professional and courteous tone while still clearly communicating their reservations about the paper."", ""The sentiment score is 80 (positive) because the reviewer states 'Overall I think this is a very good paper' and expresses a strong desire to see it accepted, calling it 'novel' and 'useful'. They praise the exposition, algorithmic details, and experimental evaluation. The politeness score is 70 (polite) due to the generally constructive tone, use of phrases like 'I would like to see' for suggestions, and compliments such as 'the paper was a pleasure to read'. However, it's not maximally polite as it does directly point out issues and uses some direct language. The reviewer balances positive feedback with specific critiques and suggestions for improvement, maintaining a professional and respectful tone throughout.""]"
"['In this submission, the authors present a variational smoothing interpretation of the data noising approach presented in (Xie et al., 2017). Although the theoretical coverage of the problem gives interesting insights. However, a comparison to related work w.r.t. alternative regularization approaches is missing. Similarly, the perplexity values reported in the experimental results on Penn Treebank are far away from state-of-the-art results published by many competitors on this task, e.g. see the current state-of-the-art results on Penn Treebank by (Yang et al., 2017, https://arxiv.org/pdf/1703.02573.pdf and references therein). It is bad practice to ignore existing work completely like this. The interesting question here would be, inhowfar the presented smoothing/regularization methods are complementary to existing approaches, and if the presented methods do provide improvements on top of these.\n\nFinally, the mode of language modeling evaluation presented here, without considering an actual language or speech processing task, provides limited insight w.r.t. its utility in actual applications. Moreover, the very limited size of the language modeling tasks chosen here is highly advantageous for smoothing/regularization approaches. It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.\n', ""This submission closely builds upon an earlier work (Xie et al., 2017, Gal and Ghahramani, 2016) and proposes a new data noising technique motivated by Bayesian RNNs. Specifically, the key contribution is to extend Gal and Ghahramani (2016) to word embedding noising, while drawing inspiration from trational data smoothing techniques. Some variants are discussed, including those motivated by linear interpolation and Kneser-Ney smoothing, just as in Xie et al., 2017. Empirical evaluation is performed with language modeling experiments, and the proposed methods outperforms comparable baselines. One can imagine such a technique could be useful in many other sequence tasks. \n\nThe paper is well-motivated and clearly written, and the experiments seem reasonable to me. Therefore I would vote for acceptance. My concern, which is not major, is that the proposed method might be a bit incremental based on Xie et al. (2017) and Gal and Ghahramani (2016).\n\nPros:\n- Theoratical justification seems reasonably sound to me.\n- Strong empirical performance.\n\nCons: \n- It would be interesting to see how the proposed technique works when applied to state-of-the-art models.\n\nDetails:\n\n- I'm not entirely familiar with Gal and Ghahramani (2016), but I'm assuming the discussion in Section 3 and how it extends to word embeddings are from this earlier work. Please correct me if I'm wrong, so that I can adjust my recommendation accordingly.\n\n- I can't find anything describing how \\sigma is determined.\n\n- Page 4, the paragraph of `Training.` I can't parse `we go though sequence t multiple times`.\n\n- \\ell_2 Regularization for `VS` models. I'm confused here, isn't the coefficient for VS determined by Eq. 3? Why is it still tuned in Section 5.1?\n\n- Elementwise smoothing: I'm confused why one needs to sample \\alpha for each dimension. Can't it be done by sampling a mask, just as in dropout?"", 'The paper presents a Bayesian/ variational interpretation of data noising in recurrent networks (Xie et al. 2017). Overall I found the paper interesting and well presented.\n\nThe authors first review the work of Xie et al. 2017, that proposes data noisy for regularizing recurrent networks. This is done by randomly replacing certain words in the context according to some distribution. Xie et al. 2017 showed that this is highly related to smoothing in n-gram models.\n\nThe authors take a Bayesian approach where there is a prior over the parameters p(W) . Computing the posterior for RNNs is generally intractable so they suggest using a variational distribution q(W) instead. They show how certain choices of the variational distribution give a similar effect to different types of smoothing (e.g. linear interpolation and Kneser Ney), as well as show how for instance, combining smoothing with dropout fits into their theory. \n\nExperimenetal results show that their approach outperforms vanilla LSTMs and the approach of Xie et al. 2017 on PTB and Wikitext-2 which are two common (although small) benchmarks for language modeling.\n\nThe paper could be improved by running a comparison on larger dataset (e.g. billion word benchmark Chelba et al. 2013)\n\n \n\n']","[-50, 60, 80]","[0, 70, 70]","[""The sentiment score is -50 because the review is generally critical, pointing out several significant shortcomings of the paper. While it acknowledges some interesting insights, it criticizes the lack of comparison to related work, outdated results, and limited scope of evaluation. The politeness score is 0 (neutral) because the language used is professional and matter-of-fact, without being particularly polite or rude. The reviewer states criticisms directly but without using harsh language or personal attacks. Phrases like 'It is bad practice' are critical but not impolite in an academic context."", ""The sentiment score is 60 (moderately positive) because the reviewer recommends acceptance, praises the paper as well-motivated and clearly written, and notes strong empirical performance. However, they express some concern about incrementality, preventing a higher score. The politeness score is 70 (fairly polite) due to the reviewer's constructive tone, use of phrases like 'please correct me if I'm wrong', and framing of criticisms as suggestions or questions rather than direct attacks. They maintain a professional and respectful tone throughout, while still providing honest feedback."", ""The sentiment score is 80 (positive) because the reviewer states they found the paper 'interesting and well presented', and provides a detailed summary of the paper's content without major criticisms. They also note that the experimental results show the approach outperforms existing methods. The only suggestion for improvement is to run a comparison on a larger dataset, which is a constructive recommendation rather than a criticism. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' work positively, and frames their suggestion for improvement in a non-demanding way ('The paper could be improved by...'). The review maintains a professional and courteous tone without being overly formal or effusive.""]"
"['This paper presents an improvement on the local/derivative-free learning algorithm equilibrium propagation. Specifically, it trains a feedforward network to initialize the iterative optimization process in equilibrium prop, leading to greater stability and computational efficiency, and providing a network that can later be used for fast feedforward predictions on test data. Non-local gradient terms are dropped when training the feedforward network, so that the entire system still doesn\'t require backprop. There is a neat theoretical result showing that, in the neighborhood of the optimum, the dropped non-local gradient terms will be correlated with the retained gradient terms.\n\nMy biggest concern with this paper is the lack of significant literature review, and that it is not placed in the context of previous work. There are only 12 references, 5 of which come from a single lab, and almost all of which are to extremely recent papers. Before acceptance, I would ask the authors to perform a literature search, update their paper to include citations to and discussion of previous work, and better motivate the novelty of their paper relative to previous work. Luckily, this is a concern that is addressable during the rebuttal process! If the authors perform a literature search, and update their paper appropriately, I will raise my score as high as 7.\n\nHere are a few related topic areas which are currently not discussed in the paper. *I am including these as a starting point only! It is your job to do a careful literature search. I am completely sure there are obvious connections I\'m missing, but these should provide some entry points into the citation web.*\n- The ""method of auxiliary coordinates"" introduces soft (often quadratic) couplings between post- and pre- activations in adjacent layers which, like your distributed quadratic penalty, eliminate backprop across the couplings. I believe researchers have also done similar things with augmented Lagrangian methods. A similar layer-local quadratic penalty also appears in ladder networks.\n- Positive/negative phase (clamped / unclamped phase) training is ubiquitous in energy based models. Note though that it isn\'t used in classical Hopfield networks. You might want to include references to other work in energy based models for both this and other reasons. e.g., there may be some similarities between this approach and continuous-valued Boltzmann machines?\n- In addition to feedback alignment, there are other approaches to training deep neural networks without standard backprop. examples include: synthetic gradients, meta-learned local update rules, direct feedback alignment, deep Boltzmann machines, ...\n- There is extensive literature on biologically plausible learning rules -- it is a field of study in its own right. As the paper is motivated in terms of biological plausibility, it would be good to include more general context on the different approaches taken to biological plausibility.\n\nMore detailed comments follow:\n\nThank you for including the glossary of symbols!\n\n""Continuous Hopfield Network"" use lowercase for this (unless introducing acronym)\n\n""is the set non-input"" -> ""is the set of non-input""\n\n""$\\alpha = ...$ ... $\\alpha_j \\subset ...$"" I could not make sense of the set notation here.\n\nwould recommend using something other than rho for nonlinearity. rho is rarely used as a function, so the prior of many readers will be to interpret this as a scalar. phi( ) or f( ) or h( ) are often used as NN nonlinearities.\n\ninline equation after ""clamping factor"" -- believe this should just be C, rather than \\partial C / \\partial s.\nMove definition of \\mathcal O up to where the symbol is first used.\n\ntext before eq. 7 -- why train to approximate s- rather than s+? It seems like s+ would lead to higher accuracy when this is eventually used for inference.\n\neq. 10 -- doesn\'t the regularization term also decrease the expressivity of the Hopfield network? e.g. it can no longer engage in ""explaining away"" or enforce top-down consistency, both of which are powerful positive attributes of iterative estimation procedures.\n\nnotation nit: it\'s confusing to use a dot to indicate matrix multiplication. It is commonly used in ML to indicate an inner product between two vectors of the same shape/orientation. Typically matrix multiplication is implied whenever an operator isn\'t specified (eg x w_1 is matrix multiplication).\n\neq. 12 -- is f\' supposed to be h\'? And wasn\'t the nonlinearity earlier introduced as rho? Should settle on one symbol for the nonlinearity.\n\nThis result is very cool. It only holds in the neighborhood of the optimum though. At initialization, I believe the expected correlation is zero by symmetry arguments (eg, d L_2 / d s_2 is equally likely to have either sign). Should include an explicit discussion of when this relationship is expected to hold.\n\n""proportional to"" -> ""correlated with"" (it\'s not proportional to)\n\nsec. 3 -- describe nonlinearity as ""hard sigmoid""\n\nbeta is drawn from uniform distribution including negative numbers? beta was earlier defined to be positive only.\n\nFigure 2 -- how does the final achieved test error change with the number of negative-phase steps? ie, is the final classification test error better even for init eq prop in the bottom row than it is in the top?\n\nThe idea of initializing an iterative settling process with a forward pass goes back much farther than this. A couple contexts being deep Boltzmann machines, and the use of variational inference to initialize Monte Carlo chains\n\nsect 4.3 -- ""the the"" -> ""to the""', ""This is a nice improvement on Equilibrium Propagation (EqProp) based on training a separate network to initialize (and speed-up at test time) the recurrent network trained by EqProp. The feedforward network takes as laywerwise targets the activities of each layer when running the recurrent net to convergence (s-). The surprising result (on MNIST) is that the feedforward approximation does as well as the recurrent net that trains it. This allows faster run-time, which is practically very useful.\n\nMy main concern is with the mathematical argument in section 2.2. s* is not the same as s- , and in general, it is not clear at all that there should be a phi* such that s*=s-. Also, the derivation in eqn 12 assumes that w is very close to w*, which is not clear at all. So this derivation is more suggestive, and the empirical results are the ones which could be convincing. My only concern there is that the only experiments performed are on MNIST, which is known to be easily dealt with using the kind of feedforward architectures studied here. Things could break down if much more non-linearity (which is what the fixed point recurrence provides) is necessary (equivalently this would correspond to networks for which much more depth is necessary, given some budget of number of parameters). I don't think that this is a deal-breaker, but I think that this section needs to be more prudent in the way that it concludes from these observations (the math and the experiments).\n\nOne question I have is about biological plausibility. The whole point of EqProp was to produce a biologically plausible variation on backprop. How plausible is it to have two sets of weights for the feedforward and recurrent parts? That is where a trick such as proposed in Bengio et al 2016 might be useful, so that the same set of weights could be used for both.\n\nIt might be good to mention Bengio et al 2016 in the introduction since it is the closest paper (trying to solve the same problem of using a feedforward net to approximate the true recurrent computation), rather than pushing that to the end.\n\nIn sec. 1.1, I would replace 'training a Continuous Hopfield Network for classification' by 'energy-based models, with a recurrent net's updates corresponding to gradient descent in the energy'. The EqProp algorithm is not just for the Hopfield energy but is general. Then before eq 1, mention that this is the variant of Hopfield energy studied in the EqProp paper.\n\nI found a couple of typos (scenerio, of the of the).\n\n\n"", 'Summary:\nThis paper aims at improving the speed of the iterative inference procedure (during training and deployment) in energy-based models trained with Equilibrium Propagation (EP), with the requirement of avoiding backpropagation. To achieve this, the authors propose to train a feedforward network to predict a fixed point of the ""equilibrating network"". Gradients are approximated by local gradients only. The method is compared to standard EP on MNIST.\n\nThe overall idea of the paper to speed up the slow iterative inference (during training and deployment) seems very reasonable. However, the paper seems to be still work in progress and could be improved on the theoretical side, the presentation, and especially the experimental evaluation. \nThe paper is rather weak on the theoretical side. The main theoretical result is perhaps the analysis of the gradient alignment. However, I cannot follow their analysis and suspect that it is false. More detailed comments follow. Regarding the presentation, I found many typos which I don\'t consider in my evaluation. However, there are both minor and major issues with several equations. Details follow below. Another major concern is the lack of experimental evaluation. There is only a single plot that shows the learning curves of EP and the proposed Initialized EP with 2 different numbers of negative-phase steps and for 2 different architectures. The authors should put a lot more effort into the evaluation. For example, evaluate the influence of the hyperparameter in Eq. (10) (Is lambda > 0 detrimental to the capacity of the equilibrating network?), etc.\n\nLastly, as of my current understanding, the whole motivation for the EP framework is biological plausibility. In my opinion, this paper lacks a discussion of that motivation with respect to the proposed approach.\n\nTo summarize, there are too many major problems that cannot be addressed only in the rebuttal phase. \n\n\nDetails:\n- Sec. 1.1. Equilibrium Propagation --> Sec. 2 (It is not part of the introduction) \n- In 1.1., ""Equilibrium Propagation is a method for training a Continuous Hopfield Network for classification"". EP is a method for training various energy-based models, not just hopfield networks. \n- Eq. (1): I find the notation very confusing. Specifically, I can\'t make sense of:\n    a) ""$\\alpha = \\{\\alpha_j: j \\in  S\\}$ denotes the network architecture"". What does it mean for alpha to denote an architecture? Please be more specific. \n    b) In the definition of $\\alpha_j$, you are constructing a set of neurons $i \\in S  \\cup I$, but then you are re-defining i in the same set, using the forall operator. \n    c) Even if the two above is corrected, I can\'t follow. Please simplify the notation (the energy function is not that complicated).\n- Eq. (1): Why is it $i \\in S$ everywhere, rather than all neurons, including input neurons (as in [Scellier and Bengio 2017])? \n- The text between Eq. (2) and Eq. (3) introduces the classification targets by adding the gradients of another energy function $C(s_O, y)$ to the previously described energy function from Eq. (1). First $C(s_O, y)$ is nowhere defined. Second, The energy is a scalar, while the gradient is a vector, so there must be a mistake. I suppose it should be just $C(s_O, y)$ rather than its gradients?\n- Eq. (6): $f_{\\phi_{j}}$ is defined as a function of multiple $f_{\\phi_{i}}$ ? \n- Eq. (9): Again the index i is used twice. \n- Sec. 2.1: Can you elaborate on why the equilibrating network can create targets that are not achievable by the feedforward network? Is it a problem of your particular choice of model architecture? Isn\'t the ""regularization"" then detrimental to the (capacity of the) equilibrating network? \n- In Sec. 2.2 on page 5, you claim that given random parameter intitialization, the gradients should almost always be aligned. For random weight matrices, where the weights are drawn with zero mean, I cannot see how this is true. To compute gradients of layer $l$, backpropagation (in an MLP) computes the matrix-vector multiplication between transposed weight matrix and the gradients of layer l+1 (I am ignoring the activation function here). The resulting gradient should have zero mean.\n- Eq. (11): Is it the L1 Norm or L2?\n- Eq. (12): In the preceding text, you made claims about the gradient alignment for random parameter initialization. In Eq. (12) you analyze the gradients close to the optimum?\n- Eq. (12): What is f, it has never been defined. I suppose it should be the h from above? \n- Eq. (12): I don\'t understand how you arrived at these gradient equations, even the first one. Shouldn\'t it be the standard backpropagation in an MLP or am I missing something? Using the chain rule $\\frac{\\partial L_1}{\\partial w_1} = \\frac{\\partial L_1}{\\partial s_1} \\frac{\\partial s_1}{\\partial w_1}$, I arrive at a different result. How can there be the derivative of f (or h) twice.\n- Sec. 3: Is beta really sampled from a zero-centred uniform distribution? On page 2, beta is introduced as a small positive number. Would a negative beta not cause the model to settle to a fixed point where maximally wrong targets are predicted?\n\n\n[Scellier and Bengio 2017] Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation']","[20, 50, -60]","[70, 80, 20]","[""The sentiment score is 20 (slightly positive) because while the reviewer expresses some concerns, particularly about the lack of literature review, they also note positive aspects like the 'neat theoretical result' and indicate willingness to raise their score if the authors address the concerns. The overall tone is constructive rather than dismissive. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, offers specific suggestions for improvement, and expresses appreciation ('Thank you for including the glossary of symbols!'). They also frame criticisms constructively, using phrases like 'My biggest concern' rather than more harsh language. The reviewer maintains a professional and helpful tone, even when pointing out errors or areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by calling it a 'nice improvement' and notes the 'surprising result', indicating appreciation for the work. However, they also express several concerns and suggest areas for improvement, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'My main concern is...', 'It might be good to...'), and offers specific suggestions for improvement rather than just pointing out flaws. The reviewer also acknowledges the value of the work even while suggesting changes, which contributes to the polite tone."", ""The sentiment score is -60 because the review is overall quite negative. The reviewer states there are 'too many major problems' and that the paper 'seems to be still work in progress'. They point out weaknesses in the theoretical side, presentation, and experimental evaluation. However, it's not entirely negative as they do acknowledge the overall idea as 'very reasonable'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'could be improved' and 'I cannot follow' rather than harsh language. They also provide detailed, constructive feedback which is helpful to the authors. The reviewer balances criticism with some positive remarks, showing an attempt to be fair despite the overall negative assessment.""]"
"['The authors propose a number of methods to identify individual important neurons in a machine translation system. The crucial assumption, drawn from the computer vision literature, is that important neurons are going to be correlated across related models (e.g. models that are trained on different subsets of the data). This hypothesis is validated to some extent: erasing the neurons that scored highly on these measures reduced BLEU score substantially. However, it turns out that most of the activation of the important neurons can be explained using sentence position. Supervised classification experiments on the important neurons revealed neurons that tracked properties such as the span of parentheses or word classes (e.g., auxiliary verbs, plural nouns, etc).\n\nStrengths:\n* The paper is very well written and provides solid intuitions for the methods proposed.\n* The methods seem promising, and the degree of localist representation is striking.\n* The methods may be able to address the question of *how* localist the representations are (though no numerical measure of localism is proposed).\n* There is a correlation between the neuron importance metrics proposed in the paper and the effect on BLEU score of erasing those neurons from the network (of course, it’s not clear what particular linguistic properties are affected by this erasure - the decrease BLEU may reflect inability to track specific word tokens more than any higher-level linguistic property).\n\nWeaknesses:\n* It wasn\'t clear to me why the neurons that track particular properties (e.g., being inside a parentheses) couldn\'t be identified using a supervised classifier to begin with, without first identifying ""important"" neurons using the unsupervised methods proposed in the paper. The unsupervised methods do show their strength in the more exploratory visualization-based analyses -- as the authors point out (bottom of p. 6), the neuron that activates on numbers but only at the beginning of the sentence does not correspond to a plausible a-priori hypothesis. Still, most of the insight in the paper seems to be derived from the supervised experiments.\n* The particular linguistic properties that are being investigated in the classification experiments are fairly limited. Are there neurons that track syntactic dependencies, for example?\n* I wasn\'t sure how the GMMs (Gaussian mixture models) for predicting linguistic properties from neuron activations were set up.\n* It\'s nice to see that individual neurons function as knobs that can change the gender or tense of the output (with varying accuracy). At the same time, I was unable to follow the authors\' argument that this technique could be used to reduce gender bias in MT.\n* I wasn\'t sure what insight was gained from the SVCCA analyses -- this method seems to be a bit of a distraction given the general focus on localist vs. distributed representation. In general, I didn’t come away with an understanding of the pros and cons of each of the methods.', 'Strengths:\n- even though the methods for detecting important neurons are not novel (as also stated in the paper), their application to MT is novel\n- the presentation is very clear\n- the choice of methods is well argued and justified\n- the experiments are well executed and analysed\n- thorough and varied analysis of the experimental findings \n\nI recommend this paper for the best paper award.', 'This paper presents unsupervised approaches to discover import neurons in\nneural machine translation systems. Some linguistic properties controlled by the\ndiscovered neurons are discussed and analyzed.\n\nStrengths:\n\nThe paper is well-written and provides valuable information to understand the\nbehaviour of neural machine translation models.\n\nThe ability to control characteristics (such as gender) without training\nspecialized models is promising, even if the results are not good enough for\nimmediate use. It would be interesting to see whether controlling neurons\nin the decoder would be more effective.\n\nWeaknesses:\n\nMultiple NMT systems are necessary to discover important neurons. The authors\nmention that it would be possible to use different checkpoints from a single\nmodel, but don\'t evaluate how well this would work.\n\nThe findings in this paper do not lead to immediate translation performance\nimprovements.\n\nQuestions and other remarks:\n\nIn Table 4a, why are there 2 results for ""-0.25, -0.125, 0""?\n\nIn section 4.3 (Tense), it may be worthwhile to mention that the neuron is\nhighly activated on the word ""Spreads"", even if it acts as a noun in this\nspecific sentence.\n\nBottom of p. 6: ""Our supervised methods"" -> ""Our unsupervised methods""\n\nTo control properties, could SVCCA directions or coefficients be manipulated?\n\nSome parentheses around citations are missing or misplaced.\n']","[50, 100, 50]","[80, 80, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several strengths of the paper, including that it is 'very well written' and the methods are 'promising'. However, they also point out some weaknesses, creating a balanced review. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or personal uncertainties (e.g., 'I wasn't sure', 'It wasn't clear to me') rather than direct attacks. They also make an effort to highlight positive aspects before discussing limitations."", ""The sentiment score is 100 (highly positive) because the review is entirely focused on strengths, with no criticisms mentioned. The reviewer even recommends the paper for the best paper award, which is a strong endorsement. The politeness score is 80 (very polite) because the language used is professional, respectful, and appreciative of the authors' work. The reviewer uses phrases like 'very clear', 'well argued and justified', and 'thorough and varied analysis', which are polite ways of praising the paper. The score is not 100 as the language, while polite, doesn't go beyond standard professional courtesy to be exceptionally polite."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting the paper's strengths, such as being well-written and providing valuable information. It also mentions promising aspects of the research. However, it also points out weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or possibilities rather than demands. The reviewer also acknowledges the potential of the work even when pointing out limitations. The tone is professional and courteous throughout, without any harsh or rude language.""]"
"['In this paper, the authors studied zeroth order sign SGD. Sign SGD is commonly used in adversarial example generation. Compared to sign SGD, zeroth-order sign SGD does not require the knowledge of the magnitude of the gradient, which makes it suitable to optimize black-box systems. The authors studied the convergence rate of zeroth-order sign SGD, and showed that under common assumptions, zero-order sign SGD achieves O(sqrt(d/T)) convergence rate, which is slower than sign SGD by a factor of sqrt(d). However, sign SGD requires an unrealisitcally large mini-batch size, which zeroth-order sign SGD does not. The authors demonstrated the performance of zeroth-order sign SGD in numerical experiments.\n\nOverall, this is a well written paper. The convergence property of the zeroth-order sign SGD is sufficiently studied. The proposal seems to be useful in real world tasks.\n\nWeaknesses: \n1) out of curiosity, can we improve the convergence rate of the zeroth-order sign SGD if we assume the mini-batch size is of order O(T)? This could help us better compare zeroth-order sign SGD and sign SGD.\n2) Figure 2 is too small to be legible. Also, it seems that the adversarial examples generated by zeroth-order sign SGD have higher distortion than those found by zeroth-order SGD on CIFAR-10 dataset. Is it true? If so, it would be beneficial to have a qualitative explanation of such behavior.', 'The authors proposed a zero-order version of the recent signSGD algorithm, by replacing the stochastic gradient with a usual function difference estimate. Similar convergence rates as signSGD were obtained, with an additional sqrt(d) factor which is typical in zero-order methods. Three (typical) gradient estimates based on function values were discussed. Overall, the obtained results are relatively straightforward combination of signSGD with existing zero-order techniques. \n\nQuality: The technical part of this paper seems to be solid. The experiments, on the other hand, are quite ambiguous. First off, why do you choose that peculiar least squares binary classification problem on page 7? Is Assumption A2 satisfied for this problem? Why not use logistic regression? The experimental results are also strange: Why would ZO-signSGD converge faster than ZO-SGD or any other ZO variant? Shouldn\'t they enjoy similar rates of convergence? Why would taking the sign make the algorithm converge faster? Note that the original motivation for signSGD is not for faster convergence but less communication. For the second set of experiment, how do you apply ZO-SGD to generate adversarial examples? Again, why do we expect ZO-signSGD to perform better than ZO-SGD?\n\nClarity: This paper is mostly well-written, but the authors at times largely overclaim their contributions or exaggerate the technical challenges. \n-- Page 2, 2nd line: the authors claim that ""Our analysis removes the impractical assumption of b = O(T)"", but in the later examples (page 6, top), they require q = O(T). How is this any different than b = O(T)? Even worse, the former case also require b = n, i.e., there is no stochasity at all...\n-- Assumption A2: how crucial is this assumption for obtaining the convergence results? note that not many functions have Lipschitz continuous bounded gradients... (logistic regression is an example)\n-- Page 4, top: ""ZO-signSGD has no restriction on the mini-batch size b""? The rates at the end of page 5 suggests otherwise if we want the bound to go to 0 (due to the term sqrt(d/b)). \n-- Page 4, top: the last two technical challenges do not make sense: once we replace f by f_mu, these difficulties go away immediately, and it is well-known how to relate f_mu with f.\n\nOriginality: The originality seems to be limited. Contrary to what the authors claimed, I found the established results to be relatively straightforward combination of signSGD and existing zero-order techniques. Can the authors elaborate on what additional difficulties they need to overcome in order to extend existing zero-order results to the signSGD case?\n\nSignificance: The proposed zero-order version of signSGD may potentially be significant in applications where gradient information is not available and yet distributed optimization is needed. This, however, is not demonstrated in the paper as the authors never considered distributed optimization.\n\n\n##### added after author response #####\nI appreciate the authors effort in trying to make their contributions precise and appropriate. The connection between ZO-signSGD and adversarial examples is further elaborated, which I agree is an interesting and potentially fruitful direction. I commend the authors for supplying further experiments to explain the pros and cons of the proposed algorithms. Many of the concerns in my original review were largely alleviate/addressed. As such, I have raised my original evaluation.', 'The paper presents algorithms for optimization using sign-SGD when the access is restricted to a zero order oracle only, and provide detailed analysis and convergence rates. They also run optimization experiments on synthetic data. Additionally, they demonstrate superiority of the algorithm in the number of oracle calls for black box adversarial attacks for MNIST and CIFAR-10. The provided algorithm has optimal iteration complexity from a theoretical viewpoint. \n\nThe paper was, overall very well written and sufficient experiment were presented. The math also seems correct. However, I think they should have explained the motivation for the need of developing such an algorithm better. Section 3 can be improved. \n\nI think this is an important paper because it provides a guaranteed algorithm for zero order sign-gradient descent. However, the ideas and the estimators are not novel. They show applicability of standard gradient estimators for zero order oracles for sign-sgd algorithm. ']","[80, 20, 60]","[70, 50, 70]","[""The sentiment score is 80 (positive) because the reviewer states that it is a 'well written paper' and that the 'convergence property is sufficiently studied'. They also mention that the proposal 'seems to be useful in real world tasks', indicating a positive overall assessment. The score is not 100 as there are some weaknesses mentioned. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They phrase their weaknesses as curiosities and suggestions rather than criticisms. The use of phrases like 'out of curiosity' and 'it would be beneficial' contribute to the polite tone. However, it's not 100 as it maintains a professional, slightly detached tone rather than being overly courteous."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some strengths of the paper ('technical part seems to be solid', 'may potentially be significant'), they also point out several limitations and concerns. The overall tone suggests a cautiously positive view, especially after the author response which led to a raised evaluation. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, offers constructive criticism, and acknowledges the authors' efforts in addressing concerns. They use phrases like 'I appreciate' and 'I commend', which contribute to a polite tone. However, they also directly challenge some claims and point out perceived flaws, which prevents the score from being higher."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, calling it 'very well written' and 'an important paper'. They note that sufficient experiments were presented and the math seems correct. However, they also suggest some improvements, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I think' to soften their suggestions, and there's no harsh or dismissive language. The tone is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher.""]"
"['This is a reasonable paper based on a simple intuition. The authors have noticed that some of the state of the art methods (they use Li et al - ICML18 as the main reference) are using only some simple normalization for improving the transfer learning and as such they propose preserving the outer layer output of the target network and aligning it with the one of the source network. On top of that they also propose modeling the difference of feature maps considering an attention mechanism obtain through supervised learning. \n\nThe idea in itself is interesting and valuable. However, I have had some difficulty in understanding precisely how the ""behavior"" is really regularized. While I understand what is depicted in Figure 1 I\'m not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs. In the evaluation, the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this. I would have liked to see experiments on some larger datasets that are commonly used in computer vision (e.g., Caltech 256 is rather old even if it has been used in Li et al.). The quantitative results in Table 1 and 2 indicate some slight improvement but I\'m not completely convinced that this is really significant in the end. The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image (in this case the result might also be correct but the examples presented are not too eloquent). \n', 'Authors present a new regularisation approach named DELTA (Deep Learning Transfer using feature map with attention). What it does is preserving the outer layer outputs of the target network (in a transfer learning scenario) instead of constraining the weights of the neural network. I am not sure how this approach helps preserve the semantics. Authors state that the distance between source/target networks is characterised by DELTA using their outer layer outputs. This distance is then used in the loss function and through back-propagation incorporates knowledge from the source network. The results demonstrate some marginal improvement in the datasets used when compared with L^2 and L^2-SP.\nMore importantly I think the paper needs some attention in its format as the concepts are not very clear. It has some elements of novelty but not yet there.\n\nAuthors have addressed most of my issues and hence I have revised my decision.', 'Summary\nThe paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction. The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention.\n\nImprovements\n- the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor\n- The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)  would be a good add']","[20, 20, 50]","[50, 50, 0]","[""The sentiment score is slightly positive (20) because the reviewer starts by calling it a 'reasonable paper' and acknowledges that the idea is 'interesting and valuable'. However, they express several concerns and are 'not completely convinced' by the results, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, such as 'I would have liked to see' and 'I'm not completely sure', which softens criticism. They also acknowledge the paper's merits before presenting concerns. The reviewer maintains a professional tone without using harsh or dismissive language, even when expressing doubts about the work's significance."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some improvement in the results and mentions that the authors have addressed most of their issues, leading to a revised decision. However, they also point out areas for improvement, such as clarity of concepts and format. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers constructive criticism without harsh words. They acknowledge the authors' efforts to address previous concerns, which is a polite gesture. The reviewer maintains a professional tone throughout, balancing critique with recognition of the paper's potential."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's technique as being 'slightly better' than existing methods and 'exceeds when used with attention'. This indicates a generally positive view of the work, though not overwhelmingly so. The politeness score is 0 (neutral) as the review uses straightforward, professional language without being particularly polite or rude. The reviewer provides direct feedback and suggestions without using overly formal or informal language. The review is concise and to the point, focusing on the content rather than on pleasantries or criticisms.""]"
"['This paper introduced a new stochastic layer termed variance layer for Bayesian deep learning, where the posterior on weight is a zero-mean symmetric distribution (e.g., Gaussian, Bernoulli, Uniform). The paper showed that under 3 different prior distributions, the Gaussian Dropout layer can converge to variance layer. Experiments verified that it can achieve similar accuracies as conventional binary dropout in image classification and reinforcement learning tasks, is more robust to adversarial attacks, and can be used to sparsify deep models.\n\nPros:\n(1)\tProposed a new type of stochastic layer (variance layer)\n(2)\tCompetitive performance on a variety of tasks: image classification, robustness to adversarial attacks, reinforcement learning, model compression\n(3)\tTheoretically grounded algorithm\n\nCons:\n(1)\tMy main concern is verification. Most of the comparisons are between variance layer (zero-mean) and conventional binary dropout, while the main argument of the paper is that it’s better to set Gaussian posterior’s mean to zero. So in all the experiments the paper should compare zero-mean variance layer against variational dropout (neuron-wise Eq. 14) and sparse variational dropout (additive Eq. 14), where the mean isn’t zero.\n(2)\tThe paper applies variance layers to some specific layers. Are there any guidelines to select which layers should be variance layers?\n\nSome minor issues:\n(1)\tPage 4, equations of Gaussian/Bernoulli/Uniform variance layer, they should be w_ij=…, instead of q(w_ij)= …\n(2)\tWhat’s the prior distribution used in the experiment of Table 1?\n\n', 'This paper studies variance neural networks, which approximate the posterior of Bayesian neural networks with zero-mean Gaussian distributions. The inference results are surprisingly well though there is no information in the mean of the posterior. It further shows that the several variational dropout methods are closed related to the proposed method. The experiment indicates that the ELBO can actually better optimized with this restricted form of variational distribution. \n\nThe paper is clearly written and easy to follow. The technique in the paper is solid.\n\nHowever, the authors might need to clarify a few questions below. \n\n\nQ1:  if every transformation is antisymmetric non-linear, then it seems that the expected distribution of $t$ in (2) is zero. Is this true or not? In another word, class information has to be read out from the encoding of instances in Fig 1. It seems antisymmetric operators cannot do so, as it will only get symmetric distributions from symmetric distributions. \n\nQ2: it is not straightforward to see why KL term needs to go zero. In my understanding, the posterior aims to fit two objectives: maximizing data likelihood and minimizing KL term. When the signal from the data is strong (e.g. large amount of data), the first objective becomes more important. Then q does not really try to make KL zero, and alpha has no reason to go infinity. Can you explain more? \n\nQ3: Is the claimed benefit from the optimization procedure or the special structure of the variance layer? Is it possible to test the hypothesis by 1) initializing a q distribution with learnable mean by the solution of variance neural network and then 2) optimizing q? Then the optimization procedure should continue to increase ELBO. Then compare the learned q against the variance neural network. If the learned q is better than the variance network -- it means the network structure is better for optimization, but the structure itself might not be so special. If the learned q is worse than the variance network, then the structure is interesting. \n\n\nA few detailed comments:\n\n1. logU used without definition. \n2. if the paper has a few sentence explaining ""Gaussian dropout approximate posterior"", section 4 will be smoother to read. ', 'This paper investigates the effects of mean of variational posterior and proposes variance layer, which only uses variance to store information.\n\nOverally, this paper analyzes an important but not well explored topic of variational dropout methods—the mean propagation at test time, and discusses the effect of weight variance in building a variational posterior for Bayesian neural networks. This findings are interesting and I appreciate the analysis. \n\nHowever, I think the claim for benefits of variance layer is not well supported. Variance layer requires test-time averaging in test time to achieve competitive accuracy, while the additive case in Eq. (14) using mean propagation achieves similar performance (e.g., the results in Table 1). The results in Sec 6 lack comparison to other Bayesian methods (e.g., the additive case in Eq. (14)). \n\nBesides, there exists several problems which needs to be addressed.\n\nSec 5.\nSec 5 is a little hard to follow. Which prior is chosen to produce the results in Table 1? KL(q||p)=0 for the zero-mean case corresponds to the fact that the variational posterior equals the prior, which implies the ARD prior if I did not misunderstand. In this case, the ground truth posterior p(w|D) for different methods is different and corresponding ELBO for them are incomparable.\n\nSec 6. \nThe setting in Table 2 is also unclear. As ``Variance’’ stands for variational dropout, what does ``Dropout’’ means? The original Bernoulli dropout? Besides, I’m wondering why directly variance layer (i.e., zero-mean case in Eq. (14)) is not implemented in this case.\n\n']","[50, 60, 20]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the review begins by summarizing the paper's contributions and listing several pros, indicating a generally positive view. However, it also includes significant cons and requests for additional comparisons, which tempers the positivity. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout, frames criticisms constructively as 'concerns' or 'issues' rather than flaws, and acknowledges the paper's strengths before discussing areas for improvement. The reviewer also uses phrases like 'My main concern is...' which softens the critique. The absence of harsh or dismissive language contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that it is 'clearly written and easy to follow' and that the technique is 'solid'. The reviewer also mentions that the inference results are 'surprisingly well'. However, it's not an extremely high score because the reviewer does raise several questions and points for clarification, indicating some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'The authors might need to clarify' and 'Can you explain more?' demonstrate a courteous approach to feedback. The reviewer also balances positive comments with areas for improvement, which is a polite way to provide constructive criticism."", ""Sentiment Score (20): The review starts with a positive tone, acknowledging the paper's importance and interesting findings. However, it then points out several significant issues and areas for improvement, which balances out the initial positivity. The overall sentiment is slightly positive but with substantial critiques.\n\nPoliteness Score (60): The reviewer uses polite and constructive language throughout. They begin by appreciating the analysis and use phrases like 'I think' and 'I'm wondering' to soften their criticisms. The reviewer points out problems but does so in a respectful manner, without using harsh or dismissive language. The tone is professional and aimed at improving the paper rather than attacking it.""]"
"['This paper studied learning unsupervised node embeddings by considering the structural properties of networks. Experimental results on a few data sets prove the effective of the proposed approaches over existing state-of-the-art approaches for unsupervised node embeddings. \n\nStrength:\n- important problem and interesting idea\n- the proposed approach seems to be effective according to the experiments\nWeakness:\n- some parts of the paper are quite unclear\n- the complexity of the proposed algorithm seems to be very high\n- the data sets used in the experiments are very small\n\nDetails:\n-In the introduction, ""it is in general impossible to find an embedding in R^d such that ..."", why do we have to make v and v\'(and u, and u\') far from each other?\n- In Equation (2), How is P_ij defined exactly, are they parameters? I am quite confused about this part\n- In Equation (6), the posterior distribution should be P(X|G) since X is the latent variable to be inferred, right？\n- In Table 2 and 3, how are the degree and block information leveraged into the model?\n', ""The authors propose a generative model of networks by learning embeddings and pairing the embeddings with a prior distribution over networks. The idea is that the prior distribution may explain structure that the embeddings would not have to capture.\n\nThe motivation for doing this is that this structure is typically hard to model for network embeddings.\nThe authors propose a clean -if improper- prior on networks and proceed to perform maximum likelihood inference on it.\nThe experiments show that the approach works fine for link porediction and can be used for visualization.\n\nTwo points: \na) Why not try to do this with Variational inference? It should conceptually still work and be fast and potentially more robust.\nb) The prior seems to be picked according to properties of the observed data and expressed in a product of constraints. This seems clunky, I would have been more impressed with a prior structure that ties in closer with the embeddings and requires less hand-engineering.\n\nA key point of interest is the following: very exciting recent work (GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models by You et al ICML2018) has proposed neural generative models of networks with a high degree of fidelity and much less hand-picked features.  The work here tries to not learn a lot of these structures but impose them. Do the authors think that ultimately learning priors with models like GraphRNN might be more promising for certain applications?\nThe drawback in this model here is that ultimately networks are embedded, but not really generated during test time. A more predictive generative model that makes less hard assumptions on graph data would be interesting.\n\nUpdate After rebuttal:\nGiven the authors' rebuttal to all reviews, I am upgrading my score to a 6. I still feel that more learning (as inGraphRNN) to build a fuller generative model of the graph would be interesting, but the authors make a strong case for the usefulness and practicality of their approach.\n"", 'The paper proposed to use a prior distribution to constraint the network embedding. The paper used very restricted Gaussian distributions for the formulation. The proposed approach should compared to other stronger methods such as graph convolution neural network/message passing neural networks/structure2vec. ']","[20, 50, -30]","[50, 70, 0]","['The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem, the interesting idea, and the effectiveness of the proposed approach. However, they also point out several weaknesses, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing praise with constructive criticism. They use neutral language to express concerns and ask questions, avoiding harsh or dismissive statements. The reviewer lists both strengths and weaknesses objectively, and their questions are framed as requests for clarification rather than accusations of incompetence.', ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the merits of the proposed model and its performance in experiments, while also offering constructive criticism and suggestions for improvement. The initial paragraphs express a generally positive view of the work, but the reviewer also points out some limitations and areas for potential enhancement. The upgrade of the score to 6 in the update after rebuttal further indicates a positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, frames criticisms as suggestions or questions rather than direct attacks, and acknowledges the authors' efforts in the rebuttal. The use of phrases like 'The authors propose...', 'Two points:', and 'Do the authors think...' maintains a professional and courteous tone. The reviewer also shows openness to changing their opinion based on the authors' rebuttal, which is a polite gesture in academic discourse."", ""The sentiment score is slightly negative (-30) because the reviewer points out limitations in the paper's approach and suggests comparisons with stronger methods, indicating some dissatisfaction with the current work. The tone is not overtly critical, but it implies that the paper's methodology is somewhat lacking. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states their observations and suggestions in a direct, matter-of-fact manner without using overtly courteous language or harsh criticism. The review is brief and to the point, focusing on the technical aspects without personal comments or emotional language.""]"
"['The authors study the problem of when the linear interpolant between two random variables follows the same distribution. This is related to the prior distribution of an implicit generative model. In the paper, the authors show that the Cauchy distribution has such a property, however due to the heavy-tails is not particularly useful. In addition, they propose a non-linear interpolation that naturally has this property.\n\nTechnically the paper in my opinion is solid. Also, the paper is ok-written, but I think it needs improvements (see comments).\n\nComments:\n\n#1) In my opinion the motivation is not very clear and should be improved. In the paper is mentioned that the goal of shortest path interpolation is to get smooth transformations. So, in principle, I am really skeptical when the linear interpolant is utilized as the shortest path. Even then, what is the actual benefit of having the property that the linear interpolants follow the same distribution as the prior? How this is related to smoother transformations? What I understand is that, if we interpolate between several random samples, we will get less samples near the origin, and additionally, these samples will follow the prior? But how this induces smoothness in the overall transformation? I think this should be explained properly in the text i.e. why is it interesting to solve the proposed problem.\n\n#2) From Observation 2.2. we should realize that the distribution matching property holds if the distribution has infinite mean? I think that this is implicitly mentioned in Section 2.2. paragraph 1, but I believe that it should be explicitly stated.\n\n#3) Fig.1 does not show something interesting, and if it does it is not explained. In Fig. 2 I think that interpolations between the same images should be provided such that to have a direct comparison. Also, in Fig. 3 the norm of Z can be shown in order to be clear that the Cauchy distribution has the desired property. \n\n#4) Section 2.2. paragraph 6, first sentence. Here it is stated that the distribution ""must be trivial or heavy-tailed"". This refers only to the Cauchy distribution? Since earlier the condition was the infinite mean. How these are related? Needs clarification in the text.\n\n#4) In Figure 4, I believe that the norms of the interpolants should be presented as well, such that to show if the desired property is true. Also in Figure 5, what we should see? What are the improvements when using the proposed non-linear interpolation?\n\n\nMinor comments:\n\n#1) Section 1.2. paragraph 2. For each trained model the latent space usually has different structure e.g. different untrained regions. So I believe that interpolations is not the proper way to compare different models.\n\n#2) Section 1.3 paragraph 1, in my opinion the term ""pathological"" should be explained precisely here. So it makes clear to the reader what he should expect.\n\n#3) Section 2.2. paragraph 2. The coordinate-wise implies that some Z_i are near zero and some others significantly larger? \n\nIn generally, I like the presented analysis. However, I do not fully understand the motivation. I think that choosing the shortest path guarantees smooth transformations. I do not see why the distribution matching property provides smoother transformations. To my understanding, this is simply a way to generate less samples near the origin, but this does not directly means smoother transformations of the generated images. I believe that the motivation and the actual implications of the discussed property have to be explained better.', '== Paper overview ==\nGiven a latent variable model (deep generative model), the paper ask how we should interpolate in the latent space. The key idea is to derive a natural interpolant from the prior distribution p(z), where z is the latent variable. The idea is that the interpolation function you apply to a variable z should not change the distribution of z of the start and end points of the interpolation curve are identically distribution. Example: consider two unit-length points drawn from a standard Gaussian, then linear interpolation of these points will result in points of smaller norm and hence different distribution. Differerent priors and corresponding interpolants are demonstrated and discussed. Empirical results are more of an illustrative nature.\n\n== Pros/cons ==\n+ The paper contribute a new and relevant point to an ongoing discussion on the geometry of the latent space.\n+ The key point is well-articulated and relevant mathematical details are derived in detail along the way.\n\n- I have some concerns about the idea itself (see below); yet, while I disagree with some of the presented view points, I don\'t think that diminishes the contribution.\n- The empirical evaluation hardly qualifies as such. A few image interpolations are shown, but it is unclear what conclusions can really be drawn from this. In the end, it remains unclear to me which approach to interpolation is better.\n\n== Concerns / debate ==\nI have some concerns about the key idea of the paper (in essence, I find it overly simplistic), but I nonetheless find that the paper brings an interesting new idea to the table.\n\n1) In section 1.1, the authors state ""one would expect the latent space to be organized in a way that reflects the internal structure of the training dataset"". My simple counter-question is: why? I know that this is common intuition, but I don\'t see anything in the cost functions of e.g. VAEs or GANs to make the statement true. Generative models, as far as I can see, only assume that the latent variables are somehow compressed versions of the data points; no assumptions on structure seems to be made.\n\n2) Later in the same section, the authors state ""In absence of any additional knowledge about the latent space, it feels natural to use the Euclidean metric"". Same question: why? Again, I know that this is a common assumption, but, again, there is nothing in the models that seem to actually justify such an assumption. I agree that it would be nice to have a Euclidean latent space, but doesn\'t make it so.\n\n3) In practice, we often see ""holes"" in the ""cloud"" of latent variables, that is regions of the latent space where only little data resides. I would argue that a good interpolant should not cross over a hole in the data manifold; none of the presented interpolants can satisfy this as they only depend no the start and end points, but not on the actual distribution of the latent points. So if the data does not fit the prior or are not iid, then the proposed interpolants will most likely perform poorly. A recent arXiv paper discuss one way to deal with such holes: https://arxiv.org/abs/1806.04994', 'The paper discusses linear interpolations in the latent space, which is one of the common ways used nowadays to evaluate a  quality of implicit generative models. More precisely, what researchers often do in this field is to (a) take a trained model (which often comes with a ""decoder"" or a ""generator"", that is a function mapping a noise sampled from a prior distribution Pz defined over the latent space Z to the data space), (b) sample two independent points Z1 and Z2 from Pz, and (c) report images obtained by decoding linear interpolations between Z1 and Z2 in the latent space. Researchers often tend to judge the quality of the model based on these interpolations, concluding that the model performs poorly if the interpolations don\'t look realistic and vice versa. The authors of the paper argue that this procedure has drawbacks, because in typical modern use cases (Gaussian / uniform prior Pz) the aforementioned interpolations are not distributed according to Pz anymore, and thus are likely to be out of the domain where decoder was actually trained. \n\nI would say the main contributions of the paper are:\n(1) The sole fact that the paper highlights the problems of linear interpolation based evaluation is already important.\n(2) Observation 2.2, stating that if (a) Pz has a finite mean and (b) aforementioned linear interpolations are still distributed according to Pz, then Pz is a Dirac distribution (a point mass).\n(3) The authors notice that Cauchy distribution satisfies point (a) from (2), but as a result does not have a mean. The authors present some set of experiments, where DCGAN generator is trained on the CelebA dataset with the Cauchy prior. The interpolations supposedly look nice but the sampling gets problematic, because a heavy tailed Cauchy often results in the Z samples with excessively large norm, where generator performs poorly.\n(4) The authors propose several non-linear ways to interpolate, which keep the prior distribution unchanged (Sections 3.4 and 3.5). In other words, instead of using a linear interpolation and Pz compatible with it (which is necessarily is heavy tailed as shown in Observation 2.2), the authors propose to use non linear interpolations which work with nicer priors Pz, in particular the ones with finite mean.\n\nI think this topic is very interesting and important, given there is still an unfortunate lack of well-behaved and widely accepted evaluation metrics in the field of unsupervised generative models. \n\nUnfortunately, I felt the exposition of the paper was rather confusing and, more importantly, I did not find a clear goal of the paper or any concrete conclusions. One possible conclusion could be that the generative modelling community should stop reporting the linear interpolations. However, I feel the paper is lacking a convincing evidence (from what I could find the authors base all the conclusions on one set of similar experiments performed with one generator architecture on one data set) in order to be viewed as a significant contribution to the generative modeling field. On the other hand, the paper has not enough insights to constitute a significant theoretical contribution (I would expect Observation 2.2 to be already known in the probability field). \n\nOverall, I have to conclude that the paper is not ready to be published but I am willing to give it a chance. \n']","[-20, -20, -30]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'technically solid' and 'ok-written', they express skepticism about the motivation and request several clarifications and improvements. The reviewer states they 'like the presented analysis' but also says they 'do not fully understand the motivation' and believes the paper 'needs improvements'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I think it needs improvements'), and balances negative feedback with positive comments. The reviewer also uses polite phrases like 'in my opinion' and 'I believe' when offering critiques, which softens the tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('new and relevant point', 'well-articulated'), they express several concerns and criticisms. The reviewer states that the empirical evaluation 'hardly qualifies as such' and that it remains unclear which approach to interpolation is better. They also disagree with some of the presented viewpoints. However, the overall tone is not entirely negative, as the reviewer still finds the paper's contribution valuable despite disagreements. The politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They present their concerns as debate points rather than harsh criticisms, and use phrases like 'I have some concerns' and 'I nonetheless find that the paper brings an interesting new idea to the table', which maintain a courteous tone even when expressing disagreement."", ""The sentiment score is -30 because while the reviewer acknowledges the importance and interesting nature of the topic, they express significant concerns about the paper's exposition, lack of clear goals, and insufficient evidence. The reviewer concludes that the paper is not ready for publication, which indicates a negative sentiment. However, the reviewer does offer some positive comments and is willing to give the paper another chance, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's potential contributions and interesting aspects. They provide constructive criticism without using harsh or rude language. The reviewer's willingness to give the paper another chance despite their concerns also contributes to the polite tone. While not overly formal or excessively polite, the review maintains a professional and courteous tone throughout.""]"
"['This paper investigates speaker adaption with a few samples based on an existing (pre-trained) multi-speaker TTS system. The three approaches in this paper are almost the same as the voice cloning work in Arik et al. (2018). However, it is still very beneficial to demonstrate these approaches for linguistic feature conditioned WaveNet.\n\nDetailed comments:\n\n1) This manuscript is not self-contained, as it omits the important details for acquiring linguistic features (e.g., phoneme duration model) and fundamental frequency (F0) at training and test time. The only information is that it uses existing model (Zen et al., 2016) to predict linguistic features and F0. What type of linguistic features are used in this work? Is the existing model (Zen et al., 2016) trained on the same training set as WaveNet model?\n\n2) It seems the only speaker-dependent part of the system is the embedding table for WaveNet. Actually, both linguistic features (e.g., phoneme duration) and fundamental frequency sequence are highly speaker-dependent. The authors normalize F0 to make it as speaker-independent as possible. What about the speaker-dependent linguistic features? Why not keep them as speaker dependent, and do speaker-adaption for the new speaker at inference?\n\n3) In my opinion, it’s a bit superfluous to name fine tuning as non-parametric few-shot adaption, and auxiliary network (speaker encoding) as parametric few-short adaption. Both ideas are quite natural as in Arik et al. (2018).\n\n4) The abbreviations SEA-ALL, SEA-EMB and SEA-ENC are appeared without explanation. \n\n5) It would be better to provide more details about early termination criterion in Section 3.1. Is it simply the validation loss?\n\n6) In Table 1, the MOS from Arik et al. (2018) and Jia et al. (2018) are not comparable. The experimental settings are different. Perhaps more importantly, these MOS evaluations are done by different group of people.\n\n7) In Section 5.3, Nachmani et al. (2018) and Arik et al. (2018) have also used speaker verification model as an objective evaluation.\n\nOverall, this is a good work with limited novelty but solid results. However, it can be improved in many ways as detailed  in previous comments. I would like to raise my rating if these comments can be addressed properly.', 'This paper proposes  an adaptation technique for TTS using wavenet as the speech backend, with the adaptation carried out on small data. The work is extremely significant in that speech data is hard to produce  (we need many hours of speaker data), and techniques to adapt (transfer learning?) data from large networks would be quite valuable. The main idea is that we train a network containing a large amount of data, and (assuming that we have a trained model), we adapt this network to the task of generating speech from text for a much smaller dataset. \n\nIn general (insofar as we can use that term), one trains such a network using <text/speech> pairs,  with speaker conditioning as added input so as to produce voice from a given speaker. The input text is converted to linguistic features in the ‘front end’, which is then injected with voice features to be synthesized into a voice output in the backend. More recent efforts in speech modeling have used RNN or wavenet based systems to carry out these transformations in the front/backends. The present work seems to use an SPSS technique (Zen et al 2016) to generate the linguistic features, while the task of converting to voice is carried out by a Wavenet. \n\nThe work is quite (conceptually) similar to ""Neural voice cloning with a few samples"" (Arik et al, https://arxiv.org/abs/1802.06006) in proposing techniques for few shot adaptation described below but with the significant difference that the latter used autoregressive DNNs (loosely speaking, seq2seq a la Tacotron) for the task in both the front and back ends, while in the current work, the linguistic features are computed with SPSS as in Zel et al (2016).\n\nThe paper proposes three quite related techniques for adaptation as shown clearly in Figure 2 of the paper. These techniques are again ‘roughly’ analogous to those described in the Baidu work “Neural Voice Cloning with a few samples”, with the difference in front and backend setups noted in the previous paragraph.\n\nWe take as text as input, and convert them to a representation for linguistic features as described in Zen et al (2016). To this, we now add the fundamental frequency F_0 for the sample voice. The key piece needed is the speaker embeddings (a vector), which is to be obtained by training. In addition to all this, we also have available the weights of a trained wavenet network (probably quite large) trained on many speakers, which we will modify (or not) using the strategies outlined for the few data dataset.\n\nSEA-EMB - Train embeddings, but not the network. We expect this to be ‘fast’, but not particularly accurate. \nSEA-ALL - Train embeddings, and network. This would be a much more accurate, if slower task. The authors note that since we train a very large network in this case, it could be prone to overfitting. They employ early stopping (as a practitioner, I would make note of the issue) with 10 % of the dataset being held out. Additional ideas such as initializing the emeddings - possibly with those that SEA-EMB calculates - are also stated to be useful.\nSEA-ENC - In this third version, they predict speaker embeddings from the trained larger network (the recipe is provided in the appendix). This task of predicting speaker embeddings is one of training a classifier.\n\n\nResults\nThe paper presents evaluations conducted with subjective, MOS based enrolment and with an evaluation metric from TI-SV d-vectors. Comparisons are made for all three models with human evaluated MOS scores, and it is seen that SEA-ALL outperforms the other two models, while performance in SEA-EMB depends on the amount of data used. Nevertheless, humans are still able to detect the difference between synthetic voices and real samples. \n\nThe TI-SV evaluations from Wan et al show t-SNE embeddings of ‘clusters’ of d-vectors for human and synthetic voices, where it is seen that inter-cluster distance (i.e. between different speakers) is high, showing that the model is able to discern speakers, and the intra-cluster distance (i.e. between real and synthetic voices) is low, showing that synthetic voices are ‘similar’ to real voices. In addition, three other measures - cosine similarity, and statistical measures for detection error trade off, ROC curves and cosine similarity measures are also presented, which show that that the adaptation models perform quite well. \n\n\nClarifications and comments:\n\nHave there been efforts to compare this model (with the SPSS based frontend) with seq2seq (Bahdanau/transformer) DNN based systems as in “Neural Voice cloning with few samples”?. How do they compare (is it even a valid comparison?)?\n\nI think the model for computing linguistic features could be elaborated upon further. \n\nRepresentations: I assume that the output audio representation is an audio waveform\n\nTypo 1 (minor): The reference  for “Bornschein et al” in section 4 “Related work”\n“Variable inference for memory addressing”. \nCorrection “Variational memory addressing in generative models”\n\nTypo 2 (minor): Figure 6: Lower curve indicate that the verification system is having a harder time distinguishing real from generated samples. \nCorrection (minor): Lower curve “indicates” ...\n\nSummary\n-------------\nIn summary, I am in favor of accepting this paper as it proposes a solution to adapt a trained network to one with has limited number of samples. A big issue in speech modeling is that datasets are tiny, and it is difficult to obtain good quality data at reasonable cost. It would be extremely useful to have a trained network that we can adapt for our own experiments. The related paper by Arik et al (Neural Voice cloning with a few samples) also operates with similar strategic aims, but uses a a different methodology using attention based DNNs. The paper under review should be a good addition to the toolbox of few shot adaptation/transfer learning for speech with much potential for practical use. ', ""This paper presents an approach to customize or adapt a text-to-speech synthesis system to a new speaker, given relatively small amount of data from that speaker.  It is a very well written paper with rather strong results indicating high quality, naturalness, and similarity with real speech from a speaker can be achieved with the authors' proposed approach.  I think the paper should be accepted for presentation at the conference.\n\nFew comments:\na) In second equation in Section 2 authors state speaker identity “s” is part of conditioning inputs “h” but it is not shown in the Equation where “h” is replaced with “l, f_0”\nb) In related work, I think the speaker code work of Abdel-Hamid et al., e.g. Ossama Abdel-Hamid, Hui Jiang, “Fast speaker adaptation of hybrid NN/HMM model for speech recognition based on discriminative learning of speaker code,” ICASSP 2013 is worth citing.\nc) The result that synthesized speech performs better than real speech in speaker verification task is interesting.  To me this points to a potential weakness in the verification methodology.  Please comment if this may be the case.""]","[-20, 80, 90]","[50, 70, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges it as 'a good work with solid results', they also point out 'limited novelty' and provide a long list of critiques and areas for improvement. The overall tone suggests the reviewer is not fully satisfied with the paper in its current state. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'it would be better to' and 'I would like to raise my rating if these comments can be addressed' which maintain a polite and encouraging tone while still conveying their concerns."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'extremely significant' and 'quite valuable'. They recommend accepting the paper and highlight its potential for practical use. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as 'clarifications and comments'. They also acknowledge the paper's strengths and potential impact. The reviewer maintains a professional tone, avoiding harsh criticism while still providing thorough analysis and suggestions for improvement."", ""The sentiment score is 90 because the reviewer expresses very positive views about the paper, calling it 'very well written' with 'strong results' and explicitly recommending acceptance. The only reason it's not 100 is because there are a few minor comments/suggestions. The politeness score is 70 because the language is consistently respectful and constructive. The reviewer offers suggestions politely (e.g., 'I think... is worth citing') and frames criticisms as interesting points for discussion rather than flaws. However, it doesn't reach 100 as it maintains a professional tone rather than being overtly courteous.""]"
"['The paper proposes a method to classify vulnerable and non-vulnerable binary codes where each data instance is a binary code corresponding to a sequence of machine instructions. The contributions include the creation of a new dataset for binary code vulnerability detection and the proposition of an architecture based on a supervised adaptation of variational auto-encoder, built upon the result of a sequential information,  \nand using a regularization term to better discriminate positive from negative data. An experimental evaluation on the data proposed is presented, including several baselines, the results show the good behavior of the method.\n\nPros:\n-Presentation of new application of representation learning models\n-Construction of a new dataset to the community for binary software vulnerability detection\n-The proposed model shows a good performance\nCons:\n-The presentation of the dataset is for me rather limited while it is a significant contribution for the authors, it seems to be an extension of an existing dataset for source code vulnerability detection.\n-From the last remark, it is unclear for me if the dataset is representative of binary code vulnerability problem\n-The proposed architecture is reasonable and maybe new, but I find it natural with respect to existing work in the literature.\n\nComments:\n\n-If providing a new dataset is a key contribution, the authors should spend more time to present the dataset. What makes it interesting/novel/challenging must be clarified. \nThis dataset seems actually built from the existing NDSS18 dataset for source code vulnerability detection. If I understood correctly, the authors have compiled (and sometimes corrected) the source to create binaries, then they use the labels in NDSS18 to label the binary codes obtained. \nThis a good start and can be useful for the community.\nHowever the notion of vulnerability is not defined and it is difficult for me to evaluate the interest of the dataset.\nI am not an expert in the field, but I am not that convinced that vulnerability for binary codes is necessary related to vulnerability that can be detected from source codes.\nIndeed, one can think that some vulnerability may appear in binary codes that cannot be detected from source codes: e.g. use of unstable libraries, problems with specific CPU architectures, problems du to different interpretation of standard.\n\nThe current version of dataset seems to be a data where one tries to find the vulnerability that can be detected from code. It would be interesting here to know if detecting the vulnerabilities are easier from source code or from binary code.\n\nIt could be good if the authors could discuss more this point.\n\n-The architecture proposed by the authors seems to use a sequential model (RNN or other) as indicated in Fig.2, the authors should precise this point.\nThe architecture is general enough to work on other problems/tasks - which is good - but the authors focus on the binary vulnerability code dataset in the experiments.\n\nIf the authors think that their contribution is to propose a general method for sequence classification, it could be good to apply it on other datasets.\nOtherwise, something maybe more specific to the task would be useful.\nIn particular, there is no clear discussion to justify that variational autoencoders are better models for the task selected, it coud be good to argue more about it.\n\nThat being said, having non fixed priors and trying to maximize the divergence between positive and negative distributions are good ideas, but finally rather natural.\n\n', 'This paper proposes a model to automatically extracted features for vulnerability detection using deep learning technique. \n\nPros:\n+ Create a labeled dataset for binary code vulnerability detection and attempts to solve the difficult but practical task of vulnerability detection.\n+ Expend VAE from single prior to multiple priors. \n+ Using figures and visualizations to show the behaviors of model.\n\nCons:\n- The operation that creates dataset may introduce bias or variance. (The developed tool that automatically detects the syntactical errors in a given piece of source code, fixes them, and finally compiles the fixed source code into binaries, may change the distribution of data.) Why not follow the way of producing dataset of malware detection or other tasks that using binary code.\n- It seems that the proposed model fails to consider the properties of the binary codes in this task. It would be more interesting if some design incorporates the special properties of the task.\n- The discussion in Figure 2 and equations  are unclear. More explanations are needed. e.g. how to testing with label-unknown data.\n- Many typos are found. E.g., : the given given  -> the given;    k = 1,2 should be k = 0,1  \n', 'This paper sets out to classify source code snippets are “vulnerable” or “not vulnerable” using sequential auto-encoders with two latent distributions (corresponding to the output classes), regularized to maximize divergence between theses two distributions (named Maximal Divergence Sequential Auto-Encoder).  The authors created a compiled subset of the NDSS18 vulnerable vs. non-vulnerable software dataset (which is listed as one of their primary contributions). The dataset construction required non-trivial effort since example code snippets are often incomplete and the authors needed to “fix” these code examples in order to compile them. The fixed code examples are then compiled against both Windows and Linux and both the x86 and x86-64 architectures. The inputs to all predictive models are the opcode sequence of the compiled programs. \n\nThis paper compares against one previously published vulnerability detection method (VulDeePecker) which is a bidirectional RNN followed by a linear classifier. They also compare with a cascade of models with increasingly complex components:\n\n* RNN-R: A recurrent neural network trained in an unsupervised fashion (language modeling over opcode sequences), whose representations are then fed into an independent linear model. \n* RNN-C: End-to-end training of a recurrent model over opcodes, followed by a single dense layer.\n* Para2Vec: Encoding of the opcode sequence using the paragraph-to-vector architecture — I’m curious what they used as the paragraph boundaries in the compiled programs and whether the subsequent classifier was the same as RNN-C. \n* SeqVAE-C: Sequential variational auto encoder trained end-to-end with a final classification layer. \n* MDSAE-RKL:  Maximal divergence sequential auto-encoder with KL divergence between the two class’s latent distributions, final classifier trained independently. \n* MDSAE-RWS: Maximal divergence sequential auto-encoder with L2/Wasserstein  divergence between the two class’s latent distributions, final classifier trained independently. \n* MDSAE-CKL: Maximal divergence sequential auto-encoder with KL divergence between the two class’s latent distributions, final classifier included as the final layer of the whole model.\n* MDSAE-CWS: Maximal divergence sequential auto-encoder with L2/Wasserstein  divergence between the two class’s latent distributions, final classifier included as the final layer of the whole model.\n\nThe two MDSAE models using Wasserstein divergence vastly outperform the two equivalent models using KL divergence. Another generalization that can be drawn from the evaluation is that models which are trained  with supervision end-to-end outperform those which train representation and classifier separately. \n\nOverall, I think this is an interesting and cool paper but I’m not sure I actually buy into the basic premise that it makes sense to model vulnerable vs. non-vulnerable code as two different latent spaces. Aren’t the changes to make a vulnerable function safe again rather small and/or subtle? I think that beyond visualizing the convergence of properties of the latent spaces it would greatly improve this paper to inspect which aspects of the source contribute to both the latent representation and final classification as vulnerable vs. non-vulnerable. \n\nAlso, I wish the process of “fix”ing the input code was better described, since the failure of this procedure excluded 4k/13k of the programs/functions in their initial dataset and had the potential to introduces learnable biases in the source code. At the very least, the authors should list how many vulnerable vs. non-vulnerable samples required fixing vs. could be compiled in their original form. \n\nLastly, the definition of ""vulnerable"" may be obvious to someone more familiar with the domain but seemed to me somewhat vague and never directly addressed. \n\nTypo:\np3, need space in ""obtain32, 281""', 'This paper proposes a variational autoencoder-based architecture for binary code embedding. For evaluation, they construct a dataset by compiling source code in the NDSS18 dataset. They evaluate their approaches against several neural network baselines, and demonstrate that their learned embeddings are more effective at distinguishing between vulnerable and non-vulnerable binary code.\n\nThe application of deep representation learning for (binary) vulnerability detection is  a promising direction in general. Meanwhile, the authors did a quite comprehensive comparison with neural network baselines for embedding representation. However, I have several questions and concerns about the paper:\n\n- The contributions of this paper are unclear to me. The authors claim that a main contribution is their dataset. I agree that this is a contribution, but since this dataset is built upon an existing dataset with source code, and the dataset construction techniques themselves are not novel, especially for machine learning community, I do not see a significant contribution in this part.\n\n- The proposed approach is new, but the technical novelty is marginal. I think this model design is not specific to the binary vulnerability detection, but should also be applicable to other vulnerability detection settings, e.g., the original NDSS18 dataset. It would be great if the proposed approach also performs better on other vulnerability detection tasks than the baselines.\n\n- What would be the performance of using hand-designed features on the same benchmark? If the proposed approach learns better embeddings, any intuition on what additional information is captured by the learned embeddings?\n\nMinor suggestions: The paper needs an editing pass to fix some typos. Also, the authors seem to setup the paper template in a wrong way, and may need to consider fixing it.']","[20, 20, 50, -20]","[60, 50, 80, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as the creation of a new dataset and the good performance of the proposed model. However, they also express several concerns and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions rather than demands. They use phrases like 'it could be good if' and 'the authors should' which are polite ways of offering recommendations. The reviewer also balances their critique by explicitly mentioning both pros and cons of the paper, which contributes to a courteous tone."", ""The sentiment score is slightly positive (20) because the review starts with a neutral description of the paper and lists both pros and cons. The pros are substantial, acknowledging the creation of a labeled dataset, expansion of a technique, and use of visualizations. However, the cons are also significant, pointing out potential biases, lack of task-specific considerations, and clarity issues. The overall tone leans slightly positive due to the balanced approach and recognition of the paper's contributions. The politeness score is moderately positive (50) as the reviewer uses professional and objective language throughout. They present criticisms as 'Cons' rather than direct attacks, and use phrases like 'It would be more interesting if' to suggest improvements. The reviewer also points out positive aspects ('Pros') before critiques, which is a polite approach. The language is not overly formal or deferential, maintaining a neutral, professional tone, hence the score is positive but not extremely high."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting and cool' and acknowledges the non-trivial effort in dataset construction. However, they also express skepticism about the basic premise and suggest improvements, indicating a mixed but overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as suggestions or questions rather than direct criticisms. They also acknowledge the authors' efforts and contributions. The reviewer maintains a professional and courteous tone, even when pointing out areas for improvement or expressing doubts about certain aspects of the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('promising direction', 'comprehensive comparison'), they express several concerns and questions about the paper's contributions and novelty. The overall tone suggests that the reviewer is not fully convinced of the paper's merits. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than harsh criticisms. They also provide specific recommendations for improvement, which is a polite way to offer feedback.""]"
"[""This paper proposes a new method to imitate expert efficiently. The paper first proposes a way to compute reward function from expert demonstration and uses the log probability to represent this reward function.  Then they find a form of bellman equation that can optimize the reward stably. After the 'Q learning without IRL', an off-policy RL off-pac is applied. So this paper achieves comparable results to GAIL but uses much less data amount. \n\nclarity:\nThis paper is clearly written.\n\noriginality:\nThis paper is original.\n\npros:\nComparable performance with GAIL.\nBetter performance than Behavioral Cloning\nNew way of using demonstrations\n\ncons:\nAlthough both the method and the experiments look promising, there is a very simple yet competitive baseline missing. This baseline is also mentioned in the original GAIL paper: you initialize GAIL with BC, and then train GAIL. That's the baseline for a set of fair comparison.\n"", 'The paper proposes a method for imitation learning via inverse reinforcement learning based on a specific modeling of the reward. It is modeled as the log probability of a state action pair to belong to the expert policy. It models this distribution as a Bernoulli one and thus it reduces the IRL problem to a classification task. The global method also uses an off-policy algorithm to learn the value function of the current agent policy to improve sample efficiency. The method is tested on a set of continuous control tasks such as walker, hopper or humanoid. \n\nI think the paper has several flaws. First, I found the paper not very well written and organized. It is hard to read. It uses some terminology in a way that is different from the rest of the littérature (such as Q-learning as learning the Q-function of the expert policy instead of using the  optimal Bellman operator (even if the expert is supposed to be optimal)). I also think that the related work section is missing a lot of important refs because it really focuses on recent papers while imitation learning has a long history. \n\nYet, my main concern is that the proposed method seems to reduce to a classification problem to me and is likely to suffer from the same issues than the supervised learning method (AKA behavior cloning). It probably overfits a lot and there is nothing in the experiments that shows how robust is the method to perturbations. In a discrete world, this method would ideally place a reward of 1 in every state visited by the expert and 0 elsewhere which is very likely to overfit and result in unstable behaviors in the presence of noise etc. I would like to see experiments showing robustness. \n\nThe experiments are also a bit strange since the learning is stopped early for the proposed method. Is it because the learning is unstable ?\n\n\n', 'This paper proposed an imitation learning algorithm that achieves competitive results with GAIL, while requiring significantly fewer interactions with the environment.\n\nI like the method proposed in this paper. It seems similar to ideas in this concurrent submission: https://openreview.net/forum?id=B1excoAqKQ\n\nHowever, the paper is a bit difficult to read. The proposed method is made up of several changes compared to the baselines (e.g. using Q-learning without IRL instead of IRL, using off-policy learning, using conditioning to obtain a stochastic policy) but motivation for each component is presented late within the paper. The terminology used to describe these components is a bit confusing. Also some math is presented without intuitive descriptions.\n\nI’d like to see more ablations performed: there are three main changes compared to GAIL, but an ablation is only performed for the stochastic policy. It would be interesting to tease out what is more important, off-policy learning, or bypassing IRL.', 'Summary/contributions:\n\nThe primary aim of this paper is to improve the sample efficiency of GAIL (Ho et al. 2016). The claimed contributions can be summarized by consisting of 1) replacing TRPO (which was used in the original paper) with a off-policy RL with a modified reward, 2) using a policy parameterizing where the noise is used as an input rather than at the output. While conceptually simple, this paper contributes a method that shows improved sample efficiency on a series of benchmark mujoco tasks, which has practical implications for real world environments. \n\nPros:\n- a simple idea with good empirical results that would be of interest to the community\n\nCons:\n- (extremely) unclear presentation which hinders the message of the paper.\n- the novelty of the approach is somewhat limited\n\nJustification for score:\nI gave my rating based upon the following considerations. The approach in this paper makes sense from a practical perspective and presents strong results. However, the experiments in the paper do not clearly identify which components of their method lead to their improved performance (i.e., an ablation on their stated contributions). The writing is also extremely poor. The paper makes use of non-standard notation (in relation to the prior work which it builds on) and unusual terminology. Overall however, I am on the fence about this paper, since I recognize the good results presented in this paper, in addition to the timely nature of the idea (there are at least two concurrent submissions that I am aware of that are similar).\n\nOther:\n- I would appreciate if the related work discussed prior off-policy methods that use demonstrations (e.g Hester et al. 2017)\n- The paper has a large number of ungrammatical sentences and unidiomatic expressions. ']","[70, -60, 50, -20]","[50, -20, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting its clarity, originality, and comparable performance to existing methods. They highlight several pros and only one con, which is presented as a suggestion for improvement rather than a major flaw. The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language throughout and offers constructive feedback. They acknowledge the paper's strengths before suggesting an additional baseline for comparison, which is framed as a helpful recommendation rather than a criticism. The language is not overly formal or excessively polite, but maintains a respectful and constructive tone."", ""The sentiment score is -60 because the reviewer expresses several significant concerns about the paper, including poor organization, unclear terminology, missing references, and potential methodological flaws. The reviewer uses phrases like 'has several flaws,' 'hard to read,' and 'main concern,' indicating a generally negative view. However, it's not entirely negative as the reviewer acknowledges some aspects of the work and suggests improvements. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much softening. Phrases like 'I think the paper has several flaws' and 'The experiments are also a bit strange' come across as somewhat blunt. The reviewer doesn't use particularly polite language or acknowledge positive aspects to balance the criticism, which contributes to the slightly negative politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they like the proposed method and acknowledges its competitive results. However, they also point out several areas for improvement, balancing the positive and negative aspects. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I like the method' and 'I'd like to see,' while offering constructive criticism. They avoid harsh language and frame their suggestions as opportunities for improvement rather than outright criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good empirical results', 'strong results', 'timely nature of the idea'), there are significant criticisms ('extremely unclear presentation', 'limited novelty', 'poor writing'). The overall tone is cautious and 'on the fence', indicating a slightly negative sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticisms with positive remarks, and using polite language such as 'I would appreciate'. The reviewer also provides constructive feedback and justifies their opinions, which contributes to the politeness of the review.""]"
"['This paper is built on a simple but profound observation: Frey\'s bits-back coding algorithm can be implemented much more elegantly when replacing arithmetic coding (AC) with asymmetric numerical systems (ANS), a much more recent development not known at the time, simply due to the fact that it encodes symbols in a stack-like fashion rather than queue-like.\n\nThis simple observation makes for an elegantly written paper, with promising results on MNIST. I truly enjoyed reading it, and I\'m convinced that it will spark some very interesting further work in the field of compression with latent-variable models.\n\nHaving said that, I would like to point out some possible limitations of the proposed approach, which I hope the authors will be able to address/clarify:\n\n1. At the beginning of section 2.1, the authors define the symbols as chained conditionals prod_n p(s_n | s_1 ... s_n-1), which is generally permissible in AC as well as ANS, as long as the decoding order is taken into account. That is, in AC, the symbols need to be encoded starting with the first symbol in the chain (s_1), while in ANS, the symbols must be encoded starting with the last symbol in the chain, because the decoding order is inverted.\n\nIn their description of BB-ANS, the authors omit the discussion of conditional chains. It is unclear to me if a conditioning of the symbols is feasible in BB-ANS due to the necessity to maintain a strict decoding order. It would be very helpful if the authors could clarify this, and update the paper accordingly, because this could present a serious limitation. For instance, the authors simply extrapolate the performance of their method to PixelVAE; however, this model is autoregressive, so a conditioning of symbols seems necessary. Similarly, in appendix A, the authors mention the work of Minnen et al. (2018), where the same situation would apply, albeit one probabilistic level higher (on encoding/decoding the latents with an autoregressive prior).\n\n2. Furthermore, in both cases (PixelVAE and Minnen et al.), the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y). This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the ""bits back"", and the overhead of BB-ANS would be prohibitive. It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.\n\n3. Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow. In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method. This would be a good point to make in the discussion.\n\n4. The authors state in the appendix that learned compression methods like Ballé et al. (2018) and Minnen et al. (2018) could be improved by using BB-ANS. The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain. Ballé et al. (2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.\n\nOverall, I think this is a well-written, important and elegant paper, and I would like to see it accepted at this conference. If the authors can satisfactorily address some of the above potential limitations, it might turn out to be even better.\n', ""The paper is very well written and the clarity is overall high. However, I was left with some questions about the significance of this work after reading this paper.\n\nThe authors approach the problem in the Bayesian inference framework. Essentially, the message is modeled as a linear neural network with a single latent layer. The authors only specify the distributions for the posterior and prior in the experimental section, where they set them both to Gaussians. This naturally raise the question how is this model different from the probabilistic PCA model? Moreover, I am confused why would it be necessary to introduce an approximation q(y|s) of the posterior p(y|s), when there is a well known closed form expression for Gaussians? Furthermore, this Gaussian model is well known to have non-unique maximum likelihood solution (due to the invariance to an arbitrary orthogonal transformation). How does that influence the addressed compression problem? Going back to equations (1)-(2), if the authors chose different distributions and the need for the ELBO was justified, wouldn’t that lead to an approximate representation? That is, wouldn’t that necessary imply some loss in compression? And if yes, wouldn't then the proposed approach be not a lossless but a lossy compression algorithm? And then why would this particular approach be better than other numerous lossy compression algorithms which the authors cite?"", ""The main contribution of this paper is to propose an improvement to the bits back (BB) coding scheme by using asymmetric numeral systems (ANS) rather than arithmetic coding for the implementation. ANS is a natural fit with BB since it traverses the coded sequence stack-style rather than FIFO. A second contribution is show how generative models with continuous latent variables can be used (via discretization) within this scheme. The paper is generally well-written, and the explanation in Sec 2.4 was especially clear. However I have some questions about the evaluation and practical application of this scheme.\n\nThe comparison in Figure 1 is very compelling, but it would be helpful to have some additional information. In particular, does the size reported for BB-ANS include any overhead related to meta information (e.g., number of images stored, their dimensions, format, etc.)? PNG is a general purpose image file format, so it certainly contains such overhead. This makes it unclear how fair of a comparison we have here. Similarly, bz2 is a general purpose file compression scheme. What file format were the images written as before being compressed? Either of those cases (PNG, bz2) could be opened on any other computer without the need for additional information (just a program that knows how to read/decompress those file formats). On the other hand, the BB-ANS bitstream is not interpretable without the models used when compressing, and as discussed in Sec 4.3, there is certainly additional overhead involved in communicating the model which is not indicated here. \n\nIn any case, the compression rate achieved is impressive, but at the same time, not so surprising given that the model was trained on MNIST. Have you checked how well a model trained on a more general image dataset (e.g., ImageNet) compresses other images (e.g., MNIST)?\n\nSec 3.2 mentions finding that around 400 clean bits are required. How does the performance vary as fewer (or more) clean bits are used? More generally, do you have suggestions for how to determine an appropriate number of clean bits for other scenarios? (E.g., does it depend on the number of images to be compressed? their size? some notion of the entropy of the set of images to be compressed? other factors?) \n\nAlso, how does the performance vary with the number of symbols (images) to be compressed? I'd believe that the compression rate approaches the ELBO as the number of compressed images becomes large, but how quickly does this convergence occur? How well does the method do if the VAE is trained using a smaller sample size?\n\nOverall this is an interesting idea, and I believe it could be an excellent lossless compression scheme in scenarios where it's applicable. At the same time, there are many aspects where the paper could be strengthened by providing a more thorough investigation/evaluation.\n\n\nMinor:\n- In Sec 2.1, using p for both a general pdf and the model to be learned (i.e., of both s_n and b_i) is potentially confusing.\n- Sec 2.5.1 talks about using uniform quantization (buckets of equal width \\delta y), but then Appendix B talks about using (nonuniform) maximum entropy discretization. Which was used in the experiments? In an implementation, the quantization strategy needs to be known by both sender and receiver too, so this is additional meta-information overhead, right?\n- The discussion in Sec 4.1 seems very speculative and not particularly convincing.""]","[80, -20, 20]","[90, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses strong appreciation for the paper, calling it 'elegantly written' with 'promising results' and stating they 'truly enjoyed reading it'. They believe it will 'spark some very interesting further work'. While they do point out limitations, these are framed as opportunities for clarification rather than severe criticisms. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I hope the authors will be able to address/clarify', 'It would be very helpful if...', and 'I do not wish to undermine the importance of this finding'. They also end on a positive note, expressing their desire to see the paper accepted. The language throughout is professional and courteous, even when raising potential issues."", ""The sentiment score is slightly negative (-20) because while the reviewer starts with positive comments about the paper being well-written and clear, they express significant doubts and questions about the significance and novelty of the work. The reviewer raises several critical points and questions that suggest they are not fully convinced by the approach or its contributions. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with positive comments, and framing their criticisms as questions rather than direct criticisms. They maintain a professional tone without using harsh or dismissive language, even when expressing doubts about the work's significance."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and clear explanations, describing it as 'generally well-written' and the comparison as 'very compelling'. However, they also raise several questions and concerns, suggesting areas for improvement. The overall tone is constructive rather than overtly critical. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'it would be helpful' and 'I have some questions' which maintain a polite tone. The reviewer also acknowledges the 'impressive' compression rate achieved, further contributing to the polite tone.""]"
"['Summary. The paper is an improvement over (Balle et al 2018) for end-to-end image compression using deep neural networks. It relies on a generalized entropy model and some modifications in the training algorithm. Experimentals results on the Kodak PhotoCD dataset show improvements over the BPG format in terms of the peak signal-to-noise ratio (PSNR). It is not said whether the code will be made available.\n\nPros. \n* Deep image compression is an active field of research of interest for ICLR. The paper is a step forward w.r.t. (Balle et al 2018). \n* The paper is well written. \n* Experimental results are promising.\n\nCons.\n* Differences with (Balle et al 2018) should be emphasized. It is not easy to see where the improvements come from: from the new entropy model or from modifications in the training phase (using discrete representations on the conditions).\n* I am surprised that there is no discussion on the choice of the hyperparameter \\lambda: what are the optimal values in the experiments? Are the results varying a lot depending on the choice? Is there a strategy for an a priori choice? \n* Also is one dataset enough to draw conclusions on the proposed method?\n\nEvaluation.\nAs a non expert in deep learning compression, I have a positive opinion on the paper but the paper seems more a fine tuning of the method of (Balle et al 2018). Therefore I am not convinced that the improvements are sufficiently innovative for publication at ICLR despite the promising experimental results.\n\nSome details.\nTypos: the p1, the their p2 and p10, while whereas p3, and and figure 2 \np8: lower configurations, higher configurations, R-D configurations\n', 'Update:\nI have updated my review to mention that we should accept this work as being concurrent with the two papers that are discussed below.\n\nOriginal review:\nThis paper is very similar to two previously published papers (as pointed by David Minnen before the review period was opened):\n""Learning a Code-Space Predictor by Exploiting Intra-Image-Dependencies"" (Klopp et al.)  from BMVC 2018,\nand\n""Joint Autoregressive and Hierarchical Priors for Learned Image Compression"" (Minnen et al.) from NIPS 2018.\n\nThe authors have already tried to address these similarities and have provided a list in their reply, and my summary of the differences is as follows (dear authors: please comment if I am misrepresenting what you said):\n(1) the context model is slightly different\n(2) parametric model for hyperprior vs non-parametric\n(3) this point is highly debatable to be considered as a difference because the distinction between using noisy outputs vs quantized outputs is a very tiny detail (any any practitioner would probably try both and test which works better). \n(4) this is not really a difference. The fact that you provide details about the method should be a default! I want all the papers I read to have enough details to be able to implement them.\n(5+)  not relevant for the discussion here.\n\nIf the results were significantly different from previous work, these differences would indeed be interesting to discuss, but they didn\'t seem to change much vs. previously published work.\n\nIf the other papers didn\'t exist, this would be an excellent paper on its own. However, I think the overlap is definitely there and as you can see from the summary above, it\'s not really clear to me whether this should be an ICLR paper or not. I am on the fence because I would expect more from a paper to be accepted to this venue (i.e., more than an incremental update to an existing set of models, which have already been covered in two papers).\n\n', 'The authors present their own take on a variational image compression model based on Ballé et al. (2018), with some  interesting extensions/modifications:\n\n- The combination of an autoregressive and a hierarchical approach to define the prior, as in Klopp et al. (2018) and Minnen et al. (2018).\n- A simplified hyperprior, replacing the flow-based density model with a simpler Gaussian.\n- Breaking the strict separation of stochastic variables (denoted with a tilde, and used during training) and deterministic variables (denoted with a hat, used during evaluation), and instead conditioning some of the distributions on the quantized variables directly during training, in an effort to reduce potential training biases.\n\nThe paper is written in clear language, and generally well presented with a great attention to detail. It is unfortunate that, as noted in the comments above, two prior, peer-reviewed studies have already explored extensions of the prior by introducing an autoregressive component, obtaining similar results.\n\nAs far as I can see, this reduces the novelty of the present paper to the latter two modifications. The bit-free vs. bit-consuming terminology is simply another way of presenting the same concept. In my opinion, it is not sufficiently novel to consider acceptance of this work into the paper track at ICLR.\n\nThe authors should consider to build on their work further and consider publication at a later time, possibly highlighting the latter modifications. However, the paper would need to be rewritten with a different set of claims.\n\nUpdate: Incorporating the AC/PC decision to treat the paper as concurrent work.']","[20, -30, -20]","[60, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as an improvement and notes its promising results, but also expresses reservations about its innovativeness for ICLR publication. The pros are clearly stated, but the cons and final evaluation suggest some hesitation. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions or questions rather than harsh judgments. The reviewer also admits to being a 'non-expert,' which shows humility. The presence of constructive feedback and the absence of harsh or dismissive language contribute to the polite tone."", ""The sentiment score is -30 because the reviewer expresses significant concerns about the paper's originality and contribution, noting its similarity to previously published work. While not entirely negative, the reviewer is 'on the fence' about whether the paper should be accepted, indicating a slightly negative sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, acknowledging the paper's merits if considered in isolation and inviting the authors to comment if they feel misrepresented. The reviewer also provides a detailed breakdown of their understanding, which is courteous. However, the score is not higher as the criticism, while politely expressed, is still direct and potentially challenging for the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clear language and attention to detail, they ultimately conclude that the work lacks sufficient novelty for acceptance. The reviewer suggests the authors should build on their work further and consider publication later. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and providing constructive feedback. They use phrases like 'interesting extensions/modifications' and 'great attention to detail', which contribute to a polite tone. Even when expressing criticism, the reviewer does so in a tactful manner, suggesting ways for improvement rather than outright dismissal.""]"
"['In a distributed learning system where a parameter server maintains a full resolution copy of the parameters, communication costs can be reduced by (a) discretizing the weights that the server broadcasts to the workers, and (b) discretizing the gradients that the workers return to the parameter server. Following existing literature, the authors propose to discretize the parameters in a manner that limits its impact on the loss function by means of a diagonal approximation of the Hessian. This also means that one can bound the difference between the gradient for the full precision parameter and the gradient for the discretized parameter.  In contrast, they discretize the gradients stochastically so that the discretized version is an unbiased estimator of the full precision stochastic gradient. Since the stochastic gradient is itself an unbiased estimator of the gradient, this means we are dealing with an estimator whose variance has increased in a manner we can bound as well. The theoretical analysis consists in pushing these two bounds through classical analyses of the stochastic gradient algorithm, in this case, a regret-based version in the style of Zinkevich or Duchi.  Although i did not check the minute details of the proof, the argument feels correct and familiar.  They also give an interesting result in favor of clipping gradients, worth developing.\n\nAlthough the title promises an analysis that holds for deep networks, this analysis strictly applies only to convex models. The author argue that the predictions made by this analysis also apply to deep networks, and support this argument with extensive experiments (which certainly represent a fair amount of work).  This result is believable but should not be construed as an analysis. Nevertheless, both results (the theoretical result for convex model and the empirical result for deep networks) are interesting and worth sharing.\n\nThe main caveat comes from the style the parallel learning algorithm they are considering.  In the data-parallel case (which they consider), parameter servers approaches have been displaced by setups where all workers update their copy of the weights using the allReduced gradients.  One could also use discretized gradients to speedup the allReduce operation (this is less of a win because latencies dominate) but this would only result in an increased variance and a much simpler analysis.\n\nFinally I am not completely up-to-date with this line of work and cannot evaluate the novelty with confidence. This was not known to me, which is only a piece of evidence.\n\n-- bumping down my score because the misleading title was not addressed by the author response.\n-- bumping it up again because the authors have reacted.\n', ""Summary\n------\n\nThe authors proposes an analysis of the effect of simultaneously quantizing the weights and gradients in training a parametrized model in a fully-synchronized distributed environment, using RMSProp training updates.\n\nThe authors provide a theoretical analysis in term of regret bound, when the objective functions are smooth, convex and gradient-bounded wrt the parameter. They also assume that the parameters remains in a compact space. Their conclusions are as follow (thm 1, 2 and 3):\n\n- weight quantization, which is deterministic and therefore introduces a bias in the objective functions, introduces a non-vanishing term in the average reget, that depens on the quantization error, where the vanishing term decreases in O(d /sqrt(T)).\n\n- gradient quantization, which is performed in a stochastic, unbiased way (wrt to the full-precision gradient) do not introduce a further non-vanishing term, but augments the constant factor in the vanishing term.\n\n- gradient clipping onto gradient quantization reduced this constant factor, at the cost of ntroducing a further non-vanishing term in the average regret.\n\nAn experimental setting is performed to assess how much the theoretical conclusions derived ina simpe setting apply to predictive functions parametrized with neural-network. The experiments are three folded:\n- a first toy experiment with convex objective validates the theoretical findings\n- a second experiment performed on CIFAR assess the performance on a grid of weight/gradient quantization with or without gradient clipping\n- a third experiement, that is profiled (synthetically) assesses the performance of wieght/gradient quantization when training a model on imagenet.\n\nIn conclusion, the authors observe that quantizing weight/gradients systematically lead to a slight decrease in performance but provides promising improvement in term of training speed\n\nReview\n------\n\nThe paper is well written, documented and well-sectioned, with well written theoretical guarantees and thorough experiments, including one on a large dataset. The theoretical guarantees are relatively non-surprising and their proofs are indeed little involved. The authors are yet the first to analyse the effect of biased weight quantization on one hand, and of gradient clipping on the other hand.\n\nThe reviewer would have appreciated further comparison with existing analysis, in particular a comparison between stochastic weight quantization and loss-aware deterministic weight quantization. The bias introduced by the latter seems the culprit in the reduction of predictive performance. What if we applied non-biased weight quantization, with stochastic quantized gradient ?\n\nThe experiments as presented are a little underwhelming: first of all, there is no report of training time on ImageNet, and I believe that the profiling as been made in a communication model and not in a real setting. It would be great to see the best training time that you achieve by weight/gradient quantization (say on 4 bits).\n\nMoreover, it appears that even with 4 bit quantization, the test accuracy of the trained model is significantly reduced. Why not increase the size to say 6 or 8 bits ? \n\nOn a related aspect, can the communication quantization be used jointly with a forward/backward quantized evalution ?\n\nOverall, although this paper is relatively incremental and has underwhelming experiments, it is a thorough work that is worthy of being presented at ICLR 2019, in the reviewer's opinion.\n\nMinor\n-----\n\np 2: the notation w_i is overloaded\n\nEq 1: S_w^d should read (S_w)^d (cartesian product)\n\nThm 3: the notation R() is overloaded\n\nFigure 1 is very hard to read: increase the font size\n\nFigure 3 4 6: increase the legend size, ensure that the color used vary in lightness for printing\n\nTable 1: use bold font to indicate the best performing FP/FP model, and your best performing model\n\nFig 7 c: training curve\n"", '\nSummary:\n\nThis paper studies the convergence properties of loss-aware weight quantization with different gradient precisions in the distributed environment, in which servers keeps the full-precision weights and workers keeps quantized weights. The authors provided convergence analysis for weight quantization with full-precision, quantized and quantized clipped gradients. Specifically, they find that: 1) the regret of loss-aware weight quantization with full-precision gradient converge to an error related to the weight quantization resolution and dimension d. 2) gradient quantization slows the convergence by a factor related to gradient quantization resolution and dimension d. 3) gradient clipping renders the speed degradation dimension-free. \n\nComments:\n\nPros:\n\n- The paper is generally well written and organized. The notation is clean and consistent. Detailed proofs can be found in the appendix, the reader can appreciate the main results without getting lost in details.\n\n- The paper provides theoretical analysis for the convergence properties of loss-aware weight quantization with full-precision gradients, quantized gradient and clipped quantized gradient, which extends existing analysis beyond full-precision gradients, which could be useful for distributed training with limited bandwidth. \n\nCons:\n\n- It is unclear what problems the authors try to solve. The problem is about gradient compression, or how the gradient precision will affect the convergence for training quantized nets in the distributed environment, in which workers have limited computation power and the network bandwidth is limited. It is an interesting setting, however, the author does not make it clear the questions they are asking and how the theoretical results can guide the practical algorithm design. \n\n- The authors mentioned that quantized gradient slows convergence (relative to using full-precision gradient) in contribution 2 while also claims that quantizing gradients can significantly speed up training of quantized weights in contribution 4, which is contradictory to each other.\n\n- It is not clear what relaxation was made on the assumptions of f_t in section 3.1. The analysis are still based on three common assumptions: 1) f_t is convex 2) f_t is twice differentiable 3) f_t has bounded gradients. The assumptions and theoretical results may not hold for non-convex deep nets. E.g., the author does not valides the theorems results on d with neural networks but only with linear models in section 4.1.\n\n- The author demonstrate training quantized nets in the distributed environment with quantized gradients, however, no comparison is made with other related works (e.g., Wen et al, 2017). \n\nQuestions: \n\n- Theorem 1 is an analysis for training with quantized weights and full-precision gradients, which is essentially the same setting as BinaryConnect. Similar analysis has been done in Li et al, 2017. What is the difference or connection with their bound?\n\n- It is not clear how gradienta are calculated w.r.t. quantized weights on worker, is straight through estimator (STE) used for backpropagation through Q_w?\n\n- In section 3.3, why is \\tilde{g}_t stochastically quantized gradient? How about statiscally quantized gradients?\n\n- Why do the authors use linear model in section 4.1? Why are the solid lines in Figure 3 finished earlier than dashed lines? For neural networks, a common observation is that the larger the dimension d, the better the generalization performance. However, Figure 3 and Theorem 1 seem to be contradictory to this common belief. Would it possible to verify the theorem on deep nets of different dimension?\n\n- Why does the number of worker affect the performance? I failed to see why the number of workers affect the performance of training if it is a synchronized distributed training with the same total batch size. After checking appendix C, I think it is better to discuss the influence of batch sizes rather than the number of workers.\n\n- Why is zero weight decay used for CIFAR-10 experiment but non-zero weight decay for imagenet experiment? How was weight decay applied in Adam for quantized weights? \n\nMinor issues: \n- The notation of full-precision gradient w.r.t quantized weights in Figure 1 should be \\hat{g}_t, however, g_t is used.\n']","[50, 50, -20]","[70, 75, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the value of the work while also pointing out some limitations. They describe the theoretical analysis as 'correct and familiar' and the results as 'interesting and worth sharing'. However, they also mention caveats about the applicability to deep networks and the relevance of the approach. The final comments about bumping the score down and then up again suggest a balanced view.\n\nThe politeness score is 70 (fairly polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' work and provide constructive feedback. Phrases like 'interesting result', 'worth developing', and 'extensive experiments (which certainly represent a fair amount of work)' show appreciation for the authors' efforts. The reviewer also admits when they are not fully confident about certain aspects, which is a polite way to express potential concerns."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper as 'well written, documented and well-sectioned, with well written theoretical guarantees and thorough experiments', they also note that it is 'relatively incremental and has underwhelming experiments'. The overall tone is constructive and the reviewer concludes that the work is 'worthy of being presented at ICLR 2019'. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'The reviewer would have appreciated...'). They also acknowledge the authors' contributions positively before offering critiques. The language is professional and courteous, avoiding any harsh or rude phrasing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms and concerns raised ('Cons'). The reviewer points out contradictions, unclear problem statements, and limitations in the paper's approach and results. However, the tone is not entirely negative, as the reviewer also recognizes the paper's contributions and potential usefulness.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, such as 'It is unclear...' and 'It is not clear...', rather than using harsh or dismissive language. The reviewer also balances criticism with positive feedback, acknowledging the paper's strengths before discussing its weaknesses. The use of questions to prompt further clarification or improvement is also a polite approach to reviewing.""]"
"['The authors are proposing a method for allowing the generation of multiple objects in generated images given simple supervision such as bounding boxes and their associated labels. They control the spatial location of generated objects by the mean of an object pathway added to the architecture of both Generator and Discriminator within a GAN framework. They show generated results on Multi-MNIST, CLEVR with discussions of their model\'s abilities and properties. they also provide quantitative results on MSCOCO (IS and FID) using StackGAN and AttGAN models with the object pathway modifications and show some improvements compared to the original models. However it must be noted (as commented by the authors) that these models are using image captions only and do not have explicit supervision of bounding box and object labels.\n\nThis paper proposes a simple approach to generating requested objects in GAN-based image generation task, The method is supervised and requests (in its current form) the Bounding Boxes and Labels of the objects to integrate into the image generation. This task of controlling the nature (identity) and size of objects to integrate in a generated image is an important one and is significant to the GAN-base image generation community. In terms of originality, the approach is a nice simple architecture that takes care of the spatial location problem head-on. It seems like an obvious step but this does not take away from the merits of the proposed method.\n\nThe generator Global path is given a noise component. From the text, it does not seem that the Object path is given a noise component. Do you generate always the same object given the same label and Bounding Box then? Why not integrate some noise in this pipeline too?\n\n\nMulti-MNIST:\nThe authors present results on Multi-MNIST 50K customed data to present the ability of the model to accurately put request images in the correct bounding box (BB) and do some ablation study. This is an interesting test as it shows that indeed the method proposed generates digits where it is expected to. Could you provide the ground truth labels for each/some image/s? For the failure cases it is often not clear what digit is what. For the Row E and F, 1s could be 7s and vice versa. Since it is a qualitative study, it would be nice to have the Ground Truth (GT) (which you provide to G at for generation). For the failure case of Row D (right) an interesting results would have been to have example of a digit bounding box from top to bottom with few pixel vertical shift to visualize when the model starts to mess-up the generation. This seems to point that your model (exposed to the location from BB for the object paths) is sensitive to what locations it has seen in training. How would you make the object path more robust to unseen location (overall you need to design an object of a given size, then locate it in your empty canvas prior to the CNN for generation)?\n\nCLEVR:\nThe images resolution make it hard to really see the shape of the images (here too, the GT would be great). The bounding boxes make the images even harder to parse. I know the colors change but ""We can confirm that the model can control both location and object\'s shape"". For the location, it is true, for the shape is hard to completely tell at this resolution without GT. \n\nMS-COCO:\n Just a comment in passing on the fact that resizing images from COCO to 256x256 will inherently distort quite a bit of images, the median size (for each dim) for COCO is 640x480, if I am not mistaken. Most, if not all images in COCO are not 1.0 size ratio.\nThe quantitative results on COCO seem to confirm that the proposed method is generating ""better"" images according to IS and FID. This is a good thing, however the technique is strongly supervised (Bounding Box and Object Labels, caption compared to solely captions for StackGAN and AttGAN) so this result should be expected and really put into perspective as your are not comparing models w/ the same supervision (which you mention in the Discussion).\n\nDiscussion: \nI appreciate that the authors addressed the limitations of their approach in this section. The overlapping BBs seems to be an interesting challenge. Did you try to normalize the embeddings in overlapping area? A simple sum does not seem to be a good solution. In Figure 7 w/ overlapping zebras, the generation seems completely lost. \n\nIn terms of clarity, the paper is well-written but would benefit *greatly* from using variables names when discussing \'layout embedding\', \'generated local labels\', etc. Variable names and equations, while not necessary, can go a long way to clearly express a model\'s internal blocks (most of the papers you referenced are using this approach). The paper employs none of this commonly used standard and suffers from it. I myself had to write down on the margin the different variables used at each step described in text to have an understanding of what was done (with help of Figure 1). You should reference Figure 1 in the Introduction, as you cover your approach there and the Figure is useful to grasp your contributions.\n\nAnother comment concerning clarity is, while it is fine to rely on previously published papers for description of our own work, you should not assume full knowledge from the reader and your paper should stand on its own without having the reader lookup for several papers to have an understanding of your training procedures. If one uses GAN training, it should be expected to cover/formulate quickly the min max game and the various losses you are trying to minimize. I am afraid that ""using common GAN procedures"" is not enough. When describing your experimental setup, pointing to another paper as ""hyperparameters remain the same as in the original training procedure"" should not be a substitution for covering it too, even if lightly in the Appendix. For instance: in the Appendix, it is mentioned that training was stopped at 20 epochs for Multi-MNIST, 40 for CLEVR... How did you decide on the epoch (early stopping, stopped before instabillity of GAN training, etc.) Did you use SGD? ADAM? Did you adjust the learning rate, which schedule? etc. for your GAN training. This information in the Appendix would make the paper overall stronger. \n\nLast comment: In terms of generation multiple objects. Have you had the chance to run an object detector on your generated image (you can build one on MSCOCO given the bounding box and label, finetune an ImageNet pretrained model). It would be interesting to see if the generated images are good enough for object detection.\n\nPost-Rebuttal: Given the work from the authors on improving the clarity of the paper as well as investigating the use of object detection metrics to compare their methods, I decided to move my rating upward to 7  ', 'The paper proposes a simple but effective method for controlling the location of objects in image generation using generative adversarial networks. Experiments on MNIST and CLEVR are toy examples but illustrate that the model is indeed performing as expected. The experiments on COCO produce results that while containing obvious artefacts are producing output consistent with the input control signal (i.e., bounding boxes). It would however have been interesting to see more varied bounding box locations for the same caption.\n\nIn short, the paper makes an interesting addition to image generation works and likely to be incorporated into future image generation and inpainting methods.', ""This paper proposed a model to generate location-controllable images built upon GANs. The experiments are conducted on several datasets. Although this  problem seems interesting, here are several concerns I have:\n\n1.Novelty: the overall framework is still conditional GAN framework. The multiple -generators-discriminators structure has been used in many other works (see the references). The global-local design is not new. Finally, compared with Reed et al. [2016], the novelty is limit. \n\n2.Motivation: I still can not tell why the proposed method is better than ones with scene layout. For me, the cost of collecting annotated data is almost the same. \n\n3. The experimental results are week.  For such a task, it is difficult to find a good metric. Thus the qualitative comparison is important. I think the author should follow standard rule to do some design for user study instead of cherry pick some examples. Besides, it should include more baselines instead of StackGAN. \n\nReferences: \na. Xi et al. Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond\nb. Yixiao et al. FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification\n\nRevision:\nThanks for the work of the authors' and all the reviewers. I spent sometime reading the rebuttal as well as the revised paper. It addressed most of my concern. I would like to change my rating from 5 to 6. ""]","[60, 70, -50]","[80, 50, 20]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's contributions and significance, while also providing constructive criticism and suggestions for improvement. The overall tone is supportive, with phrases like 'This paper proposes a simple approach' and 'This is an interesting test'. The politeness score is 80 (quite polite) due to the reviewer's respectful language throughout, using phrases like 'I appreciate that the authors addressed...' and 'Could you provide...'. The reviewer offers critiques in a constructive manner, balancing positive feedback with areas for improvement. The language is professional and courteous, avoiding harsh or dismissive statements."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as making an 'interesting addition' and suggests it's 'likely to be incorporated into future methods'. They also note that the experiments illustrate the model 'performing as expected'. While they mention some limitations (toy examples, artifacts), the overall tone is approving. The politeness score is 50 (somewhat polite) because the language is professional and constructive. The reviewer acknowledges the paper's strengths and suggests improvements without harsh criticism. They use phrases like 'it would have been interesting' rather than demanding changes, which maintains a respectful tone."", ""The sentiment score is -50 because the review is generally critical, pointing out several concerns about novelty, motivation, and experimental results. However, it's not entirely negative as the reviewer acknowledges the problem as interesting and ultimately increases their rating. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They also thank the authors for their work and acknowledge the improvements made in the revision, which adds a polite tone to the review.""]"
"['Summary:\nThe paper considers the problem of online stochastic convex optimization in a fully distributed topology. In particular, the authors focus on the synchronous setting and to avoid the slow progress that can be obtained by slow nodes, called stragglers, they propose an online distributed optimization method called Anytime Minibatch (AMB). In the update of AMB rather than fixing the minibatch size, they fix the computation time in each epoch. This characteristic prevents the stragglers from holding up the entire network, while allowing nodes to benefit from the partial work carried out by the slower nodes. \n\nA convergence analysis of AMB is provided showing that the online regret achieves the optimum performance. Numerical evaluations where a comparison of AMB and the ""Fixed MiniBatch"" method (FMB)are also presented.\n\nComments:\nI believe that the idea of the paper is interesting and the convergence analysis seems correct, however i have some concerns regarding  the presentation and the numerical evaluation. \n\n1) In the title the word ""online"" is mentioned but never explained  in the main text. What is this mean? What are the differences compare to the ""static"" setting? See for example the work of [Tsianos, Rabbat (2016)] for more details on that. What are the related literature on this setting?\n\n2) In the last paragraph of Introduction is highlighted that the algorithm AMB has the optimum performance?  The authors should add an appropriate reference there and explain why this is optimum for their setting. I believe that for the convenience of the reader current Section 5 called ""previous work"" can move immediately after introduction and more details of AMB with the existing literature should be provided. Probably rename the section ""Closely relate work"".\n\n3) Section 2 is devoted mostly on the formal presentation of algorithm AMB. I strongly suggest the addition of a pseudocode of the algorithm in the appendix (or even in the main text if there is a space) where the reader can easily understand how the algorithm works.\n\n4) On the Algorithm:  if some nodes are very slow and they do not make any update during the given time T what will happen? How this will affect the performance of the method? In this case does it make sense to increase the value of T.\n\n5) On numerical evaluation:  A comparison of AMB and FMB  is presented both in synthetic and real data showing that AMB can be faster than FMB in terms of wall clock time. \nI am not sure if the performance of the AMB is as good as one should expect especially for the case of synthetic data. Will it be possible to construct a synthetic example with extremely slow nodes where the improvement of the performance is much better than 50%?\n\nIn general i find the paper interesting, with nice ideas and I believe that will be appreciated from researchers that are interested on control theory/signal processing and information theory.  Since the paper is focused on convex optimization I am not sure if it will be particularly interesting for a substantial fraction of the ICLR attendees.\n', ""This paper studies distributed optimization in the presence of straggling computing nodes. In a synchronous distributed optimization approach, the stragglers delay the entire computation as the synchronization operation cannot be performed till every computing nod has completed its task. This paper aims to mitigate the effect of stragglers by proposing Anytime MiniBatch (AMB) approach, where each computing node is allowed to process the different number of samples between two synchronization steps. In particular, each node is given $T$ unit time to process as many samples as it can. After that, the nodes are allowed to aggregate the information among themselves through a consensus mechanism for another $T_c$ unit time. In contrast with this, the usual Fixed MiniBatch (FMB) approach requires each node to process a fixed number of samples before invoking aggregating step. The presence of stragglers can significantly increase the time between two synchronization step and slow down the overall optimization process. \n\nThis paper combines their AMB approach with the dual averaging method. The paper presents sample-path wise regret bounds for convex optimization under additional standard assumptions (e.g., Lipschitz continuousness, smoothness). The paper then compares analytically and experimentally compare the speed-ups obtained by their AMB approach as compared to the FMB approach. The paper studies an interesting problem and proposes a simple and practical solution. The paper is well written and makes novel contributions with sound analysis. The experimental evaluation on the real system also corroborates the theoretical findings.\n\nComments/questions: \n\nThe reviewer did not find the justification of using $c_i(t)$ in the definition of regret (cf. (17)) very clear. Is it because we also want compare with a centralized setting which does not have the communication overhead? As far as evaluation between distributed schemes (e.g., AMB, FMB etc) is concerned, shouldn't one define the regret with respect to $b_i(t)$s itself?\n\nCan the authors comment on the setup where the communication links are also unpredictable and may experience congestion? In this case, one would encounter variable communication overhead to achieve the consensus error up to $epsilon$.\n\nIn Sec. 4, could authors comment on the settings where $O(sqrt(n-1))$ speed up is achievable?\n\nMinor typos: In eq. (127)  E[S] -> S_F, S_T -> S_A. In eq. (128)  S_T -> S_A.\n\n\n\n\n\n"", 'Overall, this paper is well written with clearly presentation.\nHowever, the contribution is not good enough to research the ICLR requirement.\nAlthough the authors propose some method to balance the computation between distributed workers, which should be important for distributed optimization algorithm design, but not enough numerical experiments are proposed to prove the efficiency.\nEven though some convergence analysis is given.\nThe main concern of this paper is to significantly increase the algorithm efficiency, but both theoretical and numerical results are lack of strength.']","[20, 80, -50]","[60, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer finds the paper 'interesting' and believes it has 'nice ideas', but also expresses several concerns and suggestions for improvement. The overall tone is constructive rather than overly critical. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I believe', 'I strongly suggest', and 'Will it be possible', which softens the critique. The reviewer also acknowledges the potential value of the work for certain research communities. However, the score is not extremely high as the review maintains a professional, rather than overtly friendly, tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They state that the paper 'studies an interesting problem', 'proposes a simple and practical solution', is 'well written', and 'makes novel contributions with sound analysis'. The experimental results are also noted to corroborate the theoretical findings. The only slight criticism is in the form of questions for clarification, which doesn't significantly detract from the overall positive sentiment.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise where due and frame their criticisms as questions or requests for clarification rather than direct criticisms. Phrases like 'Could the authors comment on...' and 'Can the authors comment on...' are polite ways of asking for more information. The reviewer also helpfully points out minor typos, which is a constructive gesture. The tone is consistently professional and courteous without being overly deferential."", ""The sentiment score is -50 because while the review starts with a positive note about the paper being well-written, it quickly shifts to criticism. The reviewer states that the contribution is not good enough, the numerical experiments are insufficient, and both theoretical and numerical results lack strength. These criticisms outweigh the initial positive comment, resulting in an overall negative sentiment. The politeness score is 20 because the reviewer uses relatively neutral language and acknowledges some positive aspects ('well written', 'clearly presentation'). They also use softening phrases like 'However' and 'Although' when introducing criticisms, which maintains a level of politeness. The reviewer doesn't use harsh or rude language, but also doesn't go out of their way to be overly polite, resulting in a slightly positive politeness score.""]"
"['The paper analyses the data collected from 6005 neurons in a mouse brain. Visual stimuli are presented and the responses of the neurons recorded. In the next step, a rotational equivariant neural network architecture together with a sparse coding read-out layer is trained to predict the neuron responses from the stimuli. Results show a decent correlation between neuron responses and trained network. Moreover, the rotational equivariant architecture beats a standard CNN with similar number of feature maps. The analysis and discussion of the results is interesting. Overall, the methodological approach is good.\n\nI have trouble understanding the plot in Figure 4, it also does not print well and is barely readable on paper.\n\nI have a small problem Figure 6 where ""optimal"" response-maps are presented. From my understanding, many of those feature maps are not looking similar to feature maps that are usually considered. Given the limited data available and the non-perfect modeling of neurons, the computed optimal response-map might include features that are not present in the dataset. Therefore, it would be interesting to compare those results with the stimuli used to gather the data. E.g. for a subset of neurons, one could pick the stimulus that created the maximum response and compare that to what the stimulus with the maximum response of the trained neuron was. It might be useful to include the average correlation of the neurons belong to each of the 16 groups(if there are any meaningful differences), especially as the cut-off of ""correlation 0.2 on the validation set"" is rather low.\n\nNote: I am not an expert in the neural-computation literature, I am adapting the confidence rating accordingly.', '\ufeffThis paper applies a rotation-equivariant convolutional neural network model to a dataset of neural responses from mouse primary visual cortex. This submission follows a series of recent papers using deep convolutional neural networks to model visual responses, either in the retina (Batty et al., 2016; McIntosh et al., 2016) or V1 (Cadena et al., 2017; Kindel et al., 2017; Klindt et al., 2017). The authors show that adding rotation equivariance improves the explanatory power of the model compared to non-rotation-equivariant models with similar numbers of parameters, but the performance is not better than other CNN-based models (e.g. Klindt et al., 2017). The main potential contributions of the paper are therefore the neuroscientific insights obtained from the model. However, I have concerns about the presented data and the validity of rotation equivariance in modeling visual responses in general (below). Together with the fact that the model does not provide better explanatory power than other models, I cannot recommend acceptance. I am open to discussions with the authors, but do not anticipate a major change in the rating.\n\nUpdate after revisions: The authors performed extensive work to address my concerns. This showed that some concerns (RF appearance) were valid, and the authors removed them from the final manuscript. I raised my score accordingly.\n\n1. As noted by the authors, the finding that “Feature weights are sparse” (page 6) could be due to the sparsity-inducing L1 penalty. The fact that a model without L1 penalty performs worse does not mean that there is sparsity in the underlying data. For example, the unregularized model could be overfitting. A more careful model selection analysis is necessary to show that the data is better fit by a sparse than a dense model. \n\n2. The finding that there are center-surround or asymmetric (non-gabor) RFs in mouse V1 is not novel and not specific to this model (e.g. Antolik et al., 2016). \n\n3. Many of the receptive fields in Figure 6 look pathological (overfitted?) compared to typical V1 receptive fields in the literature. I understand that sensitivity to previously undetected RF features is a goal of the present work. However, given how unusual the RFs look, more controls are necessary to ensure they are not an artefact of the method, e.g. the activation maximization approach with gradient preconditioning, the sparsity constraints, or overfitting. Perhaps a comparison of RFs learned on two disjoint subsets of the training set would help to determine which features are reproducible.\n\n4. Should orientation be treated as a nuisance variable? Natural image statistics are not rotation-invariant. In the visual system, especially in mice, it is not clear whether orientation is completely disentangled from other RF properties. The orientation space is not uniformly covered, and some directions have special meaning (e.g. cardinal directions), such that it might be invalid to assume that the visual system is equivariant to rotation. (The same concern applies to the translation equivariance assumed when modeling visual RFs with standard CNNs.) Of course, there is a tradeoff between model expressiveness and the need to make assumptions to fit the model with realistic amounts of data. However, this concern should at least be discussed.\n\n5. Some more details about the neural recordings would be good. What calcium indicator? How was the recording targeted to V1? Perhaps some example traces.', 'In this interesting study, the authors show that incorporating rotation-equivariant filters  (i.e. enforcing weight sharing across filters with different orientations) in a CNN model of the visual system is a useful prior to predict responses in V1. After fitting this model to data, they find that the RFs of model V1 cells do not resemble the simple Gabor filters of textbooks, and they present other quantitative results about V1 receptive fields. The article is clearly written and the claims are supported by their analyses. It is the first time to my knowledge that a rotation-equivariant CNN is used to model V1 cells.\n\nThe article would benefit from the following clarifications:\n\n1. The first paragraph of the introduction discusses functional cell types in V1, but the article does not seem to reach any new conclusion about the existence of well-defined clusters of functional cell types in V1. If this last statement is correct, I believe it is misleading to begin the article with considerations about functional cell types in V1. Please clarify.\n\n2. For clarity, it would help the reader to mention in the abstract, introduction and/or methods that the CNN is trained on reproducing V1 neuron activations, not on an image classification task as in many other studies (Yamins 2014, etc). \n\n3. “As a first step, we simply assume that each of the 16 features corresponds to one functional cell type and classify all neurons into one of these types based on their strongest feature weight.” and “The resulting preferred stimuli of each functional type are shown in Fig. 6.“\nAgain, I think these statements are misleading because they suggest that V1 cells indeed cluster in distinct functional cell types rather than form a continuum. However, from the data shown, it is unclear whether the V1 cells recorded form a continuum or distinct clusters. Unless this question is clarified and the authors show the existence of functionally distinct clusters in their data, they should preferably not mention ""cell types"" in the text.\n\nSuggestions for improvement and questions (may not necessarily be addressed in this paper):\n\n4. “we apply batch normalization”\nWhat is the importance of batch normalization for successfully training the model? Do you think that a sort of batch normalization is implemented by the visual system? \n\n5. “The second interesting aspect is that many of the resulting preferred stimuli do not look typical standard textbook V1 neurons which are Gabor filters. ”\nOK but the analysis consists of iteratively ascending the gradient of activation of the neuron from an initial image. This cannot be compared directly to the linear approximation of the V1 filter that is computed experimentally from doing a spike-triggered average (STA) from white noise. A better comparison would be to do a single-step gradient ascent from a blank image. In this case, do the filters look like Gabors?\n\n6. Did you find any evidence that individual V1 neurons are themselves invariant to a rotation?\n\n7. The article could be more self-contained. There are a lot of references to Klindt et al. (2017) on which this work is based, but it would be nice to make the article understandable without having to read this other article.\n\nTypo: Number of fearture maps in last layer \n\nConclusion:\nI believe this work is significant and of interest for the rest of the community studying the visual system with deep networks, in particular because it finds an interesting prior for modeling V1 neurons, that can probably be extended to the rest of the visual system. However, it would benefit from the clarifications mentioned above.']","[60, -50, 50]","[70, 50, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses an overall positive view of the paper, noting that the methodological approach is good, the analysis and discussion are interesting, and the results show decent correlation. However, it's not extremely positive as the reviewer does point out some issues and suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, frames criticisms constructively, and acknowledges their own limitations ('I am not an expert...'). The reviewer offers suggestions rather than demands and uses phrases like 'it would be interesting' and 'it might be useful' which maintain a polite tone. The review is professional and constructive without being overly formal or deferential."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper and does not recommend acceptance. However, they do acknowledge some positive aspects and show openness to discussion, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific recommendations for improvement. They avoid harsh or dismissive language, even when expressing concerns. The reviewer also acknowledges the authors' efforts in addressing previous concerns, which contributes to the polite tone. The balanced approach, combining critique with recognition of potential value, reflects a courteous academic discourse."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the study as 'interesting' and states that the article is 'clearly written' with claims 'supported by their analyses'. They also mention that it's the first time a rotation-equivariant CNN is used to model V1 cells, indicating novelty. However, they also provide several suggestions for improvement, which prevents the score from being higher. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'The article would benefit from...' and 'Suggestions for improvement...', which are polite ways to offer feedback. The reviewer also acknowledges the significance of the work in the conclusion. The tone is professional and courteous throughout, without any harsh or rude comments.""]"
"['This paper builds on the long recent tradition of analyzing deep linear neural networks. In addition to an ample appendix bringing the page total to 20, the authors went over the recommended eight pages, hitting the hard limit of 10 and thus per reviewing directions will be held to a higher standard than the other (mostly 8-page) papers. \n\nThe recent literature on deep linear networks has explored many paths with the hope of producing insights that might help explain the performance of deep neural networks. A recent line of papers by Soudry and Srebro among others focuses on the behavior of stochastic gradient descent. This paper’s analysis comes from a different angle, following the work by Saxe et al (2013) whose analysis considers a (classic one hidden layer) linear teacher network that generates labels and a corresponding student trained to match those labels. The analysis hinges on the singular value decomposition of the composite weight matrix USV^T = W = W^{32} W^{21}.\n\nOne aim of the present work, that appears to be a unique contribution above the prior work is to focus on the role played by task structure, suggesting that certain notions of task structure may play a more significant role than architecture and that any bounds which consider architecture but not task structure are doomed to be excessively loose. \n\nTo facilitate their analysis, the authors consider an artificial setup that requires some specific properties. For example, the number of inputs are equal to the input dimension of the network, with the inputs themselves being orthonormal. The labeling function includes a noise term and the singular values of the teacher model admit an interpretation as signal to noise ratios. Given their setup, the authors can express the train and test errors analytically in terms of the weight matrices of the teacher and student and the input-output covariance matrix. The authors then analyze the gradient descent dynamics in what appears to follow the work of Saxe 2013 although I am not an expert on that paper. The analysis focuses on the time dependent evolution of the singular values of the student model, characterized via a set of differential equations.\n\nThe next analysis explores a condition that the authors dub “training aligned” initial conditions. This involves initializing the student weights to have the same singular vectors as the training data input-output covariance but with all singular values equal to some amount epsilon. The authors show that the learning dynamics give rise to what they characterize as a singular value “detection wave”. Detecting the modes in descending order by their corresponding singular values.\n\nA set of synthetic experiments show close alignment between theory and experiment.\n\nSection 3.5 offers just one paragraph on a “qualitative comparison to nonlinear networks”. A few issues here are that aesthetically, one-paragraph subsections are not ideal. More problematic is that this theory presumably is building towards insights that might actually be useful towards understanding deep non-linear networks. Since the present material is only interesting as an analytic instrument, I would have hoped for greater emphasis on these connections, with perhaps some hypotheses about the behavior of nonlinear nets driven by this analysis that might subsequently be confirmed or refuted. \n\nThe paper concludes with two sections discussing what happens when nets are trained on randomly labeled data and knowledge transfer across related tasks respectively. \n\nOverall I think the paper is well-written and interesting, and while I haven’t independently verified every proof, the technical analysis appears to be interesting and sound. The biggest weaknesses of this paper---for this audience, which skews empirical---concern the extent to which the work addresses or provides insight about real neural networks. One potential weakness in this line of work may be that it appears to rely heavily on the linearity of the deep net. While some other recent theories seem more plausibly generalized to more general architectures, it’s not clear to me how this analysis, which hinges so crucially on the entire mapping being expressible as a linear operator, can generalize. \n\nOn the other hand, I am personally of the opinion that the field is in the unusual position of possessing too many tools that “work” and too few new ideas. So I’m inclined to give the authors some license, even if I’m unsure of the eventual utility of the work. \n\nOne challenge in reviewing this paper is that it builds tightly on a number of recent papers and without being an authority on the other works, while it’s possible to assess the insights in this paper, it’s difficult to say conclusively which among them can rightly be considered the present paper’s contributions (vs those of the prior work).\n', 'Most theoretical work on understanding generalization in deep learning provides very loose bounds and does not adequately explain this phenomena. Moreover, their is also a gap in our understanding of knowledge transfer across tasks. \n\nThe authors study a simple model of linear networks. They give analytic bounds on train/test error of linear networks as a function of training time, number of examples, network size, initialization, task structure and SNR. They argue that their results indicate that deep networks progressively learn the most important task structure first, so the generalization at the early stopping primarily depends on task structure and is independent of network size. This explains previous observations about real data being learned faster than random data. Interestingly, they show a learning algorithm that provably out-performs gradient-descent training. They show that how knowledge transfer in their model depends on SNRs and input feature alignments of task-pairs.\n\nThe theoretical framework of low-rank noisy teachers using a more complex (e.g., wider or deeper) student network is simple and allows them to use random matrix theory to understand and interpret  interesting scenarios such as random initialization vs. training-aligned initialization. Fig. 5 shows that even though the theoretical framework is for linear networks, many of the observations hold even for non-linear (leaky ReLU) networks. They also offer a reasonable explanation for learning random vs. real data in terms of how the signal singular values get diluted or spread over many modes.\n\nI do not think that the generalization bounds given by the authors are any tighter than previous attempts. However, I think their theoretical and experimental contributions to provide quantitative and qualitative explainations of various interesting phenomena in deep learning are both solid enough to merit acceptance.', ""Pros: The paper tackles an interesting problem of generalization and transfer learning in deep networks. They start from a linear network to derive the theory, identifying phases in the learning, and relating learning rates to task structure and SNR. The theory is thorough and backed up by numerical simulations, including qualitative comparisons to nonlinear networks. \n\nThe intuition behind alignment of tasks \n\nCons: Most of the theory is developed on a linear network in an abstracted teacher/student/TA framework, where the analysis revolves around the the SVD of the weights. It's unclear to what extent the theory would generalize not only to deep, nonlinear networks (which the paper addresses empirically) but also different structures in the task that are not well approximated by the SVD.""]","[50, 70, 60]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'well-written and interesting' and the technical analysis as 'interesting and sound'. However, they also point out some weaknesses, particularly regarding the paper's relevance to real neural networks. The overall tone is balanced, leaning towards positive.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'I think', 'I would have hoped', and 'I'm inclined to give the authors some license', which show consideration for the authors' perspective. The reviewer also admits their own limitations in fully assessing the paper's contributions relative to prior work, which is a polite way of expressing uncertainty."", ""The sentiment score is 70 (positive) because the reviewer acknowledges the paper's contributions as 'solid enough to merit acceptance' and praises the theoretical framework and explanations provided. They highlight the paper's strengths in explaining various phenomena in deep learning. The slight reservation about the tightness of generalization bounds prevents a higher score. The politeness score is 50 (somewhat polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively. However, the review maintains a professional tone without overly polite expressions, keeping it balanced between neutral and polite."", ""The sentiment score is 60 (positive) because the review starts with listing the pros, highlighting the interesting problem, thorough theory, and numerical simulations. The reviewer acknowledges the paper's strengths before mentioning cons. The politeness score is 50 (slightly polite) as the language is professional and objective, without harsh criticism. The reviewer uses neutral phrases like 'It's unclear' instead of more critical language. The review balances positive aspects with constructive criticism, maintaining a respectful tone throughout.""]"
"['This paper explores the inevitability of adversarial examples with concentration inequalities. It is motivated by the difficulties of achieving adversarial robustness in literature. It derives isoperimetric inequalities on a cube, and then discuss the adversarial robustness of data distributed inside the cube, with the assumption that the data has bounded density. These inequalities are established on different norms. The authors then discuss limitation of the proposed bounds when analyzing practical data distribution and discussed the influence of dimensionality on adversarial robustness.\n\n\nNovelty of the idea:\nThe idea of using concentration inequalities to explain vulnerability is novel in the field of adversarial examples and is a relevant/meaningful angle on understanding this phenomenon. (Although there are concurrent works also relating concentration inequalities to adversarial robustness, they don\'t diminish the novelty of this work.)\n\n\n\nOn technical contributions:\nIn summary, this paper applies / adapts previous results in concentration inequalities to develop bounds related to adversarial examples. The bounds in Lemma 3 are on any p>0, this seems to be new to my knowledge, but the technical contribution in the proof is limited.\n\nHere are some detailed comments.\n\nThe authors claim that\n""This question is complicated by the fact that simple, geometric isoperimetric inequalities fail to exist for the cube, and the shapes that achieve minimal \\eps-expansion (if they exist) depend on the volume they enclose and the choice of \\eps.""\nThis statement is at least misleading, if not wrong. It is well known that geometric isoperimetric inequality does exist for cube for the L2 case (see Ledoux, M., 2001. Proposition 2.8.), and the proof procedure the author used is also very similar to the proofs in Ledoux, M., 2001.\n\nTheorem 5\'s proof is confusing, if not wrong. \nThis is my brief recap on the first part of Thm 5, \nIf there exists eps and p such that, for all classifiers on MNIST, a random image has eps-adv with probability at least p, then for all classifiers on b-MNIST, a random image has b*eps-adv with probability at least p.\nThe proof in Appendix E says b-MNIST images can be classified by first downsampling. These downsampled classifiers do not cover ""all classifiers on b-MNIST"", so I don\'t see how the proof stands.\nLikewise, the proof of the second part has the similar problem.\nTherefore, I\'m not yet convinced that Thm 5 is correct.\nAlso I suggest the authors use more rigorous language to present Theorem 5, in a similar fashion to previous theorems.\n\nRe: Lemma 4, my understanding is that it is from previous literature. The authors should point out exactly where is it from (with section# and theorem#), so that readers and reviewers can more easily check the correctness of it.\n\nThe authors mention that ""Intuitively, the concentration limit Uc can be interpreted as a measure of image complexity.""\nI think this statement is problematic. It is, at best, oversimplifying the the problem. If we assume the data lies in low-dimensional space, the volume of the support will be 0, no matter how complex the shape of the manifold is. This lead to unbounded density in the ambient dimension.\nEven when considering ""expanded dataset"" like the authors discussed in Section 7, it is not obvious that Uc can be interpreted as image complexity. To make such a claim, more assumptions need to made and more analyses need to be done.\nSimilar comments applies to the ""correlations between pixels"" and concentration.\n\n\n\nOn the significance:\nAs the author themselves have already mentioned, the bounds described in the paper all depends on the bounded density of the data distribution. In practice, the density of data distribution is difficult to understand, if not impossible. Therefore it is still inconclusive whether the ""inevitability"" exists. But to be fair, I believe this is mostly due to the difficulty of the problem being studied.\n\n\n\nClarity and writing:\nThe skeleton of the paper is well written and easy to follow. I\'ve pointed out some problems in my previous comments.\nI also appreciate that the authors made efforts to not overclaim.\n\nhere are a few more comments:\n- I personally feel Section 3 as an ""warm-up"" section is redundant, and the authors can consider move them to the appendix.\n- In Section 6 and 7, the authors talk about when is the bound ""meaningful"" and ""active"". This part is confusing/misleading. eps=sqrt(n) is actually the maximum possible perturbation and not falls into the common ""adversarial perturbation"" where the perturbation does not change the semantic meaning of the image. There should be a least an additional numerical examples on small eps, so the readers have better ideas on the tightness/looseness of the bound.\n\n\n\nReferences:\nLedoux, M., 2001. The concentration of measure phenomenon (No. 89). American Mathematical Soc..\n\n==========================\nI change my rating on this paper to be 6, after the authors\' response. \n', 'The paper considers the problem of adversarial examples in (mostly high-dimensional) multi-class classification problems. Although the results are not specific necessarily to very high dimensional data or two images, the paper mostly uses images as a running example, and so will I in the review. \n\nAssume that the data all lies in the unit box in R^n ([0, 1]^n). A multiclass classifier with K classes partitions the unit cube into K parts, each part corresponding to a given class. There are distributions \\rho_c associated with each class and there is a bound on their density given by U_c and the fraction of examples of class c is f_c. And (eps, p) adversarial point y for some point x is such that |x - y|_p <= \\eps and the classifier classifies x & y differently. \n\nThe paper shows that under this modeling assumption adversarial examples are inevitable. The results mostly use standard (but deep) results from probability theory. The technical proofs themselves are not particular difficult (provided one has the right background). I think the overall implications are interesting, and I will recommend the paper be accepted. \n\nHowever, I also feel that this is a missed opportunity. To some extent the authors do try to have some high-level discussion about adversarial examples, but I think this could be expanded on more. For instance, why should it be assumed that an example that is \\eps far should automatically have the same class label? Surely, being ""eps""-far away is an equivalence relation, thus this would mean that all the hypercube would have to be labeled by the same class. This is clearly not the case. One plausible explanation is that if you take two points that are in two different classes, then any sequence of points that take one to the other with the property that each adjacent pair is at most \\eps far away, must have the property that some intermediate mass have negligible chance of being a ""natural"" image. \n\nOn the other hand, doesn\'t the fact that humans are not susceptible to most adversarial examples, imply that adversarial-example resistant classifiers exist? My own feeling is the assumption that U_c is bounded is the strongest assumption that may not hold true with real data. In any case, the paper has enough technical content to merit acceptance and I hope the open review forum will lead to a fruitful discussion about some of these questions.\n\n--\n\nMinor comments:\nPage 6 (just after Thm 2). Isn\'t the bound in Eqn. (5) true for all \\ell_p norms for p \\geq 2? (not just \\ell_2 as the sentence says)\nParas on Page 6 (just below Thm 2). It would be more pleasant if equation x could be replaced by Eq. (x) or Equation (x). \nPara in Sec 7 on Unbounded density: Clarify what norm you mean when you talk about \\eps/2 perturbations.\nThm 5: Seems odd to have a theorem about MNIST. Surely the result is a lot more general!!!', 'This paper uses several lemmas in geometry to prove that adversarial examples\nare hard to avoid under the assumption that there is no ""don\'t know"" class and\nthe distribution of each class is not too concentrated. The paper first starts\nwith a simple case where the data points are distributed on a sphere, and then\nextends the results to the realistic case where data points are inside a cube\n[0,1]^n. \n\nThe paper uses epsilon expansion of a set as a mathematical tool, and borrows\nsome important lemmas from geometry to the case of adversarial learning.  In\nthe sphere case, the results come from a fact that high dimensional\nhalf-spheres can almost cover all points in the sphere after an epsilon\nexpansion, and the results depend on dimension n. For the unit cube case, the\nauthors borrow a result from Talagrand, to show that the epsilon expansion of a\nset can cover a large portion of the cube as long as the set distribution is\nnot very concentrated.  In this case, the results (for l_2 norm) do not depend\non dimension n.\n\nExperimentally, the authors show that inputs with higher dimension can actually\nget better robustness, aligning with the provided analysis.  The primary reason\nthat current adversarial defense does not work well on CIFAR is due to the fact\nthat dataset is more spread out in high dimensional space. This is a good\ninsight for understanding adversarial examples.\n\nThe paper is overall well written and easy to follow. The interpretation of\neach lemma and proposition is clear. Although the paper mostly depend on\nwell-known results in geometry and the ideas used are simple, it does provide\ngood insight on explaining the prevalence of adversarial examples. I recommend\nto accept this paper.\n\nQuestion:\nIs there any good method to estimate U_c for a dataset? Although it is intuitive\nthat CIFAR may have a smaller U_c than MNIST, is it possible to numerically\nestimate this quantity? This is necessary to fully support the conclusions made\nin experiments.\n']","[20, 60, 80]","[60, 80, 70]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the novelty and relevance of the paper's approach, they also point out several technical issues and limitations. The overall tone suggests cautious approval with constructive criticism. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or areas for improvement rather than harsh judgments. They use phrases like 'I suggest', 'I'm not yet convinced', and 'I personally feel', which maintain a polite tone even when expressing disagreement. The reviewer also compliments aspects of the paper, such as its novelty and clear structure, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance of the paper, stating 'I will recommend the paper be accepted' and 'the paper has enough technical content to merit acceptance'. However, it's not extremely positive as the reviewer also points out missed opportunities and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I think', 'I hope', and 'I feel' soften the critique. The reviewer also encourages further discussion, which is a polite way to suggest improvements without being overly critical."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable opinion of the paper, praising its clarity, insights, and contributions. The reviewer recommends accepting the paper and uses phrases like 'well written,' 'easy to follow,' and 'good insight.' The politeness score is 70 (polite) due to the reviewer's respectful and constructive tone throughout. They offer praise where due and frame their question at the end as a suggestion for improvement rather than a criticism. The language is professional and courteous without being overly formal or effusive.""]"
"['The paper describes a new learning framework, based on generative\nadversarial imitation learning (GAIL), that is able to learn sub-tasks\npolicies from unsegmented demonstrations. In particular, it follows\nthe ideas presented in InfoGAIL, that depends on a latent variable,\nand extend them to include a sequence of latent variables representing\nthe sequence of different subtasks. The proposed approach uses a\npre-training step, based on a variational auto-encoder (VAE), to\nestimate latent variable sequences. The paper is well written and\nrelates the approach with the Options framework. It also shows,\nexperimentally, its performance against current state-of-the-art\nalgorithms.  \n\nAlthough the authors claim in the appendix that the approach is\nrelatively independent on the dimensionality of the context variable,\nthis statement needs further evidence. The approach is similar to HMMs\nwhere the number f hidden states or latent variables can make a\ndifference in the performance of the system.\n\nAlso, it seems that the learned contexts do not necessarily correspond\nto meaningful sub-tasks, as shown in the circle-world. In this sense,\nit is not only relevant to determine the ""right"" size of the context\nvariable, but also how to ensure a meaningful sub-task segmentation. \n', 'Summary:\n\nThis paper proposes an extension over the popular GAIL method for imitation learning  for the multi-modal data or tasks that have hierarchical structure in them. To achieve that the paper introduces an unsupervised variational objective by maximizing the directed mutual information between the latents c’s and the trajectories. The advantage of using directed information instead of regular MI based criterion is two-folds: 1) Being able to express the causal and temporal dependencies among the c’s changing across time. 2) Being able to learn a macro-policy without needing to condition on the future trajectories. Authors present results both on continuous and discrete environments.\n\n\nQuestions: \n1) Can you give more detailed information about the hyperparameters of your model? For example how many seeds have you used?\n2) Have you tried pre-training c_t’s as continuous latent variables?\n3) Have you tried pre-training your model as Variational RNN instead of VAE?\n4) Have you tried training your model on the pixels on the continuous control tasks?\n\nPros:\n* Although the approach bears some similarity to Info-GAIL approach. The idea of using directed information for GAIL is novel and very interesting. This approach can be in particular useful for the tasks that have \n* The paper is very well-written the goal and motivation of the paper is quite clear.\n\nCons:\n* Experiments are quite weak. Both the discrete and the continuous environment experiments are conducted on very simplistic and toyish tasks. There are much more complicated and modern continuous control environments such as control suite [1] or manipulation suite [2].  In particular tasks where there is a more clear hierarchy would be interesting to investigate.\n* Experimental results are underwhelming. For example Table 1, the results of the proposed approach is only barely better than the baseline.\n\n[1] https://github.com/deepmind/dm_control\n[2] Learning by Playing-Solving Sparse Reward Tasks from Scratch, M Riedmiller, R Hafner, T Lampe, M Neunert et al - arXiv preprint arXiv:1802.10567, 2018\n\n', ""The paper presents a learning-based method for learning the latent context codes from demonstrations along with a GAIL model. \nThis amounts to learning the option segments and the policies simultaneously. \nThe main contribution is the model the problem as a time-dependent context and then use a directed information flow loss instead of the mutual information loss.\n\n1. What is the effect of models of the underlying distribution of latent codes. \nCan it be categorical only, or can it be continuous? \nCould we also model it as multidimensional?\nThe current results only provide single dimensional categorial distribution as latent codes. \n\n2. The paper missed an important line of work which solves nearly the same problem -- option discovery and policy learning. \nKrishnan -- Discovery of Deep Option(1703.08294). This work was used by authors in continuous options and then again for program generation (https://openreview.net/pdf?id=rJl63fZRb). \n\nThey explicitly infer the option parameters, along with termination conditions with the Expectation Propagation method. \nThe results are in very similar domains hence comments, if not a comparison, would be useful. \n\n\n3. The authors state that the main problem with an InfoGail style method is dependence on the full trajectory as in eq 1. Hence the directed info flow is required to solve the problem. However in the actual model, the authors make a sequence of variational approximations -- (a) reduction of eq2 to eq1 with a variation lower bound on posterior p(c|c,\\tau) and then replace the prior p(c) with q(c|c,\\tau) in eq 5. But looking at the model diagram in fig 2. the VAE actually makes the Markovian assumption -- i.e. c only depends on c_{t-1} and s_{t}. If that is true then how would this be very different from InfoGAIL mutual information loss. \nIt appears that to capture the authors' mathematical intuition the VAE should have a recurrent generator which should have a hidden state factor passing in to capture dependence on history until the current time. \n\n3a. In fact the first term in eq 6 looks closer to the actually used model. If that is not true then the authors should clarify. \n\n4. Experiments do capture the notion discovery of options. But the simplicity of data leaves much to be desired. \nOne of the main difference of this work in comparison to unsupervised segmentation models GMM or BP-AR-HMM is the fact that the options learned are composable. But the authors only show this composability on the circle domain -- which is arguably a toy-domain. \nA reasonable confirmation that the model indeed learns composition is to generate a trajectory for a sequence of latent code not seen in data. -- like walking -- normal -- left-right-left can be converted to limping gait -- left-left-right-right. This is only a suggestive example. \n\n5. In appendix eq 8 how is the reduction from line 3 to line 4 of the equation made -- what is the implicit assumption. \njoint distribution p(c, \\tau) is written out as p (\\tau|c) p(c) without an integral.\n""]","[50, 50, -20]","[75, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with a neutral description of the paper's content, followed by positive remarks about it being 'well written' and showing good experimental performance. However, the reviewer also raises some concerns in the latter paragraphs, balancing out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. The reviewer avoids harsh criticism and instead uses phrases like 'needs further evidence' and 'it is not only relevant to determine' which suggest areas for development rather than outright criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and potential of the approach, praising the paper as well-written with clear goals. However, they also point out weaknesses in the experiments and results, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, frames criticisms constructively, and offers suggestions for improvement. They use phrases like 'Can you give more detailed information' and 'Have you tried' which are polite ways of pointing out potential improvements. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a courteous approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they raise several critical points and suggest areas for improvement. The review begins positively but quickly moves to a list of concerns and questions, indicating a somewhat skeptical stance. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'Can it be...', 'Could we also...', and 'The authors should clarify...' which are polite ways of pointing out potential issues. The reviewer also offers constructive suggestions for improvement, which contributes to the politeness of the review.""]"
"['In this work, the authors propose Switchable Normalization (SN), which *learns* to switch / select different normalization algorithms (including batch normalization (BN), Instance Normalization (IN), Layer Normalization (LN)) in layers of the networks and in different applications. The idea is motivated by observations (shown in Fig 1) that, 1) different tasks tend to have applied different normalization methods; 2) some normalization methods (e.g. BN) are fragile to very small batch size.\n\nThe authors propose a general form for different normalization methods, which is a Gaussian normalization and then scale and shift by scalars. Different normalization methods utilize different statistics as the mean and the variance of the Gaussian normalization. The authors further propose to learn the combination weights on mean and variance, which is w_k and w\'_k in Eqn (3). To avoid duplicate computation, the authors also do some careful simplification on computing mean and variance with all of the three normalization methods.\n\nIn the experiment part, the authors demonstrate the effectiveness of the proposed SN method on various kinds of tasks, including ImageNet classification, object detection and instance segmentation in COCO, semantic image parsing and video recognition. In all of the tasks tested, which also cover the common application in computer vision, SN shows superior and robust performance.\n\nPros:\n+ Neat motivation;\n+ Extensive experiments;\n+ Clear illustration;\n\nCons\n- There are still some experiment results missing, as the authors themselves mentioned in the Kinetics section (but the reviewer thinks it would be ready); \n- In Page 3 the training section and Page 4, the first paragraph, it mentioned Θ and Φ (which are the weights for different normalization methods) are jointly trained and different from the previous iterative meta-learning style method. The authors attribute ""In contrast, SN essentially prevents overfitting by choosing normalizers to improve both learning and generalization ability as discussed below"". The reviewer does not see it is well justified and the reviewer thinks optimizing them jointly could lead to instability in the training (but it did not happen in the experiments). The authors should justify the jointly training part better.\n- Page 5 the final paragraph, the reviewer does not see the point there. ""We would also like to acknowledge the contributions of previous work that explored spatial region (Ren et al., 2016) and conditional normalization (Perez et al., 2017). ""  Please make it a bit more clear how these works are related. ', 'Summary: \n(1) This paper proposes the concept of Switchable Normalization (SN), which learns a weighted combination of three popular/existing normalization techniques, Instance Normalization (IN) for channel-wise, Layer Normalization (LN) for layer-wise, and Batch Normalization (BN) for minibatch-wise.\n(2) Some interesting technical details: a) A softmax is learned to automatically determine the importance of each normalization; b) Reuse of the computation to accelerate.  c) Geometric view of different normalization methods.\n(3) Extensive experimental results to show the performance improvement. Investigation on the learned importance on different parts of networks and tasks.\n\n\nComments:\n\nThe writing of this paper is excellent, and contributions are well presented and demonstrated.\nIt is good for the community to know SN is an option to consider. Therefore, I vote to accept the paper. \n\nHowever, the proposed method itself is not significant, given many existing efforts/algorithms; it is almost straightforward to do so, without any challenges. \n\nHere is a more challenging question for the authors to consider: Given the general formulation of normalization methods in (2), it sees more interesting to directly learn the pixel set I_k. The proposed SN can be considered as a weak version to learn the pixel set: SN employs the three candidates set pre-defined by the existing methods, and learns a weighted combination over the  “template” sets. This is easy to do in practice, and it has shown promising results. A natural idea to learn more flexible pixel set, and see the advantages. Any thoughts?\n', ""This paper considers normalization by learning to average across well-known normalization techniques.\nThis meta-procedure almost by definition can yield better results, and this is demonstrated nicely by the authors.\nThe idea is simple and easy to implement, and easy works in this case.\n\nI would like to hear more about the connections to other meta-learning procedures, by expanding the discussion on page 3.\nThat discussion is very interesting but quite short, and I am afraid I can't see how SN avoids overfitting compared to other approaches. \nAlso, the section on Inference in page 4 is unclear to me. What parameters are being inferred and why is the discussion focused on convergence instead?""]","[70, 50, 70]","[80, 80, 60]","[""The sentiment score is 70 (positive) because the review starts with a detailed description of the authors' work, highlighting its strengths and innovations. The reviewer lists several pros, including 'neat motivation', 'extensive experiments', and 'clear illustration'. While there are some cons mentioned, they are presented as constructive feedback rather than major criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' contributions and framing criticisms as suggestions for improvement. Phrases like 'The authors should justify...' and 'Please make it a bit more clear...' indicate a polite tone. The reviewer also uses neutral academic language and avoids harsh or dismissive statements, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses a positive view overall, voting to accept the paper and praising the writing and presentation. However, they also note that the method itself is not significantly novel. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language, offering praise where due, and framing criticisms constructively. They use phrases like 'It is good for the community' and pose a challenging question as a suggestion rather than a demand. The review maintains a professional and courteous tone throughout."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive overview of the paper, praising the idea as simple, easy to implement, and effective. They state that the authors have demonstrated their results 'nicely'. The politeness score is 60 (polite) as the reviewer uses respectful language throughout, expressing their requests for more information as 'I would like to hear more' and 'I am afraid I can't see', which are polite ways of suggesting improvements. The reviewer also acknowledges the interesting aspects of the paper. However, the score is not higher as the review does contain some direct criticisms, albeit expressed politely.""]"
"['Overall this paper is ok. The algorithm seems novel, but is clearly very closely related to other things in the literature. The paper is also let down by poor exposition in several areas. The numerical results seem reasonably strong, at least against relatively old baselines.\n\nEquation 8 is crucial to the final algorithm, but is presented with no proof or explanation.\n\nJust above theorem 1 the sentence does not parse ""Further, for each s, let λs be the solution to "", firstly there is no \'solution\' to an equation, secondly should it be λs or pi?\n\nThe discussion following theorem 1 is very messy and hard to follow and the notation is horrendous. I\'m confused as to why the indicator function in the \'disaggregated\' update only includes states for which the constraint is already satisfied, what about the states where it is not? I presume this is because you initialize from the previous policy, but this seems very approximate and even worse updating the parameters for one state might significantly move the policy in some other state meaning large violations are possible and not dealt with.\n\nThe connections to the papers \'MAXIMUM A POSTERIORI POLICY OPTIMISATION\' and \'Relative Entropy Policy Search\' should be mentioned, as another commenter said previously.\n\nI don\'t think TRPO/PPO is SOTA anymore, so maybe these baselines aren\'t particularly interesting.\n\nFigure 2 is incomprehensible.\n\nTwo of the references are repeated (Schulman et al, Wang et al).\n\nThe appendices include long lists of equalities with no explanation (e.g. appendix B), how is a reader meant to reasonably follow those steps? Each non-trivial equality needs a sentence explaining what was used to get it.', 'The authors formulate policy optimization as a two step iterative procedure: 1) solving a constrained optimization problem in the non-parameterized policy space, 2) using supervised regression to project this onto a parameterized policy. This approach generally applies to both continuous and discrete action spaces and can handle a variety of constraints. Their primary claims is that this approach improves sample-efficiency over TRPO on Mujoco tasks and over PPO on Atari games.\n\nThe method proposed in the paper has strong similarities with existing methods, but lacks comparisons with these approaches. The authors have not clearly demonstrated that SPU provides novel insights beyond the existing literature. I\'m happy to change my score if the authors can convince me otherwise.\n\nMain comments:\n\nThe focus of the paper is sample-efficiency, but the intro restricts to the on-policy setting. The authors should justify this choice. It is well known that off-policy algorithms (e.g., SAC for continuous control and Implicit Quantile Networks for Atari) are much more sample-efficient.\n\nIn Sec 4, what is the advantage of breaking the problem up into these 3 steps versus directly trying to solve (9),(10)? In fact, if we convert (10) into a penalty and take the derivative, we arrive at nearly the same gradient as (17). As this is central to the SPU framework, this needs to be justified.\n\nMPO (Abdolmaleki et al. 2018) is very closely related to SPU. It is unclear if SPU provides any additional insights or benefits over MPO. This needs to be discussed and compared.\n\nThe experimental section could be strengthened by:\n* Given the similarity to SPU, comparisons to MPO and GAC should be made, or clear justification for why they are not comparable must be given.\n* Why is the comparison on Mujoco to TRPO in the main text and the comparison to PPO relegated to the appendix? It would make more sense to compare to PPO, so the authors need to justify this decision.\n* The results on Mujoco are quite poor compared to state-of-the-art methods (e.g., SAC). The authors should justify why we should care about their results.\n\nComments:\n\nIn Sec 2, the authors should be careful about the discounting. For example, they are almost surely not having A_{it} approximate \\gamma^t A^{\\pi_{\\theta_k}}, rather A^{\\pi_{\\theta_k}}.\n\nIn Sec 2, the KL is denoted as KL(\\pi || pi_k), but in the text is described as the KL from \\pi_k to \\pi (reversed). From the equations, it appears that is an error, and it should read KL from \\pi to \\pi_k.\n\nIn Sec 3, the description of NPG/TRPO is not accurate. The main goal of NPG/TRPO work was to establish monotonic improvement.\n\nIn Sec 3, computational speed is cited as a major deficit of GAC, especially the solving linear systems with the Hessian (wrt to the actions). This seems rather surprising. Inverting a 1000x1000 matrix on a modern computer takes <1 second, so it doesn\'t seem like this should be the limiting step for any of the problems encountered.\n\nThe KL penalty version of PPO seems closely related to SPU. Can the authors mention differences with that version of PPO in the related work?\n\nIn Sec 4, step iii is described as supervised learning. Can the authors elaborate on why? I would typically think of the other direction as supervised learning as that leads to MLE.\n\nIn Sec 5.1, what is the justification/reasoning for setting \\tilde{\\lambda_{s_i}} = \\lambda and introducing the indicator functions?\n\nSec 5.2 is not evaluated and Sec 5.3 produces inferior results, so it may make sense to move these to the appendix. Otherwise, the authors should explain situations where we would expect these to be useful or provide some additional insight. It also should be noted that the proximity constraints in TRPO/PPO follow from a theoretical argument and are not arbitrary choices.\n\nSec 5.3 seems to deviate quite a bit from the SPU framework. In addition to the differences pointed out in the text, the ""supervised"" loss changes too. Can the authors justify/explain the reasoning for these changes?\n\n=====\n\nI appreciate the authors\' efforts to improve the paper. However, there is still substantial room for improvement in writing clarity. For example, the authors optimize the reverse KL from typical supervised learning, which makes even the title of the method confusing. The method that was experimentally evaluated can be derived more simply without the two-step procedure by directly taking the gradient and add the heuristically motivated per state indicator. This in itself is interesting and the authors demonstrate that it works well experimentally. I think the paper would be substantially more useful to the community if the authors focused on that contribution alone. As it stands now, I find the paper difficult to read because most of the theoretical results have no bearing on the method.', 'The paper proposes to perform a constraint optimization of an approximation of the expected reward function for unparameterized policy with subsequent projection of the solution to the nearest parameterized one. This approach allows fast (""nearly closed form"") solutions for nonparametric policies and leads to an increase in sample efficiency.\n\nThe proposed approach is interesting and the results are promising.\n']","[-30, -60, 70]","[0, 20, 50]","[""The sentiment score is -30 because the review is generally critical, pointing out several flaws and areas for improvement. The reviewer states that the paper is 'ok' and has 'reasonably strong' numerical results, but also mentions poor exposition, confusing explanations, and outdated baselines. This mix of mild positive and more substantial negative comments suggests a slightly negative overall sentiment. The politeness score is 0 because the language is neutral and professional. The reviewer doesn't use overtly polite language, but also doesn't use rude or harsh words. They present their criticisms in a straightforward, matter-of-fact manner without personal attacks or overly negative language. The review focuses on the content and quality of the paper rather than making judgments about the authors themselves."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty, comparisons to existing methods, and overall contribution. They state the authors 'have not clearly demonstrated that SPU provides novel insights beyond the existing literature' and point out several major issues. However, they do leave room for the authors to address these concerns, indicating it's not entirely negative. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I'm happy to change my score if the authors can convince me otherwise' and 'I appreciate the authors' efforts to improve the paper,' which show respect and openness to dialogue. The reviewer also provides detailed feedback and suggestions for improvement, which is helpful and polite. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is 70 (positive) because the reviewer describes the approach as 'interesting' and the results as 'promising', indicating a favorable view of the paper. The language is generally positive without being overly enthusiastic. The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language without any negative or harsh comments. The tone is respectful and constructive, but doesn't include explicitly polite phrases or compliments beyond the positive assessment of the work.""]"
"['The paper considers invasive BMIs and studies various ways to avoid daily recalibration due to changes in the brain signals. \nWhile I like the paper and studied methods -- using adverserial domain adaptation is interesting to use in this context --, I think that the authors oversell a bit. \nThe problem of nonstationarity rsp. stability is an old one in non-invasive BCIs (shenoy et al JNE 2006 was among the first) and a large number of prior methods have been defined to robustify feature spaces, to project to stable subspaces etc. Clearly no Gans at that time. The least the authors could do is to make reference to this literature, some methods may even apply also for the invasive data of the paper.\nWhile the authors did not clearly say that they present an offline analysis; one method, the GAN, gets 6% better results then the competitors. I am not sure whether this is practically relevant in an online setting. But this needs to be clearly discussed in the paper and put into perspective  to avoid wrong impression. Only an online study would be convincing. \n\nOverall, I think the paper could be accepted, the experiments are nice, the data is interesting, if it is appropriately toned down (avoiding statements about having done something for the first time) and properly references to prior work are given. It is an interesting application domain. I additionally recommend releasing the data upon acceptance. \n\n', 'Here the authors define a BMI that uses an autoencoder -> LSTM -> EMG. The authors then address the problem of data drift in BMI and describe a number of domain adaptation algorithms from simple (CCA to more complex ADAN) to help ameliorate it. There are a lot of extremely interesting ideas in this paper, but the paper is not particularly well written, and the overall effect to me was confusion. What problem is being solved here? Are we describing using latent variables (AE approach) for BMI?  Are we discussing domain adaptation, i.e. handling the nonstationarity that so plagues BMI and array data?  Clearly the issue of stability is being addressed but how?  A number of different approaches are described from creating a pre-execution calibration routine whereby trials on the given day are used to calibrate to an already trained BMI (e.g. required for CCA) to putting data into an adversarial network trained on data from earlier days.  Are we instead attempting to show that a single BMI can be used across multiple days?\n\n\nThis paper is extremely interesting but suffers from lack of focus, rigor, and clarity.  \nFocus : \nAE to RNN to EMG is that the idea to compare vs. Domain adaptation via CCA/KLDM/ADAM.  \nOf course a paper can explore multiple ideas, but in this case the comparisons and controls for both are not adequate.\n\nRigor: \nWhat are meaningful comparisons for all for the AE and DA portions? The AE part is strongly related to either to Kao 2017 or Pandarinath 2018 but nothing like that is compared.  The domain adaptation part evokes data augmentation strategies of Sussillo 2016 but that is not compared.\n  \nIf I were reviewing this manuscript for a biological journal a rigorous standard would be online BMI results in two animals.  Is there a reason why this isn’t the standard for ICLR? Is the idea that non-biological journals / conferences are adequate to vet new ideas before really putting them to the test in a biological journal?  The manuscript is concerned with the vexing problem of BMI stability of time, which seems to be a problem where online testing in two animals would be critical. (I appreciate this is a broader topic relevant to the BMI field beyond just this paper, but it would be helpful to get some thinking on this in the rebuttal).\n\nClarity : \nThis paper needs to be pretty seriously clarified.  The mathematical notation is not adequate to the job, nor is the motivation for the varied methodology. I cannot tell if the subscript is for time or for day. Also, what is the difference between z_0 vs. Z_0? I do not know what exactly is going into the AE or the ADAN.\n\nThe neural networks are not described to a point where one could reproduce this work. The notation for handling time is inadequate.   E.g. despite repeated readings I cannot tell how time is handled in the auto-encoder, e.g. nxt is vectorized vs feeding n-sized vector one time step at a time?\n\n\nQuestions \n\nWhat is the point of the latent representation in the AE if it is just fed to an LSTM? Is it to compare to not using it? \n\nPage 3, how precisely is time handled in the AE?  If time is just vectorized, how can one get real-time readouts? In general there is not enough detail to understand what is implemented in the AE. If only one time slice is entered into AE, then it seems clear AE won’t be very good because one desires latent representation of the dynamics, not single time slices.\n\nHow big is the LSTM used to generate the EMG?\n\nIt seems like a the most relevant baseline is to compare to the data perturbation strategies in Sussillo 2016.  If you have an LSTM already up and running to predict EMG, this seems very doable.\n\nPage 4, “We then use an ADAN to align either the distribution of latent variables or the distributions of the residuals of the reconstructed neural data, the latter a proxy for the alignment of the neural latent variables.”  This sentence is not adequate to explain the concepts of the various distributions, the residuals of reconstructed neural data (where do the residuals come from?), and why is one a proxy for the other.  Please expand this sentence into a few sentences, if necessary to define these concepts for the naive reader. \n\nPage 5, What parameters are minimized in equation (2)? Please expand the top sentence of page 5.\n\nPage 6, top - “In contrast, when the EMG predictor is  trained simultaneously with the AE…” Do you mean there is again a loss function defined by both EMG prediction and AE and summed, and then backprop is used to train both in an end-to-end fashion?  Please clarify.\n\nPage 8, How do the AE results and architecture fit into the EMG reconstruction “BMI” results? Is that all decoding results are first put through the AE -> LSTM -> EMG pipeline? I.e. your BMI is neural data -> AE -> LSTM -> EMG?  If so, then how does the ADAN / CCA and KLDM fit in?  You first run those three DA algorithms and then pipe it through the BMI? \n\nPage 8, How can you say that the BMI improvement of 6% is meaningful to the BMI user if you did not test the BMI online?\n', 'This contribution describes a novel approach for implanted brain-machine interface in order to address calibration problem and covariate shift. A latent representation is extracted from SEEG signals and is the input of a LTSM trained to predict muscle activity. To mitigate the variation of neural activities across days, the authors compare a CCA approach, a Kullback-Leibler divergence minimization and a novel adversarial approach called ADAN.\n\nThe authors evaluate their approach on 16-days recording of neurons from the motor cortex of rhesus monkey, along with EMG recording of corresponding the arm and hand. The results show that the domain adaptation from the first recording is best handled with the proposed adversarial scheme. Compared to CCA-based and KL-based approaches, the ADAN scheme is able to significantly improve the EMG prediction, requiring a relatively small calibration dataset.\n\nThe individual variability in day-to-day brain signal is difficult to harness and this work offers an interesting approach to address this problem. The contributions are well described, the limitation of CCA and KL are convincing and are supported by the experimental results. The important work on the figure help to provide a good understanding of the benefit of this approach.\n\nSome parts could be improved. The results of Fig. 2B to investigate the role of latent variables extracted from the trained autoencoder are not clear, the simultaneous training could be better explained. As the authors claimed that their method allows to make an unsupervised alignment neural recording, independently of the task, an experiment on another dataset could enforce this claim.']","[50, -50, 80]","[75, 20, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the paper and its methods, calling the experiments 'nice' and the data 'interesting'. However, they also point out several areas for improvement, such as overselling and lack of references to prior work, which tempers the positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific recommendations for improvement. They use phrases like 'I think' and 'I recommend' rather than making demands, and they conclude by suggesting the paper could be accepted with revisions, which is a positive and encouraging tone."", ""The sentiment score is -50 because while the reviewer finds the paper 'extremely interesting', they express significant concerns about the paper's focus, rigor, and clarity. The reviewer states that the paper 'suffers from lack of focus, rigor, and clarity' and needs to be 'pretty seriously clarified'. These criticisms outweigh the initial positive comment, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'Please expand' and 'Please clarify' when requesting changes. They also acknowledge interesting aspects of the work. However, the directness of some criticisms prevents a higher politeness score. The reviewer balances constructive feedback with clear expression of concerns, maintaining a relatively polite but frank tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the work, describing it as 'novel', 'interesting', and offering a good approach to a difficult problem. They mention that the contributions are well-described and the limitations are convincingly addressed. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They offer constructive criticism in a gentle manner, suggesting improvements rather than harshly criticizing. The language is professional and objective, avoiding any personal attacks or overly negative phrasing. However, it doesn't go to extremes of politeness, maintaining a balanced, professional tone.""]"
"['Pros:\n- Paper proposes a somewhat complicated but easy to understand idea for open set classification. Formulation is quite intriguing.\n- Outperforming recent baselines on most scenarios, despite being a linear classifier on fixed CNN features.\n\nCons:\n- Experiment setup somewhat flawed (but the same flaw is in prior work too)\n    To elaborate: DeCAF7 is trained on ImageNet, which gives the underlying network extra categorical information of the 1000 classes. Some of these clases are arguably in the ""unknown classes"" in the open set setting. This may jeopardize the premise since the feature knows those classes are semantically different from known classes. Unfortunately (Busto & Gall, 2017) and (Saito et al., 2018) do this too.\n    This is especially problematic since DeCAF7 has a near-linear relationship to the final sigmoid logits, which are the 1000-way ImageNet class scores. This makes the authors formulation (separate subspaces for known and unknown classes) more easily exploit this leaked information. This is because the 1000-way scores obviously have subspaces for all 1000 ImageNet classes, and by extension, the ""known"" and ""unknown"" classes in the open set setting. \n    If this is true and is the main reason that the proposed method outperforms, I would not consider the conclusion of the paper very informative. Instead, its signifies the need of a better experiment setup for the problem.\n    A way to strengthen the paper is to use a network pre-trained on other datasets (e.g. Places, or a subset of ImageNet) to verify the findings of the paper.\n- Lacks clarity for what is being done at test time. \n    I cannot find whether the final SVM is trained on original DeCAF features, or S and T. If it is the latter, how are the representations of target domain data obtained at test time? Are they d dimentional or 2d dimentional?\n    Can you clarify that the test samples are not used for unsupervised training?\n- Experiment elaborate but feels incomplete.\n    It feels like the authors are proposing 3 variations of the method, and there is not one of them that consistently outperform the others. If so, the paper would lack some ablation analysis that provides insights of what makes the FRODA-SVM outperform prior art. For example, how much do the hyperparameters matter? What happens if e.g. d or lambda1 is very large/small?\n\nClarity:\n- Abstract spends too much time on defining problem setup\n- ""Faster than prior work"" refers to the training time, and excludes the DeCAF feature extraction.\n\nOriginality:\nI am not familiar with the related work.\n\nSignificance:\nIt is quite impressive that a linear model on fixed CNN activations outperforms prior art. However, see the first point in the cons.\n\n\n-----------\nEdit: most of the issues listed in ""cons"" are addressed. Although the additional experiments are not very comprehensive, they can better support the claims. I am bumping up the rating to 7.\n', 'The paper addresses the problem of Domain Adaptation (DA) in an open setting (OSDA): while traditional DA assumes that the set of classes of the source and the target are identical, in Open-set DA, there are samples in the target which do not belong to any class in the source (unknown classes that I will outliers in this review). The main difficulty of Open-set DA is to simultaneously discard outliers and correctly classify other samples in the target. There are only two papers on Open-set DA so far, Busto\'17 and Saito\'18.\nThe method proposed by the authors can be summarized in a single equation, eq. 2, where they aim at learning a linear mapping to a latent space, which can be separated into two sub-spaces U (private space) and V (shared space) such that target outliers will be mapped to 0 in V while source and target non-outliers will be mapped to 0 in U, and hence separate outliers with non-outliers. To solve eq. 2, the authors convert it to Eqs. 3, 4, and 5 and apply techniques in Lee\'07 and Mairal\'14. The authors propose an extension for learning a linear classifier simultaneously and an extension for incorporating also unknown source classes (i.e. source outliers) when appropriate. An experimental evaluation on 2 datasets show the good performance of the method.\n\nPros:\n-A novel method for a rather new and understudied so far, the work is then interesting for this setting\n-Good results reported\n\nCons:\n-The criterion used for choosing when examples are outliers seems heuristic, more discussion would be welcomed as well as some qualitative analysis for showing the interest of the method\n-Existing baseline of Saito\'18 not used in the 1st experiment\n-Some parts require more justification\n\n*Comments:\n\n-The idea of the method is similar to the one of Jia\'10 (Eq.6) for multi view learning, but this is rather new for Open-set DA.\n\n-In order to separate target samples to either private or shared, the authors ""encourage that either of these two parts (i.e. vectors T_i^u and T_i^v) goes to zero for each sample"", which is reasonable. To achieve this the authors use sparse coding method coming from Lee\'07. However, this does not make sense to me, because the sparse coding algorithm will encourage both T_i^u and T_i^v to be sparse, but nothing forces one of them to go to the zero-vector.\nThe authors should then better justify this choice. In particular, I wonder if adding explicitly the criterion used for identifying outliers as a new constraint to satisfy. Then, the optimization problem considered would make more sense to me.\n\nAnyway, the authors could perform additional experiments to show the effectiveness of their method: (i) apply on a classic DA problem where we will expect that ||T^u|| or ||U|| (private subspace for outliers) should be close to zero. \nAdd a qualitative analysis on the values of  |T^u|| and |T^v|| - both in Open-set DA and classic DA - showing that the results are as expected. \n\n- The 1st method (Eq.2) learns the latent space without using any label in the source (i.e there are only two labels: outlier or non-outlier, and all source samples are labeled non-outlier). Thus, the authors resort to the assumption that outliers are farther from source samples than non-outliers. This assumption is strong and may not hold in practice for two reasons: (1) the domain shift can be large and (2) without clustering techniques, many outliers can easily fall into the safe non-outliers zone (consider 0-4 for outliers and 5-9 for non-outliers, high chance this method will incorrectly classify 0 or 3 as non-outliers since 6,8,9 are already non-outliers). \n\n- The Lagrange dual method (Lee\'07, Eq. 6) solves an optimization problem with multiple quadratic constraints, i.e. ||U_j||^2 \\le c for every j. However, the authors apply it to solve a problem (eq. 3 and 4) with a single linear constraint which is not quadratic: \\sum ||U_j|| \\le 1. Please explain:\n(i) Why do you use that constrain instead of the one in Lee\'07?\n(ii) With your constrain, does the Lagrange dual method still work? \n\n-The authors mention that they reported the results reported by Busto\'17 in their experiment. Does this mean that the experiments were not reproduced? If so this seems rather unfair for other baselines since they may have worked on different instances. \nMany baselines are not specific to Open-set DA, so it is rather expected to see bad results.\nSince OSDA is new, it is true that there exists only two true baselines: Busto\'17 and Saito\'18. However, Saito\'18 does not appear in BCIS benchmark (although appears in Office benchmark). Please add Saito\'18 to the BCIS benchmark.\n\n-The authors use fixed parameters for all the subproblems, I am a bit surprised by this choice, I would rather expect a parameterization task-dependent. Does this mean that the method is hard to tune ?\n\n-The method seems complex, is there any convergence guarantee?\n\n--\nAfter rebuttal: thanks many points were answered.', 'This paper tackles the problem of open-set unsupervised domain adaptation with a method based on \nsubspace learning. Specifically the proposed approach searches for two low-dimensional spaces, one shared \nby the known source and target categories while the other is specific for the unknown classes. \n\nOverall the paper is well organized and easy to read. The mathematical formulation of the method is sound and\nclearly explained in all its variants.\n\nI have few concerns \n- it would be good to have the ""average"" columns in the tables reporting the experimental results. This will help to have an overall idea on the performance of the different proposed and baseline methods.\n- it is not clear whether the authors are reporting the results of AODA from the original paper or if they re-ran the code to get the recognition accuracies. For instance in table 3 the result 70.1 for A->W is lower than those reported in the original paper for this setting.\n- the paper does not discuss how the hyperparameters of the methods are chosen. Only an analysis on epsilon is provided. It would be very helpful to understand the procedure used to select the values of alpha, beta and lambda and to evaluate the robustness of the method to those parameters. Moreover,  the value of the dimensionality d is not explicitly indicated in the text. This should be added together with a discussion about if and how the subspace disagreement measure (that was introduced for closed set domain adaptation) is reliable in the open set condition.\n\n\n\n\n']","[50, 20, 60]","[60, 60, 80]","[""The sentiment score is 50 (slightly positive) because the review begins with pros, acknowledging the paper's intriguing formulation and good performance. However, it also lists several significant cons, including flaws in the experimental setup and lack of clarity in some areas. The final edit indicates that most issues were addressed, leading to an improved rating. The politeness score is 60 (moderately polite) because the reviewer uses professional language throughout, offers constructive criticism, and provides specific suggestions for improvement. The reviewer acknowledges both strengths and weaknesses of the paper without using harsh or dismissive language. The use of phrases like 'somewhat flawed' and 'feels incomplete' softens the criticism, while still conveying the concerns clearly."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and good results of the paper, calling it 'interesting' and noting its 'good performance'. However, they also raise several concerns and request additional justifications, tempering the overall positivity. The politeness score is moderately high (60) as the reviewer uses professional language throughout, frames criticisms constructively as suggestions for improvement, and acknowledges the authors' responses positively at the end. They use phrases like 'more discussion would be welcomed' and 'please explain' rather than making blunt demands. The reviewer also balances critiques with positive observations, maintaining a respectful tone."", ""The sentiment score is 60 (positive) because the reviewer starts with a neutral description of the paper's topic, then provides positive feedback, stating the paper is 'well organized and easy to read' and the mathematical formulation is 'sound and clearly explained'. The concerns raised are presented as suggestions for improvement rather than critical flaws. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their concerns as suggestions ('it would be good to have', 'it would be very helpful') rather than demands. The reviewer also acknowledges the paper's strengths before presenting areas for improvement, which is a polite approach to feedback.""]"
"[""The paper presents an approach for simultaneously learning policies and reward functions for reaching goals that are described by an instruction providing spatial relations among objects. The proposed platform, called Adversarial Goal-Induced Learning from Examples (AGILE), is composed of an off-the-shelf RL module like A3C and a separate module for learning a reward function, implemented using the NMN paradigm. The RL module is trained using the reward function learned by the reward module. The reward module is trained to map a given <instruction, state> into a score between 0 and 1 depending on how well the provided state satisfies the instructions provided in the instruction. The returned score is used as a reward function. The training of the reward function is performed by using a dataset of positive examples, and using the states visited by the agent while it's learning as negative examples. To account for the fact that the agent becomes better over time and its visited states can no longer be used as negative examples, the authors proposed a heuristic where the states visited by the agent are not all used as negative examples, but only those that have the lowest scores.\nThe paper also presents an empirical evaluation of the proposed approach on a synthetic task where the agent is tasked with move bocks of different shapes and colors to a desired final configuration. The AGILE approach was compared to the baseline A3C algorithm where a sparse binary reward signal was used only whenever the agent reaches the goal state. AGILE is also compared to A3C with an auxiliary task of reward prediction. \nThe paper is clearly written and technically strong. However, I have two issues with this paper: 1) the proposed approach is a simple combination of A3C and the NMN architecture, 2) the experiments are performed on simple synthetic tasks that make learning spatial relations fairly easy, I would love to see more real images as it has been demonstrated in prior works on learning  spatial relations. It is not clear from these experiments if the proposed approach will scale up to higher-dimensional inputs. Moreover, there are several stability issues that can be caused by the proposed approach. For instance, the reward function is changing over time, how does that affect the learning rate? Also, instead of using the learned policy itself to generate negative examples and run into non IID data, instabilities, and increasingly good negative examples, why not use a fixed dataset of negative examples generated with a random policy? It would be interesting to do perform an experiment where you compare to the classical reward learning setup where you simply provided labeled positive and negative examples and classify them offline, then use the learned reward function online for RL. \nHow did you tune the hyper-parameter \\rho (percentage of negative examples to discard) for specific tasks? Do you have any guarantees for this approach?\nIn the generalization experiments, it is mentioned that 10% of the instructions are held out. Are these 10% randomized?"", '\n==========\nUpdate\n==========\n\nUpon reviewing the paper revision and the author comments to my and the other reviewers\' comments, I will revise my suggestion to that of acceptance. As I said in my summary, my primary concern was novelty with respect to prior work which the authors have clarified. They have also increased the rigor of their experimental results by providing variances in the plots.\nI think this work will be of interest to the community.\n\n\n==========\nStrengths:\n==========\n\n- The problem of learning to predict state rewards given language in interesting and useful. \n\n- The proposed AGILE framework is intuitively simple and works with any existing RL framework.\n\n- With the models and tasks explored in this paper, the approach does seem to learn to evaluate whether a state matches the instructions quite well. \n\n- The writing is very clear and direct. \n\n==========\nConcerns:\n==========\n\n[A] The discussion of differences to the closely related GAIL methodology is left until the related work after experiments. Given the similarities between GAIL and AGILE, this seems too late. The authors list three major differences between AGILE and GAIL:\n\t\n1) AGILE is conditioned on a goal specification, language in this case. GAIL is unconditioned and trained for one task.\n2) AGILE takes only the final/goal state rather than a trajectory like in GAIL.\n3) AGILE discretizes the discriminator probability when assigning reward, GAIL does not.\n\nSome concerns about each:\n\t\t\n1) This is an interesting and fair difference but also a necessary and somewhat obvious modification to GAIL in tasks with explicit goal-specification. \n\n2) This does not seem like an improvement, but rather a loss of generality. The authors justify this change saying ""in AGILE the reward model observes only states s_i (either goal states from an expert, or states from the agent acting on the environment) rather than traces (s1, a1),(s2, a2), . . ., learning to reward the agent based on “what” needs to be done rather than according to “how” it must be done."" \n\nIn many real applications, the how is deeply important. For instance, navigation in the world is both a ""what"" (arrive at location X) and a ""how"" (in fastest time without hitting anything or in such a way that humans aren\'t frightened). Further, the trace includes the final state such that the ""what"" is recoverable in instances where the ""how"" is unimportant, as in the set of tasks presented in this paper. \n\n3) Letting the paper speak on this subject: ""We considered this change of objective necessary because the GAIL-style reward would take arbitrarily low values for intermediate states visited by the agent, as the reward model will be confident as those are not goal states. The binary reward in AGILE carries a clear message to the policy that all non-goal states are equally undesirable."" Firstly, all non-goal states are not equally undesirable in that some lead more easily to goal states though it is fair to argue this should be learned by the policy through expected reward. My primary gripe is the footnote following these sentences which says: ""We tried values other than 0.5 for the binarization threshold, as well as not binarizing and using Dφ(c, st) directly as the reward. We got similar but slightly worse results."" This seems to imply that this difference does not matter significantly, especially if different thresholds received significantly different hyperparameter tuning effort or were not conducted under multiple runs of random seeds.\n\nA pessimistic summary would place AGILE to be a conditional GAIL with reduced ability to represent intermediate or trajectory based rewards and a possibly slightly helpful reward discretization scheme. Don\'t get me wrong, I think an conditional extension to GAIL is interesting and worth sharing with the community. However, this discussion comes very late and includes a design decisions (2/3) that I find poorly justified in text and completely unjustified experimentally. \n\nI would like to hear from the authors if any of these criticisms are inaccurate. I would also welcome experiments evaluating the effect of these design decisions.\n\n[B] In 3.2 its reported that each experiment was repeated five times however the presented results are not described as means and no variances are shown. I would like to see the results plots with shaded variances from at least 5 runs with differing random seeds. \n\n[C] Unless I\'m mistaken, the proposed architecture could also be trained with reward prediction. It would be interested in that case to see if improvement seen between A3C and A3C-AGILE extend to A3C-RP and A3C-RP-AGILE. As the authors note, the AGILE framework simply changes the source of the reward and is amicable to any RL approach. I would like to see this comparison.\n\n[D] The reward generalization experiments seemed surprising to me. The policy was fine-tuned on the test environments but only improved from 52% to 69.3%. Trying to think about this more, I\'m having trouble disentangling whether this implies poor generalization of the reward function or increased difficulty in policy learning. Could the authors provide the A3C and A3C-RP baselines for this experiment to help clarify?\n\n[E] Just a Curiosity: What exactly is done in L2 weight clipping? (Training details in supplement)\n\n[F] Just a Thought: In the reward-prediction (RP) setting, both the RP model and the policy share parameters. It would be possible with such an architecture to still apply the AGILE loss and I would be curious to see if this leads to interesting changes in performance. I understand that one of the advantages to learning a separate reward model is to generalize to new policies, but it is unclear if this approach would generalize less well (and finding it out would be cool!)\n\n==========\nOverview:\n==========\n\nI think extending generative adversarial imitation learning to a task-conditional setting a cool step made even more interesting in this work by having the task-specification be in compositional language. Further, the results and analysis are generally interesting though I do note some weaknesses above. Aside from some questions about the experiments, I\'m mostly concerned about the positioning of the paper -- specifically with respect to prior work.  I\'m looking forward to hearing from the authors and other reviewers. \n\n\n', 'The previous version of the paper was not clear enough in the motivation and uniqueness of the work. After a long and devoted discussion with the authors, we agreed on certain ways of improving the paper presentation, including connection to some related work. \n\nThe current paper is much better, so I would like to raise my score to 6. My revised review is: \n\n[orginality and significance]\n\n+ The paper deals with a challenging navigation problem where natural language instructions can be underspecified and the environment is complex---thus a correct reward function being extremely hard to craft. \n+ The paper proposed to use a <instruction, state> discriminator D to compute a pseudo reward at each step, which is then used to reinforce an agent in natural-language-guided navigation task. The paper proposed to train the discriminator in an adversarial way---with expert supervised data. The idea is neat, and its effectiveness is empirically supported by extensive experimental results.  \n\n[clarity]\n\n+ The paper is well-written. The method is introduced with clear textual description, rigorous math formulations, and good illustration (Figure-1 and -2). The experiments are also well-documented, including training and testing details, results and analysis.   \n\n[quality]\n\n+ The paper was not clear at certain points but the authors had helpful discussions with me and the paper was revised accordingly. \n+ The experiments were done with multiple random seeds, so I believe the results are convincing. The authors did not only show the numerical results but also shared qualitative videos through anonymous URL.  Overall, it is a good paper.\n\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nBelow is my original review\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n[PROS]\n\n[originality and significance]\n\nThe paper proposed to use a <instruction, state> discriminator D to compute the reward at each step, which is then used to reinforce an agent in natural-language-guided navigation task. The paper proposed to train the discriminator in adversarial way. The idea is neat, and its effectiveness is empirically supported by extensive experimental results.  \n\n[clarity]\n\nThe paper is well-written. The method is introduced with clear textual description, rigorous math formulations, and good illustration (Figure-1). The experiments are also well-documented, including training and testing details, results and analysis. The experiments were done with multiple random seeds, so I believe the results are convincing. The authors did not only show the numerical results but also shared qualitative videos through anonymous URL.  Overall, it is a good paper.  \n\n[CONS]\n\n[quality]\n\nThe major issue of this paper is the lack of connection to existing related work in the field of dealing with reward sparsity problem. This is a long-standing problem in RL (very common in, but not only restricted to, navigation tasks) and people have proposed reward shaping techniques to handle it. But the paper did not discuss any work in this direction. For references, please first check this seminal work and then follow the line of research: \n\nNg, Andrew Y and Harada, Daishi and Russell, Stuart, ICML 1999, Policy invariance under reward transformations: Theory and application to reward shaping\n\nThe method proposed in this paper seems a way of automatically shaping the reward, but loses the optimal policy invariance (for how this invariance is ensured in reward shaping, please check out this tutorial: http://www-users.cs.york.ac.uk/~devlin/presentations/pbrs-tut.pdf). \n\nThe proposed method has two key components: 1) the discriminator D; and 2) the adversarial training. The method is shown effective in experiments and outperforms appropriate baselines with actual reward. But the design of D and how it is used as reward function seems somewhat ad-hoc. \n\nD is only trained on the final states of episodes (please correct me if I am wrong), but is used at all the steps as part of reward function to determine the stepwise reward, which seems odd. The authors should discuss what (implicit) assumptions they are relying upon to make this method work in this way. The transformation function from D to reward value seems ad-hoc---e.g. why 0.5, why indicator function instead of others (e.g. scaling of indicator function), how it is generalized to non-1/0 (but still sparse) reward cases, etc? Is the method only designed for 1/0-reward cases? The authors should clearly specify if it is the case. \n\nMoreover, the paper compared to RP (Jaderberg 2016), which still reinforces the agent with actual reward but only *shapes the features of the agent* by multi-tasking on predicting the reward of next step (please correct me if this is wrong). Interestingly, the RP method achieves better performance than the proposed method, although it does not address the reward sparsity problem. Could the authors provide any insight about why this happened? Is there any trade-off between these two methods? Is there any setting, in the authors’ opinion, where the proposed method should outperform RP? \n\n[SUMMARY]\n\nI think this is good work---neat idea, nice results and clear writing. But there are indeed some issues that I hope the authors could address. So I gave a score of 5. \n']","[-20, 50, 70]","[60, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'clearly written and technically strong', they express two main issues with the paper: 1) the approach is described as a 'simple combination' of existing methods, and 2) the experiments are performed on 'simple synthetic tasks' that may not scale to more complex scenarios. The reviewer also raises several questions and concerns about the methodology and stability of the approach.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They begin by summarizing the paper's content objectively, use phrases like 'I would love to see' when suggesting improvements, and frame their criticisms as questions or areas for potential improvement rather than direct attacks. The tone is constructive and aimed at improving the paper rather than dismissing it outright."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by revising their recommendation to acceptance, stating the work will be of interest to the community. They also note several strengths of the paper. However, they also raise multiple concerns and request clarifications, balancing out the positive aspects. The politeness score is 80 because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as requests for clarification or further information rather than direct attacks. They use phrases like 'I would like to hear from the authors' and 'I would welcome experiments', which maintain a collegial tone. The reviewer also admits when a criticism might be due to their own misunderstanding, further demonstrating politeness."", ""The sentiment score is 70 because the reviewer expresses a clearly positive view of the revised paper, raising their score to 6 and noting significant improvements. They highlight several strengths of the paper, including its originality, clarity, and quality of experiments. The politeness score is 80 because the reviewer uses respectful and constructive language throughout, acknowledging the authors' efforts to improve the paper and providing detailed, helpful feedback. They balance praise with suggestions for further improvement in a professional manner, avoiding harsh criticism or dismissive language.""]"
"['This manuscript introduces a computational method to speed up training and inference in deep neural networks: the method is based on dynamic pruning of the compute graph at each iteration of the SGD to approximate computations with a sparse graph. To select which neurons can be zeros and ignored at a given iteration, the approach computes approximate activations using random projections. The approach gives an overall decrease in run-time of 0.8 to 0.6. I believe that its largest drawback is that it does not lead to the same sparsity pattern in a full minibatch, and hence cannot be implemented using matrix-matrix multiplications (GEMM). As a result, the compute-time speed ups are not huge, though the decrease in memory is important. In my eyes, this is the largest drawback of the manuscript: the total computational speed-up demonstrated is not fully convincing.\n\nThe manuscript is overall well written and easy to understand, though I wish that the authors employed less acronyms which forced me to scan back as I kept forgetting what they mean.\n\nThe strength of the paper are that the solution proposed (dynamic approximation) is original and sensible. The limitations are that I am not sure that it can give significant speedups because I it is probably hard to implement to use well the hardware.\n\nQuestions and comments:\n\n1. Can the strategy contributed be implemented efficiently on GPUs? It would have been nice to have access to some code.\n\n2. Fig 8(b) is the most important figure, as it gives the overall convergence time. Is the ""dense baseline"" using matrix-vector operations (VMM) or mini-batched matrix-matrix operation (GEMM)?\n\n3. Can the method be adapted to chose a joint sparsity across a mini-batch? This would probably mean worst approximation properties but would enable the use of matrix-matrix operations.\n\n4. It is disappointing that figure 8 is only on VGG8, rather than across multiple architectures.\n\n5. The strategy of zeroing inputs of layers can easily create variance that slows down overall convergence (see Mensh TSP 2018 for an analysis of such scenario). In stochastic optimization, there a various techniques to recover fast convergence. Do the authors think that such scenario is at play here, and that similar variance-reduction methods could bring benefits?\n\n6. I could not find what results backed the numbers in the conclusion: 2.3 speed up for training. Is this compared to VMM implementations? In which case it is not a good baseline. Is this for one iteration? In which case, it is not what matters at the end.\n\n7. Is there a link between drop-out and the contributed method, for instance if the sparsity was chosen fully random? Can the contributed method have a regularizing effect?\n\n', ""REVISED: I am fine accepting. The authors did make it a bit easier to read (although it is still very dense). I am also satisfied with related work and comparisons\nSummary: \nThis paper proposes to activate only a small number of neurons during both training and inference time, in order to speed up training and decrease the memory footprint. This works by constructing dynamic sparse graph for each input, which in turn decides which neurons would be used. This happens at each iteration and it does not permanently remove the neurons or weights. To construct this dynamic sparse graph, authors use dimensionality reduction search which estimates the importance of neurons\n\nClarity:\nOverall I found it very hard to follow. Lots of accronyms, the important parts are skipped (the algorithm is in appendix) and it is very dense and a lot of things are covered very shallowly. It would have been better for clarity to describe the algorithm in more details, instead of just one paragraph, and save space by removing other parts.  I would not be able to implement the proposed solution by just reading the paper\n\nDetailed comments.\nThis reminds me a lot of a some sort of supervised dropout. \n\nMy main concern, apart from clarity, is that there is no experimental comparison with any other method. How does it compare with other methods of dnn compression or acceleration?\n\nAlso i found the literature review is somewhat lacking. What about methods that induce sparsity via the regularization, or those that use saliency criterion, hessian based approaches like Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for efficient neural network. NIPS, 2015. , pruning filters Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for, efficient convnets. ICLR, 2017.  etc. \nBasically i don't understand how it compares to alternative methods at all.\n\nQuestions:\nHow does it run during inference? does inference stay deterministic (there is a random projection step there)\n"", '[Overview]\n\nIn this paper, the authors proposed to use dynamic sparse computation graph for reducing the computation memory and time cost in deep neural network (DNN). This method is applicable in both DNN training and inference. Unlike most of previous work that focusing on the reduction of computation during the inference time, this new method propose a dynamic computation graph by pruning the activations on the fly during the training of inference, which is an interesting and novel exploration. In the experiments, the authors performed extensive experiments to demonstrate the effectiveness of the proposed method compared with several baseline methods and original models. It is clear to me that this method helps to reduce the memory cost and computation cost for both DNN training and inference.\n\n\n[Strengthes]\n\n1. This paper addresses the computational burden in both memory and time from a novel angle than previous network pruning methods. It can be applied to reduce the computation in both network training and inference, but also preserve the representation ability of the network.\n\n2. To endow the network compression in training and inference, the authors proposed to mute the low-activated neurons so that the computations merely happened on those selected neurons. \n\n3. For the selection, the authors proposed a simple but efficient dimension reduction methods, random sparse projection, to project the original activations and weights into a lower-dimensional space and compute the approximated response map in such a lower dimension space, which the selection is based on.\n\n4. The authors performed comprehensive experiments to demonstrate the effectiveness the proposed method for network compression. Those results are insightful and solid.\n\n[Questions]\n\n1. Is the sparsity of each layer the same across the whole network? It would be nice if the authors could perform some ablation studies on varied sparsity in different layers, maybe just with some heuristic methods, e.g., decreasing the sparsity from lower layer to upper layers. As the authors mentioned, higher sparsity causes a larger degradation on deeper network. I am curious that whether there are some better way to set the sparsity.\n\n2. During the training of the network, how the activation evolve? It would be interesting to show how the selected activation changes across the training time for the same training sample.  This might provide some insights on when the activations begin to converge to a stable state, and how it varies layer by layer. \n\n3. Following the above questions, is there any stage that the sparsity can be fixed without further computation for selection. In generally, the training proceeds for a number of epochs. It would be nice if we can observe some convergence on the selected activations and then we can suspend the selection for saving the computation burden.\n\n[Conclusion]\n\nThis paper present an interesting and novel approach for network pruning in both training and inference. Unlike most of the previous work, it pruning the activations in each layer though a dimension reduction strategy. From the experiments, this method achieved an obvious improvement for reducing the computation memory and time cost in training and inference stages. I think this paper has prompted a new direction of efficient deep neural network.\n']","[-20, 50, 80]","[60, 20, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper ('original and sensible' solution), they express significant concerns about the method's effectiveness and the lack of convincing speed-up results. The reviewer states that the 'total computational speed-up demonstrated is not fully convincing' and mentions several limitations and drawbacks. However, the tone is not entirely negative, as they also note positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I believe' and 'In my eyes' to soften criticisms, and frame their concerns as questions or suggestions rather than harsh critiques. The reviewer also acknowledges the paper's strengths and the overall good writing quality. The use of 'I wish' instead of a more direct criticism about acronyms also contributes to the polite tone. While not overly effusive, the language is consistently courteous and constructive."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating they are 'fine accepting' the paper and acknowledges improvements made by the authors. However, they also express concerns about clarity and lack of comparisons, which tempers the positivity. The politeness score is 20 (slightly polite) as the reviewer uses generally neutral language but includes some polite phrases like 'I am fine accepting' and 'I am also satisfied with'. The reviewer provides constructive criticism without harsh language, but also doesn't use overtly polite phrasing throughout. The review maintains a professional tone while expressing both positive and negative points."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, highlighting its novelty, effectiveness, and comprehensive experiments. They use phrases like 'interesting and novel exploration', 'insightful and solid results', and state that the paper 'prompted a new direction of efficient deep neural network'. The few questions raised are constructive and aimed at further improvement rather than criticism. The politeness score is 90 (very polite) due to the consistently respectful and professional tone throughout the review. The reviewer uses phrases like 'It would be nice if...', 'I am curious...', and 'It would be interesting...', which are polite ways of suggesting improvements or asking questions. The review also acknowledges the authors' efforts and achievements multiple times, demonstrating respect for their work.""]"
"['This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. \'18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. \n\nResults are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where ""humans"" were asked to pick more interpretable models. \n\nThe paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns:\n\n1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice.\n\n2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the ""agglomeratively grouped CD scores of individual features"" are the same as the ""CD scores for the groups/interactions of features"" in terms of their contribution to the final prediction.\n\n3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task).\n\n4). The paper talks several times about diagnosing why a model went wrong e.g. the ""negation"" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? \n\n', '**Summary**\n\nIn this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs. They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction. \n\n**Strength**\n\n1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations.\n2. Experiments are elaborate and cover the breadth of the proposed method well.\n3. The paper is well presented and fairly easy to follow. \n\n\n**Weakness**\n\n1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/abs/1801.05453).\n2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.\n', 'This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study\n\nQuality, \nThe paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, \n\nClarity, \nThe main methodological contribution (hierarchical CD) is well motivated but only  provided in the form of an algorithm. Could have been more precisely described and optimality discussed. \n\nOriginality & significance\nThe work builds heavily on CD but has the hierarchical extension is original and significant. \nUncertainty estimates could have improved the significance of the usability study\n\npros and cons\n+ interesting problem\n+ well-motivated algorithmic extension of CD\n- uncertainty of usability experiment?\n']","[20, 20, 60]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths ('nicely written', 'puts itself nicely in context', 'experimental gains are nice'), they also express several significant concerns. The overall tone suggests cautious approval with substantial room for improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting concerns, and phrases criticisms as suggestions or questions rather than direct attacks. They use phrases like 'It would have been nice' and 'I am unsure' which maintain a polite tone while expressing concerns."", ""The sentiment score is slightly positive (20) because the review acknowledges some strengths of the paper, such as the neat approach, elaborate experiments, and good presentation. However, it also points out significant weaknesses, particularly the limited novelty. The overall tone suggests cautious approval rather than strong enthusiasm. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits before discussing its weaknesses. The reviewer avoids harsh criticism and uses neutral phrasing like 'It seems that' when pointing out issues, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the review generally expresses a favorable view of the paper, noting it is 'well motivated' and has an 'original and significant' extension. The reviewer acknowledges the paper's strengths in multiple areas, though they do point out some areas for improvement. The politeness score is 50 (somewhat polite) as the reviewer uses neutral, professional language throughout. They balance positive feedback with constructive criticism, using phrases like 'could have been' rather than more direct criticisms. The reviewer also highlights both pros and cons, showing a balanced and respectful approach to the review.""]"
"['The authors focus on the selection problem of k statistically significant features discriminating 2 probability distributions accessible via samples. They propose a non-parametric approach under the PSI (post selection inference) umbrella using MMD (maximum mean discrepancy) as a discrepancy measure between probability distributions. The idea is to apply (asymptotically) normal MMD estimators, rephrase the top-k selection problem as a linear constraint, and reduce the problem to Lee et al., 2016. The efficiency of the approach is illustrated on toy examples and in GAN (generative adversarial network) context. The technique complements the PSI-based independence testing approach recently proposed by Yamada et al., 2018. \n\nThe submission is a well-organized, clearly written, nice contribution; it can be relevant to the machine learning community.\n\nBelow I enlist a few suggestions to improve the manuscript:\n-Section 1: The notion of characteristic kernel (kernel when MMD is metric) has not been defined, but it was referred to. \'Due to the mean embeddings in RKHS, all moment information is stored.\': This sentence is somewhat vague.\n-Section 1: \'MMD can be computed in closed form\'. This is rarely the case (except for e.g. Gaussian distributions with Gaussian or polynomial kernels). I assume that the authors wanted refer to the estimation of MMD.\n-Section 1: \'K nearest neighbor approaches (Poczos & Schneider, 2011)\'. The citation to this specific estimator can go under alpha-divergences. The Wasserstein metric could also be mentioned.\n-Section 3.1: k is used to denote the number of selected features and also the kernel used in MMD. I suggest using different notations.\n-Theorem 1: \'\\Phi is the CDF...\'. There is no \\Phi in the theorem.\n-Section 3.2: The existence of MMD (mean embedding) requires certain assumptions: E_{x\\sim p}\\sqrt{k(x,x)} < \\infty, E_{x\\sim q}\\sqrt{k(x,x)} < \\infty.\n-Section 3.2.: block estimator: \'B_1 and B_2 are finite\'. \'fixed\'?\n-Section 3.2.: MMD_{inc}: \n   i) \'S_{n,k}\': k looks superfluous.\n   ii) \'l\': it has not been introduced (cardinality of D).\n-Section 3.3: typo: \'covraiance\' (2x)\n-Section 3.3: Fan et al. 2013: The citation can go to \\citep{}.  \n-Theorem 2: \n   i)\'c\' is left undefined.\n   ii)Comma is missing before \'where\'.\n   iii)\\xrightarrow{d} (Theorem 2, Corollary 3-4): Given that \'d\' also denotes dimension in the submission, I suggest using a different notation for convergence in distribution.\n-At the introduction of block-MMD the block size (B) was fixed, while in the experiments (e.g. Figure 3) it is growing with the sample size (B=\\sqrt{n}). The assumption on B should be clearly stated.\n-Section 5.1: (b) mean shift: comma is missing before \'where\'.\n-References: \n   i) Abbreviations and names in the titles should be capitalized (such as cramer, wasserstein, hilbert-schmidt, gan, nash). \n   ii) Scholkopf should be Sch\\{""o}lkopf (in the ALT 2005 work).\n   iii) \'Exact post-selection inference, with application to the lasso\': All the authors are listed; \'et al.\' is not needed.', 'The paper propose a method for post feature selection inference in the case where the distribution is non-Gaussian. The paper developed a statistic called incomplete mmd and showed its asymptotic normal property. Then the incomplete mmd can be plugged into post feature selection framework for computing the p-value. \n\nThe paper is a nice combination of incomplete mmd and post selection inference technique. \nHowever, the combination is straightforward: the asymptotic Gaussian property of the incomplete mmd is the key. \n\nFurthermore, I think the applications (feature selection and test for GAN objective) is not exciting from the machine learning point of view. A better application which can show-case the obtained p-value is very useful will make the paper more interesting. ', 'The paper proposes a new post selection inference for MMD statistics, i.e., identity the p-values for the dimensions of vector. I believe this is an important problem that has not been addressed in previous literature. The work provides an extension to the original post selection inference work for lasso (Lee et al. 2016). \n\nHowever, I wish the paper could have explained the main idea clearly. Right now it is hard to me to judge whether or not the proposed estimator is correct (the only place that seems to support this is Fig. 4(a). Where the p-value seems to be clear to a uniform distribution. \n\nFor instance, the proposed PSI estimator, we will need to estimate the covariance matrix. This was explained in Section 3.3, and it was said that the algorithm in Fan et al. (2013) was used for the explanation. However, I think more detailed discussions and explanation should be provided here. In order to obtain correct p-value estimate, I believe getting accurate covariance matrix estimate is crucial. How large the sample size is needed, in order for us to get an accurate enough covariance matrix, to perform sub-sequent post selection inference? More discussions are needed here. ']","[80, 20, 20]","[90, 50, 50]","[""The sentiment score is 80 (positive) because the reviewer describes the submission as a 'well-organized, clearly written, nice contribution' that 'can be relevant to the machine learning community'. This indicates a strong positive sentiment towards the paper. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, framing their suggestions as 'improvements' rather than criticisms. They use phrases like 'I suggest' and 'Below I enlist a few suggestions', which are polite ways of offering feedback. The reviewer also acknowledges the authors' work positively before providing detailed suggestions. The high scores are not 100 because there is still room for even more positive sentiment or politeness, but the review is overwhelmingly positive and courteous."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as a 'nice combination' of techniques and praises the asymptotic Gaussian property as the key. However, they also express that the combination is 'straightforward' and the applications are 'not exciting', which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits while offering constructive criticism. They avoid harsh language and frame their suggestions as ways to make the paper 'more interesting' rather than criticizing its current state outright."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the importance and novelty of the work in the first paragraph, but expresses concerns about clarity and methodology in the subsequent paragraphs. The positive aspects are balanced by the criticisms, resulting in a mildly positive overall sentiment. The politeness score is 50 (moderately polite) because the reviewer uses respectful language throughout, such as 'I believe' and 'I wish', and frames criticisms as suggestions for improvement rather than direct attacks. The reviewer maintains a professional tone while providing constructive feedback, avoiding harsh or rude language.""]"
"[""The paper introduces an adaptation of the Scattering transform to signals defined on graphs\nby relying on multi-scale diffusion wavelets, and studies a notion of stability of this representation\nwith respect to changes in the graph structure with an appropriate diffusion metric.\n\nThe notion of stability in convolutional networks is an important one, and the proposed notion of stability\nwith respect to diffusion distances seems like an interesting and relevant way to extend this to signals on graphs.\nWith this goal in mind, the authors introduce a scattering transform on graphs by relying on diffusion wavelets,\nand provide an appropriate study of stability, which seems to highlight relevant properties of the graphs.\nThe proposed representation seems to provide benefits compared to the previous work of Zou & Lerman,\nparticularly regarding computational efficiency, as well as stability with respect to a metric that is perhaps more\nuseful, though there is a dependence on the graph topology through the spectral gaps.\nIn addition, the experiments on author attribution and source localization suggest that the\nresulting representation remains discriminative, in addition to providing stability to changes in graph structure.\n\nI find that these contributions provide an interesting advance in theoretical understanding of graph convolutional networks\nfrom a stability perspective, in addition to introducing a useful non-learned representation,\nand am thus in favor of acceptance.\n\nNevertheless, some parts of paper would benefit from further discussions and more clarity:\n\n- other than empirically, one aspect that's missing compared to the original study of the scattering transform is energy preservation. The authors could at least provide a discussion of whether such a property can be obtained here as well (does it depend on the spectral gap through C(beta)?)\n\n- what is the role of the spectral gap in the stability bounds? is this a drawback of the diffusion metric / choice of wavelets?\n\n- Section 3.2 suggests that metric stability is a good way to characterize stability, by seeing deformations in Euclidian domains as a change to the ground metric. Yet, in Euclidian scattering, the same representation is applied to a deformed signal and the original signal, and stability is measured with the Euclidian metric.\nCan the link be made more precise, by explaining what a deformation of a signal would be on a graph, or by applying arguments from the proposed construction to the Euclidian case?\n\n- the paper is heavy on terminology from wavelets and harmonic analysis, a more detailed presentation of diffusion wavelets and related concepts such as localization would be beneficial. Also, it seems like the chosen wavelets in the construction favor spatial over frequential localization - is this due to a trade-off? if so, can it be avoided?\n\n\nSome more detailed comments:\n- Section 2, 'generally far weaker': what is meant by 'weaker'?\n- Section 3.3:\n  * 'calculus on T': T is used before being defined\n  * clarify what norm is used (I assume operator norm?)\n  * 'defines a distance', 'stronger than .. GH': this should probably be justified\n- Section 4:\n  * 'optimal spatial localization', 'temporal difference', 'favoring spatial over frequential localization': these could be clarified\n  * 'amplify the signal': what does this mean?\n  * the sentence about the choice of the appropriate J is not clear and should be further clarified\n- Section 5.1:\n  * the sentence about the choice pi/pi* = 1 should be clarified. Also, where is this assumption used?\n  * epsilon_psi, epsilon_U should be defined\n  * 'given that [..] by definition': this doesn't seem to be defined elsewhere\n  * (16): isn't a factor m missing in the first term?"", ""The paper presents in interesting and new analysis of stability of scattering transforms on graphs, when the domain (graph) is perturbed by deformations. It combines key ingredients of scattering transforms (extended here to graphs through graph diffusion wavelets), deformation of graphs (based on graph diffusion distances) and a theoretical stability analysis. Similarly to the Euclidian domain, it is shown that linear filters cannot provide representations that are simultaneously rich and stable. \n\nGenerally, the paper is pretty complete, interesting and sufficiently well presented. One might wonder if the choice of the diffusion framework for both the representation construction, and the deformation analysis, is a simplistic choice, and how similar ideas could extend to different domain deformation for example. The experiments and comparisons are also very minimal, and hard to interpret. Comparing things only with GFT and SVM is probability a 'easy' choice, with the advent of a plethora of new graph convnets architectures (GFT is probably not a 'graph baseline', as mentioned in the conclusion). \n\nThis is however an interesting work, that will likely generate exciting discussions at ICLR. "", 'The paper introduces scattering transforms on graphs by adopting diffusion wavelet constructions, and gives an extension of the scattering transforms to non-Euclidean domains. The main result consists of a stability analysis of the non-adaptive representation under deformation of the underlying graph metric, also defined in terms of graph diffusion.\n\nPros: \n\nThe study addresses the important problem of representation stability of non-Euclidean CNNs, which is a timely topic. The theoretical analysis builds an interesting connection between the diffusion graph geometry and the analysis of deep networks.\n\nCons: \n\n- It is unclear what type of graph is the primary consideration, either (a) expander/small-world with large spectral gap, e.g. social network, or (b) irregular mesh embedded in a Euclidean space or on an intrinsic manifold - as originally considered in diffusion wavelet, and in the Euclidean CNN/scattering transform theory - which often fails to present a spectral gap. The formula suggests (b) while the analysis and experiments point to (a). A coverage of both cases is unlikely. \n\n- The deformation considered is proposed in terms of the graph metric perturbation, which appears to lack sufficient motivation. This is not apparent from the experimental results (How is the x-axis of plots in Figure 1 related to ""perturbation""?). Will such deformation reduce to that as being considered for irregular meshes in computer vision applications e.g. in [1]? The proposed model would be more convincing if the class of ""covered deformations"" can be clarified and the relevance to practices of non-Euclidean CNNs can be better addressed.\n\n- The experimental section lacks performance and comparison in a controlled environment, e.g., on synthetic data with more samples to show statistical significance. There also appears to be a gap between theory and experiment: can the dependence on spectral gap be empirically supported, even only qualitatively, e.g., by a comparison on small world graph v.s. others?\n\nOverall, the recommendation is still in favor of acceptance. Finally, the reviewer would like to raise the following questions:\n\n- As the result is presented as an extension of the Euclidean scattering transform, will the stability result recover the traditional one in Mallat et al. when the underlying graph is a regular grid (though the definition of deformation differs in appearance)?\n\n- What about the computational efficiency, scalability and storage cost of the algorithm? It would also clarify the computational procedure by providing an algorithm box or release of code. However, assuming that the focus of the paper is on theory, computation is a relatively minor point.\n\n[1] Boscaini, D., Masci, J., Rodolà, E., & Bronstein, M. (2016). Learning shape correspondence with anisotropic convolutional neural networks. In Advances in Neural Information Processing Systems (pp. 3189-3197).\n']","[70, 60, 20]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer expresses strong support for the paper's acceptance, praising its 'interesting advance' and 'useful non-learned representation'. The reviewer is 'in favor of acceptance' and finds the contributions valuable. However, it's not a perfect 100 as the reviewer does suggest areas for improvement and clarification. The politeness score is 80 (very polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'would benefit from' and 'could be clarified' when suggesting improvements, rather than using harsh or demanding language. The critique is presented as helpful suggestions rather than criticisms. The reviewer also acknowledges the paper's strengths before diving into areas for improvement, which is a polite approach to feedback."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting and new', 'pretty complete', and likely to generate 'exciting discussions'. They acknowledge the paper's contributions and novelty. However, it's not extremely positive due to some criticisms about minimal experiments and comparisons. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. Phrases like 'One might wonder' and 'This is however an interesting work' soften the critique. The reviewer maintains a professional and courteous tone without being overly deferential."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance and timeliness of the topic, and recommends acceptance despite some concerns. The review begins with pros and ends with a recommendation for acceptance, which indicates a generally positive view. However, the reviewer also lists several significant cons and questions, which tempers the positivity.\n\nThe politeness score is moderately high (60) because the reviewer uses professional and respectful language throughout. They present their critiques as 'cons' rather than direct criticisms, and phrase their concerns as questions or suggestions for improvement. The reviewer also acknowledges the paper's strengths and uses phrases like 'interesting connection' and 'the reviewer would like to raise the following questions', which maintain a courteous tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional, slightly formal tone.""]"
"['The authors suggest and analyse two types of preconditioners for optimization, a Newton type and a Fisher type preconditioner.\n\nThe paper is well written, the analysis is clear and the significance is arguably given. The authors run their optimizers on a synthetic benchmark data set and on imagenet.\nThe originality is not so high as the this line of research exists for long. \nThe ""Lie"" in the title is (technically correct, but) a bit misleading, as only matrix groups were used.\n', 'This paper proposes a preconditioned SGD method where the preconditioner is adapted by performing some type of gradient descent on some secondary objective ""c"".  The preconditioner lives in one of a restricted class of invertible matrices (e.g. symmetric, diagonal, Kronecker-factored) constituting a Lie group (which is where the title comes from). \n\nI think the idea of designing a preconditioner based on considerations of gradient noise and as well as the Hessian is interesting. However most of that work was done in the Li paper, and including the design of ""c"".  This paper\'s contribution seems to be to work out some of the details for various restricted classes of matrices, to construct a ""Fisher version"" of c, and to run some experiments. \n\nThe problem is that I don\'t really buy the original motivation for the ""c"" function from the Li paper, and the newer Fisher version of c proposed in this paper doesn\'t seem to have any justification at all.  I also find that the paper in general doesn\'t do a good job of explaining its various choices when designing the algorithm.  This could be somewhat forgiven if the experimental results were strong, but unfortunately they are too limited, and marred by overly-simplistic baselines that aren\'t properly tuned.\n\n\nMore detailed comments below\n\nTitle:\n\nI think the title is poorly chosen.  The paper doesn\'t use Lie groups or their properties in any significant way, and ""learning"" is a bad choice of words too, since it involves generalization etc (it\'s not merely the optimization of some function).  A better title would be ""A general framework for adaptive preconditioners"" or something.\n\nIntro:\n\nCitation of Adagrad paper is broken\n\nThe literature review contained in the intro needs works. I wouldn\'t call methods like quasi-Newton methods ""convex optimization methods"".  Those algorithms were around a long time ago before ""convex optimization"" was a specific topic of study and are probably *less* associated with the convex optimization literature than, say, Adagrad is. And methods like Adagrad aren\'t exactly first-order methods either. They use adaptively chosen preconditioners (that happen to be diagonal) which puts them in a similar category to methods like LBFGS, KFAC, etc.\n\nIt\'s not clear at this point in the paper what it means for a preconditioner to be ""learned on"" something.  \n\nSection 2:\n\nThe way you discuss quadratic approximations is confusing.  Especially  the sentence ""is the sum of approximation error and constant term independent of theta"" where you then go on to say that a_z does depend on theta.  I know that this second theta is the ""current theta"" separate from the theta as it appears in the formula for the approximation but this is really sloppy. Usually people construct the quadratic approximation in terms of the *change in theta* which makes such things cleaner.\n\nYou should explain how eqn 8 was derived since it\'s so crucial to everything that follows.  Citing a previous paper with no further explanation really isn\'t good enough here.  Surely with all of the notation you have already set up it should be possible to motivate this criterion somehow. The simple fact that it recovers P = H^-1 in the noiseless quadratic case isn\'t really good enough, since many possible criteria would do the same.\n\nI\'ve skimmed the paper you cited and their justification for this criterion isn\'t very convincing.  There are other possible criteria that they give and there doesn\'t seem to be a strong reason to prefer one over the other.\n\n\nSection 3:\n\nThe way you define the Fisher information matrix corresponds to the ""empirical Fisher"", since z includes the training labels.  This is different from the standard Fisher information matrix.\n\nHow can you motivate doing the ""replacement"" that you do to generate eqn 12? Replacing delta theta with v is just notation, but how can you justify replacement of delta g with g + lambda v?  This isn\'t a reasonable approximation in any sense that I can discern. Once again this is an absolutely crucial step that comes out of nowhere.  Honestly it feels contrived in order to produce a connection to popular methods like Adam.\n\nSection 4: \n\nThe prominent use of the abstract mathematical term ""Lie group"" feels unnecessary and like mathematical name-dropping. Why not just talk about certain ""classes"" of invertible matrices closed under standard operations (which would also help people that don\'t know what a Lie group is)?  If you are going to invoke some abstract mathematical framework like Lie groups it needs to actually help you do something you couldn\'t otherwise. You need to use some kind of advanced Theorem for Lie groups. \n\nWithout knowing the general form of R equation 18 is basically vacuous. *any* matrix (in the same class) could be written this way.\n\nI\'ve never heard of the natural gradient being defined using a different metric than the Fisher metric.  If the metric can be arbitrary then even standard gradient descent is a ""natural gradient"" too (taking the Euclidean metric).  You could argue for a generalized definition that would include only parametrization independent metrics, but then your particular metric wouldn\'t obviously work.\n\n\nSection 6:\n\nRather than comparing to Batch Normalization you would be better off comparing to the old centering and normalization work of Schraudolph et al which the former was based on, which is actually a well-defined preconditioner.\n\nSection 7: \n\nYou really need to sweep over the learning rate parameters for optimizers like SGD with momentum or Adam.   Otherwise the comparisons aren\'t very interesting. \n\n""Tikhonov regularization"" should just be called L2-regularization\n\n', 'Author proposes general framework to use gradient descent to learn a preconditioner related to inverse of the Hessian, or the inverse of Fisher Information matrix, where the inverse may take a particular form, ie, Kronecker-factored form like in KFAC. I have tracked down the implementation of this method by author from earlier paper Li 2018 and verified that it works and speeds up convergence of convolutional networks in terms of number of iterations needed. In particular, Kronecker Factored preconditioner using approach in the paper worked better in terms of wall-clock time on MNIST LeNet5, comparing against an existing PyTorch implementation of KFAC from César Laurent.\n\n\nSome comments on the paper:\n\nSection 2\nThe key seems to be equation 8. The author provides loss function, the minimum is what is achieved by inverse of the Hessian. Given the importance of the formula, it feels like proof should be included (perhaps in Appendix).\n\nJustification of the criterion is relegated to earlier work in Li (https://arxiv.org/pdf/1512.04202.pdf), but I failed to fully grasp the motivation. There are simpler criteria being introduced, such as criterion 1, equation 17, which simply minimizes the difference between predicted gradient delta and observed, why not use that criterion?\n\nThe justification is given that using inverse Hessian may ""amplify noise"", which I don\'t buy. When using SGD to solve least-square regression, dividing by Hessian does not have a problem of amplifying noise, so why is this a concern here?\n\n\nSection 3\n\nThe paper should make it clear that empirical Fisher matrix is used, unlike ""unbiased estimate of true Fisher"" which used in many natural gradient papers.\n\nSection 4\nIs ""Lie group"" used anywhere in the derivations? It seems the same algebra holds even without that assumption. The motivation for using ""natural gradient for learning Q"" seems to come from Amari. I have not read that paper, how important it is to use the ""natural"" gradient for learning Q? What if we use regular gradient descent for Q?\n\nSection 7\nFigure 1 showed that Fisher-type criterion didn\'t work for toy problem, it would be more informative if it used square root of Fisher-type criterion. The square root comes out of regret-analysis (ie, AdaGrad uses square root of gradient covariance)\n']","[50, -60, 20]","[20, -20, 60]","[""The sentiment score is 50 (slightly positive) because the review starts with positive aspects, noting that the paper is well-written, the analysis is clear, and the significance is 'arguably given'. However, it also mentions that the originality is not high and the title is somewhat misleading, which tempers the positivity. The politeness score is 20 (slightly polite) because the language is professional and constructive, without harsh criticism. The reviewer offers balanced feedback, acknowledging both strengths and weaknesses. The use of 'arguably' and 'a bit misleading' softens potential criticism. However, the review doesn't go out of its way to be overtly polite or encouraging, maintaining a mostly neutral, professional tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses skepticism about the paper's contributions, motivation, and experimental results. They state that they 'don't really buy the original motivation' and find that the paper 'doesn't do a good job of explaining its various choices'. The experimental results are described as 'too limited' and 'marred by overly-simplistic baselines'. However, the score is not at the extreme negative end because the reviewer does acknowledge some interesting aspects, such as 'the idea of designing a preconditioner based on considerations of gradient noise and as well as the Hessian'.\n\nThe politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism and dismissive language. Phrases like 'I don't really buy', 'This could be somewhat forgiven if', and 'Honestly it feels contrived' come across as somewhat impolite. The reviewer also uses terms like 'sloppy' and 'mathematical name-dropping' which can be perceived as slightly rude. However, the review is not extremely impolite, as it does provide detailed feedback and suggestions for improvement, which is constructive."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the author's work, verifies its effectiveness, and provides constructive feedback. However, there are several critiques and questions raised, which prevent a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, avoids harsh criticism, and frames most comments as suggestions or questions rather than direct criticisms. The reviewer also acknowledges the author's previous work and its effectiveness. The language is professional and academic, without any rude or confrontational elements, but also not overly deferential or excessively polite.""]"
"[""This paper proposes a method for stereo reconstruction using Deep Learning. Like some previous methods, a 'cost volume' is first computed by plane sweeping, in other words the cost volume is indexed by the 2D locations in the image plane, and the disparities for 3D planes parallel to the image plane. A network then predicts the disparities for each image location from this cost volume.\n\nThe contributions with respect to the state-of-the-art are:\n\n- the cost volume is computed using differential warps, thus the network can be trained end-to-end;\n\n- a better cost volume is computed from the original cost volume and the reference image.\n\nThe results look good, both quantitatively and qualitatively. The paper reads well, and related work is correctly referenced.\n\nThere is nothing wrong with the proposed method, it makes sense and I am convinced it works well. However, I found the contributions quite straightforward, and it is difficult to get excited about the paper.\n\nMore details would be welcome for Section 3.2"", 'Summary\nThis paper proposes an end-to-end learnable  multiview stereo depth estimation network, which is basically very similar to the GCNet (Kendall et.al 2017) or PSMNet (Chang et.al 2018) for stereo estimation. The differences are using SPN to warp feature w.r.t RT, adding a multi view averaging cost and a cost aggregation component for final depth regression, which transform the original network to support multi-view stereo, yielding performance boost over other baselines.\n\nTechnically, I believe it is sound  because cost volume from stereo matching has already been demonstrate very effective in boosting performance because it use underlining geometry constraint.  My major concern lies in three aspects. \n\n1) Another most recent SOTA algorithm is  MVSNet (Yao et.al ECCV 2018), the paper should be considered for comparison. In addition, the structure is even more similar with the proposed network architecture.  \n\n2) The evaluation metrics are mostly use for single view depths, it is not consistent with paper of DeepMVS (Tab. 1) or that from MVSNet. Therefore, it might be hard to actual understand whether the numbers are  exactly comparable. \n\n3) Since the method largely improved over their baseline algorithms, and the number between different papers are hard to compare. In my opinion, to better show the results,  I suggest submitting results to an online benchmark with test data for verifying the results. such as ETH3D multi view benchmark, where everything is standardized. \n\nI hope the author can make strong feedback for validating the results. \n\n####### . After rebuttal\n\nThe author makes more clear indication of the performance contribution of the completeness of recovery.', ""The paper describes a method for learning a deep neural network for multi-view stereo. The overall network includes feature-extraction layers applied to all images, followed by a spatial-transformer network (which is differentiable, but with no learnable parameters) that is applied to warp these features from every matching image to the reference image's co-ordinate frame for a series of candidate depth planes, followed by concatenation of the reference and match image features and 3D convolution layers to form a cost volume. The cost volumes of different pairs are averaged, and additional layers are used to refine this cost volume while relying on the reference image's RGB features, followed by soft-max and an expectation over depth values to output the final depth at each pixel. The entire network is trained end-to-end and experiments show that it outperforms state-of-the-art methods for MVS by a significant margin on a number of datasets.\n\nOverall, I have a positive view of the paper and believe it should be accepted to ICLR. However, I would like the authors to address the following issues:\n\n- While the proposed network is complex, I do believe the description of the architecture could be a little better. It would be good to clarify that i indexes view (and N is the total number of views), and provide a few more definitions for the terms in equation (2): namely, are R and t the extrinsics of the reference camera or the i^th camera, etc. The overall approach is clear (for each plane, the method maps features from the paired camera to the reference camera  assuming all points in the the world lie on that plane), but it would be good to clarify the specifics. It might also be useful to emphasize that the cost-volume generation is per-pair (perhaps change the title of Sec 3.2) and that these volumes are averaged for all pairs.\n\n- It might also be useful to apply the algorithm to the rectified binocular stereo case (where the warping and definition of planes by disparity are much simpler), and show comparisons to the many stereo algorithms on datasets like KITTI. At some level, the proposed algorithm can be thought of taking approaches proved to be successful for rectified binocular stereo and generalizing them (by generic warping + plane sweep) to the multi-view case. Hence, such comparisons could be illuminating. (Note: the method doesn't need to outperform the state-of-the-art there, but the results would be informative).\n\n- I do believe the paper would significantly benefit from more discussion of DeepMVS since it's clearly the closest to this method (also solves MVS by deep networks + plane sweep). DeepMVS also learns the matching cost for cost volume generation, and the major difference seems to be that this method is learned end-to-end. It would be better to have a more detailed discussion of the differences (the current discussion at the end of Sec 2 is a little short on details)---architectures, super-vision at the end of the cost-volume vs end-to-end, etc.\n""]","[20, -20, 70]","[60, 50, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good results, readability, and correct referencing. However, they also express a lack of excitement about the contributions, describing them as 'straightforward'. This mixed feedback results in a mildly positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They avoid harsh language, using phrases like 'There is nothing wrong with the proposed method' and 'More details would be welcome' instead of direct criticism. The tone is professional and courteous, even when expressing reservations about the paper's novelty."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is technically sound, they express several major concerns and suggest significant additional work. The reviewer states 'My major concern lies in three aspects' and requests 'strong feedback for validating the results', indicating skepticism about the current state of the work. However, the tone is not entirely negative, as the reviewer believes the approach is 'sound' and acknowledges its performance improvements. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, such as 'I hope the author can...' and 'I suggest...', rather than making demands. The reviewer also acknowledges the paper's strengths alongside the criticisms. The language is professional and constructive, offering specific suggestions for improvement rather than harsh criticism."", ""The sentiment score is 70 (positive) because the reviewer starts with 'Overall, I have a positive view of the paper and believe it should be accepted to ICLR.' This indicates a generally favorable opinion. However, it's not 100 as the reviewer does have some issues they want addressed. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, such as 'I would like the authors to address' and 'It would be good to clarify.' They offer constructive criticism and suggestions rather than harsh critiques. The reviewer maintains a professional and courteous tone while providing detailed feedback, which is indicative of a polite academic review.""]"
"['The authors introduce a continuous relaxation for categorical variables so as to utilize the gradient descent to optimize the connection weights and the network architecture. It is a cool idea and I enjoyed the paper. \n\nOne question, which I think is relevant in practice, is the initialization of the architecture parameters. I might be just missing, but I couldn\'t find description of the initial parameter values. As it is gradient based, it might be sensitive to the initial value of alpha. \n\nIn (5), the subscript for alpha should be removed as it defines a function of alpha. I think (5) is misleading as it is because of k-1. (and remove one ""the"" in ""minimize the the validation"" in the sentence above (5))', 'This paper proposes a novel way to formulate neural architecture search as a differentiable problem.\nIt uses the idea of weight sharing introduced in previous papers (convolutional neural fabrics, ENAS, and Bender et al\'s one shot model) and combines this with a relaxation of discrete choices between k operators into k continuous weights. Then, it uses methods based on hyperparameter gradient search methods to optimize in this space and in the end removes the relaxation by dropping weak connections and selecting the single choice of the k options with the highest weight. This leads to an efficient solution for architecture search. Overall, this is a very interesting paper that has already created quite a buzz due to the simplicity of the methods and the strong results. It is a huge plus that there is code with the paper! This will dramatically increase the paper\'s impact. \nIn my first read through, I thought this might be a candidate for an award paper, but the more time I spent with it the more issues I found. I still think the paper should be accepted, but I do have several points of criticism / questions I detail below, and to which I would appreciate a response.\n\nSome criticisms / questions:\n\n1. The last step of how to move from the one-shot model to a single model is in a sense the most interesting aspect of this work, but also the one that leaves the most questions open: Why does this work? Are there cases where we lose arbitrarily badly by rounding the solution to the closest discrete value or is the performance loss bounded? How would other ways of moving from the relaxation to a discrete choice work? I don\'t expect the paper to answer all of these questions, but it would be useful if the authors acknowledge that this is a critical part of the work that deserves further study. Any insights from other approaches the authors may have tried before the mechanism in Section 2.4 would also be useful.\n\n2. The related work is missing several papers, namely the entire category of work on using network morphisms to speed up the optimization process, Bender et al\'s one shot model, and several early papers on neural architecture search (work on NAS did not only start in 2017 but goes back to work in the 1990s on neuroevolution that is very similar to the evolution approach by Real). This is a useful survey useful for further references: https://arxiv.org/abs/1808.05377\n\n3. I find a few of the claims to be a bit too strong. In the introduction, the paper claims to outperform ENAS, but really the paper doesn\'t give a head-to-head comparison. In the experiments, ENAS is faster and gives slightly worse results. The authors state explicitly that their method is slower because they run it 4 times and pick the best result. One could obviously also do that with ENAS, and since ENAS is 8 times faster one could even run it 8 times! This is unfair and should be fixed. I don\'t really care even if it turns out that ENAS performs a bit better with the same budget, but comparisons should be fair and on even ground in order to help our science advance -- something that is far too often ignored in the ML literature in order to obtain a table with bold numbers in one\'s own row.\nLikewise, why is ENAS missing in the Figure 3 plots for CIFAR, and why is its performance not plotted over time like that of DARTS?\n\n4. The paper is not really forthcoming about clearly stating the time required to obtain the results:\n- On CIFAR, there are 4 DARTS run of 1 day each\n- Then, the result of each of these is evaluated for 100 epochs (which is only stated in the caption of Figure 3) to pick the best. Each of these validation runs takes 4 hours (which, again, one has to be inferred from the fact that random search can do 24 such evaluations in 4 GPU days), so this step takes another 16 GPU hours.\n- Then, one needs to train the final network for 600 epochs; this is a larger network, so this should take another 2-3 GPU days.\nSo, overall, to obtain the result on CIFAR-10 requires about one GPU week. That\'s still cheap, but it\'s a different story than 1 day.\nLikewise, DARTS is *not* able to obtain 55.7 perplexity on PTB in 6 hours with 4 GPUs; again, there is the selection step (probably another 4*6 hours?) and I think training the final model takes about 2 GPU days. These numbers should be stated prominently next to the stated ""search times"" to not mislead the reader.\n\n5. One big question I have is where the hyperparameters come from, for both the training pipeline and the final evaluation pipeline (which actually differ a lot!).\nFor example, here are the hyperparameters for CIFAR, in this format: training pipeline value -> final evaluation pipeline value:\n#cells: 8 -> 20\nbatch size: 64 -> 96\ninitial channels: 16 -> 36\n#epochs: 50 -> 600\ndroppath: no -> yes (with probability 0.2)\nauxiliary head: no -> yes (with weight 0.4)\nBatchNorm: enabled (no learnable parameters) -> enabled\n\nThe situation is similar for PTB:\nembedding size: 300 -> 850\nhidden units per RNN layer: 300 -> 850\n#epochs: 500 -> 8000\nbatch size: 256 (SGD) -> 64 (ASGD), sped up by starting with SGD\nweight decay: 5e-7 -> 8e-7\nBatchNorm: enabled (no learnable parameters) -> disabled\n\nThe fact that there are so many differences in the pipelines is disconcerting, since it looks like a lot of manual work is required to get these right. Now you need to tune hyperparameters for both the training and the final evaluation pipeline? If you have to tune them for the final evaluation pipeline, then you can\'t capitalize at all on the fact that DARTS is fast, since hyperparameter optimization on the full final evaluation pipeline will be order of magnitudes more expensive than running DARTS.\n\n6. How was the final evaluation pipeline chosen? Before running DARTS the first time, or was it chosen to be tuned for architectures found by DARTS?\n\n7. A question about how the best of 4 DARTS runs is selected, and how the best of the 24 random samples in random search is evaluated: is this based on 100 epochs using the *training* procedure or the *final evaluation* procedure? Seeing how different the hyperparameters are above, this should be stated.\n\n8. A few questions to the authors related to the above: how did you choose the hyperparameters of DARTS? The DARTS learning rate for PTB is 10 times higher than for CIFAR-10, and the momentum also differs a lot (0.9 vs. 0.5). Did you ever consider different hyperparameters for DARTS? If so, how did you decide on the ones used? Is it sensitive to the choice of hyperparameters? In the author response period, could you please report the  \n(1) result of running DARTS on PTB using the same DARTS hyperparameters as used for CIFAR-10 (learning rate 3*e-4 and momentum (0.5,0.999)) and\n(2) result of running DARTS on CIFAR-10 using the same DARTS hyperparameters as used for PTB (learning rate 3*e-3 and momentum (0.9,0.999))?\n\n9. DARTS is being critizized in https://openreview.net/pdf?id=rylqooRqK7#page=10&zoom=180,-16,84\nI am wondering whether the authors have a reply to this.\nThe algorithm for solving the relaxed problem is also not mathematically derived from the optimization problem to be solved (equations 3,4), but it is more a heuristic. A derivation, or at least a clearer motivation for the algorithm would be useful.\n\n10. Further comments:\n- Equation 1: This looks like a typo, shouldn\'t this be x(j) = \\sum_{i<j} o(i,j) x(i) ? Even if the authors wanted to use the non-intuitive way of edges going from j to i, then o(i,j) should still be o(j,i).\n- Just above Equation 5: ""the the""\n- Equation 5: I would have found it more intuitive had \\alpha_{k-1} already just been a generic \\alpha here.\n- It would be nice if the authors gave the explicit equations for the extension with momentum in the appendix for completeness.\n- The authors should include citations for techniques such as batch normalization, Adam, and cosine annealing.\n\n\nDespite these issues (which I hope the authors will address in the author response and the final version), as stated above, I\'m arguing for accepting the paper, due to the simplicity of the method combined with its very promising results and the direct availability of code.', '(Disclaimers: I am not not active in the sub-field, just generally interested in the topic, it is easy however to find this paper in the wild and references to it, so I accidentally found out the name of the authors, but had not heard about them before reviewing this, so I do not think this biased my review).\n\nDARTS, the algorithm described in this paper, is part of the one-shot family of architecture search algorithms. In practice this means training an over-parameterized architecture is, of which the architectures being searched for are sub-graphs. Once this bigger network is trained it is pruned into the desired sub-graph. DARTS has ""indicator"" weights that indicate how active components are during training, and then alternatively trains these weights (using the validation sets), and all other weights (using the training set). Those indicators are then chosen to select the final sub-graph.\n\nMore detailed comments:\n\nIt seems that the justification of equations (3) and (4) is not immediately obvious, in particular, from an abstract point of view, splitting the weights into w, and \\eta to perform the bi-level optimizations appears somewhat arbitrary. It almost looks like optimizing the second over the validation could be interpreted as some form of regularization. Is there a stronger motivation than that is similar to more classical model/architecture selection?\n\nThere are some papers that seem to be pretty relevant and are worth looking at and that are not in the references:\n\nhttp://proceedings.mlr.press/v80/bender18a.html \nhttps://openreview.net/forum?id=HylVB3AqYm (under parallel review at ICLR, WARNIGN TO REVIEWERS: contains references to a non anonymized version of this paper )\n\nI think architecture pruning literature is relevant too, it would be nice to discuss the connection between NAS and this sub-field, as I think there are very strong similarity between the two.\n\nPros:\n* available source code\n* good experimental results\n* easy to read\n* interesting idea of encoding how active the various possible operations are with special weights\n\nCons\n* tested on a limited amount of settings, for something that claims that helps to automate the creation of architecture, in particular it was tested on two data set on which they train DARTS models, which they then show to transfer to two other data sets, respectively\n* shared with most NAS papers: does not really find novel architectures in a broad sense, instead only looks for variations of a fairly limited class of architectures\n* theoretically not very strong, the derivation of the bi-level optimization is interesting, but I believe it is not that clear why iterating between test and validation set is the right thing to do, although admittedly it leads to good results in the settings tested\n']","[80, 50, 20]","[70, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses enjoyment of the paper and describes the idea as 'cool'. They provide constructive feedback and questions, indicating overall positive engagement. The politeness score is 70 (polite) due to the respectful tone throughout. The reviewer uses phrases like 'I enjoyed the paper' and 'I might be just missing', showing consideration. They offer suggestions and point out errors in a neutral, non-confrontational manner. The scores are not 100 as there is room for even more enthusiasm or explicit politeness, but the review is clearly positive and courteous."", ""The sentiment score is 50 (slightly positive) because while the reviewer expresses interest in the paper and recommends acceptance, they also list numerous criticisms and questions. The initial praise is balanced by detailed concerns, indicating a mixed but overall positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I would appreciate a response' and 'It would be useful if the authors...' which maintain a courteous tone even when expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as 'good experimental results', 'easy to read', and 'interesting idea'. However, they also point out several limitations and areas for improvement, balancing the overall sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions rather than harsh criticisms. They also acknowledge their own potential biases and limitations. The reviewer maintains a professional tone while providing both positive feedback and areas for improvement, which contributes to the polite nature of the review.""]"
"['Summary:\nThe authors present a novel adversarial attack scheme where a neural net is repurposed or ""reprogrammed"" to accomplish a different task than it the one it was originally trained on. This reprogramming from task1 to task2  is done through a given image from task2 additively enhanced with an adversarial program which is trained given the knowledge of the models parameters. A mapping from the repurposed output from task1 to relevant output for taks2 is also necessary (h_g function).\n\nReview:\nThis approach seems quite novel as it enables the repurposing of ImageNet classifiers to be used for counting dots in images, MNIST and CIFAR10 classifications. This new type of ""adversarial attack"" by repurposing a model shows surprising efficacy at allowing an attacked models to change its task at hand. Some tasks being more difficult (CIFAR10) than MNIST or counting dots.\n\nThe paper is well-written and explains clearly the proposed technique. The proposed technique is simple in its formulation.\nThe assumption it is based on (access to model parameters) is acceptable for the sake of proof of concept.\nOverall it is an interesting paper to read and seems of significance for the community working on adversarial attacks.\n\nFew comments/questions come to mind though:\n- The adversarial images are quite different from a common image as they embed the program around the new task images. This makes the technique itself quite susceptible to detection (just look at the statistics of the input images).\n- How do you handle front end processing? Usually for ImageNet classification, a system will (for instance) resize its input to 256x256, center crop to 224x224 and renormalize the RGB features to match the statistics from the training data. It looks like the images generated are passed as inputs to the system. Do you assume that the front-end steps are not applied or do you assume it is (by including them in the network while training your program W).  My assumption is that you include those steps in the training network for W.\n- The size of the program is disproportionately big compare to the task2 embedded image. This begs the question: what happens when you limit the size of the program to a smaller percentage of the whole image? When do you see a break in the reprogramming? Do you need that much extra programming W in your adversarial images?\n- As the adversarial images seem to be quite easy to detect, would it be easy to integrate it into some task1 images? The equation (2) gives X_{adv} = \\tilda{X} + P, could you use X_{adv} + w * X_{task1}, basically finding a way to hide the program and task2 image within a task1 image. This seems difficult, but have you thought of such approach?\n\nOverall this is a paper that is a pleasant read and should be considered for publication.\n\nPost Rebuttal: The draft paper improves on the original paper and demonstrates possible concealment of the program. I adjusted my rating upward to 8.  ', 'This paper proposed ""adversarial reprogramming"" of well-trained and fixed neural networks, which can be viewed as learning a trainable input perturbation on a fixed network for multi-tasking by using a different dataset (e.g., MNIST) from the original dataset (ImageNet) as input. Domain mapping functions (h_g and h_f) are required if the data have different dimensions. The key factor to enable adversarial reprogramming of a fixed network to perform a different task is by training the additive adversarial program as defined in (1). Experimental results show that 7 different ImageNet models (adversarially trained or not) can be reprogrammed for performing counting tasks, and MNIST and CIFAR-10 classifications. The authors also show that adversarial reprogramming is less effective on untrained networks. \n\nAlthough the idea of this paper is interesting,  the contribution is unclear and the ""adversarial"" setting is not well motivated. The detailed comments are as follows.\n\n1. Unclear contribution - As mentioned in this paper, the main difference between ""adversarial reprogramming"" and transfer learning or multi-task learning is the fact that the network to be reprogrammed is fixed during reprogramming and was trained on a single task that is independent of the targeted task. However, the reprogramming results are not surprising given the fact that multi-task learning can be achieved on the same network. Given the fact that the perturbed input data (e.g., MNIST) is different from the original input data (ImageNet), what adversarial reprogramming demonstrates is actually a simple way of learning a new task via input perturbation to an unseen dataset at training time. However, transfer learning can be done in a similar way by simply fine-tuning the last (few) layers of a well-trained network. So the number of parameters required to be modified in order to ""reprogram"" a network is already known to be quite small via fine-tuning, which may even be less than the dimension of the adversarial program. In addition, given that the input of ImageNet model is high-dimensional and ImageNet images are likely to lie on a low dimensional manifold (but they are very different from hand-written digits or CIFAR images), the capability of reprogramming using deep models under this setting is expected and thus the contribution is unclear.\n\n2. The ""adversarial"" setting is vague - I am very confused about why the experimental settings should be considered ""adversarial"", given the fact that ImageNet images and the three sets of adversarially perturbed images are quite different. What the experiments show is that a well-trained classifier has a large enough capacity to perform other tasks by simply training a perturbation on a different (out-of-distribution) dataset as inputs. It would make more sense to call this method ""adversarial"" if it can be used on ImageNet images to secretly implement some programmed tasks, while on the surface they are seemingly simply performing a typical classification task.\n\n3. Limited novelty - How is adversarial program different from additional perturbation? Let alone the mapping function M in eqn (3), the adversarial program is nothing but a constrained perturbation (ranging from [-1,1] in each dimension). The optimization formulation in (3) can be seen as a  Carlini-Wager L2 attack with a simplified attack loss + L2 distortion regularization. Therefore, the proposed method has limited technical contribution and novelty.\n\nIn summary, this paper has some interesting ideas, but the current presentation lacks clear motivation, and its technical contribution and implications need to be better highlighted.  The authors are suggested to better motivate this paper from the angle of studying the learning capacity of input perturbation induced multi-tasking learning of a well-trained and fixed neural network model, and compare the pros and cons with transfer learning based on fine-tuning and joint multi-task learning / meta-learning on the same network architecture. Based on my own reading, I truly feel that advocating  ""adversarial"" reprogramming does not add any value to this work, as its use for an adversary is not properly motivated (e.g., visual imperceptibility) and its training has no adversarial nature (e.g., GAN training). Titles like ""(Out-of-domain) Input perturbation induced reprogramming of neural networks"" should better justify the contents and experiments presented in this work. Lastly, the authors need to specify how equation (3) is different from the formulation of finding adversarial perturbations in existing literature. Otherwise,  the novelty of ""adversarial program"" is quite limited.\n\n----\nPost-rebuttal review:\n\nI appreciate the authors\' efforts in including the new experiments in Sections 4.4 and 4.5. In my opinion, these new results and the discussion in Section 5.2 add great values to this work and make the contributions of this paper substantially clear. I\'ve increased my rating to 6.', ""This paper extends the idea of 'adversarial attacks' in supervised learning of NNs, to a full repurposing of the solution of a trained net. \n\nThe note of the authors regarding 'Transfer learning' is making sense even to the extend that I fail to see how the proposed study differs from the setting of Transfer learning. The comment of 'parameters' does not make much sense in a semi-parametric approach as studied. The difference might be significant, but I leave it up to the authors to formulate a convincing argument.\n\n""]","[80, -20, -20]","[90, 50, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, calling it 'novel', 'well-written', 'interesting', and 'of significance'. They recommend it for publication and even increased their rating after the rebuttal. The few criticisms are presented as constructive questions rather than major flaws. The politeness score is 90 (very polite) due to the consistently respectful and professional tone. The reviewer uses phrases like 'pleasant read', offers balanced feedback, and frames critiques as questions or suggestions rather than harsh criticisms. The language is formal and courteous throughout, without any rude or dismissive comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas, they express significant concerns about the paper's contribution, novelty, and motivation. The reviewer states the contribution is 'unclear', the 'adversarial' setting is 'vague', and there is 'limited novelty'. However, the score is not deeply negative because the reviewer does see some merit in the work and provides constructive feedback. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout, offering specific suggestions for improvement rather than harsh criticism. They use phrases like 'the authors are suggested to' and 'I appreciate the authors' efforts', which maintain a polite tone even while expressing concerns. The post-rebuttal section also shows the reviewer's willingness to reconsider their initial assessment based on new information."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that some aspects of the paper 'make sense', they also express skepticism about the novelty of the approach and question how it differs from transfer learning. The reviewer also points out that some comments in the paper 'do not make much sense'. However, the tone is not overwhelmingly negative, hence the moderate negative score. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'I leave it up to the authors' which shows respect for the authors' expertise. The reviewer also frames their criticisms as suggestions or questions rather than outright dismissals, which contributes to the polite tone.""]"
"['This paper presents a novel method for budgeted cost sensitive learning from Data Streams.\nThis paper seems very similar to the work of Contrado’s RADIN algorithm which similarly evaluates sequential datapoints with a recurrent neural network by adaptively “purchasing” the most valuable features for the current datapoint under evaluation according to a budget. \n\nIn this process, a sample (S_i) with up to “d” features arrives for evaluation.  A partially revealed feature vector x_i arrives at time “t” for consideration.  There seems to exist a set of “known features” that that are revealed “for free” before the budget is considered (Algorithm 1).  Then while either the budget is not exhausted or some other stopping condition is met features are sequentially revealed either randomly (an explore option with a decaying rate of probability) or according to their cost sensitive utility.  When the stopping condition is reached, a prediction is made.  After a prediction is made, a random mini-batch of the partially revealed features is pushed into replay memory along with the correct class label and the P. Q, and target Q networks are updated.\n\nThe ideas of using a sequentially revealed vector of features and sequentially training a network are in Contrado’s RADIN paper.   The main novelty of the paper seems to be the use of MC dropout as an estimate of certainty in place of the softmax output layer and the methods of updating the P and Q networks.\nThe value of this paper is in the idea that we can learn online and in a cost sensitive way.  The most compelling example of this is the idea that a patient shows up at time “t” and we would like to make a prediction of disease in a cost sensitive way.  To this end I would have liked to have seen a chart on how well this algorithm performs across time/history.  How well does the algorithm perform on the first 100 patients vs the last 91,962-91,062 patients at what point would it make sense to start to use the algorithm (how much history is needed).\n\nAm I correct in assuming there are some base features that are revealed “for free” for all samples?  If so how are these chosen?  If so how does the number of these impact the results?  \n\nIn Contrado’s RADIN paper the authors explore both the MNIST dataset and others, including a medical dataset “cardio.”  Why did you only use RADIN as a comparison for the MNIST dataset and not the LTRC or diabetes dataset?  Did you actually re-implement RADIN or just take the numbers from their paper?  In which case, are you certain which MNIST set was used in this paper? (it was not as well specified as in your paper).\n\nWith respect to the real world validity of the paper, given that the primary value of the paper has to do with cost sensitive online learning, it would have been better to talk more about the various cost structure and how those impact the value of your algorithm.  For the first example, MNIST, the assumed uniform cost structure is a toy example that equates feature acquisition with cost.  The second example uses computational cost vs relevance gain.  This would just me a measure of computational efficiency, in which case all of the computational cost of running the updates to your networks should also be considered as cost.  With respect to the third proprietary diabetes dataset, the costs are real and relevant, however there discussion of these are given except to say that you had a single person familiar with medical billing create them for you (also the web address you cite is a general address and does not go to the dataset you are using). \n\n In reality, these costs would be bundled.  You say you estimate the cost in terms of overall financial burden, patient privacy and patient inconvenience.  Usually if you ask the patient to fill out a survey it has multiple questions, so for the same cost you get all the answers.  Similarly if you do a blood draw and test for multiple factors the cost to the patient and the hospital are paid for the most part upfront.  It is not realistic to say that the cost of asking a patient a questions is 1/20th of the cost of the survey.  The first survey question asked would be more likely 90-95% of the cost with each additional question some incremental percentage.  To show the value of your work, a better discussion of the cost savings would be appreciated.             \n', 'I like the approach, however: I consider the paper to be poorly written.  The presentation needs to be improved for me to find it acceptable.\n\nIt presents a stream-oriented (aka online) version of the algorithm, but experiments treat the algorithm as an offline training algorithm.  This is particularly critical in this area because feature acquisition costs during the ""warm-up"" phase are actual costs, and given the inherent sample complexity challenges of reinforcement learning, I would expect them to be significant in practice.  This would be fine if the setup is ""we have a fixed offline set of examples where all features have been acquired (full cost paid) from which we will learn a selector+predictor for test time"".\n\nThe algorithm 1 float greatly helped intelligibility, but I\'m left confused.  \n  * Is this underlying predictor trained simultaneously to the selector?  \n        * Exposition suggests yes (""At the same time, learning should take place by updating the model while maintaining the budgets.""), but algorithm block doesn\'t make it obvious.\n        * Maybe line 21 reference to ""train data"" refers to the underlying predictor.\n  * Line 16 pushes a value estimate into the replay buffer based upon the current underlying predictor, but:\n        * this value will be stale when we dequeue from the replay buffer if the underlying predictor has changed, and \n        * we have enough information stored in the replay buffer to recompute the value estimate using the new predictor, but\n        * this is not discussed at all.\n\nAlso, I\'m wondering about the annealing schedule for the exploration parameter (this is related to my concern that the\nalgorithm is not really an online algorithm).  The experiments are all silent on the ""exploration"" feature acquisition cost.  Furthermore I\'m wondering: when you do the test evaluations, do you set exploration to 0?\n\nI also found the following disturbing: ""It is also worth noting that, as the proposed method is\nincremental, we continued feature acquisition until all features were acquired and reported the average\naccuracy corresponding to each feature acquisition budget.""  Does this mean the underlying predictor was trained on data \nthat it would not have if the budget constraint were strictly enforced?\n', 'The paper presents a RL approach for sequential feature acquisition in a budgeted learning setting, where each feature comes at some cost and the goal is to find a good trade-off between accuracy and cost. Starting with zero feature, the model sequentially acquires new features to update its prediction and stops when the budget is exhausted. The feature selection policy is learned by deep Q-learning. The authors have shown improvements over several prior approaches in terms of accuracy-cost trade-off on three datasets, including a real-world health dataset with real feature costs.\n\nWhile the results are nice, the novelty of this paper is limited. As mentioned in the paper, the RL framework for sequential feature acquisition has been explored multiple times. Compared to prior work, the main novelty in this paper is a reward function based on better calibrated classifier confidence. However, ablations study on the reward function is needed to understand to what extent is this helpful.\n\nI find the model description confusing. \n1. What is the loss function? In particular, how is the P-Network learned? It seems that the model is based on actor-critic algorithms, but this is not clear from the text.\n2. What is the reward function? Only immediate reward is given.\n3. What is the state representation? How do you represent features not acquired yet?\n\nIt is great that the authors have done extensive comparison with prior approaches; however, I find more ablation study needed to understand what made the model works better. There are at least 3 improvements: 1) using proper certainty estimation; 2) using immediate reward; 3) new policy architecture. Right now not clear which one gives the most improvement.\n\nOverall, this paper has done some nice improvement over prior work along similar lines, but novelty is limited and more analysis of the model is needed.']","[-20, -50, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the paper's method, they express several concerns and criticisms. They point out similarities to existing work, question the real-world validity of the cost structures used, and request more information on various aspects. The overall tone suggests that the reviewer sees potential in the work but feels it needs significant improvements.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They phrase their criticisms as questions or suggestions rather than direct attacks. For example, they use phrases like 'Am I correct in assuming...?' and 'It would have been better to talk more about...'. The reviewer also acknowledges the value of the paper's ideas, which adds to the politeness. However, the score is not higher because the review is quite critical and doesn't include many explicitly positive or encouraging statements."", ""The sentiment score is -50 because while the reviewer starts with a positive note ('I like the approach'), they quickly follow with strong criticism ('poorly written', 'needs to be improved'). The review then lists several significant concerns and issues with the paper, indicating an overall negative sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects and provides constructive feedback. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I consider', 'I would expect', and 'I'm left confused' rather than making blunt accusations. They also provide detailed explanations for their concerns, which is a polite way to give criticism. However, some phrases like 'I found the following disturbing' are more direct and slightly less polite, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('results are nice', 'great that the authors have done extensive comparison'), they also point out significant limitations ('novelty of this paper is limited', 'more ablation study needed', 'more analysis of the model is needed'). The overall tone suggests that the paper has merits but falls short in several areas. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively ('I find more ablation study needed', 'Overall, this paper has done some nice improvement'). The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out shortcomings.""]"
"['In the paper, the authors proposed a new algorithm for instance-wise feature selection. In the proposed algorithm, we prepare three DNNs, which are predictor network, baseline network, and selector network. The predictor network and the baseline networks are trained so that it fits the data well, where the predictor network uses only selected features sampled from the selector network. The selector network is trained to minimize the KL-divergence between the predictor network and the baseline network. In this way, one can train the selector network that select different feature sets for each of given instances.\n\nI think the idea is quite simple: the use of three DNNs and the proposed loss functions seem to be reasonable. The experimental results also look promising.\n\nI have a concern on the scheduling of training. Too fast training of the predictor network can lead to the subotpimal selection network. I have checked the implementations in github, and found that all the networks used Adam with the same learning rates. Is there any issue of training instability? And, if so, how we can confirm that good selector network has trained?\n\nMy another concern is on the implementations in github. The repository originally had INVASE.py. In the middle of the reviewing period, I found that INVASE+.py has added. I am not sure which implementations is used for this manuscript. It seems that INVASE.py contains only two networks, while INVASE+.py contains three networks. I therefore think the latter is the implementation used for this manuscript. If this is the case, what INVASE.py is for?\nI am also not sure if it is appropriate to ""communicate"" through external repositories during the reviewing period.', ""This paper proposes a new instance-wise feature selection method, INVASE. It is closely related to the prior work L2X (Learning to Explain). There are three differences compared to L2X. The most important difference is about how to backpropagate through subset sampling to select features.  L2X use the Gumbel-softmax trick and this paper uses actor-critic models.\n\nThe paper is written well. It is easy to follow the paper. The contribution of this paper is that it provides a new way,  compared to L2X, to backpropagate through subset sampling in order to select features. The authors compare INVASE with L2X and several other approaches on synthetic data and show outperforming results. In the real-world experiments, the authors do not compare INVASE with other approaches. \n\nRegarding experiments, instance-wise feature selection is often applied on computer vision or natural language process applications, where global feature selection is not enough. This paper lacks experiments on CV or NLP applications. For the MAGGIC dataset, I expect to see subgroup patterns. The patterns that authors show in Figure 2 are very different for all randomly selected 20 patients. The authors do not explain why it is preferred to see very different feature patterns for all patients instead of subgroup patterns.\n\nI have questions about other two differences from L2X, pointed by the authors. First, the selector function outputs a probability for selecting each feature \\hat{S}^\\theta(x). In the paper of L2X, it also produces a weight vector w_\\theta(x) as described in section 3.4. I think the \\hat{S}^\\theta(x) has similar meaning as w_\\theta(x) in L2X. In the synthetic data experiment, the authors fix the number of selected features for L2X so that it forces to overselect or underselect features in the example of Syn4. Did the author try to relax this constraint for L2X and use w_\\theta(x) in L2X to select features as using \\hat{S}^\\theta(x) in INVASE? \n\nSecond, I agree with the authors that L2X is inspired by maximizing mutual information between Y and X_S and INVASE is inspired by minimizing KL divergence between Y|X and Y|X_S. Both intuitions lead to similar objective functions that INVASE has an extra term \\log p(y|x) and \\lambda ||S(x)||. INVASE is able to add a l_0 penalty on S(x) since it uses the actor-critic models. For the \\log p(y|x) term, as the author mentioned, it helps to reduce the variance in actor-critic models. This \\log p(y|x) term is a constant in the optimization of S(x). In Algorithm 1, 12, the updates of \\gamma does not depend on other parameters related to the predictor network and selector network. Could the authors first train a baseline network and use it as a fixed function in Algorithm 1? I don't understand the meaning of updates for \\gamma iteratively with other parameters since it does not depend on the learning of other parameters. Does this constant term \\log p(y|x) have other benefits besides reducing variance in actor-critic models?\n\nI have another minor question about scaling. How does the scaling of X affect the feature importance learned by INVASE?\n\nNote: I have another concern about the experiments. Previous instance-wise variable selection methods are often tested on CV or NLP applications, could the authors present those experiments as previous works?"", 'This paper proposes an instance-wise feature selection method, which chooses relevant features for each individual sample. The basic idea is to minimize the KL divergence between the distribution p(Y|X) and p(Y|X^{(s)}). The authors consider the classification problem and construct three frameworks: 1) a selector network to calculate the selection probability of each feature; 2) a baseline network for classification on all features; 3) a predictor network for classification on selected features. The goal is to minimize the difference between the baseline loss and predictor loss.\n\nThe motivation of the paper is clear and the presentation is easy to follow. However, I have some questions on the model and experiments:\n\n1. How is Eq. (5) formulated? As the selector network does not impact the baseline network, an intuition regarding Eq. (5) is to maximize the predictor loss, which seems not reasonable. It seems more appropriate to use an absolute value of the difference in Eq. (5). Some explanation for the formulation of Eq. (5) would be helpful.\n\n2. The model introduces an extra hyper-parameter, $\\lambda$, to adjust the sparsity of selected features. I was curious how sensitive is the performance w.r.t. this hyper-parameter. How is $\\lambda$ determined in the experiments?\n\n3. After the selector network is constructed, how are the features selected on testing data? Is the selection conducted by sampling from the Bernoulli distribution as in training or by directly cutting off the features with lower probabilities?\n']","[50, 20, 20]","[75, 60, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the idea as 'quite simple' and 'reasonable', and notes that the experimental results 'look promising'. However, they also express some concerns, balancing out the positive aspects. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or concerns rather than direct accusations, and acknowledges positive aspects before raising issues. They use phrases like 'I think' and 'I have a concern' which maintain a polite tone. The reviewer also shows engagement by mentioning they checked the GitHub repository, indicating thorough consideration of the work."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and good writing, but also raises several questions and concerns about the methodology and experiments. The reviewer notes that the paper is 'written well' and 'easy to follow', and recognizes its contribution in providing a new approach. However, they also point out limitations in the experiments and raise questions about the methodology, which tempers the overall positive sentiment.\n\nThe politeness score is moderately high (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I expect to see', 'I have questions about', and 'Could the authors' which are polite ways of raising concerns or requesting clarifications. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a courteous approach. There are no rude or harsh comments, and the critique is presented in a constructive manner."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the clear motivation and easy-to-follow presentation of the paper. However, they also raise several questions and concerns, indicating a mixed but generally favorable view. The politeness score is moderately high (60) as the reviewer uses respectful language, frames their concerns as questions rather than criticisms, and offers constructive feedback. They use phrases like 'I was curious' and 'Some explanation would be helpful', which maintain a polite and professional tone throughout the review.""]"
"['\nIn this work, the authors considers a variation of GAN by consider simultaneously decrease the probability that real data is real for the generator. To include such a property, the authors propose a relativistic discriminator which estimate the probability that the given real data is more realistic than the fake data. Numerical results are performed to show that the proposed methods are effective, and the resulting GANs are relatively more stable and generate higher quality data samples than their non-relativistic counterparts.\n\nOverall the paper is well written and the rationale behind the proposed modification is clear. In particular, the authors use three different perspective, (the prior knowledge, the divergence minimization, and the gradient expressions), to explain what they thought is missing in the state-of-the-art. By proposing to utilize the information about both real and fake data in the discriminator definition, the authors’ have (to some extent) alleviated the above shortcoming of the state-of-the-art.  Unfortunately, like almost all papers related to the field,  there has been no rigorously justification behind the proposed methods. \n\nThe English of the paper has to be significantly improved. For example, grammar errors like “this mean….”, “didn’t converge, …”\n\nUnfortunately, the codes of the paper is not released, I will encourage the authors to do so. \n', 'The paper proposes a “relativistic discriminator” which has the property that the probability of real data being real decreases as the probability of fake data being real increases. \n\nThe paper is very well-written. I particularly liked Section 3 which motivates the key idea through multiple viewpoints. The experiments show that the relativistic discriminator helps in some settings, although it does seem a bit sensitive to hyperparameters, architectures and datasets.\n\nI found the argument about connections to IPM-GANs a bit confusing. In a couple of places in Section 4, the relativistic loss is motivated by showing that the relativistic discriminator makes SGANs more like IPM-GANs. However, not all IPM-GANs are the same, e.g. the experiments show performance gaps between RSGAN, RaSGAN, and WGAN-GP, which suggests there could be other confounding factors. \n\nCould you devise experiments on synthetic datasets where the different hypotheses in Section 3 might lead to different solutions? Would be very interesting to see which hypothesis best explains why relativistic discriminator helps!\n\nSection 4.3: How do you justify the averaging? While the relativistic GAN is well-explained, section 4.3 only briefly mentions the averaging idea. Given that averaging seems to help a lot in some of the experiments, it’d be great to see further discussion of why this helps.\n', 'The paper describes an interesting tweak of the standard GAN model (inspired by IPM based GANs) where both the generator and the discriminator optimize relative realness (and fakeness) of the (real, fake) image pairs. The authors give some intuition for this tweak and ran experiments with CIFAR10 and CAT datasets. Different variants of the standard GAN and the new tweak were compared under the FID metric. The experimental setup and details are provided; and the code is made publicly available. \n\nThe results are good and their tweak seems to help in most of the cases. The paper, however, is not very well written and is not of publication quality.  All the insights given in Section 3 are wrong, incomplete and unsatisfying. For example, in Section 3.4, the authors suggest that gradient dynamics of the tweaked model (with some unrealistic and infeasible assumptions) is same as that of an IPM-GAN and contribute to stability. This is wrong. Similar dynamics (even under the unrealistic assumption), does not imply similar performance. In fact, if one is trying to move towards IPM dynamics, then one should try to tweak an IPM model directly. Section 3.2 also seems wrong from my understanding of GAN training. Section 3.3 could also be improved. In fact, any explanations based on minimizing JS divergence is incomplete without answering as to why JS divergence minimizing is the best thing to do. \n\nThe author should have provided more comparison images to rule out the fact that the tweak is not overfitting for the FID metric. The benchmarks are also weak and more experiments need to be done (Eg, CelebA). ']","[50, 60, -30]","[60, 80, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is 'well written' and the rationale is 'clear'. They appreciate the authors' efforts to address shortcomings in the state-of-the-art. However, they also point out some weaknesses, such as lack of rigorous justification and grammar errors, which prevents a higher positive score. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and encouragement (e.g., 'I will encourage the authors to do so'). They balance positive feedback with areas for improvement. The use of 'unfortunately' twice softens the criticism. However, the directness in pointing out errors (e.g., 'The English of the paper has to be significantly improved') prevents a higher politeness score."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, praising it as 'very well-written' and noting that the proposed method 'helps in some settings'. However, it's not extremely positive as the reviewer also points out some limitations and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or polite requests (e.g., 'Could you devise...', 'it'd be great to see...'). The reviewer balances praise with critique in a professional manner, maintaining a courteous tone even when pointing out potential weaknesses in the paper."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting tweak', 'results are good'), they are largely critical of the paper's writing quality and theoretical explanations. The reviewer states that 'the paper is not very well written and is not of publication quality' and points out several flaws in the authors' reasoning. However, it's not entirely negative as they do recognize some merits of the work. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'The author should have provided' instead of more direct criticisms. They also begin with positive observations before moving to critiques. However, some statements like 'All the insights given in Section 3 are wrong' are quite direct, preventing a higher politeness score.""]"
"['This paper proposes an algorithm to approximate kernel matrix based on the Taylor expansion of the element-wise functions. The authors provide a spectral norm based error bound for their method and the corresponding results for the special case, \\epsilon-sparse matrix.\n\nI have some comment as follow.\n\n1. Can you provide some comparison with Nystrom methods? It is very popular for kernel approximation and looks more efficient than the proposed algorithm. \n\n2. The analysis relies on the Gaussian assumption on the input matrix. Can we extend it to more general case?\n\n3. In section 5, the paper said “as our method consists in computing the sparse eigenvectors of a p \\times p matrix which can be done by power method, the complexity of estimating the principal component is about O(ps) where s is the sparsity level”. The time complexity of the proposed algorithm is not clearly.\na) Is there any bound for the sparsity level s? Why the eigenvectors of p \\times p matrix is sparse?\nb) The convergence of power method is heavily affected by the eigen-gap of the matrix. Is there any theoretical or empirical result for the convergence behavior of power method on approximate matrix and original matrix?\n\n', ""This paper discusses the sparse PCA problem from the random matrix perspective. First, it establishes a theorem that connect a f(sample covariance) to f(actual covariance) in Theorem 1, and shows that when f if three-times continuous differentiable,  f(sample covariance) can be written in terms of actual covariance and $1/n XX^T-I$. Then, based on this theorem, it shows that if f'(0)=f''(0)=0, then f(sample covariance) is well approximated by f(actual covariance). \n\nBased on this result, a procedure for sparse PCA is proposed: first, soft threshold the sample covariance (the thresholding function is described in (9)); second, calculate the top eigenvectors of the thresholded sampled covariance. In simulations, it has similar performance as some popular sparse PCA algorithms.\n\nWhile I think the result of the paper is certainly interesting and worth publication, many notations in the papers are not clear and I can not verify the proofs completely as a result. For example:\n1. Z\\in C E(c,.) in Definition 1---what is the set E(c,.) and is it the same as N(c,.) as implied in definition 1? But it E(c,.) is the same as N(c,.), why they are treated differently in Proposition 2?\n\n\n2.  the subscript {.,i} in the first paragraph Section 4.1 (I guess it means the i-th column).\n\n3. how are f and f^{(k)} defined for matrices in Theorem 1 and what is the supscript {\\odot k}--elementwisely k-th power?\n\n4. The notation O_\\eta in (8).\n\nSome other thought: is the assumption before Theorem 1 reasonable? Can the author(s) add some comments and show that it holds for a reasonable Sigma=I+P: the assumption and Theorem 1 would hold for very small P, but that is not an interesting case. \n\nThe function in (9) is essentially a soft-threshoding procedure. Can the method in this work be used to prove other thresholding procedures such as hard thresholding?"", 'The paper aims at generalizing a result by Deshpande and Montanari.\n\nDeshpande and Montanari prove a result for the covariance thresholding algorithm which consists of (1) removing noise from an empirical covariance matrix of a (single) spiked sparse PCA model using soft thresholding, then (2) computing the leading eigenvector of the denoised matrix and finally (3) picking the leading coordinates of the leading eigenvector.\n\nThe current paper focuses on step (1) in the above mentioned process. They claim to generalize the use of soft thesholding to more general functions applied element-wise to the empirical covariance matrix.\n\nThere is a questionable term in the paper\'s title: the word ""kernel"" is mistakenly used. In fact a symmetric matrix is the Gram matrix of a kernel if it is positive semi-definite. The empirical covariance is PSD, but when you apply a function to it elementwise it has no guarantee of conserving the PSD property.\n\nRegarding the motivation of the paper (1) the paper claims to study the rank K case with arbitrary K>=1. Deshpande and Montanari studied K=1 and the analysis is already an interesting result. Generalizing it to higher ranks poses many questions, including the sparse vector supports\' overlaps. \nIt is not clear to me why authors insist on trying to generalize the result to a function f that has broader properties. The main motivation is to recover the support of the (leading) sparse eigenvector / PC. It should not be to try denoising the empirical covariance with a complicated function f. If the focus is on generalizing the soft-thresholding part of the approach, then the real question can be formulated as what is the optimal f given that we have this or that property in the data? This often leads to Bayesian analysis of the problem. \n\nThe numerical experiments do not show any substantial improvement obtained using the prescribed method over using the baseline method (covariance thresholding). I suspect that authors can emphasis the benefit of their method by picking f to hold certain properties that reflect the noise process and beat covariance thresholding in those regimes.\nFigure 1 right hand side. I do not see why authors refer to phase transition. I don\'t see a phase transition happening there.\n\n\n']","[20, 50, -20]","[60, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and provides constructive feedback without harsh criticism. The opening paragraph summarizes the paper's content neutrally, and the subsequent comments are framed as questions and suggestions for improvement rather than outright criticisms. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'Can you provide...', 'Is there any...', which shows respect for the authors. The reviewer also avoids accusatory or dismissive language, instead framing their points as areas for clarification or expansion. The overall tone is professional and constructive, aiming to improve the paper rather than criticize it harshly."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting results and recommends publication, but also points out several areas needing clarification. The reviewer begins with positive comments about the paper's worth and interesting results, but then lists several specific issues and unclear notations. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and balances positive and negative feedback. The reviewer uses phrases like 'I think the result of the paper is certainly interesting and worth publication' and frames issues as requests for clarification rather than direct criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to generalize previous work, they express several concerns and criticisms. They question the use of the term 'kernel' in the title, the motivation for generalizing to a broader function f, and the lack of substantial improvement shown in numerical experiments. The reviewer also suggests that the authors may be misinterpreting their results (e.g., referring to a phase transition that isn't apparent). However, the score isn't deeply negative because the reviewer does offer constructive suggestions and acknowledges the potential of the work.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout. They use neutral language to express their concerns (e.g., 'It is not clear to me why...', 'I suspect that authors can...') rather than making harsh or dismissive statements. The reviewer also offers constructive suggestions for improvement, which is a polite way to address weaknesses in the paper. However, the score isn't higher because the review doesn't include explicitly positive or encouraging statements, and the overall tone is more critical than supportive.""]"
"['This work analyses the information bottleneck (IB) method applied to the supervised learning of a deterministic rule Y=f(X).\n\nThe idea as I understood it is as follows:\n1) In a first section the authors discuss the relationship between supervised learning through minimization of the empirical cross entropy and the maximization of the empirical mutual information with an intermediate latent variable T. \n2) They show that in the case of a deterministic rule, the information bottleneck curve has a simple shape, piecewise linear, and is not strictly concave. \n3) They show that the optimization of the IB Lagrangian for different \\beta does not lead to a point by point exploration of the IB curve.\n4) They propose a cure to the previous issue by introducing the squared IB Lagrangian. \n5) They exhibit uninteresting representations (noisy versions of the output Y) that are on the IB curve.\n6) They show that multiple successive representations (like in DNNs), have identical predicting power (mutual information with output Y) when they allow for perfect prediction. \n7) They use the IB method to train a neural net on MNIST, using the Kolchinsky estimate of the mutual informations. \n\t- they show that the optimization of the squared IB reaches more different points on the IB curve,\n\t- but that these representations are possibly uninteresting (hard clustering of uneven numbers of grouped classes) \n\t- they show that for large enough value of beta, zero error is reached. \n\nThe necessity of noise in the IB theory has been already pointed out by (Gilad-Bachrach et al., 2003; Shwartz-Ziv et al.  2017), although the more thorough analysis proposed here is novel. In practice, besides a few recent propositions (Kolchinsky et al., 2017; Alemi et al., 2016; Chalk et al., 2016) the IB Lagrangian is not a usual objective function for supervised learning. The motivation and impact of this work studying deterministic rules is therefore not completely convincing. \n\nFurther pros and cons:\n\nPros:\n- The discussion is generally well written. \n- This work provides in depth clarification of the counter-intuitive behaviors of the IB method in the case to the learning of a deterministic rule. \n- These are demonstrated with experiments conducted on the MNIST dataset for concreteness.\n\nCons:\n- The fact that multiple successive representations have identical predicting power when the prediction error is zero, was already observed for example in Shwartz-Ziv et al.  2017. It is not clear why this should be considered as an issue. It also seems to be a straightforward observation when restricting to the empirical measure on the training set. \n- The fact that the entire IB curve is not explored point by point by the IB Lagrangian is not necessarily an issue for learning. In the experiments of the present paper, the results seem to suggest that the interesting intermediate representations (separation in 10 compact clusters of the MNIST classes) is actually easier to obtain (large range of \\beta) optimizing the IB Lagrangian rather than the proposed squared IB Lagrangian. \n\nQuestions:\n- Do the authors know of an application where the full probing of the IB curve would be necessary?\n- In Section 2, when injecting the decomposition of the prediction density q(y|x) over the intermediate variable t in eq (3) was a Jensen inequality replaced by an equality?\n', 'This paper is about issues that arise when applying Information Bottleneck (IB) concepts to machine learning, more precisely in deterministic supervised learning such as classification (deterministic in the sense that the target function to estimate is deterministic: it associates each example to one true label only, and not to a distribution over labels).\nNamely:\n(1) the ""Information Bottleneck curve"" cannot be computed with the Information Bottleneck Lagrangian approach (because of optimization landscape issues: optimization of such a piecewise-linear function with a linear penalty will always yield the same optimum whatever the slope of the penalty is [same story as L1 vs. L0]); \n(2) there are many solutions to the optimization of the IB Lagrangian for any given compression/performance ratio (i.e. for any given beta in the IB Lagrangian method: I(Y,T)/I(X,T)) and some of them are provably trivial; thus optimizing just the IB Lagrangian does not imply that the solution will be interesting, and better (or complementary) criteria are needed.\n\nAnother point discussed also is about the successive layers of perfect classifiers (neural networks), in which I(Y,T) remains constant while I(X,T) decreases.\n\n\nPros:\n- the paper is well written, mostly self-contained, and easy to read (for someone familiar with information theory);\n- all mathematical points are detailed and well explained, with sufficient introduction;\n- the writing is compact, the paper is dense, and given the page limit this is a good information/compression compromise;)\n- information bottleneck is a topic of prime interest in the community these days;\n- the two first problems described ((1) and (2)) are original, interesting contributions to the field, of particular interest for people interested in applying information bottleneck concepts to supervised learning;\n- the solution brought to the IB Lagrangian issues is simplistic though efficient (squaring I(X,T) so that it\'s not linear in I(X,T) anymore).\n\n\nCons:\n- not much.\n\nRemarks:\n- there exist recent papers tackling the information bottleneck concept for neural networks from a variational perspective, which enables them to compute exactly the mutual informations (such as ""Compressing Neural Networks using the Variational Information Bottleneck"" by Dai & al., ICML 2018); I have not seen these papers cited in the article, nor discussed (nor used); I feel it would be appropriate, either in the general literature section, either for discussing how to compute in practice the mutual informations (exact values vs. estimates or lower bounds as here).\n- at first reading, I had found the tone of the beginning of the paper (first section) a bit aggressive, though this feeling disappeared later. Maybe rephrase some expressions that might be wrongly perceived?\n- About multilabel classification (end of section 2): multilabel classification can still be seen as with deterministic expected outputs, if considered as a task from X to P(Y) (power set of Y, i.e. set of all possible subsets of labels).\n- As in practice T is constrained to belong to a particular space of functions (neural network layer with predefined architecture): how does this impact the study? For instance the T_alpha in equation (5) are not reachable anymore; the optimization space for the IB Lagrangian is different; etc. Which properties/conclusions can be kept, and which ones cannot?\n- What about sampling on the other part of the IB curve, the horizontal one (same I(Y,T) for various I(X,T))? Would it bring any insight, and how to do it?\n- A side remark about applying IB to neural networks: What about neural networks that are not a ""linear"" chain of layers (i.e. most networks now)? i.e. Inception, ResNet, U-nets, etc., where computational flows are parallel, sometimes keeping full information till the end. For instance in a U-net, meant for image processing, features computed at the beginning at a full pixelic resolution are communicated to the last layer. This is not an image classification task though, as predictions are made for each pixel; still, given an input image X, there is only one correct output Y, so, still in the deterministic supervised classification problem.\n', 'SUMMARY:\nThis paper is about potential problems of the information bottleneck principle in cases where the output variable Y is a deterministic function of the inputs X. Such a deterministic relationship between outputs and inputs induces the problem that the the IB ""information curve"" (i.e. I(T;Y) as a function of I(X;T)) is piece-wise linear and, thus, no longer strictly concave, which is crucial for non-degenerate (""interesting"") solutions. The authors argue that most real classification problems indeed show such a deterministic relation between the class labels and the inputs X, and they explore several issues that result from such pathologies.\n\nEVALUATION:\nIn my opinion, the whole story could be summarized as follows: if  Y is\na deterministic function of p-dimensional inputs X, then the joint distribution P(X,Y) is \ndegenerate in that its support lies in a space of dimension p (an not p+1 as it would be in the non-degenerate situation), and this is the source of all pathologies observed. As a consequence, only the cumulative distribution is defined, but there is no density with respect to the Lebesgue measure of R^{p+1}. Thus, one has to be careful when defining the mutual information I(X,Y), which explains the problems with the IB information curve (which should asymptotically converge to I(X;Y) as I(X;T) gets large. Another consequence of this degeneracy concerns the latent variable interpretation of the IB: if T is treated as a latent variable (as, for instance, in the ""deep"" IB models) then we have the conditional independence relation ""Y independent of X given T"", which simply makes no sense if Y is deterministic in X (there is, of course, a deeper underlying problem here: the IB problem is difficult in that it is difficult to define a geneative model with a faithful DAG...).\nAnalyzing situations in which Y = f(X) (with f being a deterministic function) is certainly interesting from a theoretic point of view, but I am not convinced that this analysis is truly relevant for practical problems. \nIn particular, I strongly disagree with the statement that ""in most classification problems, the labels Y are a deterministic function of X"". I would rather argue that the opposite is the case, because I don\'t think that there are too many such problems with zero Bayes error rate.  In particular, I would argue that digit recognition problems like MNIST so not have deterministic labels, since there will always be images of handwritten characters that will give room for interpretation...']","[20, 80, -20]","[60, 70, 50]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges some pros of the work ('well written', 'provides in depth clarification', 'demonstrated with experiments'), they also express several concerns and doubts about the necessity and impact of the work. The overall tone is more constructive than negative, but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as 'cons' and 'questions' rather than direct attacks. The reviewer also uses phrases like 'as I understood it' and 'The idea is as follows', showing consideration for potential misunderstandings. The language is professional and objective, avoiding any harsh or rude expressions."", ""The sentiment score is 80 (positive) because the reviewer provides a long list of pros, including that the paper is well-written, self-contained, and makes original, interesting contributions. The cons section is notably brief, stating 'not much.' The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as 'remarks' rather than outright negatives. The reviewer even acknowledges their own initial misperception about the tone, showing a willingness to reconsider their views. The language is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges the theoretical interest of the paper, they express significant disagreement with some of the authors\' key claims. The reviewer states \'I strongly disagree with the statement that ""in most classification problems, the labels Y are a deterministic function of X""\' and argues that the analysis may not be \'truly relevant for practical problems\'. However, the review is not entirely negative as it recognizes the theoretical value of the work. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, presenting their criticisms in a professional manner. They use phrases like \'In my opinion\' and \'I would rather argue\' to soften their disagreements. The reviewer also provides a detailed summary and evaluation, showing engagement with the paper\'s content, which contributes to the overall polite tone.']"
"['The authors present a method for generating points clouds with the help of graph convolution and a novel upsampling scheme. The proposed method exploits the pairwise distances between node features to build a NN-graph. The upsampling scheme generates new points via a slimmed down graph convolution, which are then concatenated to the initial node features. The proposed method is evaluated on four categories of the ShapeNet dataset. Resulting point clouds are evaluated via a qualitative and quantitative comparison to r-GAN.\n\nAs far as I know, the paper introduces an overall novel and interesting idea to generate point clouds with localized operations.\n\n\nThe following questions could be addressed by the authors in a revised manuscript:\n\n* The upsampling operation is not well motivated, e.g., neighboring node features are weighted independently, but root node features are not. What is the intuition besides reducing the number of parameters? Are there significant differences when not using diagonal weight matrices?\n* As computation of pairwise node feature distances and graph generation based on nearest neighbors are expensive tasks, more details on the practical running time and theoretical complexity should be provided. Can the complexity be reduced by rebuilding graphs only after upsampling layers? How would this impact the performance of the proposed model?\n* Although the evaluation on four categories is reported, Table 2 only gives results for two categories.\n* How is the method related to GANs which generates graphs, such as GraphGAN or NetGAN?', 'The paper proposes a version of GANs specifically designed for generating point clouds. The core contribution of the work is the upsampling operation: in short, it takes as an input N points, and produces N more points (one per input) by applying a graph convolution-like operation.\n\nPros:\n+ The problem of making scalable generative models for point clouds is clearly important, and using local operations in that context makes a lot of sense.\n\nCons:\n- The paper is not particularly well-written, is often hard to follow, and contains a couple of confusing statements (see a non-exhaustive list of remarks below).\n- The experimental evaluation seems insufficient: clearly it is possible to come up with more baselines. Even a comparison to other types of generative models would be useful (e.g. variants of VAEs, other types of GANs). There also alternative local graph-convolution-like operations (e.g. tangent convolutions) that are designed for point clouds. In addition, it is quite strange that results are reported not for all the classes in the dataset.\n\nVarious remarks:\np.1, “whereby it learns to exploit a self-similarity prior to sample the data distribution”: this is a confusing statement.\np.2, “(GANs) have been shown on images to provide better approximations of the data distribution than other generative models”: This statement is earthier too strong (all other models) or does not say much (some other models)\np.2, “However, this means that they are unable to learn localized features or exploit weight sharing.”: I see the point about no weight sharing in the generator, but feature learning \np.3, “the key difference with the work in this paper is that PointNet and PointNet++ are not\ngenerative models, but are used in supervised problems such as classification or segmentation.”: Yet, the kind of operation that is used in the pointnet++ is quite similar to what you propose?\np.4: “because the high dimensionality of the feature vectors makes the gridding approach unfeasible.”: but you are actually dealing with the point clouds where each point is 3D?\n', 'This paper proposes graph-convolutional GANs for irregular 3D point clouds that learn domain (the graph structure) and features at the same time. In addition, a method for upsampling at the GAN generator is introduced. The paper is very well written, addresses a relevant problem (classification of 3D point clouds with arbitrary, a priori unknown graph structure) in an original way, and supports the presented ideas with convincing experiments. It aggregates the latest developments in the field, the Wasserstein GAN, edge-conditional convolutions into a concise framework and designs a novel GAN generator. I have only some minor concerns:\n\n1)\tMy only serious concern is the degree of novelty with respect to (Achlioptas et al., 2017). The discriminator is the same and although the generator is a fully connected network in that paper, it would be good to highlight conceptual improvements as well as quantitative advantages of the paper at hand more thoroughly. Similarly, expanding a bit more on the differences and improvements over (Grover et al., 2018) would improve the paper. \n\n2)\tP3, second to last line of 2.1: reference needs to be fixed ""…Grover et al. (Grover et al., 2018)""\n\n3)\tIt would be helpful to highlight the usefulness of artificially generating irregular 3D point clouds from an application perspective, too. While GANs have various applications if applied to images it is not obvious how artificially created irregular 3D point clouds can be useful. Although the theoretical insights presented in the paper are exciting, a more high-level motivation would further improve its quality.\n\n4)\tA discussion of shortcomings of the presented method seems missing. While it is understandable that emphasis is put on novelty and its advantages, it would be interesting to see where the authors see room for improvement. \n']","[60, -30, 80]","[80, 20, 90]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as presenting 'an overall novel and interesting idea' and acknowledges the method's novelty. However, it's not extremely positive as the reviewer also raises several questions and points for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'could be addressed' and 'more details... should be provided' indicate a constructive and courteous tone. The reviewer also acknowledges the paper's contributions before presenting their questions, which is a polite approach in academic reviews."", ""The sentiment score is -30 because the review is slightly negative overall. While it acknowledges the importance of the problem and some positive aspects ('Pros'), it lists more 'Cons' and points out several issues with the paper, including poor writing, insufficient experimental evaluation, and confusing statements. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express criticisms. They provide specific examples and suggestions for improvement, which is constructive. The use of 'Pros' and 'Cons' sections helps organize the feedback in a balanced way. However, the review doesn't go out of its way to be overly polite or cushion the criticisms, keeping it closer to neutral than highly polite."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'very well written,' addressing a 'relevant problem' in an 'original way,' and supporting ideas with 'convincing experiments.' The reviewer's only 'serious concern' is minor, relating to the degree of novelty. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'it would be good to,' 'would improve the paper,' and 'it would be interesting to see,' which suggest improvements in a courteous manner. The reviewer also balances criticism with praise, acknowledging the paper's strengths before offering suggestions for improvement.""]"
"['This paper proposed an adversarially regularized AE algorithm that improve interpolation in latent space. Specifically, a critic is used to predict the interpolation weight \\alpha and encourage the interpolated images to be more realistic. The paper verified the method on a newly proposed synthetic line benchmark and on downstream classification and clustering tasks.\n\nPros:\n1.\tA novel algorithm that promotes the interpolation ability of AE\n2.\tA new synthesized line benchmark to verify the interpolation ability of different AE variants\n3.\tStrong results on downstream classification and clustering tasks\n\nCons: \n1.\tThe interplay of the adversarial network (between AE and critic) isn’t very clear and can be improved\n2.\tEq. 1, should x be x_1 or a new data other than x1 and x2?\n3.\tThe paper states that the 2nd term of Eq. 1 isn’t crucial. If x is a new data (other than x1 or x2), how can the critic infer \\alpha without a reference to x1 or x2?\n4.\tThe paper states that “encouraging this behavior also produce semantically smooth interpolation …”. Besides the empirical evidences from data, it would be better to any some theoretical justifications.\n', 'Summary: The authors propose a new approach to encourage valid interpolation in Auto-Encoders (AE). It is based on a regularization procedure involving a critic network judging the realistic nature of reconstructed data point from its mixed latent representations by recovering the mixing coefficient. The authors show that this approach does indeed improve the quality of interpolated samples on few tasks. A synthetic tasks of lines interpolation (proposing new Mean Distance and Smoothness metric for this task), classification task (with a single-layer classifier) from the latent space representation and finally a clustering accuracy on the latent space. On the proposed regularization method seems to help significantly compared to commonly used AE architectures (Basic AE, Denoising AE, Variational AE, Adversarial AE and VQ-VAE).\n\nThis paper was a very interesting read, and the work seems to be of significance for the unsupervised learning community.\nIt was clearly written and conveys the contributions clearly and the experimental results and their interpretations seem valid.\n\nThe proposed approach of a critic based regularizer is a simple but seemingly important addition that contributes to improving interpolation in AE significantly and even show impact ""downstream tasks"" as the authors put it.\n\nFew comments/questions come to mind:\n\n- For the critic Loss L_d in equation (1) , the authors mention that the \\gamma based second term (that should ensure that the critic outputs 0 for non-interpolated inputs and expose the critic to realistic data even if the AE reconstruction is poor)  does not seem to be crucial in your approach but stabilized the adversarial training. Could you somehow quantify this. It seems like stability of the adversarial training should be paramount to your method to make sure the AE learns a better latent representation. This comment, even though I assume it well-founded, seems a bit of a contradiction.\n\n- For the Lines synthetic data. It was chosen to use a 32x32 image size with 16 points length lines. This configuration does quantize directly the angles your measures can distinguish. Below a certain angle differences (or delta), 2 angles must have the same pixel representation, i.e. exact overlapping lines. My question is simple: What is the smallest angle you can use/distinguish or, how many exact unique lines can you have? \n\nOverall this is a good paper that deserves publications.', 'Main idea:\nThis paper investigates the desiderata for a successful interpolation:\n1) Interpolation looks realistic;\n2) The interpolation path is semantically smooth. \nAn adversarial regularizer is proposed to achieve 1), and in practice 2) may also satisfied.  \nTo evaluate the method, they introduce a synthetic dataset with line images and compare with different autoencoder methods without the interpolation regularization.\nFor real data, they show that the interpolation regularized autoencoder (i.e. ACAI) leads to a better unsupervised representation.\n\nQuestions:\n1. Do we really need every interpolated point to be realistic (i.e. similar to a data point in the train-set)? I believe that there exists an interpolation between two totally different objects can never be observed.  \n2. Do we need interpolation points to form a semantically smooth morphing? I guess this is a desired property for continuous generators, but it seems not necessary in general.\n3. The gamma in the 2nd term in (1) is confusing. If gamma = 1, I understand it forces to predict alpha = 0 since x is real. But if gamma < 1, the average in data space may be very blurry thus not realistic at all. How does gamma affect the optimization?\n4. ACAI looks very similar to LSGAN: by giving ""0"" label to real data and ""alpha"" label to fake data; in LSGAN, alpha = 1.\nHave you tested a LSGAN like regularizer? \n5. The baselines are not representative: since ACAI introduces an adversarial regularizer, you should compare with other GAN techniques induced regularizers, such as WGAN regularized autoencoder. \n\nAfter rebuttal:\nSee the long discussion below. I tend to believe that a good interpolation is not only a way to do sanity check but also a nice property to explicitly control in representation learning.']","[60, 80, 20]","[70, 70, 70]","[""The sentiment score is 60 (positive) because the review starts with a neutral summary of the paper's content, followed by a list of pros that highlight the paper's strengths. The cons are presented as constructive criticism rather than harsh negativity. The politeness score is 70 (polite) because the reviewer uses professional and respectful language throughout. They present their feedback in an organized manner (pros and cons) and phrase their criticisms as questions or suggestions for improvement rather than direct attacks. The reviewer acknowledges the paper's contributions while offering areas for potential enhancement, maintaining a balanced and courteous tone."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper was 'a very interesting read', 'of significance', 'clearly written', and 'deserves publications'. They also mention that the experimental results seem valid and the approach is 'simple but seemingly important'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their comments as questions rather than criticisms. They use phrases like 'Few comments/questions come to mind' and 'Could you somehow quantify this', which are polite ways of requesting clarification. The overall tone is professional and supportive, without being overly formal or effusive."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and shows interest in the topic, but also raises several questions and points out limitations. The review begins with a neutral summary of the paper's main ideas, followed by thoughtful questions and suggestions for improvement, indicating a balanced perspective. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, poses questions in a constructive manner, and avoids harsh criticism. The reviewer's tone is professional and academic, focusing on the content rather than making personal comments. The use of phrases like 'I believe' and 'I guess' softens potential criticisms, contributing to the polite tone.""]"
"[""The paper proposes a method for inverse reinforcement learning based on AIRL. It's main contribution is that the shaping function is not learned while training the discriminator, but separately as an approximation of the empowerment (maximum mutual information). This shaping term aims to learn disentangled rewards without being restricted to learning state-only reward functions, which is a major restriction of AIRL.\n\nThe main weakness of the paper is, that it does not justify or motivate the main deviations compared to AIRL. The new objective for updating the policy is especially problematic because it does no longer correspond to the RL objective but includes an additional term that biases the policy towards actions that increase its empowerment. Although both terms of the update can be derived independently from an IRL and Empowerment perspective respectively, optimizing the sum was not derived from a common problem formulation. By combining these objectives, the learned reward function may lead to policies that fail to match the expert demonstration without such bias. This does not imply that the approach is not sound per se, however, simply presenting such update without any discussion is insufficient--especially given that it constitutes the main novelty of the approach. I think the paper would be much stronger if the update was derived from an empowerment-regularized IRL formulation. And even then, the implications of such bias/regularization would need to be properly discussed and evaluated, in particular with respect to the trade-off lambda, which--again--is hardly mentioned in the submission. I'm also not sure if the story of the paper works out; when we simply want to use empowerment as shaping term, why not use two separate policies for computing the empowerment and reward function respectively. Is the bias in the policy update maybe more important than the shaping term in the discriminator update for learning disentangled rewards?\n\nKeeping these issues aside, I actually like the paper. It tackles the main drawback of AIRL and the idea seems quite nice. Having a reward function that does not actively induce actions that can be explained by empowerment, may not always be appropriate, but often enough it may be a sensible approach to get more generalizable reward functions. The paper is also well written with few typos. The parts that are discussed are clear and the experimental results seem fine as well (although more experiments on the reward transfer would be nice).\n\nMinor notes:\nI think there is a sign error in the policy update\nTypo in the theorem, grantee should be guarantee\n\nQuestion:\nPlease confirm that the reward transfer was learned with a standard RL formulation. Does the learned policy change, when we use the empowerment objective as well?\n\n\n\nUpdate (22.11)\nI think that the revised version is much better than the original submission because it now correctly attributes the improved generalization to an inductive bias in the policy update.  However, the submission still seems borderline to me. \n\n- The proposed method uses the empowerment both for regularization as well as for reward shaping, but it is not clear whether the latter improves generalization. If the reward shaping was not necessary, it would be cleaner to use empowerment only for regularization. If the reward shaping is beneficial, this should be shown in an ablative experiment.\n\n- The benefit of using empowerment (whether for reward shaping or for regularization) should be discussed. Empowerment for generalization is currently hardly motivated.\n\n- The derivation could be a bit more rigorous.\n\nAs the presentation is now much more sound, I slightly increased my rating."", 'The authors propose empowerment-based adversarial inverse reinforcement learning (EAIRL), an extension of AIRL which uses empowerment (which quantifies the extent that an agent can influence its state, see eq. 3) as a reward-shaping potential to recover more faithful learned reward functions. \n\nEvaluation:     4/5     Experiments are more preliminary but establish the benefit of the approach.\nClarity:        4/5     Well written. Just a few typos (see below minor comments)\nSignificance:   4/5     Effective, well motivated approach. Excellent transfer learning results.\nOriginality:    3.5/5   As the empowerment subroutine is existing work, as is AIRL, combining previous work, but effectively.\n\nRating:         7/10\nConfidence:     3/5     Reviewed this paper in a little less detail than I would prefer, due to time constraints. I will review in more detail and update this and add any additional questions/comments below the minor comments below.\n\nPros:\n- Extension of AIRL which utilizes empowerment to advance the SOE in reward learning\n- Well written, related previous work well explained.\nCons:\n- Experiments more preliminary\n- Combines existing approaches, somewhat incremental\n\nMinor comments: \n- grantee (typo), barely utilized -> not fully realized?, \n\n----\n\nUpdated review:\n\nAfter reviewing the comments and the paper in more detail (whose story has evolved substantially) , I have revised my score slightly lower. While in hindsight I can see that the paper has definitely improved, the story has changed rather dramatically, and appears to be still unfolding: the paper\'s many new elements require further maturation, and that the utility of empowerment for reward shaping and/or regularization to evolve AIRL (i.e. the old story vs. the new story) still needs further investigation/maturation. If the paper is accepted I\'m reasonably confident that the authors will be able to ""finish up"" and address these concerns. \n(typo: eq. 4 omits maximizing argument)', 'Summary/Contribution:\nThis paper builds on the AIRL framework (Fu et al., 2017) by combining the empowerment maximization objective for optimizing both the policy and reward function. Algorithmically, the main difference is that this introduces the need to optimize a inverse model (q), an empowerment function (Phi) and alters the AIRL updates to the reward function and policy. This paper presents experiments on the original set of AIRL tasks, and shows improved performance on some tasks.\n\nPros:\n    - The approach outperform AIRL by a convincing margin on the crippled ant problem, while obtaining comparable/favorable performance on other benchmarks.\n\nCons:\n    - The justification for using the empowerment maximization framework to learn the shaping parameters is unclear. The formulation introduces a potentially confounding factor by biasing the policy optimization which clouds the experimental picture. \n\nJustification for rating:\nThis paper presents good empirical results, but without a clear identification of the source of improvement. I lean on the side of rejecting unless the authors can better eliminate any potential bias in their formulation (see question below). The justification for combining the empowerment maximization objective is also unclear while being integral to the novelty of the proposed method. \n\nQuestions I could not resolve from my reading:\n    - The ""imitation learning benchmark"" numbers in Table 2 are different from the original AIRL paper. Do the authors have an explanation as to why? Is this only due to a difference in the expert performance?\n    - Can the authors confirm that in the transfer experiments, the policy is optimized with only the transfered reward and no empowerment bonus? Otherwise, can the authors comment on whether the performance benefits could be explained by the additional bonus.\n    - In equation (12), \\Phi is optimized as an (approximate) mutual information, not a value function, so it is not clear why this term approximates the advantage (I suspect this is untrue in EAIRL as V* is recovered at optimality in the AIRL/GAN-GCL formulation). Can the authors comment?\n    - Why is w* unnormalized? Unless I am misunderstanding something, in the definition immediately above it, there is a normalization term Z(s). \n\nOther comments:\n    - ""AIRL(s, a) fails to learn rewards whereas EAIRL recovers the near optimal rewards function"" -> This characterization is strange since on some tasks AIRL(s,a) outperforms or is within one standard deviation of EAIRL (e.g. on Half Cheetah, Ant, Swimmer, Pendulum).\n    -  ""Our experimentation highlights the importance of modeling discriminator/reward functions.. as a function of both state and action"". AIRL(s) is better on both the pointmass and crippled-ant task than AIRL(s,a). Can the authors clarify?\n    - ""Our method leverages .. and therefore learns both reward and policy simultaneously"". Can the authors clarify in what sense the reward and policy is being learned simultaneously in EAIRL where it is not in AIRL?\n    - In all the tables, the authors\' approach is bolded as oppose to the best numbers. I would instead prefer that the authors bold the best numbers to avoid confusion.\n\n- Typos:\n    - ""the imitation learning methods were proposed""\n    - ""quantify an extent to which"" \n    - ""GAIL uses Generative Adversarial Networks formulation""\n    - ""grantee""\n    - ""no prior work has reported the practical approach""\n    - ""but, to""\n    - ""(see (Fu et al., 2017))""\n']","[-20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I actually like the paper', 'The paper is also well written'), they express significant concerns about the main contribution and methodology. The reviewer points out several weaknesses and suggests major improvements, indicating overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think the paper would be much stronger if...' and 'Please confirm that...', which are polite ways of offering criticism and asking for clarification. The reviewer also balances negative feedback with positive comments, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some positive aspects ('Pros'), they also express several concerns and have lowered their overall rating in the updated review. The reviewer mentions that the paper needs 'further investigation/maturation' and that experiments are 'more preliminary'. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses of the paper without harsh criticism. They offer constructive feedback and explain their reasoning for the score adjustment in a considerate manner."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good empirical results', 'outperform AIRL by a convincing margin'), they ultimately lean towards rejecting the paper unless changes are made ('I lean on the side of rejecting unless...'). They also raise several concerns and questions about the methodology and results. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, balancing criticism with praise, and framing concerns as questions rather than accusations. They also provide constructive feedback and specific suggestions for improvement, which is considerate. The tone remains objective and focused on the content rather than making personal remarks.""]"
"[""The paper presents a coupled deep learning approach for generating realistic liquid simulation data that can be useful for real-time decision support applications. While this is a good applied paper with a large variety of experimental results, there is a significant lack of novelty from a machine learning perspective. \n\n1. The primary novelty here is in the problem formulation (e.g., defining cost function etc.) where two networks are used, one for learning appropriate deformation parameters and the other to generate the actual liquid shapes. This is an interesting idea to generate the required training data and build a generalizable model. \n\n2. But based on my understanding, this does not really explicitly incorporate the physical laws within the learning model and can't guarantee that the generated data would obey the physical laws and invariances. So, this is closer to a graphics approach and deep learning has been used before extensively in a similar manner for shape generation, shape transformation etc.    \n\n3. In terms of practical applications, to the best of my knowledge there are sophisticated physics-based and graphics based approaches that perform very fast fluid simulations. So, the authors need to provide accuracy and computation cost/time comparisons with such methods to establish the benefits of using a deep learning based surrogate model.   \n\nxxxxxxxxxxxxxxxxxxx\n\nI appreciate the rebuttals from the authors, updated my score, but I still believe (just like another reviewer) that this is better suited for a workshop or a conference like SIGGRAPH. "", ""This is an application paper on dense volumetric synthesis of liquids and smoke. Given densely registered 4D implicit surfaces (volumes over time) for a structured scene, a neural-network based model is used to interpolate simulations for novel scene conditions (e.g. position and size of dropped water ball). The interpolation model composes two components -- given these conditions, it first regresses weights combining a set of precomputed deformation fields, and then a second model regresses dense volumetric deformation corrections -- these are helpful as some events are not easily modeled with a set of basis deformations. \n\nI found the paper hard to read at first, since the paper is heavy on terminology, only really understood what is going on when I went through the examples in the appendix, which are helpful and then on a second read the content was clear and appears technically correct. I would advise considering defining in more detail early the problem setup (e.g. Fig 13 was helpful), explain some of the variables in context. \n\nThis is primarily an application paper on simulating liquids in controlled scenes using nets and appears novel in that narrow domain. The specific way deformations are composed -- using v_inv to backwards correct basis deformations, following up the mixing of those with a correction model -- is intuitive and is also something I see for the first time. \n\nThe experimental results are sufficient for simulating liquids/smoke, except I would like to also see a comparison to using deformation field network only, without its predecessor. This was done for Fig 6, but would be nice to also see it numerically in ablation in Fig. 4. Another useful experiment would be to vary the number of bases and/or the resolution of the deformation correction network and see the effects. \n\nMore importantly, it would be very helpful is to try this approach for modeling deforming object and body shapes for which there are many datasets (e.g. Shapenet). Right now the implicit surface deformation model is only tested on liquids examples, which limits the impact to that specialist domain -- it's a bit more of a SIGGRAPH type of paper than ICLR. \n\n---- Post author feedback comment ---- \nI raised my rating to 7 as the paper itself is solid, main concern as another reviewer points out is it may be a bit too specialist for ICLR. If the AC decides to reject based on this fact I am ok with that as well. \n\nI think it would be helpful to add more ablation (deformation-only results for all cases) and experiments with different numbers of bases in the final version. If that's added it will strengthen the paper. \n"", 'This paper introduces a deep learning approach for physical simulation. The approach combines two networks for synthesizing 4D data that represents 3D physical simulations. Here the first network outputs an initial guess, and the second network adds details. The first network utilizes a set of precomputed deformations, while the weights can be set to generate different output shapes. The precomputed deformations are applied in a recurrent manner. The second network is a variant of STN. \n\nThe results are impressive from the perspective of the current abilities of deep neural networks. The synthesized simulations are not physically accurate, but with certain visual realism. Experimental results are sufficient. \n\nHowever, it is also necessarily to add more intuitions to the current approach. First, it would be good to discuss why the current network design is desired. For example, when designing the first network, can we also design another neural network that applies the deformation backwards and enforce some consistency to improve the results? Also, many simulations use adaptive sampling (high-resolution near the surface and low-residual in the interior). Can we use an adaptive grid-structure (say Octree) to increase the resolution? \n\nAlso, is there a simple setting so that the current network design generates accurate results. If not, would increase the number of pre-computed deformations improve the approximation. If so, what would be the optimal basis for $u_i$? What is the tradeoff between using more basis for the first network and increasing the complexity of the second network?\n\nFor visualization, it would also good to show the 3D grid.\n\nOverall, it is good paper to see at ICLR.\n']","[-30, 60, 60]","[50, 70, 70]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('good applied paper', 'interesting idea'), they express significant concerns about the novelty and practical benefits of the approach. The overall tone is more critical than positive, especially in the final paragraph where they suggest the paper might be better suited for a workshop or different conference. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. They use phrases like 'I appreciate' and provide specific suggestions for improvement, which maintains a professional and courteous tone despite the critical content."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's novelty in its domain, describes the technical approach as 'intuitive', and states that the experimental results are 'sufficient'. The reviewer also raised their rating to 7 after author feedback, indicating a positive view. However, they do suggest several improvements and note that the paper might be too specialized for ICLR, which prevents a higher score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges improvements after author feedback. They use phrases like 'I would advise' and 'it would be helpful' when making suggestions, which maintains a polite tone. The reviewer also admits their initial difficulty in understanding the paper without blaming the authors, which shows consideration."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'good' and the results are 'impressive', while also noting that it's suitable for ICLR. They use phrases like 'The results are impressive' and 'Overall, it is good paper to see at ICLR.' However, it's not extremely positive as they also point out areas for improvement and raise questions. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'it would be good to discuss' and 'can we also design' which are polite ways of suggesting improvements. The reviewer maintains a professional and courteous tone, even when pointing out limitations or areas for further exploration.""]"
"[""Summary:\nThe paper presents techniques for training a non expansive network, which keeps the Lipchitz constant of all layers lower than 1. While being non-expansive, means are taken to preserve distance information better than standard networks. The architectural changes required w.r.t standard networks are minor, and the most interesting changes are made to the loss minimized. The main claim of the paper is that the method is robust against adversarial attacks of a certain kind. However, the results presented show that a) such robustness comes at a high cost of accuracy for standard examples, and b) even though the network is preferable to a previous alternative in combating adversarial examples, the accuracy obtained in the face of adversarial attacks is too low to be of practical value. Other properties of the networks, explored empirically, are that the confidence of the prediction is indicative of robustness (to adversarial attacks) and that the networks learn better in the presence of high label noise. \nIn short, this paper may be of interest to a sub-community interested in defense against certain types of adversarial attacks, even when the defense level is much too low to be practical. I am not part of this community, hence did not find this part very interesting. I believe the regularization results are of wider interest. However, to present this as the main contribution of L2NNN more work is required to find configuration which are resilient to overfit yet enable high training accuracy, and more diverse experiments are required.\nPros:\n+ the idea of non expansive network is interesting and important\n+ results indicate some advantages in fighting adversarial examples and label noise\nCons:\n- the results for fighting adversarial examples are not significant from a practical perspective\n- the results for copying with label noise are preliminary and require expansion with more experiments.\n- the method has costs in accuracy, which is lower than standard networks and this issue is not faced with enough attention\n- presentation clarity is medium: proofs for claims are missing, as well as relevant background on the relevant adversarial attacks. The choice to place the related work at the end also reduces presentation clarity.\n\nMore detailed comments:\nPages 1-3: In many places, small proofs are left to the reader as ‘straightforward’. Examples are: the claim in the introduction, in eq. 2, in section 2.2, section 2.3’ last line of page 3, etc.. While the claim are true (in the cases I tried to verify them long enough), this makes reading difficult and not fluent. For some of these claims I do not see the argument behind them. In general, I think proofs should be brought for claims, and short proofs (preferably) should be brought for small claims. Leaving every proof to the reader as an exercise is not a convenient strategy. \nPage 4: The loss is complex and its terms utility require empirical evidence. The third term is shown to be clearly useful, enabling a trade off between train accuracy and margin. However, the utility of terms 4) and 5) is not verified. Do we really need both these terms? Cannot we just stay with one?\nThe main claim is robustness w.r.t “white-box non targeted L2-bounded attacks”. This seems to be a very specific attack type, and it is not explained at all in the text. Hence it is hard to judge the value of this robustness. Explanation of adversarial attack kinds, and specifically of “white-box non targeted\nL2-bounded attacks” is required for this paper to be a stand alone readable paper. Similarly ‘L_\\infty’-bounded attacks, for which results are shown, should be explained.\nTable 1,2: First, the model architecture used in these experiments is not stated. Second, the accuracy of the ‘natural’ baseline classifier, at least in the MNist case, is somewhat low – much better results can be obtained with CNN on MNist. Third, the accuracies of the suggested robust models are very low compared to what can be obtained on these datatsets. Forth, while the accuracies under attack of the proposed method are better than those of Madri et al., both are quite poor and indicate that the classifier is not useful under attack (from a practical perspective).\nPage 6: The classifiers which share the work between an L2NNN network and a regular more accurate network may be interesting, as the accuracies reported for them are significantly higher than the L2NNN networks. However, the robustness scores are not reported for these classifiers, so it is not possible to judge if they lead to a practical and effective strategy.\nPage 7: For me, the results with partially random labels are the most interesting in the paper. The resistance of L2NNN to overfit and its ability to learn with very noisy data are considerably better than the suggested alternatives.\nRelevant work not mentioned “Spectral Norm Regularization for Improving the Generalizability of Deep Learning” - Yuichi Yoshida and Takeru Miyato, Arxiv, 2017.\n\nI have read the rebuttal.\nThe discussion was interesting, but I do not see a need to change my assessment.\nThe example of ad-blocking in indeed a case (the first I encounter) where l2- perturbated adversarial examples can be useful for cyber attack. The other ones are less relevant (the attacks are not based on adversarial attacks in the sense used in the paper: images crated with small gradient-direction perturbations). Anyway talking about 'attacks on a self-driving car' are still not neaningful to me: I do not understand what adversarial examples have to do with this.\nI do not find the analogy of 'rocket improvements and moon landing' convincing: in 69 rocket improvements were of high interest in multiple applications, and moon landing was visible over the corner. \n\n"", 'I read this paper with some excitement. The authors propose a very sensible idea: simultaneously maximizing the confidence gap and constraining the Lipschitz constant of the network, thus achieving a guarantee that no L2-bounded perturbation can alter the prediction so long as the perturbation is bounded by some function of the confidence gap. \n\nThe main idea consists of three parts:\n 1) smooth networks (fixed, low Lipschitz constant)\n (2) loss function that explicitly maximizes the confidence gap (distance between largest and second-largest logits). \n (3) “the network architecture restricts confidence gaps as little as possible. We will elaborate.”   \n\nThe first two conditions make plain sense. The third condition and subsequent elaborations are far too vague. What precisely is the property of restricting confidence gaps? At first glance this seems akin to the smoothness sought in property one. Even in the bulleted list, the authors owe the reader a clearer explanation.\n\nThe proposed model, denoted L2-nonexpansive neural networks (L2NNNs) and consists of a sensible form of Lipschitz-constant-enforcing weight regularization, a loss function that penalizes the confidence gap.\n\nTo address the third condition, the authors say only “we adapt various layers in new ways for the third condition, for example norm-pooling and two-sided ReLU, which will be presented later” which is far too vacuous. At this point the reader is exposed to the third condition for the second time and yet it remains shrouded in mystery. The authors should elaborate here and describe what precisely, if anything, this third condition consists of. If it is not rigorously defined but only a heuristic notion, that would be fine, but this should be communicated clearly to the reader. \n\nA following paragraph introduces the notion of “preserving distance”. However, what follows is too informal a discussion, and the rigorous definition never materializes. The authors say in one place “a network that maximizes confidence gaps well must be one that preserves distance well”. In this case, why do we need the third condition at all if the second condition appears to be sufficient?\n\nIn the next sections the authors describe the methods in greater detail and summarize their results. I have placed some more specific nittier comments in the ***small issues*** section below. But comment hear on the empirical findings.\n\nOne undersold finding here is that the existing methods (including the widely-believed-to-be-robust method due to MAdry 2017) that appear robust under FGSM attacks break badly under iterated attacks, and that the attacks go stronger up to 1M iterations, bringing accuracy below 10%. \n\nIn contrast the proposed method reaches 24% accuracy, which isn’t magnificent, but does appear to outperform the model due to Madry. A comparison against the method due to Kolter & Wong seems in order. The authors do not implement methods based on the adversarial polytope due to their present un-scalability, but that argument would be better supported if the authors were addressing larger models on harder datasets (vs MNIST and CIFAR10).\n\nIn short, I like the main ideas in this paper although some more empirical elbow grease is in order, the third condition needs to be discussed more rigorously or discarded. Additionally the choice of loss function should be better justified. Why do we need the original cross-entropy objective at all. Why not directly optimize the confidence gap? Did the authors try this? Did it work? Apologies if I missed this detail. Overall, I am interested in the development of this paper and would like to give it a higher vote but believe the authors have a bit more work to do to make this an easier decision. Looking forward to reading the rebuttal.\n\n\n***Small issues***\nPage 1 “nonexpansive neural networks (L2NNN)” for agreement on pluralization, should be “L2NNNs”\n\n“They generalize better from noisy training labels than ordinary networks: for example, when 75% of MNIST training labels are randomized, an L2NNN still achieves 93.1% accuracy on the test set”\nWhen you make a claim about accuracy of a proposed model, it must be made in reference to a standard model, even in the intro. It’s well-known in general that DNNs perform well even under large amounts of label noise. Hard to say without reference if 93.1% represents a significant improvement.\n\nRepeated phrase on page 2:\n“How to adapt subtleties like recursion and splitting-reconvergence is included in the appendix.”\n“Discussions on splitting-reconvergence, recursion and normalization are in the appendix.”\n\nInputs to softmax cross-entropy should be both a set of logits and the label -- here the way the function is used in the notation does not match the proper function signature\n\nFigure --- do not put “Model1, Model2, Model3, Model4”. This is unreadable. Put some shortname and then define it in the caption. Once one knows the abbreviations, they should be able to look at the figure and understand it without constantly referencing the caption. \n\nTable 1-4 should be at the top of the page and arranged in a grid.  This wrapfigure floating in the middle of the page, while purely a cosmetic issue that should not bear on our deliberations, tortures the template unnecessarily, turning the middle 80% of page 5 into a one-column page unnecessarily.\n\nTable 4 should show comparison to Madry model. Also this is why you need a shortname in the legend. In order to understand table 4, the reader has to consult the caption for tables 1 and 2. \n\n“It is an important property that an L2NNN has an easily accessible measurement on how robust its decisions are”\nI AGREE!', ""This paper presents a combination of methods that, together, yield neural networks that are robust to small changes in L2 distance. The main idea is to ensure that changing the input by a bounded L2 distance never changes the output by more than the same L2 distance. Then, the difference between the highest-scoring class and the second-highest scoring class provides a bound on how much the input must change. The trivial way to do this is to rescale the final output layer so that all of the magnitudes are very small; however, this would give no additional robustness at all. To counteract this, the paper introduces several additional heuristics for increasing the gap between the highest-scoring class and the second-highest scoring one. Adversarial training can be used to make the models even more robust. \n\nExperimental results on MNIST and CIFAR look impressive, although most are in terms of L2 distance, while most previous work optimizes L_infinity distance.\n\nThe methods described by this paper are similar to max-margin training, which is already known to be optimally robust to L2 perturbations for linear models (e.g., Xu et al. (2009)). This paper would be stronger with more discussion and analysis of this connection, although that might be work for a future paper.\n\nAlthough the method relies heavily on heuristics, the empirical results are promising. The analysis of the contribution of the heuristics is fairly thorough as well. The MNIST results are strong. The CIFAR results show improved robustness, though at reduced accuracy on natural images. A combination of robust and non-robust classifiers improves the accuracy somewhat.\n\nOverall, this is interesting work with promising empirical results. The biggest weaknesses are:\n\n- Limited theory. The loss function is particularly strange. \n\n- The majority of the comparisons focus on L2-robustness, but are comparing to a model optimized for L_infinity-robustness. (Thankfully, the authors also do some comparisons on L_infinity-robustness.)\n\n- Robustness comes at a cost in accuracy, though this is not uncommon for adversarial training.\n\nThe biggest strengths are:\n\n- Strong empirical robustness\n\n- Analysis of combinations of methods and their interactions: different loss function, different architecture, different weight constraints, and adversarial training are all evaluated together and separately.\n\n- Wide variety of experiments, including generalization on training data with noisy labels and analysis of the confidence gaps.\n\n\n\nQuestions for the authors:\n\n- For equation (4) in the loss function, why would rescaling the layers in the middle of the network be equivalent to a linear transformation (u1, u2, ..., u_K) of the output?\n\n- In equation (6), what is the average averaging over?\n\n- The connection between confidence gap and robustness is discussed empirically, as a correlation, rather than theoretically, as a bound.  Doesn't the confidence gap give a lower bound on the minimum perturbation to change the predicted class?\n\n---------\n\nEDIT: After the author response, I remain positive about this paper. In addition to addressing my concerns, I admire the authors' patience in answering the concerns of other reviewers and commenters. I think that this is a solid paper that makes a good contribution to the literature on adversarial machine learning.""]","[-30, 20, 70]","[20, 60, 80]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('pros'), the overall tone is critical and highlights several significant shortcomings ('cons'). The reviewer expresses that the paper's main claims are not practically significant and that more work is required. However, it's not entirely negative as they do recognize some interesting aspects of the work. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, offering constructive criticism without using harsh language. They use phrases like 'may be of interest' and 'I believe' which soften the critique. The reviewer also balances negative points with positive ones, showing a fair approach. However, the politeness doesn't reach higher levels as the review is quite direct in its criticisms without much sugar-coating."", ""The sentiment score is slightly positive (20) because the reviewer expresses initial excitement about the paper and finds the main ideas sensible and interesting. However, they also point out several areas needing improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses interest in future developments. They use phrases like 'I like the main ideas' and 'Looking forward to reading the rebuttal,' which contribute to a polite tone. The reviewer also balances critique with praise and provides detailed feedback, demonstrating engagement with the work."", ""The sentiment score is 70 (positive) because the reviewer expresses overall positive sentiment towards the paper, noting 'interesting work with promising empirical results' and 'strong empirical robustness'. They also mention 'impressive' experimental results and a 'wide variety of experiments'. While they do point out some weaknesses, these are presented as constructive criticism rather than major flaws. The final edit reinforces the positive sentiment, stating 'I remain positive about this paper' and 'this is a solid paper that makes a good contribution'. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They balance praise with constructive criticism, ask thoughtful questions for the authors, and acknowledge the authors' efforts in responding to concerns. The tone is consistently courteous and academic, avoiding any harsh or dismissive language.""]"
"['This paper shows that deep ""narrow"" neural networks (i.e. all hidden layers have maximum width at most the input dimension) with a variety of activation functions, including ReLU and sigmoid, can only learn functions with unbounded level set components, and thus cannot be a universal approximator. This complements previous work, such as Nguyen et. al 2018 which study connectivity of decision regions and Lu et. al 2017 on ReLU networks in different ways.\n\nOverall the paper is clearly written and technically sound. The result itself may not be super novel as noted in the related work but it\'s still a strict improvement over previous results which is often constrained to ReLU activation function. Moreover, the proofs of this paper are really nice and elegant. Compared to other work on approximation capability of neural networks, it can tell us in a more intuitive way and explicitly which class of functions/problems cannot be learned by neural networks if none of their layers have more neurons than the input dimension, which might be helpful in practice. Given the fact that there are not many previous work that take a similar approach in this direction, I\'m happy to vote for accepting this paper.  \n\nMinor comments:\nThe proof of Lemma 3 should be given for completeness. I guess this can be done more easily by setting delta=epsilon, A_0=A and A_{i+1}=epsilon-neighborhood of f_i(A_i)?\npage7: the square brackets in ""...g(x\'\')=[y-epsilon,y+epsilon]..."" should be open brackets.\npage7:""By Lemma 4, every function in N_n has bounded level components..."" -> ""..unbounded...""', 'This is a very nice paper contributing to what I consider a relatively underexplored but potentially very promising research direction. The title of the paper in my opinion undersells the result which is not only that ""deep skinny neural networks"" are not universal approximators, but that the class of functions which cannot be approximated includes a set of practically relevant classifiers as illustrated by the figure on page 8. The presentation is extremely clear with helpful illustrations and toy but insightful experiments.\n\nMy current rating of this paper is based on assuming that the following concerns will be addressed. I will adjust the score accordingly after authors\' reply.\n\n\n\nMain:\n\n- A very similar result can be found in Theorem 7 of Beise et al.\'s ""On decision regions of narrow deep neural networks"" from July 2018 ( https://arxiv.org/abs/1807.01194 )\n\tSome differences:\n\n\t\t- The other paper considers connected whereas this paper considers path-connected components (the former is more general).\n\t\t- The other paper only considers multi-label classification, this paper is relevant to all classification and regression problems (the latter is more general).\n\t\t- The other paper requires that the activation function is ""strictly monotonic or ReLU"" whereas this paper allows ""uniformly approximable with one-to-one functions"" activations (the latter is more general).\n\n\tThe result in this paper seems slightly more general but largely similar. Can you please comment on the differences/relation to the other paper?\n\n\n- Proof of Lemma 4:  ""Thus the composition \\hat{f} is also one-to-one, and therefore a homeomorphism from R^n onto its image I_{\\hat{f}}"". Is it not necessary that \\hat{f} has a continuous inverse in order to be a homeomorphism? I do not immediately see whether the class of activation functions considered in this paper implies that this condition is satisfied. Please clarify. \n\n\n\nMinor:\n\n- Proof of Lemma 5: It seems g is assumed to be continuous at several places (e.g. ""... level sets of are closed as subsets of R^n ..."" seems to assume that pre-image of a closed set under g is closed, or later ""This implies g(F) is a compact subset of R ...""). Perhaps you are assuming that M is a set of continuous functions and using the fact that uniform limit of continuous functions is continuous? Please clarify.\n\n- On p.4: ""This is fairly immediate from the assumptions on \\varphi and the fact that singular transition matrices can be approximated by non-singular ones."" Is the second part of the sentence using the assumption that the input space is compact? Please clarify.\n\n- Second line in Section 5: i < k should probably be i < \\kappa.', ""This paper proves a theoretical limitation of narrow-and-deep neural networks. It shows that, for any function that can be approximated by such networks, its level set (or decision boundary for binary classification) must be unbounded. The conclusion means that if some problem's decision boundary is a closed set, then it cannot be represented by such narrow networks.\n\nThe intuition is relatively simple. Under the assumptions of the paper, the neural network can always be approximated by a one-to-one mapping followed by a linear projection. The image of the one-to-one mapping is homeomorphic to R^n, so that it must be an open topological ball. The intersection of this open ball with a linear hyperplane must include the boundary of the ball, thus it extends to infinity in the original input space. The critical assumptions here, which guarantees the one-to-one property of the network, are: 1) the network is narrow, and 2) the activation function can be approximated by a one-to-one function.\n\nThe authors claim that 2) captures a large family of activation functions. However, it does exclude some popular activation families, such as the polynomial activation, which were proven effective in multiple areas. As a concrete example, the simple function f(x1,x2) = x_1^2 + x_2^2 has bounded level sets, but it can be represented by a narrow 2-layer neural network with the quadratic activation.\n\nOverall, I feel that the result is interesting but it depends on a strong assumption and doesn't capture all interesting cases. It is also not clear how this theoretical result can shed insight on the empirical study of neural networks. \n\n""]","[80, 80, -20]","[70, 90, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, noting it is 'clearly written and technically sound', has 'nice and elegant' proofs, and the reviewer is 'happy to vote for accepting this paper'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their minor comments politely. The reviewer acknowledges the paper's strengths while providing gentle suggestions for improvement, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 80 (positive) because the reviewer starts by calling it a 'very nice paper' and praises its clarity, helpfulness, and insightfulness. They also mention that the paper's title undersells its results, implying the work is even more valuable than it claims. The score is not 100 because the reviewer does have some concerns and requests for clarification.\n\nThe politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They begin with praise, frame their concerns as requests for clarification or additional information rather than criticisms, and use phrases like 'please clarify' and 'can you please comment'. The reviewer also acknowledges that their rating is contingent on these concerns being addressed, showing consideration for the authors' potential responses."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting result, they express significant reservations about its limitations and applicability. The reviewer points out that the result depends on strong assumptions, doesn't capture all interesting cases, and its practical relevance is unclear. However, the score is not deeply negative as the reviewer does recognize the paper's theoretical contribution.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their critiques, avoiding harsh or dismissive statements. Phrases like 'I feel that' and 'Overall' soften the criticism. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a polite approach in academic discourse.""]"
"['This paper proposed an approximation technique to learn the large-scale graph with the desired edge density. It was well-written and contains thorough experimental results and analysis.\n\nA minor drawback is that while this work was motivated by the use of k-NN graph in graph convolution network (GCN), there was no evidence on how well A-NN performs in compare to k-NN with GCN.', ""The paper proposes a scalable approximate calculation of graph construction. Based on the sparse optimization formulation of a graph construction, the authors provide a way to select parameter automatically based on user desired connectivity of graph.\n\nThe problem setting, graph construction, is significant for the wide range of ML community. Overall, however, advantage/novelty of the proposed method is unclear for me.\n\nScalability is main advantage of the proposed method, but the authors just employed known nearest neighbor approximation methods, and thus here no technical novelty is shown.\n\nI couldn't find connection between Section 3 and 4, these seem to be an independent topics. Main claim of the paper would be in Section 3, but the novelty would be weak as mentioned above.\n\nSolving reverse problem is interesting, but it just provide the parameter value range which results in given sparsity level k. This doesn't provide exact value of \\theta (and user still have to specify k), and selection would be possible easily without the analytical formula (e.g., by following the regularization path)\n\nPerformance verification is not convincing. Showing accuracy gain for more wide variety of datasets would be convincing."", 'Learning graphs from data fine tunes standard similarity graph constructions such as k-nearest neighbor graphs.  \nThere has been a line of research works that focuses on learning graphs and that shows that this results in superior\nresults in various machine learning tasks.  The current state-of-the-art method is the method proposed by Kalofolias, \nwhich however is slow.   The authors suggest a method to avoid searching for the parameters that achieve a desired\nlevel of sparsity by providing closed a formula. The parameter that determines the sparsity is theta, see proposition 1 on page 4. This was originally shown by Kalofolias. To achieve their goal, the authors first consider the degree of any given node by looking at equation (8), page 4. They prove theorem 1, that is intuitive and  provides the form of the optimal \nweights that connect this node to the rest of the nodes in the graph.  The proof is based on applying the KKT conditions on\nthe objective (8), with the single constraint that there are no negative weights.  Finally, since we care about the \nsparsity of the graph as a whole, the authors use the average of the parameter theta over all nodes. The authors perform \nexperiments on real-world graphs, and show basic properties of their method, as well as the main source of mistakes ,i.e., disconnected nodes, figure 5.\n\nEssentially, this paper starts from the work of Kalofolias  and improves it significantly. This by itself is \na neat contribution, but the authors could improve their paper by showing a more complete view  of graph \nlearning methods, with respect to the quality of the produced graphs and the scalability. I find this aspect of the paper narrowing its contribution, hence my evaluation. Some remarks follow.\n\n- A different family of graph learning methods is based on the objective ||LX||_F^2 or equivalently tr(X^TLLX). \nFor this objective, Daitch et al. proved certain neat properties, such as the existence of a sparse optimal graph. \nThis allows Daitch et al. to solve the primal dual significantly faster than O(n^2) since by their theorem, \nO(nd) edges are required where d is the dimension of the data points. When d is large, a random projection can be applied. \nThe paper should compare with this family of methods that are more scalable both with respect to the accuracy, \nand to the runtimes. \n\n- While the proposed method scales significantly better than Kalofolias, the datasets used are small. \n\n- Using LSH for k-nn graphs results in a  scalable, practical way to construct similarity graphs. The authors should cite\nthe following related work, and compare with such methods.\n“Efficient K-Nearest Neighbor Graph Construction for Generic Similarity Measures“ by Dong, Charikar, Li. \n\n- An interesting experiment would be to inject outliers in the dataset, or use some dataset with outliers. \nWould this affect the tightness of the interval in equation (17)? ']","[80, -40, 50]","[70, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well-written' and notes that it contains 'thorough experimental results and analysis'. The only criticism is described as a 'minor drawback', indicating an overall positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before mentioning the drawback. The criticism is presented constructively, suggesting an area for improvement rather than harshly criticizing. The tone is professional and courteous throughout, without any rude or dismissive language."", ""The sentiment score is -40 because the reviewer expresses several concerns and criticisms about the paper, such as unclear advantage/novelty, weak technical novelty, and unconvincing performance verification. However, they do acknowledge the significance of the problem setting and that some aspects are interesting, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses relatively neutral language and avoids harsh criticism. They present their concerns in a professional manner, using phrases like 'unclear for me' and 'would be convincing' rather than more confrontational language. The reviewer also acknowledges some positive aspects of the work, which contributes to the slightly positive politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution as 'neat' and an improvement on previous work, but also suggests areas for improvement and expansion. The reviewer's tone is generally constructive, recognizing the value of the work while providing specific suggestions for enhancement. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as suggestions for improvement rather than direct attacks. Phrases like 'the authors could improve their paper by...' and 'An interesting experiment would be...' demonstrate a considerate approach to feedback. The review maintains a professional and objective tone, focusing on the content rather than making personal comments.""]"
"['This work extends on [1] by constructing CNN filters using Fourier-Bessel (FB) bases for rotation equivariant networks. Additionally to [1] it extends the process with using SO(2) bases which allow to learn combination of rotated FB bases and ultimately achieve good performance with less parameters than standard CNN networks thanks to filter truncation.\n\nIn general, this work is well written and shows interesting results. However it lacks context with regards to other existing works. For example [2] also uses steerable filters for achieving rotation equivariance, however with different steerable bases (rotation harmonics instead of FB). It would be useful to clarify why FB bases are more appropriate for truncation, eventually providing empirical evidence (even though rotation harmonics would probably need more parameters). Authors mention [2], however disregard it due to computational complexity, which would be the same if the rotation harmonics bases were truncated as well.\n\nSimilarly, this work is not strong in evaluating against existing methods. It provides evaluation of the vanilla group equivariant networks in a similar configuration, but due to design choices in the training and test set, it is not possible to compare it against other algorithms and other steerable bases such as those from [2]. This degrades the results slightly as it does not allow to verify the baseline results from other works.\n\nAdditionally, it would be useful to provide an ablation study which would show how important the bases in SO(2) are important for the model accuracy. This would allow to compare the results against the [1] as the FB filters are steerable as well (Equation 4).\n\nIt is hard to reach a final rating for this submission. On one hand, it can be seen as an incremental improvement of [1] for a new domain of tasks, without a thorough comparison against existing methods. On the other hand, the paper is well written and the results look promising - evaluation verifies that the algorithm performs well in multiple tasks with a fraction of parameters.\n\nConsidering that authors plan to release the source code and that this conference aims for publishing novel ideas (and the goal of this work is to achieve rotation equivariance with less parameters, which hasn\'t been tackled before), I am inclined towards acceptance of this paper, even though the experiments can be significantly improved.\n\nUnfortunately, I was not able to verify correctness of the provided proofs.\n\nAdditional minor issues:\n* The paper does not specify what FB bases exactly are being used (such as in [table 1;1]), mainly it does not seem to specify the SO(2) bases.\n* It would be useful to visualise K and K_\\alpha in Figure 1.\n* Citations, if not part of the sentence, should be in parentheses to improve readability (\\citep for natbib).\n* On page 8, end of first paragraph - wrong reference (see S.M.)\n* L, in section 2.3 is not defined.\n\n[1] Qiu, Qiang, et al. ""DCFNet: Deep Neural Network with Decomposed Convolutional Filters."", ICML 2018\n[2] Weiler, Maurice, et al. “Learning Steerable Filters for Rotation Equivariant CNNs.” CVPR 2018\n', 'Group-equivariant deep networks are used as a solution for rotation-equivariance in CNNs. However, they are computationally expensive as the number of filters increases by a factor proportional to the number of groups. Inspired by ideas of filter decomposition used in CNN model compression, the authors of this work instead propose to use steerable filters across space and rotation, as basis filters for achieving rotation-equivariance, which leads to computational efficiency. \n\nThe authors show improved accuracy and model compression with their proposed approach versus regular CNNs for several different tasks (MNIST, CIFAR, autoencoders and face recognition) for rotated and upright images.\n\nFurthermore the authors theoretically prove and demonstrate empirically (via multiple experiments) the group equivariance property and the representational stability under input variations of their proposed architecture. \n\nThe work is novel and it solves an open research problem.\n\nHowever, the one major criticism of the work is that in the experimental section, especially for the rotated MNIST and rotated face recognition tasks, the authors should compare the accuracy of their method with the latest state-of-the-art group-equivariant deep networks instead of just regular CNNs. This will help to truly understand whether their method is superior or comparable to the more computationally expensive group-equivariant networks that are specifically designed to handle rotations in terms of accuracy as well or not. The regular CCNs, which are not designed to handle rotations, are obviously bound to be inferior to their approach.\n\n', 'Summary:\nThis paper combines the benefits of using joint steerable filters (using the SO(2) group) for designing rotation-equivariant CNNs with those of decomposing the filters (using Fourier-Bessel bases) for reducing the computational complexity. In addition, this leads to a compressed model and filter regularization. The authors give theoretical guarantees on the rotation equivariance and representation stability with respect to in and out of plane rotation. Empirical results show that the model attains better accuracy compared to CNNs and non-rotation-equivariant deep networks while using fewer parameters and also performs similarly to a rotation-equivariant model with much bigger capacity.\n\nPros:\n- Theoretical guarantees, elegant approach\n- Good empirical results compared to other models\n- Desirable properties: rotation-equivariance, lower computational complexity, fewer parameters, robustness and guaranteed stability to deformations\n\nCons:\n- Somewhat incremental technical novelty: combination of two previously published methods (Qiu et al. 2018 & Weiler et al. 2017)\n\nComments:\n1. I believe the related work section can be improved by explaining more clearly the connection between your work and the cited ones and emphasizing the advantages and limitations of RotDCF compared to other methods In particular, a reader should be able to precisely understand what is the novelty of this work is and what were the technical challenges in combining previously published ideas (such as DCF and SFCNN) \n2. How do you determine the truncation in practice? How robust is the method to this choice? What are the trade-offs between using a value that is too low or too high? It would be interesting to show how performance and complexity vary with this parameter\n3. It would also be helpful to have a discussion on choosing the parameters K_{alpha} and N_{theta} and how this affects the performance, computational complexity and number of parameters. This would provide more intuition on the limits of this method and the types of data it can be used for\n4. In section 2.3, it would be helpful to specify an estimated range for the parameter reduction from the non-bases rotation-equivariant CNN to RotDCF (similar to the ½ factor from RotDCF to regular CNN) \n5. Eq. (4) seems to be missing the definition of R_{m,q}\n6. The notation for the supplementary material was confusing at times. I would suggest using the more standard notation for the appendix which can also be a more specific reference (e.g. A.1, A.2, etc.)\n\n\n\n\n\n']","[50, 70, 70]","[70, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is 'well written and shows interesting results' and is 'inclined towards acceptance'. However, they also point out several limitations and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions positively (e.g., 'it would be useful to...'). They also acknowledge the paper's strengths alongside its weaknesses. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out issues."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the work, describing it as 'novel' and solving 'an open research problem'. They praise the authors' theoretical proofs and empirical demonstrations. The only major criticism is presented constructively as a suggestion for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' contributions and framing their criticism as a suggestion rather than a demand. The phrase 'However, the one major criticism' is direct but not impolite, and the reviewer explains their reasoning clearly without using harsh or dismissive language."", ""The sentiment score is 70 (positive) because the review begins with a summary that highlights the paper's strengths, including theoretical guarantees, good empirical results, and desirable properties. The reviewer lists more pros than cons, indicating a generally positive view. The cons mentioned are relatively minor, describing the work as 'somewhat incremental'. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions for improvement. The comments are framed as helpful recommendations rather than criticisms, using phrases like 'I believe', 'It would be helpful', and 'It would be interesting'. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback.""]"
"['Summarization:\nThis paper presents a framework (called FX Network) of quantizing the weights and gradients of neural networks, based on five quantization criteria proposed in literature. The proposed framework can quantize the neural network obtaining a minimal or close-to-minimal error for a pre-specified precision level.\n\n\nPros:\n- The proposed FX network can quantize all variables including both network weights and back-propagated gradients.\n- Promising results have been obtained. Experimental results on CIFAR have shown that the proposed quantization framework had reduced the representational cost, computational cost, and the communication  by up to 6x, 8x, and 4x, respectively, compared to the 32-b FL baseline and related works.\n- The paper is well written.\n\n\n\n\nCons:\n- The experiment results showed in Figure 3 are quite confusing: why do the curves of the test error and loss suddenly drop at epoch 100? Explanation is needed. \n\n- This proposed quantization method require to pre-train a network with high precision in advance, similarly as the student-teacher framework or knowledge distillation. Different from BN and TG, FX network requires to pre-train a 32-b floating-point network, which requires more extra computational costs. \n\n- How does the quantization method compare with strategies like parameter pruning and sharing? It is better to see a discussion with them. It is also suggested to show the improvement of the proposed framework in terms of inference time during test. \n\n', 'This papers introduces a quantization scheme for the back-propagation algorithm to reduce the bit size in the target neural networks. While the paper introduces one way to bring the quantization inside the training procedure and shows the tradeoff between number of bits and the accuracy, the paper is poorly written so it is hard to understand the paper\'s main proposal.\nSo I would recommend to re-organize the paper and introduce one toy example to illustrate how the proposed method works in the training time and the inference time.\nCurrently the important part, the overall architecture, is explained in the appendix, not in the main paper.\nThe main idea is rather simple, to introduce a quantizer in various components in the back-propagation algorithm.\nI think we need a clear explanation on ""how to"" quantize each tensor in each quantizer, instead of many obscure terms in the section 2 and 3. Also the important numbers are in the appendix C, but their meanings are hard to understand.\n\nAlso in general, quantization is one way of reducing training and inference computational complexity. There are other ways of achieving the same purpose such as distillation to a smaller network (less parameters), etc, so in order to argue the computational gains over this obvious approach, we need a training time and inference time benchmark. \n', ""This paper proposes a FX (fixed point) framework to calculate the reduced bit numbers, which can (I) use float numbers with the reduced bits to represent each NN layer's weight values W_l, activation values A_l, gradients of weights G_l^W, gradients of nodes G_{l+1}^A, and the cumulated (updated) weight W_l^(acc); (II) with the reduced representations, the training loss and testing loss will not be sacrificed much comparing with the original FL framework, where each float number is 32-bit.\n\nSome positive points:\n(a) The proposed FX framework can reduce cost for both inference and training.\n(b) The experimental results looks promising.\n(c) The Criteria 1-5 seems systematic and the conditions in Claim 1 can be used to calculate the required bit numbers. The author proposed an implementation of Claim 1.\n\nSome negative points / questions:\n\n(a) The most important part of the paper is Criteria 1-5. Criteria 1 generalizes the idea from Sakr et al. 2017, to force the contributions of weight and activation almost at the same order, which seems reasonable to make the mismatch budget p_m smallest. But the other criteria (with their corresponding notions, e.g., Criterion 2 and the concept of clipping rate \\beta) are introduced in a way which is not clear enough and make the audience confused. For example, why is clipping rate \\beta and relative quantization bias \\eta is needed here and what is their relationship with the usual weight gradient clip norm (5% target \\beta and 1% \\eta target correspond to what order of clip norm)? Criteria 4 & 5 are introduced in the same way with one sentence explained like heuristics. They seem to me are introduced just for reducing corresponding bit numbers. More motivation and explanation of introducing these criteria and notions are needed.\n\n(b) For W_l and A_l, the necessary bit numbers are calculated using Criteria 1 & EFQN condition. But for gradients, their PDRs and Deltas are calculated using other criteria & conditions. Then how to calculate their bit numbers from PDRs and Deltas?\n\n(c) The proof of Lemma 2 & 3 directly used CLT for mini-batch average gradient items. CLT is for asymptotic case and in finite sample case it is not true. So it is heuristic calculation rather than lemma with proof (If seeking proof then some finite-sample argument like Berry-Esseen theorem is needed to quantify the probability of the average is not Gaussian). And what is the mini-batch size used here? If it is too small then probably the error of taking the mini-batch SGD as Gaussian will be large.\n\n(d) The importance/minimality of each individual bit number in C_o is not investigated, and the claim of the near minimality of C_o cannot hold according to the current experiments. The experiments of C_{+1} and C_{-1} do not exclude the possibility that some items (not the whole C_o) are minimal. More experiments (changing one or more items while fixing the others) are needed to show every item in C_o is minimal (or not). And which one of them is the most important for training/testing (how sensitive the training/testing performance is to each bit number)?\x10 Also in C_{-1} and C_{+1}, are target \\beta, \\eta changed? What are these changed values?\n\n(e) From the Claim 1, it seems that these bit numbers are sufficient, and smaller than necessary to get the same training/testing performance (e.g., from the proof of Lemma 3, with the result \\eta = 0.4% < 1%). So one question is what kind of \\beta and \\eta target are necessary for preserving the performance and what corresponding bit numbers are necessary to achieve the necessary \\beta and \\eta values?\n\n(f) The computational cost definition looks different with Eq (3) in Sakr et al. 2017. Why?\n\nSome typos:\n1.Figure 2(a), B_{A_l} is 8 for Layer 1, but 9 in Appendix Table.\n2. In the last third paragraph of Page 7, is it 2.6 = (148/56.5) instead of 2.6 * (148/56.5)? Same for the following numbers.\n\n========================================\nRevision: I have read the reply from the authors and it clarified several matters. I adjusted my rating of this paper (from 6 to 7).""]","[50, -50, 50]","[70, 20, 75]","[""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a balanced list of pros and cons. The pros highlight the paper's strengths and promising results, while the cons point out areas for improvement without being overly critical. The overall tone suggests the reviewer sees value in the work but also identifies areas for enhancement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper is 'well written' and using phrases like 'it is better to see' and 'it is suggested' when making recommendations, rather than using more demanding language. The reviewer also presents criticisms as questions or suggestions for improvement rather than direct attacks on the work."", ""The sentiment score is -50 because the reviewer expresses significant criticism about the paper being 'poorly written' and 'hard to understand', while acknowledging that it introduces a new method. This indicates a negative sentiment, but not entirely dismissive. The politeness score is 20 because the reviewer uses professional language and offers constructive suggestions for improvement, such as 're-organize the paper' and 'introduce one toy example'. However, the directness of the criticism ('poorly written') prevents a higher politeness score. The reviewer maintains a respectful tone throughout, balancing criticism with recommendations, which contributes to a slightly positive politeness score."", ""The sentiment score is 50 (slightly positive) because the review begins with acknowledging positive aspects of the paper, such as the promising experimental results and systematic approach. However, it also raises several critical points and questions, indicating a balanced view. The reviewer's decision to adjust the rating from 6 to 7 after receiving clarifications from the authors further supports a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct attacks. The reviewer also acknowledges the authors' responses and shows willingness to adjust their opinion based on new information. The use of phrases like 'Some positive points' and 'Some negative points / questions' helps to structure the feedback in a constructive manner.""]"
"['This paper provides theoretical analysis for two kinds of straight-through estimation (STE) for activation bianrized neural networks. It is theoretically shown that the ReLU STE has better convergence properties the identity STE,  by studying the properties of the orientation and norm of the course gradients for STE.\n\nWhile the paper presents many theoretical results which might be useful for the community, they are not organized very well.  It is a bit hard for readers to quickly find the most important theoretical results.  Moreover, some symbols are used without definition, e.g. g_{relu} is used before being defined in sec 3.1. The discussions for most theoretical results are very short or not organized well, making the whole paper hard to follow,  e.g., ""the key observation ..."" after Lemma 4 is actually not about the Lemma 4 above, but Lemma 5 in the next Lemma.  Another major concern is that activation quantization is usually used in combination with weight quantization.  It would be more useful if weight and activation quantizations can be analyzed together.\n\nClarity in the experiment part can also be further improved. From Table 1, the clipped ReLU STE has the best performance, however, there is no theoretical analysis for it. For ResNet-20 with 2-bit activation, the training loss/accuracy results of vanilla ReLU is much worse than clipped ReLU, is there any explanation for this?  For the discussion in sec 4.2, what information does it want to convey?  What is the ""normal schedule of learning rate""? What if the small learning rate 1e-5 is kept after 20 epochs?\n\nTypo: The last sentence on page 3, the definition of y*.\n\n------------------------\n\nThe author response have addressed most of my concerns. Thus I have increased my score. ', 'Summary:\nThe paper presents an analysis of training single-layer hard-threshold (binary activation) networks for regression with a mean-squared loss function using two different straight-through estimators: the original identity-function STE and a ReLU-based STE. The paper demonstrates that training with the latter against the population loss is guaranteed to converge to a critical point, whereas using the former can cause instability in the training.\n\n    Pros:\n        - Interesting analysis that provides a novel method for determining which gradient estimators are effective for training single-layer binarized networks and which are not.\n        - The paper is fairly clear, despite being quite technical; however, I did find myself jumping around a lot to refer back to previous results or definitions so the ordering and layout could definitely be improved.\n\n    Cons:\n        - Related work is missing and some claims in the paper are wrong as a result.\n        - A single-layer binarized network is essentially just a perceptron, which we know how to learn already, so it’s not clear how this analysis will benefit analysis of multi-layer binarized networks (however, since it seems like a novel analysis approach, it’s possible that it can be extended). This connection is not made in the paper.\n        - The paper does not analyze the most common and successful straight-through estimator: the saturated straight-through estimator, which uses the derivative of the hard_tanh activation (e.g., see [2]) and is a shifted and scaled version of the clipped ReLU STE.\n\nOverall, I like the paper but it has too many issues currently for me to give it a high score. However, if my questions and comments are addressed sufficiently, I would be happy to improve my score.\n\n\nDetailed questions and comments:\n\n1.\tThe claim that “we make the first theoretical justification for the concept of STE” is wrong and should be significantly toned down and clarified. Bengio et al. (2013), which this paper cites, provides some theoretical justification already, as do papers on target propagation, such as [1] and [2]. These, as well as additional papers cited in [2] are quite relevant and should also be cited and discussed.\n\n2.\tThe claim that “it is not the gradient of any function” is also wrong. Each STE is the gradient of a particular function, but is not the gradient of the function used in the forward pass. Please clarify.\n\n3.\tThe single-layer binarized network architecture studied in this paper can equivalently be framed as a linear function of a collection of single-layer perceptrons with shared weights. Obviously, much work has been done on analyzing the perceptron architecture. Why is none of it discussed in this paper? How does that work relate to the work done in this paper? How does the convolutional layer used here change the results of that related work? \n\n4.\t(a) Is there an intuition for why the derivative of the ReLU performs better (i.e., converges) better than the identity? Why does clipping the bottom make it work better? I do not see this explained in the text anywhere and it would be helpful to include this. \n(b) Further, depending on the reasoning given, it seems that clipping the top may also be useful (as in the clipped ReLU, which is a shifted and scaled version of the saturated STE discussed in Hubara et al. and [2]). Does your analysis extend to this STE? This would be very useful, as the SSTE/clipped ReLU is the most commonly used STE and the most empirically successful (as validated by your own experiments, as well as in previous work on training binary networks). Also, the SSTE/clipped ReLU is an even better approximation of the step function.\n(c) Cai et al. (2017) is not the first use of the clipped ReLU activation function, since it is equivalent to the SSTE when using sign(x) \\in {-1, +1} instead of your activation function (\\sigma(x) \\in {0, 1}) (i.e., you can shift and scale everything to get equivalent results).\n\n5.\tIn section 3.1, you mention that when using the derivative of the ReLU for the STE then \\mu`(x) = \\sigma(x). Is this just a coincidence or does this fact help with convergence?\n\n6.\tWhy did you choose to train your networks initialized with the weights from their full-precision counterparts? When you train using different initializations, does this significantly affect your results?\n\n7.\tThe improved empirical performance of the clipped ReLU / SSTE is unsurprising but why does the vanilla ReLU STE perform so poorly on CIFAR-10 with ResNet-20 with 2 bit quantization?\n\n8.\tIn the end, it’s not clear that training single-layer hard-threshold networks is particularly important. Instead, the goal of quantization, etc. is to train multi-layer hard-threshold networks. Can this analysis be extended to such networks? Does it say anything about training such networks currently?\n\n9.\tThe acknowledgments section is just the text from the style file.\n\n10.\tThe capitalization is wrong in a number of places in your references.\n\n\n[1] Difference Target Propagation. Lee, Zhang, Fischer, and Bengio. ECML/PKDD (2015).\n\n[2] Deep Learning as a Mixed Convex-Combinatorial Optimization Problem. Friesen and Domingos. ICLR (2018).\n\n\n------------------------\n\nAfter reading the author response, they have sufficiently addressed my main concerns. I think that this is a good paper that will be of interest to those concerned with understanding the training of activation-quantized / hard-threshold neural networks. I have thus increased my score.\n\n', 'The paper examines the use of STE for learning simple one-layer convolutional networks with binary activations and non overlapping patches. In this setting, the gradients are 0 almost everywhere (gradient of sign(x)) hence it is not clear how to use gradient descent. The approach studied here is to instead use the gradient of an alternative function such as ReLU or identity which is not always 0. The authors prove that if the ReLU\'s gradient is used then under gaussian distribution, the algorithm will converge to the local minimas/saddle points of the expected squared loss. they also show that the same does not hold for the identity\'s gradient.\n\nThe proof technique is interesting and the results do show the validity of the STE approach. The fact that the loss is provably monotonically decreasing is a strong validation. The paper is clearly written. However, I do have the following concerns/questions:\n- The authors claim that their analysis is the first to analyze STE however I would like to point out that [1] studies the same setting (they allow overlapping patches and other distributions) with ReLU activation and show convergence guarantees to the global optima with using identity gradient instead of the ReLu gradient. Also for a single binary output case, using STE as identity equals the perceptron algorithm which is very well studied in literature.\n- Restrictive setting: gaussian input, no label noise, non-overlapping architecture. Not clear what the motivation for this setting is. Also binary activations are rarely used in practice. Analysis also seems tied to the gaussian distribution.\n- Infinite sample assumption is strong.\n- No guarantees for convergence to the optimal solution unlike prior work.\n- Assumptions on the weights being lower and upper bounded by a constant at each iteration seems strong unless an explicit projection step is used. Could the authors explain why this is a valid assumption to make?\n- In the experimental section, momentum is used whereas it is not mentioned in the analysis. Does the STE perform well without the momentum? It is unclear why quantized ReLU is used.\n\n[1] Surbhi Goel, Adam Klivans, and Raghu Meka. ""Learning One Convolutional Layer with Overlapping Patches."" ICML 2018.\n\n----------\nApart from one concern (refer to comment), the authors have responded to most of my other comments. Based on this, I think the paper does offer an interesting analysis of the STE approach used for training binary networks, hence I\'m increasing my score.']","[50, -20, 50]","[20, 60, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's theoretical contributions and potential usefulness to the community, but also points out several areas for improvement. The initial paragraph recognizes the value of the work, while subsequent paragraphs highlight issues with organization, clarity, and comprehensiveness. The final sentence indicates that the author's response addressed most concerns, leading to an increased score, which suggests an overall positive sentiment despite the criticisms.\n\nThe politeness score is 20 (slightly polite) because the reviewer maintains a professional tone throughout, offering constructive criticism without using harsh language. They use phrases like 'might be useful' and 'can be further improved' instead of more negative alternatives. However, the review is primarily focused on the paper's shortcomings rather than its strengths, which prevents it from being scored as highly polite. The reviewer also directly points out issues without much softening language, which keeps the politeness score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses some positive aspects ('I like the paper'), they also highlight several significant issues and state the paper 'has too many issues currently for me to give it a high score'. The overall tone suggests the reviewer sees potential but is not satisfied with the current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to improve their score if concerns are addressed. They provide detailed feedback in a professional manner without using harsh or rude language. The reviewer balances critique with positive comments and offers specific suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting proof technique, clear writing, and validity of results, while also raising several concerns. The increase in score mentioned at the end indicates an overall positive view. The politeness score is 75 (quite polite) as the reviewer uses respectful language, phrases concerns as questions or suggestions, and acknowledges the authors' responses positively. The reviewer maintains a professional and constructive tone throughout, even when expressing criticisms.""]"
"['This paper introduces a method for handing input data that is defined on irregular mesh-type domains. If I understand it correctly, the core technique is  to perform Fourier analysis to transform the input data to the frequency domain, which is then transformed back to a regular domain before applying a standard neural network. The claimed result is that this is better than standard linear interpolations. The key technical contribution is to define FT on points, edges, and meshes (This reviewer appreciates these efforts). Explicit formula are given. However, the paper does not perform convolutions on the input irregular domain directly, which is quite disappointing. The experimental results are preliminary. It is expected to perform evaluation on more applications such as semantic segmentation. \n\n\nThe major issue of the paper is that the goal was not stated clearly. Does it target for a neural network that is defined on irregular domains or simply a technique to handling irregular domains? Given the Fourier transform, it is possible to define convolutions directly as multiplications in the Fourier domain....the paper can be more interesting, if it follows this line.\n\nOverall, it is hard to champion the paper based on the current technical approach and the experimental results. \n', 'Convolutiuonnal Neural Networks on Non-uniform Geometrical Signals using Euclidean Spectral Transformation\n\nThe paper tackles the challenging problem of learning across mixed graph topologies, which is today a real challenge. It is highly original due to the unified general framework for handling differing graph topologies. The method is highly generalizable to other learning techniques since it proposes a transformation of varied topologies into a cartesian grid-like embedding, via the new non-uniform Fourier transform. The method is evaluated on MNIST, Shape Retrieval, and point to surface reconstruction. The paper is dense and uses non-trivial mathematical formulations, but reads well and remains easy to follow. The experiments supports well, and greatly adds clarity to understand the proposed methodology. Overall, recommendation towards acceptance. \n\nPositive\n+ Develop a method to analyze signal on mixed topologies with a new non-uniform Fourier transform.\n+ The proposed approach has advantages on -reducing sampling error, -unified framework for mixed topology, -reducing heuristics in designing can architecture, -local weights in mesh structures.\n+ Improved performance in surface reconstruction task.\n\nSpecific Comments\n- In the inverse Fourier Transformation, a voxel-like grid structure is used, however - how to control the size of this volume? If the size is large, or explodes, the complexity of the cnn architecture would explode as well - How is this size issue tackled?\n- In this same inverse Fourier Transformation, the whole infinite space would be obviously hard to sample - Spectral information would be lost - How bad is this and how does this impact results?  How would this compare to direct graph-based methods, for instance, in a fixed graph structure?\n- Ovsjanikov’s Functional maps, siggraph 2012, have been proposed to find maps between differing graph spectrum, partly solving the problem of handling graphs of multiple topologies. One way would be to find spectral correspondences between embeddings. How helpful would this be to find similarities between embeddings in this new proposed unified framework?\n\nTypos - geometris', 'Overall Thoughts:\n\nI think this paper addresses an interesting topic and that the community as a whole are interested on the application of learning algorithms to non-Euclidean domains. It is nice to see the application of Fourier sampling to geometric primitives in a sensible manner and I am positive about that part of the paper. However, in its current form, I have quite a few questions about the approach and the empirical studies - I would need to here more information from the authors on the points below.\n\nSpecific Comments/Questions:\n\nSec1: The authors make a number of assertions about the representational errors that occur in other approaches - I feel that these claims should be supported by specific references.\n\nContributions: It is not clear to me that the experiments show that the method “preserves maximal information content” - in my understanding, information content has a formal definition and I don’t see where this is presented in the results?\n\nSec2: Before CNNs there has been a substantial analysis of Fourier methods applied to shape models, e.g. elliptical Fourier series for shape contours (and signed distance representations) by Prisacariu et al.\n\nSec2: It is also worth noting that there is substantial literature on non-uniform Fourier methods including the non-uniform Fourier transform and a number of accelerations (e.g. NUFFT) as well as consideration of the implications of band-limiting the sampled spectra.\n\nSec3: The mathematical derivation all makes sense to me and makes use of results for piecewise uniform signals. Please could the authors provide more details on how the spectra are represented? These discontinuous signals (esp. delta functions) will have infinite bandwidth in the spectral domain so how they are stored would seem very important to me. Are the signals band limited at some point? If so, how does this affect the approximation and should filtering/windowing be used? Otherwise is there not a difficult storage problem? The final paragraph suggests all the analytic signals might be stored but this has a big impact on how efficient the algorithm is and really is far too important a point to just have a single sentence - please can the authors expand on how this is actually implemented and what the computational considerations are (and resulting impacts on performance)?\n\nSec4: Please can the authors add error bars (at the least) to all the tables/plots in the results. It is entirely unreasonable to make any statements about how significant the results may be without even the most basic of analysis. Ideally we should see histograms of the results for the retrieval and shape reconstruction results. \n\nSec4: How is the downsampling performed in the MNIST experiment? It would seem very important to take care with this for the purpose of comparison. A significant disparity between the signed distance function and the NUFT would seem slightly surprising to me? Again, without error bars we really cannot say very much about the results on the right of Fig3(b).\n\nSec4: Could the Fig4 results not be provided as histograms? We also need many more details about how the results were obtained and procedures to ensure that the results are meaningful and robust (e.g. repeated tests and partitions of the data, etc..)\n\nArch and Training Details: How are we to know that these choices provide fair comparisons to previous approaches?\n\nSec3/4: All the results seem to require the input to be reconstructed back into a dense sampling domain (via inverse FT) - is this the case? Would it not be more efficient to perform the convolutions in the spectral domain where the signal is sparse?\n\nSec4: It seems pretty unfair to train and test on a single category of shapes in the shape test since the data is known not to be very diverse? Particularly when, unless I’ve misunderstood, the baselines on the shape recovery test to not involve learning and so (while helpful to have) they are not really fair baselines compared to other learning approaches? Also, please can the authors provide much more information about the extra processing applied (e.g. the part starting with the “extra mesh thickness”) since there seem to be some extra steps that are nothing to do with the rest of the method and may impact the results significantly. \n\nSec4: It is interesting that Table 3 (again difficult to say without error bars) indicates that there are times when the method performs better with the additional of noise - this seems counter-intuitive - please could the authors comment on this?\n\nOther Points:\n\nI’m afraid that there are quite a few grammatical errors in the text (too many to list here) so I would recommend another round of proof-reading.']","[-50, 80, -20]","[20, 70, 60]","[""The sentiment score is -50 because the review expresses disappointment and criticism, stating that 'it is hard to champion the paper' and that the experimental results are 'preliminary'. However, it's not entirely negative as it acknowledges some positive aspects like 'This reviewer appreciates these efforts'. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They avoid harsh or rude phrasing, instead using phrases like 'If I understand it correctly' and offering suggestions for improvement. The reviewer also acknowledges the authors' efforts, which adds a polite tone. However, the overall critique is still direct, preventing a higher politeness score."", ""The sentiment score is 80 (positive) because the review begins with strong praise for the paper's originality, generalizability, and clarity. It explicitly recommends acceptance and lists several positive aspects. The few criticisms are framed as questions for improvement rather than major flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms as constructive questions. The tone is professional and encouraging, avoiding harsh or dismissive language. However, it doesn't reach the highest level of politeness as it maintains a formal, rather than overly deferential, tone."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses some positive aspects ('interesting topic', 'nice to see the application'), they raise 'quite a few questions' and express concerns about the approach and empirical studies. The overall tone suggests more work is needed before the paper would be acceptable. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, such as 'please could the authors', 'It is nice to see', and frames criticisms as questions or requests for more information rather than direct criticisms. However, some statements like 'It is entirely unreasonable' and 'I'm afraid that there are quite a few grammatical errors' slightly reduce the politeness score from being very high.""]"
"['The paper presents several ways to regularize plain ReLU networks to optimize 3 things\n\n- the adversarial robustness, defined as the fraction of examples for which adversarial perturbation exists\n- the provable adversarial robustness, defined as the fraction of examples for which some method can show that there exists no adversarial example within a certain time budget\n- the verification speed, i.e. the amount of time it takes some method to verify whether there is an adversarial example or not\n \nOverall, the ideas are sound and the analysis is solid. My main concern is the comparison between the authors method and the \'certification\' methods, both conceptually and regarding performance.\n\nThe authors note that their method falls under \'verification\', whereas many competing methods fall under \'certification\'. They point to two advantages of verification over certification: (1) the ability to provide true negatives, i.e. prove that an adversarial example exists when it does, and (2) certification requires that \'models must be trained and optimized for a specific certification method\'. However, neither argument convinces me regarding the utility of the authors method. \n\nRegarding (2): The authors method also requires training the network in a specific way (with RS loss), and it is only compatible with verifiers that care about ReLU stability. \n\nRegarding (1): It is not clear that this would be helpful at all. Is it really that much better if method A has 80% proven robustness and 20% proven non-robustness versus method B that has 80% proven robustness and 20% unknown? One could make the case that method B is actually even better.\n\nSo overall, I think one has to compare the authors method and the certification methods head-to-head. And in table 3, where this is done, Dvijotham comes out on top 2 out of 2 times and Wong comes out on top 2 out of 4 times. That does not seem convincing. Also, what about the performance numbers form other papers discussed in section 2?\n\n-------\n\nOther issues:\n\nAt first glance, the fact that the paper only deals with (small) plain ReLU networks seems to be a huge downside. While I\'m not familiar with the verification / certification literature, from reading the paper, I suspect that all the other verification / certification methods also only deal with that or highly similar architectures. However, I will defer to the other reviewers if this is not the case.\n\nTo expand upon my comment above, I think the paper should discuss true adversarial accuracy on top of provable adversarial robustness. Looking at table 1, for instance, for rows 2, 3 and 4, it seems that the verifier used much less than 120 seconds on average. Does that mean the verifier finished for all test examples? And wouldn\'t that mean that the verifier determined for each test example exactly whether an adversarial example existed or not? In that case, I would write ""true adversarial accuracy"" instead of ""provable adversarial accuracy"" as column header. If the verifiers did not finish, I would include in the paper for how many examples the result was ""adverarial example exists"" and for how many the result was ""timeout"". I would also include that information in table 3, and I would also include proving / certification times there. \n\nBased on the paper, I\'m not quite sure whether the idea of training with L1 regularization and/or small weight pruning and/or ReLU pruning for the purpose of improving robustness / verifiability was an original idea of this paper. In either case, this should be made clear. Also, the paper seems to use networks with adversarial training, small weight pruning, L1 and ReLU pruning as its baseline in most cases (all figures except table 1). If some of these techniques are original contributions, this might not be an appropriate baseline to use, even if it is a strong baselines.\n\nWhy are most experiments presented outside of the ""experiments"" section? This seems to be bad presentation.\n\nI would include all test set accuracy values instead of writing ""its almost as high"". Also, in table 3, it appears as if using RS loss DOES in fact reduce test error significantly, at least for CIFAR. Why is that?\n\nWhile, again, I\'m not familiar with the background work on verification / certification, it appears to me from reading this paper that all known verification algorithms perform terribly and are restricted to a narrow range of network architectures. If that is the case, one has to wonder whether that line of research should be encouraged to continue.\n\n--------\n\nMinor issues:\n\n- ""our focus will be on the most common architecture for state-of-the-art models: k-layer fully-connected feed-forward DNN classifiers"" Citation needed. Otherwise, I would suggest removing this statement.\n- ""such models can be viewed as a function f(.,W)"" - you also need to include the bias in the formula I think\n- ""convolutional layers can be represented as fully-connected layers"". I think what you mean is ""convolutional layers can be represented as matrix multiplication""\n- could you make the difference between co-design and co-training more clear?\n- The paper could include in the appendix a section outlining the verification method of Tjeng', 'This paper proposes methods to train robust neural networks that can also be verified faster. Specifically, it uses pruning methods to encourage weight sparsity and uses regularization to encourage ReLU stability. Both weight sparsity and ReLU stability reduces time needed for verification. The verified robust accuracy reported in this paper is close to previous SOTA certified robust accuracy, although not beating SOTA.\n\nThe paper is clearly written and easy to follow.\n\nThe reviewer is familiar with literatures on certifiable robust network literature, but not familiar with verification literature. To the best knowledge of the reviewer, the proposed method is well motivated and novel, and provides a scalable method for verifying (instead of lower bounding) robustness.\n\nOther comments:\n\nI think there should be some discussions on applicability on different robustness measures. The paper focus on L_\\infty norm bounded attack, is this method extendable to other norms?\n\nRe: robust accuracy comparison, I found some previous SOTA results missing from Table 3. For example, Mirman et al., 2018 (Appendix Table 6) reached 82% (higher than 80.68% achieved in this paper) provable robust accuracy for MNIST eps=0.3 case. and this is not reported in Table 3. The CIFAR10 results in Mirman et al., 2018 is also better than the best SOTA accuracy in Table 3.\n\n\nMatthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for provably robust neural networks. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 3575–3583, Stockholmsmssan, Stockholm Sweden, 10–15 Jul 2018. PMLR. URL http://proceedings.mlr.press/v80/mirman18b.html.\n', 'Training for Faster Adversarial Robustness verification via inducing RELU stability\n\n\nAs I am familiar yet not an expert on adversarial training and robustess, my review will focus mainly on the overall soundness of the manuscript. I also only went superficially into the quantitative results.\n\nSummary:\n\nThe authors are interested in the problem of verifying neural networks models trained to be robust against adversarial attacks. The focus is on networks with relu activations and adversarial perturbations within an epsilon l1-ball around each input, and the verification problem consists in proving the network performs as intended for all possible perturbations (infinitely many)\n\nThe review on verification is clear. \nElements that affect verification time are introduced and well explained in main text or appendix from both intuitive and theoretical perspective: l1 penalty, weight pruning, relu stability. These can be summ\\arized as : you want few neurons, and you want them to operate in the same regime for all inputs, both to avoid branching. Relu stability is apparently a new concept and the proposed regularization approximately enforces relu stability.\nThe approximation [itself using the novel improved interval arithmetic] based bounds on unit activations propagated through the network seems not to scale well with depths (more units are mis-labelled as relu unstable, hence wrongly regularized if I understand correctly). The authors acknowledge and document this fact but I would like to hear more discussion on this feature and on the trade-off that still make this approach worthwhile for deeper networks.\n\nThis regularization does not help performance but only paves the way for a faster verification, for this reason the term co-design is used.\n\nThe rest of the manuscript is a thorough empirical analysis of the effect of the penalties/regularizations on the network and ultimately on the verification time, keeping an eye on not deteriorating the performance of the network.\nHow much regularization can be added seems to be indeed an empirical question since networks are ‘over-parametrized in the first place’ with no clear way to a priori quantify task or model complexity.\n\nThe devil is in the details and in practice implementation seems not straightforward with a complex optimization with varying learning rates and different regularizations applied at different time along the way. But this seems to be the case for most deep learning paper.\n\nThe authors claim and provide evidence to be able to verify network well beyond the scope of what was achievable before due to the obtained speed-ups, which is a notable feature.\n\nOverall, this manuscript is well structured, thorough and pleasant to read, and I recommend it to be accepted for publication at ICLR\n']","[-20, 60, 80]","[50, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that 'the ideas are sound and the analysis is solid', they express several significant concerns and criticisms about the paper's methodology, comparisons, and overall contribution. The reviewer questions the utility of the authors' method and finds the performance comparisons unconvincing. However, the score is not deeply negative as the reviewer does recognize some merits in the work. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'My main concern is...' and 'I think one has to compare...' rather than using harsh or dismissive language. The reviewer also offers constructive feedback and suggestions for improvement, which contributes to the polite tone. However, the score is not extremely high as the review is quite direct in its criticisms without excessive softening language."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that it is 'clearly written and easy to follow', and that the proposed method is 'well motivated and novel'. However, it's not extremely positive as the reviewer points out that the results don't beat the state-of-the-art and suggests some missing comparisons. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('The reviewer is familiar with... but not familiar with...'), and frames criticisms as suggestions or questions rather than direct attacks. The reviewer also compliments the paper's clarity and motivation before offering critiques, which is a polite approach to reviewing."", ""The sentiment score is 80 (positive) because the reviewer expresses a clear recommendation for acceptance, describes the paper as 'well structured, thorough and pleasant to read', and highlights notable features of the work. The overall tone is supportive and appreciative of the authors' contributions. The politeness score is 70 (polite) due to the reviewer's respectful and constructive language throughout. They acknowledge their own limitations ('as I am familiar yet not an expert'), offer balanced feedback, and use phrases like 'I would like to hear more discussion' rather than demanding changes. The reviewer also compliments various aspects of the paper, showing respect for the authors' work.""]"
"['This paper presents an incremental extension to the Self-imitation paper by Oh, Junhyuk, et al. The previous paper combined self-imitation learning with actor-critic methods, and this paper directly integrates the idea into the generative adversarial imitation learning framework.\n\nI think the idea is interesting, but there remains some issues very unclear to me. In the algorithms, when updating the good trajectory buffer, it is said ""We define ‘good trajectories’ as any trajectories whose the discounted sum of rewards are higher than that of the policy"". What does ""that of the policy"" mean? How do you know the reward of the policy?\n\nSecond, without defining good trajectories, I don\'t think Algorithm 1 would work. Algorithm ` 1 misses the part of how to update buffer B. After introducing their own algorithm, the author did not provide much solid proof or analysis for why this self-imitation learning works.\n\nIn the experiment section, the author implemented GASIL for various applications and presented reasonable results and compared them with other methods. Nevertheless, without theoretical proof, it is hardly convincing that the results could be consistently reproduced instead of being merely accidental for some applications.\n\nUpdate:\nThe rebuttal resolves some of my concerns. However, I still think the contribution is incremental. The current version looks too heuristic, more theoretical analysis or inspirations need to be added.\n', ""Summary:\n\nThis paper proposes a self-imitation learning technique which modifies GAIL such that top-k trajectories with high reward found by the agent are kept in a buffer (and updated as learning goes on) such that the discriminator tries to distinguish between trajectories generated by the generator and those in the buffer while the generator tries to fool the discriminator by trying to imitate trajectories present in the buffer. \n\nExperiments are shown on two domains: 1. a simple 2D domain where the agent must avoid orange circles (negative reward) and touch green and blue circles which yield positive reward and 2. on MuJoCo against PPO and variants of PPO as baselines where it is shown that GASIL performs better (even under increased stochastic noise in the dynamics.)\n\n\nComments:\n\n- Generally well-written and easy to understand. Thanks!!\n\n- Intuitive algorithm and good experiments with ablation studies on MuJoCo.  \n\n- My main concern is that the paper while offering a good self-imitation algorithm fails to really shine light on when/why this is expected to work. Especially in the following natural areas:\n\na. Why is it that performance decreases as buffer size B increases?\nb. Why doesn't the policy get stuck imitating the first few good trajectories? the conjecture offered is that policy gradient strongly encourages greedy myopic behavior while GASIL does not. Wouldn't one expect GASIL to suffer more?\nc. Does GASIL work better on rich observation spaces (e.g. Atari games) as well?\n\nWithout good answers (theoretical or empirical) to the above questions it is a bit hard to assess how significant of an improvement GASIL actually is and what is the prescription for using this over non-GAIL style self-imitation learning algorithms?"", '[Paper Summary]:\nThis paper proposes a regularization technique for existing RL algorithms by encouraging them to learn to reproduce the best past trajectories which obtained higher reward than that of current policy. The proposed method in the paper has the same high-level idea as ""Self-imitation learning"" [Oh et.al. ICML 2018] with a different objective. Instead of performing imitation learning to distill the knowledge from past best trajectories, this proposes to use inverse reinforcement learning via GAIL objective [Ho and Ermano, 2016]. The best k trajectories from past experience are stored to train a discriminator which is then used to augment the external reward function with a discriminator reward.\n\n[Paper Strengths]:\nThe paper combines ideas from GAIL and self-imitation learning to propose a method that leverages past best trajectories via inverse-RL. This combination allows one to interpret self-imitation of best trajectories as a mechanism for ""reward shaping"" where learned discriminator shapes the environmental reward using past experiences. This is an exciting perspective and needs further discussion.\n\n[Paper Weaknesses and Clarifications]:\n=> This paper is very closely related to self-imitation learning [Oh et.al.], however, there is no theoretical justification provided (unlike [Oh et. al.]) whether the policy learned by optimizing Equation-11 is in anyway related to the optimal policy -- which was the case as shown in [Oh et.al.]. That being said, this is not a requirement for a paper to show theoretical justification as long as the paper justifies given approach with ample empirical evidence.\n=> The main comparison point for the proposed approach, ""GASIL"", is ""SIL"" [Oh et.al.]. This paper provides a good comparison on continuous control tasks on Mujoco where ""GASIL"" performs slightly better than ""SIL"" in 3 out of 6 environments. However, ""SIL"" [Oh et. al.] showed extensive experiments on all Atari Games + Mujoco tasks. Since the proposed approach is mainly empirically motivated, the experiments should at least show a comparison on all the environments of the closely-related prior work. It would be much more convincing to see a bar chart across all 48 Atari Games showing relative improvement of ""GASIL"" over ""SIL"", as shown in Figure-4 of [Oh et. al.].\n=> Other concerns:\n    - The paper mentions on multiple occasions that the proposed method would handle delayed and ""sparse"" reward. However, it is not clear how can past best trajectories help with ""sparse"" rewards (""delayed-dense-rewards"" seems alright, but they are not the same as ""sparse""!). For instance, suppose the agent gets only terminal-reward in a maze. In such a case, the agent would need to rely on some form of exploration bonus (count-based, curiosity etc.) to reach the sparse-goal even once.\n    - What prevents the learned policy from over-fitting to the local minima of the ""locally"" best trajectories seen so far?\n\n[Final Recommendation]:\nI request the authors to address the comments raised above. The paper has good potential, but sufficient empirical evidence is needed to justify the proposed technique. If the results on all Atari games can be included and shown to improve over ""SIL"", I would update my final rating.']","[-20, 50, -20]","[50, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'interesting', they express several concerns and criticisms. They mention unclear aspects, lack of solid proof or analysis, and describe the contribution as 'incremental'. The overall tone suggests skepticism about the paper's robustness and significance.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'I don't think' to express opinions, avoiding harsh or confrontational language. The critique is presented as questions and observations rather than direct attacks. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral-to-positive professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with positive comments about the paper being well-written, easy to understand, and having intuitive algorithms and good experiments. However, the reviewer also expresses significant concerns about the paper's lack of explanation for certain aspects of the algorithm's performance, which balances out the initial positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, beginning with a thank you note and framing criticisms as questions or areas for improvement rather than direct attacks. The reviewer also acknowledges the paper's strengths before diving into concerns, which is a polite approach to giving feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express several significant concerns and request substantial additional work. The reviewer states that the paper has 'good potential' but needs 'sufficient empirical evidence' and major additions like results on all Atari games to justify the proposed technique. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as requests or suggestions rather than demands. Phrases like 'I request the authors to address' and 'It would be much more convincing' contribute to the polite tone. The reviewer also offers constructive feedback and explains their reasoning for each point of criticism.""]"
"['In this paper the authors propose DL2 a system for training and querying neural networks with logical constraints\n\nThe proposed approach is intriguing but in my humble opinion the presentation of the paper could be improved. Indeed I think that the paper is bit too hard to follow. \nThe example at page 2 is not clearly explained.\n\nIn Equation 1 the relationship between constants S_i and the variables z is not clear. Is each S_i an assignment to z?\n\nI do not understand the step from Eq. 4 to Eq. 6. Why does arg min become min?\n\nAt page 4 the authors state ""we sometimes write a predicate \\phi to denote its indicator function 1_\\phi"". I’m a bit confused here, when is the indicator function used in equations 1-6?\n\nWhat kind of architecture is used for implementing DL2? Is a feedforward network used? How many layers does it have? How many neurons for each layer? No information about it is provided by authors.\n\nIt is not clear to me why DL2/training is implemented in PyTorch and DL2/querying in TensorFlow. Are those two separate systems? And why implementing them using different frameworks?\n\nIn conclusion, I’m a bit insecure about the rating to give to this paper, the system seems interesting, but several part are not clear to me.\n\n[Minor comments]\nIt seems strange to me to use the notation L_inf instead of B_\\epsilon to denote a ball.\n\nIn theorem 1. \\delta is a constant, right? It seems strange to me to have a limit over a constant.', '\nThe paper tackles the interesting problem of combining logical approaches with neural networks in the form of  translating a logical formula into a non-negative loss function for a neural network. \nThe approach is novel and more general than previous approaches and the math is sound. However, I feel that the method is not well presented. Sadly the introduction does not set the method into context or give a motivation. The abstract is very short and misses key information. Indeed, even the more technical parts sometimes lack clarity and assume familiarity with a wide range of methods. \n\nThe experiments are well thought out and show the promise of the method when encoding performance measures such as entropy into the constraints. It would have been interesting to additionally see other kinds of constraints such as purely logical formulas that do not have a specific aim (robustness or performance or otherwise) but simply state preconditions that should be fulfilled. It would furthermore be interesting to inspect the corner cases of the proposed method such as what happens if two constraints are nearly opposing each other and so on. \n\n\n\nTo conclude, the presented method is clearly novel and provides an interesting solution to a challenging problem. However the paper in the current form does not fully adhere to the standards of conferences such as ICLR. I suggest rewriting especially the abstract and the introduction and then submitting to a different venue as the approach itself seems promising. Additionally, as only very limited comparison experiments can be performed the method itself should be more thoroughly inspected by performing, for example, edge-case or time/number of constraints inspections.\n\nMinor remarks:\nHyperparameters such as batch size not reported\nSpelling mistake in line 2, page 2 “Lipschitz condition”\nWhen mentioning “prior work” in the introduction a citation is needed.', 'Summary\n-------\nThis paper proposes DL2, a framework for turning queries over parameters and input, output pairs to neural networks into differentiable loss functions, and an associated declarative language for specifying these queries. The motivation for this work is twofold. The first is to allow for the specification of additional domain knowledge during training. For example, if a user expects that the predicted probabilities of some output classes should be correlated for all predictions, this constraint can be enforced during weight learning. Second, it allows users to search for specific inputs that satisfy specified conditions. In this way, DL2 can capture popular applications like searching for adversarial examples by querying for inputs close to a known input of class A but that the network predicts is class B with high confidence.\n\nThe paper provides a concise specification of the query language (a mixture of logical and numeric operators) and asserts a theorem that the given procedure for constructing the query loss produces a function such that anytime the function is 0, the constraints are satisfied. No proof is given, but I cannot see a counterexample. There is also a statement about the converse relationship, that when the loss is above some threshold it implies that the query is not satisfied. \n\nExperiments are conducted on supervised, semi-supervised, and unsupervised computer vision tasks. I particularly liked the experiment on semi-supervised learning with CIFAR-100. By replacing labeled examples with domain knowledge about the relationships among classes in CIFAR-100, the paper demonstrates a compelling use case for DL2.\n\nThe primary technical challenge is the non-convex optimization required to search for a solution to a query. Experiments show that the loss functions created by DL2 are often solved quickly and correctly, but not always\n\nStrengths\n---------\nThe framework is expressive enough that many interesting use cases are clear, from specifying background knowledge during training to model inspection. The experiments cover a range of these use cases, demonstrating that the constructed optimization objectives usually work as intended.\n\nWeaknesses\n-----------\nThe statement in Theorem 1 regarding the converse case is unclear, because it says that the limit of \\delta as \\epsilon approaches zero is zero, but it is not explained what \\epsilon is or how it changes. If \\epsilon is the threshold that can often be used in the query, it is not obvious that every query contains exactly one \\epsilon. If other cases exist, it is unclear how Theorem 1 applies.\n\nIt remains unknown how to handle the case when queries fail. AS the paper points out, if a query fails, it cannot be determined whether no solution exists or if the optimization simply failed to find a solution. Of course, this is a computationally hard in general.\n\nRelated Work\n------------\nThere are a couple of points from related work that would be good to add to the paper.\n\nFirst, the paper ""Adversarial Sets for Regularising Neural Link Predictors"" (Minervini et al., UAI17) is a prior paper that generates adversarial examples to handle restrictions on inputs which may not exist in the training set. The paper claims DL2 is the first to do this, but I believe this paper is an earlier example that does so, albeit for a particular problem. DL2 is certainly more general.\n\nSecond, the description of the limitations of rule distillation (Hu et al., ACL16), particularly in Appendix A is not fully accurate. The expressivity of PSL is greater than stated (see Bach et al., JMLR17 for a full description). In particular, the DL2 loss function for z = (1, 1) can be expressed exactly in PSL using what it calls arithmetic rules. It is not clear that this affects the findings of the semi-supervised learning experiment significantly, although I would appreciate a clarification of the authors. PSL by construction produces convex loss functions, and so the constraint that all outputs for a group of classes is either high OR low would probably not work well.']","[-20, -20, 70]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the approach 'intriguing', they express several concerns and confusions about the paper's clarity and presentation. They state that the paper is 'hard to follow' and list multiple aspects that are unclear or not well explained. The reviewer concludes by saying they are 'insecure about the rating to give to this paper', indicating overall uncertainty and mild dissatisfaction.\n\nThe politeness score is moderately positive (60) because the reviewer uses polite language throughout. They start with 'In my humble opinion' and use phrases like 'I'm a bit confused' and 'It is not clear to me' rather than making blunt criticisms. The tone is generally constructive and inquisitive rather than harsh or dismissive. The reviewer also acknowledges the potential of the system by calling it 'interesting' despite their concerns.\n\nBoth scores reflect a balanced review that expresses concerns politely while still acknowledging potential merits of the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and potential of the method, they express significant concerns about the paper's presentation, clarity, and completeness. The reviewer suggests rewriting parts of the paper and submitting to a different venue, indicating that it doesn't meet the current conference standards. However, the score isn't deeply negative as the reviewer sees promise in the approach itself. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and providing constructive feedback. They use phrases like 'I feel that' and 'I suggest' rather than making blunt criticisms. The reviewer also balances negative points with positive ones, showing consideration for the authors' efforts. The tone is professional and aimed at improvement rather than harsh criticism."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its strengths and the compelling use cases it demonstrates. They appreciate the expressiveness of the framework and the range of experiments conducted. However, they also point out some weaknesses and areas for improvement, which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They balance praise with criticism, and phrase their suggestions in a collegial manner (e.g., 'It would be good to add...'). The reviewer also acknowledges the paper's contributions while suggesting improvements, which is a polite approach in academic discourse.""]"
"['The authors present an architecture search method where connections are removed with sparse regularization. It produces good network blocks relatively quickly that perform well on CIFAR/ImageNet.\n\nThere are a few grammatical/spelling errors that need ironing out.\n\ne.g. ""In specific"" --> ""Specifically"" in the abstract, ""computational budge"" -> ""budget"" (page 6) etc.\n\nA few (roughly chronological comments).\n\n- Pioneering work is not necessarily equivalent to ""using all the GPUs""\n\n- There are better words than ""decent"" to describe the performance of DARTS, as it\'s very similar to the results in this work!\n\n- From figure 2 it\'s not clear why all non-zero connections in (b) are then equally weighted in (c). Would keeping the non-zero weightings be at all helpful?\n\n-  Why have you chosen the 4 operations at the bottom of page 4? It appears to be a subset of those used in DARTS.\n\n- How do you specifically encode the number of surviving connections? Is it entirely dependent on budget?\n\n- You should add DARTS 1st order to table 1. \n\n- Measuring in GPU days is only meaningful if you use the same GPU make for every experiment. Which did you use?\n\n- The ablation study is good, and the results are impressive.\n\nI propose a marginal acceptance for this paper as it produces impressive results in what appears to be a short amount of search time. However, the implementation details are hazy, and some design choices (which operations, hyperparameters etc.) aren\'t well justified.\n\n------------\nUPDATE: Score changed based on author resposne\n------------\n', '\n- Summary\nThis paper proposes a neural architecture search method based on a direct sparse optimization, where the proposed method provides a novel model pruning view to the neural architecture search problem. Specifically, the proposed method introduces scaling factors to connections between operations, and impose sparse regularizations to prune useless connections in the network. The proposed method is evaluated on CIFAR-10 and ImageNet dataset.\n\n- Pros\n  - The proposed method shows competitive or better performance than existing neural architecture search methods.\n  - The experiments are conducted thoroughly in the CIFAR-10 and ImageNet. The selection of the datasets is appropriate. Also, the selection of the methods to be compared is appropriate.\n  - The effect of each proposed technique is appropriately evaluated.\n\n- Cons\n  - The search space of the proposed method, such as the number of operations in the convolution block, is limited.\n  - The proposed method does not outperform the existing state-of-the-art methods in terms of classification accuracy.\n  - The technical contribution of the proposed method is not high, because the architecture space of neural network is similar to the prior works.\n\nOverall, if we focus on the balance between the classification accuracy and computational efficiency, the proposed method is promising.\n', 'Summary:\nThis paper proposes Direct Sparse Optimization (DSO)-NAS, which is a method to obtain neural architectures on specific problems, at a reasonable computational cost.\n\nThe main idea is to treat all architectures as a Directed Acyclic Graph (DAG), where each architecture is realized by a subgraph. All architectures in the search space thus share their weights, like ENAS (Pham et al 2018) and DARTS (Liu et al 2018a). The DAG’s edges can be pruned via a sparsity regularization term. The optimization objective of DSO-NAS is thus:\n\nAccuracy + L2-regularization(W) + L1-sparsity(\\lambda),\n\nwhere W is the shared weights and \\lambda specifies which edges in the DAG are used.\n\nThere are 3 phases of optimization:\n1. All edges are activated and the shared weights W are trained using normal SGD. Note that this step does not involve \\lambda.\n2. \\lambda is trained using Accelerated Proximal Gradient (APG, Huang and Wang 2018).\n3. The best architecture is selected and retrained from scratch.\n\nThis procedure works for all architectures and objectives. However, DSO-NAS further proposes to incorporate the computation expense of architectures into step (2) above, leading to their found architectures having fewer parameters and a smaller FLOP counts.\n\nTheir experiments confirm all the hypotheses (DSO-NAS can find architectures, having small FLOP counts, having good performances on CIFAR-10 and ImageNet).\n\nStrengths:\n1. Regularization by sparsity is a neat idea.\n\n2. The authors claim to be the first NAS algorithm to perform direct search on ImageNet. Honestly, I cannot confirm this claim (not sure if I have seen all NAS papers out there), but if it is the case, then it is impressive.\n\n3. Incorporating architecture costs into the search objective is nice. However, this contribution seems to be orthogonal to the sparsity regularization, which, I suppose, is the main point of the paper.\n\nWeaknesses:\n1. Some experimental details are missing. I’m going to list them here:\n- Was the auxiliary tower used during the training of the shared weights W?\n\n- Figure 4 does not illustrate M=4 and N=4, e.g. which operation belongs to which layer?\n\n- Did the experiments on CIFAR-10 and ImageNet use the cosine learning rate schedule [1]? If or if not, either way, you should specify it in a revised version of this paper, e.g. did you use the cosine schedule in the first 120 steps to train the shared parameters W, did you use it in the retraining from scratch?\n\n- In Section 3.3, it is written that “The sparse regularization of \\lambda induces great difficulties in optimization”. This triggers my curiosity of which difficulty is it? It would be nice to see this point more elaborated, and to see ablation study experiments.\n\n2. Missed citation: MnasNet [2] also incorporates the cost of architectures in their search process. On ImageNet, your performance is similar to theirs. I think this will be a good comparison.\n\n3. The paper has some grammatical errors. I obviously missed many, but here are the one I found:\n\n- Section 3.3: “Different from pruning, which the search space is usually quite limited”. “which” should be “whose”?\n\n- Section 4.4.1: “DSO-NAS can also search architecture [...]”  -> “DSO-NAS can also search for architectures [...]”\n\nReferences.\n[1] SGDR: Stochastic Gradient Descent with Warm Restarts. https://arxiv.org/pdf/1608.03983.pdf\n\n[2] MnasNet: Platform-Aware Neural Architecture Search for Mobile. https://arxiv.org/pdf/1807.11626.pdf\n']","[50, 50, 50]","[60, 75, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'impressive results' and 'good ablation study', while also noting areas for improvement. The review proposes 'marginal acceptance', indicating a generally positive but cautious stance. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as proposals rather than demands. The reviewer points out errors and areas for improvement without harsh language, maintaining a professional tone. The use of phrases like 'I propose' and 'Would keeping... be at all helpful?' demonstrate a considerate approach to feedback."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary and lists both pros and cons. The overall tone is cautiously optimistic, as evidenced by the final sentence stating the method is 'promising'. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout, avoiding harsh criticism and presenting both positive and negative aspects in a balanced manner. The review is structured clearly and objectively, which contributes to its politeness. The use of phrases like 'appropriately evaluated' and 'the selection... is appropriate' further demonstrates a courteous approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by summarizing the paper's main ideas and contributions, and then lists both strengths and weaknesses. The strengths mentioned are substantial (e.g., 'neat idea', 'impressive', 'nice'), indicating a positive view of the paper. However, the weaknesses section is also detailed, balancing out the positive aspects.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's contributions and frame criticisms as suggestions or questions rather than direct attacks. Phrases like 'it would be nice to see' and 'I think this will be a good comparison' demonstrate a collaborative tone. Even when pointing out grammatical errors, the reviewer prefaces with 'I obviously missed many,' showing humility. The overall tone is professional and aimed at improving the paper rather than tearing it down.""]"
"[""This paper proposes to use GAN to address the image compression problem. It is shown to achieve superior results over the past work in two different settings (GC and SC). \n\nNovelty:\n\nIt has been well discovered in the literature of GANs that they can resolve the problem of blurriness in generation, compared to the traditional MSE loss. This paper proposes to combine a GAN loss with MSE, together with an entropy loss. However similar approaches were used such as video prediction [1] from 2016. The paper lacks a few references like this.\n\nMajor questions:\n\n- How do the different loss terms play against each other? The entropy term and the MSE apparently conflict with each other. And how would this affect L_gan? I would like to request some more analysis of this or ablation study on different terms.\n\n- How well does the GAN converge? A plot of G and D loss is often presented with GAN approaches.\n\n- Discrete latent variable is in itself an interesting problem [2]. I see the image compression as a task to discover a discrete latent variable with minimal storage. Perhaps one most important problem is how to estimate the gradient through the discrete bottleneck. But the paper doesn't provide much insights or experiments on this. \n\n- I'm not fully convinced by the claim of the noise that this paper uses to combine the code can act as a regularizer. Adding the noise makes the decoder output stochastic, but the compression problem seems to be deterministic by nature, unlike many other generation problems.\n\n[1] https://arxiv.org/abs/1511.05440\n[2] https://arxiv.org/abs/1711.00937"", 'This paper proposed an interesting method using GANs for image compression. The experimental results on several benchmarks demonstrated the proposed method can significantly outperform baselines. \n\nThere are a few questions for the authors:\n\n1.The actually benefit from GAN loss: the adversarial part usually can benefit the visual quality but is not necessary related to image quality (e.g. SSIM, PSNR).  \n\n2.The novelty of the model: GAN models with multiple G-Ds or local/global discriminators is not novel (see the references).\n\n3.Do you have ablation study on the effects of conditional GAN and compression part to the model? \n\nReferences: \na. Xi et al. Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond \nb. Yixiao et al. FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification\n\nRevision: the rebuttal can not address my concerns, especially the image quality assessment and the novelty of the paper parts. I will keep my original score but not make strong recommendation to accept the paper. ', 'This paper proposed GAN-based framework for image compression and show improved results over several baseline methods. Although the approach is not very novel by itself, the adaption and combination of existing methods for the proposed solution is interesting. Although the bpp are consistently lower, the quality metrics used for comparison seem unclear.\n\n\nPros:\n+ The reported compression results with a GAN-based framework for large images are impressive\n+ Comprehensive set of results with Kodak, RAISE1K and Cityscapes datasets\n+ The paper is well written with the core results and idea being well articulated\n\n\nCons:\n+ Primary concern:  The quality metrics are unclear esp. for GC models, since traditional metrics such MS-SSIM and PSNR are noted to worse and primarily visual inspection is used for comparison, making it less concrete. Would also to help include these metrics for comparison\t\n+ Eqn6: \\lamda balancing the distortion between GAN loss and entropy terms - can the authors elaborate on this ? Furthermore, the ensuing statement that the addition of the distortion term, results in acting like a regularizer - seems like only a conjecture, can the authors additionally comment on this as well. \n\n\nMinor issues:\n+ The comparison of improvement in compression is reported using relative percentage numbers in some places as the improvement and others as lack of therein. It would help to use a common reporting notation throughout the text, this helps readability/understandability ']","[-20, -20, 50]","[50, 50, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('superior results over the past work'), they raise several major questions and concerns about the approach, methodology, and claims. The reviewer points out lack of references, requests for more analysis, and expresses skepticism about some claims. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, framing criticisms as questions or requests for more information rather than direct attacks. They use phrases like 'I would like to request' and 'I'm not fully convinced' which maintain a polite tone while still expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the method as 'interesting' and notes that it 'significantly outperforms baselines', they express several concerns and ultimately do not recommend acceptance. The phrase 'keep my original score but not make strong recommendation to accept' indicates a negative leaning. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, framing criticisms as questions and using neutral terms like 'interesting' rather than harsh critiques. They also provide specific references to support their points, which is a courteous academic practice. However, the tone remains professional rather than overtly friendly, hence the moderate rather than high score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as impressive compression results and comprehensive datasets, while also pointing out areas for improvement. The overall tone is balanced, with both pros and cons listed. The politeness score is 75 (fairly polite) as the reviewer uses respectful language throughout, framing criticisms as suggestions or requests for clarification rather than direct attacks. Phrases like 'Would also help to include' and 'can the authors elaborate on this?' demonstrate a constructive approach. The review maintains a professional tone without using overly harsh or negative language.""]"
"['Update: Lower the confidence and score after reading other comments. \n===\n\nIn this paper, the authors benchmark several RL algorithms on their abilities of generalization. The experiments show interpolation is somehow manageable but extrapolation is difficult to achieve. \n\nThe writing quality is rather good. The authors make it very clear on how their experiments run and how to interpret their results. The experiments are also solid. It\'s interesting to see that both EPOpt and RL^2, which claim to generalize better, generalize worse than the vanilla counterparts. Since the success rates are sometimes higher with more exploration, could it be possible that the hyperparameters of EPOpt and RL^2 are non-optimal? \n\nFor interpolation/extrapolation tasks, all 5 numbers (RR, EE, DR, DE, RE) are expected since the geometric mean is always 0 once any of the numbers is 0. \n\nWhat does ``""KL divergence coefficient"" in RL^2-PPO mean? OpenAI\'s Baselines\' implementation includes an entropy term as in A2C. \n', 'This paper proposes a benchmark for for reinforcement learning to study generalization in stationary and changing environments. A combination of several existing env. from OpenAi gym is taken and several ways to set this parameters is proposed. Paper provides a relatively thorough study of popular methodologies on this benchmark.\n\nOverall, I am not sure there is a pressing need for this benchmark and paper does not provide an argument why there is an urgent need for one.\n\nFor instance, paragraph 3 on page 1 details a number of previous studies. Why those benchmarks are in-adequate?\nOn page at the end of second paragraph a  number of benchmarks from transfer learning literature is mentioned. Why not just use those and disallow model updates?\nIn the same way, it is not clear why new metric is introduced? How does it correlate with standard reward metrics?\n\nOverall, as empirical study, I think this work is interesting but I think paper should justify why we need this new benchmark.', 'This paper presents a new benchmark for studying generalization in deep RL along with a set of benchmark results. The benchmark consists of several standard RL tasks like Mountain Car along with several Mujoco continuous control tasks. Generalization is measured with respect to changes in environment parameters like force magnitude and pole length. Both interpolation and extrapolation are considered.\n\nThe problem considered in this paper is important and I agree with the authors that a good set of benchmarks for studying generalization is needed. However, a paper proposing a new benchmark should have a good argument for why the set of problems considered is interesting. Similarly, the types of generalization considered should be well motivated. This paper doesn’t do a good job of motivating these choices.\n\nFor example, why is Mountain Car a good task for studying generalization in deep RL? Mountain Car is a classic problem with a two-dimensional state space. This is hardly the kind of problem where deep RL shines or is even needed at all. Similarly, why should we care whether an agent trained on the Cart Pole task can generalize to a pole length between 2x and 10x shorter than the one it was trained on without being allowed to update its policy? Both the set of tasks and the distributions of parameters over which generalization is measured seem somewhat arbitrary.\n\nSimilarly, the restriction to methods that do not update its policy at test time also seems arbitrary since this is somewhat of a gray area. RL^2, which is one of the baselines in the paper, uses memory to adapt its policy to the current environment at test time. How different is this from an agent that updates its weights at test time? Why allow one but not the other?\n\nIn addition to these issues with the proposed benchmark, the baseline results don’t provide any new insights. The main conclusion is that extrapolation is more difficult than interpolation, which is in turn more difficult than training and testing on the same task. Beyond that, the results are very confusing. Two methods for improving generalization (EPOpt and RL^2) are evaluated and both of them seem to mostly decrease generalization performance. I find the poor performance of RL^2-A2C especially worrisome. Isn’t it essentially recurrent A2C where the reward and action are fed in as inputs? Why should the performance drop by 20-40%?\n\nOverall, I don’t see the proposed tasks becoming a widely used benchmark for evaluating generalization in deep RL. There are just too many seemingly arbitrary choices in the design of this benchmark and the lack of interesting findings in the baseline experiments highlights these issues.\n\nOther comments:\n- “Massively Parallel Methods for Deep Reinforcement Learning” by Nair et al. introduced the human starts evaluation condition for Atari games in order to measure generalization to potentially unseen states. This should probably be discussed in related work.\n- It would be good to include the exact architecture details since it’s not clear how rewards and actions are given to the RL^2 agents.\n']","[50, -20, -70]","[70, 50, 20]","[""Sentiment score: The review starts with a neutral summary of the paper's content. It then praises the writing quality and clarity of the experiments, which is positive. The reviewer shows interest in the results and asks thoughtful questions, indicating engagement. However, the sentiment is not overwhelmingly positive, as there are some critical observations about the performance of certain algorithms. The overall tone is more positive than negative, but not extremely so, hence a score of 50.\n\nPoliteness score: The language used throughout the review is professional and respectful. The reviewer offers praise where due (e.g., 'The writing quality is rather good') and frames criticisms as questions or observations rather than direct attacks (e.g., 'could it be possible that the hyperparameters of EPOpt and RL^2 are non-optimal?'). The tone is constructive and inquisitive rather than harsh or dismissive. While not excessively formal or deferential, the review maintains a polite and collegial tone throughout, warranting a score of 70."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as an 'interesting' empirical study, they express significant doubts about the necessity of the proposed benchmark and new metric. The reviewer questions the need for this work multiple times, which indicates a generally skeptical stance. However, it's not entirely negative as they do recognize some value in the study.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I am not sure' and 'I think' to soften their criticisms, and they frame their concerns as questions rather than direct criticisms. The language is not overly formal or polite, but it avoids any rudeness or harsh statements, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is -70 because the reviewer expresses significant criticism and skepticism about the paper's approach, methodology, and results. They point out several issues with the benchmark design, question the choice of tasks, and express doubt about the usefulness of the proposed benchmark. The overall tone is quite negative, though not entirely dismissive.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively respectful tone throughout. They use phrases like 'I agree with the authors that...' and 'It would be good to include...', which show some level of politeness. However, the criticism is direct and doesn't employ many softening phrases, keeping the score only slightly positive rather than highly polite.""]"
"[""This paper proposes an encoder-decoder model based on the graph representation of inputs and outputs to solve the multi-label classification problem. The proposed model considers the output labels as a fully connected graph where the pair-wise interaction between labels can be modelled.\n\nOverall, although the proposed approach seems interesting, the representation of the paper needs to be improved. Below I listed some comments and suggestions about the paper.\n\n- The proposed model did not actually use any graph structure of input and output, which can potentially mislead the readers of the paper. For instance, the encoder is just a fully connected feed-forward network with an additional attention mechanism. In the same sense, the decoder is also just a fully connected feed-forward network. Furthermore, the inputs and outputs used throughout the paper do not have any graph structure or did not use any inferred graph structure from data. I recommend using any graph-structured data to show that the proposed model can actually work with the graph-structured data (with proper graph notations) or revise the manuscript without graph2graph representation.\n\n- I personally do not agree with the statement that the proposed model is interpretable because it can visualise the relation between labels through the attention. NN is hard to interpret because the weight structure cannot be intuitively interpretable. In the same sense, the proposed model cannot avoid the problem with the nature of black-box mechanism. Especially, multiple weight matrices are shared across the different layers, which makes it more difficult to interpret. Although the attention weights can be visualised, how can we visualise the decision process of the model from end-to-end? The question should be answered to claim that the model is interpretable.\n\n- 2.2.1, 2.2.2, 2.3 shares the similar network layer construction, which can be represented as a new layer of NN with different inputs (or at least 2.2.2 and 2.3 have the same layer structure). It would be better to encapsulate these explanations into a new NN module which can be reused multiple parts of the manuscript for a concise explanation.\n\n- Although the network claims to model the interactions between labels, the final prediction of labels are conditionally independent to each other, whereas the energy based models such as SPEN models the structure of output directly. In that sense, the model does not take into account the structure of output when the prediction is made although the underlying structure seems to model the 'pair-wise' interaction between labels.\n\n- In Table1, if the bold-face is used to emphasise the best outcome, I found it is inconsistent with the result (see the output of delicious and tfbs datasets).\n\n- Is it more natural to explain the encoder first followed by the decoder?"", 'As a reviewer I am expert in learning in structured data domains. Because of that I completely disagree that the proposed title of the paper is not misleading. In fact, both the input and the output of the proposed system are not graphs. Moreover, the intermediate representations are always complete graphs, so there is no graph to graph transformation here. It is the internal topology of the encoder and decoder that corresponds to a complete graph and not the nature of the processed data. \nThe main intended contribution of the paper is to define a system able to capture the dependencies among input features as well as output labels, so to improve the multi-label classification task addressed by the system. This is obtained by defining a recurrent model with a complete graph topology to both encode the input and decode the output. The decoding part starts from the assumption of independence among the output labels and then, via interaction with the encoded representation of the input, eventually turns to an output where relevant statistical dependences among output labels emerge with decoding. Since both encoding and decoding are recurrent models (with no enforced guarantee to have stable points), the paper proposes to unfold the recursion for a fixed predefined number of time steps.\nPresentation of the proposal is generally good, although there are some issues that are not clear. For example, the same weights indices are used for matrices belonging to the encoding and decoding, making the reader to believe that such matrices are shared. In addition, the sentence about model parameters at page 5 is a bit ambiguous and it is not sufficient to resolve the presentation problem. \nThe discussion at the end of page 4 on the fact that a sequential representation for the input components is not natural is actually out of place for the specific application task selected for presentation. In fact, words in a sentence have an order. The fact that such order is lost with the bag-of-word representation is a problem of preprocessing, not of the nature of the data. In general, however, it is true that forcing an order is not natural. \nGoing in the merit of the proposal, the number of parameters for the decoder scales quadratically with the number of output labels (fully connected graph). In domains with a large numbers of labels (e.g. thousands) there may be concerns on two different aspects: i) computational burden may grow significantly even if the average number of labels per item is small; ii) proper propagation of information on dependencies among labels may require to use a large value for T (graph hops), i.e. there is a dependency between size of label graph and ""useful"" value for T.  On this issue, by the way, figures 3 and 4 seem to report incongruent results since, because of symmetries in the model topology, equal and  reciprocal influences between input components (and output labels) would have been expected, but these are not observed in the figures. \nAnalogous considerations could be done for the encoder when the size of the input is large.\nConcerning experimental results, no statistical significance test is performed, so it is not clear to me if the shown improvements are actually significant. Speed-up in training and testing seem at least to give some advantage with respect to other competing approaches, however the scaling problem described above for the decoder (and encoder) may lead to much worst performances in those special cases.\nThe addressed problem is covered by a large literature, involving many different approaches. It would have been nice to report, for the selected datasets, the best performance (and computation times) obtained by, for example,  probabilistic graphical models or SVM-based models.\nThe paper seems to refer most of the relevant recent neural-based approaches.\nI think the paper is relevant for ICLR (although there is no explicit analysis of the obtained hidden representations) and of interest for a good portion of attendees. \n\nMinor issues: \n- two rows before Section 2.2.1: \\mathbb{h}_*^2  should be \\mathbb{h}_*^1\n- equations 4, 5, 9, 10, 14: matrices W are indexed in such a way to assume that each input word/label is associated to a different matrix (i.e., set of parameters). Is this really the case ? How is then managed the fact that different inputs may have a different number of components ? how is a specific matrix assigned to a specific word ? I guess this is a presentation mistake, otherwise there are relevant issues that are completely not addressed by the presentation.\n- equation (10): since the output should be interpreted as a probability, why not using a softmax? sigmoidal units by themselves do not guarantee that the outputs sum to 1. I guess you do not have this problem because you adopt batch normalisation. This however is conceptually not nice since there is no uniformity across the dataset. Moreover, the softmax function has a nice probabilistic interpretation in the family of the exponential distributions.\n- ""[...] we use add a positional encoding...""\n- Multi-head Attention: apart for the not so clear description, the equation involving the softmax is missing.\n- ""[..] the the attention and feedforward layers.""\n- ""[..] the the sum of the total true...""\n', 'The paper describes an approach for using graph neural networks (GNN) to perform multi-label classification (MLC). The main idea is to use attentional pooling to project an input graph into a ""label graph"", whose nodes correspond to labels on some MLC problem. Multiple rounds of self-attention/message-passing hops can be performed on the input graph and label graph. Each output label is binary-valued, and is predicted from its corresponding node in the label graph. They evaluate on 6 multi-label sequence classification datasets, and report strong perform over baselines.\n\nThough interesting, I recommend rejection for several reasons:\n\n1) The technical contribution has limited novelty. One (very recent) reference this paper misses is ""Hierarchical Graph Representation Learning with Differentiable Pooling"" by Ying et al. (2018), which uses a very similar mechanism. The field is moving quickly, so references get missed sometimes, however from what I can tell, the graph-coarsening idea presented here isn\'t that technically distinct from Ying el al.\'s. The Mrowca et al. (2018) ""Flexible Neural Representation for Physics Prediction"" is also fairly similar and should probably at least be cited.\n\n2) There aren\'t strong baselines. This approach is based on GNNs, and the Graph2MLP results, which is similar to previous GNN graph-level classification methods, are fairly strong too. My suspicion is that with some more tuning and tweaking, the results here would be similar to those of Ying et al., Velickovic et al. (2017)\'s Graph Attention Nets, and other models which use what Gilmer et al. (2017) terms the ""readout"" function for MLC. Without testing some of these other approaches, how can readers be sure this is approach has value over other approaches? The reviews by Gilmer et al. (2017) and Battaglia et al. (2018) summarize a bunch of alternatives that could be tried, some of which use similar encoder/decoder setups (not with the attentional pooling, however, as far as I know).\n\n3) The writing is fairly dense for what is a fairly straightforward idea. And the paper is over 8.5 pages, with key details in the Appendix. \n\nI believe this approach could be quite powerful, and there was clearly a lot of excellent work that went into this project. But because the GNN area is very active, the bar is high. With a little more innovation on the model side (can the same core model be useful for things beyond MLC as well? I\'m guessing it could), better baselines, better scholarship, and condensing the writing, I think this paper can be an important step forward.\n\n']","[-30, -40, -60]","[50, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges the approach as 'interesting', they express several significant concerns and criticisms about the paper's representation, claims of interpretability, and methodology. The overall tone suggests the paper needs substantial revisions. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I recommend', 'It would be better', and frame criticisms as personal opinions ('I personally do not agree') rather than absolute statements. The reviewer also balances critique with acknowledgment of potentially positive aspects ('the proposed approach seems interesting')."", ""The sentiment score is -40 because the reviewer expresses significant disagreement with core aspects of the paper, including the title and methodology. They point out several issues and limitations, though they do acknowledge some positive aspects like good presentation and relevance to the conference. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They avoid harsh personal comments and frame their concerns as suggestions for improvement. The reviewer also acknowledges the paper's strengths alongside its weaknesses, maintaining a balanced tone overall."", ""The sentiment score is -60 because the reviewer recommends rejection and lists several significant criticisms, including limited novelty, lack of strong baselines, and dense writing. However, they do acknowledge some positive aspects like the interesting approach and excellent work, which prevents the score from being even lower. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges the effort put into the work, and provides constructive feedback. They use phrases like 'Though interesting' and 'I believe this approach could be quite powerful' which soften the criticism. The reviewer also offers suggestions for improvement, showing a helpful attitude rather than just criticism.""]"
"['Overview:\n\nThis paper proposes an approach to document classification in a low-resource language using transfer learning from a related higher-resource language. For the case where limited resources are available in the target low-resource language (e.g. a dictionary, pretrained embeddings, parallel text), multi-task learning is incorporated into the model. The approach is evaluated in terms of document classification performance using several combinations of source and target language.\n\nMain strengths:\n\n1. The paper is well written. The model description in Section 2 is very clear and precise.\n2. The proposed approach is simple but still shows good performance compared to models trained on corpora and dictionaries in the target language.\n3. A large number of empirical experiments are performed to analyse different aspects and the benefits of different target-language resources for multi-task learning.\n\nMain weaknesses:\n\n1. The application of this model to document classification seems to be new (I am not a direct expert in document classification), but the model itself and the components are not (sequence models, transfer learning and multitask learning are well-established). So this raises a concern about novelty (although the experimental results are new).\n\n2. With regards to the experiments, it is stated repeatedly that the DAN model which are compared to uses ""far more resources."" The best ALL-CACO model also relies on several annotated but ""smaller"" resources (dictionaries, parallel text, embeddings). Would it be possible to have a baseline where a target-language model is trained on only a small amount of annotated in-domain document classification data in the target language? I am proposing this baseline in order to answer two questions. (i) Given a small amount of in-domain data for the task at hand, how much benefit do we get from additionally using data from a related language? (ii) How much benefit do we get from using target-language resources that do not address the task directly (dictionaries, embeddings) compared with using a ""similar"" amount of data from the specific task?\n\nOverall feedback:\n\nThis is a well-written paper, but I think since the core of the paper lies in its empirical evaluation, the above experiments (or something similar) would greatly strengthen the work.\n\nEdit: I am changing my rating from 5 to 6 based on the authors\' response.', 'Summary: The authors address the task of cross language document classification when there is no training data available in the target language but data is available a closely related language. The authors propose forming character-based embeddings of words to make use of sub-word similarities in closely-related languages. The authors do an extensive evaluation using various combinations of related languages and show improved performance. In particular,  the performance is shown to be competitive with word-based models, which are tied to a requirement of resources involving the original language (such as MT systems, bilingual lexicons, etc). The authors show that their results are boosted when some additional resources (such as bilingual dictionaries of minimal size) are used in a multi-task learning setup.\n\n\n- I would have liked to see some comparison where your model also uses all the resources available to CLWE based models (for example, larger dictionary, larger parallel corpus, etc)\n\n- It is mentioned that you used parallel projection only for Amharic as for other languages you had enough RCV2 training data. However, it would be interesting to see if you still use parallel projection on top of this.\n\n- I do not completely agree with the statement that CACO models are ""not far behind"" DAN models. IN Table 1, for most languages the difference is quite high. I understand that your model uses fewer resources but can it bridge the gap by using more resources? Is the model capable of doing so ?\n\n- How did you tune the lambdas in Eqn 11? Any interesting insights from the values of these lambdas? Do these lambda values vary significantly across languages ?\n\n- The argument about why the performance drops when you use language identifiers is not very convincing. Can you please elaborate on this ?\n\n- Why would the performance be better in one directions as compared to another (North Germanic to Romance v/s ROmance to North Germanic). Some explanation is needed here.\n\n- One recurring grievance that I have is that there are no insights/explanations for any results. Why are the gains better for some language pairs? Why is there asymmetry in the results w.r.t direction of transfer ? In what way do 2 languages help as compared to single source language? What is you use more that 2 source languages?\n\n', 'The paper proposes to transfer document classifiers between (closely) related languages by exploiting cross-lingual subword representations in a cross-lingual embedder jointly with word-based classifier: the embedder represents the words, while the classifier labels the document. The approach is reasonable, albeit somewhat unexciting, as the basic underlying ideas are in the vein of Pinter et al. (2017), even if applied on a different task.\n\nThe main concern I have with the paper is that it leaves much open in terms of exploring the dimension of (dis)similarity: How does the model perform when similarity decreases across language pairs in the transfer? The paper currently offers a rather biased view: the couplings French-Italian-Spanish, Danish-Swedish are all very closely related languages, and Amharic-Tigrinya are also significantly related. Outside these couplings, there\'s a paragraph to note that the method breaks down (Table 5 in the appendix). Sharing between Romance and Germanic languages is far from representative of ""loosely related languages"", for all the cross-cultural influences that the two groups share.\n\nWhile the experiment is reasonably posed, in my view it lacks the cross-lingual breadth and an empirical account of similarity. What we do in cross-lingual processing is: port models from resource-rich to low-resource languages, and to port between very similar languages that already have resources is a purely academic exercise. This is not to say that evaluation by proxy should be banned, but rather that low-resource setups should be more extensively controlled for.\n\nThus, in summary, a rather straightforward contribution to computational modeling paired with sub-par experiment setup in my view amounts to a rejection. The paper can be improved by extending the experiment and controlling for similarity, rather than leaving it as implication.']","[60, 50, -60]","[80, 70, 20]","[""The sentiment score is 60 (moderately positive) because the reviewer notes several strengths of the paper, including that it is well-written, shows good performance, and includes extensive experiments. However, they also point out some weaknesses and suggest additional experiments, indicating it's not entirely positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer also mentions changing their rating positively based on the authors' response, showing a willingness to engage positively."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the extensive evaluation and improved performance of the authors' approach, while also providing constructive criticism and suggestions for improvement. The review begins with a positive summary of the work but follows with several points for enhancement, indicating a balanced perspective. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct criticisms. For example, 'I would have liked to see...' and 'Can you please elaborate on this?' The reviewer also acknowledges the authors' achievements while requesting more information, maintaining a collegial tone throughout the review."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, describing it as 'unexciting' and having a 'sub-par experiment setup'. The reviewer ultimately recommends rejection, indicating a negative sentiment. However, they do acknowledge some positive aspects ('reasonable', 'reasonably posed'), preventing the score from being extremely negative. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'The main concern I have' and 'in my view', which soften the criticism. The reviewer also offers constructive suggestions for improvement, which is a polite approach. However, the directness of some criticisms ('rather straightforward contribution', 'sub-par experiment setup') prevents the score from being higher on the politeness scale.""]"
"['The biggest contribution is the setting part, where one seeks to adapt one source to multiple, but somewhat similar, target domains.  It is interesting to explore such direction since in many real-world applications, applying the model to many different target domains are required.   \n\nIt is also noted that there is one very related work ""Multi-target Unsupervised Domain Adaptation without Exactly Shared Categories"" available online (https://arxiv.org/pdf/1809.00852.pdf).  It is desirable to have a discussion and comparison with them since they are doing Multi-target Unsupervised Domain Adaptation. In their method, the exact shared category is even not required. \n\nFor the algorithm part, authors basically adopt the information-theoretic approach to handle the proposed method. This part contribution is limited since the techniques involved are very common in the domain adaptation. \n\n', 'This paper investigates multi-target domain adaptation which is an unexplored domain adaptation scenario compared with adapting single/multiple source to single target. A mutual information-based loss is proposed to encourage part of the features to be domain-specific while the other part to be domain-invariant. Instead of optimizing the proposed loss which is intractable, this work proposes to use neural network to model the relative functions and optimize proposed loss’ lower bound by SGD.\n\nMethod: \nThe proposed loss has an explanation from information theory, which is nice. However, the proposed loss is a combination of 4 different mutual information. The effectiveness of each one is unclear. An ablation study should be provided. \n\nClarity: The presentation should be improved, especially in the descriptions for experiments. \n- Typo: Section 4: TanH should be Tanh\n- Duplicated reference: Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-level domain adaptation with generative adversarial networks. In CVPR, July 2017a.\n\nResults: \n- I am confused by the experimental settings of MTDA-ITA, c-MTDA-ITA, and c-MTDA-ITA. s-MTDA-ITA. I understand c-MTDA-ITA is to combine all the target domains into a single one and train it using MTDA-ITA. And s-MTDA-ITA is to train multiple MTDA-ITA separately, where each one corresponds to a source-target pair. But I am confused by the MTDA-ITA results in both table 1 and table 2. Could the authors provide some explanation for MTDA-ITA?\n\n- For the metric in digits adaptation, the standard metric is classification accuracy. The authors use mean classification accuracy. Is this the mean of classification accuracy of multiple runs? If so, authors should provide the standard deviation. If this is the average per-class accuracy, this is different from standard routine in ADDA, CORAL, etc.\n\nConcerns: \nThe effectiveness of MDTA-ITA, s-MDTA-ITA and c-MDTA-ITA are not convincing. From the experiments, it seems the c-MDTA-ITA cannot provide convincing superior performance compared to c-ADDA and c-DTN.', 'In this paper, the authors proposed a new domain adaptation setting for adaptation between single source but multiple target domains. To address the setting, the authors proposed a so-called information theoretic approach to disentangle shared and private features and meanwhile to take advantage of the relationship between multiple target domains. \n\nPros:\n- This paper conducts comprehensive empirical studies.\n\nCons:\n- The motivation for this new domain adaptation setting is not clear to me. In the real world, the domain adaptation between multiple source domains and single target domain is in desperate need, as like human beings an agent may gradually encounter many source domains which could altogether benefit a target domain. However, I do not think that the adaptation between single source and multiple targets is intuitively in need.\n- The proposed framework is quite similar to DSN, which limits this work\'s novelty. Though the authors take a large paragraph to illustrate the connections and differences between this work and DSN, I cannot be convinced. Especially during empirical study, the comparison is not fair. The adapted mp-DSN models multiple encoders for multiple target domains, while it is correct to extend DSN with a shared encoder for multiple target domains just like MDTA-ITA.\n- There are technical flaws. The authors claimed that this work is different from ELBO optimisation, but follows an information theoretical approach. Actually, the right way to optimise the proposed loss in Eqn. (1)(2) is exactly the ELBO. Instead, the authors replace the probability/distribution q(x|z) and q(d|z) with concrete terms, which is technically wrong. such concrete term ||x-F(z;\\phi)|| cannot represent a probability/distribution. \n- In the experiments for feature visualisation, I do not think such comparison with original features makes any sense. The features by DSN which also separates private from shared features  should be compared. \n- The presentation is in a quite poor quality, including many typos/grammatical errors. \n   - The most annoying is the inappropriate citations. Every citation should be included in a brace, e.g. ""the same underlying distribution Sun et al. (2016)"" -> ""the same underlying distribution (Sun et al. (2016))"". Please kindly refer to other submissions to ICLR 2019. \n   -  Typos: in the beginning of Section 2, ""without loss of generalizability"" -> ""without loss of generality""; in the end of Page 3,  the last equation is not right, where p(y|z_s) should be q(y|z_s).\n   - The font in Table 2 is too small to read. \n']","[20, -30, -60]","[50, 20, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting and relevant aspects of the work, particularly in the first paragraph. They mention the 'biggest contribution' and note that the direction is 'interesting to explore'. However, the sentiment is not strongly positive due to critiques in the following paragraphs, such as the limited contribution in the algorithm part. The politeness score is moderately positive (50) as the reviewer uses neutral and professional language throughout, avoiding harsh criticism. They use phrases like 'It is desirable' and 'It is also noted' which maintain a respectful tone. The reviewer provides constructive feedback and suggestions for improvement without using negative or rude language."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('nice explanation from information theory'), they express several concerns and criticisms. These include unclear effectiveness of the proposed method, need for ablation studies, confusion about experimental settings, and unconvincing performance compared to other methods. The politeness score is slightly positive (20) as the reviewer uses professional language and offers constructive feedback. They use phrases like 'Could the authors provide some explanation' and 'should be improved' rather than harsh criticism. The reviewer also points out positive aspects alongside the critiques, maintaining a balanced tone."", ""The sentiment score is -60 because the review lists significantly more cons than pros, and the cons are quite substantial (questioning the motivation, novelty, and technical correctness of the paper). The single pro mentioned is relatively minor. However, it's not maximally negative as the reviewer does acknowledge some positive aspects. The politeness score is 20 because the reviewer uses generally polite language ('I cannot be convinced' rather than 'This is wrong'), offers some constructive feedback, and frames criticisms as their personal opinion. However, some phrases like 'quite poor quality' and 'the most annoying' prevent a higher politeness score. The reviewer also provides specific suggestions for improvement, which is a polite approach to criticism.""]"
"[""Strengths:\n- clear explanation of the problem\n- clear explanation of the model and its application (pseudocode)\n- clear explanation of training and resulting hyperparameters\n\nWeaknesses:\n- weak experimental settings: \n-- (a) comparison against 'easy to beat' baselines. The comparison should also include as baselines the very relevant methods listed in the last paragraph of the related work section (Snow et a.l 2005, Sun and Grishman 2010, Liao et al. 2017, Cambria et al. 2018). \n-- (b) unclear dataset selection: it is not clear which datasets are collected by the authors and which are pre-existing datasets that have been used in other work too. It is not clear if the datasets that are indeed collected by the authors are publicly available. Furthermore, no justification is given as to why well-known publicly available datasets for this task are not used (such as CoNLL-YAGO (Hoffart et al. 2011), ACE 2004 (NIST, 2004; Ratinov et al. 2011), ACE 2005 (NIST, 2005; Bentivogli et al. 2010), and Wikipedia (Ratinov et al. 2011)).\n- the coverage of prior work ignores the relevant work of Gupta et al. 2017 EMNLP. This should also be included as a baseline.\n- Section 2 criticises Mikolov et al.'s skip-gram model on the grounds that it introduces noisy entities because it ignores context structure. Yet, the skip-gram model is used in the preprocessing step (Section 3.1). This is contradictory and should be discussed.\n- the definition of synonyms as entities that are interchangeable under certain contexts is well known and well understood and does not require a reference. If a reference is given, it should not be a generic Wikipedia URL.\n- the first and second bulletpoint of contributions should be merged into one. They refer to the same thing. \n- the paper is full of English mistakes. A proficient English speaker should correct them.\n"", ""The paper presents a neural network model (SYNONYMNET) for automatically discovering synonymous entities from a large free-text corpus with minimal human annotation. The solution is fairly natural in the form of a siamese network, a class of neural network architectures that contain two or more identical subnetworks, which are an obvious approach for such a task, even though this task's SotA does not cover such architectures. even though the abstract consists the word novel, the chosen architecture is not a novel one but attached to this task, it can be considered as if.\n\n# Paper discussion:\n\nThe introduction and the related work are well explained and the article is well structured. The authors mark very well the utility of automatically discovering synonyms.\n\nSection 2 presents the SynonymNet, mainly the bi-LSTM applied on the contexts and the bilateral matching with leaky unit and the context aggregation for each entity, along with training objectives and the inference phase.\n\nThe novelty does not consist in the model since the model derives basically from a siamese network, but more in the approach, mainly the bilateral matching: one input is a context for an entity, the other input is a context for the synonym entity, and the output is the consensus information from multiple pieces of contexts via a bilateral matching schema with leaky unit (highest matched score with its counterpart as the relative informativeness score) and the context aggregation. The inference phase is a natural step afterward. Also, the usage of the leaky unit is clearly stated.\n\nSection 3 presents the experimental phase, which is correct. The choice of LSTMs is understandable but other experiments could have been done in order to make clearer why it has been chosen. Regarding also the word embeddings choice, other experiments could have been completed (word2vec and GloVe have been competing with many other embeddings recently).\n\nOne noticed misspelling: GolVe (Pennington et al., 2014) "", 'This paper studies the problem of identifying (discovering) synonymous entities. The paper proposes using the ""contexts"" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task. The key novelties of the approach lie in the ""matching"" system used, where contexts of one entity are matched with that for the other entity to see how well they align with each other (which effectively determines the similarity of the two entities). Experiments are conducted on three different datasets to show the efficacy of the proposed approach.\n\nOverall I found the paper to be an interesting read with some nice ideas mixed in. However I also had some concerns which are highlighted later down below, which I believe if addressed would lead to a very strong work.\n\nQuality: Above average\n\nIn general the method seems to work somewhat better than the baselines and the method does have a couple of interesting ideas.\n\nClarity: Average\n\nI found a few key details to be missing and also felt the paper could have been better written.\n\nOriginality: Average\n\nThe matching approach and use of the leaky units was interesting tidbits. Outside of that the work is largely about the application of such Siamese RNNs based networks to this specific problem. (The use of context of entities has already been looked at in previous works albeit in a slightly more limited manner)\n\nSignificance: Slightly below average\n\nI am not entirely sold on the use of this approach for this problem given its complexity and unclear empirical gains vs more sophisticated baselines. The matching aspect may have some use in other problems but nothing immediately jumps out as an obvious application.\n\n----\n\nStrengths / Things I liked about the paper:\n\n- In general the method is fairly intuitive and simple to follow which I liked.\n- The matching approach was an interesting touch.\n- Similarly for the ""leaky"" unit.\n- Experiments conducted on multiple datasets.\n- The results indicate improvements over the baselines considered on all the three datasets.\n\nWeaknesses / Things that concerned me:\n\n-  (W1) Slightly unfair baselines? One of the first things that struck me in the experimental results was how competitive word2vec by itself was across all three datasets. This made me wonder what would happen if we were to use a more powerful embedding approach say FastText, Elmo, Cove or the recently proposed BERT? (The proposed method itself uses bidirectional LSTMs)\n\nFurthermore all of them are equally capable of capturing the contexts as well. An even more competitive (and fair) set of baselines could have taken the contexts as well and use their embeddings as well. Currently the word2vec baseline is only using the embedding of the entity (text), whereas the proposed approach is also provided the different contexts at inference time. The paper says using the semantic structure and the diverse contexts are weaknesses of approaches using the contexts, but I don\'t see any method that uses the context in an embedding manner -- say the Cove context vectors. If the claim is that they won\'t add any additional value above what is already captured by the entity it would be good to empirically demonstrate this.\n\n- (W2) Significance testing: On the topic of experimentation, I was concerned that significance testing / error estimates weren\'t provided for the main emprical results. The performance gaps seem to be quite small and to me it is unclear how significant these gaps are. Given how important significance testing is as an empirical practice this seems like a notable oversight which I would urge the authors to address.\n\n- (W3) Missing key details: There were some key aspects of the work that I thought were not detailed. Chief among these was the selection of the contexts for the entities. How was this? How were the 20 contexts identified? Some of these entities are likely far more common than just 20 sentences and hence I wonder how these were selected?\n\nAnother key aspect I did not see addressed: How were the entities identified in the text (to be able to find the contexts for them)? The paper claims that they would like to learn from minimal human annotations but I don\'t understand how these entity annotations in the text were obtained. This again seems like a notable oversight.\n\n- (W4) Concerns about the method: I had two major concerns about the method: \n\n(a) Complexity of method :  I don\'t see an analysis of the computational cost of the proposed method (which scales quadratically with P the number of contexts); \n\n(b) Effect of redundant ""informative"" contexts: Imagine you have a number of highly informative contexts for an entity but they are all very similar to each other. Due to the way the matching scores are aggregated, these scores are made to sum to 1 and hence no individual score would be very high. Given that this is the final coefficient for the associated context, this seems like a significant issue right?\n\nUnless the contexts are selected to be maximally diverse, it seems like this can essentially end up hurting an entity which occurs in similar contexts repeatedly. I would like to see have seen the rationale for this better explained.\n\n(c) A smaller concern was understanding the reasoning behind the different loss functions in the siamese loss function with a different loss for the positive and the negative, one using a margin and one which doesn\'t. One which scales to 1/4, the other scaling to (1-m)^2. This seems pretty arbitrary and I\'d like to understand this.\n\n-(W5) Eval setting : My last concern was with the overall evaluation setup. Knowledge bases like Freebase are optimized for precision rather than recall, which is why ""discovery"" of new relations is important. However if you treat all missing relationships as negative examples then how exactly are you measuring the true ability of a method? Thus overall I\'m pretty skeptical about all the given numbers simply because we know the KBs are incomplete, but are penalizing methods that may potentially discover relations not in the KB.']","[-40, 60, -20]","[20, 80, 60]","[""The sentiment score is -40 because while the review acknowledges some strengths (clear explanations), it lists more weaknesses and areas for improvement. The criticisms are substantial, including weak experimental settings, missing comparisons to relevant baselines, unclear dataset selection, and contradictions in the paper's arguments. However, it's not entirely negative as it does recognize some positive aspects. The politeness score is 20 because the reviewer uses neutral language and frames criticisms as 'weaknesses' rather than direct attacks. The tone is professional and constructive, offering specific suggestions for improvement. However, the comment about English mistakes could be seen as slightly impolite, preventing a higher politeness score."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's strengths, such as being well-structured and explaining the utility of automatically discovering synonyms. They also note that while the model itself isn't novel, the approach and application are. The reviewer provides constructive feedback and suggestions for improvement, indicating a generally positive but not overwhelmingly enthusiastic sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and offering suggestions in a constructive manner. They use phrases like 'well explained' and 'correct', and even when pointing out areas for improvement, they do so diplomatically (e.g., 'other experiments could have been done'). The reviewer also politely notes a misspelling without being critical. The overall tone is professional and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer found some positive aspects ('interesting read with some nice ideas'), they expressed several significant concerns and weaknesses about the paper. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'I found', 'I believe', and 'I would urge the authors to' which maintain a polite tone even when expressing concerns.""]"
"['The paper proposes to plan by taking an initial plan and improving it. The authors claim that 1) this will achieve results faster than planning from scratch and 2) will lead to better results than using quick, local heuristics. However, when starting with an initial solution there is always the danger of the final solution being overly biased by the initial solution. The authors do not address this adequately. They show how to apply tree and DAG-based LSTMs to job scheduling and shortening expressions. Since they are simply using previously proposed LSTM variants, I do not see much contribution here. The experiments show some gains on randomly generated datasets. More importantly, details are missing such as the definitions of SP and RS from section 4.4.', ""\nSummary:\nSearch-based policies are stronger than a reactive policies, but the resulting time consumption can be exponential. Existing solutions include designing a plan from scratch given a complete problem specification or performing iterative rewriting of the plan, though the latter approach has only been explored in problems where the action and state spaces are continuous.\n\nIn this work, the authors propose a novel study into the application of iterative rewriting planning schemes in discrete spaces and evaluate their approach on two tasks: job scheduling and expression simplification. They formulate the rewriting task as a reinforcement learning problem where the action space is the application of a set of possible rewriting rules to modify the discrete state. \n\nThe approach is broken down into two steps. In the first step, a particular partition of the discrete state space is selected as needing to be changed by a score predictor. Following this step, a rule selector chooses which action to perform to modify this state space accordingly.\n\nIn the job scheduling task, the partition of the state space corresponds to a single job who’s scheduled time must be changed. the application of a rule to rewrite the state involves switching the order of any two jobs to be run. In the expression simplification task, a state to be rewritten corresponds to a subtree in the expression parse tree that can be converted to another expression.\n\nTo train, the authors define a mixed loss with two component:\n1. A mean squared error term for training the score predictor that minimizes the difference between the benefit of the executed action and the predicted score given to that node\n2. An advantage actor critic method for training the rule selector that uses the difference between the benefit of the executed action and the predicted score given to that node as a reward to evaluate the action sampled from the rule set\n\nPros:\n\n-The approach seems to be relatively novel and the authors address an important problem.\n-The authors don’t make their approach more complicated than it needs to be\n\nCons:\n\nNotation: The notation could be a lot clearer. The variable names used in the tasks should be directly mapped to those defined in the theory in Section 2. It wasn’t clear that the state s_t in the job scheduling problem was defined as the set of all nodes g_j and their edges and that the {\\hat g_t} corresponds to a single node. Also, there are some key details that have been relegated to the appendix that should be in the main body of the paper (e.g., how inference was performed)\n\nEvaluation: The authors perform this evaluation on two automatically generated synthetic datasets. It’s not clear that the method would generalize to real data. Why not try the approach on a task such as grammar error correction? Additionally, I would have liked to see more analysis of the method. Apart from showing the comparison of the method with several baselines, the authors don’t provide many insights into how their method works. How data hungry is the method? Seeing as the data is synthetically generated, how effective would the method be with 10X of the training data, or 10% of it? Were any other loss functions attempted for training the model, or did the authors only try the Advantage Actor Critic? What about a self-critical approach? I'd like to see more analysis of how varying different components of the method such as the rule selector and score predictor affect performance."", 'This paper addresses the challenges of prediction-based, progressive planning on discrete state and action spaces. Their proposed method applies existing DAG-LSTM/Tree-LSTM architectures to iteratively refine local sections in the existing plan that could be improved until convergence. These models are then evaluated on a simulated job scheduling dataset and Halide expression simplification.\n\nWhile this paper presents an interesting approach to the above two problems, its presentation and overall contribution was pretty unclear to me. A few points:\n\n1. Ambiguous model setup: It may have been more advantageous to cut a large portion of Section 3 (Problem Setup), where the authors provide an extensive definition of an optimization problem, in favor of providing more critical details about the model setup. For example, how exactly should we view the job scheduling problem from an RL perspective? How are the state transitions characterized, how is the network actually trained (REINFORCE? something else?), is it episodic (if so, what constitutes an episode?), what is the exploration strategy, etc. It was hard for me to contextualize what exactly was going on\n\n2. Weak experimental section: The authors mention that they compare their Neural Rewriter against DeepRM using a simplified problem setup from the original baseline. I wonder how their method would have fared against a task that was comparable in difficulty to the original method -- this doesn’t feel like a fair comparison. And although their expression simplification results were nice, I would also like to know why the authors chose to evaluate their method on the Halide repository specifically. Since they do not compare their method against any other baselines, it’s hard for me to gauge the significance of their results.\n\n3. Variance across initializations: It would have been nice to see an experiment on how various initializations of schedules/expressions affect the policies learned. I would imagine that poor initializations could lead to poor results, but it would be interesting if the Neural Rewriter was robust to the quality of the initial policy. Since this is not addressed in the paper, it is difficult to gauge whether the authors’ model performed well due to an unfair advantage. Additionally, how much computational overhead is there to providing these (reasonable) initial policies as opposed to learning from scratch?\n\n4. Unclear notation: As previously addressed by other reviewers, key definitions such as the predicted score SP(.) are missing from the text.\n']","[-50, -20, -50]","[0, 60, 20]","[""The sentiment score is -50 because the review is generally critical of the paper. The reviewer points out several weaknesses, such as the danger of bias from the initial solution, lack of novelty in the LSTM variants used, and missing details in the experiments. However, it's not entirely negative as the reviewer acknowledges some gains shown in the experiments. The politeness score is 0 (neutral) because the language used is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly without using harsh language, but also doesn't use particularly courteous phrasing. The tone is matter-of-fact and focused on the content of the paper rather than on being either polite or impolite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The approach seems to be relatively novel', 'authors address an important problem'), they list more cons than pros and express several criticisms and areas for improvement. The review suggests that the work has potential but needs significant refinement.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms ('It wasn't clear that...', 'I would have liked to see...') rather than harsh or dismissive statements. The reviewer also acknowledges positive aspects of the work before diving into criticisms, which is a polite approach in academic reviews."", ""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses in the paper. The reviewer states that the paper's presentation and overall contribution was 'pretty unclear', and lists multiple areas for improvement. However, it's not entirely negative as the reviewer acknowledges the approach as 'interesting' and some results as 'nice'. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone. They use phrases like 'It would have been nice to see' and 'I wonder how' rather than using harsh or dismissive language. The reviewer also provides specific, actionable feedback, which is a polite way to critique. However, the score is not higher as the language is quite direct and doesn't include many overtly polite phrases or compliments.""]"
"['I appreciate the work that went into creating this paper, but I\'m afraid I see little justification for accepting it.  I have three major complaints with this paper:                                                                         \n                                                                                                     \n1. I think the framing of decaNLP presented in this paper does more harm than good, because it perpetuates a misguided view of question answering.\n                                                                                                     \nQuestion answering is not a unified phenomenon.  There is no such thing as ""general question answering"", not even for humans.  Consider ""What is 2 + 3?"", ""What\'s the terminal velocity of a rain drop?"", and ""What is the meaning of life?""  All of these questions require very different systems to answer, and trying to pretend they are the same doesn\'t help anyone solve any problems.\n                                                                                                     \nQuestion answering is a _format_ for studying particular phenomena.  Sometimes it is useful to pose a task as QA, and sometimes it is not.  QA is not a useful format for studying problems when you only have a single question (like ""what is the sentiment?"" or ""what is the translation?""), and there is no hope of transfer from a related task.  Posing translation or classification as QA serves no useful purpose and gives people the wrong impression about question answering as a format for studying problems.\n\nWe have plenty of work that studies multiple datasets at a time (including in the context of semi-supervised / transfer learning), without doing this misguided framing of all of them as QA (see, e.g., the ELMo and BERT papers, which evaluated on many separate tasks).  I don\'t see any compelling justification for setting things up this way.\n                                                                                                     \n2. One of the main claims of this paper is transfer from one task to another by posing them all as question answering.  There is nothing new in the transfer results that were presented here, however.  For QA-SRL / QA-ZRE, transfer from SQuAD / other QA tasks has already been shown by Luheng He (http://aclweb.org/anthology/N18-2089) and Omer Levy (that was the whole point of the QA-ZRE paper), so this is merely reproducing that result (without mentioning that they did it first).  For all other tasks, performance drops when you try to train all tasks together, sometimes significantly (as in translation, unsurprisingly).  For the Czech task, fine tuning a pre-trained model has already been shown to help.  Transfer from MNLI to SNLI is known already and not surprising - one of the main points of MNLI was domain transfer, so obviously this has been studied before.  The claims about transfer to new classification tasks are misleading, as you really have the _same_ classification task, you\'ve just arbitrarily changed how you\'re encoding the class label.  It _might_ be the case that you still get transfer if you actually switch to a related classification task, but you haven\'t examined that case.\n                                                                                                     \n3. This paper tries to put three separate ideas into a single conference paper, and all three ideas suffer as a result, because there is not enough space to do any of them justice.  Giving 15 pages of appendix for an 8 page paper, where some of the main content of the paper is pushed to the appendix, is egregious.  Putting your work in the context of related work is not something that should be pushed into an appendix, and we should not encourage this behavior.\n                                                                                                     \nThe three ideas here seem to me to be (1) decaNLP, (2) the model architecture of MQAN, (3) transfer results.  Any of these three could have been a single conference paper, had it been done well.  As it stands, decaNLP isn\'t described or motivated well enough, and there isn\'t any space left in the paper to address my severe criticisms of it in my first point.  Perhaps if you had dedicated the paper to decaNLP, you could have given arguments that the framing is worthwhile, and described the tasks and their setup as QA sufficiently (as it is, I don\'t see any description anywhere of how the context is constructed for WikiSQL; did I miss it somewhere?).  For MQAN, there\'s more than a page of the core new architecture that\'s pushed into the appendix.  And for the transfer results, there is very little comparison to other transfer methods (e.g., ELMo, CoVe), or any deep analysis of what\'s going on - as I mentioned above, basically all of the results presented are just confirming what has already been done elsewhere.', ""Update: I've updated my score based on the clarifications from the authors to some of my questions/concerns about the experimental set-up and multi-task/single-task differences.\n\nOriginal Review:\nThis paper provides a new framework for multitask learning in nlp by taking advantage of the similarities in 10 common NLP tasks. The modeling is building on pre-existing qa models but has some original aspects that were augmented to accommodate the various tasks.  The decaNLP framework could be a useful benchmark for other nlp researchers.  \n\nExperiments indicate that the multi-task set-up does worse on average than the single-task set-up.  I wish there was more analysis on why multi-task setups are helpful in some tasks and not others.  With a bit more fine-grained analysis, the experiments and framework in this paper could be very beneficial towards other researchers who want to experiment with multi-task learning or who want to use the decaNLP framework as a benchmark.\n\nI also found the adaptation to new tasks and zero-shot experiments very interesting but the set-up was not described very concretely: \n  -in the transfer learning section, I hope the writers will elaborate on whether the performance gain is coming from the model being pretrained on a multi-task objective or if there would still be performance gain by pretraining a model on only one of those tasks.  For example, would a model pre-trained solely on IWSLT see the same performance gain when transferred to English->Czech as in Figure 4? Or is it actually the multi-task training that is causing the improvement in transfer learning? \n  -Can you please add more detail about the setup for replacing +/- with happy/angry or supportive/unsupportive? What were the (empirical) results of that experiment?\n\nI think the paper doesn’t quite stand on its own without the appendix, which is a major weakness in terms of clarity.  The related work, for example, should really be included in the main body of the paper.  I also recommend that more of the original insights (such as the experimentation with curriculum learning) should be included in the body of the text to count towards original contributions.  \n\nAs a suggestion, the authors may be able to condense the discussion of the 10 tasks in order to make more room in the main text for a related work section plus more of their motivations and experimental results.  If necessary, the main paper *can* exceed 8 pages and still fit ICLR guidelines.\n\nVery minor detail: I noticed some inconsistency in the bibliography regarding full names vs. first initials only."", ""The paper formulates several different NLP problems as Q&A problem and proposed a general deep learning architecture. All these tasks are trained together. \n\nIf the goal is to achieve general AI, the paper gives a good starting point. One technical novelty is the deep learning architecture for this general Q&A problem including the multi-pointer-generator. The paper presents an example of how to do a multi-task learning for 10 different tasks. It raises a very challenging problem or in some way release a new dataset.\n\nIf our goal is to optimize a single task, the usefulness of the method proposed by the paper is questionable. \nAs we know, multi-task learning works well if some important knowledge shared by different tasks can be learned and leveraged. From table 2, we see for many problems, the results of the single task training are better than the multi-task training, meaning that other tasks can't really help at least under this framework. This makes me doubt if this multi-task learning is useful if our goal is to optimize the performance of a single task. This general model also sacrifices some important prior knowledge of an individual task. For example, for the Squad, the prior that the answer is a continuous span. Ideally, the prior knowledge should be leveraged.\n\n""]","[-80, 50, 20]","[-20, 80, 50]","[""The sentiment score is -80 because the reviewer expresses strong disagreement with the paper's approach and findings, stating they see 'little justification for accepting it' and listing three major complaints. The tone is predominantly critical throughout. The politeness score is -20 because while the reviewer begins with a polite acknowledgment of the authors' work, the language quickly becomes blunt and dismissive, using phrases like 'misguided view', 'does more harm than good', and calling some claims 'misleading'. The reviewer maintains a professional tone but doesn't soften their criticisms, leading to a slightly impolite overall impression."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential usefulness, but also points out several areas for improvement. The reviewer sees value in the framework and experiments, but desires more analysis and clarity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or requests for clarification. The reviewer also acknowledges updating their score based on author clarifications, showing a willingness to engage positively. The use of phrases like 'I wish', 'I hope', and 'Can you please' contribute to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution to general AI and its technical novelty, but also expresses doubts about its usefulness for optimizing single tasks. The review starts with positive points but becomes more critical in the second half. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms constructively without harsh or rude phrasing. They acknowledge the paper's strengths before presenting their concerns, which is a polite approach to reviewing.""]"
"['The submission proposes to combine a tree2tree autoencoder with a sequence encoder for natural language. It uses the autoencoding objective to appropriately shape the latent space and train the decoder, and then uses a second training step to align the output of a sequence encoder with the input for the tree decoder. Experiments on a recent dataset for the natural language-to-code task show that the proposed model is able to beat simple baselines.\n\nThere\'s much to like about this paper, but also many aspects that are confusing and make it hard to tease out the core contribution. I\'m trying to reflect my understanding here, but the authors could improve their paper by providing an explicit contribution list. Overall, there seem to be three novel things presented in the paper:\n(1) (Pre)training the (program) tree decoder using an autoencoder objective\n(2) The doubly-recurrent tree decoder, which follows a different signal propagation strategy from most other approaches.\n(3) An ""attention"" mechanism over the point in latent space (that essentially rescales parts of the decoder input)\n\nHowever, the experiments do not evaluate these contributions separately; and so their relative merits remain unclear. Primarily, I have the following questions (for the rebuttal, and to improve the paper):\n\nRe (1):\n (a) Does the pre-training procedure help? Did you evaluate joint end-to-end training of the NL spec encoder and the tree decoder? \n (b) The auto-encoder objective would allow you to train on a larger corpus of programs without natural language specifications. Arguably, the size of the dataset is insufficient for most high-capacity deep learning models, and as you use word embeddings trained on a much larger corpus...), you could imagine training the autoencoder on an additional corpus of programs without NL specs. Did you attempt this?\n\nRe (2): \n (a) The tree decoder is unusual in that (one) part of the recurrence essentially enforces a breadth-first expansion order, whereas almost all other approaches use a depth-first technique (with the only exception of R3NN, as far as I remember). You cite the works of Yin & Neubig and Rabinovich et al.; did you evaluate how your decoder compares to their techniques? (or alternatively, you could compare to the absurdly complex graph approach of Brockschmidt et al. (arxiv 1805.08490)))\n (b) Ablations on this model would be nice: How does the model perform if you set the horizontal (resp. the vertical) input to 0 at each step? (i.e., ablations to standard tree decoder / to pure BFS)\n\nRe (3): This is an unusual interpretation of the attention mechanism, and somewhat enforced by your choice (1). If you run an experiment on end-to-training (without the autoencoder objective), you could use a standard attention mechanism that attends over the memories of the NL encoder. I would be interested to see how this would change performance.\n\nAs the experimental evaluation seems to be insufficient for other researchers to judge the individual value of the paper\'s contribution, I feel that the paper is currently not in a state that should be accepted for publication at ICLR. However, I would be happy to raise my score if (some) of the questions above are answered; primarily, I just want to know if all of the contributions are equally important, or if some boost results more than others.\n\n\nMinor notes:\n- There are many spelling mistakes (""snipped"" for ""snippet"", ""isomorhpic"", ...) -- running a spell checker and doing a calm read-through would help with these details.\n- page1par2: Writing specifications for programs is never harder than writing the program -- a program is a specification, after all. What you mean is the hardness of writing a /correct/ and exact spec, which can be substantially harder. However, it remains unclear how natural language would improve things here. Verification engineers will laugh at you if you propose to ""ease"" their life by using of non-formal language...\n- page1par3: This (and the rest of the paper) is completely ignoring the old and active field of semantic parsing. Extending the related work section to compare to some of these works, and maybe even the experiments, would be very helpful.\n- page2par3 / page6par4 contradict each other. First, you claim that mostly normal english vocabulary is used, with only occasional programming-specific terms; later you state that ""NL vocabulary used in specifications is strongly related to programming"". The fact that there are only 281 (!!!) unique tokens makes it very doubtful that you gain anything from using the 1.9million element vocab of GLoVe instead of direct end-to-end training...\n- page4par3: You state ""a reference to a previously used variable may require \'climbing up\' the tree and then descending"" - something that your model, unlike e.g. the work of Yin & Neubig, does not support. How important is this really? Can you support your statement by data?\n- page5, (14) (and (13), probably): To avoid infinite recursion, the $h_i^{(pred)}$ on the right-hand-side should probably be $h_{i-1}^{(pred)}$\n\n', '# Summary\n\nThis paper introduces a model called SAPS for the task of mapping natural language descriptions of programs to the AST tree of the corresponding program. The model consists of a variation of a double recurrent neural network (DRNN) which is pre-trained using an autoencoder. The natural language description is turned into a latent vector using pretrained word embeddings and a bidirectional stacked LSTM. The final model consists of training this sentence embedding model jointly with the decoder of the autoencoder.\n\n# Quality\n\nThe authors introduce a reasonable model which achieves good performance on a relevant task. The results section contains a fair amount of numbers which give some insight into the performance of the model. However, the results make it hard to compare the proposed model with other models, or with other training procedures.\n\nFor example, the Seq2Tree model that is shown in table 2 was not necessarily intended to be used without a search algorithm. It is also not mentioned how many parameters both models have which makes it hard to judge how fair of a comparison it is. (I couldn\'t find the dimensionality of the encoder in the text, and the decoder dimensionality is only shown in figure 2.)\n\nThe model proposed in this work uses decoder pretrained in an autoencoder setting. No results are shown for how the model performs without pretraining. Pretraining using autoencoders is a technique that fell out of favor years ago, so it seems worthwhile to investigate whether or not this pretraining is necessary, and if so, why and how it aids the final performance.\n\nIt is unclear to me what type of robustness the authors are trying to show in table 5. The use of robustness here is not clear (robustness is often used to refer to a network\'s susceptability to adversarial attacks or perturbations of the weights). It also seems that the type of ""simple replacements"" mentioned are very similar to the way the examples were generated in the first place (section 4 of Polosukhin). If the goal is to measure generalization, why do the authors believe that performance on the test set alone is not a sufficient measure of generalization?\n\nSome smaller comments and questions:\n\n* In section 4 you mention training the sentence-to-tree and the sentence-to-vector mappings. Isn\'t the sentence-to-vector model a subset of the sentence-to-tree model? Should I interpret this as saying that, given the pretrained decoder and the glove embeddings, you now train the entire model jointly? Or do you first learn the mapping from sentences to the latent space, and only then finetune the entire model?\n* The attention mechanism is not actually an attention mechanism: Attention mechanisms are used to reduce a variable number of elements to a single element by learning a weighting function and taking a weighted sum. My understanding is that in this case, the input (the latent representation) is of fixed size. The term ""gating function"" would be more appropriate.\n* You specify that the hidden states of the decoder are initialized to zero, but don\'t specify what the cell states are initialized to.\n\n# Clarity\n\nThe writing in the paper is passable. It lacks a bit in structure (e.g., I would introduce the problem and dataset before introducing the model) and sometimes fails to explain what insights the authors draw from certain results, or why certain results are reported. Take table 3 as an example: As a reader, I was confused at first why I should care about the reconstruction performance of the autoencoder alone, considering its only purpose is pretraining. Then, when looking at the numbers, I am even more confused since it is counterintuitive that it is harder to copy a program than it is to infer it. At the end of the paragraph the authors propose an explanation (the encoder isn\'t as powerful as the decoder) but leave it unclear as to why these numbers were being reported in the first place.\n\nIn general, the paper would do well to restructure the text so that the reader is explained what the goal of the different experiments is, and what insights should be drawn from them.\n\nA variety of smaller concerns and comments:\n\n* Please reduce and harmonize the terminology in the paper: the terms latent-to-AST, NLP2Tree, NLP2Vec, tree2tree/tree-to-tree, sentence-to-tree, sentence-to-vector, NL-to-latent, and spec-to-latent all appear in the paper and several of them are redundant, making it significantly harder to follow along with the text.\n* Avoid citing the same work multiple times within a paragraph; cite only the first use and use prose to make clear that future references are to the same work.\n* Formula 14 has h_i^{(pred)} on both sides of the quation, and is used in the definition of A as well. I am assuming these two terms are actually the h_i^{(pred)} from equation 8, but this should be made clear in the notation.\n* Why does figure 1 have boxes for ""NL specification"", ""NL spec."", and ""NL query""? In general, the boxes inconsistently seem to represent both values and operations.\n* It is never explicitly stated that Seq2Tree is the model from the Polosukhin et al. paper, which is a bit confusing.\n* Parameters is missing an -s in the first paragraph of section 4.\n* It is said that regularization is applied to layer normalization, which I assume means that the regularization is applied to the gain parameters of the layer normalization.\n* It says ""like a in the above example"" when table 1 is rendered at the bottom of the page by Latex.\n\n# Originality and significance\n\nThe paper introduces model variations that the authors claim improve performance on this particular program synthesis problem. In particular, in the DRNN decoder the hidden state is never reset for the ""horizontal"" (breadth-first order) decoder, and each node is only allowed to attend over the latent representation of the program. The authors claim this means their model ""significantly diverges from [other] works"", which seems hyperbolical.\n\nThe main contribution of this work is then the performance on the program synthesis task of Polosukhin and Skidanov. However, the model fails to improve on the Seq2Tree-guided search approach, so its main claimed benefit is that it is trained end-to-end. Although there is a strong trend in ML research to prefer end-to-end systems, it is worthwhile to ask when and why end-to-end systems are preferred. It is often clear that they are better than having separately learned components that are combined later. However, this does not apply to the model from Polosukhin et al., which consists of a single learned model being used in a search, which is a perfectly acceptable technique. In comparison, translations in neural machine translation are also produced by performing a beam search, guided by the probabilities under the model.\n\nThe paper would be significantly stronger if it could show that some alternative/existing method (e.g., a standard DRNN, or a Seq2Tree model with the same number of parameters, or a non-pretrained network) would fail to solve the problem where the authors\' proposed method does not. However, the single comparison with the Seq2Tree model does not show this.\n\n# Summary\n\nPros:\n\n* Reasonable model, extensive results reported\n* Decently written\n\nCons:\n\n* Unclear how the performance compares to other models\n* Not well justified why end-to-end methods would be better than guided-search based methods\n* Model architectural differences seem relatively minor compared to original DRNN\n* The pretraining using an autoencoder and the use of pretrained word embeddings seems arbitrary and is not critically evaluated\n* Lack of coherent story to several results (the autoencoder performance, robustness analysis)', 'This paper proposes the Structure-Aware Program Synthesis (SAPS) system, which is an end-to-end neural approach to generate snippets of executable code from the corresponding natural language descriptions. Compared to a previous approach that used search in combination of a neural encoder-decoder architecture, SAPS relies exclusively on neural components. The architecture uses a pretrained GloVe embedding to embed tokens in the natural language description, which are then embedded into a vector representation using a bidirectional-LSTM. The decoder uses a doubly-recurrent neural network for generating tree structured output. One of the key ideas of the approach is to use a single vector point in the latent space to represent the program tree, where it uses a tree2tree autoencoder to pre-train the tree decoder. The results on the NAPS dataset show an impressive increase in accuracy of about 20% compared to neural-only baselines of the previous approach.\n\nWhile overall the SAPS architecture achieves impressive practical results, some of the key contributions to the design of the architecture are not evaluated and therefore it makes it difficult to attribute the usefulness and impact of the key contributions. For example, what happens if one were to use pre-trained GloVe embeddings for embedding NL specifications in Polosukhin & Skidanov (2018). Such and experiment would lead to a better understanding of how much gain in accuracy one can obtain just by using pre-trained embeddings.\n\nOne of the key ideas of the approach is to use a tree2tree autoencoder to train the latent space of program trees. The decoder weights are then initialized with the learnt weights and fine-tuned during the end-to-end training. What happens if one keeps the decoder weights fixed while training the architecture from NL descriptions to target ASTs? Alternatively, if one were to not perform auto-encoding based decoder pre-training and learn the decoder weights from scratch, how would the results look?\n\nAnother key point of the paper is to use a soft attention mechanism based on only the h^latent. What happens if the attention is also perform on the NL description embeddings? Presumably, it might be difficult to encode all of the information in a single h^latent vector and the decoder might benefit from attending over the NL tokens.\n\nIt was also not clear if it might be possible to perform some form of a beam search over the decoded trees to possibly improve the results even more? \n\nThere are also other datasets such as WikiSQL and Spider for learning programs from natural language descriptions. It might be interesting to evaluate the SAPS architecture on those datasets as well to showcase the generality of the architecture.\n']","[-20, -30, 50]","[60, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges 'there's much to like about this paper', they also express significant concerns and state that the paper is 'currently not in a state that should be accepted for publication'. The reviewer provides extensive feedback and questions, indicating a willingness to potentially raise their score if these are addressed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I would be happy to raise my score' and 'I'm trying to reflect my understanding here', which maintain a collegial tone. The reviewer also offers specific suggestions for improvement, which is helpful and considerate."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('reasonable model', 'good performance', 'decently written'), there are numerous criticisms and concerns raised about the paper's methodology, comparisons, justifications, and overall contribution. The cons outweigh the pros in the summary. The politeness score is mildly positive (20) as the reviewer maintains a professional and constructive tone throughout, using phrases like 'The paper would be significantly stronger if...' and 'Please reduce and harmonize...' rather than harsh criticism. They also acknowledge positive aspects alongside critiques. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a fairly neutral academic tone overall."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the 'impressive practical results' and 'impressive increase in accuracy' of the SAPS system. However, they also raise several questions and suggestions for improvement, indicating a balanced view. The politeness score is 80 (quite polite) due to the constructive nature of the feedback. The reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'What happens if...', 'It might be interesting to...'), and acknowledges the strengths of the paper before offering areas for improvement. The tone is professional and collaborative rather than dismissive or harsh.""]"
"['Summary:\n--------------\nThe paper considers the problem of constructing compositional robotic morphologies that can solve different continuous control tasks in a (multi-agent) reinforcement learning setting. The authors created an environment where the actor consists of a number of primitive components which interface with each other via ""linking"" and construct a morphology of a robot. To learn in such an environment, the authors proposed a graph neural network policy architecture and showed that it is better than the baselines on the proposed tasks.\n\nI find the idea of learning in environments with modular morphologies as well as the proposed tasks interesting. However, the major drawback of the paper is the lack of any reasonable details on the methods and experiments. It\'s hard to comment on the novelty of the architecture or the soundness of the method when such details are simply unavailable.\n\nMore comments and questions are below. I would not recommend publishing the paper in the current form.\n\n\nComments:\n----------------\n- If I understand it correctly, each component (""limb"") represents an agent. Can you define precisely (ie mathematically) what the observations and actions of each agent are?\n\n- Page 4, paragraph 2: in the inline equation, you write that a sum over actions equals policy applied to a sum over states. What does it mean? My understanding of monolithic agents is that observations and actions must be stacked together. Otherwise, the information would be lost.\n\n- Page 4, paragraphs 3-(end of section): if I understand it correctly, the proposed method looks similar to the problem of ""learning to communicate"" in a cooperative multi-agent setting. This raises the question, how exactly the proposed architecture is trained? Is it joint learning and joint execution (ie there\'s a shared policy network, observation and action spaces are shared, etc), or not? All the details on how to apply RL to the proposed setup are completely omitted.\n\n- Is the topology of the sub-agents restricted to a tree? Why so? How is it selected (in cases when it is not hand-specified)?\n\n- From the videos, it looks like certain behaviors are very unphysical or unrealistic (eg parts jumping around and linking to each other). I\'m wondering which kind of simulator was used? How was linking defined (on the simulator level)? It would be nice if such environments with modular morphologies were built using the standard simulators, such as MuJoCo, Bullet, etc.\n\n\nAll in all, despite potentially interesting ideas and setup, the paper is sloppily written, has mistakes, and lacks crucial details.', 'The paper describes training a collection of independent agents enabled with message passing to dynamically form tree-morphologies.  The results are interesting and as proof of concept this is quite an encouraging demonstration.\n\nMain issue is the value of message passing\n- Although the standing task does demonstrate that message passing may be of benefit. It is unclear in the other two tasks if it even makes a difference. Is grouping behavior typical in the locomotion task or it is an infrequent event?\n  - Would it be correct to assume that even without message passing and given enough training time the ""assemblies"" will learn to perform as well as with message passing? The graphs in the standing task seem to indicate this. Would you be able to explain and perform experiments that prove or disprove that?\n  - The videos demonstrate balancing in the standing task and it is unclear why the bottom-up and bidirectional messages perform equally well. I would disagree with your comment about lack of information for balancing in the top-down messages. The result is not intuitive.\n  - Given the above, does message passing lead to a faster training?  Would you be able to add an experimental evidence of this statement?', 'This paper investigates a collection of primitive agents that learns to self-assemble into complex collectives to solve control tasks.\nThe motivation of the paper is interesting. The project videos are attractive. However there are some issues:\n1. The proposed model is specific to the ""multi-limb"" setting. I don\'t understand the applicability to other setting. How much generality does the method (or the experiment) have?\n\n2. Comparison to other existing methods is not enough. There are many state-of-the-art RL algorithms, and there should be natural extension to this problem setting. I can not judge whether the proposed methods work better or not.\n\n3. The algorithm is not described in detail. For example, detail of the sensor inputs, action spaces, and the whole algorithm including hyper-parameters are not explained well.']","[-60, 50, -30]","[20, 70, 50]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, stating they 'would not recommend publishing the paper in the current form' and describing it as 'sloppily written' with 'mistakes' and lacking 'crucial details'. However, they do acknowledge some positive aspects, finding 'the idea of learning in environments with modular morphologies as well as the proposed tasks interesting', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I find the idea... interesting' and ask questions for clarification rather than making accusatory statements. However, the use of terms like 'sloppily written' in the conclusion slightly reduces the overall politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the paper's interesting results and encouraging demonstration, which is positive. However, they then raise several questions and concerns, balancing out the initial positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their concerns as questions rather than direct criticisms. They use phrases like 'Would you be able to explain' and 'Would it be correct to assume', which are polite ways of requesting clarification or suggesting improvements. The reviewer also acknowledges the paper's strengths before diving into their concerns, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the interesting motivation and attractive project videos, they raise several significant issues with the paper. The reviewer uses phrases like 'However there are some issues' and lists three major concerns, which outweigh the initial positive comments. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They begin with positive observations and use neutral language to express their concerns, such as 'I don't understand' and 'I can not judge' rather than using harsh or accusatory language. The reviewer also frames their points as areas for improvement rather than outright criticisms, which contributes to the polite tone.""]"
"['The paper proposes to use a reward function to guide the learning of energy-based models for structured prediction. The idea is to update the energy function based on a random search algorithm guided by a reward function. At each iteration, the SPEN proposes a solution, then a better one is found by the search algorithm, and the energy function is updated accordingly.  Experiments are made on three use-cases and show that this method is able to outperform other training algorithms for SPENs. \n\nIn term of model, the proposed algorithm is interesting since it can allow us to learn from weakly supervised datasets (i.e a reward function is enough). Note that in Section 3, the reward function R is never properly defined which would be nice. The algorithm is quite simple and well presented in the paper. The fact that it is based on a margin could be discussed a little bit more since the effect of the margin is not clear in the paper (the value of alpha). Moreover, the structured prediction problem has already been handled as the maximization of a reward function using RL techniques (see works by H. Daume, and works by F. Maes) and the interest of this approach w.r.t these papers is not clear to me. A clear discussion on that point (and experimental comparison) would be nice. \n\nThe experimental section could be improved. First, the experiments on multi-label classification do not provide any comparison with SoTA methods while the two other use-cases provide some comparisons. Moreover, as far as I understand, the different use-cases could be fully supervised, and different reward functions could be defined. So investigating more deeply the consequences of the nature of the supervision/reward on these use-cases could be interesting and strengthen the paper.  Moreover, training sets are very small and it is difficult to know if this method can work on large-scale problems. \n\nPro:\n* interesting algorithm for structured prediction (base on reward)\n* interesting results on some (toy) use-cases\n\nCons:\n* Lack of discussion on the positive/negative point of the approach w.r.t SoTA, and on the influence of the reward function\n* Lack of experimental comparisons \n* Only toy (but complicated) problems with limited training sets\n', 'Summary:\nThis paper discusses a method to train SPENs when strong supervision is not provided. Instead, training feedback comes in the form of a scalar-valued scoring function for a provided input as well as a prediction. The approach taken here is similar to that described in [1] in that score-violating pairs are found using some procedure, which are then used to update the parameters of the model. The primary difference here is that a random search procedure is used to find score violations rather than the test-time inference procedure; this is justified by noting that the gradient descent procedure may become stuck in flat areas of the optimization surface and thus not encounter high-reward areas. Experiments are run on multilabel classification, citation field extraction, and shape parsing tasks to demonstrate the validity of this approach.\n\nComments:\nOverall, this paper is very nicely written and presents its ideas very clearly. The base approach is the same as presented in [1], but the changes to the learning procedure are adequately justified (and the experiments corroborate this). Furthermore, everything is explained in sufficient detail to be easy to follow. The main detail that I didn’t notice anywhere was a sentence or two describing the random search procedure used - adding this would further clarify your approach.\n\nThe tasks chosen to evaluate these methods are diverse and indicate that this approach is broadly useful in situations where strong supervision may be hard to come by. I think it would have been interesting to see how the model performs in a semi-supervised task (i.e. where some small fraction of the data has labels), but perhaps this is better suited for future work. The one question I have regarding your results is the following: you include the average reward for the citation-field extraction task in your results table, but don’t seem to comment on this anywhere. Are there any conclusions that you think these results imply?\n\nThis paper is an excellent addition to the field of structured prediction, and thus I think it should be accepted.\n\n[1] Rooshenas, A., Kamath, A., & McCallum, A. (2018). Training Structured Prediction Energy Networks with Indirect Supervision. NAACL HLT 2018\n', '# Summary\n\nThis paper proposes search-guided training for structured prediction energy networks (SPENs). SPENs are structured predictors that learn an input-dependent, non-linear energy function that scores candidate output structures. Many methods have recently been proposed for training SPENs. One in particular, rank-based training, has the advantage of supporting training from weak supervision in the form of a reward function. By performing gradient descent on this reward function, rank-based training generates output, improved output pairs that become margin-based constraints on the learning objective. Each constraint specifies a pair of outputs for a given input, and penalizes the current weights if the improved output is not scored higher than the other output by a certain margin.\n\nThis paper addresses a limitation of rank-based training, that this gradient descent procedure for finding output pairs may get stuck in plateaus. In search-guided training,\xa0truncated randomized searches are performed starting at an initial output to find an improved output. The paper says that the random search procedure is informed by the reward function, but it is not specific. Are steps in the search space performed uniformly at random? The paper only says that the returned improved example must score higher in the reward function by some margin \\delta that is ""based on the features of the reward function (range, plateaus, jumps)"" but it is not discussed how to identify these features of the reward function or how to set \\delta accordingly.\n\nExperiments are conducted multi-label classification, citation field extraction, and shape parsing. On multi-label classification search-guided SPENs (SG-SPENs) outperform structural SVM training of SPENs. Why is it not compared with rank-based training (R-SPENs)? On citation field extraction, SG-SPENs improves accuracy by two percentage points over R-SPENs. On shape parsing, R-SPENs fail because it cannot produce valid parsing programs as improved outputs. SG-SPENs perform well relative to other methods like iterative beam search and neural shape parsing.\n\n# Strengths\n\nSG-SPENs are better across the experiments than other SPEN training methods, though I do not know why they are not compared against R-SPENs on multi-label classification.\n\n# Weaknesses\n\nThe work seems incremental without any major new insights beyond the work on R-SPENs. The idea seems to reduce to doing random search instead of gradient descent on a reward function in order to produce output pairs.\n\nAs mentioned above, the paper is also light on details about how the experiments were conducted, such as setting \\delta and creating the space of operators to use when searching for improved outputs.']","[-20, 90, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting algorithm', 'interesting results'), they also point out several significant limitations and areas for improvement. The cons outweigh the pros, and phrases like 'could be improved', 'lack of', and 'difficult to know' indicate a generally critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, employing phrases like 'would be nice' and 'could be interesting' to suggest improvements rather than making demands. They also acknowledge the positive aspects of the work before diving into criticisms, which is a polite approach to reviewing."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer states that the paper is 'very nicely written', 'presents its ideas very clearly', and is 'an excellent addition to the field'. They recommend acceptance, which is a strong positive indicator. The only minor criticisms are suggestions for additional information, not fundamental flaws. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout. They offer constructive feedback and pose questions in a polite manner, such as 'I think it would have been interesting...' and 'Are there any conclusions...?'. The tone is professional and supportive, without any harsh or rude comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and describe the work as 'incremental without any major new insights'. The overall tone suggests the reviewer is not fully convinced by the paper's contributions. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout, providing constructive feedback without using harsh language. They acknowledge the paper's strengths and frame criticisms as areas for improvement rather than outright flaws. The reviewer also uses phrases like 'I do not know why' instead of making accusatory statements, which contributes to the polite tone.""]"
"['In this paper the authors introduce a new technique for softmax inference. In a multiclass setting, the idea is to take the output of a NN and turn it into a gating function to choose one expert. Then, given the expert, output a particular category. The first level of sparsity comes from the first expert. The second level of sparsity comes from every expert only outputting a limited set of output categories.\n\nThe paper is easy to understand but several sections (starting from section 2) could use an english language review (e.g. ""search right"" -> ""search for the right"", ""predict next word"" -> ""predict the next word"", ...) In section 3, can you be more specific about the gains in training versus inference time? I believe the results all relate to inference but it would be good to get an overview of the impact of training time as well. You motivate some of the work by the fact that the experts have overlapping outputs. Maybe in section 3.7 you can address how often that occurs as well?\n\nNits:\n- it wasn\'t clear how the sparsity percentage on page 3 was defined?\n- can you motivate why you are not using perplexity in section 3.2?\n', 'The paper proposes doubly sparse, which is a sparse mixture of sparse experts and learns a two-level class hierarchy, for efficient softmax inference.\n\n[+] It reduces computational cost compared to full softmax.\n[+] Ablation study is done for group lasso, expert lasso and load balancing, which help understand the effect of different components of the proposed\n[-] It seems to me the motivation is similar to that of Sparsely-Gated MoE (Shazeer et al. 2017), but it is not clear how the proposed two-hierarchy method is superior to the Sparsely-Gated MoE. It would be helpful the paper discuss more about this. Besides, in evaluation, the paper only compares Doubly Sparse with full softmax. Why not compare with Sparsely-Gated MoE?\n\nOverall, I think this paper is below the borderline of acceptance due to insufficient comparison with Sparsely-Gated MoE.\n', 'The present paper proposes a fast approximation to the softmax computation when the number of classes is very large. This is typically a bottleneck in deep learning architectures. The approximation is a sparse two-layer mixture of experts.\n\nThe paper lacks rigor and the writing is of low quality, both in its clarity and its grammar. See a list of typos below.\n\nAn example of lack of mathematical rigor is equation 4 in which the same variable name is used to describe the weights before and after pruning, as if it was computer code instead of an equation. Also pervasive is the use of the asterisk to denote multiplication, again as if it was code and not math.\n\nAlgorithm 1 does not include mitosis, which may have an effect on the resulting approximation.\n\nHow are the lambda and threshold parameters tuned? The authors mention a validation set, are they just exhaustively explored on a 3D grid on the validation set?\n\nThe results only compare with Shim et al. Why only this method? Why would it be expected to be faster than all the other alternatives? Wouldn\'t similar alternatives like the sparsely gated MoE, D-softmax and adaptive-softmax have chances of being faster?\n\nThe column ""FLOPS"" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases. Also, a ""1x"" label seems to be missing in for the full softmax, so that the reference is clearly specified.\n\nAll in all, the results show that the proposed method provides a significant speedup with respect to Shim et al., but it lacks comparison with other methods in the literature.\n\nA brief list of typos:\n\n""Sparse Mixture of Sparse of Sparse Experts""\n""if we only search right answer""\n""it might also like appear""\n""which is to design to choose the right""\nsparsly\n""will only consists partial""\n""with γ is a lasso threshold""\n""an arbitrarily distance function""\n""each 10 sub classes are belonged to one""\n""is also needed to tune to achieve""']","[20, -30, -70]","[60, 50, -20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is easy to understand and provides constructive feedback for improvement. However, they also point out several areas that need revision, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases suggestions as questions or polite requests (e.g., 'can you be more specific', 'Maybe in section 3.7 you can address'), and balances critique with positive comments. The reviewer also uses 'nits' to introduce minor points, which is a gentle way to address small issues. The overall tone is professional and constructive, without being overly formal or excessively complimentary."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (reduced computational cost, helpful ablation study), they ultimately conclude that the paper is 'below the borderline of acceptance' due to insufficient comparison with a similar method. This indicates a slightly negative overall sentiment. The politeness score is 50 because the reviewer uses neutral, professional language throughout and frames criticisms constructively (e.g., 'It would be helpful if...'). They also balance positive and negative points before giving their overall assessment, which is a polite approach to reviewing."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's lack of rigor, low writing quality, and insufficient comparisons with other methods. They do acknowledge a 'significant speedup' but this is overshadowed by the criticisms. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. Phrases like 'lacks rigor' and 'writing is of low quality' are quite blunt. The reviewer does provide specific examples and suggestions for improvement, which prevents the score from being lower, but the overall tone is more critical than constructive.""]"
"['This paper introduces deficiency bottleneck for learning a data representation and represent  complicated channels using simpler ones. This problem has a natural variational form that can be easily implemented from VIB. Experiments show good performance comparing to VIB. \n\nThis paper is well-written and easy to read. The idea using KL divergence creating a deficiency channel to learn data representation is very natural. It is interesting that this formulation could be understood as minimizing a regularized risk gap of statistical decision problems, which justifies the usage of deficiency bottleneck (eq.9). \n\nMy biggest concern is the lack of comparison with other representation learning methods, which is a very well studied problem. However, it looks like authors only compared with VIB which is similar to the proposed method in terms of the objective function. For example, how does the method compare with (variants of) Variational Autoencoder? A discussion on this or some empirical evaluations would be nice. ', 'The paper presents a method of learning representations that is based on minimizing ""deficiency"" rather than optimizing for information sufficiency. While perfect optimization of the sufficiency term in IB is equivalent to minimizing deficiency, the thesis of the paper is that the variational upper bound on deficiency is easier to optimize, and when optimized produces\nbetter (more compressed representations), while performing equally on test accuracy.\n\n\n\nThe paper is well written and easy to read. The idea behind the paper (optimizing for minimizing deficiency instead of sufficiency in IB) is interesting, especially because the variational formulation of DB is a generalization of VIB (in that VIB reduces to VDB for M=1). What takes away from the paper is that while perfect optimization of IB/sufficiency is equivalent to perfect optimization of DB, it is not clear what happens when perfection is not achieved. Further, the authors claim that DB is able to obtain more compressed representations (But is the goal a compressed representation, or an informative one?). The paper would also benefit from evaluation of the representation itself, and comparison to other non-information bottleneck based algorithms.\n', ""This paper used the concept based on channel deficiency to derive a variational bound similar to variational information bottleneck. Theoretical analysis shows that this bound is an lower bound on the VIB objective. The empirical analysis shows it outperforms VIB in some sense. \n\nI think this paper's contribution is rather theoretical than practical. The experiments section can be improved in the following aspect:\n-  Figure 2 are hard to read for different M's. It would be better if the authors can show the exact accuracy numbers rather than the overlapped lines\n- I(Z;Y) vs I(Z;X) graph is typically used in a VIB setting. In the paper's variational deficiency setting, although plotting I(Z;Y) vs I(Z;X) is necessary, it would be also helpful for the authors' to plot Deficiency vs I(Z;X), because this is what new objective is trading-off. \n- Again, Figure 3, it is hard to see the benefits for increasing M from the visualizations for different clusterings. \n- How do the paper estimate I(Z;Y) and I(Z;X) for plotting these figures? Does the paper use lower bound or some estimators? It should be made clear in the paper since these are non-trivial estimations.\n\nLast comment is that, although the concept of `deficiency` in a bottleneck setting is novel, the similar idea for tighter bound of log likelihood has already been pursed in the following paper:\n\n- Yuri Burda, Roger Grosse, Ruslan Salakhutdinov. Importance Weighted Autoencoders. ICLR 2016\n\nIt was kind of surprising that the authors did not cite this paper given the results are pretty much the same. It would also be helpful for the authors to do a comparison or connection section with this paper. \n\nI like the paper in general, but given it still has some space for improvement, I would keep my decision as boarder line for now.""]","[70, 50, -20]","[80, 75, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well-written and easy to read' and the idea as 'very natural' and 'interesting'. The reviewer also mentions 'good performance' in experiments. However, it's not a perfect score due to the 'biggest concern' about lack of comparisons with other methods. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing the criticism constructively as a suggestion for improvement ('A discussion on this or some empirical evaluations would be nice') rather than a harsh critique."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written and presents an interesting idea, but also points out some limitations and areas for improvement. The positive aspects (well-written, interesting concept) are balanced by the criticisms (unclear implications of imperfect optimization, need for additional evaluations). The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional and courteous tone while providing both positive feedback and areas for enhancement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I like the paper in general'), they also point out several areas for improvement and keep their decision as 'borderline'. This indicates a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It would be better if...' and 'It would be also helpful...' which are polite ways of suggesting improvements. The reviewer also acknowledges the paper's contributions and novel aspects, which adds to the politeness of the tone.""]"
"['This paper presents a network compression method based on block-diagonal sparse structure for RNN. Two kinds of group mixing methods are discussed. Experiments on PTB and SQUAD have shown its superiority over ISS.\nThe idea present is interesting, and this paper is easy to follow. However, this paper can be improved from the following perspectives.\n1.\tThe method of balancing the quantity of different parts in knowledge distillation is trivial. It is quite general trick.\n2.\tDetails of experimental setup were unclear. For example, the optimization method used, the block size, and the hyper-parameters were unclear. In addition, it is also unclear how the block diagonal structure was used for the input-to-hidden weight matrix only or all weights. \n3.\tIn addition, the proposed method was compared with ISS only. Since there are many methods of compressing RNNs, comparison with other competitors (e.g., those presented in Related work) are necessary.  Moreover, more experiments with other tasks in addition to NLP will be better.  \n4.\tIn Table 2, the comparison with ISS seems be unfair. The proposed methods, i.e., LGP-shuffle was obtained based on the distillation. However, ISS was trained without distillation. From Table 3, when Cmse and Ckl were set to zero, the result was much worse. The reviewer was wondering that how does ISS with distillation perform. \n', ""This paper proposed to use sparse low-ranking compression modules to reduce both computation and memory complexity of RNN models. And the model is trained using knowledge distillation. \nclarity:\nI think Fig1a can be improved. Initially I don't understand how the shuffle part works. It will be more clear if the mx1 vectors have the same length and the two (m x1) labels are in the same height.\noriginality:\nThe method is quite interesting and should be interesting to many people. \npros:\n1) The method reduces computation and memory complexity at the same time.\n2) The result looks impressive.  \ncons:\n1) Is the training of AntMan models done on GPU or CPU? How is the training time. It seems efficient implementation of the model on GPU can be challenging. \n2) It seems the modules can be used to replace any dense matrix in the neural networks. I'm not sure why it is applied on RNN only.\n3) I think another baseline is needed for comparison, a directly designed small RNN model trained using knowledge distillation. In this way, we can see if the sparse low-rank compression provides new values. "", 'Model Compression is used to reduce the computational and memory complexity of DL models without significantly affecting accuracy. Existing works focused on pruning and regularization based approaches where as this paper explores structured sparsity on RNNs, using predefined compact structures.\n\nThey replace matrix-vector multiplications which is the building computational block part of RNNs, with localized group projections (LGP). where LGP divides the input and output vectors into groups where the elements of the output group is computed as a linear combination of those from the corresponding input group. Moreover, they use a permutation matrix or a dense-square matrix to combine outputs across groups. They also combine LGP with low-rank matrix decomposition in order to further reduce the computations. \n\nStrong points: \n\nPaper shows how combining the SVD and LGP can reduce computation. In particular in matrix-vector multiplications Ax, low rank reduces the computation by factorizing A into smaller matrices P and Q, while LGP reduces computation by sparsifying these matrices without changing their dimensions.\n\nThe paper discussed that their model target labels alone does not generalize well on test data and they showed teacher-student training helps greatly on retaining accuracy. They use the original uncompressed model as the teacher, and train the compressed model(student) to imitate the output distribution of the teacher, in addition to training on the target labels.\n\nPaper is well written and easy to follow. \n\nThis paper would be much stronger if it compared against quantization and latest pruning techniques. \n\nThis paper replace matrix-vector multiplications with the lowRank-LGP, but they only consider RNN networks. I am wondering how it affects other models given the fact that matrix-vector multiplications is the core of many deep learning models. It is not clear why their approach should only work for RNNs.\n\nTable 1 shows the reduction in computation and model size over the original matrix-vector multiplications Ax. I think in this analysis the computation of the those approaches are neglected. For example running the SVD alone on A (n by m matrix) takes O(m^2 n+n^3). That is true that if P and Q are given, then the cost would be n(m+n)/r. However, finding P and Q takes O(m^2 n+n^3) that could be very expensive when matrices are large.\n\nTable 2 only shows the LGB-shuffle resuts. What about the combined SVD and LGP? Similarly in Table 4, what is the performance of the LGB-Dense?\n\n']","[-20, 50, 50]","[50, 70, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is interesting and easy to follow, they provide several critiques and areas for improvement. The initial positive comments are outweighed by the subsequent list of issues and suggestions for enhancement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with positive aspects before moving to constructive criticism. They use phrases like 'can be improved' and 'the reviewer was wondering' which maintain a polite tone while offering feedback. The review avoids harsh or dismissive language, instead providing specific, actionable suggestions for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting and impressive aspects of the paper, while also providing constructive criticism and suggestions for improvement. The review highlights both pros and cons, indicating a balanced perspective. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct attacks. The reviewer also acknowledges the paper's strengths before discussing areas for improvement. The use of phrases like 'I think' and 'It seems' further softens the critique, making it more polite and constructive."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's topic, followed by a balanced mix of strong points and areas for improvement. The reviewer acknowledges the paper's contributions and clarity while also suggesting comparisons with other techniques and raising questions about the approach's applicability. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions or questions rather than direct attacks. Phrases like 'Paper is well written and easy to follow' and 'This paper would be much stronger if' indicate a constructive and courteous tone. The reviewer also uses neutral language when pointing out potential issues, such as 'I am wondering' and 'It is not clear why', which maintains a polite and professional tone.""]"
"['This paper proposes a method for learning sentences encoders using artificially generated (fake) sentences. While the idea is interesting, the paper has the following issues:\n\n- There are other methods that aim at generating artificial training data, e.g.:  Z. Zhao, D. Dua, S. Singh. Generating Natural Adversarial Examples. International Conference on Learning Representations (ICLR). 2018,  but no direct comparison is made. Also InferSent  (which is cited as related work) trains sentence encoders on SNLI: https://arxiv.org/pdf/1705.02364.pdf. Again a comparison is needed as the encoders learned perform very well on a variety of tasks. Finally, the proposed idea is very similar to ULMfit (https://arxiv.org/pdf/1801.06146.pdf) which trains a language model on a lot of unlabeled data and then finetunes it discriminatively. Finally, there should be a comparison against a langauge model without any extra training in order to assess the benefits of the fake sentence classification part of the model.\n\n- It is unclear why the fake sentence construction method proposed by either swapping words or just removing them produces sentences that are fake and/or useful to train on. Sure it is simple, but not necessarily fake. A language model would be able to discriminate between them anyway, by assigning high probability to the original ones, and low probability to the manipulated ones. Not sure we need to train a classifier on top of that.\n\n- I found the notation in section 2 confusing. What kind of distribution is P(enc(x,theta1)|theta2, theta3)? I understand that P(x|theta) is the probability of the sentence given a model, but what is the probability of the encoding? It would also be good to see the full derivation to arrive at the expression in the beginning of page 3. \n\n- An argument in favour of the proposed method is training speed; however, given that less data is used to train it, it should be faster indeed. In fact, if we consider the amount of time per million sentences, the previous method considered in comparison could be faster (20 hours of 1M sentences is 1280 hours for 64M sentences, more than 6 weeks). More importantly, it is unclear from the description if the same data is used in training both systems or not.\n\n- It is unclear how one can estimate the normalization factor in equation 2; it seems that one needs to enumerate over all fake sentences, which is a rather large number due to the number of possible word swaps in the sentence,\n\n- I am not sure the generator proposed generates realistic sentences only, ""Chicago landed in John on Friday"" is rather implausible. Also there is no generation method trained here, it is rule-based as far as I can tell. There is no way to tell the model trained to generate a fake sentence as far as I can tell.\n\n- It is a bit odd to criticise other methods ofr using LSTMs with ""millions of parameters"" while the proposed approach also uses them. A comparison should calculate the number of parameters used in either case.\n\n- what is the motivation for having multiple layers without non-linearity instead of a single layer?', 'Summary:\n=======\nThe paper proposes a discriminative training formulation for learning sentence representations, where a classifier is required to distinguish between real and fake sentences. The sentences are encoded with a Bi-LSTM and the resulting sentence representations are then used in a number of sentence-level tasks (classification, entailment, and retrieval). The experiments show benefits on most tasks compared to Skip-Thought and FastSent baselines, and the information captured by the representations is analyzed with probing tasks, showing that they are better at capturing certain kinds of information like the presence or order of words. \n\nThe paper proposes a simple and fairly effective approach for learning sentence encoders. The basic idea is appealing and the experimental results are fairly good. However, at present it seems like more work is required for delivering a comprehensive evaluation and analysis. My main concerns with the paper are the insufficient comparison with prior work, its lack of clarity and organization in certain places, and the limited amount of work. Please see below detailed comments on these and other points, as well as suggestions for how to improve some of these issues.  \n\n\nMajor comments:\n==============\n1. Better baselines and comparisons: \n- The results are compared only with SKip-Thought and (the weaker) FastSent. However, there are far better models by now. First, already in the Skip-Thought paper there is a version combining Naive Bayes bi-gram features which performs much better on some benchmarks, for example that version would be better than the paper\'s results on MR (80.4). \n- Moreover, there have been many newer papers with better results on many of the tasks [1, 2, 4, and references therein]. At the very least, mention should be made that there are better published results, and ideally there should be some comparison to the more relevant papers [1, and maybe others].  \n\n2. Paper organization and clarity:\n- I found Section 2 to be unnecessarily lengthy and disorganized. It mixes motivation with modeling, introduces excessive notation, sometimes without clearly defining it (what is L_{aux}? Why is U in eq. 2 not defined on first usage?), and digresses to weakly related discussions (the link to GANs seems vague and the relation to Introspective Neural Networks is not made clear). The last paragraph is largely redundant with the introduction. \n- There is also a statement that seems just wrong: ""maximizing the data likelihood P(enc(x,\\theta_1)|\\theta_1,\\thera_3)"" -- the data likelihood is P(X | ...). Maximizing the encoding of x can be trivially achieved by simply having a constant encoding whose probability is 1. \n- The entire Section 2 can be condensed to one or two paragraph, essentially deriving the discriminative training task in equations (1) and (2). \n- On the paper organization level, this lengthy section is followed by the related work and then section 4 on ""training tasks for encoders"". There is again redundancy between section 4 and 2. Consider merging sections 2 and 4 into one Methodology section, where the general task is formulated, the sentence encoding (Bi-LSTM with max-pooling) and binary classifier (the MLP) are defined, and the fake sentence generation is described. This would make a better flow and remove excessive text. \n\n3. Motivation and advantages of the approach:\n- The approach is motivated by shortcomings of sentence encodings based on language modeling, such as Skip-Thought, which are computationally intensive due to the large output space and the complicated decoding process. This is an appealing motivation, although there have also been simpler methods for sentence representations that work as well as or better than Skip-Thought [1, 2]. \n- The second motivation is not clear to me, and the claim that ""the training text collection should include many instances of sentences that have only minor lexical differences but found in completely different contexts"" needs more support, either theoretical or empirical. Why wouldn\'t a language model be able to distinguish such differences?\n- The advantages of the binary classification task make sense. The point about forcing the encoder to track both syntax and semantics is interesting. Have you tried to analyze whether this indeed happens? The probing tasks are a good way to evaluate this, but most of them are syntactic, except SOMO and perhaps CoordInv and BShift. Still, more analysis of this point would be good. \n- One concern with generating fake sentences by swapping words is that it would not apply to languages with free word order. Have you considered how well your approach would work on other languages? \n\n4. Relevant related work: \n- The fake data generation resembles noise used in denoising auto-encoders. A recent application is in unsupervised neural machine translation [3], but there is relevant prior work (see references in [3]). \n- The binary classification task resembles that in [1], where they train a classifier to distinguish between the representation of a correct neighbor sentences and incorrect sentences. \n\n5. Ideas for more experiments and analysis:\n- The results are fairly good by using only 1M sentences. How good would they be with the full corpus? What\'s the effect of training data size on the method? \n- Table 4 is providing nice examples showing how the fake sentence task generates better sentences representations. Can this be measured on a larger set of examples in aggregate? Why is t-SNE needed for calculating the neighbor rank? \n- Proving tasks are very interesting, but the discussion is limited. A more detailed discussion and analysis would be useful. \n- Consider other techniques for generating fake sentences. \n\n\nMinor comments:\n==============\n- Related work: the Skip-Thought decoder is a unidirectional LSTM and not a bidirectional one as mentioned, right? \n- Related work: more details on supervised approaches would be useful. \n- Section 4.1: how many fake exampels are generated from every real example? Have you experimented with this? \n- Section 4.2 mentions 2 hidden layers in the MLP but figure 3 indicates 3 layers. \n- Is there a reason to use multiple layers without a non-linearity in the MLP? This seems unusual. In terms of expressivity, this is equivalent to using one larger linear layer, although there might be some benefit in optimization. \n- Table 1 seems unnecessary as there is no discussion of how dataset statistics refer to the results. It\'s enough to refer to previous work. \n- What are some results missing in table 2, specifically SKipthought (1M) on COCO datasets? \n- The paragraph on sentence encoder implementation mentions a ""validation set accuracy of 89 for word shuffle"". Which validation set is that? How is convergence determined for word drop? \n- In analyzing sentence lengths, figure 2 shows the fake sentence to be similar to SKip-Thought on short sentences in SST. Do you have any idea why? Also, fake sentence is better than Skip-Thought on all lengths in MR, not just longer sentences, so I\'m not sure there\'s any signal there. \n- Figure 3: what is the test set for WordShuffle? \n- The idea to create negative samples focused towards specific phenomena sounds like a good way to go\n\n\nWriting, grammar, etc.:\n======================\n- Introduction, paragraph 3, last sentence: start with ""The"". \n- Introduction, paragraph 4, first sentences: discriminative training task fake sentence detection -> discriminative training task *of* fake sentence detection\n- Motivation: an useful -> a useful; we assumes -> we assume; then number -> the number; this much -> this is much\n- Motivation: do not differ -> do not differ much? \n- Related work: skip-gram -> skip-gram model; Training Skipthought model -> Training a Skipthought model\n- Section 4: Prior work use -> Prior work uses/used \n- Section 4.2: space between ""Multi-layer Perceptron"" and ""(MLP)"". This also happens with other acronyms. \n- Page 6: Our models, however, train -> are trained \n- Table 3 caption: is bigram in -> is bigram; is co-ordination is -> is-coordination \n- Page 7: The analysis ... also indicate*s* ... but do*es* not ... \n- Figure 3 caption: classification/proving task -> tasks \n- References: fix capitalization in paper titles\n\n\nReferences\n==========\n[1] Logeswaran and Lee, An efficient framework for learning sentence representations\n[2] Khodak et al., A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors\n[3] Artetxe et al., Unsupervised Neural Machine Translation\n[4] Arora et al., A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs\n', 'Summary: Derive sentence representations from a bidirectional LSTM encoder trained to distinguish real sentences from fake ones. Fake sentences are derived from real ones by swapping two words or dropping a single word (yielding two different models). The resulting representations are applied to various sentence classification tasks by using them as input to a logistic regression classifier trained for the task. Results are generally better than similar experiments performed with SkipThought vectors trained on the same Toronto BookCorpus.\n\nThis is a reasonable idea, and the win over SkipThought is quite convincing, but the paper is short on substance, and parts are confusing or superfluous. Some problems and questions:\n\n1) Most of section 2 could be omitted, since it doesn’t really add insight to the well-established idea of pre-training parameters on an auxiliary task. \n\n2) Section 3 calls the Conneau et al (2017) transfer approach supervised. It also distinguishes between semi-supervised approaches that “do task-specific adaptation using labeled data” and unsupervised approaches (including the current one) that also must do exactly that.\n\n3) In 4.2, does the 3-layer MLP have non-linearities in its hidden layers? If so, it’s not equivalent to a single linear layer as claimed, regardless of whether a non-linearity is applied to its output. If not, there is no point in using 3 layers.\n\n4) Section 5 gives only minimal descriptions of the tasks - often just acronym and type, presumably because they are borrowed from Conneau et al (2017, 2018). More information needs to be provided.\n\n5) Section 6 should show the best results from the Conneau et al papers for calibration.\n\n6) Were the baseline systems also supplied with Glove word embeddings? Do they have the same number of parameters?\n\n7) Details of the logistic regression classifier?\n\n8) Why train on your method on only 1M sentences, since training is fast? Wouldn’t using more text give better results?\n\n9) Given the recent very strong results from the ELMo paper (which you cite), the current paper doesn’t seem complete without some attempt to replicate this as a baseline - eg, use a deeper encoder, combine state vectors through layers, etc. These features aren’t incompatible with your objective, which might make for an interesting extension.']","[-60, -20, -20]","[20, 60, 50]","[""The sentiment score is -60 because the review is predominantly critical, pointing out several issues with the paper such as lack of comparisons, unclear methodologies, and questionable assumptions. However, it does acknowledge that the idea is 'interesting' at the start, preventing a more extreme negative score. The politeness score is 20 because while the reviewer maintains a professional tone and uses neutral language ('it is unclear', 'I am not sure'), there's little effort to soften criticisms or offer encouragement. The reviewer directly states problems without much hedging, but also doesn't use harsh or impolite language, resulting in a slightly positive politeness score."", ""Sentiment score: The review starts with some positive comments about the paper's 'simple and fairly effective approach' and 'appealing' basic idea. However, it quickly moves to express 'main concerns' and states that 'more work is required'. The majority of the review then focuses on areas for improvement and limitations, indicating a generally negative sentiment, albeit not extremely so. Thus, I've assigned a slightly negative score of -20.\n\nPoliteness score: The reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'Please see below' and 'Consider merging...'. Even when pointing out issues, the language is respectful, using phrases like 'I found Section 2 to be...' rather than making blunt criticisms. The reviewer also offers suggestions for improvement and acknowledges positive aspects. However, it's not overly deferential, maintaining a balance between politeness and directness. Therefore, I've assigned a moderately positive politeness score of 60."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper presents a 'reasonable idea' with 'convincing' results over SkipThought, they also state that the paper is 'short on substance' and 'parts are confusing or superfluous'. The review then lists several problems and questions, indicating more criticism than praise. The politeness score is moderately positive (50) because the reviewer uses neutral language and phrases criticisms as questions or suggestions rather than direct attacks. They use phrases like 'This is a reasonable idea' and frame issues as 'problems and questions' rather than outright flaws. The reviewer also provides specific, constructive feedback for improvement, which is a polite approach to criticism in academic reviews.""]"
"['This submission sets out to taxonomize evasion-time attacks against deep RL and introduce several new attacks, including two heuristics for efficient evasion-time attacks and attacks that target the environment dynamics and RL system’s actions. The main limitation of this paper is probably its broad scope, which unfortunately prevents it in its current form from addressing each of the goals stated in the introduction systematically to draw conclusive takeaways. \n\nTaxonomizing the space of adversaries targeting deep RL at test time is a valuable contribution. While the existing taxonomy is a good start, it would be useful if you can clarify the following points in your rebuttal. Why were the “further categorization” items separated from adversarial capabilities? Being constrained to real-time or physical perturbations appears to be another way to describe the adversary’s capabilities. In addition, is there a finer-grained way to characterize the adversary’s knowledge beyond white-box vs. black-box? This binary perspective is common but not very informative. One way to move forward would be for instance to think about the different components of a RL system, and identify those that are relevant to have knowledge of when adversaries are mounting attacks. It would also be helpful to position prior work in the taxonomy. Finally, the taxonomy currently stated in the submissions is more a taxonomy of attacks (or adversaries) than a taxonomy of vulnerabilities, so the title of Section 3 could perhaps be updated accordingly. \n\nSection 4.1 gives a good overview of different attack strategies against RL based on modifying the observations analyzed by the agent. Many of these attacks are applications of known attack strategies and will be familiar to readers with adversarial ML background (albeit some of these strategies were previously introduced and evaluated against “supervised” classifiers only). One point was unclear however: why is the imitation learning based black-box attack not a transferability-based attack? As far as I could understand, the strategy described corresponds exactly to the commonly adopted strategy of transferring adversarial examples found on a substitute model (see for instance “Intriguing properties of neural networks” by Szegedy et al. and “Practical Black-Box Attacks against Machine Learning” by Papernot et al.). In other words, Section 4.1 could be rescoped to put emphasis on the attack strategies that have not been explored previously in the context of reinforcement learning: e.g., the finite difference approach with adaptive sampling or the universal attack with optimal selection of initial frames. It is unfortunate that the treatment of these two attacks is currently deferred to the appendix as they make the paper more informative. Similarly, Sections 4.2 and 4.3 would benefit from being extended to put forward the new attack threat model considered in these two sections. \n\nWhile the introduction claimed to make a systematic evaluation of attacks against RL, the presentation of the experimental section can be improved to ensure the analysis points out the relevant takeaways. For instance, it is unclear what the differences are between results on TORCS and other tasks included in the Appendix. Specifically, results on Enduro do not seem as conclusive as those presented on TORCS. Do you have some intuition as to why that is the case? In Figure 7, it appears that a large number of frames need to be manipulated before a drop on cumulative reward is noticeable. Previous efforts manipulated single frames only, could you stress why the setting is different here? Throughout the section, many Figures are small and it is difficult to infer whether the difference between the white-box and black-box variants of an attack is significant or not. Could you analyze this in more details in the text? In Table 2, how should the L2 distance be interpreted? In other words, when is the adversary successful? \n\nIf you can clarify any of the points made above in your rebuttal, I am of course open to revise my review. \n\nEditorial details: \nFigures are not readable when printed. \nFigure 5 is improperly referenced in the main body of the paper. \nFigure 7: label is incorrect for Torcs and Hopper (top of figure)\n', ""The authors design a new taxonomy of attacks on deep RL agents - they developed three classes of attacks - attacks the modify the observation given to the agent, attacks that modify the action used by the agent and attacks that change the dynamics of the environment. In settings that have been studied previously, the authors show that they can find attacks more effectively than previous approaches can. They also study learning based and online attack generation approaches, that can be effectively used to quickly find adversarial attacks on the agent. The authors validate their approaches experimentally on Mujoco tasks and the TORCS driving simulator.\n\nQuality: I found the paper's contributions difficult to understand - the significance of the three classes of attacks is not properly explained (in particular, I found the action perturbation to be difficult to justify in a real world setting). Further, the difficulty of generating attacks in each of these classes and the need for new algorithms is not explained properly. The need for effective ways to quickly generate adversarial attacks in RL is clear, but the authors' experiments don't seem to clarify that their proposed aproaches achieve this goal.\n\nClarity: The organization of section 4 makes the paper difficult to read - I would separate the taxonomy from the contribution of novel ways of generating adversarial attacks (the latter, imo, is the more significant contribution). \n\nOriginality: To the best of my knowledge, the authors propose novel kinds of attacks as well as novel attack algorithms on RL agent.\n\nSignificance: The problem considered is certainly significant. Despite the successes achieved by DeepRL, their robustness (in terms of distribution shifts, adversarial noise, model errors etc.) is of great importance when considering deploying these models. However, the presentation and experiments leave me unconvinced that the presented approaches are  a significant step ahead in attack generation (particularly in ways to generate attacks that can efficiently be incorporated into adversarial training of RL agents).\n\nCons\n1. Unclear presentation of technical contributions, experimental results do not support the key contributions of faster attack generation\n2. I am also unconvinced of the relevance of blackbox attack algorithms given the nascent stage of deepRL - since these agents are just being developed and their abilities need to improve significantly before they become deployable (and blackbox adversarial attacks are a real concern), I feel this work is premature and will need to be redone once more capable/robust agents can be trained for practical RL settings\n\n###\nIn light of the revision, I have revised my score given the rewriting of section 3 that addresses the second con I raised above. However, due to the lack of clarity in presentation of the technical results in section 4 and the experiments in section 5, I feel that the paper still require improvement before it can be accepted."", 'The attack methods are clearly and extensively described and the paper is well organized overall. Some of the attacks are a straightforward variation of known attacks.  Strong original contributions are not found in this work while I do not think lack of original contributions is a minus for this type of paper. One concern is that the connections of each attack setting to a specific threat scenario in the real world are not discussed in this paper. The authors display 14 types of attacks under various settings. Which attack is likely to be performed by what kind of adversaries in what situation?  For this type of security research, contribution becomes weak without a connection to a threat in the real world. Suppose attack scenario A destroys a policy network more seriously than attack scenario B. Even in such a situation, a rescue for attack scenario A might not be needed if attack scenario A is not realistic at all. Even if connections to threats in the real world is not clear, it would be important for security analysis to learn about the worst case. Unfortunately, this work simply exhibits a catalogue of attacks against RL and does not give a deep insight into what we should do to make RL secure. \n\nThe summarization of the attack scenarios against RL is high quality and the results shown in this paper would be useful for many researchers. I expect authors to give more discussions on connections to the real world.\n \n\n\n\n']","[-20, -30, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Taxonomizing the space of adversaries targeting deep RL at test time is a valuable contribution'), they also point out several limitations and areas for improvement. The overall tone suggests the paper needs significant revisions before it can be considered acceptable. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses openness to revising their opinion based on the authors' rebuttal. They use phrases like 'it would be useful if you can clarify', 'Could you analyze this in more details', and 'I am of course open to revise my review', which contribute to a polite and professional tone."", 'The sentiment score is -30 because while the reviewer acknowledges some positive aspects (novel attacks and algorithms), they express significant concerns about clarity, presentation, and the convincingness of the experimental results. The overall tone is more negative than positive, but not extremely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without being harsh. They acknowledge positive aspects and frame criticisms as areas for improvement rather than outright flaws. The reviewer also explains their reasoning for scores and recommendations, which is a polite and helpful approach.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clear organization and extensive description of attack methods, they express concerns about the lack of original contributions and connections to real-world threat scenarios. The reviewer states that the paper 'does not give a deep insight into what we should do to make RL secure,' which indicates disappointment with the paper's depth and practical implications. However, they do recognize the high-quality summarization and potential usefulness for researchers, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I expect authors to give more discussions' rather than making demands, and they balance critique with positive observations about the paper's organization and potential usefulness.""]"
"['Paper Summary: \nThe idea of the paper is to improve Hindsight Experience Replay by providing natural language instructions as intermediate goals. \n\nPaper Strengths:\nUnfortunately, there is not many positive points about the paper except that it explores an interesting direction. \n\nPaper Weaknesses: \n\nI vote for rejection of the paper due to the following issues:\n\n- It is not clear how a description for a point along the way is provided (when the agent is not at a target). It is not clear how those feedback sentences are generated. That is the main claim of the paper and it is not clear at all.\n\n- The result of DQN is surprising (it is always zero). DQN is not that bad. Probably, there is a bug in the implementation. There should be comments on this in the rebuttal.\n\n- According to several recent works, algorithms like A3C work much better than DQN. Does the proposed method provide improvements over A3C as well?\n\n- The only measure that is reported is success rate. The episode length should be reported as well. I suggest using the SPL metric proposed by Anderson et al. in ""On Evaluation of Embodied Navigation Agents"".\n\n- Replacing one word with its synonym is considered as zero-shot. That is not really a zero-shot setting. Please refer to the following paper, which is missing in the related work:\nInteractive Grounded Language Acquisition and Generalization in a 2D World, ICLR 2018\n\n- The environments are toy environments. The experiments should be carried out in more complex environments such as THOR or House3D that include more semantics.\n\n- What is the difference between this method and providing a large negative reward at a non-target object?\n\n- The paper discusses the advantages of word embeddings over one-hot vectors. That is obvious and not the goal of this paper. \n\n- It seems the same environment is used for train and test.\n\n------------------------\nPost rebuttal comments:\n\nMost of my concerns have been addressed. My new rating is 5. I like the idea of having a compact representation for the hindsight experience replay, but there are still a few issues:\n\n- I expected more complexity in vision and language. I do not agree with the rebuttal that AI2-THOR or House3D are not suitable. This level of complexity would be ok if this paper was among the first ones to explore this domain, but there are already several works. The zero-shot setting (changing the word with its synonym) is also so simplistic.\n\n- The proposed method uses much more annotations than the baselines so the comparisons are not really fair. This information should have been added to the baseline to see how this additional information changes the performance. Basically, it is not clear if the improvement should be attributed to the extra annotation or the way the advice is given.\n\n- The writing is still confusing. For instance, it is mentioned that ""Concretely, for each state s ∈ S, we define T as a teacher that gives an advice T(s)"", while that is not true since later it is mentioned that ""the teacher give advice based solely on the terminal state"". These statements are contradictory, and it is not trivial at all to provide an advice for each state.\n', ""This submission presents a method to improve the sample-efficiency of instruction-following models by leveraging the Hindsight Experience Replay framework with natural language goals. \n\nHere are  my comments/questions:\n- The paper is well written and easy to follow, it introduces a simple idea which achieves very good results.\n- In addition to improving the performance as compared to the baselines, the authors perform a wide variety of experiments such as analysis of language representations, visualization of embeddings, etc. which lead several insightful results such as ability of sentence embeddings to generalize to unseen lexicon, ability of the model to perform well with just 1% advice.\n- It is important to note that as compared to the baselines, the proposed method requires access to the set of goals and extra information about which goal was reached in each episode.\n- In Table 1, how many frames were DQN and ACTRCE trained for? I am wondering why the MT performance for DQN is so low. Did the DQN have Gated-Attention?\n- The composition task is very interesting, did the agent receive intermediate rewards for completing a part of the instruction in this task?\n- Some implementation details questions:\n\t- In Appendix D Training details, what do you mean by 'chosen from the range {1000, 10000, 10000}'?\n\t- In Appendix D Training details,  it is mentioned that you reproduce training using Asynchronous Advantage Actor Critic (A3C), where is A3C used in the experiments?"", 'This paper considers the assumption implicit in hindsight experience replay (HER), namely that we have access to a mapping from states to goals. Rather than satisfying this requirement by defining goals as states, which involves great redundancy, the paper proposes a natural language goal representation. Concretely, for every state a teacher is used to provide a natural language description of the goal achieved in that state, which can be used to directly relabel the goal so the episode can be used as a positive experience.   \n\nStrengths:\n- the proposed idea is simple and intuitively appealing, and shows much better results than the DQN baseline.\n\nWeaknesses:\n- In the VizDoom task, the goal specification is already in (templated) language. Given that this is the case, and the mapping from states to goals can be extracted from the environment anyway, it seems like the method that is applied really just reduces to a vanilla implementation of HER. There seems to be little novelty in this. From reading the introduction and method, I expected the ACTRCE approach to be applied to a task where the goal was not originally specified in language, perhaps by collecting language from human teachers. This would be a much more interesting experiment, addressing the question of whether human feedback in natural language can help the agent learn more quickly.\n- Even leaving aside the previous concern, it seems very difficult to put this work in the context of previous work on the same tasks. For example, it is not clear why there are no comparisons to the previous work on instruction following in VizDoom, as the setting appears to be exactly like Chaplot et al. 2017. It would seem like a natural comparison would be to take the model from Chaplot (leaving the task and architecture etc unchanged) and train it using ACTRCE. Is there any reason why this can’t be done? There is already so much existing work in this space, it seems quite unusual that the proposed new method is not compared to any existing work on an existing task.\n\n\nSummary:\nThis is a simple and intuitively appealing idea, but I find the evaluation to be quite lacking because the tasks already use a language specification (such that ACTRCE seems to be vanilla HER in application) and there are no comparisons to previous work. These two concerns seem quite substantial to me and make it difficult to recommend acceptance. \n\nSmaller issues:\n- ACTRCE - possibly the most tortured acronym in recent memory! How should it be pronounced?']","[-70, 80, -50]","[-20, 70, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer explicitly states 'I vote for rejection of the paper' and lists numerous weaknesses with very few strengths. Even after the rebuttal, the reviewer maintains several criticisms. The politeness score is -20 because while the reviewer isn't overtly rude, the tone is quite direct and critical without much attempt to soften the feedback. Phrases like 'It is not clear' and 'That is obvious' come across as somewhat dismissive. The reviewer does not use polite language or offer encouragement, focusing almost entirely on criticisms."", ""The sentiment score is 80 (positive) because the reviewer begins by praising the paper as 'well written and easy to follow' and notes that it achieves 'very good results'. They also commend the authors for performing a 'wide variety of experiments' leading to 'insightful results'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, framing critiques as questions or observations rather than direct criticisms. For example, they note an important difference from baselines as an observation, not a flaw. The reviewer also uses phrases like 'I am wondering' when asking for clarification, which maintains a collegial tone. The overall structure of providing positive feedback first, followed by constructive questions and suggestions, contributes to both the positive sentiment and polite tone."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper ('simple and intuitively appealing idea', 'shows much better results than the DQN baseline'), they express significant concerns about the novelty and evaluation of the work. The reviewer states that it's 'difficult to recommend acceptance' due to these issues, indicating an overall negative sentiment. However, it's not extremely negative as they do recognize some positive aspects.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They present their criticisms as 'concerns' rather than outright dismissals, and use phrases like 'it seems' to soften their critiques. The reviewer also acknowledges the strengths of the paper before discussing its weaknesses. However, the score is not higher because the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a fairly neutral, matter-of-fact tone overall.""]"
"['This work shows that adding a simple blurring into max pooling layers can address issues of image classification instability under small image shifts. In general this work presents a simple and easy to implement solution to a common problem of CNNs and even though it lacks more thorough theoretical analysis of this problem from the signal processing perspective (such as minimal size of the blurring kernel for fulfilling the Nyquist-Shannon sampling theorem), it seems to provide ample empirical evidence.\n\nPros:\n+ The introduction and motivation is really well written and Figure 3 provides a clear visualisation main max pooling operator issues.\n+ The proposed method is really simple and shows promising results on the CIFAR dataset. With random shifts, authors had to tackle cropping with circular shifts. As it can cause artifacts in the data, authors also provide baseline performances on the original data (used for both training and testing).\n+ Authors provide a thorough evaluation, ranging from comparing hidden representations to defining consistency metrics of the classified classes.\n\nThis work is lacking in the experimental section due to some missing details and few inconsistencies. I believe the most of my concerns can be relatively easily fixed/clarified in an update of this submission.\n\nMajor issues, which if fixed would improve the rating:\n- It is not correct to average test accuracy and test consistency as both measures are different quantities, especially when using them for ranking. The difference between accuracy of different methods are considerably smaller than differences in the classification consistency. \n- It is not clear how many shifts are used for computing the ""Random Test Accuracy"" and the ""Classification Accuracy"". Also whether the random shifts are kept constant between evaluated networks and evaluation metrics.\n- Authors do not address the question what is the correct order of operations for the blurring. E.g. would the method empirically work if blurring was applied before max pooling? Do the operations commute?\n- The selection of the filters is rather arbitrary, especially regarding the 1D FIR filters. The separability of these filters should be discussed.\n- I believe authors should address how this work differs to [1], as it also tests different windowing functions for pooling operators, even though in different tasks.\n\nMinor issues, which would be nice to fix however which do not influence my rating:\n* Section 3.1 - And L-Layer deep *CNN*, H_l x W x C_l -> H_l x W_l x C_l\n* Section 3.1. Last paragraph - I would not agree with the statement that in CNNs the shift invariance must necessarily emerge upon shift equivariance. If anything, this may hold only for the last layer of a network without fully connected layers and with average pooling of the classifier output (ResNet/GoogleNet like networks).\n* Explicitly provide the network architecture as [Simonyan14] does not test on CIFAR and cannot use Batch normalisation.\n* It would be useful to add citation for the selected FIR filters.\n* The flow of section 4.2. can be improved to help readability. The three metrics should be first motivated before their introduction. Metric 2. paragraph - the metric is defined below, not above. \n* It would be interesting to see what would be the performance if the blurring filters were trained as well (given some sensible initialisation).\n* One future direction would be to verify that this approach generalises to larger networks as well. It might be worth to discuss this in the conclusions.\n\n[1] Scherer, Dominik, Andreas Müller, and Sven Behnke. ""Evaluation of pooling operations in convolutional architectures for object recognition."" Artificial Neural Networks–ICANN 2010. Springer, Berlin, Heidelberg, 2010. 92-101.', 'This paper analyzed on the core factor that make CNNs fail to hold shift-invariance, the naive downsampling in pooling. And based on that the paper proposed the modified pooling operation by introducing a low-pass filter which endows a shift-equivariance in the convolution features and consequently the shift-invariance of CNNs.\n\nPros:\n1.\tThe paper proposed a simple but novel approach to make CNNs shift-invariant following the traditional signal processing principle.\n2.\tThis work gave convincing analysis (from both theoretical illustrations and experimental visualizations) on the problem of original pooling and the effectiveness of the proposed blur kernels.\n3.\tThe experiment gave some promising results. Without augmentation, the proposed method shows higher consistency to the random shifts.\n\nCons:\n1.\tWhen cooperating with augmentation, the test accuracy on random shifted images of proposed method did not exceed the baseline. Although the consistency is higher, it is secondary to the test accuracy of random shifted data. And it is confused to do average on consistency and test accuracy, which are in different scales, and then compare the overall performance on the averages. \n2.\tIt seems to be more convincing if the ‘random’ test accuracy is acquired by averaging several random shifts on a single image and then do average among images, as well as to show how accuracy various on shifting distance.\n3.\tSome other spatial transforming/shifting adaptive approaches should be taken into consideration to compare the performance.\n4.\tThere are some minor typos, such as line 3 in Section 3.1 and line 15 in Section 3.2\n', '\nSummary\n\nFrom a theoretical point of view, one might be tempted to believe that deep CNNs are translation equivariant and their predictions are translation invariant. In practice, this is not necessarily true. The authors propose to augment standard deep CNNs with low-pass filters to reduce this problem. The results seem promising for an older VGG architecture.\n\nQuality\n\nThe paper is very verbose, the figures and captions are tedious to read, the mathematical notation seems strange as well, making the writing more concise is highly encouraged. The main ideas are easy to follow and the choice of experiments seems fine. \n\nSignificance\n\nThis is the first empirical work trying to fix the issue of non-translation equivariance in convolutional neural networks. The conclusions of this work are potentially relevant for a wide audience of CNN practitioners.\n\nMain Concerns\n\nTo show that all claims of the paper do indeed hold, the authors should attack their augmented network with the translation attack of [1]. As robustness to this type of transformations is one of the main goals, it should be tested if it was achieved. The attack can be found in some open source frameworks [2] and should be easy to apply.\n\nWall-clock times need to be reported for the various blurring kernels and compared to the baselines.\n\nExtend results to a cutting-edge architecture, e.g. DenseNets or Wide ResNets. If this result is not provided the significance of the work is not clear.\n\nDespite being more expensive, do dilations fix the issue of missing translation equivariance provably and not just approximately like the low-pass filtering approach proposed here? This should be discussed and a comparison in terms of wall-clock time would be great as well.\n\nMinor\n\n- Strange notation e.g. in equation 1. Why not write: x+\\delta x in the argument of the function instead of ""Shift"". The current notation seems unnecessarily informal.\n- Figure 4: show scale and color bar.\n\n[1] Engstrom et al., ""A rotation and a translation suffice: Fooling cnns with simple transformations.""\n[2] https://foolbox.readthedocs.io/en/latest/modules/attacks/decision.html#foolbox.attacks.SpatialAttack']","[50, 60, 20]","[80, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the work's strengths and potential impact, praising the introduction, motivation, and thorough evaluation. However, they also point out several major issues that need addressing, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the work's merits and framing criticisms constructively. They use phrases like 'I believe' and 'it would be nice to fix' when suggesting improvements, maintaining a professional and courteous tone. The review is structured to clearly separate pros, major issues, and minor issues, which is helpful and considerate to the authors."", ""The sentiment score is 60 (positive) because the review starts with a neutral summary of the paper's content, followed by a list of pros that highlight the paper's strengths. The reviewer acknowledges the novelty, convincing analysis, and promising results of the proposed method. However, the score is not higher due to the presence of several cons that point out limitations and areas for improvement. The politeness score is 50 (slightly polite) because the reviewer maintains a professional and objective tone throughout, presenting both pros and cons without using harsh language. The reviewer uses phrases like 'it seems to be more convincing if...' and 'should be taken into consideration,' which suggest recommendations rather than demands. The mention of minor typos is done matter-of-factly without criticism. Overall, the review is balanced and constructive, showing respect for the authors' work while providing valuable feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the potential significance of the work and its relevance to a wide audience. They mention that the results seem promising and that it's the first empirical work addressing a specific issue. However, they also point out several concerns and areas for improvement, which prevents the score from being higher. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'is highly encouraged' instead of more direct criticism. They provide constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer also balances critique with positive comments about the paper's main ideas and experiment choices. The language is not overly formal or excessively polite, but it maintains a respectful and constructive tone throughout.""]"
"['The paper improves upon the Real NVP/Glow design by proposing better dequantization schemes and more expressive forms of coupling layers. I really like Real NVP models, which I think are a bit underappreciated. Thus, I’m happy that there are papers trying to improve their performance.  However, I wish this was done with more rigour.\n\nThe paper makes 3 claims about the current flow models: (1) it is suboptimal to use additive uniform noise when dequantizing images, (2) affine coupling layers are not expressive enough, and (3) the architectures fail to capture global image context. I’ll comment on these claims and proposed solutions below.\n\n(1) I agree with the reasoning behind the need for a better dequantization distribution. However, I think the authors should provide an evidence that the lower bound is indeed loose when q is uniform. For example, for the CIFAR-10 model, the authors calculated a gap of 0.025 bpd when using variational dequantization. What would this gap be when using uniform q?  Maybe, a clear illustration of the dequantization effect on a simpler dataset or a toy example would be more useful.\n\n(2) My main concern about the mixture CDFs coupling layer is how much bigger the model becomes and how much slower it trains. I find this analysis crucial when deciding whether 0.05 bpd improvement as reported in Table 1 is worth the hassle.\n\n(3) As a person not familiar with the Transformer, I couldn’t understand how exactly self-attention works and how much it helps the model to capture the global image context. Also, I think this problem needs a separate illustration on a dataset of larger images.  \n  \nThe experiments section is very weak in backing up the identified problems and proposed solutions. Firstly, I think it is more clear if the ablation study is done in reverse: instead of making Flow++ and removing components, start with the vanilla model and then add stuff.  Secondly, it’s not clear if these improvements generalize across datasets, e.g. when images are larger than 32x32. Though, larger inputs may lead to huge models which are impossible to train when the resources are quite limited. That’s why I find it important to report how much complexity is added compared to the initial Real NVP. Also, I think it’s a well-known fact that sampling from PixelCNN models is slow unlike for Real NVPs, so I don’t find the results in Table 3 surprising or even useful. \n\nTo conclude, I find this paper unfinished and wouldn’t recommend its acceptance until the analysis of the problems and their solutions becomes better thought out.  ', ""This paper offers architectural improvements for flow-based models that enable them to be very competitive with autoregressive models in terms of bits/dim metrics while still providing efficient sampling scheme. The three main contributions are the use of variational dequantization scheme, more powerful element-wise bijections (mixture of logistic CDF), and multi-head self-attention in the dependency structure. \nThe two first contributions are in my opinion the most interesting as:\n- variational dequantization demonstrates the improvement that one can obtain by redefining part of the image processing that has been overlooked before;\n- the inversion of element-wise bijection without closed form inverse can be efficiently approximated with bisection (binary search).\nThe performances achieved by the resulting model are in my opinion a stepping stone in the area of flow-based models and encouraging as to their potential. \nThe ablation study suggest that each contribution by themselves only improve slightly the model but that their simultaneous application results in a stronger boost in performance, which I can't explain from the paper. Nonetheless, some this ablation study was useful in tearing apart the contribution of each of several pieces of the model (missing pieces being gated convolutions, dropout, and instance normalization), although without explaining them.\nAlthough flow-based model can intuitively sample faster than autoregressive models, the measure of sampling time is a bit interesting as an actual evidence of that claim. But the analysis of sampling time should be done on same hardware as to fair comparison before it can be a convincing argument. \nConcerning variational dequantization, is there a reason coupling layer architecture was used instead of potentially more powerful model with less convenient inverses such as inverse autoregressive flow?"", 'I think the ideas are of sufficient interest to the community to merit acceptance & discussion, but I still miss the high resolution samples we got with the Glow paper. Responses to my concerns somewhat addressed, though simpler alternatives to uniform dequant would be nice.\n\n=====\n\nImprovements are attained on two image datasets by (a) variational dequantization, (b) mixture CDF coupling layers, and (c) self-attention in conditioning net.\n\nQuality: The work is fine, demonstrating familiarity with recent work in flows and improving upon it. The experiments are on CIFAR-10 and 32x32 ImageNet. Unclear if the evaluation numbers are on a test set or a \'validation\' set. I will be assuming test set. The visualizations are fine, but not nearly as convincing as the Glow visualizations on CelebA.\n\nClarity: The presentation is clear enough, and the motivation seems reasonable, though the assertion that all AR models are slow seems a bit belied by the recent WaveRNN work, which gets a Wavenet like model running in realtime on a phone. On the other hand, I felt like the proposed fixes were all a bit scattered here & there. Each could stand as a research topic on its own, and one paper can\'t fit in much analysis of all three. For example, a RealNVP style model usually needs to shuffle or reverse the channels to attain decent performance, but there\'s no discussion of how/whether that is done here. Folks wanting to replicate this work would want a formula for the tractable log-abs-det-jacobian of the coupling layer, but all we have is ""involves calculating the pdf of the logistic mixtures"".\n\nOriginality: Self-attention is not new, though its uptake in the conditioning networks of flow models has been slow/nonexistent. I found the dequantization improvement more novel. The new proposal for a coupling layer seems like a clever way of introducing more parameters in a structured manner. \n\nSignificance: Bringing flow models closer to the performance of AR models is good progress.\n\n\nQuestions\nI wonder whether some kind of spline or cubic interpolation might achieve similar improvement over the uniform dequantization. Perhaps uniform is not the best baseline?\nThe new coupling layer might just be viewed as a way of introducing many more parameters in a structured manner. Have you compared parameter counts?\nAppendix B shows some portion of the code, but seems like a missed opportunity to fit this into a framework like tfp.bijectors. The code seems glued in somewhat slapdash. For example, the tf_go function looks like debugging/logging code (unwanted), and lacks any usage.\n\nI think this work is promising and interesting to the probabilistic modeling community, but needs some cleanup and some more compelling presentation (non image data? Glow-style graphics?).']","[-50, 70, 20]","[50, 60, 50]","[""The sentiment score is -50 because while the reviewer initially expresses appreciation for the paper's topic, they ultimately conclude that the paper is 'unfinished' and not ready for acceptance. They point out several weaknesses in the experiments and analysis, indicating a generally negative sentiment. However, it's not extremely negative as they do acknowledge some positive aspects. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I really like', 'I wish', and 'I think'. They provide constructive criticism without being harsh or rude. However, it's not extremely polite either, as the reviewer is direct in pointing out the paper's shortcomings. The reviewer maintains a professional tone while clearly expressing their concerns."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing the contributions as 'interesting' and 'a stepping stone in the area of flow-based models'. They also mention that the performance achieved is 'encouraging'. The score is not higher because the reviewer does raise some questions and points out areas that could be improved or explained better.\n\nThe politeness score is 60 (moderately polite) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and suggestions without being harsh or dismissive. Phrases like 'in my opinion' and 'I can't explain from the paper' show a degree of humility and politeness. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's merit and interest to the community, stating 'I think the ideas are of sufficient interest to the community to merit acceptance & discussion'. However, they also express some reservations and suggestions for improvement, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering specific feedback and suggestions without using harsh language. They acknowledge the work's strengths while also pointing out areas for improvement in a respectful manner. The reviewer uses phrases like 'I wonder whether' and 'I think this work is promising' which contribute to the polite tone.""]"
"[""This paper proposes an approach to model social influence in a scenario-independent manner by instantiating the concept of intrinsic motivation and combine various human abilities as part of a reinforcement learning function in order to improve the agent's operation in social dilemma scenarios. \n\nAgents are operationalised as convolutional neural network, linear layers and LSTM. Using these base mechanisms, different abilities (communication, models of other agents (MOA)), their causal influence is inferred based on counterfactual actions. The architecture is explored across two different sequential social dilemmas. \n\nThe architecture is described in sufficient detail, with particular focus on the isolation of causal influence for communication and MOA influence. The experimental evaluation is described in sufficient detail, given the low complexity of the scenarios. While the agents with communicative ability and MOA show superior performance, a few results warrant clarification.\n\nFigure 6a) highlights the performance of influencers in contrast to a visible actions baseline. This specific scenarios shows the necessity to run experiments for larger number of runs, since it appears that action observations may actually outperform influencer performance beyond 3 steps. Please clarify what is happening in this specific case, and secondly, justify your choice of steps used in the experimental evaluation. \n\nAnother results that requires clarification is Figure 6f), which is not sufficiently discussed in the text, yet provides interesting patterns between the MOA baseline performance decaying abruptly at around 3 steps, with the influence MOA variant only peaking after that. Please clarify the observation. Also, could you draw conclusions or directions for a combination of the different approaches to maximise the performance (more generally, beyond this specific observation)? \n\nA valuable discussion is the exemplification of specific agent behaviour on Page 7. While it clarifies the signalling of resources in this specific case, it also shows shortcomings of the model's realism. How would the model perform if agents had limited resources and would die upon depletion (e.g. the de facto altruistic influencer in this scenario - since it only performs two distinct actions)? The extent of generalisability should be considered in the discussion. \n\nIn general, the paper motivates and discusses the underlying work in great detail and is written in an accessible manner (minor comment: the acronym LSTM is not explicitly introduced). The quality of presentation is good. "", ""INTRINSIC SOCIAL MOTIVATION VIA CAUSAL INFLUENCE IN MULTI-AGENT RL\n\nMain Idea: The authors consider adding a reward term to standard MARL which is the mutual information between its actions and the actions of others. They show that adding this intrinsic social motivation can lead to increased cooperation in several social dilemmas. \n\nStrong Points:\n-\tThis paper is a novel extension of ideas from single agent RL to multi agent RL, there are clear benefits from doing reward shaping in the right way to make deep RL work better.\n-\tThe paper focuses on cooperative environments which is an underfocused area in RL right now\n \nWeak Points:\n-\tThere is missing discussion of a lot of literature. The causal influence term can be thought of as a form of reward shaping. There is little discussion on the (large) literature on reward shaping to get MARL to exhibit good behavior. \n-\tThe results feel quite thin. Related to the point above: the theory of different types of reward shaping (e.g. optimistic Q-learning, prosociality, etc…) are well understood. It is not clear to me under what conditions the authors’ proposed augmentation to the reward function will lead to better or worse outcomes. The experiments in this paper are quite simple and only span a small set of environments so it would be good to have at least some formal theory.\n-\tSocial dilemmas don’t seem like the best application. The authors define the social dilemma as: “For each individual agent, ‘defecting’ i.e. non-cooperative behavior has the highest payoff.” With the intrinsic motivation, agents learn to cooperate. This is good, however, if we’re thinking about situations where agents aren’t trained together and have their own rewards (the authors’ example: “autonomous vehicles are likely to be produced by a wide variety of organizations and institutions with mixed motivations”) then won’t these agents be exploited by rational agents? Other solutions to this problem (e.g. recent papers on tit-for-tat by Lerer & Peysakhovich or LOLA by Foerster et al. construct agents where defectors get explicitly punished and so don’t want to try exploiting). Is there something I am missing here? Do the agents learn to punish non-cooperators (if no, isn’t it rational at that point to just not cooperate and won’t self-driving cars trained via this method get exploited by others)? \n-\tRelate to the point(s) above: a better environment for application here seems to be coordination games/”Stag Hunt” games where it is known that MARL converges to poor equilibria and many other methods e.g. optimistic Q-learning or prosociality have been invented to make things work better. Perhaps the method proposed here will work better than these (and it has the appealing property that it does not require the ability to observe the other agents' rewards as e.g. prosociality does)\n-\tThis paper contains some quite grandiose language connecting the proposed reward shaping to “how humans learn” (example: It may also have correlates in human cognition; experiments show that newborn infants are sensitive to correspondences between their own actions and the actions of other people, and use this to coordinate their behavior with others) it’s unclear to me that humans experience extra reward for their actions having high mutual information (and/or causal information with others). While it’s fine to argue some of these points at a high level I would suggest scrubbing the text of the gratuitous references to this.\n\nNits:\n“Crawford & Sobel (1982) find that once agents’ interests diverge by a finite amount, no communication is to be expected.” – this is an awkward phrasing of the Crawford and Sobel result (it can be read as “if interests diverge by any epsilon there can be no communication”). The CS result is that information revealed in communication (in equilibrium) is proportional to amount of common interest. "", 'The paper introduces a new intrinsic reward for MARL, representing the causal influence of an agent’s action on another agent counterfactually. The authors show this causal influence reward is related to maximising the mutual information between the agents’ actions. The behaviour of agents using this reward is tested in a set of social dilemmas, where it leads to increased cooperation and communication protocols, especially if given an explicit communication channel. As opposed to related work, the authors also equip the agents with an internal Model of Other Agents that predicts the actions of other agents and simulates counterfactuals. This allows the method to run in a decentralized fashion and without access to other agents’ reward functions.\n\nThe paper proposes a very interesting approach. I’m not a MARL expert, so I focused more on the the causal aspects. The paper seems generally well-organized and well-written, although I’m a bit confused about the some of the causal modelling decisions and assumptions. This confusion and  some potential errors, which I describe in detail below, are the reason for my borderline decision, despite liking the paper otherwise. \n \nFirst, I’m a bit confused about the utility of the Section 2.1 model (Figure 1), mostly because of the temporal and multiple agents aspects that seem to be dealt with (“more”) correctly in the MOA model. Specifically in Figure 1, one would need to assume that there is only one agent A influencing agent B at the same time (and agent B does not influence anything else). For example, there is no other agent C which actions also influence agent B, and no agent D that is influenced by agent B, otherwise the backdoor-criterion would not work, unless you add also the action of agent C to the conditioning set (or its state). Importantly, adding the actions of all agents, also a potential agent D that is downstream of B would be incorrect. So in this model there is some kind of same time interaction and there seems to be the need for a causal graph that is known a priori. These problems should disappear if one assumes that only the time t-1 actions can influence the time t actions, as in the MOA model. I assume the idea of the Figure 1 model was to show a relationship with mutual information, but for me specifically it was quite confusing. \n\nI was much less confused by the MOA causal graph represented in Figure 4, although I suspect there are quite some interactions missing (for example s_t^A causes u_t^A similarly to the green background? s_t causes s_{t+1} (which btw in this case should probably be split in two nodes, one s_{t+1} and one s_{t+1}^B?). Possibly one could also add the previous time step for agent B (with u_{t+1}^B influenced by u_t^B I would assume?). As far as I can see there is no need to condition on a_t^B in this case to see the influence of a_t^A on a_{t+1}^B, u_t^A and s_t^A should be enough?\n\nMinor details:\nIs there possibly a log missing in Eq. 2?\n']","[50, -30, -20]","[80, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and detailed descriptions, while also providing constructive criticism and suggestions for improvement. The overall tone is balanced, with both positive aspects and areas for clarification highlighted. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language, constructive feedback, and the absence of harsh criticism. The reviewer asks for clarifications and justifications using phrases like 'Please clarify' and 'could you draw conclusions,' which maintain a polite and professional tone throughout the review. The reviewer also acknowledges the paper's strengths, such as the detailed motivation and accessible writing style, which contributes to the polite tone."", ""The sentiment score is -30 because while the reviewer acknowledges some strong points, they list more weak points and criticisms. The review is overall more negative than positive, but not extremely so. The politeness score is 50 because the reviewer uses professional and respectful language throughout, even when critiquing. They offer constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer also acknowledges the paper's strengths before diving into weaknesses, which is a polite approach. However, the score isn't higher because the review doesn't go out of its way to be exceptionally polite or encouraging."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the approach 'very interesting' and likes the paper overall, they express confusion about some aspects and mention 'potential errors', leading to a 'borderline decision'. This indicates a mix of positive and negative sentiments, with the negative slightly outweighing the positive. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths ('well-organized and well-written') and framing criticisms as personal confusion ('I'm a bit confused') rather than direct attacks. They also provide detailed, constructive feedback, which is a polite approach to peer review. The reviewer maintains a professional tone without using overly formal or informal language.""]"
"[""I like this paper. What the authors have done is of high quality. It is well written and clear. However, quite a lot of experiments are necessary to make this paper publishable in my opinion.\n\nStrenghts:\n- The idea to use a GAN for model compression is something that many must have considered. It is good to see that someone has actually tried it and it works well.\n- I think the compression score is definitely an interesting idea on how to compare GANs that can be of practical use in the future.\n- The experimental results, which are currently in the paper, largely support what the authors are saying.\n\nWeaknesses:\n- The authors don't compare how good this technique is in comparison to simple data augmentation. My suspicion is that the difference will be small. I realise, however, that the advantage of this method over data augmentation is that it is harder to do it for tabular data, for which the proposed method works well. Having said that, models for tabular data are usually quite simple in comparison to convnets, so compressing them would have less impact.\n- The experiments on image data are done with CIFAR-10, which as of 2018 is kind of a toy data set. Moreover, I think the authors should try to push both the baselines and their technique much harder with hyperparameter tuning to understand what is the real benefit of what they are proposing. I suspect there is a lot of slack there. For comparison, Urban et al. [1] trained a two-layer fully connected network to 74% accuracy on CIFAR-10 using model compression.\n\n[1] Urban et al. Do Deep Convolutional Nets Really Need to be Deep (Or Even Convolutional)? 2016."", 'Summary: \nThe paper proposes an approach for improving standard techniques for model compression, i.e. compressing a big model (teacher) in a smaller and more computationally efficient one (student), using data generated by a conditional GAN (cGAN). The paper suggests that the standard practice of training the student to imitate the behavior of the teacher *on the same training data* that the teacher was trained on is problematic and can lead to overfitting. Instead, the paper proposes learning a conditional GAN, which can potentially generate large amounts of realistic synthetic data, and use this data (in addition to original training data) for model compression.\nExperimental results show that this idea seems to improve the performance of convnet student models on CIFAR-10 classification and random forest student models on tabular data from UCI and Kaggle.\nAnother contribution of the paper is to propose an evaluation metric for generative model, called the compression score. This score evaluates the quality of generated data by using it in model compression: “good” synthetic data results in a smaller gap in performance between student and teacher models.\n\nStrengths:\n-\tThe paper sheds a light on an interesting aspect in model compression. The idea of teaching a student model to imitate behavior of the teacher model on *new* data is interesting. In fact, it emphasizes the fact that we are mostly interested in imitating the teacher model’s capability of generalizing to new examples rather than overfitting to training examples.\n-\tExperiments show that for several settings (model class, architecture and datasets), using synthetic data by a cGAN can be useful in reducing the gap between student and teacher models. \n-\tThe paper is clearly written and easy to follow.\n\nWeaknesses:\n-\tThe claim that reusing the same training data used for training the teacher model in model compression can lead to overfitting of student model is not very obvious and needs more experimental evidence in my opinion. One way to test this is to use some unseen real data (e.g. validation or a held-out part of training data) for model compression, and showing that it can indeed help in improving student performance.\n-\tThe claim that cGAN can generate “infinite” amount of realistic data is too strong. In light of some well-known problems of GANs such as mode collapse [2] and low-support learned distributions [1], this assumption seems unrealistic. In fact, it is not too obvious how synthetic data by a generative model learned on *same training data as the teacher* can provide any additional information to real data.\n-\tWhile the idea of the proposed evaluation metric seems interesting, I believe it is not very practical, because: \n1.\tIt is computationally intensive (requires training a model from scratch on fake data)\n2.\tIt relies on performance of the compression mechanism, which might also have some idiosyncrasies that prefer some features in synthetic data which do not necessarily correspond to quality of generated data.\n\nQuestions/Suggestions:\n-\tIn addition to using held-out real data for model compression as suggested above, a useful baseline could be using standard data-augmentation techniques in model compression.\n-\tWhat would happen if a student model is very small and cannot possibly overfit training data? Would using synthetic data be still useful there?\n-\tI am actually confused about a claim made when presenting compression score in Section 5. The paper claims that the best compression score is 1 (training student model on real data), while the paper shows that in fact, good synthetic data should produce *better* accuracy than using real data. I would appreciate if authors can clarify this point.\n\nOverall recommendation: \nWhile the paper presents an interesting problem in model compression, I’m leaning towards rejecting the paper because of the weaknesses mentioned above. That being said, I am happy to reconsider my decision if there is any misunderstanding on my part.\n\nReferences:\n[1] Arora, Sanjeev, and Yi Zhang. ""Do GANs actually learn the distribution? an empirical study."" arXiv preprint arXiv:1706.08224 (2017).\n[2] Goodfellow, Ian. ""NIPS 2016 tutorial: Generative adversarial networks."" arXiv preprint arXiv:1701.00160 (2016).\n\n\n-----\n\nUpdated score and posted a comment to author response.\n', ""This paper focused on training a small network with a pre-trained large network in a student-teacher strategy, which also known as knowledge distillation. The authors proposed to use a separately trained GAN network to generate synthetic data for the student-teacher training. \n\nThe proposed method is rather straightforward. The experimental results look good, GAN generated data help train a better performed student in knowledge distillation. However, I have concerns about both motivations and experiments. \n\n1. The benefits of GAN for generating synthetic data to assist supervised training are still mysterious, especially when GAN is separately trained on the same dataset without more information introduced. I would love the authors to clarify why GAN generated data are particularly effective for knowledge distillation. Does GAN generated data also help standard supervised training? I would expect following experiments: use mixture of training and GAN data to train teacher and student network by standard supervised loss without knowledge distillation, and compare with values in table 1. \n\n2. The performance of the proposed method depends on the quality of GAN. To help me further understand the quality of GAN, I hope to see the following experiments to compare with scores in table 1.\ni) The accuracy of supervised trained teach and student on GAN generated image. \nii) The classification accuracy on test data by the classifier trained in AC-GAN. \n\n3. I would like the authors to clarify their experiments to convince me the comparison in table 1 is fair.\ni) How many data and iterations in total are used for standard training and knowledge distillation with/without GAN data? Does the better performance come from synthetic data, or come from exploiting more data and training for longer time?\nii) Related to i), In figure 1 (a), how many data and iteration for each epoch? It would help if the standard supervised training curve for student can be provided. \niii) The experiments have a lot of hyperparameters, for example, the weight \\alpha, the temperature T,  optimizer, the learning rate, learning rate decay, the probability p_fake. These hyperparameters are different for each experimental setting. How are they chosen?\n\n4. Please explain conceptually why the proposed compression score is better than inception score. \n\n5. The paper is missing a conclusion section. The following papers introduce adversarial training for knowledge distillation. Though it is not necessary to compare with them in experiments as they are complicated method and the usage of GAN is different from this paper, I think it is still worth to mention them in related work. \nWang et al. 2018 Adversarial Learning of Portable Student Networks\nXu et al. 2018 Training Student Networks for Acceleration with Conditional Adversarial Networks \n\n================ after rebuttal ====================\nI appreciate the authors' response and slightly raise the score. It is a good rebuttal and it has clarified several things. I like the authors' explanation on why GAN is particularly good in a student-teacher setting. The explanation reminds me of the mixup data augmentation paper from last year. I also like the additional experiments which clearly show the benefits of GAN data augmentation. \n\nHowever, I still think it is borderline for several reasons.\n1. As the other reviewer has pointed out, CIFAR-10 is a bit too toy and some models (like LeNet for Figure 2) cannot really show the advantage of the method. I would suggest try ImageNet, and use more recent networks for ablation study.  \n2. As the other reviewer has pointed out, the compression ratio can be impractical. The compression ratio  depends on student-teacher training, which can take a relatively long time. \n3. I would suggest the following experiments that may strengthen the paper. I would consider these as a plus, not necessarily related to my current evaluation. \ni) Try not use GAN, but use mixup (linear interpolation of samples) as data augmentation, and go through the student-teacher training.\nii) Try evaluate the effect of generator structure for data augmentation. Does the generator have to be very strong? The GAN generated results did not improve supervised learning may suggest the generator is not necessarily to be strong.  \n""]","[50, -30, -20]","[80, 70, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer starts by saying they like the paper and praising its quality and clarity. However, they also mention that more experiments are needed, which tempers the positivity. The strengths are highlighted before the weaknesses, indicating a generally positive view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They present criticisms constructively, using phrases like 'I think' and 'My suspicion is' rather than making blunt statements. The reviewer also provides specific suggestions for improvement and references to support their points, which is a polite and professional approach in academic review."", 'The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they ultimately lean towards rejecting it due to significant weaknesses. The overall tone is more negative than positive, but not extremely negative. The politeness score is 70 because the reviewer uses respectful and constructive language throughout, acknowledging strengths before discussing weaknesses, and offering suggestions for improvement. They also express willingness to reconsider their decision, which adds to the politeness. The review is well-structured and professional, avoiding any harsh or rude language.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The experimental results look good'), they express several concerns and request numerous clarifications and additional experiments. The overall tone suggests skepticism about the paper's contributions and methodology. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, employing phrases like 'I would love the authors to clarify' and 'I hope to see', which maintain a courteous tone while expressing criticisms. The reviewer also acknowledges the authors' rebuttal positively, showing a willingness to engage constructively. However, the persistent questioning and extensive list of requested changes prevent the politeness score from being higher.""]"
"['This paper proposes an approximate second-order method with low computational cost. A common pitfall of second-order methods is the computation (and perhaps inversion) of the Hessian matrix. While this can be avoided by instead relying on Hessian-vector products as done in CG, it typically still requires several iterations. Instead, the authors suggest a simpler approach that relies on one single gradient step and a warm start strategy. The authors points out that the resulting algorithm resembles a momentum method. They also provide some simple convergence proofs on quadratics and benchmark their method to train deep neural networks.\n\nWhile I find the research direction interesting, the execution is rather clumsy and many details are not sufficiently motivated. Finally, there is a lot of relevant work in the optimization community that is not discussed in this paper, see detailed comments and references below.\n\n1) Method\nThe derivation of the method is very much driven on a set of heuristics without theoretical guarantees. In order to derive the update of the proposed method, the authors rely on three heuristics:\na) The first is to reuse the previous search direction z as a warm-start. The authors argue that this might be beneficial if If z does not change abruptly. In the early phase, the gradient norm is likely to be large and thus z will change significantly. One might also encounter regions of high curvature where the direction of z might change quickly from one iteration to the next.\nThe ""warm start"" at s_{t-1} is also what yields the momentum term, what interpretation can you give to this choice?\n\nb) The second step interleaves the updates of z and w instead of first finding the optimum z. This amounts to just running one iteration of CG but it is rather unclear why one iteration is an appropriate number. It seems one could instead some adaptive strategy where CG with a fixed accuracy. One could potentially see if allowing larger errors at the beginning of the optimization process might still allow for the method to converge. This is for instance commonly done with the batch-size of first-order method. Gradually increasing the batch-size and therefore reducing the error as one gets close to the optimum can still yield to a converging algorithm, see e.g. \nFriedlander, M. P., & Schmidt, M. (2012). Hybrid deterministic-stochastic methods for data fitting. SIAM Journal on Scientific Computing, 34(3), A1380-A1405.\n\nc) The third step consists in replacing CG with gradient descent.\n""If CG takes N steps on average, then Algorithm 2 will be slower than SGD by a factor of at least N, which can easily be an order of magnitude"".\nFirst, the number of outer iterations may be a lot less for the Hessian-free method than for SGD so this does not seem to be a valid argument. Please comment.\nSecond, I would like to see a discussion of the convergence rate of solving (12) inexactly with krylov subspace methods. Note that Lanczos yields an accelerated rate while GD does not. So the motivation for switching to GD should be made clearer.\n\nd) The fourth step introduces a factor rho that decays z at each step. I’m not really sure this makes sense even heuristically. The full update of the algorithm developed by the author is:\nw_{t+1} = w_t - beta nabla f + (rho I - beta H) (w_t - w_{t-1}).\nThe momentum term therefore gets weighted by (rho I - beta H). What is the meaning of this term? The -beta H term weights the momentum according to the curvature of the objective function. Given the lack of theoretical support for this idea, I would at least expect a practical reason back up by some empirical evidence that this is a sensible thing to do.\nThis is especially important given that you claim to decay rho therefore giving more importance to the curvature term.\nFinally, why would this be better than simply using CG on a trust-region model? (Recall that Lanczos yields an accelerated linear rate while GD does not).\n\n2) Convergence analysis\na) The analysis is only performed on a quadratic while the author clearly target non-convex functions, this should be made clear in the main text. Also see references below (comment #3) regarding a possible extension to non-convex functions.\nb) The authors should check the range of allowed values for alpha and beta. It appears the rate would scale with the square root of the condition number, please confirm, this is an important detail. I also think that the constant is not as good as Heavy-ball on a quadratic (see e.g. http://pages.cs.wisc.edu/~brecht/cs726docs/HeavyBallLinear.pdf), please comment.\nc) Sub-sampling of the Hessian and gradients is not discussed at all (but used in the experiments). Please add a discussion and consider extending the proof (again, see references given below).\n\n3) Convergence Heavy-ball\nThe authors emphasize the similarity of their approach to Heavy-ball. They cite the results of Loizou & Richtarik 2017. Note that they are earlier results for quadratic functions such as \nLessard, L., Recht, B., & Packard, A. (2016). Analysis and design of optimization algorithms via integral quadratic constraints. SIAM Journal on Optimization, 26(1), 57-95.\nFlammarion, N., & Bach, F. (2015, June). From averaging to acceleration, there is only a step-size. In Conference on Learning Theory (pp. 658-695).\nThe novelty of the bounds derived in Loizou & Richtarik 2017 is that they apply in stochastic settings.\nFinally, there are results for non-convex functions such convergence to a stationary point, see\nZavriev, S. K., & Kostyuk, F. V. (1993). Heavy-ball method in nonconvex optimization problems. Computational Mathematics and Modeling, 4(4), 336-341.\nAlso on page 2, ""Momentum GD ... can be shown to have faster convergence than GD"". It should be mentioned that this only hold for (strongly) convex functions!\n\n4) Experiments\na) Consider showing the gradient norms. \nb) it looks like the methods have not yet converged in Fig 2 and 3.\nc) Second order benchmark:\nIt would be nice to compare to a method that does not use the GN matrix but the true or subsampled Hessian (like Trust Region/Cubic Regularization) methods given below.\nWhy is BFGS in Rosenbrock but not in NN plots?\nd) ""Batch normalization (which is known to improve optimization)"" \nThis statement requires a reference such as\nTowards a Theoretical Understanding of Batch Normalization\nKohler et al… - arXiv preprint arXiv:1805.10694, 2018\n\n5) Related Work\nThe related work should include Cubic Regularization and Trust Region methods since they are among the most prominent second order algorithms. Consider citing Conn et al. 2000 Trust Region,  Nesterov 2006 Cubic regularization, Cartis et al. 2011 ARC.\nRegarding sub-sampling: Kohler&Lucchi 2017: Stochastic Cubic Regularization for non-convex optimization and Xu et al.: Newton-type methods for non-convex optimization under inexact hessian information.\n\n6) More comments\n\nPage 2\nPolyak 1964 should be cited  where momentum is discussed.\n""Perhaps the simplest algorithm to optimize Eq. 1 is Gradient Descent"". This is technically not correct since GD is not a global optimization algorithm. Maybe mention that you try to find a stationary point\nrho (Eq. 2) and lambda (Eq. 4) are not defined\n\nPage 4: \nAlgorithm 1 and 2 and related equations in the main text: it should be H_hat instead of H.\n\nBackground\n“Momemtum GD exhibits somewhat better resistance to poor scaling of the objective function”\nTo be precise the improvement is quadratic for convex functions. Note that Goh might not be the best reference to cite as the article focuses on quadratic function. Consider citing the lecture notes from Nesterov.\n\nSection 2.2\nThis section is perhaps a bit confusing at first as the authors discuss the general case of a multivalue loss function. Consider moving your last comment to the beginning of the section.\n\nSection 2.3\nAs a side remark, the work of Dauphin does not rely on the Gauss-Newton approximation but a different PSD matrix, this is probably worth mentioning.\n\nMinor comment: The title is rather bold and not necessarily precise since the stepsize of curveball is not particularly small e.g. in Fig 1.\n', 'In this paper, the authors introduce a new second-order algorithm for training deep networks. The method, named CurveBall, is motivated as an inexpensive alternative to Newton-CG. At its core, the method augments the update role for SGD+M with a Hessian-vector product that can be done efficiently (Algorithm 1). While a few new hyperparameters are introduced, the authors propose ways by which they can be calibrated automatically (Equation 16) and also prove convergence for quadratic functions (Theorem A.1) and guaranteed descent (Theorem A.2). The authors also present numerical results showing improved training on common benchmarks. I enjoyed reading the paper and found the motivation and results to be convincing. I especially appreciate that the authors performed experiments on ImageNet instead of just CIFAR-10, and the differentiation modes are explained well. As such, I recommend the paper for acceptance. \n\n\nI suggest ways in which the paper can be further improved below:\n\n- In essence, the closest algorithm to CurveBall is LiSSA proposed by Agarwal et al. They use a series expansion for approximating the inverse whereas your work uses one iteration of CG. If you limit LiSSA to only one expansion, the update rule that you would get would be similar to that of CurveBall (but not exactly the same). I feel that a careful comparison to LiSSA is necessary in the paper, highlighting the algorithmic and theoretical differences. I don\'t see the need for any additional experiments, however.\n- For books, such as Nocedal & Wright, please provide page numbers for each citation since the information quoted is across hundreds of pages. \n- It\'s a bit non-standard to see vectors being denoted by capital letters, e.g. J(w) \\in R^p on Page 2. I think it\'s better you don\'t change it now, however, since that might introduce inadvertent typos. \n- It would be good if you could expand on the details concerning the automatic determination of the hyperparameters (Equation 16). It was a bit unclear to me where those equations came from. \n- Could you plot the evolution of \\beta, \\rho and \\lambda for a couple of your experiments? I am curious whether our intuition about the values aligns with what happens in reality. In Newton-CG or Levenberg-Marquardt-esque algorithms, with standard local strong convexity assumptions, the amount of damping necessary near the solution usually falls to 0. Further, in the SGD+M paper of Sutskever et al., they talked about how it was necessary to zero out the momentum at the end. It would be fascinating if such insights (or contradictory ones) were discovered by Equation 16 and the damping mechanism automatically. \n- I\'m somewhat concerned about the damping for \\lambda using \\gamma. There has been quite a lot of work recently in the area of Stochastic Line Searches which underscores the issues involving computation with noisy estimates of function values. I wonder if the randomness inherent in the computation of f(w) can throw off your estimates enough to cause convergence issues. Can you comment on this?\n- It was a bit odd to see BFGS implemented with a cubic line search. The beneficial properties of BFGS, such as superlinear convergence and self-correction, usually work out only if you\'re using the Armijo-Wolfe (Strong/Weak) line search. Can you re-do those experiments with this line search? It is unexpected that BFGS would take O(100) iterations to converge on a two dimensional problem. \n- In the same experiment, did you also try (true) Newton\'s method? Maybe we some form of damping? Given that you\'re proposing an approximate Newton\'s method, it would be a good upper baseline to have this experiment. \n- I enjoyed reading your experimental section on random architectures, I think it is quite illuminating. \n- Please consider rephrasing some phrases in the paper such as ""soon the latter"" (Page 1), ""which is known to improve optimisation"", (Page 7), ""non-deep problems"" (Page 9). ', 'Authors propose choosing direction by using a single step of gradient descent ""towards Newton step"" from an original estimate, and then taking this direction instead of original gradient. This direction is reused as a starting estimate for the next iteration of the algorithm. This can be efficiently implemented since it only relies on Hessian-vector products which are accessible in all major frameworks.\n\nBased on the fact that this is an easy to implement idea, clearly described, and that it seems to benefit some tasks using standard architectures, I would recommend this paper for acceptance.\n\nComments:\n- introducing \\rho parameter and solving for optimal \\rho, \\beta complicates things. I\'m assuming \\rho was needed for practical reasons, this should be explained better in the paper. (ie, what if we leave rho at 1)\n- For  ImageNet results, they show 82% accuracy after 20 epochs on full ImageNet using VGG. Is this top5 or top1 error? I\'m assuming top5 since top1 would be new world record for the number of epochs needed. For top5, it seems SGD has stopped optimizing at 60% top5. Since all the current records on ImageNet are achieved with SGD (which beats Adam), this suggests that the SGD implementation is badly tuned\n- I appreciate that CIFAR experiments were made using standard architectures, ie using networks with batch-norm which clearly benefits SGD']","[-40, 80, 70]","[20, 90, 60]","[""The sentiment score is -40 because while the reviewer finds the research direction interesting, they express significant concerns about the execution, lack of theoretical guarantees, and insufficient motivation for various aspects of the method. The review points out multiple areas needing improvement or clarification, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'please comment' and 'consider citing', which are polite ways of requesting clarification or suggesting improvements. The reviewer also acknowledges positive aspects before critiquing, which is a polite approach. However, some phrases like 'rather clumsy' and 'not sufficiently motivated' are somewhat direct criticisms, preventing a higher politeness score."", ""The sentiment score is 80 (positive) because the reviewer explicitly states they 'enjoyed reading the paper' and found the 'motivation and results to be convincing.' They also 'recommend the paper for acceptance,' which is a strong positive indicator. The score is not 100 as there are some suggestions for improvement. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I suggest,' 'It would be good if,' and 'Could you,' which are polite ways of offering feedback. They also compliment specific aspects of the paper, such as the experiments on ImageNet and the random architectures section. The reviewer maintains a professional and courteous tone throughout, even when pointing out areas for improvement."", ""The sentiment score is 70 (positive) because the reviewer recommends the paper for acceptance, praising it as an 'easy to implement idea, clearly described' that 'seems to benefit some tasks using standard architectures'. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, appreciates certain aspects of the work ('I appreciate that CIFAR experiments were made using standard architectures'), and offers constructive criticism. The reviewer maintains a professional tone, balancing praise with suggestions for improvement. The language is not overly formal or excessively polite, but it is consistently respectful and constructive, which is appropriate for a peer review.""]"
"[""The paper claims to propose a novel generative probabilistic neural network model such that its encoder (classifying an image) can be approximated by a convolutional neural network with ReLU activations and MaxPooling layers. Besides the standard parameters of the units (weights and biases), the model has two additional latent variables per unit, which decide whether and where to put the template (represented by the weights of the neuron) in the subsequent layer, when generating an image from the class. Furthermore, the authors claim to derive new learning criteria for semi-supervised learning of the model including a novel regulariser and claim to prove its consistency. \n\nUnfortunately, the paper is written in a way that is completely incomprehensible (for me). The accumulating ambiguities, together with its sheer length (44 pages with all supplementary appendices!), make it impossible for me to verify the model and the proofs of the claimed theorems. This begins already with definition of the model. The authors consider the latent variables as dependent and model them by a joint distribution. Its definition remains obscure, let alone the question how to marginalise over these variables when making inference. Without a thorough understanding of the model definition, it becomes impossible (for me) to follow the presentation of the learning approaches and the proofs for the theorem claims.\n\nIn my view, the presented material exceeds the limits of a single conference paper. A clear and concise definition of the proposed model accompanied by a concise derivation of the basic inference and learning algorithm would already make a highly interesting paper.\n\nConsidering the present state of the paper, I can't, unfortunately, recommend to accept it for ICLR.\n\n"", 'pros:\n- Interesting probabilistic interpretation of the CNNs improving work of [Patel 2016].\n- State-of-the-art results following from the proposed probabilistic model. \n\ncons:\n- The regular 10 pages of the paper are not self-contained. \n\nThe paper is written in overly condensed way. I found it impossible to clearly understand major claims of the paper without reading the accompanied 34 pages long appendix. Many concepts/notations used in the paper are introduced in the appendix. My assessment is done solely based on reading the 10 regular pages. \n\n- The probabilistic model NMR (equ (1) and (2)) defines distribution of inputs given latent variables and the outputs, $p(x|z,y)$, as well as it defines a distribution $p(z|y)$. Hence, in principle, one could maximize $p(x)=\\sum_{i} E_{z} p(x_i|z,y)p(z|y)p(y)$ when learning from unsupervised data. Instead, the authors propose to learn by MINIMIZING the expectation (not clear w.r.t which variables) of $\\log p(x,z|y)$ (equ (7)). Although it leads to empirically nice results, I do not see a clear motivation for such objective function. \n\n- The motivation for using the MIN-MAX entropy as a loss function (sec 3) is also not clear. Why it should be better than the standard cross-entropy in the statistical sense?\n\n- The proposed probabilistic model NMR differs form the previous work of [Patel 2016] by introducing the prior (1) on the latent variable. Unfortunately, pros and cons of this modifications are not fully discussed. E.g. how using dependent latent variables impact complexity of the inference.  \n', 'Summary: This paper introduces the Neural Rendering Model (NRM), a generative model in which the computations involved in inference correspond to those of a CNN forward pass. The NRM’s supervised learning objective is lower bounded by a variant of the cross-entropy objective. This objective is used to formulate a max-min network, which has a particular type of weight sharing between a standard branch with max pooling / ReLUs and a second branch with min pooling / NReLUs. The max-min objective and network show strong performance on semi-supervised learning tasks. \n\nPosing a CNN as inference in a generative model is an interesting direction, and could be very useful for probabilistic inference in the context of neural nets. However, the paper is rather difficult to follow and requires frequent reference to the appendix to understand the main body. Some important components (like those relating to rendering paths and RPNs) are given good intuitive explanations early on but remain a bit ambiguous throughout the paper. I would recommend improving the presentation before publication.\n\nQuestion: “we can modify NRM to incorporate our knowledge of the tasks and datasets into the model and perform JMAP inference to achieve a new CNN architecture.“\nI appreciate the CNN / NRM correspondence in Table 1, and see how the NRM may be modified to produce modified CNN architectures. That being said, I am not sure I understand what sorts of task-specific knowledge are being referred to here. Could you give an example of a type of knowledge that the NRM would allow you to bake into a CNN architecture, but would otherwise be difficult to incorporate?\n\nMinor:\n“As been shown later in Section 2.2…”\n\n“…is part of the optimization in equation equation 6.”']","[-70, -30, -20]","[20, 20, 60]","[""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's comprehensibility and length, ultimately recommending against acceptance. The reviewer uses phrases like 'completely incomprehensible,' 'impossible for me to verify,' and 'can't, unfortunately, recommend to accept it,' which indicate a strongly negative sentiment. However, the score is not at the extreme negative end because the reviewer does acknowledge the potential interest of the topic if presented more clearly. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Unfortunately' and 'in my view' to soften their criticisms, and they explain their reasoning for not recommending acceptance. The reviewer also suggests how the paper could be improved, which is a constructive approach. However, the score is only slightly positive because the criticism, while politely phrased, is still quite direct and strong."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('Interesting probabilistic interpretation', 'State-of-the-art results'), they express several significant concerns and criticisms. These include the paper being overly condensed, lack of clarity in major claims, unclear motivations for certain methodological choices, and insufficient discussion of the model's pros and cons. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, presenting their criticisms as observations rather than attacks. They use neutral language like 'I found it impossible to clearly understand' and 'My assessment is' rather than more confrontational phrasing. The reviewer also begins by noting positive aspects before moving on to criticisms, which is a polite approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting direction of the paper, they express concerns about the difficulty in following the paper and recommend improving the presentation before publication. This suggests a mix of positive and negative feedback, leaning slightly negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the potential value of the work, and frames criticisms constructively. They use phrases like 'I appreciate' and 'Could you give an example', which maintain a polite tone. The reviewer also offers specific suggestions for improvement, which is helpful and courteous. The language is professional and avoids any harsh or rude phrasing.""]"
"['The authors present a method for fine-tuning neural networks so inference can be performed in a quantized low bit data format down to 3 bits. The authors achieve this through a combination of three techniques:\n1. Noise injection to fine-tune the weights before quantization. The effect of noise injection can model that of quantization, but rather than being stuck in a quantization bin, fine grained weight updates are still possible\n2. A schedule that quantizes layer by layer, rather than all layers at the same time\n3. Clipping weights and activations within a learned range to obtain finer grained bins within that range. \n\n\nThe main contribution is a novel combination of mostly existing techniques. Clipping (or clamping as the authors call it) has been proposed by Zhang et al. 2018, but it\'s an interesting contribution to have the clipping learned directly via backpropagation with a straight-through estimator. Treating the quantization as noise has been proposed in a different form in McKinstry et al. 2018. Gradual quantization appears novel, but is also the least interesting of the techniques. Therefore, novelty on ideas/methods is somewhat limited, and the contribution is mostly the in the impressive experimental results, which appear to be outperforming previous methods. The main weaknesses are poor writing, and that some details of the implementation required to reproduce the results are missing. For example, the training schedule is not given, e.g. how many epochs to train the clean model, how many with noise, how many quantized. Details on the gradual quantization are also missing. Block based quantization is completely heuristic and not well motivated. If this is the main novel ingredient, more details on the mechanics would be needed. Is both the noise injection and the quantization done in blocks? If the motivation is in ""the opportunity to adapt”, then what does the adaptation look like? \n\nAs above, my other main issue is with the writing, there are many examples where I would suggest improvements:\n\nThis work could be improved greatly by copy editing for English grammar. There are many typos (including ones that can be caught by autocorrect, missing punctuation, or using similar but unrelated words, e.g. ""token"" instead of ""taken""). The manuscript appears hastily put together and not ready for publication. \n\nThe acronym NICE already has a meaning in the DL literature: Dinh, L., Krueger, D., & Bengio, Y. (2014). NICE: Non-linear Independent Components Estimation. It confusing to reuse it. \n\nThe term clamping is only explained on page 4 but used since the abstract. It’s used in a nonstandard way to mean “constrained to lie within a range” which should be explained earlier. I think “clipped” would be a better term, following the related Choi et al. 2018. Clamping usually means ""constrained to a fixed value"" (not a range), so it is not a good term to use in this context. \n\nAre the results shown in table 2 and table 3 from a single trial or averaged across reruns? If single trial, it\'s misleading to have 2 figures after the decimal. Even non-quantized ResNet tends to have 0.5% or so run to run variability, which is much larger than the differences between some of the methods shown here. In fact, a lot of the results could just be due to picking a lucky random seed. \n\nComparisons are shown against methods JOINT (Jung et al), LQ-Nets (Zhang et al), FAQ (McKinstry et al). It would be helpful to present them with the same names in the ""related work"" section, and explain why they were picked out for the comparison. For someone not familiar with the literature it\'s hard to see why these 3 would be the obvious picks. \n\nReadability would increase if table 2 and 3 were moved to section 4 where they are referenced, rather than after the discussion. Fig 2 font size too small and hard to read. \n', 'The article presents a method for quantization of deep neural networks for classification and regression, using three key parts: (i) noise injection to model the effect of quantization during forward inference, (ii) clamping with learned maximum activations to reduce the quantization bin size, and (iii) gradual quantization of blocks of the network, while previously quantized blocks remain unchanged. The method is evaluated on ImageNet, CIFAR-10, and a regression task, showing performance on-par or better than state-of-the-art methods for particular quantization bit size. Finally, the method is used for porting network onto a FPGA.\n\nThe paper addresses an important topic, because there is increasing interest in hardware-efficient implementations of deep neural networks. The method could be interesting for practitioners, because it does not interfere with the original training of the full-precision method, and can be applied later on.\n\nThe main weakness is that none of the proposed methods are entirely original, and the combination is rather ad-hoc than well-justified. For example, quantization noise has been considered in several previous articles, e.g. already in BinaryConnect (Courbariaux et al. 2015), although the novelty here is that the noise is explicitly added during the forward path. However, the choice of the Bernoulli mask with p=0.05 is not justified and might not work best for other tasks. The authors admit that gradual quantization has been proposed before, and clamping a ReLU is also not new, although here a new way to learn and initialize the clamping parameters is presented.\n\nThe article would be OK if the empirical results were really strong, but unfortunately they are not entirely convincing:\n1. The classification results are only for ResNet architectures, it remains unclear whether results would hold also for other architectures.\n2. The numerical results in Table 2 are very close to each other, and no error bars are available, so it is not possible to judge whether differences are significant. Also, the advantage of the NICE method vanishes for 3-bit models.\n3. The results for CIFAR-10 come without any comparison.\n4. The results for regression are only compared to a single method, which is re-implemented by the authors, and might therefore not be fully optimized. Thus there is no strong baseline to judge the results.\n5. No results are shown for the hardware implementation.\n\nOverall, the paper is not a particularly interesting read for people interested in a deeper understanding of network quantization, but the method could still be valuable for applications. Is this sufficient for ICLR? Since the experimental results do not entirely convince me I will put my grade slightly below acceptance threshold.\n\nMinor points:\n- The abstract has a pretty long introduction before it begins to tell what the contributions of the article are.\n- Occasional grammar mistakes.\n- Tables 1 and 2 are misplaced\n\nPros:\n+ important topic (network quantization)\n+ good empirical results\n+ easy to apply\n\nCons:\n- combination of previously proposed methods\n- no convincing justification \n- no strong advantage over previous methods', '[Summary]\nNeural network quantization is can enable many practical applications for deep learning, therefore it is an important research problem. The paper claims two contributions: 1. Injecting noise during training to make it more robust to quantization errors. 2. Clamping the parameter values in a layer as well as the activation output, where the clamping interval is some multiple of the standard deviation about the mean, and the clamping interval is updated using the Straight through estimator. The main strength of the paper lies in the empirical results where the combination of techniques employed by the authors outperforms the SOTA methods in a compute of scenarios.\n\n[Pros]\nThe paper is working on an important problem area and as a technical report this work can be valuable in the industry. There is novelty in the particular combination of techniques that the authors have employed and some of the empirical results show the strength of the technique.\n\n[Cons]\nthe main contribution of the paper is a careful combination of existing techniques and the associated empirical results, therefore the experiments need to be strong. I noticed some strange omissions in the  results, and asked the authors for a reply via a public comment but they did not reply. Specifically,\n\na) On RESNET 34 the results for PACT 5,5 are not shown and JOINT and PACT on 3,3 on ResNet-34 are also not shown. Why are these results omitted?\n\nb) The noise+gradual training decreases performance on (layer-weight bitwidth, activation bitwidth)  =  (3, 3). But further experiments for table 2 where the nets do not use noise+gradual training is not shown. Currently the proposed recipe for quantizing nets does not seem to be all that better than existing methods and it hard to guess exactly what was the reason for the improved results in situations where the results were infact better. Why were these experiments omitted ?\n\nOverall the experimental results in the paper are weak and the novelty of the proposed methods is low.']","[-20, -20, -50]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work (e.g., 'impressive experimental results'), they also point out several weaknesses and areas for improvement. The review highlights issues with novelty, missing details, and poor writing quality. However, it's not entirely negative as the reviewer recognizes the value of the experimental results and some interesting contributions.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and explain their concerns clearly without using harsh language. The reviewer uses phrases like 'could be improved' and 'I would suggest improvements' rather than more critical language. However, some statements are quite direct (e.g., 'The manuscript appears hastily put together and not ready for publication'), which prevents the score from being higher.\n\nOverall, the review balances criticism with recognition of the work's strengths, and maintains a generally polite and professional tone while providing detailed feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and some positive aspects of the paper, they express significant concerns about the originality of the methods and the strength of the empirical results. The reviewer concludes that the paper is 'slightly below acceptance threshold'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive feedback. They avoid harsh criticism and use phrases like 'could be interesting' and 'would be OK if', which maintain a polite tone even when expressing concerns."", 'The sentiment score is -50 because while the reviewer acknowledges the importance of the research area and some strengths of the paper, they express significant concerns about the novelty and experimental results. The review starts positively but becomes increasingly critical, especially regarding omissions in the results and the overall weakness of the experiments. The politeness score is 20 because the reviewer uses professional language and acknowledges some positive aspects, but their criticism is direct and they point out that the authors did not respond to their previous queries, which slightly reduces the politeness. The reviewer maintains a respectful tone throughout, even when expressing concerns, which keeps the score in the positive range.']"
"['PROs\n-seemingly reasonable approach to polyphonic music generation: figuring out a way to splitting the parts, share parameters appropriately, measuring entropy per time, all make sense\n-the resulting outputs tend to have very short-term harmonic coherence (e.g. often a ‘standard chord’ with some resolving suspensions, etc), with individual parts often making very small stepwise motion (i.e. reasonable local voice leading)\n-extensive comparison of architectural variations\n-positive results from listening experiments\n\nCONs\n-musical outputs are *not* clearly better than some of the polyphonic systems described; despite the often small melodic steps, the individual lines are quite random sounding; this is perhaps a direct result of the short history\n-I do not hear the rhythmic complexity that is described in the introduction\n-the work by Johnson (2015) (ref. provided below) should be looked at and listened to; it too uses coupled networks, albeit in a different way but with a related motivation, and has rhythmic and polyphonic complexity and sounds quite good (better, in my opinion) \n-some unclear sections (fixable, especially with an appendix; more detail below)\n-despite the extensive architectural comparisons, I was not always clear about rationale behind certain choices, eg. if using recurrent nets, why not try LSTM or GRU? (more questions below)\n-would like to have heard the listening tests; or at least read more about how samples were selected (again, perhaps in an appendix and additional sample files)\n\n quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).\n\nQuality -- In this work, various good/reasonable choices are made. The quality of the actual output is fine. It is comparable to-- and to my ears not better than-- existing polyphonic systems such as the ones below (links to sample audio are provided here):\n\n-Bachbot - https://soundcloud.com/bachbot (Liang et al 2017)\n- tied parallel nets - http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/ (Johnson 2015, ref below)\n-performanceRNN - https://magenta.tensorflow.org/performance-rnn - (Simon & Oore 2017)\n..others as well..\n\n\nClarity -- Some of the writing is ""locally"" clear, but one large, poorly-organized section makes the whole thing confusing (details below). It is very helpful that the authors subsequently added a comment with a link to some sample scores; without that, it had been utterly impossible to evaluate the quality. There are a few points that could be better clarified:\n\t-p5”a multi-hot vector of notes N”. It sounds like N will be used to denote note-numbers, but in fact it seems like N is the total number of notes, i.e. the length of the vector, right? What value of N is used?\n-p5 “a one-hot vector of durations D”. It sounds like D will be used to denote durations, but actually I think D is the length of the 1-hot vector encoding durations right? What value of D is used, and what durations do the elements of this vector represent?\n-similarly, does T represent the size of the history? This should really be clarified.\n\t-p5 Polyphonic models.\n\t\t-Eq (2), (3), (4): Presumably the h’s are the hidden activations layers?\n\t\t-the networks here correspond to the blue circles in Fig 1, right? If so, make the relationship clear and explicit \n\t\t-Note that most variables in most equations are left undefined       \n\t\t-actually defining the W’s in Eq(2-4)  would allow the authors to refer to the W’s later (e.g. in Section 5.2) when describing weight-sharing ideas. Otherwise, it’s all rather confusing. For example, the authors could write, “Thus, we can set W_p1 = W_p2 = W_p3 = W_p4” (or whatever is appropriate). \n\t-Generally, I found that pages 5-7 describe many ideas, and some of them are individually fairly clearly described, but it is not always clear when one idea is beginning, and one idea is ending, and which ideas can be combined or not. On my first readings, I thought that I was basically following it, until I got to Table 5, which then convinced me that I was in fact *not* quite following it. For example, I had been certain that all the networks described are recurrent (perhaps due to Fig1?), but then it turned out that many are in fact *not* recurrent, which made a lot more sense given the continual reference to the history and the length of the model’s Markov window etc. But the reader should not have had to deduce this. For example, one could write, \n\t“We will consider 3 types of architectures: convolutional, recurrent, .... In each architecture, we will have [...] modules, and we will try a variety of combinations of these modules. The modules/components are as follows:”. It’s a bit prosaic, but it can really help the reader. \n-Appendices, presented well, could be immensely helpful in clarifying the exact architectures; obviously not all 22 architectures from Table 5 need to be shown, but at least a few of them shown explicitly would help clarify. For example, in Fig1, the purple boxes seem to represent notes (according to the caption), but do they actually represent networks? If they really do represent notes, then how can “notes” receive inputs from both the part-networks and the global network? Also, I was not entirely clear on the relationship of the architecture of the individual nets (for the parts) to that of the global integrating network. E.g. for experiment #20, the part-net is an RNN (with how many layers?? with regular or LSTM cells?) followed by a log-linear predictor (with one hidden layer of 300 units right? or are there multiple layers sometimes?), but then what is the global network? Why does the longest part-history vector appear to have length 10 based on Table 5, but according to Table 3 the best-performing history length was 20? Though, I am not sure the meaning of the “bottom/top” column was explained anywhere, so maybe I am completely misunderstanding that aspect of the table? Etc.\n-Many piano scores do not easily deconstruct into clean 4-part polyphony; the example in Appendix A is an exception. It was not clear to me how piano scores were handled during training. \n-Terminology: it is not entirely clear to me why one section is entitled “homophonic models”, instead of just “monophonic models”. Homophonic music usually involves a melody line that is supported by other voices, i.e. a sort of asymmetry in the part-wise structure. Here, the outputs are quite the opposite of that: the voices are independent, they generally function well together harmonically, and there is usually no sense of one voice containing a melody. If there’s some reason to call it homophonic, that would be fine, but otherwise it doesn’t really serve to clarify anything. However, the authors do say that the homophonic composition tasks are a “minor generalization of classic monophonic composition tasks”, so this suggests to me that there is something here that I am not quite understanding.\n\nThe last sentence of Section 5.3 is very confusing-- I don’t understand what lin_n is, or 1_n is, or how to read the corresponding entries of the table. The first part of the paragraph is fairly clear. \n\nTable 4: “The first row” actually seems like it is referring to the second row. I know what the authors mean, but it is unnecessarily confusing to refer to it in this way. One might as well refer to “the zeroth row” as listing the duration of the clip :)\n\nThe experimental evaluation: I would like to hear some of the paired samples that were played for subjects. Were classical score excerpts chosen starting at random locations in the score, or at the beginning of the score? It is known that listening to a 10-second excerpt without context can sometimes not make sense. I would be curious to see the false positives versus the false negatives. Nevertheless, I certainly appreciate the authors’ warning to interpret the listening results with caution.\n\n\n\n\nOriginality & Significance -- So far, based both on the techniques and the output, I am not entirely convinced of the originality or significance of this particular system. The authors refer to “rhythmically simple polyphonic scores” such as Bachbot, but I cannot see what is rhythmically fundamentally more sophisticated about the scores being generated by the present system. One nice characteristic of the present system is the true and audible independence of the voices.\n\nOne of the contributions appears to be the construction of models that explicitly leverage with shared weights some of the patterns that occur in different “places” (pitch-wise and temporally) in music. This is both very reasonable, and also not an entirely novel idea; see for example the excellent work by Daniel Johnson, “Generating Polyphonic Music Using Tied Parallel Networks” (paper published 2017, first shared online, as far as I know, in 2015: links to all materials available at http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/  )\nAnother now common (and non exclusive) way to handle some of this is by augmenting the data with transposition. It seems that the authors are not doing this here. Why not? It usually helps. \n\nAnother contribution appears to be the use of a per-time measure of loss. This is reasonable, and I believe others have done this as well. I certainly appreciated the explicit justification for it, however.\n\nNote that the idea of using a vector to indicate metric subdivision was also used in (Johnson 2015).\n\nPlaying through some of the scores, it is clear that melodies themselves are often quite unusual (check user studies), but the voices do stay closely connected harmonically, which is what gives the system a certain aural coherence. I would be interested to hear (and look at) what is generated in two-part harmony, and even what is generated-- as a sort of baseline-- with just a single part. \n\nI encourage the authors to look at and listen to the work by Johnson:\n-listening samples: http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/\n-associated publication: http://www.hexahedria.com/files/2017generatingpolyphonic.pdf\n\nOverall, I think that the problem of generating rhythmically and polyphonically complex music is a good one, the approaches seem to generally be reasonable, although they do not appear to be particularly novel, and the musical results are not particularly impressive. The architectural choices are not always clearly presented.\n\t\t\t\n\t\t\n', ""\nComposing polyphonic music is a hard computational problem. \nThis paper views the problem as modelling a probability distribution \nover musical scores that is parametrized using convolutional and recurrent \nnetworks. Emphasis is given to careful evaluation, both quantitatively and qualitatively. The technical parts are quite poorly written.\n\nThe introduction is quite well written and it is easy to follow. It provides a good review that is nicely balanced between older and recent literature. \n\nUnfortunately, at the technical parts, the paper starts to suffer due to sloppy notation. The cross entropy definition is missing important details. What does S exactly denote? Are you referring to a binary piano roll or some abstract vector valued process? This leaves a lot of guess work to the reader. \nEven the footnote makes it evident that the authors may have a different mental picture -- I would argue that a piano roll does not need two bits. Take a binary matrix: Roll(note=n, time=t) = 1 (=0) when note n is present (absent) at time t. \n\nI also think the term factorization is sometimes used freely as a synonym for representation in last paragraphs of 4 and first two paragraphs of 5 -- I find this misleading without proper definitions.\n\nThe models, which are central to the message of the paper, are not described clearly. Please\ndefine function a(\\cdot) in (2), (3), (4), : this maybe possibly a typesetting issue (and a is highly likely a sigmoid) but what does x_p W_hp x x_pt etc stand for? Various contractions? You have only defined the tensor as x_tpn. Even there, the proposed encoding is difficult to follow -- using different names for different ranges of the same index (n and d) seems to be avoiding important details and calling for trouble. Why not just introduce an order 4 tensor and represent everything in the product space as every note must have a duration? \n\nWhile the paper includes some interesting ideas about representation of relative pitch, the poor technical writing makes it not suitable to ICLR and hard to judge/interpret the extensive simulation results.\n\nMinor:\n\nFor tensors, 'rank-3' is not correct use, please use order-3 here if you are referring to the number of dimensions of the multiway array. \n\nWhat is a non-linear sampling scheme? Please be more precise.\n\nThe Allan-Williams citation and year is broken:\nMoray Allan and Christopher K. I. Williams. Harmonising Chorales by Probabilistic Inference. Advances in Neural Information Processing Systems 17, 2005.\n"", 'The paper is well written and presented, giving a good literature review and clearly explaining the design decisions and trade-offs. The paper proposes a novel factorisation approach and uses recurrent networks. \n\nThe evaluation is both quantitative and qualitative. The qualitative experiment is interesting, but there is no information given about the level of musical training the participants had. You would expect very different results from music students compared to the general public. How did you control for musical ability/ understanding?\n\nThe paper has a refreshing honesty in its critical evaluation of the results, highlighting fundamental problems in this field.\n\nOverall, while I am not an expert in musical composition and machine learning, the paper is clear, and appears to be advancing the art in a reliable fashion.']","[-20, -50, 80]","[60, 20, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('PROs'), there are more extensive 'CONs' listed. The reviewer expresses skepticism about the originality and significance of the work, and points out several areas needing improvement or clarification. However, the tone is not entirely negative, as the reviewer sees potential in the approach and offers constructive feedback. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I encourage the authors to look at...', 'I would be interested to hear...', and 'I certainly appreciated...', which demonstrate courtesy. The reviewer also acknowledges positive aspects and provides detailed, constructive feedback rather than harsh criticism. However, the score is not extremely high as the review is still quite direct in pointing out flaws and shortcomings."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., 'The introduction is quite well written'), they express significant concerns about the technical parts being 'quite poorly written' and 'not suitable to ICLR'. The overall tone is critical, especially regarding the technical content. The politeness score is 20 because the reviewer uses relatively polite language ('Unfortunately', 'Please be more precise') and offers constructive feedback, but also includes some direct criticisms without softening language. The reviewer maintains a professional tone throughout, balancing positive and negative comments, which prevents the politeness score from being lower despite the critical content."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, praising its writing, presentation, and honesty. They note that it advances the field in a reliable fashion, though they do raise some questions about the methodology. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They offer praise where due and frame their critique as questions rather than direct criticisms. The reviewer also acknowledges their own limitations ('while I am not an expert'), which adds to the polite tone. The language used throughout is professional and courteous, without any harsh or rude expressions.""]"
"['Summary: This paper proposes an integration of active learning for multi-task learning with policy search. This integration is built on an existing framework, EPOpt, which each time samples a set of models and a set of trajectories for each model. Only trajectories with the bottom \\epsilon percentile returns will be used to update the multi-task policy. This paper proposes a way to improve the sample-efficiency so that fewer trajectories will be sampled and fewer trajectories will be loss. \n\nIn general, the paper presentation is easy to follow. The idea is well motivated of why an active learning integration is needed. The related work is a bit too narrow, e.g. work [1] on the same approach like EPOpt or meta-learning (for model adaptation) [2] (and others more on this topic)\n\n[1] T. Kurutach, I. Clavera, Y. Duan, A. Tamar, and P. Abbeel. Model-Ensemble Trust-Region Policy Opti\nmization. In ICLR, 2018.\n\n[2] C. Finn, P. Abbeel, and S. Levine. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In ICML, 2017.\n\nIn overall, I have major concerns regarding to the proposed framework.\n- Active learning is a method that is in general known to be an optimal trade-off between exploration vs. exploitation in finding a global optimal solution. That means, the proposed use of linear stochastic bandits is trying to find an optimal arm \\theta^* (the worst trajectory) that gives the highest reward (the lowest return). In my opinion, integrating this idea naively into EPOpt to sample a set of trajectories would only aim to find the worst trajectory among all trajectories from all models. This is clearly not enough to say ""finding ALL the WORSE regions among trajectory space"" to improve the policy. Therefore, a new way of integration or a new objective should be used in order to make a principled framework. \n\n- The statement over sample-efficiency gain vs. EPOpt in Section 4 is too loose which is not based on any detailed analysis or further theoretical results.\n\n- The experiment results are not well presented: there is no results for EPOpt in Fig. 1; \n\n\nMinor comments:\n\n- Algorithm 1: argument of GetTrajectory (in LEARN) should be \\theta_i, instead of \\pi_\\theta_i?.\n\n\nIn conclusion, the proposed framework is not yet principled. Experiment results are too preliminary and not well presented. ', 'This paper targets at a particular type of robust policy search, where a simulation environment exists with explicit tuning parameters, which is referred to as the model parameters of a Markov decision process. The task of robust policy search is to learn a policy robust to all the parameters of the simulator, so that it can potentially give robust performance in real environment. The previous work handles this problem by sampling many trajectories and only learning from the trajectories, in which the current policy produces the worst performance. This approach effectively focus the policy search on the worst case performance, but is highly inefficient as most of the sampled trajectories are discarded. This paper proposes to improve the sampling efficiency by building a surrogate model predicting the return of the current policy given a MDP parameter. The surrogate model is used to select the MDP parameters leading to the worsts performance, so that the policy search can directly sample and learn from the selected MDP parameters without discarding any trajectories.\n\nThis paper tries to tackle the sampling efficiency of RL with building a probabilistic surrogate model. This is a promising direction. The biggest concern is that this paper tackles this problem with a combination with existing techniques, leaving many questions unanswered. Presenting the paper in a more theoretical-grounded perspective would make the paper much stronger.\n\nThis paper uses a linear stochastic bandits (LSB) method to build a surrogate model of the return of the current policy and fits the surrogate model into the EPOpt framework by sampling from the worst performing parameters according to the surrogate model. As the Thompson sampling algorithm of LSB draw samples from the distribution of MDP parameters that leads to the wost performance, why not directly use it for policy search?\n\nThe surrogate model is expected not to give accurate prediction everywhere due to the limited number of data but produces uncertainty of its prediction as an dictator. However, the uncertainty of prediction is not used by the proposed algorithm.\n\nThe presentation of the experiment section needs to be improved. The performance of the baseline needs to be explicitly presented, otherwise it is hard to compare. The proposed method will not outperform if the number of trajectories used for updating policy is the same, as the surrogate model can never be as good as the real model. It would be nice to explicitly demonstrate the runtime and performance trade-off.\n\nMinor issues:\n1. What does TRPO stand for?\n2. When referring to the paper instead of the authors, the citation format needs to be (authors year) instead of authors (year).\n', 'This paper introduced an active learning mechanism on top of robust policy search in RL for better sampling efficiency. The authors proposed EffAcTS active learning framework and combined it with policy search method EPOpt. Theoretical analysis of active learning efficiency was not investigated. Simulation experiments were done on Hopper and Half Cheetah, 5 runs for each parameter setting.\n\nThe paper is well written and easy to follow. The authors quickly went through several key topics (active learning, linear bandits, multi-task, etc.) without too many details. However, there is a huge lack of key references in these topics. It would be better to notice that they were not introduced together with DRL.\n\nOverall, it is a nice paper with incremental contributions on every dimension the authors claimed (e.g. comparing to Sharma et al., 2018).\n']","[-60, -20, 60]","[20, 50, 70]","[""The sentiment score is -60 because the review expresses 'major concerns' about the proposed framework and concludes that it is 'not yet principled' with 'too preliminary' results. The reviewer points out several significant issues with the paper's approach and experimental results. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the paper being 'easy to follow' and the idea being 'well motivated'. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'In my opinion' and 'In conclusion' which soften the criticism. The reviewer also provides constructive feedback and specific suggestions for improvement, which is a polite approach to criticism in academic contexts."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's promising direction, they express significant concerns about unanswered questions and the need for a more theoretical-grounded perspective. The reviewer also points out several areas for improvement, which contributes to the overall negative sentiment. However, the score is not deeply negative as the reviewer does see potential in the approach. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'It would be nice to...' and 'The presentation... needs to be improved' rather than more aggressive language. The reviewer also balances criticism with positive acknowledgments of the paper's potential, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'well written and easy to follow' and 'a nice paper with incremental contributions'. They acknowledge the paper's merits while also pointing out some areas for improvement, indicating a generally positive but not overwhelmingly enthusiastic sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They balance positive comments with suggestions for improvement, maintaining a professional and courteous tone. The phrase 'It would be better' is used to suggest improvements politely rather than demanding changes.""]"
"['The paper addresses the incremental few-shot learning problem where a model starts with base network and then introduces the novel classes, building a connection between novel and base classes via an attention module.\n\nStrengths:\n+ clear writing. \n+ the experiments are compared with related work and the ablation studies can verify the effectiveness of the proposed (or ""introduced"" would be a precise term) recurrent BP.\n\nWeakness:\n\n- [Novelty]\nThe paper title is called attention attractor network, which shares very relevance to previous CVPR work (Gidaris & Komodakis, 2018). So the first thing I was looking for is the clear description of the difference between these two. Unfortunately, in related work, authors mention the CVPR work without stating the difference (last few lines in Section 2). As such, I don\'t see much novelty in the paper compared with previous work. Eqn. (7)-(10) explicitly describes the attention formula. What\'s the distinction from the CVPR work?\n\n- [Motivation of the regularizer using Recurrent BP is not clear]\nThe use of recurrent BP is probably the most distinction from previous work. However, I don\'t see a clear description on why such a technique is necessary.\n\nStarting from the first line in Section 3.3, ""since there is no closed-form of the regularizer in Eqn (13)"", E needs BPTT or the introduced recurrent BP. This part is simply a re-adaption of other algorithms. A very simple question is, how about use other regularizers to replace Eqn (13)? \n\n- [Some experiments missing]\nThe experiments section 4.6 uses a case of None and ""best WD"" to address some of my concerns. This is good. Does the ""gamma random"" indicates only E is used without the ||W||^2? why the best WD for one-shot is zero? This implies the model is best for applying no weight decay?\n\nWhat\'s the effect of using the recurrent BP technique to the CVPR work? Is there some similar improvement? If yes, then the paper makes some contribution by the regularization. If not, what\'s the reason?\n\nHow about using the truncated BPTT with a larger T?\n\nIn general, I think the recurrent BP part should be the highlight of the paper and yet authors fail to spread such a spirit in the abstract or title. And there are some experiments missed as I mentioned above.\n', 'This paper proposes a novel few-shot learning method that achieves better overall accuracies on base and novel classes. The key idea is to regularize the learning of novel classes such that base classes are not forgotten. \n\nI mainly have the following two concerns. \n\n-In Table 2, I observe that performance on novel classess is actually not improved. The main improvement lies in overall accuracy. As numbers of training samples between base and novel classes are not balanced, there must be some trade-off between  obtaining better performance on base or novel classes. For instance, stopping early when training on novel classes would result in high base accuracy but low novel accuracy. Fine-tuning on novel classes for more iterations would lead to high novel accuracy but  low base accuracy. Such trade-off can be also controlled by simply over-sampling novel or base classes.  I would suggest the authors to study more on understanding this trade-off. In addition, another naive baseline is to train a softmax classifier at the second stage on both base and novel class training samples and sample mini-batch by uniformly sampling over novel and base classes.  \n\n-The following two papers extensively studied the problem of achieving better overall accuracies on base and novel classes. Including comparison and discussion with those two papers will enhance this paper further. \nLow-Shot Learning from Imaginary Data\nlow-shot visual recognition by shrinking and hallucinating features', 'This work addresses incremental few-shot learning that learns novel classes without forgetting old classes, which is interesting and different from conventional few-shot learning that considers only the few-shot learning task of interest. This problem is also related closely to the important problem of life-long learning. \n\nThis work presents an interesting framework based on meta-learning by learning to learn how to attend to the old classes using an attention mechanism. Experimental results also show improvement over two related works on incremental few-shot learning. The writing is quite clear. Some concerns, especially its novelty, are listed below.  \n\n1. The novelty appears to be limited. The presented framework looks quite similar to the recent work \n\nSpyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. CVPR\'18\n\nthat addresses the same problem in a similar manner: 1) learn a base feature extractor and classifier; and then 2) attend to old classes also via meta-learning and attention mechanism.  \nAs mentioned by the authors, ""The main difference to this work is that we use an iterative optimization to compute W_b"". More discussions on the iterative optimization and why it matters may be helpful.\n\nAnother related work is ""Deep Meta-Learning: Learning to Learn in the Concept Space"", Arxiv\'18, that also relies on an external base classes for few-shot learning. Similar to the proposed research, it also learns a feature extractor and a classifier from the base classes, which are used to regularize the learning of novel classes, in an end-to-end meta-learning manner. Extending it for the incremental setting seems natural. \n\n2. To learn a few novel classes, all U_k on old classes are relearned, which seems quite time-consuming with a large vocabulary of base classes.\n\n3. To learn a few novel classes, old data on base classes are still required, which seems different from how humans learn -- humans learn novel concepts solely from a few examples without forgetting old concepts, without requiring examples on old concepts.  ']","[-30, -20, 20]","[50, 60, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths (clear writing, comprehensive experiments), they express significant concerns about the paper's novelty, motivation, and missing experiments. The overall tone leans negative, but not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions (e.g., 'How about...', 'What's the effect of...') rather than direct attacks. They also acknowledge positive aspects before presenting criticisms. However, the language isn't overly formal or deferential, maintaining a professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novel approach and improved overall accuracies, they express two main concerns about the paper. These concerns suggest that the work needs significant improvements or clarifications. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering suggestions and recommendations rather than harsh criticisms. They use phrases like 'I would suggest' and 'Including comparison and discussion... will enhance this paper further', which maintain a constructive tone. The reviewer also acknowledges the paper's contributions before presenting their concerns, which is a polite approach to peer review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work as 'interesting' and notes that it shows improvement over related works. However, they also express several concerns, particularly about novelty, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the merits of the work before presenting concerns. They use phrases like 'interesting framework' and 'writing is quite clear' before listing their concerns. The concerns are presented as suggestions for improvement rather than harsh criticisms. The reviewer also provides specific references and explanations for their concerns, which is a constructive approach.""]"
"['To the best of my understanding the paper proposes some methodological ideas for visualizing and analyzing representations. \nThe paper is unclear mainly because it is a bit difficult to pinpoint the contribution and its audience. What would help me better understand and potentially raise my rating is an analysis of a classical model on a known dataset as a case study and some interesting findings would help make it more exciting and give the readers more incentives to try this out. Like train an AlexNet and VGG imagenet model and show that the embeddings are better aligned with the wordnet taxonomy in one of the other. This should be possible with their approach if i understand it correctly. \n\npros:\n- visualization and analysis is a very exciting and important topic in machine learning\n- this is clearly useful if it worked\ncons:\n- not sure what the contribution claim for the paper is since these types of plots existed already in the literature (is it a popularization claim ?)', ""The idea of analyzing embedding spaces in a non-parametric (example-based) way is well-motivated. However, the main technical contribution of this paper is otherwise not clear - the methodology section covers a very broad set of techniques but doesn't provide a clear picture of what is novel; furthermore, it makes a strong assumption about linear structure in the embedding space that may not hold. (It's worth noting that t-SNE does not make this assumption.)\n\nThe visualization strategies presented don't appear to be particularly novel. In particular, projection onto a linear subspace defined by particular attributes was done in the original word2vec and GloVe papers for the analogy task. There's also a lot of other literature on interpreting deeper models using locally-linear predictors, see for example LIME (Ribeiro et al. 2016) or TCAV (Kim at el. 2018).\n\nEvaluations are exclusively qualitative, which is disappointing because there are quantitative ways of evaluating a projection - for example, how well do the reduced dimensions predict a particular attribute relative to the entire vector. Five-axis polar plots can pack in more information than a 2-dimensional plot in some ways, but quickly become cluttered. The authors might consider using heatmaps or bar plots, as are commonly used elsewhere in the literature (e.g. for visualizing activation maps or attention vectors).\n\nUser study is hard to evaluate. What were the specific formulae used in the comparison? Did subjects just see a list of nearest-neighbors, or did they see the 2D projection? If the latter, I'd imagine it would be easy to tell which was the t-SNE plot, since most researchers are familiar with how these look."", 'Paper presented a new and simple method to visualize the embedding space geometry rather than standard t-SNE or PCA. The key is to carefully select items to be visualized/embed and interpretable dimensions. A few case study and user study were conducted to show the benefit of the proposed approach. \n\n- on algebraic formulae (AF): it would be good to clarify the def of AF explicitly. Rules/extention/axes are not very clear and mathematically consistent in section 3. Would projection idea be applied to arbitrary AFs?\n\n- while the idea being simple, I am not quite confident about the novelty. For example for the de-bias application, Bolukbasi et al. had already did the same plot along the he-she axis. Similar plots on the polysemous word embedding can be found in Arora et al., 2017, etc. \n\n- The user study with n=10 are typically less reliable for any p-value evaluation. \n\n']","[-20, -50, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and potential usefulness of the approach, they express significant concerns about the clarity of the paper's contribution and its audience. They suggest major improvements, indicating dissatisfaction with the current state of the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'To the best of my understanding' and 'What would help me better understand', which are polite ways of expressing concerns. The reviewer also balances their critique by mentioning both pros and cons of the paper."", ""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses in the paper's methodology, novelty, and evaluation. However, it does acknowledge some positive aspects, such as the well-motivated idea of analyzing embedding spaces. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive suggestions. They avoid harsh or personal attacks, instead focusing on the content of the paper. The reviewer also uses phrases like 'it's worth noting' and 'the authors might consider,' which add a degree of politeness to the critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's new method and its benefits, they express concerns about novelty, mathematical consistency, and the reliability of the user study. These criticisms outweigh the initial positive remarks. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive feedback without harsh criticism. They use phrases like 'it would be good to clarify' and 'I am not quite confident about' which maintain a polite tone while expressing concerns. The reviewer also balances critique with recognition of the paper's strengths, contributing to the overall politeness of the review.""]"
"[""General:\nIn general, this is a well-written paper and I feel pleasant to read the paper. The paper proposed a model named Pseudo Invertible Autoencoder(PIE) which combines invertible architecture and inference model.\n\nStrength:\n1. The explanation of the paper is very clear and consistent.\n2. The idea is interesting. A lot of papers related to the inverse problem focus on perfect invertibility, but the author(s) emphasize the importance of invertible compression and relate PIE to the inference model.\n\nPossible Improvements:\n1. The experiments could have been more convincing: 1) The only competitors are VAE and WAE. 2)The only data set has been tested was MNIST data set. There are many great works mentioned in the paper and those works should also be compared in a way.\n2. The content could be more compact so that more experiments can be shown to support the paper. It seems to me there is too much explanation to previous works in the paper. \n3. The paper has 9 pages which exceed the suggestion a little bit.\n4. I am not sure if the author(s) checked the grammar of the paper carefully. I found quite few typos in the paper. Page 3: 'Rather then' should be 'Rather than' and 'As we are interested' should be as 'As we are interested in'; Page 4: 'Can me' should be 'Can be'; Page 6: 'Better then' should be 'Better than'; Fig.6 (b): Should it be '0' or 'g(z)'?\n\nConclusion:\nThis is a good and clean paper in general. It explains the related work and presents PIE with necessary details. My biggest concern is that empirical validation(experiment) is poor. As a conclusion, I tend to vote for weak rejection.\n\nMinor Suggestion:\nRefer to the conference instead of arXiv if the paper was already published."", 'In this paper, an invertible encoding method is proposed for learning latent representations and deep generators via inverting the encoder. The proposed method can be seen as an autoencoder without the need to learn the decoder. This can be computed by inverting the encoder. To the best of my knowledge the proposed method is novel and its building blocks are described adequately. \n\nMy main questions are the following: What is the main advantage of this model? Does it make the problem of deep generative model learning tractable? If so, under what conditions?\n\nDiscussion of prior art and relevant methods is limited in the paper and it can be extended. The authors may want to consider discussing relevant work on invertible autoencoders (e.g., https://arxiv.org/pdf/1802.06869.pdf) and methods like https://openreview.net/pdf?id=ryj38zWRb which can be seen as symmetric to the proposed one in the sense that an encoderless autoencoder is learnt. \n\nThe experimental evaluation is limited. The authors should consider to compare their method with other relevant models such as those mentioned above as well as GANs and their variants. Experiments on other more complex real-world data (e.g., faces) are also needed in order to prove the merits of the proposed model.\n', 'PIE extend NICE and Real NVP into situations which require having a smaller dimensionality of the latent variable (d) compared to the dimensionality of the observed variable (D), i.e. d < D. This is done by learning an extension function g(z) from R^d to R^{D-d} and then using the change of variables formula on x and [z, g(z)]. To model probabilistically the deterministic function g(z) is replaced by Normal distribution with mean g(z) and a small variance.\n\nPIE is used to build deep generative models and trained on the MNIST dataset. The authors show that the models learnt via PIE produce sharper samples than VAEs and Wasserstein autoencoders (WAEs). No comparison to real NVP is made, which should be the main baseline of comparison to answer the question of ""what is the advantage of having d < D?"". Further MNIST is no longer a good enough benchmark to evaluate deep generative models. Most representative work in this literature use CIFAR-10, downsampled Imagenet, or Imagenet at 256x256.\n\nThis work falls short of the standards of ICLR in a few ways:\n\n1. The presentation is unclear. The explanation of the extension-restriction idea is overly complicated. Further, the paper does very little to properly contextualize this work in the literature. Real NVP and flow-based models are mentioned but the proposed technique is not compared to it. The authors say they ""introduce new class of likelihood-based Auto-Encoders"", but this is false as far as I understood. The technique is not even an autoencoder since a separate decoder is not trained, and is obtained by exactly inverting the encoder as in real NVP.\n\n2. The experiments are weak. The samples shown are of poor quality, and on a very simplisitic dataset (MNIST). The authors compare with vanilla VAEs, but ignore more recent improvements to VAE such as VAE-IAF, flow-based models, and also autoregressive models. A heuristic is used to measure sharpness and only used to compare against VAE and WAE. Since all these models allow likelihood evaluation, likelihoods should also have been compared.\n\n3. The technique itself is a small change over real NVP and it\'s not clear whether this change brings any improvements or provides any insights about generative modeling.']","[-20, 20, -70]","[60, 60, -20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'well-written' and 'interesting', they conclude with a 'weak rejection' recommendation. They list several 'possible improvements' and express concerns about the empirical validation. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging strengths and providing constructive feedback. They use phrases like 'I feel pleasant to read the paper' and 'This is a good and clean paper in general', which contribute to a polite tone. However, the directness of some criticisms prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the proposed method and its adequate description. However, they also raise questions and point out limitations, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language, offers constructive feedback, and phrases criticisms as suggestions ('The authors may want to consider...'). The reviewer maintains a professional tone throughout, avoiding harsh language while still clearly communicating areas for improvement."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the work 'falls short of the standards of ICLR' and lists several major criticisms, including unclear presentation, weak experiments, and lack of significant improvement over existing techniques. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'This work falls short', 'The presentation is unclear', and 'The experiments are weak' are direct and somewhat harsh. The reviewer also states that some of the authors' claims are 'false', which is a strong accusation in academic writing. However, the reviewer does provide specific feedback and suggestions, which prevents the score from being even lower.""]"
"['This paper proposes a Bayesian extension to knowledge base embedding methods, which can be used for hyperparameter learning. My rating is based on following aspects.\n\nNovelty. \nApplying Bayesian treatment to embedding methods for uncertainty modelling and hyperparameter tuning is not new (examples include PMF [1] and Bayesian PMF [2]), and Sec 3 can be regarded as a knowledge base extension of them with a different likelihood (MF considers user-item pairs while knowledge base considers head-edge-tile triplets). However, it seems that there is little work considering the hyperparameter tuning problems for knowledge base embeddings.\n\nQuality & Clarity.\nThis paper makes two arguments. 1. Small data problems exist, and needs parameter uncertainty; 2. Bayesian treatment allows efficient optimization over hyperparameters. However, as mentioned in Sec 4 and Sec 5, they still use MAP estimations with tuned hyperparameters instead of variational distribution directly. This does not support the parameter uncertainty argument (since there is no uncertainty in parameters of the final model, i.e., those re-trained in line 10 of algorithm 1). More analysis, both theoretically and experimentally, is needed to address this argument. The hyperparameter tuning argument is well-supported by both theoretical analysis and experiments. \n\nMy questions are mainly about experiments. Overally, I think current experiments cannot support the claims well and further experiments are needed.\n1.\tAs mentioned above, the parameter uncertainty issue hasn’t been well verified (Figure 3 demonstrates the advantages of hyperparameter tunning instead of uncertainty in parameters).\n2.\tTable 1 & 2 demonstrates that hyperparameter tunning using algorithm 1 introduces performance improvement on ComplEx and DistMult. Since the Bayesian treatment is general, such an improvement should be found for other knowledge base embedding methods. \n3.\tTime complexity is not analyzed (since Algorithm 1 requires re-train the models).\n4.\tAlgorithm 1 is a one-EM-step approximation for optimizing the ELBO. How well such a algorithm approximates the optimal solution of ELBO. For example, what will happens if running line 4-10 for multiple times? Does the performance increase or decrease?\n\n[1] Salakhutdinov and Minh, Probabilistic Matrix Factorization, NIPS 2007.\n[2] Salakhutdinov and Minh, Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo, ICML 2008.\n', 'In this paper, authors propose a probabilistic extension of classic Neural Link Prediction models, such as DistMult and ComplEx. The underlying assumption is that the entity embeddings and the relation embeddings are sampled from a prior Multivariate Normal distribution, whose (hyper-)parameters can be estimated via maximum likelihood. In this paper, authors use Variational Inference (VI) for approximating the posterior distribution over the embeddings, and use Stochastic VI for maximising the Evidence Lower BOund (ELBO) while scaling to large datasets. In Sect. 3, authors introduce the generative process, and show how MAP estimation of the embedding matrices can recover the original models. In Sect. 4, authors start from the intractable marginal likelihood over the data (Eq. 5) for deriving the corresponding ELBO (Eq. 6), which is defined over:\n- The ""hyperparameters"" gamma, which define the parameters of the prior Multivariate Normal distribution over the embeddings, and\n- The parameters gamma of the variational distributions.\n\nQuestion: why the ELBO (Eq. 6) is not used anywhere in Algorithm 1?\n\nThe model does not mention a number of significantly more accurate models proposed in the literature, such as [1].\n\nFurthermore, it seems to me that the point of the whole paper is finding efficient ways of estimating the hyperparameters efficiently. In that sense, there are other methods that were not considered, either simple (e.g. random sampling or black-box optimization techniques [2]) or more complex (e.g. hypergradient descent [3]).\n\n[1] https://arxiv.org/abs/1707.01476\n[2] https://github.com/hyperopt/hyperopt\n[3] https://arxiv.org/abs/1703.04782', 'Summary:\nThe paper presents a probabilistic treatment of knowledge graph embeddings, motivating it in parameter uncertainty estimation and easier hyperparameter optimisation. The authors present density-based DistMult and ComplEx variants, where the posterior parameter distributions for entity and relation embeddings are approximated by diagonal Gaussians q_\\gamma. Variational EM is used to infer the variational parameters \\gamma as well as the per-entity/per-relation precision (\\lambda) hyperparameters. The training process proposed by the authors consists of three phases: (1) pretraining a MAP estimate that’s used as initial means of the posterior approximating Gaussians, (2) variational EM (see above) to find better hyperparameters and (3) another MAP training phase that uses the updated per-entity/per-relation hyperparameters. Finally, experimental results indicate a slight improvement in MRR and HITS@10 across FB and WN datasets.\n\nOriginality:\nTo the best of the reviewer’s knowledge, the presented approach is novel for knowledge graph embeddings.\n\nDiscussion:\nWhile the task is relevant, it is unclear how significant the improvements are. While overall, the proposed method seems to indicate small improvement upon a very strong baseline, in some cases it’s very close (96.2 vs 96.4 HITS@10 on WN18, 36.4 vs 36\n.5 MRR on FB15K237), or worse (85.8 vs 85.4 MRR on FB15K). \nIt is unclear how adequate some details in the experimental setup are for verifying the main hyperparameter optimization claim. In particular, what is “a reasonable choice of hyperparameters” in the first training phase? From figure 3b it seems the initial lambda’s are set proportionately to the frequency, as in the baseline. Are the initial hyperparameter values in EM set the same as the hyperparameter values used for MAP in the reported results? If the claim is to optimize hyperparameters, shouldn’t their initial values be set as uninformed as possible? How do different initial hyperparameter values affect final performance?\nThe authors claim that the improvement is most notable for entities with fewer training points, however, this is only investigated by using a balanced MRR, where the results are again very close, the same (WN18) or worse (FB15K) for ComplEx. Wouldn’t it be clearer to perform a separate evaluation only considering low-frequency entities to verify this claim?\nParameter uncertainty is not further handled in the paper, the final approach is a point estimate, which discards the uncertainties obtained by VI. Authors mention (last paragraph of Sec. 4) that for a large embedding dimension, bayesian predictions are worse, while for small dimension, they are better. The author’s hypothesis is that a more flexible posterior approximation could solve this issue. No concrete numbers or further analysis are provided.\n\n\nClarity and presentation:\nThe result tables should be merged and formatted better. \nFigures need some work (Fig. 2 looks poorly scaled, all figures should be in vector format for scalability, typos in Fig. 1)\n\nQuestions:\n- How much additional computation is needed to achieve the reported results?\n- Would it be possible to group the entities in bins by frequencies (say 6-10 bins) and assign each bin a hyperparameter, and run grid search over just 6-10 hyperparameters, and then interpolate between the bins to set hyperparameters per entity as a function of its frequency?\n']","[-20, -20, -20]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some novelty in the paper's approach to hyperparameter tuning for knowledge base embeddings, they express several concerns about the paper's arguments and experimental support. The reviewer points out that the paper's claims about parameter uncertainty are not well-supported by the current experiments and methodology. They also suggest that more analysis and experiments are needed to fully support the paper's arguments. However, the score is not deeply negative as the reviewer does find value in the hyperparameter tuning aspect of the work. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They phrase their criticisms as 'questions' and 'needs', rather than direct criticisms. The reviewer also acknowledges the paper's strengths alongside its weaknesses, demonstrating a balanced approach. The language used is formal and respectful, without any harsh or rude phrasing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' work and provides a detailed summary, they also point out significant omissions and raise questions about the methodology. The reviewer mentions that the paper doesn't discuss more accurate models and suggests alternative methods that weren't considered, indicating some dissatisfaction with the comprehensiveness of the work. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language to express their concerns and suggestions. They avoid harsh criticism and frame their points as observations or questions rather than direct criticisms. The reviewer also provides specific references to support their points, which is a courteous way to offer constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the approach, they express several concerns about the significance of the improvements and the adequacy of the experimental setup. The reviewer points out that in some cases, the results are very close to the baseline or even worse. They also question the methodology for verifying the main claims of the paper.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'it is unclear' and 'wouldn't it be clearer,' rather than making accusatory statements. The reviewer also acknowledges the novelty of the approach and the relevance of the task. The questions at the end are posed in a constructive manner, suggesting potential improvements or alternative approaches.\n\nOverall, while the review is critical in many aspects, it is presented in a polite and constructive manner, balancing negative observations with positive acknowledgments and suggestions for improvement.""]"
"['The paper tackles the problem of semi-supervised classification using GAN-based models. They proposed a manifold regularization by approximating the Laplacian norm using the stochastic finite difference. The motivation is that making the classifier invariant to perturbations along the manifold is more reasonable than random perturbations. The idea is to use GAN to learn the manifold. The difficulty is that (the gradient of) Laplacian norm is impractical to compute for DNNs. They stated that another approximation of the manifold gradient, i.e. adding Gaussian noise \\delta to z directly (||f(z) - f(g(z+\\delta))||_F) has some drawbacks when the magnitude of noise is too large or too small. The authors proposed another improved gradient approximation by first computing the normalized manifold gradient \\bar r(z) and then adding a tunable magnitude of \\bar r(z) to g(z), i.e., ||f(z) - f(g(z) +\\epsilon \\bar r(z) )||_F. Since several previous works Kumar et al. (2017) and Qi et al. (2018) also applied the idea of manifold regularization into GAN, the authors pointed out several advantages of their new regularization.\n\nPros:\n- The paper is clearly written and easy to follow. It gives some intuitive explanations of why their method works.\n- The idea is simple and easy to implement based on a standard GAN.\n- The authors conduct various experiments to show the interaction of the regularization and the generator.\n\nCons:\n- For semi-supervised classification, the paper did not report the best results in other baselines. E.g., in Table 1 and 2,  the best result of VAT (Miyato et al., 2017) is VAT+Ent, 13.15 for CIFAR-10 (4000 labels) and 4.28 for SVHN (1000 labels). The performance of the proposed method is worse than the previous work but they claimed ""state-of-the-art"" results. The paper also misses several powerful baselines of semi-supervised learning, e.g. [1,2]. The experimental results are not very convincing because many importance baselines are neglected.\n- The paper does not have a significant novel contribution, but rather extends GANs (improved-GAN mostly) with a manifold regularization, which has been explored in many other works Kumar et al. (2017) and Qi et al. (2018). \n\nI\'m wondering whether other smoothness regularizations can achieve the same effect when applied to semi-supervised learning, e.g. spectral normalization[3]. It would be better to compare with them.\n\nReferences:\n[1] Adversarial Dropout for Supervised and Semi-Supervised Learning, AAAI 2018\n[2] Smooth Neighbors on Teacher Graphs for Semi-supervised Learning, CVPR 2018\n[3] Spectral Normalization for Generative Adversarial Networks, ICLR 2018', 'This paper builds upon the assumption that GANs successfully approximate the data manifold, and uses this assumption to regularize semi-supervised learning process.\nThe proposed regularization strategy enforces that a discriminator or a given classifier should be invariant to small perturbations on the data manifold z. It is empirically shown that naively enforcing such a constraint by randomly adding noise to z could lead to under-smoothing or over-smoothing in some cases which can harm the final classification performance. Consequently, the proposed regularization technique takes a step of tunable size in the direction of the manifold gradient, which has the effect of smoothing along the direction of the gradient while ignoring its norm.\n \nExtensive experiments have been conducted, showing that the proposed approach\noutperforms or is comparable with recent state-of-the-art approaches on cifar 10, especially in presence of fewer labelled data points. On SVHN however, the proposed approach fails in comparison with (Kumar et al 2017) but performs better than other approaches.\n\nFurthermore, it has been shown that adding the proposed manifold regularization technique to the training of GAN greatly improves the image quality of generated images (in terms of FID scores and inception scores). Also, by combining the proposed regularizer with a classical supervised classifier (via pre-training a GAN and using it for regularization) decreases classification error by 2 to 3%.\n \nFinally, it has also been shown that after training a GAN using the manifold regularization, the algorithm is able to produce similar images giving a low enough perturbation of the data manifold z.\n \nOverall, this paper is well written and show significant improvements especially for image generation. However, the novelty is rather limited as similar ideas have been undertaken (e.g., Mescheder et al 2018), but in different contexts. The paper would be improved if the following points are taken into account:\n \nA comparison with Graph Convolutional Network based techniques seems appropriate (e.g. Kipf and Welling 2017).\nHow do the FID/Inception improvements compare to (Mescheder et al 2018)?\nIt would be interesting to discuss why the FID score for SVHN gets worse in presence of 1000 labels.\nAlthough there is a clear improvement in FID scores for Cifar10. It would be informative to show the generated images w/ and w/o manifold regularization.\nMore analysis should be provided on why (Kumar et al 2017) perform so well on SVHN.\nIt should be stated that bold values in tables do not represent best results (as it is usually the case) but rather results for the proposed approach.\n', 'Review for MANIFOLD REGULARIZATION WITH GANS FOR SEMISUPERVISED LEARNING\nSummary:\nThe paper proposed to incorporate a manifold regularization penalty to the GAN to adapt to semi-supervised learning. They approximate this penalty empirically by calculating stochastic finite differences of the generator’s latent variables. \nThe paper does a good job of motivating the additional regularization penalty and their approximation to it with a series of experiments and intuitive explanations. The experiment results are very through and overall promising. The paper is presented in a clear manner with only minor issues. \nNovelty/Significance:\nThe authors’ add a manifold regularization penalty to GAN discriminator’s loss function. While this is a simple and seemingly obvious approach, it had to be done by someone. Thus while I don’t think their algorithm is super novel, it is significant and thus novel enough. Additionally, the authors’ use of gradients of the generator as an approximation for the manifold penalty is a clever.\nQuestions/Clarity:\nIt would be helpful to note in the description of Table 3 what is better (higher/lower). Also Table 3 seems to have standard deviations missing in Supervised DCGANs and Improved GAN for 4000 labels. And is there an explanation on why there isn’t an improvement in the FID score of SVHN for 1000 labels?\nWhat is the first line of Table 4? Is it supposed to be combined with the second? If not, then it is missing results. And is the Pi model missing results or can it not be run on too few labels? If it can’t be run, it would be helpful to state this.\nOn page 11, “in Figure A2” the first word needs to be capitalized. \nIn Figure A1, why is there a dark point at one point in the inner circle? What makes the gradient super high there?\nWhat are the differences of the 6 pictures in Figure A7? Iterations?\n']","[-20, 60, 70]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also highlight significant shortcomings ('Cons') that outweigh the positives. The reviewer points out that the paper's results are not as good as claimed and that it lacks novelty. However, the score is not deeply negative because the reviewer does recognize some merits in the work. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout, balancing critique with acknowledgment of the paper's strengths. They use phrases like 'The paper is clearly written' and 'The idea is simple and easy to implement', which show appreciation. Even when criticizing, the reviewer maintains a constructive tone, suggesting improvements and additional comparisons rather than dismissing the work outright."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges significant improvements in image generation and overall good writing, while also noting limited novelty and some areas for improvement. The politeness score is 80 (quite polite) due to the use of respectful language throughout, constructive criticism, and positive acknowledgments of the paper's strengths. The reviewer uses phrases like 'well written,' 'show significant improvements,' and provides specific suggestions for improvement without harsh criticism. The tone is professional and courteous throughout, maintaining a balance between praise and constructive feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its motivation, clarity, and thorough experiments. They describe the results as 'promising' and the approach as 'clever', indicating a favorable opinion. However, it's not a perfect score as they mention some minor issues and question the novelty of the approach to some extent. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and frame their criticisms as questions or suggestions for improvement rather than harsh critiques. The use of phrases like 'it would be helpful' and 'can you explain' demonstrates a polite and collaborative tone. The reviewer also balances critique with praise, which contributes to the overall politeness of the review.""]"
"[""The authors present a study on multi-agent communication.\nSpecifically, they adapt communication to be targeted and multi-staged.\nExperiments on  2 synthetic datasets and 1 3D visual dataset confirm that both additions are beneficial\n\nOverall, this paper was somewhat clear and more importantly includes experiments on House3D, a more realistic dataset.\n\nMy main concern is the following: the method is not about targeting, but about selectively hearing.\nIf agents are sharing the reward then why should targeted communication be beneficial at all? Isn't the optimal strategy to just communicate everything to everyone? I understand that they should be selective at the listening side to properly integrate only the relevant information (so, attend over all received messages), but why should we expect the speaker to apriori know who this message should go to? Moreover, I don't really understand how targeted communication can even work (in the way the authors explain it) since the agents have partial information (e.g., in shapes they only see 5x5 around them), so they don't really know who is where --  but I could potentially see this working should the agents put information about their own identity and location.  So, given the positive results that the authors get, my understanding is that the signature doesn't have information about who should the recipient of the information be but more about what where the properties of the sender of this information.  So, based on my understanding, I don't feel that the flow of the story quite matches what is really happening and this might be very confusing for prospective readers. Can the authors elaborate on this, aim i getting things wrong?\n\nThere is literally no information about model size (or at least I wasn't able to find any). Is there any weight-sharing across agents? Do you obtain CommNets by using the implementations of the authors or by ablating the signature-part of your model? Moreover, why do agents have a limited view window on the SHAPES -- is (targeted) communication redundant when agents have full observability? The part about how multi-staged communication is implemented is quite cryptic at the moment -- is multi-staged the fact that the message is out-putted by processing with a recurrent unit? The messages is factorized into two parts k and u leading to a vector of size D -- what happens should we have one message of size D (rather than factorizing into 2), something like this would control for any improvements obtained from increases the parameters of the model.\n\nFinally,  if the premises of the paper is to define more effective communication protocols, evident in the use of continuous communication, (rather than studying what form can multi-agent communication etc etc), a necessary baseline  (especially in cases where agents share reward), is to communicate the full observation (rather than a function of it).  This baseline is not presented here and it's absolutely necessary.\n"", 'The authors propose a new architecture for learning communication protocols. In this architecture each message consists of a key and a value. When receiving the message the listener produces an attention key that is used to selectively attend to some messages more than other using soft attention. This differs from the typical \'broadcasting\' protocols learned in literature. \n\nQuestions / Comments: \n- Eqn (4) looks like a vanilla RNN. Did you experience any issues around exploding or vanishing gradients when doing multiple rounds of communication? Why not use a gated architecture here? \n- ""Centralized Critic"" section: This equation is from the COMA paper, ie. a centralised critic with policy gradients rather than DDPG. What did you use for the variance reduction baseline to estimate the advantage? Also, did you try conditioning the critic on the central state rather than the concat of observations? Formally this is required for the algorithm to be convergent. \n- How many independent seeds are the results averaged over? \n- The attention mechanism seems to provide very little value across all experiments: \n-- 84.9% vs 82.7% \n-- 89.5% vs 89.6% \n-- 64.3% vs 68.9% \nDid you check if any of these numbers are significant? This is my single biggest concern with the paper. Currently it\'s unclear whether attention is required at all in the settings presented. It would be good to see eg. the TarMAC 2-stage on the traffic junction (97.1%) ablated without attention.', 'The authors present a multi-agent communication architecture where, agents can use targeted communication and can perform multiple communication steps. The paper is well written and easy to follow.\n\nComments:\n\n1) The idea of multi-stage communication is great, but the paper doesn\'t have a strong point to support this contribution. Could the authors illustrate the benefit of multi-stage e.g. vs. the communication channel width?\n\n2) In DIAL, the authors introduce a ""null"" action, what is the difference of that and multi-stage?\n\n3) It is not clear to the reader what is the contribution of targeted communication vs. non-targeted as it looks a solution to the mean-pooling. Could the authors include at least one more experiment with on an architecture that doesn\'t use mean pooling. From an architecture perspective there is a scalability benefit of using pooling, but if that\'s the only one it has to be made more clear.\n\n4) Following (3) based on Reddit there was a recent code release in python https://github.com/minqi/learning-to-communicate-pytorch. An alternative would be to evaluate TarMAC to one of the test beds, but the paper misses baselines.']","[-20, -20, 50]","[50, 60, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Overall, this paper was somewhat clear and more importantly includes experiments on House3D, a more realistic dataset'), they express several significant concerns and criticisms about the methodology and presentation of the research. The reviewer questions the fundamental premise of the paper and points out potential inconsistencies in the approach.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Can the authors elaborate on this, am I getting things wrong?' which shows a willingness to consider alternative explanations. The critique is presented as questions and suggestions rather than harsh criticisms. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, academic tone overall."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the proposed architecture, they express significant concerns about the effectiveness of the attention mechanism and the lack of statistical significance in the results. The reviewer's biggest concern is clearly stated, which indicates skepticism about the paper's main contribution. However, the score is not deeply negative as the reviewer does engage constructively with the paper's content. The politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They phrase their concerns as questions or suggestions rather than direct criticisms, and use polite phrases like 'It would be good to see'. The reviewer also demonstrates engagement with the paper by asking detailed technical questions, which shows respect for the authors' work."", ""The sentiment score is 50 (slightly positive) because the review starts with a positive statement about the paper being well-written and easy to follow. However, the rest of the review consists of questions and suggestions for improvement, indicating a balanced perspective. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. They use phrases like 'Could the authors...' and 'It is not clear to the reader...', which maintain a constructive and courteous tone. The reviewer also acknowledges the positive aspects of the work, such as the 'great' idea of multi-stage communication, before suggesting improvements.""]"
"['The paper proposes a new ""sorting"" layer in neural networks that offers\nsome theoretical properties to be able to learn network which are 1-Lipschitz\nfunctions.\n\nThe paper contains what seems to be a nice contribution but the manuscript\nseems to have been written in a rush which makes it full of typos\nand very hard to read. This unfortunately really feels like unfinished work.\n\nJust to name a few:\n\n- Please check the use of \\citep and \\citet. See eg Szegedy ref on page 3.\n\n- Unfinished sentence ""In this work ..."" page 3.\n\n- ""]"" somewhere at the bottom of page 4.\n\n- ""Hence, neural network has cannot to lose Jacobian norm... "" ???\n\netc...\n\nAlthough I would like to offer here a comprehensive review I consider\nthat the authors have not done their job with this submission. ', 'summary:\n\nA paper that states that a new activation function, which sorts coordinates in a vector by groups, is better than ReLU for the approximation of Lipschtiz functions.\n\npros:\n\n- interesting experiments\n- lots of different problems evaluated with the technique\n\ncons:\n\n- the GroupSort activation is justified from the angle of approximating Lipschitz transformations. While references are given why Lip is good for generalisation, I cannot see why GroupSort does not go *against* the ability of deep architectures to integrate the topology of inputs (see below).\n- the proof of Theorem 1 requires polishing (see below)\n- experiments require some polishing\n\ndetail:\n\n* The proof of Theorem 1 has three problems, first in the main file argument: since ReLU is not differentiable, you cannot use the partial derivative. Maybe a sub differential ? Second, in the RHS after the use of the Cauchy-Schwartz inequality (no equation numbering…) you claim that the product of all three norms larger than 1 implies *each* of the last two is 1. This is wrong: it tell nothing about the the value of each, only about the *product* of each, which then make the next two identities a sufficient *but not necessary* condition for this to happen and invalidates the last identity. Last, the Theorem uses a three lines appendix result (C) which is absolutely not understandable. Push this in the proof, make it clear.\n\nSection D.1 (proof of Theorem 2) the proof uses group size 2 over a vector of dimension 2. This, unless I am mistaken, is the only place where the group sort activation is used and so the only place where GroupSort can be formally advocated against ReLU. If so, what about just using ReLUs and a single group sort layer somewhere instead of all group sort ? Have the authors tried this experimentally ?\n\nIf I strictly follow Algorithm 1, then GroupSort is carried out by *partitioning* the [d] indexes in g groups of the same size. This looks quite arbitrary and for me is susceptible to impair the capacity of deep architectures to progressively integrate the topology of inputs to generalise well. Table 3 tends to display that this is indeed the case as FullSort does much worse than ReLU.\n\n* Table 5: replace accuracies by errors, to be consistent with other tables.\n\n* in the experiments, you do not always specify the number of groups (Table 4)\n', 'This paper introduces GroupSort. The motivation is to find a good way to impose Lipschitz constraint to the learning of neural networks. An easy approach is ""atomic construction"", which imposes a norm constraint to the weight matrix of every network layer. Although it guarantees the network to be a Lipschitz function, not all Lipschitz functions are representable under this strong constraint. The authors point out that this is because the activation function of the network doesn\'t satisfy the so called Jacobian norm preserving property.\n\nThen the paper proposes the GroupSort activation which satisfies the Jacobian norm preserving property. With this activation, it shows that the network is not only Lipschitz, but is also a universal Lipschitz approximator. This is a very nice theoretical result. To my knowledge, it is the first algorithm for learning a universal Lipschitz function under the architecture of neural network. The Wasserstein distance estimation experiment confirms the theory. The GroupSort network has stronger representation power than the other networks with traditional activation functions.\n\nAdmittedly I didn\'t check the correctness of the proof, but the theoretical argument seems like making sense.\n\nDespite the strong theoretical result, it is a little disappointing to see that the GroupSort doesn\'t exhibit any significant advantage over traditional activation function on image classification and adversarial learning. This is not surprising though.']","[-60, -20, 60]","[-20, 50, 70]","[""The sentiment score is -60 because the reviewer expresses significant disappointment with the paper's presentation, describing it as 'unfinished work' and 'full of typos and very hard to read.' While they acknowledge a 'nice contribution,' this positive aspect is overshadowed by the criticism. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. Phrases like 'the authors have not done their job with this submission' are particularly blunt. The reviewer does attempt some politeness with 'I would like to offer here a comprehensive review,' but overall the tone is more negative than neutral or polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting experiments', 'lots of different problems evaluated'), they also point out several significant issues with the paper, including problems with the proof, justification of the method, and experimental details. The cons outweigh the pros in this review.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use neutral language to describe issues ('requires polishing', 'cannot see why') rather than harsh criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. However, the review doesn't go out of its way to be overly polite or complimentary, keeping a balanced and objective tone."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's theoretical contribution, calling it a 'very nice theoretical result' and 'the first algorithm for learning a universal Lipschitz function under the architecture of neural network.' However, it's not extremely positive due to the slight disappointment expressed about the practical results. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and expressing disappointment in a constructive manner. The reviewer also admits to not checking the proof's correctness, which shows humility. The language is consistently professional and courteous, without any harsh criticism or rudeness.""]"
"['This submission is an great ablation study on the capabilities of modern reinforcement learning to discover the causal structure of a synthetic environment. The study separates cases where the agents can only observe or they can also act, showing the expected gains of active intervention.\n\nThe experiments are so far synthetic, but it would be really interesting to see how the lessons learned extend to more realistic environments. It would also be very nice to have a sequence of increasingly complex synthetic environments where causal inference is the task of interest, such that we can compare the performance of different RL algorithms in this task (the authors only used one).\n\nI would change the title to ""Causal Reasoning from Reinforcement Learning"", since ""meta-learning"" is an over-loaded term and I do not clearly see its prevalence on this submission.', '\nThe paper presents a meta-learning RL framework to train agents that\ncan learn and do causal reasoning.  The paper sets up three tasks for\nagents to learn to do associational, interventional, and\ncounterfactual reasoning. The training/testing is done on all\n5-variable graphs. The authors demonstrate how the agent can maximize\ntheir rewards, which demonstrate that the agent might have learnt to\nlearn some causal structure and do reasoning in the data.\n\nReview:\n\nI think Causality is an important area, and seeing how RL can help in\nany aspect is something really worth looking into.\n\nHowever, I have a few qualms about the setting and the way the tasks\nare modeled.\n\n1. Why is the task to select the node with the highest ""value""\n(value=expected value?  the sample? what is it?) under some random\nexternal intervention? It feels very indirect.\n\nWhy not explicitly model certain useful actions that directly query\nthe structure, such as:\n\n- selecting nodes that are parents/children of a node\n- evaluating p(x | y) or p(x | do(y))?\n\n2. The way you generate test data might introduce biases:\n\n- If you enumerate 3^(n(n-1)/2) DAGs, some of them will have loops.  Do you weed them out?\n  Does it matter?\n\n- How do you sample weights from {-1, 0, 1}? uniform?  What happens if\n  wij = 0?  This introduces bias in your training data.  This means\n  your distribution is over DAGs + weights, not just DAGs.\n\n- Your training/test split doesn\'t take into account certain\n  equivalence/symmetries that might be present in your training data,\n  making it hard to rule out whether your agents are in effect\n  memorizing training data, specially that the number of test graphs\n  is so tiny (300, while test could have been in the thousands too):\n\nExample, if you graph just has one causal connection with weight = 1:\n  X1 -> X2; X3; X4; X5, This is clearly equivalent to X2 -> X1; X3; X4; X5.\n  Or the structure X1 -> X2 might be present in a larger graph, example with these two components:\n  X1 -> X2; X3 -> X4 -> X5;\n\n3. Why such a low number of learning steps T (T=5 in paper) in each episode? no\nexperimentation over choice of T or discussion of this choice is\ngiven.  And it is mentioned in the findings, in several cases, that\nthe active agent is only merely comparable to the passive agent, while\none would think active would be better. If T were reasonably higher\n(not too low, not too high), one would expect to see a difference.\n\n4. Although I have concerns listed above, something about Figure 2(a)\n  seems to suggest that the agent is learning something.  I think if\n  you had tried to probe into what the agent is actually learning, it\n  would have clarified many doubts.\n\nHowever, in Figure 2(c), if the black node is -5, why is the node\nbelow left at -2.5?  The weight on the edge is 1 and other parent is\n0, so -2.5 seems extremely unlikely, given that the variance is 0.1\n(stdev ~ 0.3, so ~8 standard deviations away!).  (Similar issue in\nFigure 3c)\n\n5. Although the random choice would result in a score of -5/4, I think\n  it\'s quite easy and trivial to beat that by just ignoring the node\n  that\'s externally intervened on and assigned -5, given it\'s a small\n  value. This probably doesn\'t require the agent to be able to do\n  ""causal reasoning"" ...  That immediately gives you a lower bound of\n  0.  That might be more appropriate.\n\n  If you could give a distribution of the max(mean_i(Xi)) over all\n  graphs (including weights in your distribution), it could give an\n  idea of how unlikely it is for the agent to get a high score without\n  actually learning the causal structure.\n\nSuggestions for improving the work:\n\n- Provide results on wider range of experiments (eg more even\n  train-test split, choice of T), or at minimum justify choices\n  made. And address the issues above.\n\n- Focus on more intuitive notions that clearly require causal\n  knowledge, or motivate your objective very clearly to show its\n  sufficiency.\n\n- Perhaps discuss simpler examples (e.g., 3 node), where it\'s easy to\n  enumerate all causal structures and group them into appropriate\n  equivalence classes.\n\n- Please proof-read and make sure you\'ve defined all terms (there are\n  a few, such as Xp/Xf in Expt 3, where p/f are not really defined).\n\n- You could show a few experiments with larger N by sampling from the space of all possible\n  DAGs, instead of enumerating everything.\n\nOf course, it would be great if you can probe the agent to see what it\nreally learnt. But I understand that could be a long-shot.\n\nAnother open problem  is whether this approach can scale to larger number of\nvariables, in particular the learning might be very data hungry.\n', 'This paper aims at training agents to perform causal reasoning with RL in three settings: observational (the agent can only obtain one observational sample at a time), interventional (the agent can obtain an interventional sample at a time for a given perfect intervention on a given variable) and a counterfactual setting (the agent can obtains interventional samples, but the prediction is about the case in which the same noise variables were sampled, but a different intervention was performed) . In each of these settings, after T-1 steps of information gathering, the algorithm is supposed to select the node with the highest value in the last step. Different types of agents are evaluated on a limited simulated dataset, with weak and not completely interpretable results.\n\nPros:\n-Using RL to learn causal reasoning is a very interesting and worthwhile task.\n-The paper tries to systematize the comparison of different settings with different available data.\n\n\nCons:\n-Task does not necessarily require causal knowledge (predict the node with the highest value in this restricted linear setting)\n-Very limited experimental setting (causal graphs with 5 nodes, one of which hidden, linear Gaussian with +/- 1 coefficients, with interventions in training set always +5, and in test set always -5) and lukewarm results, that don’t seem enough for the strong claims. This is one of the easiest ways to improve the paper.\n-In the rare cases in which there are some causal baselines (e.g. MAP baseline), they seem to outperform the proposed algorithms (e.g. Experiment 2)\n-Somehow the “active” setting in which the agent can decide the intervention targets seems to always perform worse than the “passive” setting, in which the targets are already chosen. This is very puzzling for me, I thought that choosing the targets should improve the results...\n-Seem to be missing a lot of literature on causality and bandits, or reinforcement learning (for example: https://arxiv.org/abs/1606.03203, https://arxiv.org/abs/1701.02789, http://proceedings.mlr.press/v70/forney17a.html)\n-Many details were unclear to me and in general the clarity of the description could be improved\n\nIn general, I think the paper could be opening up an interesting research direction, but unfortunately I’m not sure it is ready yet. \n\n\nDetails:\n-Abstract: “Though powerful formalisms for causal reasoning have been developed, applying them in real-world domains is often difficult because the frameworks make idealized assumptions”. Although possibly true, this sounds a bit strong, given the paper’s results. What assumptions do your agents make? At the moment the agents you presented work on an incredibly small subset of causal graphs (not even all linear gaussian models with a hidden variable…), and it’s even not compared properly against the standard causal reasoning/causal discovery algorithms...\n-Footnote 1: “this formalism for causal reasoning assumes that the structure of the causal graph is known” - (Spirtes et al. 2001) present several causal discovery (here “causal induction”) methods that recover the graph from data.\n-Section 2.1 “X_i is a potential cause of X_j” - it’s a cause, not potential, maybe potentially not direct.\n-Section 3: 3^(N-1)/2 is not the number of possible DAGs, that’s described by this sequence: https://oeis.org/A003024. Rather that is the number of (possibly cyclic) graphs with either -1, 1 or 0 on the edges. \n-“The values of all but one node (the root node, which is always hidden)” - so is it 4 or 5 nodes? Or it is that all possible DAGs on N=6 nodes one of which is hidden? I’m asking because in the following it seems you can intervene on any of the 5 nodes… \n-The intervention action is to set a given node to +5 (not really clear why), while in the quiz phase (in which the agent tries to predict the node with the highest variable) there is an intervention on a known node that is set to -5 (again not clear why, but different from the interventions seen in the T-1 steps). \n-Active-Conditional is only marginally below Passive-Conditional, “indicating that when the agent is allowed to choose its actions, it makes reasonable choices” - not really, it should perform better, not “marginally below”... Same for all the other settings\n-Why not use the MAP baseline for the observational case?\n-What data does the Passive Conditional algorithms in Experiment 2? Only observations  (so a subset of the data)?\n-What are the unobserved confounders you mention in the results of Experiment 2? I thought there is only one unobserved confounder (the root node)? Where do the others come from?\n-The counterfactual setting possibly lacks an optimal algorithm? \n', 'Note: This review is coming in a bit late, already after one round of responses. So I write this with the benefit of having read the helpful previous exchange. \n\nI am generally positive about the paper and the broader project. The idea of showing that causal reasoning naturally emerges from certain decision-making tasks and that modern (meta-learning) RL agents can become attuned to causal structure of the world without being explicitly trained to answer causal questions is an attractive one. I also find much about the specific paper elegant and creative. Considering three grades of causal sophistication (from conditional probability to cause-effect reasoning to counterfactual prediction) seems like the right thing to do in this setting.\n\nDespite these positive qualities, I was confused by many of the same issues as other reviewers, and I think the paper does need some more serious revisions. Some of these are simple matters of clarification as the authors acknowledge; others, however, require further substantive work. It sounds like the authors are committed to doing some of this work, and I would like to add one more vote of encouragement. While the paper may be slightly too preliminary for acceptance at this time, I am optimistic that a future version of this paper will be a wonderful contribution.\n\n(*) The authors say at several points that the approach “did not require explicit knowledge of formal principles of causal inference.” But there seem to be a whole of lot of causal assumptions that are critically implicit in the setup. It would be good to understand this better. In particular, the different agents are hardwired to have access to different kinds of information. The interventional agent is provided with data that the conditional agent simply doesn’t get to see. Likewise, the counterfactual agent is provided with information about noise. Any sufficiently powerful learning system will realize that (and even how) the given information is relevant to the decision-making task at hand. A lot of the work (all of the work?) seems to be done by supplying the information that we know would be relevant.\n\n(*) Previous reviewers have already made this point - I think it’s crucial - and it’s also related to the previous concern: It is not clear how difficult the tasks facing these agents actually are, nor is it clear that solving them genuinely requires causal understanding. What seems to be shown is that, by supplying information that’s critical for the task at hand, a sufficiently powerful learning agent is able to harness that information successfully. But how difficult is this task, and why does it require causal understanding? I do think that some of the work the authors did is quite helpful, e.g., dividing the test set between the easy and hard cases (orphan / parented, unconfounded / confounded). But I do not feel I have an adequate understanding of the task as seen, so to say, from the perspective of the agent. Specifically:\n\n(*) I completely second the worry one of the reviewers raised about equivalence classes and symmetries. The test set should be chosen more deliberately - not randomly - to rule out deflationary explanations of the agents’ purported success. I’m happy to hear that the authors will be looking more into this and I would be interested to know how the results look.\n\n(*) The “baselines” in this paper are often not baselines at all, but rather various optimal approaches to alternative formulations of the task. I feel we need more actual baselines in order to see how well the agents of interest are doing. I don’t know how to interpret phrases like “close to perfect” without a better understanding of how things look below perfection. \n\nAs a concrete case of this, just like the other reviewers, I was initially quite confused about the passive agents and why they did better than the active agents. These are passive agents who actually get to make multiple observations, rather than baseline passive agents who choose interventions in a suboptimal way. I think it would be helpful to compare against an agent who makes the same number of observations but chooses them in a suboptimal (e.g., random) way. \n\n(*) In relation to the existing literature on causal induction, it’s telling that implementing a perfect MAP agent in this setting is even possible. This makes me worry further about how easy these tasks are (again, provided one has all of the relevant information about the task). But it also shows that comparison with existing causal inference methods is simply inappropriate here, since those methods are designed for realistic settings where MAP inference is far from possible. I think that’s fine, but I also think it should be clarified in the paper. The point is not (at least yet) that these methods are competitors to causal inference methods that do “require explicit knowledge of formal principles of causal inference,” but rather that we have a proof-of-concept that some elementary causal understanding may emerge from typical RL tasks when agents are faced with the right kinds of tasks and given access to the right kinds of data. That’s an interesting claim on its own. The penultimate paragraph in the paper (among other passages) seems to me quite misleading on this point.\n\n(*) One very minor question I have is why actions were softmax selected even in the quiz phase. What were the softmax parameters? And would some of the agents not perform a bit better if they maximized?']","[80, -30, -40, 20]","[70, 50, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer describes the submission as 'great' and expresses interest in potential extensions of the work. The overall tone is appreciative and encouraging. The politeness score is 70 (polite) due to the use of positive language and constructive suggestions. The reviewer offers recommendations in a respectful manner, using phrases like 'it would be really interesting' and 'it would also be very nice'. The suggestion to change the title is presented gently. The review maintains a professional and courteous tone throughout, without any harsh criticism or demanding language."", ""The sentiment score is -30 because while the reviewer acknowledges the importance of the research area, they express several significant concerns about the methodology and results. The review begins positively but quickly shifts to a critical tone, listing multiple issues with the study design and interpretation of results. However, it's not entirely negative as the reviewer offers constructive suggestions for improvement. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I think' and 'Please' when offering criticisms and suggestions. They also acknowledge the potential difficulty of some of their suggestions. The language is not overly formal or deferential, but it avoids harsh or rude phrasing, striking a balance between critique and courtesy."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects ('very interesting and worthwhile task', 'tries to systematize the comparison'), the overall tone is critical. The reviewer lists more cons than pros, points out several limitations, and concludes that the paper is 'not ready yet'. However, the score is not extremely negative as the reviewer sees potential in the research direction. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively (e.g. 'This is one of the easiest ways to improve the paper'). The reviewer also uses phrases like 'I think' and 'I'm not sure' to soften criticisms. However, the score is not extremely high as the review is still quite direct in its criticisms."", ""The sentiment score is 20 (slightly positive) because the reviewer expresses general positivity about the paper and its broader project, calling it 'attractive', 'elegant', and 'creative'. However, they also raise several significant concerns and state the paper needs 'serious revisions', indicating it's not entirely positive. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I would like to add one more vote of encouragement' and 'I am optimistic', showing consideration. The reviewer also balances critiques with positive feedback and uses polite hedging language like 'I think' and 'I feel'. However, they don't go out of their way to be excessively polite, maintaining a professional tone.""]"
"['Update: see comments ""On revisions"" below.\n\nThis paper essentially introduces a label-dependent regularization to the VIB framework, matching the encoder distribution of one computed from labels. The authors show good performance in generalization, such that their approach is relatively robust in a number of tasks, such as adversarial defense.\n\nThe idea I think is generally good, but there are several problems with this work.\n\nFirst, there has been recent advances in mutual information estimation, first found in [1]. This is an important departure from the usual variational approximations used in VIB. You need to compare to this baseline, as it was shown that it outperforms VIB in a similar classification task as presented in your work.\n\nSecond, far too much space is used to lay out some fairly basic formalism with respect to mutual information, conditional entropy, etc. It would be nice, for example, to have an algorithm to make the learning objective more clear. Overall, I don\'t feel the content justifies the length.\n\nThird, I have some concerns about the significance of this work. They introduce essentially a label-dependent “backwards encoder” to provide samples for the KL term normally found in VIB. The justification is that we need the bottleneck term to improve generalization and the backwards encoder term is supposed to keep the representation relevant to labels. One could have used an approach like MINE, doing min information for the bottleneck and max info for the labels. In addition, much work has been done on learning representations that generalize using mutual information (maximizing instead of minimizing) [2, 3, 4, 5] along with some sort of term to improve ""relevance"", and this work seems to ignore / not be aware of this work.\n\nOverall I could see some potential in this paper being published, as I think the approach is sensible, but it\'s not presented in the proper context of past work.\n\n[1] Belghazi, I., Baratin, A., Rajeswar, S., Courville, A., Bengio, Y., & Hjelm, R. D. (2018). MINE: mutual information neural estimation. International Conference for Machine Learning, 2018.\n[2] Gomes, R., Krause, A., and Perona, P. Discriminative clustering by regularized information maximization. In NIPS, 2010.\n[3] Hu, W., Miyato, T., Tokui, S., Matsumoto, E., and Sugiyama, M. Learning discrete representations via information maximizing self-augmented training. In ICML, 2017.\n[4] Hjelm, R. D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Trischler, A., & Bengio, Y. (2018). Learning deep representations by mutual information estimation and maximization. arXiv preprint arXiv:1808.06670.\n[5] Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. ""Representation learning with contrastive predictive coding."" arXiv preprint arXiv:1807.03748 (2018).', 'This paper wants to discuss a new objective function, which the authors dub ""Conditional Entropy Bottleneck"" (CEB), motivated by learning better latent representations. However, as far as I can tell, the objective functions already exists in the one-parameter family of Information Bottleneck (IB) of Tishby, Pereira, and Bialek. The author seems to realize this in Appendix B, but calls it ""a somewhat surprising theoretical result"". However, if we express IB as max I(Z;Y) - beta I(Z;X), see (19), and then flip signs and take the max to the min, we get min beta I(Z;X) - I(Z;Y). Taking beta = 1/2, multiplying through by 2, and writing I(X;Z) - I(Y Z) = I(X;Z|Y), we find CIB. Unfortunately, I fail to see how this is surprising or different.\n\nA difference only arises when using a variational approximation to IB. The authors compare to the Variational Information Bottleneck (VIB) of Alemi, Fischer, Dillon, and Murphy (arXiv:1612.00410), which requires a classifier, an encoder, and a marginal posterior over the latents. Here, instead of the marginal posterior, they learn a backwards encoder from labels to latents. This difference arises because the IB objective has two terms of opposite sign, and we can group them into positive definite terms in different ways, creating different bounds.\n\nPerhaps this grouping leads to a better variational bound? If so, that\'s only a point about the variational method employed by Alemi et al., and not a separate objective. As this seems to be the main contribution of the paper, this point needs to be explained more carefully and in more detail. For instance, it seems worth pointing out, in the discrete case, that the marginal posterior |Z| values to estimate, and the backwards encoder has |Z| x |Y| -- suggesting this is a possibly a much harder learning problem. If so, there should be a compelling benefit for using this approximation and not the other one.\n\nIn summary, the authors are not really clear about what they are doing and how it relates to IB. Furthermore, the need for this specific choice in IB parameter space is not made clear, nor do the experimental results giving a compelling need. (The experimental results are also not at all clearly presented or explained.) Therefore, I don\'t think this paper satisfies the quality, clarity, originality, or significance criteria for ICLR.', ""[UPDATE]\n\nI find the revised version of the paper much clearer and streamlined than the originally submitted one, and am mostly content with the authors reply to my comments. However, I still think the the work would highly benefit from a non-heuristic justification of its approach and some theoretic guarantees on the performance of the proposed framework (especially, in which regimes it is beneficial and when it is not). Also, I still find the presentation of experimental results too convoluted to give a clear and comprehensive picture of how this methods compares to the competition, when is it better, when is it worse, do the observations/claim generalize to other task, and which are the right competing methods to be considering. I think the paper can still be improved on this aspect as well. \n\nAs I find the idea (once it was clarified) generally interesting, I will raise my score to 6.\n\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nThe paper proposes an objective function for learning representations, termed the conditional entropy bottleneck (CEB). Variational bounds on the objective function are derived and used to train classifiers according to the CEB and compare the results to those attained by competing methods. Robustness and adversarial examples detection of CEB are emphasized.\n\nMy major comments are as follows:\n\n1) The authors base their 'information-theoretic' reasoning on the set-theoretic structure of Shannon’s information measures. It is noteworthy that when dealing with more than 2 random variables, e.g., when going from the twofold I(X;Y) to the threefold I(X;Y;Z), this theory has major issues. In particular, there are simple (and natural) examples for which I(X;Y;Z) is negative. The paper presents an information-theoretic heuristic/intuitive explanation for their CEB construction based on this framework. No proofs backing up any of the claims of performance/robustness in the paper are given. Unfortunately, with such counter-intuitive issues of the underlying theory, a heurisitc explanation that motivates the proposed construction is not convincing. Simulations are presented to justify the construction but whether the claimed properties hold for a wide variety of setups remain unclear.\n\n2) Appendix A is referred to early on for explaining the minimal necessary information (MNI), but it is very unclear. What is the claim of this Appendix? Is there a claim? It's just seems like a convoluted and long explanation of mutual information. Even more so, this explanation is inaccurate. For instance, the authors refer to the mutual information as a 'minimal sufficient statistic' but it is not. For a pair of random variables (X,Y), a sufficient statistic, say, for X given Y is a function f of Y such X-f(Y)-Y forms a Markov chain. Specifically, f(Y) is another random variable. The mutual information I(X;Y) is just a number. I have multiple guesses on what the authors' meaning could be here, but was unable to figure it out from the text. One option, which is a pretty standard way to define sufficient statistic though mutual information is as a function f such that I(X;Y|f(Y))=0. Such an f is a sufficient statistic since the zero mutual information term is equivalent to the Markov chain X-f(Y)-Y from before. Is that what the authors mean..?\n\n3) The Z_X variable introduced in Section 3 in inspired by the IB framework (footnote 2). If I understand correctly, this means that in many applications, Z_X is specified by a classifier of X wrt the label Y. My question is whether for a fixed set of system parameters, Z_X is a deterministic function of X? If this Z_X play the role of the sufficient statistics I've referred to in my previous comment, then it should be just a function of X. \n\nHowever, if Z_X=f(X) for a deterministic function f, then the CEB from Equation (3) is vacuous for many interesting cases of (X,Y). For instance, if X is a continuous random variable and Z_X=f(X) is continuous as well, then \nI(X;Z_X|Y)=h(Z_X|Y)-h(Z_X|X,Y)\nwhere h is the differential entropy and the subtracted terms equals -\\infty by definition (see Section 8.3 of (Cover & Thomas, 2006). Consequently, the mutual information and the CEB objective are infinite. If Z_X=f(X) is a mixed random variable (e.g., can be obtain from a ReLU neural network), then the same happens. Other cases of interest, such as discrete X and f being an injective mapping of the set of X values, are also problematic. For details of such problem associated with IB type terms see:\n\n[1] R. A. Amjad and B. C. Geiger 'Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle', 2018 (https://arxiv.org/abs/1802.09766).\n\nCan the authors account for that?\n\n4) The other two reviews addressed the missing accounts for past literature. I agree on this point and will keep track of the authors' responses. I will not comment on that again. \n\nBeyond these specific issue, they text is very wordy and confusing at times. If some mathematical justification/modeling was employed the proposed framework might have been easier to accept. The long heuristic explanations employed at the moment do not suffice for this reviewer. Unless the authors are able to provide clarification of all the above points and properly place their work in relation to past literature I cannot recommend acceptance. \n""]","[-20, -80, -50]","[50, -20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the idea is 'generally good' and sees 'some potential' in the paper, they also point out several significant problems and concerns. The reviewer states that the paper lacks proper context, has issues with content justification, and raises concerns about its significance. However, it's not entirely negative as they suggest the approach is 'sensible' and could potentially be published with improvements. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think' and 'I could see some potential,' which soften criticism. They also provide specific suggestions for improvement and references to relevant work, which is helpful and courteous. The language is not overly formal or polite, but it avoids rudeness or harsh criticism, striking a balance between directness and respect."", ""The sentiment score is -80 because the reviewer is highly critical of the paper, stating that the main contribution is not original and that the paper fails to meet the quality, clarity, originality, and significance criteria for ICLR. The reviewer consistently points out flaws and expresses skepticism about the paper's claims. The politeness score is -20 because while the reviewer maintains a professional tone, there are instances of blunt criticism and dismissive language, such as 'Unfortunately, I fail to see how this is surprising or different' and 'The authors are not really clear about what they are doing'. The reviewer does not use overtly rude language but also does not make efforts to soften the criticism, resulting in a somewhat impolite tone overall."", ""The sentiment score is -50 because while the reviewer acknowledges some improvements ('I find the revised version of the paper much clearer and streamlined'), they still express significant concerns and criticisms throughout the review. The reviewer raises multiple major issues with the paper's approach, methodology, and presentation, indicating an overall negative sentiment despite some positive aspects. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I find' and 'I think' to soften criticisms. They also acknowledge positive aspects before presenting critiques. However, the review is direct in its criticisms without excessive politeness, keeping the score only moderately positive.""]"
"['Summary:\nThe role of auxiliary tasks is to improve the generalization performance of the principal task of interest. So far, hand-crafted auxiliary tasks are generated, tailored for a problem of interest. The current work addresses a meta-learning approach to automatically generate auxiliary tasks suited to the principal task, without human knowledge.  The key components of the method are: (1) meta-generator; (2) multi-task evaluator. These two models are trained using the gradient-based meta-learning technique (for instance, MAML).  The problem of image classification is considered only, while authors claimed the method can be easily applied to other problems as well. \n\nStrengths:\n- To my best knowledge, the idea of applying the meta-learning to the automatic generation of auxiliary tasks is novel. \n- The paper is well written and easy to read.\n- The method nicely blends a few components such as self-supervised learning, meta-learning, auxiliary tasks into a single model to tackle the meta auxiliary learning. \n\nWeakness:\n- The performance gain is not substantial in experiments. I would like to suggest to use the state-of-the-arts classifier for the principal task and to evaluate how much gain your method can get with the help of auxiliary tasks. You can refer to the state-of-the-arts performance on CIFAR.\n- If the information on the hierarchy of sub-categories is not available, it will be an annoying hyperparameters that should be well tuned.\n', 'This paper proposes a self-auxiliary-training method that aims to improve the generalization performance of simple supervised learning. The basic idea is to train the classification network to predict fine-level auxiliary labels in addition to the ground-truth coarse label, where the auxiliary labels used in training is generated by a generator network. During training, the classification network and the generator network are alternatively updated, and the update of the latter aims to maximize the improvement of the former after using the generated auxiliary label for training. The method requires a class hierarchy in advance to define the binary mask applied to the output layer for auxiliary class prediction. A KL divergence term is attached to the optimization objective to avoid generating trivial and collapsing auxiliary classes.\n\nPros:\n\n1) The main idea is simple and easy to understand.\n2) It discusses the class collapsing problem in generating pseudo (auxiliary) labels and provides a reasonable solution, i.e., using KL divergence as regularization.\n3) Uses several visualizations to show experimental results.\n\nCons:\n\n1) The problem it aims to solve is neither multi-task learning nor meta-learning: it tries to solve a supervised classification problem defined on principle classes, with the help of simultaneously predicting/generating auxiliary class labels. Although the concept of ""task"" is not explicitly defined in this paper, the authors seem to associate each task with a specific class. This is not correct: in meta-learning, each task is a subset of classes drawn from a ground set of classes, and different tasks are independently sampled. In addition, the classification models for different tasks are independent, though their training might be related by a meta-learner. Hence, the claims in multiple places of this paper and the names for the two networks are misleading.\n\n2) At the end of Page 4, the authors show that the update of the generator only depends on the improvement of the classifier after using the auxiliary label for training. In fact, the optimal auxiliary labels minimizing the objective is the ground truth label for principle classes. This results in the class collapsing problem observed by the authors. The KL divergence regularization introduces extra randomness to the auxiliary labels and thus mitigates the problem, but it hardly provides any useful information except randomness. In other words, the auxiliary labels for a specific principle class are very possible to be multiple noisy copies of the principal label with random perturbations. So it is not convincing to me that the auxiliary labels generated by the generator can be really helpful. My conjecture is that the observed improvements are mainly due to the softness of the auxiliary labels, which has been proved by model compression/knowledge distillation and recent ""born-again neural networks"". To verify this, the authors might need to compare the results with those methods (which use the generated soft probability of ground truth classes for training), and the ""random-noisy copies of soft principle label"" mentioned above.\n\n3) The experiments lack comparisons to several important baselines from self-supervised learning community, and methods using soft labels for training (as mentioned in 2) above). A successful idea of self-supervised learning is to use the output feature map of the trained classification network to generate auxiliary training signals, since it provides extra information about the learned distance beyond the ground-truth labels. The authors might want to compare to ""Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep Clustering for Unsupervised Learning of Visual Features. ECCV 2018."" and ""Carl Doersch and Andrew Zisserman. Multi-task self-supervised visual learning. ICCV 2017."" Moreover, since the method is not a meta-learning approach for few-shot learning, it is not fair and also not appropriate to compare with Prototypical Network.\n\n4) Although the paper claims that the ground truth fine labels are not required, it requires a class hierarchy, which in the experiments are provided by the dataset and defined between true coarse and fine classes. In practice, such hierarchy might be much harder to achieve than the primary (coarse) labels, and might be as costly to obtain as the true fine-class labels. This weakens the feasibility of the proposed method.\n\n5) The experiments only test the proposed method on CIFAR100 and CIFAR10, which has at most 100 fine classes. It is necessary to test it on datasets with much more fine classes and much-complicated hierarchy, e.g., ImageNet, MS COCO or their subsets, which have ideal class hierarchy structures.\n\nMinor comments:\n\nSome important equations in the paper should be numbered. ', 'This paper proposes an algorithm for auxiliary learning. Given a target prediction task to be learned on training data, the auxiliary learning utilizes external training data to improve learning. The authors focus on a setup where both target and external training data come from the same distribution but differ in class labels, where each class in the target data is a set of finer-grained classes in the auxiliary data. The authors propose a heuristic for learning from both data sets through minimization of a joint loss function. The experimental results show that the proposed methods works well on this particular setup on CIFAR data set.\n\nStrengths:\n+ a new auxiliary learning algorithm\n+ positive results on CIFAR data set\n\nWeaknesses:\n- novelty is low: the proposed algorithm is a heuristic similar to previously proposed algorithms in the transfer learning and auxiliary learning space\n- there is no attempt to provide a theoretical insight into the performance of the algorithm\n- the problem assumptions are too simplistic and unrealistic (feature distributions of target and auxiliary data are identical), so it is questionable if the proposed algorithm has practical importance\n- experiments are performed using a synthetic setup on a single data set, so it remains unclear if the algorithm would be successful in a real life scenario\n- the paper is poorly written and sentences are generally very hard to parse. For example, section 3.1 is opened by statements such as ""(we use) a multi-task evaluator which trains on the principal and auxiliary tasks, and evaluates the performance of the auxiliary tasks on a meta set""??']","[50, -30, -50]","[80, 60, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting the strengths of the paper, noting its novelty, readability, and innovative approach. However, they also point out weaknesses, which balances the overall sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'To my best knowledge' and 'I would like to suggest,' which maintain a courteous tone. The reviewer also provides specific recommendations for improvement without using harsh or dismissive language."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), the majority of the review focuses on critical points ('Cons') and areas for improvement. The reviewer expresses skepticism about the method's effectiveness and points out several limitations, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer does recognize some merits of the paper.\n\nThe politeness score is 60 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, such as 'It is not convincing to me' and 'The authors might want to compare', rather than using harsh or dismissive language. The reviewer also balances criticism with positive observations ('Pros'). However, it's not extremely polite as it doesn't include overtly courteous language or praise beyond the initial 'Pros' section."", ""The sentiment score is -50 because while the review acknowledges some strengths ('a new auxiliary learning algorithm' and 'positive results on CIFAR data set'), it lists more weaknesses and criticisms. The reviewer questions the novelty, theoretical insight, practical importance, and generalizability of the work. The final comment about poor writing further contributes to the negative sentiment. However, the criticism is not extremely harsh, hence a moderately negative score rather than a strongly negative one. The politeness score is 20 because the reviewer maintains a professional tone throughout, presenting criticisms as objective observations rather than personal attacks. The use of bullet points for strengths and weaknesses is a polite way to organize feedback. However, the language is not overtly warm or encouraging, keeping the score only slightly positive.""]"
"[""The paper proposes a novel adversarial attack on deep neural networks. It departs from the mainstream literature in two points: \n1. A 'federated' learning setting is considered, meaning that we optimize a DNN in parallel (imagine a map-reduce approach, where each node performs SGD and then a central server (synchronously) updates the global parameters by averaging over the results of the nodes) and an attacker has control over one of the nodes.\n2. The treat model is not the common data poisoning setting, but 'model poisoning' (the attacker can send an arbitrary parameter vector back to the server).\n\nThe paper, which is well written, starts with proposing a couple of straightforward (naive) attacks, which are subsequently used as a baseline. Since there (apparently) is no direct related work, these baselines are used in the experimental comparisons. Then the authors propose a more sophisticated attacks, based on alternatingly taking a step into the attack direction (to get an effective attack) and minimizing the loss (to Camouflage the attack), respectively. They add also the feature of restricting the solution being not to far away from the usual benign SGD step.\n\nAll in all, I am acknowledging that his paper introduces the federated learning paradigm to 'adversarial examples' subcommunity of ICLR and would make for good discussions at a potential poster. I find the used method slightly oversimplistic, but this is maybe fine for a proof of concept paper. \n\nFinal judgement: For me this paper is a 6-7 rating paper; a nice addition to the program, but not a must-have.\n\nA have a question to the authors that is important to me: it seems that the baseline attack could be very very simply detected by checking on the server the norm of the update vector of the attacked node. Since the vector has been boosted, the norm will be large. While your distance-based regularization somewhat takes that effect away, it remains unclear to what amount. Can you give me some (empirical) details on this issue? / or clarify if I am completely off here?  thank you"", 'The paper considers the federated learning setting as introduced by McMahan et al. (2017) and aims at securing it against model poisoning attacks.\n\nCons: \n\nWhile I appreciated the writing clarity of the paper, the paper misses the whole point of defensive ML research: in the model poisoning case, a minimal requirement for a defense mechanism is to be formally proven *whatever is the behavior of the attacker* (within the threat model). Experiments alone are not sufficient for this purpose given the size of the space of possible attacks. Especially that (unlike evasion attacks) proofs are relatively easy to be made in the poisoning case.\n\nFor instance the literature cited by the paper (Chen 2017, Chen 2018, Blanchard 2017) + the recent follow-ups ((1)Alistarh et al. NIPS 2018, (2) El Mhamdi  et al. ICML 2018,  (3) Yin et al. ICML 2018 etc) are full of approaches the authors can follow to formally support their claims.\nAlso, the literature review has been done very lightly: Chen et al. 2017b (And most cited above) do *not* assume a single Byzantine agent as said in the paper, but assume up to <50% malicious (potentially colluding) agents. \n\nBesides absence of formal support, how does the approach compare to the optimal results in (1) and (3) at least in the convex case ?\nIn the abstract, it is said (ii) that in the i.i.d situation, it will be easy to make spurious update standout among benign ones), this was proven wrong in (2) when the dimension of the model is large and the loss function highly non-convex, the case of neural networks for example. As a general comment, the defense mechanisms of the paper are all relying on a distance computation and thus will all provide the sqrt(d) leeway for an attacker as described in (2) and will fail preventing high-dimensionality attacks.\n\n\nPros: \n\nI was very excited by the ideas in section 5, this work is the first to my knowledge to attempt at interpreting poisoning attacks. I suggest to the authors to either fix the issues mentioned above (and formally analyze their work), or to focus more on the interoperability question, if they want to keep the paper in the empiricist nature.\n\n', 'This paper presents an interesting adversarial strategy to attack federated learning systems, and discussed options to detect and prevent the attacks. It is based not upon data poisoning attacks, but model poisoning attacks. It analyzes different strategies on the attacker\'s side, discusses the effect with real experimental data, and proposes ways to prevent such attacks from the federated learning perspective. \n\nIt is an interesting line of work which develops specific optimization algorithms to try to manipulate the global classifier for certain desired outcomes. I particularly appreciate the authors\' thought process of improving the attack strategies with the understanding of the detection strategies. Also the authors proposed visualization to interpret poisoned models. However, I feel this paper needs major revision to make it a solid piece of work:\n- Need better motivations. Is there any benefit to exploit model poisoning as opposed to data poisoning? Which one is more effective in attacking (and therefore harder to detect)? \n- It\'s confusing to read through Section 3 on these different attack strategies. For instance, in 3.2 the authors introduced explicit boosting and implicit boosting, but only explicit boosting is focused because implicit boosting didn\'t show good results in Figure 2. But is there a setup that implicit boosting will be beneficial (to the attackers)? I feel the authors introduced many strategies, but didn\'t give theoretical analysis. It is hard to pick the ""best"" attack strategy in practice, thus making it equally hard to have the ""best"" detection strategy. \n- The figures are also confusing in that it\'s hard to understand what the 3D figures are trying to show, and it is not obvious what the legend means. The authors should also explain whether this experimental observation is unique to this data set/experimental setup or has similar trends in similar federated learning settings. \n- Clearly Appendix A is unfinished\n\nI encourage the authors to address these questions carefully and resubmit the manuscript later. \n']","[60, -50, -20]","[80, 20, 60]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper as a 'nice addition to the program' and rates it 6-7 out of 10. They praise the paper as 'well written' and recognize its novelty in introducing federated learning to the field. However, they also note some limitations, calling the method 'slightly oversimplistic'. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout. They use phrases like 'I am acknowledging', 'I find', and pose a question to the authors in a courteous manner, even thanking them at the end. The reviewer provides constructive feedback and frames criticisms diplomatically, maintaining a professional and considerate tone."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several significant flaws in the paper's approach and methodology. However, it's not entirely negative as it does mention some positive aspects, particularly in the 'Pros' section. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I appreciated' and 'I was very excited by', which add a polite touch. The reviewer also offers constructive suggestions for improvement, which is a polite approach to criticism. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and appreciates certain aspects, they state that the paper 'needs major revision' and list several significant concerns. The overall tone suggests the paper is not yet ready for publication in its current form. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects of the work, and phrases criticisms constructively. They use polite phrases like 'I encourage the authors' and 'I feel', which soften the critique. The reviewer also provides specific, actionable feedback for improvement, which is a courteous approach in academic review.""]"
"['The paper proposes a framework for training generative models that work on composed data. The models are trained in an adversarial fashion. The authors apply it to decompose foreground/background parts on MNIST images, and to perform sentence composition/decomposition.\n\nHigh level comments:\n* Clarity: In terms of language and writing style, the paper is written very clearly and easy to follow. In terms of presentation, there are some details that are omitted which would have made understanding easier and the work more reproducible.\n* Quality: The idea that is introduced seems intuitive and reasonable, but the experiments does not have enough details to prove that this method works (i.e. no quantitative results presented).  Moreover, the presentation of the method is not very well done (missing details), especially since the authors used the upper limit of 10 pages.\n* Originality: I am not familiar with the literature of generative models to judge this precisely, but according to the related work section it sounds like an original idea that is worth sharing.\n* Significance: I believe the idea of modeling data composition explicitly sounds intuitive and interesting, and it is worth sharing. However, the experimental section does not have enough evidence that it is actually possible to learn this, so it is not clear whether the contribution is significant.\n\nPros:\n-\tinteresting new problem formulation \n-\tsimple and clear language\n-\tthe theoretical analysis in the last section could be interesting more generally in the context of GANs\n-\tthe framework is applied on 2 different modalities: images and text.\n\nCons:\n-\thard to tell whether this approach works since the metrics for evaluation are not specified and there are no quantitative results in the experimental section (only 1 qualitative example per task)\n-\tthe work is not reproducible due to the lack of details (see more explanations below)\n-\tthe theoretical analysis is a standalone piece of the paper, without any discussion about the implications, or making connections to the previous sections.\n\nDetailed comments:\n1.\tI believe the weakest part of this paper is the evaluation section. The authors run their framework on 4 tasks of increasing difficulty. While the MNIST examples make for a nice and intuitive qualitative analysis, the are no quantitative results at all. The only result that is reported for each task is one qualitative picture. The authors make statements such as “The decomposition network learns to decompose the digits and backgrounds correctly” , “Given one component, decomposition function and the other component can be learned.” but there is not mention for how these conclusion are made (no metrics, no numbers). Indeed, it is difficult in general to quantify the results of generative models, but most other GAN papers introduce some sort metric that can be used to aggregate the evaluation on an entire dataset. If the authors manually inspected the results, they should at least report how many images they inspected and how many looked correct. \n2.\tAside from evaluation, there are some other details missing from the presentation. The individual details may not be major, but because all of these are missing together, it really affects the overall quality of the paper. For example:\n    \uf0a7\t the authors state: “To train discriminator(s), a regularization is applied. For brevity, we do not show the regularization term (see Petzka et al. (2017)) used in our experiments.”. For reproducibility purposes, I believe it is important to at least mention the type of regularization, at least in the appendix. \n    \uf0a7\tThere is a parameter alpha used to balance the losses. What values was used in the experiments?\n    \uf0a7\tChoices of models are often not explained. Why did you choose that form for c(o1, o2) in section 3.3? Why DCGAN for component generators, and U-net for decomposition?\n    \uf0a7\tIt is not explained in detail how the Yelp-reviews dataset is altered to achieve coherence. The authors mention that “As we sample a pair independently, the input sentences are not generally coherent but the coherence can be achieved with a small number of changes.”. However, the specific algorithm by which these changes are made is not specified, and thus it can’t be reproduced.\n3.\tThe theoretical section is an interesting contribution, but the paper just states a list of theorems without making any connections to the applications used before, or a broader discussion about how these fit in the context of GANs more generally.\n4.\tMy understanding is that both datasets used are created by the authors by making alterations to MNIST and Yelp-reviews dataset, thus making them to some extent synthetic datasets suited to fit this problem formulation. I would have like to see how this composition/decomposition works on existing datasets with no alterations. Does it still work? \n5.\tIn section 2.3, in the coherent sentence experimental setting, I don’t fully understand the design of the task. Figure 2 shows an example where composition and decomposition are not symmetric (i.e. composing then decomposing does not go back to the input sentences), although one of your losses is supposed to ensure exactly this cyclic consistency. Why not choose another problem that doesn’t directly violate your assumptions?\n\nMinor issues: \n6.\tFrom the related work section, it is not clear how your approach is different from Azadi et al. (2018). Please include more details.\n7.\tIn section 2.4, you mention using Wasserstein GANs, with no further details about this model (not even a one line description). Without reading their paper, the readers of your paper could not easily follow through this section. The losses further introduced are also not explained intuitively (e.g. what do the two expectation terms in l_g_i represent?).\n8.\tI believe there are some errors in which tasks reference which figures in section 3.3. Should Task 2 refers to Figure 6, and Task 3 to Figure 7?\n9.\tWhat exactly is range(.) in section 4? If this refers to the interval of values that a variable can take, the saying “is a matrix of size |range(Z)| × |range(Y )|” doesn’t exactly make sense. Please define formally. \n\nFinal remarks and advice: \nOverall, I believe the paper introduces some interesting ideas. There is definitely value in the problem definition and theoretical analysis. However, I believe the paper needs more work on presentation and evaluation, especially since the authors opted for 10 pages and according to ICLR guidelines “Reviewers will be instructed to apply a higher standard to papers in excess of 8 pages.”. Hopefully the above comments will help the authors improve this work!', '- There have been works on this before in the GAN literature, they have not been even cited, let alone being compared to in the experiments. Seminal examples include Donahue et al., ICLR 2018 ""Semantically decomposing the latent spaces of generative adversarial networks"", and (a bit less starkly in terms of the alignment with the goals of this paper): Huang et al., 2017 ""Stacked generative adversarial networks"". \n\n- In general, comparisons to state-of-the-art (or to other) algorithms are missing.\n\n- Is the assumptions of pre-trained components viable with image, and not text, data? Please elaborate\n\n- The related work section is missing out on dozens of  works, those on disentanglement or interpretability; what is the point then of making a related work section in the first place if only one single example of an algorithm in each broad topic is mentioned? If so, I would suggest mentioning this single example prior to the discussing the topic without a related work section, or (apparently the better option) to do a related work section with a rigorous coverage. Examples of some related works on disentanglement and interpretability: \nHiggins et al., ICLR 2017 ""beta-VAE"" - Kim & Mnih, ICML 2018 ""Disentangling by factorising"" - Adel et al., ICML 2018 ""Discovering interpretable representations for both deep generative and discriminative models"" - Chen et al., NIPS 2017 ""InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets"", etc.\n\n- The advantages promised in Section 1 are a little bit too presumptuous. Too many idealistic assumptions are need in order for these advantages to hold. For instance, extensibility has been mentioned as an advantage in Section 1 and in the abstract, and that has not been capitalised on, or confirmed in the experiments, or from this point onwards. \n\n- It will be interesting to see what happens with rather real-world cases like occlusion, etc\n\n- Writing has room for improvements, in terms of both the flow and also grammar, etc. There are a few typos. ', '[Overview]\n\nIn this paper, the authors studied the problem of composition and decomposition of GANs. Motivated by the observations that images are naturally composed of multiple layouts, the authors proposed a new framework to study the compositional image generation and its decomposition by defining several tasks. On those various tasks, the authors demonstrate the possibility of the proposed model to composing image components and decompose the images afterwards. These results are interesting and insightful to some extent.\n\n[Strengthes]\n\n1. The authors proposed a framework for compose images from components and decompose the images into components. Based on this new framework, the authors tried different settings, by fixing the learning of one or more modules in the model. The experiments on various tasks are appreciated.\n\n2. In the experiments, the authors tried both image and text to demonstrate the concepts in this paper. Moreover, some qualitative results are presented.\n\n[Weaknesses]\n\n1. The authors performed multiple experiments regarding various tasks defined in this paper.However, I can hardly find any quantitative evaluation for the results. It is not clear to me that how the quality of the composed images and the decomposed components from images are. I would suggest the authors derive some metric to measure quality quantitatively, provide some statistics on the whole datasets.\n\n2. In this paper, the authors proposed multiple tasks in terms of which parts are fixed and known in the training process. However, dominated by so many different tasks, the core idea is losses in the paper. From the paper, I cannot get the core idea the authors want to deliver. I would suggest the authors focus on one certain task and perform more qualitative and quantitative analysis and comparisons, as also mentioned above.\n\n3. The proposed model has several tricky parts. First, the number of components are pre-determined. However, in realistic cases, the number of components are unknown, and thus how many component generators should be used is ill-posed. Second, the composing operation is simple and tricky. Such a simple composing operation make it hard to adapt to some more complicated data, such as cifar10 or so. Thirdly, almost all tasks need some components known. Even for the Task 4, c is known, and the model performs poorly for generating the disentangled components.\n\n4. The authors missed one very relevant paper:\n\nLR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation. Yang et al.\n\nIn the above paper, the authors proposed an end-to-end model for generating images with background and foreground compositionally. It can be applied to a number of realistic datasets. Regardless of the decomposition part in this paper, the proposed method in the above paper seems to be clearly superior to the composition part in this paper considering this paper fails on Task 4. The authors should give credit to the above paper (even the synthesized MNIST dataset looks similar ) and pay some efforts to explain the advantages in comparison it.\n\n[Summary]\n\nThis paper proposed a new framework to study the compositionally of images during generation and decomposition. Through several experiments on various tasks, the authors presented some interesting results and provided some insights on the potentials and difficulties in this direction. However, as pointed above, I think this paper lacks enough experimental analysis and comparison. Its core idea hard to capture. Also, it missed a comparison to some related work.']","[-20, -70, -20]","[80, -20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting new problem formulation', 'simple and clear language'), they also highlight significant concerns about the paper's evaluation, lack of quantitative results, and missing details. The overall tone suggests the paper needs substantial improvements.\n\nThe politeness score is high (80) because the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'I believe', 'please include', and 'Hopefully the above comments will help the authors improve this work!'. The reviewer also balances criticism with positive remarks and provides detailed, actionable feedback without using harsh or dismissive language."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several significant shortcomings, such as missing citations, lack of comparisons to state-of-the-art algorithms, an inadequate related work section, and overly presumptuous claims. There are no positive comments to balance these criticisms. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the feedback. Phrases like 'too presumptuous' and 'what is the point then' come across as somewhat harsh. However, the reviewer does use some neutral language and offers constructive suggestions, preventing the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths and interesting aspects of the paper, they also point out several significant weaknesses and areas for improvement. The review begins with a neutral tone but becomes more critical as it progresses, especially in the 'Weaknesses' section. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They use phrases like 'I would suggest' and 'The authors should' rather than using harsh or dismissive language. The reviewer also acknowledges the positive aspects of the work before delving into criticisms, which is a polite approach to peer review.""]"
"['This paper presents a thorough and systematic study of the effect of pre-training over various NLP tasks on the GLUE multi-task learning evaluation suite, including an examination of the effect of language model-based pre-training using ELMo. The main conclusion is that both single-task and LM-based pre-training helps in most situations, but the gain is often not large, and not consistent across all GLUE tasks.\n\nThis paper represents an impressive amount of experimentation. The study and the experimental results will be useful and interesting to the community. The result that some tasks\' performance are negatively correlated with each other is surprising. The paper is clearly written. \n\nOne clarification question I have is about what the ""Single-task"" pre-training means. The paper seems to suggest that it consists of pre-training a model on the same task on which it is later evaluated. I\'m confused by what this means, and how this is different from just training on that task. ', ""Only a handful of NLP tasks have an ample amount of labeled data to get state-of-the-art results without using any form of transfer learning. Training sentence representation in an unsupervised manner is hence crucial for real-world NLP applications.\nContextualized word representations have gained a lot of interest in recent years and the NLP and ML community could benefit from such detailed comparison of such methods.\n\nThis paper's biggest strength is the experimental setting.  The authors cover a lot of ground in comparing a lot of the recent work, both qualitatively and quantitatively -- there are a lot of experiments.\nI do understand the computational limitations of the authors (as they mention on HYPERPARAMETER TUINING) and I do agree with their statement “ The choice not to tune limits our ability to diagnose the causes of poor performance when it occurs”.\nExtensive hyper-parameter tuning can make a substantial different when dealing with NN models, maybe the authors should have considered dropping some of the tasks (the article has more than enough IMHO) and focus on a smaller sub set of tasks with proper hyper-parameter tuning.\nTable 2 is very interesting, the results suggesting that we are indeed very far from fully robust sentence representation method. \n"", 'The work presented in this paper relates to the impact of the dataset on the performance of contextual embedding (namely ELMO in this paper) on many downstream tasks, including GLUE tasks, but also alternative NLP tasks.\n\nThe work is focused on experiments, and draws several conclusions that are interesting, mostly around the amount of gain one can expect and the fact that the choice of the dataset is task-dependent. \n\nOne of the issue is that the authors if seems to believe that ELMO is the best contextual language model. The field is moving so quickly that the experiments might become invalid pretty soon (e.g. see BERT model referenced below).\n\nFinally, the analysis is mostly descriptive and there is few insight by the author about what should be the future work, apart from ""we need a better understanding"".\n\n\nMinor details:\n\nPage 1: ""can yield very strong performance on NLP tasks"" is a very busy way to express the fact that Sentence Encoders work well in practice. \n\nThe field evolves quickly and ELMO has now a competitive models called BERT (arXiv.org\xa0>\xa0cs\xa0> arXiv:1810.04805). I understand that the results of the current papers would hove to be re-run on all these tasks, but I\'m afraid the current paper will have a limited impact if it does not use the most effective method at the date of publication...']","[80, 60, -20]","[70, 70, 50]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'thorough and systematic', notes the 'impressive amount of experimentation', and states that the results will be 'useful and interesting to the community'. The reviewer also praises the clear writing. The only slight negative is a request for clarification on one point. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the value of the work and offering constructive feedback. The tone is professional and courteous, with phrases like 'This paper represents an impressive amount of experimentation' demonstrating respect for the authors' work. The clarification question at the end is posed politely, without criticism."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's experimental setting, calling it the 'biggest strength' and noting that it covers 'a lot of ground' with 'a lot of experiments'. They also mention that the NLP community could benefit from such a detailed comparison. However, it's not extremely positive as they suggest some improvements, like focusing on fewer tasks with better hyperparameter tuning. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' computational limitations and agreeing with some of their statements. They offer constructive criticism in a gentle manner, using phrases like 'maybe the authors should have considered' rather than making demands. The tone is professional and courteous throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the work, they also point out several limitations and issues. The reviewer mentions that the experiments might become invalid soon due to rapid advancements in the field, and that the analysis lacks insight into future work. However, they do recognize the interesting conclusions drawn from the experiments. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting conclusions' and offer constructive criticism without harsh language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer feedback. The overall tone is academic and objective, avoiding personal attacks or overly negative language.""]"
"['This paper presents a new approach in network quantization. The key insights of this paper is quantizing different layers with different bit-widths, instead of using fixed 32-bit width for all layer weights and activation in previous works. At the same time, this paper adopted the idea form both DARTS and ENAS with parameter sharing, and introduces a new differentiable neural architecture search framework. As the authors proposed, this DNAS framework is able to search efficiently and effective through a large search space.  As demonstrated in the Experiment section of the paper, it achieves better validation accuracy than ResNet with much smaller model size and lower computational cost.\n\n1. An improved gradient method in updating the network architecture and parameters compared to DARTS and ENAS. It applies the Gumbel softmax to refine the sub-graph structure without training the entire super-net through the whole process. The work is able to obtain the same level of validation accuracy on Cifar-10 as ResNet while reduce the model parameters by a large margin. \n2. The work is in the middle ground of two previous works: ENAS by Pham et al. (2018) and DARTS by Liu et al. (2018). However, there is no comparison with ENAS and DARTS in experiments. ENAS samples child networks from the super net to be trained independently while DARTS trains the entire super net together without decoupling child networks from the super net. By using Gumbel Softmax with an annealing temperature, The proposed DNAS pipeline behaves more like DARTS at the beginning of the search and behaves more like ENAS at the end. \n', 'In this work the authors introduce a new method for neural architecture search (NAS) and use it in the context of network compression. Specifically, the NAS method is used to select the precision quantization of the weights at each layer of the neural network. Briefly, this is done by first defining a super network, which is a DAG where for each pair of nodes, the output node is the linear combination of the outputs of all possible operations (i.e., layers with different precision quantizations). Following [1], the weights of the linear combination are regarded as the probabilities of having certain operations (i.e., precision quantization), which allows for learning a probability distribution over the considered operations. Differently from [1], however, the authors bridge the soft sampling in [1] (where all operations are considered together but weighted accordingly to the corresponding probabilities) to a hard sampling (where a single operation is considered with the corresponding probability) through an annealing procedure based on the Gumbel Softmax technique. Through the proposed NAS algorithm, one can learn a probability distribution on the operations by minimizing a loss that accounts for both accuracy and model size. The final output of this search phase is a set of sampled architectures (containing a single operation at each connection between nodes), which are then retrained from scratch. In applications to CIFAR-10 and ImageNet, the authors achieve (and sometime surpass) state-of-the-art performance in model compression.\n\nThe two contributions of this work are\n1)\tA new approach to weight quantization using principles of NAS that is novel and promising;\n2)\tNew insights/technical improvements in the broader field of NAS. While the utility of the method in the more general context of NAS has not been shown, this work will likely be of interest to the NAS community.\n\nI only have one major concern. The architectures are sampled from the learnt probability distribution every certain number of epochs while training the supernet. Why? If we are learning the distribution, would not it make sense to sample all architectures only after training the supernet at our best?\nThis reasoning leads me to a second question. In the CIFAR-10 experiments, the authors sample 5 architecture every 10 epochs, which means 45 architectures (90 epochs were considered). This is a lot of architectures, which makes me wonder: how would a “cost-aware” random sampling perform with the same number of sampled architectures?\n\nAlso, I have some more questions/minor concerns:\n\n1)\tThe authors say that the expectation of the loss function is not directly differentiable with respect to the architecture parameters because of the discrete random variable. For this reason, they introduce a Gumbel Softmax technique, which makes the mask soft, and thus the loss becomes differentiable with respect to the architecture parameters. However, subsequently in the manuscript, they write that Eq 6 provides an unbiased estimate for the gradients. Do they here refer to the gradients with respect to the weights ONLY? Could we say that the advantage of the Gumbel Softmax technique is two-fold? i) make the loss differentiable with respect to the arch parameters; ii) reduce the variance of the estimate of the loss gradients with respect to the network weights.\n\n2)\tCan the author discuss why the soft sampling procedure in [1] is not enough? I have an intuitive understanding of this, but I think this should be clearly discussed in the manuscript as this is a central aspect of the paper.\n\n3)\tThe authors use a certain number of warmup steps to train the network weights without updating the architecture parameters to ensure that “the weights are sufficiently trained”. Can the authors discuss the choice on the number of warmup epochs?\n\nI gave this paper a 5, but I am overall supportive. Happy to change my score if the authors can address my major concern.\n\n[1] Liu H, Simonyan K, Yang Y. Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055. 2018 Jun 24.\n\n-----------------------------------------------------------\nPost-Rebuttal\n---------------------------------------------------------\nThe authors have fully addressed my concerns. I changed the rating to a 7.\n', 'The authors propose a network quantization approach with adaptive per layer bit-width. The approach is based on a network architecture search (NAS) method. The authors aim to solve the NAS problem through SGD. Therefore, they propose to first reprametrize the the discrete random variable determining if an edge is computed or not to make it differentiable and then use Gumbel Softmax function as a way to effectively control the variance of the obtained unbiased estimator. This variance can indeed make the convergence of the procedure hard. The procedure is then adapted to the problem of network quantization with different band-widths.\n\nThe proposed approach is interesting. The differerentiable NAS procedure is particularly important and can have an important impact. The idea of having an adaptive per layer precision is also well motivated, and shows competitive (if not better) results empirically. \n\nSome additional experiments can make the paper stronger:\n* Compare the result of the procedure to an exhaustive search in a setting where the latter is feasible (shallow architecture on an easy task with few possible bit widths)\n* Compare the procedure to other state of the art NAS procedures (DARTS and ENAS) with the same search space adapted to the quantization problem, to empirically show that the proposed procedure is a compromise between these two methods as claimed by the authors. ', 'The paper approaches the bit quantization problem from the perspective of neural architecture search, by treating each possible precision as a different type of neural layer. They estimate the proportion of each layer using a gumbel-softmax reparametrization. Training updates parameters and these proportions alternately. \n\nThe authors claim that prior work has only dealt with uniform bit precision. This is clearly false e.g. \nhttps://arxiv.org/pdf/1807.00942.pdf\nhttps://arxiv.org/abs/1708.04788\nhttps://arxiv.org/pdf/1705.08665.pdf\n\nIn particular, https://arxiv.org/pdf/1807.00942.pdf uses the same approach, using gumbel-softmax to estimate the best number of bits. In the least, the authors needs to mention and contrast their approach, e.g. they can handle a budget constraint, but they use a fixed quantization function.\n\nThere is an inherent strength in this approach that the authors have not fully explored. The most recent key discovery in low precision networks is that the optimal parameters take very different values depending on the precision, ie beyond simple clipping/snapping based on quantization error. The DNAS approach can capture this, because the parameters of different precisions need not be constrained via a fixed quantization/activation function (appendix B). Therefore the following questions become important to understand.\n\n1. How are the weights w updated for low precision. I understand that you first sample an architecture but there is no explanation of how the low bit (e.g. 1-bit) weights are updated. Do you update the 32-bit weights, then use the functions in Appendix B to derive the low bit parameters? This is much less interesting than the power of the DNAS idea. Do you directly update them using STE?\n2. Why is it important to train in an alternating fashion? How did you split the training set in to two for each ? Why not use a single training set?\n3. Are the ""edge probabilities"" over different precision in any way the function of the input (image)? It seems your approach is able to distinguish ""easy"" and ""hard"" images by increasing the precision of parameters. If so, this should be explained and demonstrated. \n4. In Eq (10), it is unusual to take the product of network performance and penalty term for parsimony. This needs to be explained vs. taking a sum of the two terms which has the nice interpretation of being the lagrangian of a constrained optimization problem. Do you treat these as instance level weights? \n5. Experiments only show ResNet architecture, whereas prior work showed a broaded set of results. Only TTQ and ADMM is compared, where the most relevant work is https://arxiv.org/pdf/1807.00942.pdf. It is not clear if the good performance comes due to the block connectivity structure with skip connections, combined with the fact that the first and last layers are not quantized. ']","[80, 60, 70, -50]","[50, 80, 80, 0]","[""The sentiment score is 80 (positive) because the review begins with a positive overview of the paper's contributions, highlighting its novel approach and effectiveness. The reviewer notes the paper's key insights, its adoption of ideas from previous works, and its demonstrated improvements in accuracy and efficiency. The politeness score is 50 (slightly polite) because the language used is professional and respectful, without being overly formal or effusive. The reviewer provides constructive feedback and acknowledges the paper's strengths, while also pointing out areas for potential improvement or comparison in a neutral tone. The review maintains a balanced and objective stance throughout, which contributes to its overall polite and professional tone."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall support for the paper, stating they are 'overall supportive' and even increased their rating after the authors addressed their concerns. However, they did raise some questions and concerns, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, asks questions in a constructive manner, and acknowledges the paper's contributions. They also express willingness to change their score based on the authors' response, which shows flexibility and respect. The reviewer maintains a professional and courteous tone, even when raising concerns or asking for clarifications."", ""The sentiment score is 70 (positive) because the reviewer describes the proposed approach as 'interesting' and states that it 'can have an important impact'. They also mention that the idea is 'well motivated' and shows 'competitive (if not better) results empirically'. The overall tone is supportive and appreciative of the work. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the potential impact of the work and offering constructive suggestions for improvement without any harsh criticism. The reviewer's tone is professional and courteous, providing balanced feedback that recognizes the strengths of the paper while suggesting ways to make it 'stronger'."", ""The sentiment score is -50 because the review is generally critical, pointing out several significant issues with the paper, such as false claims about prior work and unexplored strengths of the approach. However, it's not entirely negative as it acknowledges some potential in the method. The politeness score is 0 (neutral) because the language is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly but constructively, asking questions and suggesting improvements rather than dismissing the work outright. The tone is matter-of-fact and focused on scientific merit rather than personal comments.""]"
"['The paper presents a method for training a probabilistic model for Multitask Transfer Learning. The key idea is to introduce a latent variable ""z"" per task which to capture the commonality in the task instances. Since this leads to an intractable likelihood the authors use the standard ELBO with a Variational Distribution over ""z"" defined as a Gaussian + Inverse Autoregressive Flow. For classification, the authors also show that they can combine the model with the main idea in Prototypical Networks. \n\nThe experiments evaluate on three different task, the comparison against MAML on the toy problem is quite interesting. However, the results on the Mini-Imagenet suggest that the main contributors to the better performance are the Prototypical Networks idea and the improved ResNet. Additionally, the authors compare against MAML only on the toy task and not on their synthetic dataset. I think that the experiments need better comparisons (there have been published an improved version of MAML, or even just add results from your own implementation of MAML with the same ResNet on the 3rd task as well). \n\nA major issue is that the model presented is not really a Hierarchical Bayesian model as being strongly presented. It is much more a practical variational algorithm, which is not bad by no means, but I find its ""interpretation"" as a Hierarchical Bayesian method as totally unnecessary and making the paper significantly harder to read and follow than it needs to be. This is true for both the base model and the model + ProtoNet. I think that the manuscript itself requires more work as well as a better comparison of the method to baseline algorithms.\n\n\nSection 2.2:\n\nThe authors start by introducing a ""Hierarchical Bayes"" model over the parameters of a Neural Network for multi-task learning. By defining the model parameters to be an implicit function of some low-dimensional noise and the hyper-parameter they shift the inference to the noise variable ""z"". One issue, which I won\'t discuss further, is that this defines a degenerate distribution over the parameters (a fact well known in the GAN literature), which seem counter-intuitive to call ""Bayesian"". Later, since the parameters ""w"" has vanished from the equation the authors conclude that now they can change the whole graphical models such that there is actually no distribution over the parameters of a Neural Network, while the hyper-parameter IS now the parameters of a Neural Network and the latent variable is an input to it. Mathematically, the transformation is valid, however, this no longer corresponds to the original graphical model that was described earlier. The procedure described here is essentially a Variational Model with latent variable ""z"" for each task and the method performs a MAP estimation of the parameters of the Generative Model by doing Variational Inference (VAE to be exact) on the latent ""z"". There is nothing bad about this model, however, the whole point of using a ""Hierarchical Bayes"" for the parameters of the Network serves no purpose and is significantly different to the actual model that is proposed. \n\nIn section 2, the prior term p(a) in equation 7 and Algorithm 1 is missing.\n\nSection 3:\n\nThe authors argue that they add yet another level of hierarchy in the Graphical Model with a further latent variable ""v"", which is unclear fundamentally why you need it as it can be subsumed inside ""z"" (from a probabilistic modelling perspective they play similar roles). Additionally, they either do not include a prior or on ""v"" or there is a mistake in the equation for p(S|z) at the bottom of page 4. The main motivation for this comes from the literature where for instance if we have a linear regression and ""v"" represents the weights of the last linear layer with a Gaussian Prior than the posterior over ""v"" has an analytical form. After this whole introduction into the special latent variable ""v"", the authors actually use the idea from Prototypical Networks. They introduce a valid leave-one producer for training. However, the connection to the latent variable ""v"" which was argued to be the third level of a Hierarchical Bayes model is now lost, as the context c_k is no longer a separate latent variable (it has no prior and in the original Prototypical Network although the idea can be interpreted in a probabilistic framework it is never presented as a Hierarchical Bayes).  \n\n', 'The authors state that their goal with this paper is manifold:\nThey want to learn a prior over neural networks for multiple tasks. The posterior should go beyond mean field inference and yield good results.  The authors claim in their paper that they learn an \'expressive transferable prior over the weights of a network\' for multi-task settings, which they denote with the unfortunate term \'deep prior\'.\n\nIn sec. 2.1 the authors introduce the idea of a hierarchical probabilistic model of weights for a neural network p(W|a) conditioned on task latent variables p(a). They realize that one might want to generate those weights with a function which conditions on variable ""z"" and has parameters ""a"". They continue their argument in Sec 2.2 that since the weight scoring can be canceled out in the ELBO, the score of the model does not depend on weights ""w"" explicitly anymore.\nThis, of course, is wrong, since the likelihood term in the ELBO still is an expectation over the posterior of q(w|z)q(z). \nHowever, the authors also realize this and continue their argumentation as follows:\nIn this case -according to the authors- one may drop the entire idea about learning distributions over weights entirely.\nThe math says: p(y|x ; a) = int_z p(z) int_w p(w|z ; a) p(y|x, w)dw dz.\nSo the authors claim that a model p(y|x, z) which only conditions on \'z\' is the same as the full Bayesian Model with marginalized weights. They then suggest to just use any neural network with parameters ""a"" to model this p(y|x, z ;a) directly with z being used as an auxiliary input variable to the network with parameters ""a"" and claim this is doing the same. This is of course utterly misleading, as the parameter ""a"" in the original model indicated a model mapping a low dimensional latent variable to weights, but now a maps to a neural network mapping a latent variable and an input vector x to an output vector y. As such, these quantities are different and the argument does not hold. Also a point estimate of said mapping will not be comparable to the marginalized p(y|x).\n\nWhat is more concerning is that the authors claim this procedure is equivalent to learning a distribution over weights and call the whole thing a deep prior, while this paper contains no work on trying to perform the hard task of successfully parametrizing a high-dimensional conditional distribution over weights p(w|z) (apart from a trivial experiment generating all of them at once  from a neural network for a single layer in a failed experiment) but claims to succeed in doing so by circumventing it entirely. \n\nIn their experiments, the authors also do not actually successfully try to really learn a full distribution over the weights of a neural network. This alone suffices to realize that the paper appears to be purposefully positioned in a highly misleading way and makes claims about weight priors that are superficially discussed in various sections but never actually executed on properly in the paper.\nThis is a disservice to the hard work many recent and older papers are doing in actually trying to derive structured hierarchical weight distributions for deep networks, which this paper claims is a problem they find to be \'high dimensional and noisy\', which is exactly why it is a valid research avenue to begin with that should not be trivially subsumed by work such as this.\n\nWhen reducing this paper to the actual components it provides, it is a simple object: A deterministic neural network with an auxiliary, task-dependent latent variable which provides extra inputs to model conditional densities.\nSuch ideas have been around for a while and the authors do not do a good job of surveying the landscape of such networks with additional stochastic input variables.\nOne example is ""Learning Stochastic Feedforward Neural Networks"" by Tang and Salakhutdinov, NIPS 2013, a more recent one is ""Uncertainty Decomposition in Bayesian Neural Networks with Latent Variables"" by Depeweg et al 2017.\nAn obvious recent example of multi-task/meta/continual learning comparators would be ""VARIATIONAL CONTINUAL LEARNING"" by Nguyen et al. and other work from the Cambridge group that deals with multi-task and meta-learning and priors for neural networks.\n\nAnother weakness of the paper is that the main driver of success in the paper\'s experiment regarding classification is the prototypical network idea, rather than anything else regarding weight uncertainty which seems entirely disentangled from the core theoretical statements of the paper.\n\nAll in all, I find this paper unacceptably phrased with promises it simply does not even attempt to keep and a misleading technical section that would distort the machine learning literature without actually contributing to a solution to the technical problems it claims to tackle (in relation to modeling weight uncertainty/priors on NN). Paired with the apparent disinterest of the authors to cite recent and older literature executing strongly related underlying ideas combining neural networks with auxiliary latent variables, I can only recommend that the authors significantly change the writing and the attribution of ideas in this paper for a potential next submission focusing on multi-task learning and clarify and align the core ideas in the theory sections and the experiment sections.\n', 'Strengths:\n+ A variational approach to meta-learning is timely in light of recent approaches to solving meta-learning problems using a probabilistic framework.\n+ The experimental result on a standard meta-learning benchmark, miniImageNet, is a significant improvement.\n\nWeaknesses:\n- The paper is motivated in a confusing manner and neglects to thoroughly review the literature on weight uncertainty in neural networks.\n- The SotA result miniImageNet is the result of a bag-of-tricks approach that is not well motivated by the main methodology of the paper in Section 2.\n\nMajor points:\n- The motivation for and derivation of the approach in Section 2 is misleading, as the resulting algorithm does not model uncertainty over the weights of a neural network, but instead a latent code z corresponding to the task data S. Moreover, the approach is not fully Bayesian as a point estimate of the hyperparameter \\alpha is computed; instead, the approach is more similar to empirical Bayes. The submission needs significant rewriting to clarify these issues. I also suggest more thoroughly reviewing work on explicit weight uncertainty (e.g., https://arxiv.org/abs/1505.05424 , http://proceedings.mlr.press/v54/sun17b.html , https://arxiv.org/abs/1712.02390 ).\n- Section 3, which motivates a combination of the variational approach and prototypical networks, is quite out-of-place and unmotivated from a probabilistic perspective. The motivation is deferred to Section 5 but this makes Section 3 quite unreadable. Why was this extraneous component introduced, besides as a way to bump performance on miniImageNet? \n- The model for the sinusoidal data seems heavily overparameterized (12 layers * 128 units), and the model for the miniImageNet experiment (a ResNet) has significantly more parameters than models used in Prototypical Networks and MAML.\n- The training and test set sampling procedure yields a different dataset than the one used in e.g., MAML or Prototypical Networks. Did the authors reproduce the results reported in Table 1 using their dataset?\n\nMinor points:\n- abstract: ""variational Bayes neural networks"" -> variational Bayesian neural networks, but also this mixes an inference procedure with just being Bayesian\n- pg. 1: ""but an RBF kernel constitute a prior that is too generic for many tasks"" give some details as to why?\n- pg. 2: ""we extend to three level of hierarchies and obtain a model more suited for classification"" This is not clear.\n- pg. 2: "" variational Bayes approach"" -> variational Bayesian approach OR approach of variational Bayes\n- pg. 2: ""scalable algorithm, which we refer to as deep prior"" This phrasing is strange to me. A prior is an object, not an algorithm, and moreover, the word ""deep"" is overloaded in this setting.\n- pg. 3: ""the normalization factor implied by the ""∝"" sign is still intractable."" This is not good technical presentation.\n- pg. 3: ""we use a single IAF for all tasks and we condition on an additional task specific context cj"" It might be nice to explore or mention that sharing parameters might be helpful in the multitask setting...\n- Section 2.4 describes Robbins & Munro style estimation. Why call this the ""mini-batch"" principle?']","[-40, -80, -50]","[20, -30, 20]","[""The sentiment score is -40 because the review is generally critical, pointing out several issues with the paper, including the need for better comparisons, concerns about the model's interpretation, and the need for more work on the manuscript. However, it's not entirely negative as it acknowledges some interesting aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout, using phrases like 'I think' and 'The authors argue' rather than making blunt accusations. They also acknowledge positive aspects, such as the 'quite interesting' comparison against MAML on the toy problem. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone."", ""The sentiment score is -80 because the reviewer is highly critical of the paper, pointing out numerous flaws and misleading claims. They use strong negative language like 'utterly misleading', 'disservice', and 'unacceptably phrased'. The reviewer recommends significant changes and clarifications, indicating a very negative view of the paper's current state. The politeness score is -30 because while the reviewer maintains a professional tone overall, there are instances of harsh criticism and implications of intentional misrepresentation by the authors (e.g., 'purposefully positioned in a highly misleading way'). The language is not overtly rude, but it is more direct and critical than a typical polite academic review, especially in the concluding paragraph."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths ('timely' approach, 'significant improvement' in results), they list more weaknesses and major points of criticism. The review is overall critical, pointing out issues with motivation, methodology, and presentation. The politeness score is 20 because the reviewer uses professional language and provides constructive feedback, but doesn't use overtly polite phrases. They directly state weaknesses and issues, but do so in a respectful, academic tone. The reviewer also offers suggestions for improvement, which adds to the politeness.""]"
"['Focus on navigation problems, this paper proposes Q-map, a neural network that estimates the number of steps (in terms of the discount factor gamma) required to reach any position on the observable screen/window. Moreover, it is shown that Q-map can be applied for exploration, by trying to reach randomly selected goal.\n\nPros\n1. Novel goal-based exploration scheme\n\nCons\n1. Similar idea has been proposed before\nFor example, Dayan (1993) estimates the number of steps to reach any position on the map using successor representations. Discussion about this field (successor representations/features) is completely missing in the paper.\nRef:\n- Peter Dayan. Improving generalization for temporal difference learning: The successor representation. Neural Computation, 5(4):613–624, 1993.\n- Andre Barreto, Will Dabney, Remi Munos, Jonathan J Hunt, Tom Schaul, David Silver, and Hado van Hasselt. Successor features for transfer in reinforcement learning. In Advances in Neural Information Processing Systems, pp. 4058–4068, 2017.\n- Andre Barreto, Diana Borsa, John Quan, Tom Schaul, David Silver, Matteo Hessel, Daniel Mankowitz, Augustin Zidek, and Remi Munos. Transfer in deep reinforcement learning using successor features and generalised policy improvement. In International Conference on Machine Learning, pp. 510–519, 2018.\n\n2. Comparison to existing methods is only vaguely discussed\nFor example, it is claimed multiple times that UVFA requires the goal coordinates, but Q-map also requires coordinates when doing the exploration.\n\n3. The network architecture is not clearly presented\nFor example, the output of the network needs to be clipped, which suggests that there is no output transform. Since the predicted output is in [0,1], it would make sense to use Sigmoid transform for each pixel and use logistic loss.\n\n4. The proposed exploration scheme could be unnecessarily complicated\nSec.3.1 provides lengthy discussion about the drawback of eps-greedy exploration. Then in Sec.3.2, \\epsilon_r is basically the same as the eps-greedy algorithm, using to randomly select an action. Isn\'t this a ""bad"" thing as suggested in Sec.3.1? Moreover, the new exploration scheme requires two more hyper-parameters (min/max distance threshold), which will add more complication to the already very complicated deep RL learning procedure.\n\n5. Experiment results are limited\nFor the toy experiment in Sec.2.3, the map are relatively simple. The example of Dayan (1993) with an agent surrounded by walls is an interesting scenario and should be included. The proposed Q-map (ConvNet) could fail because it is hard to learn geodesic distance with only local information. More importantly, there is no comparison to similar methods in Sec.3. UVFA can replace Q-map to do similar exploration.\n\n6. Writing can be greatly improved\nThere are many grammar errors. To name a few, ""agent capable to produce"", ""the gridworld consist of"", ""in the thrist level"".\n\nMinors\n- UFV should be UVF in the introduction\n- Citation in Sec.3 is not consistent with the rest of the paper. Use \\citep or \\citet properly.', 'The main idea in the paper is to use on-screen locations as goals for an RL agent. Using a de-convolutional network to parameterize the Q-function allows all goals to be updated at once and correlations between nearby or similar goal locations could be modelled. The paper explores how this type of goal space can be used for better exploration showing modest improvement in scores on Super Mario.\n\nClarity - The paper is well written and easy to follow. The Q-map architecture is well motivated and intuitive and the exploration strategy based on Q-maps is interesting.\n\nNovelty - The idea of using spatial goals combined with a de-convolutional architecture is not new and goes back at least to “Reinforcement Learning with Unsupervised Auxiliary Tasks” by Jaderberg et al.. The UNREAL agent used the same type of de-convolutional “Q-map” to update a spatial grid of goals all at once. The main difference is that the UNREAL agent learns about spatial goals as an auxiliary task and does not execute/act on the goals like the Q-map agent. Nevertheless, the type of architecture and algorithm (called 3D Q-learning in this paper) is essentially the same.\n\nSignificance - The Q-map architecture requires access to the position of the avatar on the screen at training time. I would expect that using such a significant part of the agent’s true state during training should lead to a significant improvement in performance at test time. Why not evaluate the proposed exploration strategy on well known hard exploration tasks? The results on Montezuma’s Revenge are only qualitative. There Q-map agent did outperform an epsilon-greedy DQN baseline on Super Mario but the improvement does not seem very significant given how much prior knowledge Q-map was given compared to the baseline. It is also not clear how much of the improvement comes from training the Q-map as an auxiliary task and how much of it comes from better exploration.\n\nOverall quality - Given that the architecture is not very novel and requires the avatar’s position to train I did not find the qualitative or quantitative results compelling enough. Perhaps the authors could show that the exploration strategy works well on several difficult exploration games. Another possibility would be to showcase other ways to use the Q-map, for example in an HRL setup.\n\nMinor comment - Some sections seem to be missing references. For example, the second paragraph of the introduction discusses GVFs and the Horde architecture without any references.', 'Authors propose to overcome the sparse reward problem using an exploration strategy that incentivizes the agent to visit different parts of the game screen. This is done by building Q-maps, a 3D tensor that measures the value of the agent\'s current state (defined as the position of the agent) and action in reaching other (x, y) locations in the map. Each 2D slice of the Q-map measures the value at different (x, y) locations for one action. Such 2D slices (i.e. channels) are stacked together to form the Q-map. Taking the max across the channels, thus, provides the Q-value for the optimal action. \n\nA policy for maximizing the rewards is trained using DQN. The Q-map based exploration is used as a replacement for \\epsilon-greedy exploration. \n\nThe Q-map is used for exploration in the following way:\n(a) Chose a random action with probability \\epsilon_r. \n(b) If neither a random action nor a ""goal"" is chosen, a new goal is chosen with probability \\epislon_g. The goal is a (x, y) location, chosen so that is not too hard or too easy to reach it (i.e. Q-map values are neither too high or low; intuitively [1 - Q-map(x, y, a)] (for normalized/clipped Q) is a measure of distance of the goal).  \n     -- If a ""goal"" is chosen, the greedy action to go towards the goal is chosen. \n(c) If neither a goal or random action is chosen, DQN is used to chose the greedy exploration. \n\nAuthors also bias the goal selection to match DQN\'s greedy action. This is done as following -- from a set of goals that satisfy (b) above; chose the goal for which Q-map selected action matches the DQN\'s greedy action. \n\nResults are presented on simple 2D maze environments, Mario and Montezuma\'s revenge. \n\nI have multiple concerns with the papers:\n(i) The writing is informal and the ideas are not well explained. It would really benefit -- if authors introduce an algorithm box or talk about the method as a sequence of points. Right now, the ideas are scattered throughout the paper. I am still confused by figure 3 -- when are random goals chosen? Do random goals correspond to (b) above? Also, when the Horde architecture, GVF and UVF are mentioned, the references are missing -- I would love for the authors to include the corresponding  references.  \n\n(ii) The idea of reaching as many states as possible has been explored in count based visitation (Bellemare et al, Tang et al) — but no comparisons have been made to any previous work. Its always good to put a new work in the perspective of old work with similar ideas. \n\n(iii) The authors propose biased and random goal sampling — I would love to see how much improvement does biased goal sampling offer over random goal sampling. \n\n(iv) “…compare the performance of our proposed agent and a baseline DQN with a similar proportion of exploratory actions” .. I don’t agree with this a metric — I think the total number of steps is a good metric. Exploration is part of the agent’s algorithm to find the goal, we shouldn’t compare against DQN by matching the number of exploratory actions. \n\n(v) “The Q-map is trained with transitions generated by randomly starting from any free locations in the environment and taking a random action.” Does this mean that when the agent is trained with Mario — the game is reset after every episode and the agent is placed a random starting location? If yes, then this is not a realistic assumption. \n\n(vi) I would like to see — how do Q-maps generalize across levels of Mario or Montezuma’s revenge? Does Q-map trained on level-1 help in good exploration on future levels without any further fine-tuning? \n\nOverall, I like the idea of incentivizing exploration without changing the reward function as is done in multiple prior works. However, I think more thorough quantitative evaluation is required and it will be interesting to see transfer of Q-maps outside the 2D-domains. I am happy to increase my score if such evidence is provided. \n\nOther references worth including:\n(a) Strategies for goal generation: Automatic Goal Generation for Reinforcement Learning Agents (https://arxiv.org/abs/1705.06366) ']","[-50, -20, -20]","[20, 60, 60]","[""The sentiment score is -50 because while the reviewer acknowledges a 'novel goal-based exploration scheme' as a pro, they list several significant cons that outweigh this single positive point. These include similar ideas being proposed before, lack of comparison to existing methods, unclear network architecture, unnecessarily complicated exploration scheme, limited experimental results, and poor writing quality. The overall tone suggests the paper needs substantial improvements.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to describe the issues. They frame criticisms as 'Cons' rather than direct attacks, and use phrases like 'could be' and 'suggests that' to soften their critiques. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a fairly neutral, matter-of-fact tone overall."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'easy to follow', 'interesting'), they express significant concerns about novelty and significance. The reviewer states that the architecture is 'not very novel' and the results are not 'compelling enough', indicating overall disappointment with the paper's contribution. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and offering constructive suggestions for improvement. They avoid harsh or dismissive language, instead using phrases like 'I did not find' and 'Perhaps the authors could', which maintain a polite and professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('I like the idea of incentivizing exploration without changing the reward function'), they express multiple concerns and suggest that 'more thorough quantitative evaluation is required'. The overall tone indicates that significant improvements are needed before the reviewer would be satisfied.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would love to see' and 'I am happy to increase my score if such evidence is provided', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects of the work before presenting criticisms, which is a polite approach. However, the score is not extremely high as the review is direct in its criticisms without excessive softening language.""]"
"['\nPros:\nI also study some related tasks and suspect that Wasserstein is helpful for measuring co-occurrence-based similarity. It is nice to see the effort in this direction. \n\nCons:\nThe methods are either not very novel or not very well-motivated. The experiment results are interesting but mixed. If the doubts about the experiments are clarified and the methods are motivated better (or the strengths/weaknesses are better analyzed), I will vote for acceptance.\n\nRelated work:\nIn addition to the work in the related work section, some other work also studied the NLP applications of Wasserstein, especially the ones (such as [1,2,3]) which are related to similarity measurement. The authors should include them in the related work section. \n\nQuestion about experiments:\n1. Why are the SIF scores reported in Table 1 much lower than the results reported in Arora et al., 2017 and in [4]?\n2. If we compare CMD with DIVE + C * delta S, the proposed method wins in EVALution and Weeds, loses in Baroni, Kotlerman, BLESS, and Levy. If you compare DIVE + delta S (Chang et al. 2017) with DIVE + C * delta S, delta S also wins in EVALution and Weeds, loses in Baroni, BLESS, Kotlerman, and Levy (although CMD seems to be better than DIVE + delta S). \nBased on the fact that your method has a high correlation with DIVE + delta S (Chang et al. 2017), I guess that CMD does not work very well when the dataset contains random negative samples, but work well when all the negative samples are similar to the target words. If my guess is right, the performance should be improved on average if you multiply the scores from CMD with the word similarity measurement.\n3. To make it efficient, CMD seems to sacrifice some resolutions by using the K representative context. Does this step hurt the performance? Could you provide some performance comparison with different numbers of K to let readers know whether there is a tradeoff between accuracy and efficiency?\n4. Since the results are mixed, I suppose readers would like to know when this method will perform better and the reasons for having worse results sometimes.\n\nWriting and presentation suggestions/questions:\n1. If the proposed method is a breakthrough, I am fine with the title but I think the experiment results tell us that Wasserstein is not all you need. I understand that everyone wants to have an eye-catching title for their paper. The title of this paper indeed serves this purpose. Since the strategy is effective, more and more people might start to write papers with a title like this. However, having lots of paper called ""XXX is all you need?"" or ""Is XXX all you need?"" is definitely not good for the whole community. Please use a more specific title such as Context Mover Distance or something like that.\n2. The last point in the contribution is not supported by experiments. I suggest that the authors move this point to the future work section.\n3. It is good to see some negative results like Baroni in Table 2. Results on other datasets should not be put into Table 4 in Appendix.\n4. Using Wasserstein barycenter to measure sentence similarity seems to be novel, but the motivation is not very clear. Based on A.6, we could see that for each sentence, authors basically find the representative word which is most likely to co-occur with every word in the sentence (has the highest average relatedness rather than similarity) and measure the Wasserstein distance between the co-occurrence probability distribution. I suppose sometimes relatedness is a better metric when measuring sentence similarity, but I think authors should provide some motivative sentence pairs to explain when that is the case.\nUsing Wasserstein to detect hypernym seems to also be novel, but the motivation is also not clear. Again, a good example would be very helpful.\nThis point is also related to the last question for experiments.\n\nMinor writing suggestions:\n1. In section 3, present the full name of CITE\n2. If you put some important equations to the appendix (e.g., the definition of SPPMI_{alpha,gamma}), remember to point readers to the appendix. \n3. In the second paragraph of section 7, Nickel & Kiela, 2017 is a method supervised by a hierarchical structure like WordNet rather than a count-based or word embedding based methods. \n4. In Chang et al., the training dataset is not Wikipedia dump from 2015. This difference of evaluation setup should be mentioned somewhere (e.g., in the caption of Table 2).\n5. The reference section is not very organized. For example, the first name of Benotto is missing for the PhD thesis ""Distributional Models for Semantic Relations: A Study on Hyponymy and Antonymy"". The arXiv papers are cited using different formats. Only some papers have URL. The venue\'s names are sometimes not capitalized. Gaussian embedding is cited twice, etc.\n\n\n[1] Kusner, M., Sun, Y., Kolkin, N., & Weinberger, K. (2015). From word embeddings to document distances. In International Conference on Machine Learning (pp. 957-966).\n[2] Xu, H., Wang, W., Liu, W., & Carin, L. (2018). Distilled Wasserstein Learning for Word Embedding and Topic Modeling. NIPS \n[3] Rolet, A., Cuturi, M., & Peyré, G. (2016, May). Fast dictionary learning with a smoothed wasserstein loss. In Artificial Intelligence and Statistics (pp. 630-638).\n[4] Perone, C. S., Silveira, R., & Paula, T. S. (2018). Evaluation of sentence embeddings in downstream and linguistic probing tasks. arXiv preprint arXiv:1806.06259.\n', 'The paper proposes a method to augment representation of an entity (such as a word) from standard ""point in a vector space"" to a histogram with bins located at some points in that vector space. In this model, the bins correspond the context objects, the location of which are the standard point embedding of those objects, and the histogram weights correspond to the strength of the contextual association. The distance between two representations is then measured with, Context Mover Distance, based on the theory of optimal transport, which is suitable for computing the discrepancy between distributions. \nThe representation of a sentence is proposed to be computed as the barycenter of the representation of words inside.\nEmpirical study evaluate the method in a number of semantic textual similarity and hypernymy detection tasks. \n\nThe topic is important. The paper is well written and well structured and clear. The method could be interesting for the community. However, there are a number of conceptual issues that make the design a little surprising. First, the method does not learn the representations. Instead, augments a given one and computes the context mover distance on top of that. But, if the proposed context mover distance is an effective distance, maybe representations are better to be ""learned"" based on the same distance rather than being received as inputs.\nAlso, whether an object is represented as a single point or as a distribution seems to be an orthogonal matter to whether the context predicts the entity or vice versa. This two topics are kind of mixed up in the discussions in this paper.\n\nOther issues:\n\n- One important technicality which seems to be missing is the exact value of p in Wp which is used. This becomes important for barycenters computations and the uniqueness of barycenters. \n- Competitors in Table 1 are limited. Standard embedding methods are missing from the list.\n- Authors raise a question in the title of the paper, but the content of the paper is not much in the direction of trying to answer the question. \n- It is not clear why the ""context"" of hyponym is expected to be a subset of the context of the hypernym. This should not always be true.\n- Table 4 gives the impression that parameter might not be set based on performance on validation set, but instead based on the performance on the test set.\n\n- Minor:\nof of\ndata ,\nby\nbyMuzellec\nCITE\n\nOverall, comparing strengths and shortcomings of the paper, I vote for the paper to be marginally accepted.', 'The submission explores a new form of word representation based on a histogram over context word vectors, allowing them to measure distances between words in terms of optimal transport between these histograms. The authors speculate that this may allow better representations of polysemous words. The approach is mathematically elegant, and requires no additional training on top of existing approaches like Glove. To improve efficiency, they use clustering on context vectors. They present results on various semantic textual similarity and hypernym detection tasks, outperforming some baselines.\n\nThe paper presents itself as an alternative to word embeddings as a way of representing words. As far as I can tell, their method only really allows a way of computing distances between pairs of word representations, which hasn\'t been a useful concept for the vast majority of cases that word embeddings have been used for (translation, QA, etc.). Point estimates are at least very convenient to work with. That doesn\'t mean the proposed approach is useless, but the paper needs to give a much stronger motivation for when and why measuring distances between words may be helpful.\n\nThe experiments are a bit underwhelming. STS and hypernymy detection are somewhat unimpressive tasks to work - I\'m not aware of any results on these tasks that have generalized to more realistic applications like translation or question answering. I think for publication with just these tasks, the method would need to show a dramatic breakthrough, which the submission definitely does not. The STS baselines are very simple bag-of-words approaches, and even then the results for the SIF baseline are much lower than those reported by Arora et al. (2017). At the least, there should be a comparison with the current state of the art. On the hypernymy task, what validation data was used? Unfortunately I\'m not able to suggest better experiments, because I can\'t think of cases where their method would be useful.\n\nThe paper is significantly weakened by frequently making very strong claims based on rather limited experimental results (for one example, ""we illustrate how our framework can be of significant benefit for a wide variety of important tasks"" feels like quite a stretch). It would be much improved if some of the language was toned down. \n\nOverall, the paper introduces a mathematically elegant method for representing words as distributions over contexts, and for computing distances between these words. For acceptance, I think the paper needs to better motivate why the method could be useful, and back that up with more convincing experiments.']","[-20, 20, -20]","[60, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice to see the effort'), they express several concerns about the novelty, motivation, and mixed results of the study. The overall tone suggests that significant improvements are needed before the reviewer would recommend acceptance. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement, use polite language ('I suggest', 'Please use'), and acknowledge positive aspects. The reviewer also provides detailed feedback and questions, which is helpful and respectful to the authors. However, some direct criticisms prevent the score from being higher."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the importance of the topic, the paper's good structure, and potential interest to the community, they also raise several conceptual issues and technical concerns. The overall recommendation is 'marginally accepted', indicating a slightly positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They use phrases like 'could be interesting' and 'well written' before presenting criticisms, which are framed as 'issues' rather than outright flaws. The tone remains professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'mathematically elegant'), they express several criticisms and concerns. The reviewer finds the experiments 'underwhelming', the claims 'very strong' based on 'limited experimental results', and suggests the paper needs significant improvements for acceptance. However, the score isn't deeply negative as the reviewer still sees some merit in the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement, acknowledge positive aspects, and use phrases like 'I think' and 'As far as I can tell' to soften criticisms. The language is not overly formal or deferential, but it avoids harsh or rude phrasing, striking a balance between honesty and respect.""]"
"['This paper presents a laudable attempt to generalize the learning of active learning strategies to learn general strategies that apply across many different datasets that have variables of different, not pre-determined, types, and apply the learned active learning strategies to datasets that are different from what they have been learned with. The paper is written quite clearly and is clear in its discussion of what its advance is beyond the current state of the art.\n\nUnfortunately, the motivation of the details of the algorithm and the experiment analysis leave the paper short of what is needed to truly assess the value of this area of work and; therefore, short of what is needed for publication in ICLR. The most notable shortcoming is on page 4, at the bottom, where the actions are described. Among the components of the actions are statistics related to the dataset---the average distance from the chosen point to all the labeled data, and the average distance from the chosen point to all the unlabeled data. The authors do not provide a motivation for the use of these particular statistics. Additionally, the authors did not explore any other statistics. I should think that statistics relevant to the sparsity of the data (e.g., how well they cluster). Additionally, what distance measure is being used? A variety of distance metrics should be explored, such as d-separation for continuous variables and Hamming distance for discrete variables, should be tested, as they intuitively seem likely to affect the results. Additionally, many values are chosen for the experiments without motivation and without testing a variety of values (e.g., 30 for the size of the dataset used to calculate the reward, 1000 RL iterations, and others).\n\nIn the experiments, there needs to be discussion of how much variety there is in the different datasets in terms of their statistical properties that are relevant to active learning, such as how well the data cluster? That would help in understanding why the new algorithm performs as it does relative to the baseline.\n\nOne relatively minor point: The authors state on page 3, ""For example, the probability that the classifier assigns to a datapoint suits this purpose because most classifiers estimate this value."" This is a bit misleading---only generative classifiers would do this, not discriminative classifiers.\n\nPros:\n1. Very clear writing.\n2. Good motivation for the general problem.\n3. Precise description of algorithm.\n\nCons:\n1. Poor motivation for the particular algorithm implementation---features used in the actions, parameter values chosen.\n2. Lack of experiments with different choices for features and parameter values.\n3. Lack of assessment of the dataset characteristics and how they relate to algorithm performance.', 'Summary: This paper studies the recently problem of learning active learning (LAL). It sets up a MDP where the the state is determined by the labeled, unlabelled datasets and classifier, the acton is to query a point, the reward is linked to classifier test set performance improvement and the transition is to update the base classifier. Recent Q-learning algorithms are used to perform the optimisation. The results show that it outperforms some classic handcrafted AL algorithms and some prior LAL algorithms. A feature of this paper is that the method is relatively simple compared to some prior LAL methods, and also that it learns policies that can transfer successfully across diverse heterogenous datasets.\n\nStrengths:\n+ Good results. \n+ Nice that it works well while being simpler and faster than prior transferrable method MLP-GAL.\n+ Generally well written.\n+ Fig 4 is interesting.\n\nWeaknesses:\n- Novelty/originality is rather incremental. \n- Experiments are still on toy datasets.\n\nSpecifics:\n1. Novelty: The concept of formulating AL as a MDP for optimisation is now a standard idea. The optimisers used are recent off-the-shelf Q-learners. The result is that this method is similar to a non-myopic extension of LAL (Konyushkova’17) but several papers already did non-myopic AL. In particular it’s very similar to the SingleRL method in (Pang’18). The only differences are smallish design parameters like: slightly different reward function definition, use Q-learning instead of policy-gradient optimiser, and slightly different state featurisation. The improved sample/speed-efficiency vs SingleRL is likely relatively automatic due to use of recent Q-learning optimisers, rather than vanilla PG optimiser of SingleRL. Not clear that benefit comes from something uniquely contributed here. Other limitations of various prior LAL work, such as binary classifier only, are not alleviated here.\n2. Experiments: The experiments are on toy datasets. Particularly given the small novelty, then evaluation should be much more. For example: 1. How well does it work when transferred to a relatively less toy dataset such as CIFAR. 2. To what extent can it transfer across classifiers rather than only across datasets? \n3. The state representation as a sorted list of scores is rather unintuitive. Is there any intuition on what smart decisions the model could be using this to make?\n4. The featurisations used are not very standard: Like the classifier state sorted score list, and the action featurisation (instance score, instance distance to class, instance distance to unlabelled). It would be good to evaluate this featurisation with a supervised active learner (like LAL), in order to disambiguate whether the good performance comes from these feature choices, or from the recent RL algorithms used to optimise. Similarly for the choice of reward function.\n5. How does the proposed method deal with a suite of training datasets for AL that are of greatly varying difficulty. A relatively very easy dataset needing << 100 examples to reach threshold would generate few AL training examples due to early stopping. A very hard dataset might use all 100 examples. Does it mean that easy datasets contribute less to training than hard ones? ', 'The authors suggest to model active learning (AL) as a Markov Decision Process to try to learn the best possible AL strategy across related domains. \n\nThe paper is well-written and structured -- although the background section could be expanded. Sec 3 presents the method in a clear and straightforward manner. \n\nMy main concern with regards to the paper is novelty. The authors mention two main contributions, the first one being to defined the AL objective to minimize the number of annotations required to achieve a given prediction quality, instead of maximizing performance given an annotation budget. There has been AL approaches from that perspective in the past (e.g., https://arxiv.org/pdf/1510.02847.pdf). \n\nThe second contribution has to do with a procedure to learn the AL strategy using data from different domains (with available labels). Again, the literature in transfer learning in Reinforcement Learning is extensive and should be discussed. ', ""Summary:\nThis paper presents an RL approach to active learning that is generic across ML model being learned, and across dataset being used. The paper formulates the standard active learning problem as an MDP with the objective of minimizing the number of annotated labels required to meet a pre-specified prediction quality. \n\nThe MDP state proposed by this paper is the current performance score on each sample in a hold-out set. The actions are specified by selecting a datapoint from the set of all un-annotated datapoints. The action feature vector consists of the current performance score of the model on the datapoint, and the average distance of that datapoint from every datapoint in the labeled set and every datapoint in the unlabeled set.\n\nReview:\nI do not recommend this paper for publication in ICLR because I believe:\n1) the work is too incremental\n2) the comparison to baseline and competing methods is incomplete\n3) some design decisions of the proposed method are not well motivated.\n\nI appreciated the clarity of the writting, and the paper organization. I also believe that the proposed method is quite intuitive, and is a good addition to the field. Finally, I appreciate that sufficient experimental details are available within the paper to be able to easily reproduce the results.\n\nDetails:\nMy points (1) and (2) are highly related, so I will discuss both simultaneously. I find that this paper makes only incremental forward progress from the Pang 2018 paper and the Konyushkova 2017 paper. The methodology here looks very similar to the SingleRL method, which Pang 2018 notes can be considered a special case of Konyushkova 2017's method. I think that the work in this paper would be sufficient to stand on its own if it performed a convincing comparison to SingleRL and/or MLP-GAL from Pang 2018. I recognize that this paper references why no such comparison currently exists, but I think this comparison would be extremely valuable to the paper.\n\nA further comment on my point (2), I do not find the comparisons to baseline methods to be entirely convincing. Of note, only the average performance for each method is reported. I'm curious of the variance---and more specifically the standard error and number of independent runs---of each of the reported results. On many of the datasets, the performance difference between the proposed method and uncertainty sampling is quite small in table 1.\n\nA final comment on point (2): I would have liked to see more exploration of different models. I think table 2 is quite informative, showing notable differences between simple baseline AL methods. I would have liked to see table 2 with more classifiers and with more competing AL methods. Because logistic regression is a simple model, the differences between AL methods may be more subtle. Perhaps a more complex model (say a single hidden layer NN) would show more notable differences.\n\nFor point (3), I would have liked to see either an exploration of other design decisions or an explanation of given design decisions. For instance, why only use 30 hold-out samples for the state? I imagine the proposed method would be fairly sensitive to this choice.  Another unexplained design decision was using a maximum budget of 100 datapoints. Table 2 shows some extremely interesting interactions with this budget in its comparison between LogReg-100 and LogReg-200, and further explanation would have been useful. Finally, I would have liked to see some motivation for choice of stopping condition. Using the stopping condition of 98% of maximum performance may have some biasing effect of each method, and it would helpful to have some motivation behind this choice.\n\nQuestions:\n - Why did uncertainty sampling have such limited benefits on LogReg-200 in table 2? This was a surprising result to me, as uncertainty sampling consistently outperformed most other methods.\n - Why is there a disparity between the results for the SVM in table 2 and the discussion in the first paragraph of section 4.3?\n - How does choice of final performance metric affect all methods? Choosing final performance to be 98% of maximum performance could have a major effect on each method. Because the proposed method is non-myopic, I would expect that it performs well when this value is large but would perform poorly with a smaller percentage of maximum performance.\n - Is the proposed method sensitive to number of samples used to compute the state?\n - What does figure 1 show? Are the same 30 samples used for all three subfigures? Perhaps this would more interpretable if, instead of showing the predicted class, this figure showed the prediction error.\n\nMinor nitpicks (did not influence decision):\n - The datasets are 1-based indexed sometimes and 0-based indexed sometimes, even with disparities within a single paragraph.\n - Figure 1 appears a long time before it is discussed, which made it difficult to understand what was going on.\n""]","[-30, -20, 20, -50]","[60, 50, 60, 50]","[""The sentiment score is -30 because while the review starts positively, acknowledging the paper's 'laudable attempt' and clear writing, it quickly shifts to a more critical tone. The reviewer states that the paper falls 'short of what is needed for publication' and lists several significant shortcomings. However, it's not entirely negative as it does mention some pros. The politeness score is 60 because the reviewer uses respectful language throughout, even when criticizing. They use phrases like 'Unfortunately' to soften criticism and 'I should think' to suggest improvements politely. The reviewer also balances criticism with positive comments, listing both pros and cons. The language is professional and constructive, avoiding harsh or rude expressions."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some strengths ('Good results', 'Nice that it works well', 'Generally well written'), they also point out significant weaknesses, particularly around novelty ('Novelty/originality is rather incremental') and experimental limitations ('Experiments are still on toy datasets'). The review lists more weaknesses than strengths and provides several critical suggestions for improvement, indicating an overall slightly negative sentiment. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout, balancing criticism with praise ('Good results', 'Generally well written'). They provide constructive feedback and specific suggestions for improvement without using harsh or rude language. The tone remains objective and focused on the paper's content rather than personal attacks."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is well-written and structured, and the method is presented clearly. However, they express concerns about novelty, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'My main concern' instead of more direct criticism, and provide constructive feedback by suggesting areas for improvement and citing relevant literature. The reviewer maintains a professional and courteous tone while still providing honest feedback."", ""The sentiment score is -50 because the reviewer does not recommend the paper for publication and lists several criticisms, indicating a negative overall sentiment. However, they do acknowledge some positive aspects like clarity of writing and the intuitive nature of the proposed method, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I appreciated' and 'I believe', which maintain a polite tone. The reviewer also provides detailed explanations for their concerns and offers specific suggestions for improvement, which is considerate and helpful to the authors.""]"
"[""\n-- Contribution, Originality, and Quality --\n\nThis paper has presented two approaches for transfer learning in the reinforcement learning (RL) setting: max-ent GPI (Section 3.1) and DC (Section 3.2). The authors have also established some theoretical results for these two approaches (Theorem 3.1 and 3.2), and also demonstrated some experiment results (Section 5).\n\nThese two developed approaches are interesting. However, based on existing literature (Barreto et al. 2017; 2018, Haarnoja et al. 2018a), neither of them seems to contain *significant* novelty. The derivations of the theoretical results (Theorem 3.1 and 3.2) are also relatively straightforward. The experiment results in Section 5 are interesting.\n\n-- Clarity --\n\nI have two major complaints about the clarity of this paper. \n\n1) Section 4 of the paper is not well written and is hard to follow.\n\n2) Some notations in the paper are not well defined. For instance\n\n2a) In page 3, the notation \\delta has not been defined.\n2b) In page 6, both notation V_{\\theta'_V} and V'_{\\theta_V} have been used. I do not think either of them has been defined. \n\n-- Pros and Cons --\n\nPros:\n\n1) The proposed approaches and the experiment results are interesting.\n\nCons:\n\n1) Neither the algorithm design nor the analysis has sufficient novelty, compared to the typical standard of a top-tier conference.\n\n2) The paper is not very well written, especially Section 4.\n\n3) For Theorem 3.2, why not prove a variant of it for the general multi-task case?\n\n4) It would be better to provide the pseudocode of the proposed algorithm in the main body of the paper."", 'This paper proposes using Divergence Correction to compose max ent policies. Based on successor features, this method corrects the optimistic bias of Haarnoja 2018. The motivation for composing policies is sound. This paper addresses the problem statement where policies must accomplish different linear combinations of different reward functions. This method does not require observation the reward weights.\n\nAs shown in the experiments, this method outperforms or equally performs past work in both tabular and continuous  environments. The paper is well written and discusses prior work in an informative manner. The tabular examples provide good visualizations of why the methods perform differently.\n\nMinor:\n- Figure 1.e: Why does the Optimistic transfer have high regret when the caption says that ""on the LU task, optimistic transfers well""\n- Figure 1.i states ""Neither GPI nor the optimistic policies (j shows GPI, by the Optimistic policy is similar)"" but Figure1.j is labeled DC T, is this a typo?\n- Figure 2: Many typos:  ""(b) Finger position at the en (of the trajectoriesstard ting from randomly sampled start states)""\n', 'The authors introduce Divergence Correction (DC) for the problem of transfer learning by composing policies. There approach builds on GPI with a maximum entropy objective. They also prove that DC solves for the max-entropy optimal interpolation between two policies and derive a practical approximation for this algorithm. They provide experimental results in a gridworld problem and study their approximate algorithm in two continuous control problems.\n\nWhile this paper has some interesting ideas (combining GPI with a Max-Entropy objective and DC), these ideas are not properly motivated. The main problem seems to be clarity. One big problem is that the paper never defines the notion of a notion of optimality (or near-optimality). Also, considering that the DC algorithm is one of the main contributions of the paper it is barely motivated. Theorem 3.2 is presented with almost no explanation about how DC was derived. Why do the authors believe that DC is a good idea on a conceptual level? It\'s very interesting that the paper presents cases where previous approaches (Optimistic and GPI) don\'t perform well. But the authors don\'t explain why they believe DC should perform well in these cases. \n\nThe authors make the unjustified claim in the abstract that their approach has ""near-optimal performance and requires less information"". I say this is unjustified because they only try this approach on three benchmarks. In addition, there should be situations where DC also performs poorly since there are known hardness results for solving MDPs. Admittedly, those results may not apply if the authors are making assumptions that are not being clearly discussed in the paper.\n\nMinor Comments:\n1. In the abstract, ""requiring less information"" is very imprecise. Are you referring to sample complexity?\n2. In the introduction, ""can consistently achieve good performance"" is imprecise. What is the notion of near-optimality? What does consistent mean? Having experimental results on 3 tasks doesn\'t seem to be enough to me to justify this claim.\n3. In the introduction (and rest of the paper), please don\'t call Haarnoja et al.\'s approach optimistic. Optimism already has another widely used meaning in RL literature. Maybe call it ""Uncorrected"".\n4. In section 2.2, the authors introduce \\pi_1, \\pi_2, ... , \\pi_n but never actually use that notation. This section does not clearly explain how GPI works.\n5. In Theorem 3.1, the authors should introduce Q^1, Q^2, ... , Q^n and define the policies in terms of the action-value functions. Also, the statement of this theorem is not self contained, what is the reward function of the MDP? The proof below should be called a proof sketch.\n6. The paper mentions that extending to multiple tasks is possible. Is it trivial? What is the basic idea? It seems straightforward but it might be helpful to explicitly state the idea.\n7. In Theorem 3.2, how was C derived? Please add some commentary explaining the conceptual idea.\n8. In Table 1, what is f(s, a|b)? I don\'t see where this was defined?\n9. CondQ is usually referred to as UVFA in the literature.\n10. Section 3 really needs a conclusion statement.\n11. Section 4 is very unclear and hard to follow.\n12. In figure 1f, what is LTD? It\'s never defined. I\'m guessing it\'s DC.\n13. All of the figures are too small and some are not clear in black and white.']","[-20, 80, -50]","[50, 70, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express significant concerns about its novelty and clarity. The reviewer states that the approaches lack 'significant novelty' and that the paper 'is not very well written.' However, they do mention some positive aspects like 'interesting' experiment results, which prevents the score from being more negative. The politeness score is moderately positive (50) because the reviewer maintains a professional tone throughout, using phrases like 'I have two major complaints' instead of more harsh language. They also balance criticism with positive remarks ('pros and cons'). The reviewer's language is direct but not rude, offering constructive feedback and specific suggestions for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They state that the motivation is sound, the paper is well-written, and the method outperforms or equals past work. The reviewer also praises the informative discussion of prior work and the good visualizations. The score is not 100 because there are some minor issues pointed out at the end.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They begin by summarizing the paper's contributions positively and provide specific praise for various aspects of the work. Even when pointing out minor issues, the tone remains professional and helpful rather than critical. The score is not 100 because the review maintains a formal, neutral tone rather than being excessively polite or flattering."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as lack of clarity, insufficient motivation, and unjustified claims. However, it's not entirely negative as it acknowledges some 'interesting ideas'. The politeness score is 20 because the reviewer uses polite language and constructive criticism, offering specific suggestions for improvement. They avoid harsh language, using phrases like 'The authors make the unjustified claim' instead of more direct accusations. The reviewer also provides a detailed list of minor comments, which is helpful and considerate. However, the overall tone is more neutral than overtly polite, hence the moderate positive score.""]"
"['The paper introduces RL based approach to prune layers in a DenseNet. This work extends BlockDrop to DenseNet architecture making the controller independent form the input image. The approach is evaluated on CIFAR10 and CIFAR100 datasets as well as on ImageNet showing promising results.\n\nIn order to improve the paper, the authors could take into consideration the following points:\n\n1. Given the similarity of the approach with BlockDrop, I would suggest to discuss it in the introduction section clearly stating the similarities and the differences with the proposed approach. \n2. BlockDrop seems to introduce a general framework of policy network to prune neural networks. However, the authors claim that BlockDrop ""can only be applied to ResNets or its variants"". Could the authors comment on this? \n3. In the abstract, the authors claim: ""Our experiments show that DenseNet with LWP is more compact and efficient than existing alternatives"". It is hard to asses if the statement is correct given the evidence presented in the experimental section. It is not clear if the method is more efficient and compact than others, e. g.  CondenseNet. \n4. In the experimental section, addressing the following questions would make the section stronger: What is more important FLOPs or number of parameters? What is the accuracy drop we should allow to pay for reduction in number of parameters or FLOPs?\n5. For the evaluation, I would suggest to show that the learned policy is better than a random one: e. g. not using the controller to define policy (in line 20 of the algorithm) and using a random random policy instead.\n6. In Table 1, some entries for DenseNet LWP are missing. Is the network converging for this setups? \n7. \\sigma is not explained in section 3.3. What is the intuition behind this hyper parameter?\n8. I\'d suggest moving related work section to background section and expanding it a bit.\n9. In the introduction: ""... it achieved state-of-the-art results across several highly competitive datasets"". Please add citations accordingly.\n\nAdditional comments:\n1. It might be interesting to compare the method introduced in the paper to a scenario where the controller is conditioned on an input image and adaptively selects the connections/layers in DenseNet at inference time.\n2. It might be interesting to report the number of connections in Table 1 for all the models.\n\nOverall, I liked the ideas presented in the paper. However, I think that the high degree of overlap with BlockDrop should be addressed by clearly stating the differences in the introduction section. Moreover, I encourage the authors to include missing results in Table 1 and run a comparison to random policy. In the current version of the manuscript, it is hard to compare among different methods, thus, finding a metric or a visualization that would clearly outline the ""efficiency and compactness"" of the method would make the paper stronger.', 'This paper proposes a layer-based pruning method based on reinforment learning for pre-train networks.\n\nThere are several major issues for my rating:\n\n- Lack of perspective. I do not understand where this paper sits compared to other compression methods. If this is about RL great, if this is about compression, there is a lack of related work and proper comparisons to existing methods (at least concenptual)\n- Claims about the benefits of not needed expertise are not clear to me as, from the results, seems like expertise is needed to set the hyperparameters.\n\n- experiments are not convincing. I would like to see something about computational costs. Current methods aim at minimizing training / finetuning costs while maintaining the accuracy. How does this stands in that regard? How much time is needed to prune one of these models? How many resources?\n\n- Would it be possible to add this process into a training from scratch method?\n\n- how would this compare to training methods that integrate compression strategies?\n- Table 1 shows incomplete results, why? Also, there is a big gap between accuracy/number of parameters trade-of between this method and other presented in that table. Why?\n\n', 'This paper proposes to apply Neural Architecture Search (NAS) for connectivity pruning to improve the parameter efficiency of DenseNet. The idea is straightforward and the paper is well organized and easy to follow.\n\nMy major concern is the limited contribution. Applying deep reinforcement learning (DRL) and following the AutoML framework for architecture/parameter pruning has been extensively investigated during the past two years. For instance, this work has a similar motivation and design ""AMC: AutoML for Model Compression and Acceleration on Mobile Devices.""\n\nThe experimental results also show a limited efficiency improvement according to Table 1. Although this is a debatable drawback compared with the novelty/contribution concern, it worth to reconsider the motivation of the proposed method given the fact that the AutoML framework is extremely expensive due to the DRL design. \n\n']","[20, -50, -20]","[80, 0, 60]","[""The sentiment score is slightly positive (20) because the reviewer begins by acknowledging the paper's contribution and mentions 'promising results'. However, the bulk of the review consists of suggestions for improvement, indicating a mixed but generally constructive sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, framing criticisms as suggestions ('could take into consideration', 'I would suggest') and ending on a positive note ('I liked the ideas presented'). The reviewer maintains a professional and courteous tone, even when pointing out areas for improvement."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several major issues with the paper. The reviewer expresses a lack of understanding about the paper's perspective, questions the claims made, and finds the experiments unconvincing. However, it's not entirely negative as the reviewer suggests potential improvements and asks questions that could enhance the paper.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout. They don't use overtly polite language, but they also avoid rudeness. The criticism is presented in a straightforward, matter-of-fact manner without personal attacks or overly harsh language. The use of questions to express concerns rather than direct criticisms contributes to the neutral tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-organized and easy to follow, they express major concerns about the limited contribution and efficiency improvement. The reviewer questions the novelty and motivation of the proposed method, which outweighs the initial positive comments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and phrases concerns as suggestions rather than harsh criticisms (e.g., 'worth to reconsider'). The reviewer maintains a professional tone without using overly negative or confrontational language.""]"
"[""Unfortunately, while this is interesting work, the authors emails are listed on the first page and the acknowledgments are very revealing. I am a big fan of Google, UCL, and the Royal Society, and this strongly biases my view of the work. \n\nMy biased review:\n\n- the paper is interesting, and should go to another venue. I do not think the authors will get benefit from presenting this work at ICLR (there is a tiny quantum focus).\n\n- how is the cost function justified? I'd be curious to see how the authors derived it. Right now above Eq 2.4 it seems like it is heuristic to balance successful/erroneous/inconclusive rates. If it is a heuristic, the paper should clearly state this. \n\n- using simple examples of quantum data and quantum states would go a long way towards helping me understand the problem setup (Eq 2.1). It took me a while to grok this.\n\n- The acronym POVM is never defined. "", 'Summary of paper:\nThe authors partially integrate a neural network into classical approaches to classify the state of a quantum circuit. The model is not actually clear in what it is doing, but there are some trained weights somewhere. They allow for an ""uncertainty"" prediction by giving one more node than there are classification targets, corresponding to a less-penalized uncertain prediction. They evaluate their model on numerical simulations.\n\nStrengths:\n-\nWeaknesses:\n- The neural network architecture is entirely standard with nothing new.\n- The paper is poorly written and very hard to follow.\n- The focus is almost exclusively on the application, and yet the application is not explained effectively.\n- The implication of the results and usefulness is not elaborated.\n- The particular contributions are not clear.\n\nSuggested Revisions:\n- What is the 9b8d in the first sentence of the abstract?\n- ""...been developed to address the question [of] whether quantum mechanics...""\n- ""...for all the dataset[s] in Table 1...""', 'Authors give a method to perform a full quantum problem of classifying unknown mixed quantum states. This is an important topic but the paper is ok and I think the test case is a bit lacking.\n\nThe theory  is sound and the math is good. The only question I have is how does this hold on a real quantum computer such as IBMQ/rigetti quantum computing etc.. or even under a noisy simulator \n\nAlthough the paper is sounds and it is a good idea, the presentation is a bit lacking. There are several typos and formatting problems, such as excess spaces and some sort of hex code (9b8d) in the abstract which I am guessing is left over from the NIPS template.\nTwo other things is that usually in double blind review one should not leave the emails with affiliation and one should anonymize the Acknowledgements as well.']","[-20, -70, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because the reviewer expresses concerns about bias due to the authors' affiliations and suggests the paper should go to another venue. However, they do mention the work is 'interesting,' which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I'd be curious to see' and 'It took me a while to grok this,' showing respect for the authors' work. They also provide constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer's admission of potential bias also demonstrates a level of professional courtesy."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer lists several weaknesses and no strengths, indicating significant issues with the paper. The language used, such as 'poorly written' and 'very hard to follow', further emphasizes the negative sentiment. However, it's not at the extreme negative end as the reviewer does provide some constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone. They use neutral language for suggestions ('Suggested Revisions') and phrase criticisms as observations rather than personal attacks. The reviewer also provides specific examples for improvement, which is a polite way to offer criticism. However, the lack of any positive comments and the directness of some criticisms ('poorly written') prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the soundness of the theory, they express concerns about the test case, presentation, and lack of real quantum computer testing. The phrase 'the paper is ok' suggests a lukewarm reception. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They avoid harsh language when pointing out issues, using phrases like 'a bit lacking' instead of more negative expressions. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"['The paper proposes a method for using auxiliary tasks to support the optimization with respect to a main task. In particular, the method assumes the existence of a loss function for the main task that we are interested in, and a loss function for an auxiliary task that shares at least some of the parameters with the main loss function. When optimizing for the main loss function, the gradient of the auxiliary loss function is also used to update the shared parameters in cases of high cosine similarity with the main task. The method is demonstrated on image classification and a few reinforcement learning settings.\n\nThe idea of the paper is simple, and the method has a nice property of (if ignoring some caveats) guaranteeing steps that are directionally correct with respect to the main task. In that sense it is useful in practice, as it limits the potential damage the auxiliary task does to the optimization of the main task.\n\nAs the authors also note, the method suffers from some drawbacks. Although the method limits the negative effect of the auxiliary task on the optimization of the main loss function, it can still slow down optimization if the auxiliary task is not well chosen. In that sense, the method is no silver bullet. In addition, the method seems fairly computationally expensive (it would be interesting to understand how much it slows down an update, I would assume the added complexity is roughly a constant multiplier). However, as an alternative to naively adding an auxiliary task, the proposed method is a welcome addition to the tool box of practitioners.\n\nAlthough the experiments presented in the paper are quite different from each other, I would have wished for even more experiments. The reason is that as the method does not guarantee faster convergence, its applicability is mainly an empirical question. Especially experiments where auxiliary tasks have been used before would be interesting to test with the only addition being introducing the method proposed.\n\nThe paper is generally well written and the results are fairly clearly presented. As a minor comment, the authors might want to check that articles (such as ""the"") are not missing in the text.\n\nAll in all, the main merit of the proposed method is its conceptual simplicity and easy to understand value in practical applications where an auxiliary loss function is available. The method also seems to work well enough in the experiments presented.', ""The paper studies the problem of how to measure the similarity between an auxiliary task and the target tasks, and further decide when to use the auxiliary loss in the training epoches. The proposed cosine simiarity based soft gradient update scheme seems reasonable. The author(s) also experiment the proposed method on three tasks, one supervised learning image classification task, two reinforcement learning tasks, and show improved results respectively.\n\nThe paper is in generally well-written. However it would be great if the concerns below could be addressed or discussed in the paper.\n\n1) The proposed method is based on the intuition: if the gradients of the target and auxiliary loss are in the same direction, the auxiliary loss will help the main/target task. Some examples are showed in the paper to support this argument, however it would be helpful if there is some theoritical gurantee on this. So a more general question would be: rather than define the similarity measure to measure the gradient similarity of the target and auxiliary loss, it would be more useful to try to learn or define whether the auxiliary task is good for the target task beforehand.\n\n2) In proposition 1, if the concerns in 1) are reasonable, the equation would be doubtful. For example, one can simply try (g(target task)-g(auxiliary task)) in the equation. Besides, more similarity metrics are expected to be compared here to show why cosine is the optimal choice. For example, L2.\n\n3) Too much content is embedded in appendix, for example, it would be helpful to move the two algorithms or at least discussed the two variants of the gradient updates in the experimental section. Since it is not clear to me whether hard cosine mixing or soft cosine mixing is used to produce the results in the image classification task.\n\n4) In the image classification task, a quantitative analysis would be more convincing since the semantics of the near and far is really hard to define. Even the authors can show a vague definition, it will be helpful. In figure 2b), why the cosine method performs worse compared the other methods before 5000 in x-axis? Is this because of the noise of the gradient? Plus, what is the optimizer used in this experiment?\n\n5) In the first reinforcement learning task, since cosine similarity is the only method used to measure the similarity between auxiliary task and the target task, it would be useful to show the comparison among other task relatedness method in reinforcement learning. For 'This is expected as the noise in the gradients make it hard to measure if the two tasks are a good fit or not',  why is this? Since cosine similarity would be zero if the two tasks are not good fit."", ""The paper is addressing the problem of a specific multi-task learning setup such that there are two tasks namely main task and auxiliary task. Auxiliary task is used for the sole purpose of helping the main one. In other words, auxiliary task performance is not of interest. The simple and sensible approach proposed in the paper is using cosine similarity between the gradients of two loss functions and incorporating the auxiliary one if it is positively aligned with the main gradient. Authors suggest to further scale loss functions using the cosine similarity but it only experiments with the simpler case of binary decision of using both gradients or only the main one. Authors provide a convergence guarantee (without any convergence rate) by simply extending the convergence of gradient method.\n\nThe paper is definitely addressing an important problem as the authors cite many previous work which uses the setup of set of auxiliary tasks helping a main one. The method is simple and easy to implement. Hence, it has a potential to be useful for the community.\n\nOne major issue for me is the experimental setup. The authors cite many interesting, realistic and practical setups (Zhang et al., 2016; Jaderberg et al., 2017; Mirowski et al., 2017; Papoudakis et al., 2018), but do not use any of these setups in their experiments. Instead, paper uses set of toy experiments. This is very puzzling to me as all these papers set existing baselines for interesting problems which authors can easily compare. I think the paper needs to be experimented and compared with these established methods.\n\nAnother major issue is the weak multi-task learning baseline used in the paper. There have been many interesting developments in adaptive scaling of multiple loss functions in the literature. However, paper does not compare with them. Example of these methods are: [GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks, ICML 2018] and [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics, CVPR 2018]. Although these methods addresses the case of all tasks being important, it is a valid baseline and need to be compared. Similar to my first points, these papers also use very realistic and interesting experiments which would fit better than the toy experiments in the paper.\n\nFinal major issue is the fact that experimental results are suggesting the method is not effective. In ImageNet experiment, auxiliary tasks actually hurt the final performance as the single task is better than all methods including the proposed one. Proposed method does not guarantee that auxiliary tasks will have no harm. The GridWorld experiment is sort of a sanity check to me as it is very hand-crafted. For Breakout experiment, single task actually outperforms all baselines and this means the proposed method results in a harm similar to ImageNet case. For Breakout+MSPacMan experiment, multi task and the proposed method performs almost exactly same. I do not get why the performance on Breakout is relevant for this case since it is not a main task. The paper clearly states that only performance of an interest is the main one which is MSPacMan in this case. Also, in this experiment clearly all methods are still learning as the curve did not plateau yet. I am curious, why the learning is stop there. I do not think we need the method to be effective to be published; but, the negative result should be explained properly.\n\nMINOR NITPICKS\n- Algorithm 1&2 are crucial to understand the paper, they should be in main text\n- ImageNet class IDs change between years. So, actual wordnet IDs or class names is a better thing to state\n- What happens if there are multiple auxiliary tasks?\n- Does the theory still hold for loss functions which are not Lipschitz as the Cauchy's gradient method requires that for convergence\nIn summary, the paper is proposing a sensible method for an important problem. However, it is only tested for toy problems although there are interesting existing setups which would be ideal for the method to be tested. Moreover, it is only compared with the most-naive multi task learning baselines. Even this limited experimental setup does not confirm what the paper is claiming (using auxiliary tasks only when they help). And the paper fails to explain this failure cases. The method needs to be experimented with a more realistic setup with more realistic baselines.\n\n------\nAfter rebuttal:\n\nI gave detailed responses to each part of the rebuttal below. Here is the summary:\n\nAlthough the response addresses some of my concerns. There are still major issues with the experimental study. 1) there are existing, relevant and well-studied multi-task setups with negative interference. Method should be experimented with some of those setups. 2) Multi-task baseline in the paper is naive and far from state-of-the-art. Paper need strong baselines as discussed. Hence, I am keeping my score. Paper needs to be improved with a stronger experimental study and need to be re-submitted.""]","[60, 20, -60]","[80, 80, 20]","[""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper. They describe the idea as 'simple' and 'useful in practice', and call it a 'welcome addition to the tool box of practitioners'. While they do mention some drawbacks, these are presented as minor issues rather than major flaws. The overall tone is supportive, though not overwhelmingly enthusiastic.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's merits and provide suggestions for improvement in a gentle manner. Phrases like 'I would have wished for' and 'As a minor comment' soften criticism. The reviewer also ends on a positive note, reinforcing the paper's value. There are no rude or harsh comments, and the tone remains professional and courteous throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is 'generally well-written' and the proposed method 'seems reasonable'. They also mention 'improved results' from experiments. However, the bulk of the review consists of concerns and suggestions for improvement, which tempers the positive sentiment. The politeness score is high (80) due to the use of respectful language throughout. The reviewer uses phrases like 'it would be great if', 'it would be helpful if', and frames criticisms as suggestions or questions rather than direct criticisms. They also begin with positive comments before moving to concerns, which is a polite approach in academic reviews."", ""The sentiment score is -60 because the reviewer expresses several major concerns with the paper, including issues with the experimental setup, weak baselines, and results that don't support the paper's claims. The reviewer states that the paper needs significant improvements and resubmission. However, they do acknowledge some positive aspects, such as addressing an important problem and proposing a sensible method, which prevents the score from being even lower. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'I am curious' to soften criticisms. They also acknowledge positive aspects of the paper. However, the criticism is direct and extensive, which prevents a higher politeness score.""]"
"['The paper is well written and addresses an interesting problem. Overall, I do find the federated dropout idea quite interesting. As for the lossy compression part, I am a bit skeptical on its application for this problem. In general, I believe that the manuscript could greatly benefit from answering the questions that I am raising below. It would certainly help me better appreciate the contributions of this work. \n\nThe lossy aspect of the compression inevitably introduces performance downgrades. However, compression/communication systems are designed to make sure that the information dropped is not important for the task at hand (e.g., high frequencies that are not perceived by our eyes in the spatial domain are typically dropped when compressing images through zig zag scanning after transformation). Randomly dropping coefficients as suggested in this paper seems odd to me (the subsampling technique that is used). Can you justify this approach? The manuscript does hint that this approach provides lukewarm results. Could there be a better approach that focuses on parts of the model that deemed “less” important if a notion of coefficient importance can be derived? \n\nCan you emphasize more the benefits of compression and federated drop out, versus training a low capacity model with less parameters? The introduction refers to the low capacity approach as a naive model. Could this be compared experimentally? This would help better appreciate the benefits of the federated dropout strategies that are proposed here. In the experiments, could you explain why increases in q (quantization steps) seems to lead to limited or marginal accuracy improvements? \n\nFor the results shown in Figure 4, did you also use any form of subsampling and quantization? Also, do you have a justification for why with some amounts of dropout, the accuracy may improve but at a slower pace (pretty much the punch line of these experiments)? It is an interesting finding but it is counter intuitive and requires explanations in my view. \n\nOn the communication cost experiments, can you explain precisely how did you compute these reduction factors? Did you tolerate some form of accuracy degradation? Also, did you consider the fact that more ""rounds"" are needed to get to a target accuracy level? Is there a cost associated with these additional rounds and was that cost taken into consideration? Adding clarity on this would certainly help. ', 'The paper tackles a major issue in distributed learning in general (and not only the federated scheme), which is communication bottleneck.\n\nI am not fully qualified to judge and would rather listen to the opinion of more qualified reviewers, I was annoyed by some aspects of the paper:\n\n1) many claims required formal support (proofs), as an example: ""more aggressive dropout rates ted to slow down the convergence rate of the model, even if they sometimes result in a higher accuracy"" is a statement that would benefit from analyzing the dropout out effect on convergence, something that wouldn\'t be hard to do given the extensive theoretical toolbox on distributed optimization.\n\n2) no comparison with other compression schemes (see e.g. Alistarh et al.\'s ZipML (NIPS or ICML 2017) and followups)\n\n3) proving an unbiased-ness guarantee out of the Probabilistic quantization (section 3.1) would have been a minimal requirement in my opinion.\n\nI encourage the authors to further expand those points, but would happily lighten-up my skepticism if more qualified reviewers say that we do not need such guarantees as the one in point 1 and 3. (the few compression papers I know provide that)', 'The paper presents some new approaches for communication efficient Federated Learning (FL) that allows for training of large models on heterogeneous edge devices. In FL, heterogeneous edge devices have access to potentially non-iid samples of data points and try to jointly learn a model by averaging their local models at a parameter server (the cloud). As the bandwidth of the up/downlink-link may be limited communication overheads may become the bottleneck during FL. Moreover, due to the heterogeneity of the hardware, large models may be hard to train on small devices. Due to that, there are several recent approaches that aim to minimize communication via methods of quantization, which also aim to allow for smaller models via methods of compression and model quantization.\n\nIn this paper, the authors suggest a combination of two methods to reduce communication and allow for large model training by 1) using a lossy compressed model when that is communicated from the cloud to the edge devices, and 2) subsampling the gradients, a form of dropout, at the edge device side that allows for an overall smaller model update. The novelty of either of those techniques is quite limited as individually they have been suggested before, but the combination of both of them is interesting. \n\nThe paper is overall well written, however there are two aspects that make the contribution lacking in novelty. First of all, the presented methods are a combination of existing techniques, that although interesting to combine together, are neither theoretically analyzed nor extensively tested. The model/update quantization technique has been used in the past extensively [eg 1-3]. Then, the “federated dropout” can be seen as a “coordinate descent” type of a technique, i.e., randomly zeroing out gradient elements per iteration. \n\nSince this is a more experimental paper, the setup tested is quite limited in its comparisons. For example, one would expect to see extensive comparisons with methods for quantizing gradients, eg QSGD, or Terngrad, and combinations of that with DeepCompression. Although the authors do make an effort to experiment with a different set of hyperparameters (dropout probability, quantization levels, etc), a comparison with state of the art methods is lacking.\n\nOverall, although the combination of the presented ideas has some merit, the lack of extensive experiments that would compare it with the state of the art is not convincing, and the overall effectiveness of this method is unclear at this point.\n\n[1] https://arxiv.org/pdf/1510.00149.pdf\n[2] https://arxiv.org/pdf/1803.03383.pdf\n[4] https://arxiv.org/pdf/1610.05492.pdf']","[20, -50, -30]","[80, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging that the paper is well-written and addresses an interesting problem. They find the federated dropout idea 'quite interesting'. However, they express skepticism about the lossy compression part and raise several questions, which tempers the overall positive sentiment. The politeness score is high (80) because the reviewer uses respectful language throughout, framing their concerns as questions rather than criticisms. They use phrases like 'Could you explain...', 'Can you emphasize...', and 'Adding clarity on this would certainly help', which are polite ways of requesting more information or suggesting improvements. The reviewer also acknowledges the interesting aspects of the work, which contributes to the polite tone."", ""The sentiment score is -50 because the reviewer expresses skepticism and annoyance with several aspects of the paper, listing multiple criticisms. However, they do acknowledge the paper tackles a major issue and show willingness to change their opinion if other reviewers disagree, which prevents the score from being more negative. The politeness score is 20 because while the reviewer is critical, they use relatively polite language such as 'I encourage the authors' and 'I would happily lighten-up my skepticism'. They also acknowledge their potential lack of expertise, which is a humble approach. However, the use of words like 'annoyed' and the direct criticism prevent the score from being higher."", ""The sentiment score is -30 because while the reviewer acknowledges some merits of the paper ('interesting combination', 'well written'), they express significant concerns about the novelty and thoroughness of the work. The overall tone is more negative than positive, with phrases like 'lacking in novelty', 'not convincing', and 'effectiveness... is unclear'. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. They use phrases like 'the authors suggest' and 'one would expect' rather than direct accusations. The review maintains a professional tone without being overly formal or deferential.""]"
"['pros:\n\n- Clearly written and sound paper.\n- Addresses interesting problem. \n- Improves existing methods used for this learning scenario.  \n\ncons:\n\n- The core contribution is a special case of previously published more general framework which is not cited in the paper.\n\nIt is clearly written paper with a good motivation. The major problem is that the core contribution, namely, the risk reformulation in Theorem 1 and the derived loss (6), are special cases of more general framework published in \n   Jesus Cid-Sueiro et al. Consistency of Losses for Learning from Weak Labels. ECML 2014.\n\nThe work of [Cid-Sueiro2014] proposes a general way how to construct losses for learning from weak labels. They require that the distribution of weak labels is a linear transformation of the true label distribution, i.e. the assumption (3) of the paper under review. According to [Cid-Sueiro2014], the loss on weak labels is constructed by $weak_loss = L*original_loss$, where $L$ is the left inversion of the ""mixing matrix"" $T$ in (3). [Cid-Sueiro2014] also shows that such weak loss is classification calibrated which implies statistical consistency of the method. \n\nLearning from complementary labels is a special case when the mixing matrix is $T=(E-I)/(K-1)$ (E is unitary matrix, I is matrix of ones, K is number of labels). In this case, the left inversion of $T$ is simply $L=- E*(K-1) + I$ and so the weak loss is $weak_loss=L*loss$ which corresponds to the loss (5) proposed in the paper under review (in fact, the loss (5) also adds a constant term (Y-2)/(Y-1) which however has no effect on the minimizer). \n\nThe novel part of the paper is the non-negative risk estimator proposed in sec 3.3 and the online optimization methods addressed in sec 3.4. These extensions, although relatively straightforward, are empirically shown to significantly improve the results.', 'This paper proposes an improved approach to the ""complementary-label"" form of weak supervision, in which a label that is *not* the true label is marked. Specifically, this paper proposes an unbiased estimator that accepts arbitrary loss functions and models. Noting that this proposed estimator can suffer from overfitting due to unbounded negative loss, a lower-bounded estimator is proposed. Experiments are then performed on several image classification datasets.\n\nPros:\n- This paper addresses a creative form of weak supervision, proposed by prior work, in which labels that are *not* the true label are labeled, in a clear fashion.\n\n- The first proposed estimator is unbiased, as shown by a proof, and accepts arbitrary losses, an improvement over prior approaches\n\n- The overall presentation is clear and clean\n\nCons:\n- One of the main claims of the paper is the proposal of an unbiased estimator. However, this estimator then does not seem to work well enough due to degenerate negative loss.  So then a modified version is proposed- which does not appear to be unbiased?  Either way, no assertion or proof of it being unbiased is given.  So then presumably this also reverses the claim of being able to cross-validate?  This seems like a major weakening of the paper\'s contributions\n\n- Since the unbiased estimator does not appear to work well, two implementations of a corrected one are proposed, using heuristic approaches without explicit theoretical guarantees.  This shifts the burden to the experimental studies.  These are somewhat thorough, but not extremely so: for example, one set of hyperparameters were used for all of the methods?  This seems like it could implicitly handicap / favor some over others?\n\n- The proposed estimator is based on the assumption that the probability of classes in the complement set (the set of labels other than the one marked as incorrect) is uniformly distributed (e.g. see beginning of Proof of thm 1).  However, this seems like a potentially naive assumption. Indeed, in the related work section, it is mentioned that work in 2018 already considered the case where this uniformity assumption does not hold.\n\n- More broadly, but following from the above: The paper does not provide any real world examples, real or hypothetical, to give the reader an idea of whether the above uniformity assumption---or really any of these assumptions---are well-motivated or empirically justified.  At the bottom of page 3 in the related work, a concrete application used in prior work is mentioned---where crowd workers are shown single labels and vote Y/N, leading to a mix of standard (if Y) and complement-labeled (if N) data---however this mixed setting is not considered explicitly in this paper.  So, how is the reader supposed to get any idea of whether the assumed setup is motivated or justified?  The experiments do not provide this, because the complementary labels are synthetically generated according to the model assumed in the paper.  Additionally, it is briefly mentioned that collecting complementary labeled data is faster, but again no concrete examples are given to support this.', ""Pros:\n- The authors consider an interesting problem of learning from complementary labels\n- They propose an approach that, assuming that the complementary label is selected uniformly at random, provides an unbiased estimate for any loss function, which is an improvement over the previous work. \n- Experiments show promising results for modifications of the proposed estimate\n\nCons:\n- Having an unbiased estimate doesn't imply that its minimisation is a successful learning strategy. Indeed, the authors show that minimising their original estimate for the cross-entropy loss leads to overfitting. While the authors attribute this behaviour to the fact that the estimate can be negative, I believe the loss being negative is not problem per se (for example, substituting 0/1 loss with -100/-99 loss would not change the learning; similarly, this is not a problem for the losses considered in [Ishida'17]). I would rather attribute the problem to the fact that the proposed estimate is unbounded from below and there are no generalisation guarantees for it. Indeed, assuming there exists a training example that appears in the training set only once, with one complementary label, estimate (8) can be made arbitrary small by just training to predict probability 0 for the provided complementary label on that example ( and any non-zero probability for other classes). \n- to cope with the above mentioned problem, the authors propose two heuristic-based modifications of the estimate, which are potentially biased. This weakens the initial motivation for finding an unbiased estimate and shifts the focus towards the experimental evaluation\n- one of the mentioned motivations for unbiased estimates - being able to perform model selection on complementary labeled validation set - is not illustrated in the experiments\n\nQuestions:\n- I believe 1/(K-1) normalisation factor in (5) is not needed\n- there seems to be a mistake in (9) (and its modifications later on) - I would expect either the subscript $j$ of the probability distribution in the last summand to be exchanged with $k$ in the loss, or a factor $\\pi_j/\\pi_k$ added\n- also, I think there are some mistakes in subscripts in (11)\n- what loss is the method from [Ishida'17] optimising in the experiments?""]","[-20, -20, 20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Clearly written and sound paper', 'Addresses interesting problem', 'Improves existing methods'), the main criticism is quite significant - the core contribution is described as a special case of a previously published framework that wasn't cited. This oversight is presented as a 'major problem'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The critique, while direct, is presented in a professional and constructive manner, explaining the issue in detail rather than simply dismissing the work. The reviewer also notes the novel aspects of the paper that do add value, showing a balanced approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') that outweigh the positives. The reviewer points out several weaknesses in the paper's methodology, assumptions, and experimental design, which contribute to the overall negative sentiment. However, the score is not extremely negative as the reviewer does recognize some merits of the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to present both pros and cons, avoiding harsh or dismissive statements. The critique is presented in a constructive manner, using phrases like 'This seems like...' or 'The paper does not provide...' rather than making accusatory statements. The reviewer also acknowledges the paper's strengths before delving into criticisms, which is a polite approach to peer review."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting problem and the improvements over previous work, showing promising results. However, they also point out significant cons and potential issues with the approach, balancing out the positive aspects. The politeness score is moderately high (60) as the reviewer uses neutral and professional language throughout, presenting both pros and cons in a balanced manner without using harsh or critical language. They also phrase their concerns as questions or observations rather than direct criticisms, which contributes to the polite tone.']"
"[""In this work, the authors explore different ways to pre-train contextualized word and sentence representations for use in other tasks. They propose two main methods: a straight-forward extension of the ElMO model for hierarchical uni-directional language models, and a de-noising auto-encoder type method which allows to train bi-directional representations. The learned contextual representations are evaluated on three downstream tasks, demonstrating the superiority of the bi-directional training setting, and beating strong baselines on extractive summarization.\n\nThe method is clearly presented and easy to follow, and the experiments do seem to support the author's claims, but their exposition misses several important details (or could be presented more clearly). For the document segmentation task, are the articles taken from a held-out set, or are they contained in the pre-training set? For passage retrieval, is the representation the same or are the representations re-trained from scratch using paragraph blocks? What exactly are the other features (those can go in the appendix)? And for the extractive summarization task, how many sentences are selected? Is pre-training also done on Wikipedia, or are those representations trained on news text?\n\nA comparison to non-contextualized sentence representations would also be welcome (SkipThought, InferSent, ElMO-pool for settings other than passage retrieval). Note also that the local pre-training is not equivalent to ElMO, as the later sees context form the whole document rather than just the current sentence.\n\nIt is interesting to see that contextualized sentence representations can be used and that the Mask-LM objective yields better results than L+R-LM, but these points would be better made if the above questions were answered."", 'Summary: \nThis paper proposes to extend the pretraining used for word representations in QA (e.g., ELMO) in the following sense: Instead of just predicting next/previous words in a sentence/paragraph, performing a hierarchical prediction over the whole document, by having a local LSTM and a global LSTM as presented in Fig. 1 + the idea of masked language model. Authors show meaningful improvements in 3 tasks that require document level understanding: extractive summarization, document segmentation, and answer passage retrieval for doc level QA. \n\nPros:\n- Good presentation and clear explanations.\n- Meaningful improvements in various tasks requiring document level understanding.\n\nCons:\n- Novelty is mainly incremental\n\nMinor comment: \n- Use a bigger picture for Fig. 1\n- In page 1, Introduction, paragraph 2, line 10, ""due the long-distance ..."" ==> ""due to the long-distance ...""\n\n**********\nI would like to thank authors for their feedback. After reading their feedback I still believe that novelty is incremental and would like to keep my score. ', 'Reasonable method, but not too much novelty\n\n[Summary]\n\nThe paper proposed techniques to pretrain two-layer hierarchical bi-directional or single-directional LSTM networks for language processing tasks. In particular, the paper uses the word prediction, either for the next work or randomly missing words, as the self-supervised pretraining tasks. The main idea is to not only train text embedding using context from the same sentence but also take the embedding of the surrounding sentences into account, where the sentence embedding is also context-aware. Experiments are done for document segmentation, answer passage retrieval, extractive document summary.\n\n[Pros]\n\n1.\tThe idea of considering across-sentence/paragraph context for text embedding learning is very reasonable. \n2.\tThe random missing-word completion is also a reasonable self-supervised learning task. \n3.\tThe results are consistently encouraging across all three task. And the performance for “answer passage retrieval” is especially good. \n\n[Cons]\n\n1.\tThe ideas of predicting the next word (L+R-LM) or missing words (mask-LM) have been around and widely used for a long time. Apply this idea to an two-layer hierarchical LSTM is a straightforward extension of this existing idea.\n2.\tFor document segmentation, no comparison with other methods is provided. For extractive document summary, the performance difference between the proposed method and the previous methods are very minor.\n3.\tImportantly, the experiments can be stronger if the learned embedding can be successfully applied to more fundamental tasks, such as document classification and retrieval. \n\nOverall, the paper proposed a reasonable method, but the significance of the paper can be better justified by more solid experiments.\n\n\n']","[50, -20, 20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the clear presentation and experimental support for the authors' claims, while also pointing out missing details and suggesting improvements. This balanced approach indicates a generally positive but not overly enthusiastic sentiment. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively and framing criticisms as suggestions or questions rather than direct criticisms. Phrases like 'It is interesting to see' and 'would be better made if' contribute to the polite tone. The reviewer maintains a professional and constructive approach, which is characteristic of polite academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some pros like 'Good presentation and clear explanations' and 'Meaningful improvements', they also state that 'Novelty is mainly incremental' which is a significant criticism. Even after the authors' feedback, the reviewer maintains this criticism. The politeness score is moderately positive (50) as the language used is professional and respectful. The reviewer thanks the authors for their feedback and provides specific, constructive comments. However, the persistence in the criticism without further elaboration slightly reduces the politeness score from what could have been higher."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the method as 'reasonable' and notes some pros, such as 'consistently encouraging' results. However, they also point out several cons and suggest the paper's significance 'can be better justified'. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout, balancing critique with recognition of the paper's merits. They offer constructive feedback without using harsh or dismissive language, maintaining a respectful tone while providing clear suggestions for improvement.""]"
"['Major Contribution:\nThe paper introduces a method that combines the advantage and of model-based RL and imitation learning and offset their weakness. The method proposes a probabilistic inference approach to analyze the action of the model.\n\nOrganization/Style:\nThe paper is well written, organized, and clear on most points. \n\nTechnical Accuracy:\nI\'m not an expert in RL. The method is obscure to me, but from my point of view, the experiments are done quite thoroughly and the results look good.\n\nPresentation:\nGood. \n\nAdequacy of Citations: \nThe author should consider adding the related works include:\nBojarski, Mariusz, et al. ""End to end learning for self-driving cars."": using CNNs to implement imitation learning for self-driving cars\n\nMultimedia:\nVideos are helpful to understand the method and are well composed.', '# Summary\n\nThis submission proposes a method to combine the benefits of model-based RL and Imitation Learning (IL) for navigation tasks. The key idea is to i) learn a prior over trajectory distributions from a fixed dataset of demonstrations, and ii) use this learned dynamical model for path planning via probabilistic inference. Reaching target waypoints is done by maximizing the trajectory likelihood conditioned on the planning goal. The prior is learned using R2P2 on LIDAR features and past positions. Experiments using the CARLA driving simulator show that this method can outperform standard control, IL, and model-based RL baselines, while flexibly incorporating test-time goals and costs thanks to its probabilistic formulation.\n\n\n# Strengths\n\nThe method is an elegant way to get the best of both worlds in RL and IL, leveraging the recent R2P2 work to estimate a powerful sequential model used for planning via probabilistic inference. The flexibility of the method in considering test-time cost maps and user-defined goals (e.g. to avoid potholes) is appealing, especially since it does not require on-policy data collection.\n\nThe proposed planning-as-inference method can in theory handle the multi-modality present in human demonstrations by using a probabilistic model of the observed behaviors as prior over undirected expert trajectories.\n\nThe approach seem to outperform both model-based and imitation learning baselines on a simplified version of the CARLA benchmark, including on interesting fine-grained metrics (e.g., comfort based).\n\n\n# Weaknesses\n\nThe main weakness of this submission lies in its experimental evaluation, especially the absence of any dynamic objects in the tested environment (""static world CARLA"", section 1). It is unclear how this approach would generalize beyond just staying on the road. How would it handle traffic lights, pedestrians, other drivers, weather variations, and more complex driving tasks than waypoint following by traversing mostly free space? How does the prior generalize to more complex behaviors (e.g, by using more contextual information \\phi)? How robust is the method to noise in the demonstrations, i.e. non-expert or suboptimal behavior? It seems that estimating the generative prior on human behavior might suffer from the same issues as behavior cloning, e.g., the sample inefficiency due to the combinatorial explosion of causal factors explaining complex human behaviors. It might be in fact even harder to estimate that generative model than use a direct discriminative approach (e.g., a modular pipeline), at the cost of reduced flexibility at test time of course. The currently reported sample efficiency (7000 training samples) and near perfect success rate seem to suggest that this (non-standard) version of the CARLA benchmark is too simple (no weather variations, no dynamic obstacles). Comparison to the state of the art (beyond the baselines implemented here) on the original CARLA benchmark seems needed (especially in the ""Nav. dynamic"" task).\n\nThe method is only described very succinctly in section 2. I do not believe there are enough details (especially around the learning algorithm, hyper-parameters, and other important technical elements) for reproducibility at this stage. Section 2.1 is also quite dense for people not familiar with the R2P2 paper. As the main contribution of the paper is to leverage that model for planning and control, it would be great to maybe discuss a bit deeper. Finally, the input modalities are not clear, especially for the baselines: the proposed method is using LIDAR and localization whereas the IL baseline seems to use vision (while the others just use the trajectory). This makes the fairness of the comparison really unclear (LIDAR is a much stronger signal for just staying on the road).\n\nMinor remarks:\n- Why use a proportional controller as a baseline instead of the standard PID one?\n- Section 2.3 seems like it\'s missing the extension of equation 2 to the multi-goal case?\n- Typos in section 3 (""trail-and-error""), section 4 (""autonmous"", ""knowledge to"")\n\n\n# Recommendation\n\nAlthough the theoretical benefits of the method are well-motivated and clear (off-policy learning, probabilistic model, flexibility at test time), the experimental evaluation (custom simple CARLA test, unclear comparison to baselines) and lack of details impeding reproducibility seems to suggest that this submission needs a bit more work. First, adding more details as suggested above and clarifying the experimental protocol seem like a must, but can be easily addressed by an update to the text. Second, it would be ideal to evaluate the approach on the standard CARLA benchmark in order to compare fairly to the prior art. This is much more involved.\n\nI personally like the approach, so although I think it is marginally below the acceptance threshold in its current form, I reserve my judgement for the time being and look forward to the authors\' reply.\n\n\n# Update\n\nThe submission has been drastically rewritten (the diff is massive) and I think it is in much better shape, answering some of my concerns around reproducibility and generalization. Furthermore, it reinforces the strengths of the approach (esp. around its flexibility).\n\nI am willing to recommend acceptance, but I have some further questions (hence I have only updated my score to a 6 for now). They are mostly related to the comparison with IL (important to validate the claim in the paper that the proposed approach is quantitatively better than both existing IL and RL methods). See discussion below for details.', '- Does the paper present substantively new ideas or explore an under explored or highly novel\nquestion? \n\nYes, the paper combines two frameworks (Imitation Learning and Model Base\nReinforcement Learning) to incorporate target information while fitting to the expert distribution. Maybe, the idea is novel but experiments are only in simulation. \n\n- Does the results substantively advance the state of the art?\n\n No, the compared methods are not state-of-the-art.\n\n-  Will a substantial fraction of the ICLR attendees be interested in reading this paper? \n\n Yes a substantial fraction of ICLR attendees might be interested in reading the paper.\n\n - would I send this paper to one of my colleagues to read?\n\nYes. \n\n\n- Quality: \n\nThe key point of this paper is that the proposed algorithm is novel and combines\nthe advantages of Imitation Learning and Model Base Reinforcement Learning. However, the\nauthors do not address the problem of IL when the stochasticity in the environment and/or model\nresults in trajectories outside of expert’s distribution. Additionally, all experiments are done in\nsimulation only and comparisons are made against components of the proposed algorithm instead\nof the state-of-the-art.  This is definitely a limitation of the paper given recent works on imitation learning and model predictive control  as applied to real robotic systems in the task of agile off-road visual navigation. \n\nIn addition, the paper does not provide any detail on the training procedure (Network architecture, cost\nfunction, etc), which makes results hard to reproduce. In addition, the experiments only compare\nthe proposed algorithm to its components, namely proportional controller, IL only controller and\nModel Basel RL only controller.\n\n- Clarity: \n\nEasy to read. Thorough comparison with existing frameworks (Advantages compared to IL and model\nbased RL). \n\nOriginality: \n\n– Novel algorithm presented with success in simulation. \n\n']","[80, -20, -20]","[70, 60, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the paper's major contribution as introducing a valuable method, state that it is 'well written, organized, and clear on most points', and mention that the experiments are thorough with good results. The only slight criticism is that the method is 'obscure' to the reviewer, but this is offset by their admission of not being an expert in the field. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I'm not an expert in RL'), and offers constructive suggestions ('The author should consider adding...'). The tone is professional and courteous, without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer sees potential in the approach, they express significant concerns about the experimental evaluation and lack of details, stating the submission is 'marginally below the acceptance threshold'. However, they do note some strengths and leave room for improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the strengths of the work, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'I personally like the approach' and 'I look forward to the authors' reply', maintaining a collegial tone even while expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (novel idea, interesting to ICLR attendees), they also point out significant limitations (experiments only in simulation, lack of comparison to state-of-the-art methods, missing details on training procedure). The overall tone suggests the paper has potential but falls short in several important areas. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, offering constructive criticism without harsh language. They acknowledge the paper's strengths alongside its weaknesses and use phrases like 'Yes, the paper combines...', 'Easy to read', which contribute to a polite tone. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral professional tone in most parts.""]"
"['This paper gives a model for understanding locally connected neural networks. The main idea seems to be that the network is sparsely connected, so each neuron is not going to have access to the entire input. One can then think about the gradient of this neuron locally while average out over all the randomness in the input locations that are not relevant to this neuron. Using this framework the paper tried to explain several phenomena in neural networks, including batch normalization, overfitting, disentangling, etc.\n\nI feel the paper is poorly written which made it very hard to understand. For example, as the paper states, the model gives a generative model for input (x,y) pairs. However, I could not find a self-contained description of how this generative model works. Some things are described in Section 3.1 about the discrete summarization variables, but the short paragraph did not describe: (a) What is the ""multi-layer"" deterministic function? (b) How are these z_\\alpha\'s chosen? (c) Given z\'s how do we generate x? (d) What happens if we have z_\\alpha and z_\\beta and the regions \\alpha and \\beta are not disjoint? What x do we use in the intersection?\n\nIn trying to understand the paper, I was thinking that (a)(b) The multilayer deterministic function is a function which gives a tree structure over the z_\\alpha\'s, where y is the root. (I have no idea why this should be a deterministic function, intuitively shouldn\'t y be chosen randomly, and each z_\\alpha chosen randomly conditioned on its parent?)  (c) there is a fixed conditional distribution of P(x_\\alpha|z_\\alpha), and I really could not figure out (d). The paper definitely seems to allow two receptive fields to intersect as in Figure 1(b).\n\nWithout understanding the generative model, it is impossible for me to evaluate the later results. My general comments there is that there are no clear Theorems that summarizes the results (the Theorems in the paper are all just Lemmas that are trying to work towards the final goal of giving some explanations, but the explanations and assumptions are not formally written down). Looking at things separately (as again I couldn\'t understand the single paragraph describing the generative model), the Assumption in Theorem 3 seems extremely limiting as it is saying that x_j is a discrete distribution (which is probably never true in practice). I wouldn\'t say ""the model does not impose unrealistic assumptions"" in abstract if you are going to assume this, rather the model just makes a different kind of unrealistic assumptions (Assumptions in Theorem 2 might be much weaker, but it\'s hard to judge that).\n\n==== After reading the revision\n\nThe revised version is indeed more clear about how the teacher network works, and I have tried to understand the later parts of the paper again. The result of the paper really relies on the two assumptions in Theorem 2. Of the two assumptions, the first one seems to be intuitive (and it is OK although exact conditional independence might be slightly strong). The second assumption is very unclear though as it is not an assumption that is purely about the model/teacher network (which are the x and z variables), it also has to do with the learning algorithm/student network (f\'s and g\'s). It is much harder to reason about the behavior of an algorithm on a particular model and directly making an assumption about that in some sense hides the problem. The paper mentioned that the condition is true if z is fine-grained, but this is very vague - it is definitely true if z is super fine-grained to satisfy the assumption in Theorem 3, but that is too extreme.\n\nOverall I still feel the paper is a bit confusing and it would benefit from having a more concrete example. I like the direction of the work but I can\'t recommend for recommendation at this stage.', 'The authors propose a framework that utilizes the teacher-student setting to evaluate deep locally connected ReLU network. The framework explicitly formulates data distribution, which has not been considered by previous works. The authors also show that their framework is compatible with Batch Normalization and favors disentangled representation when data distributions have factorizable structures. Based on this framework, the authors re-explain some common issues of deep learning, such as overfitting. \n\nMy major concerns are as follows.\n\n1. The framework is based on the teacher-student setting, and the authors claim that ""the teacher generates classification label via a hidden computational graph"". However, how the teacher can be designed is not clear in the paper.\n\n2. The data distribution included in this paper is $P(z_{\\alpha}, z_{\\beta})$, where $z_{\\alpha}$ and $z_{\\beta}$ are all summarization variables. From this perspective, it only has an indirect connection with original data distribution $P(x)$ or $P(x_{\\alpha}, x_{\\beta})$, and thus it could be questionable whether $P(z_{\\alpha}, z_{\\beta})$ is a convincing representation.\n\n3. The authors may want to conduct more experiments to better support their claims.\n', 'This paper proposes a new approach to understand the theory of RELU neural networks. Using a teacher-student setting, this paper studies the batch normalization and the disentangled representations of neural networks. However, the definitions of some of the concepts and notation are not sufficiently clear. In addition, the assumptions that the main results of this paper depend on do not have clear intuitions.\n\nDetailed comments:\n\n1. It seems that this paper over claims its contribution. It is not clear why the ""teacher-student setting"" can be called a theoretical framework, even the definitions of the teacher and the student are not clear. It seems that the new framework is just a way to compute the relations of the gradients of neurons based on a few assumptions (Theorem 2).\n\n2. I found it very hard to follow the notations given in this paper. The main reason is that many of the terms appear without a definition, and the reader has to guess what they stand for. For example, in equation (2), w_{jk} seems to be the weight between nodes j and k, where k is a child of j. But this term is not defined. As another example, all the matrices in Theorem 9 are not defined. They just suddenly appear. In addition, S(f) in (11) is not defined. I would suggest the authors to spend one section to carefully define everything. \n\n3. The theorems all depends on some assumptions that are unclear whether will hold in practice or not. For example, in theorem 2, it is hard to see what kind of data distribution satisfy these three conditions. Although in Theorem 3 the author gave a sufficient condition, we still don\'t know what kind of $X$ satisfies this. For example, does Gaussian distribution satisfy those? This problem also happens to other theorems. It would be much better to make sure that these assumptions are unrealistic.\n']","[-60, -20, -50]","[20, 50, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's clarity and methodology. They state the paper is 'poorly written' and 'very hard to understand', and they 'can't recommend for recommendation at this stage'. However, they do acknowledge some improvements in the revised version and like the direction of the work, preventing an extremely negative score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I feel' and 'I like the direction of the work' to soften criticism, and provide constructive feedback. However, some direct criticisms like 'poorly written' prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and potential of the proposed framework, they express 'major concerns' about key aspects of the work. The review begins positively by summarizing the contributions, but then lists three significant issues, indicating a overall slightly negative sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present their concerns as 'My major concerns' rather than using more critical language, and they suggest improvements ('may want to conduct more experiments') rather than making demands. The review maintains a respectful tone while providing constructive criticism."", ""The sentiment score is -50 because the review expresses several criticisms and concerns about the paper, including unclear definitions, over-claiming contributions, and unrealistic assumptions. However, it's not entirely negative as it acknowledges the paper's attempt to propose a new approach. The politeness score is 20 because while the reviewer is critical, they use relatively polite language such as 'It seems that' and 'I would suggest,' and provide constructive feedback. The reviewer also uses phrases like 'It would be much better' which shows a desire for improvement rather than outright dismissal. However, the overall tone is more neutral than overtly polite, hence the modest positive score.""]"
"['This paper formulates a new method called human-guided column networks to handle sparse and noisy samples. Their main idea is to introduce human knowledge to guide the previous column network for robust training.\n\nPros:\n\n1. The authors find a fresh direction for learning with noisy samples. The human advice can be viewed as previledged information.\n\n2. The authors perform numerical experiments to demonstrate the efficacy of their framework. And their experimental result support their previous claims.\n\nCons:\n\nWe have three questions in the following.\n\n1. Motivation: The authors are encouraged to re-write their paper with more motivated storyline. The current version is okay but not very exciting for idea selling. For example, human guidance should be your selling point, and you may not restrict your general method into ColumnNet, which will limit the practical usage.\n\n2. Related works: In deep learning with noisy labels, there are three main directions, including small-loss trick [1], estimating noise transition matrix [2,3], and explicit and implicit regularization [4]. I would appreciate if the authors can survey and compare more baselines in their paper instead of listing some basic ones.\n\n3. Experiment: \n3.1 Baselines: For noisy labels, the authors should add MentorNet [1] as a baseline https://github.com/google/mentornet From my own experience, this baseline is very strong.\n3.2 Datasets: For datasets, I think the author should first compare their methods on symmetric and aysmmetric noisy data. Besides, the authors are encouraged to conduct 1 NLP dataset.\n\nBy the way, if your human guidance is totally wrong, how your model handle such extreme cases? Could you please discuss this important point in your paper?\n\nReferences:\n\n[1] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n\n[2] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n\n[3] J. Goldberger and E. Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In ICLR, 2017.\n\n[4] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.', 'The  paper  introduces  a  method  to  incorporate  human  advises  to  deep  learning  by  extending  Column  Network  (CLN)  -  a  powerful  graph  neural  network  for  collective  classification. \n\nThe  problem  is  quite  interesting  and  is  practical  in  real-world. However, I have some concerns:\n\nCorrectness\n==========\nIn the main modification to the CLN in Eq (3), the rule-based gates are introduced to every hidden layer. However, the functional gradient with respect to the ""advise gradient"" is only computed for the last layer (at the end of Section 3). The exponential gates may cause some instability issue due to its unboundedness. \n\nEvaluation\n=========\nThe  questions  in  experiment  (Can  K-CLNs  learn  efficiently/effectively  with  noisy  sparse  samples?)  do  not  support  the  problem  statement  about  human  advice  incorporation.  Thus,  all  they  did  in  the  experiment  is  trying  to  compete  against  CLN.\n\nI would believe that the improvement (which I trust is real) depends critically on the quality and quantity of the human-crafted rules, much in the same way that feature engineering plays the major roles in the classical structured output prediction. Hence more details about the rules set used in experiments should be given.\n\nPresentation\n===========\nIn  the  experiment  part,  the  authors  need  to  describe  their  model  configuration.  The  presentation  of  datasets  consumes  a  lot  of  space  and  can  be  reduced (e.g., using a table).  This  paper  displays  many  unnecessary  figures  that  consumes  a  lot  of  space.  The  paper  provides  some  unnecessary  text  highlights  in  bold.  \n', 'This work proposes a variant of the column network based on the injection of human guidance. The method does not make major changes to the network structure, but by modifying the calculations in the network. Human knowledge is embodied in a defined rule formula. The method is flexible and different entities correspond to different rules. However, the form of knowledge is limited and simple. Experiments have shown that the convergence speed and results are improved, but not significant.\n\nMinor：\nExample 2: ""A"" -> ""AI"".']","[20, -30, -20]","[70, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as finding a 'fresh direction' and performing experiments that support their claims. However, they also list several cons and questions, which tempers the overall positivity. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, such as 'The authors are encouraged to...' and 'I would appreciate if...'. They also provide constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer maintains a professional tone, offering specific recommendations and even providing relevant references to support their points."", ""The sentiment score is -30 because while the reviewer acknowledges the problem as interesting and practical, they express several concerns about the paper's correctness, evaluation, and presentation. The tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism while clearly stating their concerns. They use phrases like 'I have some concerns' and 'I would believe that' which maintain a polite tone while providing constructive feedback. The reviewer also acknowledges positive aspects, such as the interesting nature of the problem, which contributes to the overall politeness."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work (improved convergence speed and results, flexibility), they also point out limitations (limited and simple form of knowledge, not significant improvements). The overall tone suggests that the work is somewhat underwhelming. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive feedback without harsh criticism. They objectively state both strengths and weaknesses of the work, maintaining a professional tone throughout the review.']"
"['The paper presents and evaluates different common inductive biases in Deep RL. These are systematically evaluated on different experimental settings.\n\nThe paper is easy to read and the authors explain well the setting and their findings. The comparison and evaluations is well conducted and valuable contribution to the literature.  I would have liked some more details on the motivating example in section 3.1, maybe with a figure supporting the explanation of the example. ', 'This paper contains various numerical experiments to see the effects of some heuristics in reinforcement learning. Those heuristics include reward clipping, discounting for effective learning, repeating actions, and different network structures. However, since the training algorithms also greatly affect the performance of RL agents, it seems hard to draw any quantitive conclusions from this paper.\n\nDetailed comments:\n\n1. It seems that actor-critic algorithms are defined for RL with function approximation. What is the tabular A2C algorithm? A reference in Section 3.1 would be better.\n\n2. This paper claims to study the ""inductive biases"", which is not clearly defined. How to quantify those biases and how to measure ""generality""?\n\n3. Are there any quantitive conclusions that can be drawn from the experiments?\n\n4. Since the performance of RL agents also relies on initialization and the training algorithms. There are a lot of tricks of optimization for deep learning. How to measure the ""inductive biases"" by ruling out the effects of training algorithms?\n', ""This paper focuses on deep reinforcement learning methods and discusses the presence of inductive biases in the existingRL algorithm. Specifically, they discuss biases that take the form of domain knowledge or hyper-parameter tuning. The authors state that such biases rise the tradeoff between generality and performance wherein strong biases can lead to efficient performance but deteriorate generalization across domains. Further, it motivates that most inductive biases has a cost associated to it and hence it is important to study and analyze the effect of such biases. \n\nTo support their insights, the authors investigate the performance of well known actor-critic model in the Atari environment after replacing domain specific heuristics with the adaptive components. The author considers two ways of injecting biases: i) sculpting agents objective and ii) sculpting agent's environment. They show empirical evidence that replacing carefully designed heuristics to induce biases with more adaptive counterparts preserves performance and generalizes without additional fine tuning.\n\nThe paper focuses on an important concept and problem of inductive biases in deep reinforcement learning techniques. \nAnalysis of such biases and methods to use them judiciously is an interesting future direction. The paper covers a lot of related work in terms of various algorithms and corresponding biases.\nHowever, this paper only discusses such concepts at high level and provides short empirical evidences in a single environment to support their arguments. Further, both the heuristics used in practice and the adaptive counterparts that the paper uses to replace those heuristics are all available in existing approaches and there is no novel contribution in that direction too.\nFinally, the adaptive methods based on parallel environment and RNNs have several limitation, as per author's own admission.\n\nOverall, the paper does not have any novel technical contributions or theoretical analysis on the effect of such inductive biases which makes it very weak. Further, there is nothing surprising about the author's claims and many of the outcomes from the analysis are expected. The authors are recommended to consider this task more rigorously and provide stronger and concrete analysis on the effects of inductive biases on variety of algorithms and variety of environments.\n\n\n\n""]","[80, -20, -60]","[70, 50, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'easy to read' and state that the authors 'explain well the setting and their findings'. The reviewer also calls the work a 'valuable contribution to the literature'. The only slight criticism is a request for more details on one section, which prevents a perfect score. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering praise and constructive feedback. They phrase their suggestion for improvement politely ('I would have liked some more details'). The tone is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's content, they express skepticism about the ability to draw quantitative conclusions from the experiments. The opening statement is neutral, but the overall tone suggests limitations in the study's approach and findings. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and pose questions for improvement without using harsh or dismissive language. The reviewer maintains a balanced tone, acknowledging the paper's content while pointing out areas for clarification and improvement in a polite manner."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper 'does not have any novel technical contributions or theoretical analysis' and describes it as 'very weak'. They also mention that there is 'nothing surprising' about the authors' claims. However, it's not entirely negative as the reviewer acknowledges that the paper focuses on an 'important concept and problem'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'the authors are recommended to' rather than making blunt demands. The reviewer also acknowledges some positive aspects of the paper before critiquing it, which is a polite approach. However, the language is not overly polite or deferential, maintaining a neutral professional tone for the most part.""]"
"['After rebuttal, I adapted the score. See below for original review.\n--------------------------------------------\n\n\nThe authors implement a two-stage multi-objective optimization scheme to optimize neural network architectures with several conflicting goals.\nI can not accept the paper in its current form.\n\nIn short, I have the following main criticisms:\n1. use of crowding distance(CD) instead of hypervolume-contribution.\nCD is not consistent with the HV estimator, especially CD might remove solutions that have a large HV-contribution and thus HV will not increase monotonically. The effect is even visible in Figure 8c) as in iteration 22, HV is decreasing as crowding distance removes a good offspring. In short: Crowding distance should not be used as long as the number of objectives does not prohibit computing the HV-contribution.\n\n2. No good justification of BN. It is unclear to me why BN should be used instead of more iterations at stage 1. In 4.4 BN is only compared to the uniform initialization, but this comparison has no meaning given that we already have an optimized front that improved on the uniformly sampled distribution. To be honest, the samples shown from BN do not look very convincing as a lot of very poor architectures are created.\n\nA proper comparison would be comparing the 2-step approach with only the first step and the same budget. Then we could compare samples from both distributions (either sampling from the front using mutation/crossover or sampling from BN). Also we would have a fair comparison of the obtained fronts and HV-values.\n\n3. Ablation study cross-over\nI am not convinced by the results presented. The paper says this is a ""small scale"" study but does not give the number of iterations/samples. It is clear that in the setup of the mutation operator cross-over might help, simply because it can change many more connections in a single iteration than mutation alone, which is limited to max 1 change. Allowing up to two mutations and no crossover could already proof to be better (orsmaller size of offspring population, see below)\n\n\nSmaller concerns:\n\n1. The results suggest that the uniform distribution might not be tuned well, as it only covers the ""expensive"" networks but not the ""cheap"" networks. A better initialization scheme that covers the x-axis better might already show vastly different results. As the Flop-objective is cheap to compute and does not require simulation, one could expect to tune this offline before initialization.\n\n2. No handling of Noise.\nDuring optimization, the chosen starting point and SGD algorithm will introduce noise into the process. Thus, the final test accuracy will be noisy. As an elitist dominance scheme is used, one might easily end up with an architecture that has a large variance when trained, i.e. when performing a final training pass on the full dataset, the performance might be very different. Moreover, the algorithm might stop convergence towards the true pareto front as it is held back by noisy ""good"" results. This should be discussed in the paper\n\n3. A single-offspring approach might be better than sampling a full population (or offspring size in the order of parallel instances one can expend to run). 40 sounds excessive given that the sampling distribution is only improved through selection and given that the pareto front approximation appears to include less than 40 elements. This might also affect the results in the ablation study for cross-over: more iterations with reduced offspring size allows for more mutations of successful offspring.\n\n4. Some unclear or wrong wordings:\npage 4: ""As a consequence[...] the best solution encountered [...] will always be present in the final population. "" What do you consider ""best"" in a 2-objective problem? Do you mean: the best in each objective?\npage 6, footnote1: this is not true. even without crossover the selection operator ties the solutions together, an offspring has to beat any point in the population, not necessarily its direct parent.\n\n5. Figure 8a) does not include the state of the art result for CIFAR10, see for example \nhttp://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130', '\n- Summary\nThis paper proposes an evolutionary-based method for the multi-objective neural architecture search, where the proposed method aims at minimizing two objectives: an error metric and the number of FLOPS. The proposed method consists of an exploration step and an exploitation step. In the exploration step, architectures are sampled by using genetic operators such as the crossover and the mutation. In the exploitation step, architectures are generated by a Bayesian Network. The proposed method is evaluated on object classification and object alignment tasks.\n\n- Pros\n  - The performance of the proposed method is better than the existing multi-objective architecture search methods in the object classification task.\n  - The effect of each proposed technique is appropriately evaluated. \n\n- Cons\n  - The contribution of the proposed method is not clear to me. The proposed method is compared with the existing multi-objective methods in terms of classification accuracy, but if we focus on that point, the performance (i.e., error rate and FLOPs) of the proposed method is almost the same as those of the random search judging from Table 4. It would be better to compare the proposed method to the existing multi-objective methods in terms of classification accuracy and other objectives.\n  - This paper argues that the choice of the number of parameters is sub-optimal and ineffective in terms of computational complexity. Please provide more details about this point. For example, what is the drawbacks of the number of parameters, what is the advantages of FLOPs for multi-objective optimization?\n  - Please elaborate on the procedure and settings of the Bayesian network used in this paper.\n  - It would be better to provide discussions of recent neural architecture search methods solving the single-objective problem.\n', 'This paper proposes a search method for neural network architectures such that two (potentially) conflicting objectives: maximization of final performance and minimization of computational complexity can be pursued simultaneously. The motivation for the approach is that a principled multiobjective search procedure (NSGA-II) makes it unnecessary to manually find the right trade-off between two objectives, and simultaneously finds several solutions spanning the tradeoff. It is also capable of finding solutions from the concave regions of the Pareto-front. Multiobjective search for architectures has been explored in recent work, so the primary contribution of this paper is to show its utility in a more general and perhaps more powerful setting.\n\nThe paper is clearly written and is easy to understand, except that the parenthetical citations used appear to differ from the ICLR style and cause confusion. The authors delve into details of the approach though many aspects are from past work. I think that this makes the paper more self-contained and easy to understand, even if it makes the paper longer than the suggested length of 8 pages. I also found the comparisons and ablations shown in Figures 8 and 9 to be useful and informative. \n\nHowever, based on the presented results on the CIFAR-10 dataset (which can be compared to past work), I am not convinced of the utility of multiobjective optimisation for architecture search. There are a few reasons for this:\n\n1. The best architectures found by previous methods in the literature are already at a similar or better accuracy. It appears that NSGA-Net did not succeed in finding architectures that a) outperform past results with higher FLOPs, or b) match past results with fewer FLOPs. I understand that in principle, a benefit of NSGA-Net is that other solutions with lower accuracy and fewer FLOPs are also found simultaneously, but these models are not discussed or analysed much in detail. What precisely is the utility of the proposed method then? This consideration is also complicated by the next point.\n\n2. For the evaluation in the paper, the network with the lowest accuracy is extrapolated — the number of filters in each layer are increased and the network is retrained. Is this procedure justified in general? How to know the best increasing factor? \nSince lowering the computational cost is an objective of the search, changing the cost of an obtained solution does not seem principled.  Moreover, changing network sizes will affect any ordering of networks by accuracy since optimal hyperparameters for both optimization and regularization may change. In general, it is rather difficult to decouple hyperparameter search from architecture search.\n\n3. A baseline that is missing in the paper is hyperparameter search, which can often yield very good performance for a given architecture. Tuning regularization in particular is often crucial. Since NSGA-Net trains 1200 networks, a comparable search would consider a known architecture e.g. Densenet and allocate 200 trials each to 6 architectures of different FLOPS (or 100 each to 12 architectures). How effective is this simple procedure at obtaining a good tradeoff front?\n\nDue to these concerns, I am presently unconvinced by the results in this paper, though I think that in general multiobjective optimization of architectures should be a fruitful direction. \n\nMinor question: Figure 9(b) indicates that experiments were also conducted on the SVHN and MNIST datasets. Why are these results not reported?']","[-70, 20, -50]","[-20, 60, 50]","[""The sentiment score is -70 because the reviewer states they 'can not accept the paper in its current form' and lists several major criticisms. The overall tone is quite negative, with phrases like 'I am not convinced' and pointing out multiple flaws. However, it's not entirely negative as the reviewer does provide constructive feedback for improvement. The politeness score is -20 because while the reviewer is direct and critical, they maintain a professional tone. The language isn't overtly rude, but it's not particularly polite either. Phrases like 'I can not accept' and 'No good justification' come across as somewhat blunt. The reviewer doesn't use softening language or positive reinforcement, which contributes to the slightly negative politeness score."", ""The sentiment score is slightly positive (20) because the review begins with a neutral summary and lists both pros and cons. The pros mention better performance and appropriate evaluation, which are positive points. However, the cons section is longer and raises several concerns, which balances out the positivity. The overall tone is constructive rather than overtly negative.\n\nThe politeness score is moderately high (60) because the reviewer uses respectful and professional language throughout. They phrase criticisms as suggestions (e.g., 'It would be better to...') rather than direct criticisms. The reviewer also acknowledges the paper's strengths before discussing areas for improvement. The language is not overly formal or deferential, but maintains a courteous and constructive tone appropriate for peer review."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (clear writing, informative comparisons), they express significant concerns about the utility and effectiveness of the proposed method. The reviewer states they are 'unconvinced by the results' and lists several major issues, indicating an overall negative sentiment. However, it's not extremely negative as they still see potential in the general direction of the research.\n\nThe politeness score is 50 because the reviewer uses respectful and professional language throughout. They acknowledge positive aspects before presenting criticisms, use phrases like 'I think' and 'I understand' to soften their critiques, and frame their concerns as questions or suggestions rather than harsh criticisms. The tone is constructive rather than dismissive, even when expressing doubts about the paper's conclusions.""]"
"[""The paper proposes a class of Evolutionary-Neural hybrid agents (Evo-NAS) to take advantage of both evolutionary algorithms and reinforcement learning algorithms for efficient neural architecture search. \n\n1. Doesn't explain how exactly the mutation action is learned, and missing the explanation of how RL acts on its modification on NAS (Evo-NAS). \n2. Very poor explanation on LEARN TO COUNT experiment. The experiment contains difficult setups on a toy data, which makes it difficult to repeat. In figure 3, the paper says that the sample efficiency of the Evo-NAS strongly outperforms both the evolutionary and the neural agent. However, where the strength comes from is not discussed in detail. In figure 2, the paper claims that PQT outperforms Reinforce for both the Neural and the Evo-NAS agent. For the Evo-NAS agent, the gain is especially pronounced at the beginning of the experiment. Thus, the paper concludes that PQT can provide a stronger training signal than Reinforce. However, how much stronger training signal can obtain of the proposed method is not discussed. Because the experiments of 5.1 is setup on a toy data with complicated parameters. The conclusions based on this data set is not convincing. It would be better to add comparative results on the CIFAR and Imagenet data for convenient comparisons with state-of-the-art. \n3. Confusing notation and experimental setup. In 5.1, the sequence a is first defined as <a1, a2, .., an>. Then, after eq.2, the sequence a is given as a=<1, 2, ..., n>. It would be better to use different symbols here. "", ""Summary:\n\nThe paper proposes a hybrid approach which combines evolution and RL. The key idea is to conduct tournament selection over a population of architectures with learned mutations. The mutations are defined as the output of an RNN controller which either reuses or alters the sequence descriptor of the parent at each step. The proposed hybrid architect is evaluated on both synthetic and text classification tasks and then compared against pure evolutionary and RL-based agents.\n\nPros:\n\n* The method can be viewed as a generalization of conventional evolution by replacing the handcrafted (uniform) distribution of mutations with a learned one. On the one hand, this should hopefully improve the sample efficiency of pure genetic methods since the population can evolve towards more meaningful directions, assuming useful patterns can be learned by the mutation controller. On the other hand, mutating existing architectures seem a easier task than sampling the entire architecture from scratch.\n* The synthetic experiment is interesting, though it's hard to draw any conclusions based a single task.\n\nCons:\n\n* To my knowledge, all text classification tasks used in 5.2 are quite small. There is no evidence that the method can scale to and work well on large-scale tasks, where improving the sample efficiency becomes truly crucial and challenging. \n* It is good to see comparisons against pure evo and RL within the authors' own search space. However, the advantage of the proposed evo-NAS, especially when evaluated on real-world text classification tasks, does not seem significant enough. In particular, there is a clear overlap between the performance of architectures found by NAS, evo and evo-NAS (Figure 4). The advantage of evo-NAS is even smaller if we compare the very best model (as can be read from Figure 4) instead of the average among the top 10 (as reported in Table 2). In my option, performance of the strongest model is arguably more interesting than the averaged one in practice.\n* Since no results on CIFAR or ImageNet are provided as in most prior works in the literature, it is impossible to empirically compare the method with the state-of-the-art. The experiments would be more convincing if a comparison can be provided on those benchmarks. Otherwise, it is possible that the current search space & hyperparameters are tailored towards evo-NAS and it remains unclear whether the method can generalize well to other domains and/or search spaces.\n"", 'Review: \nThe paper introduces a novel way to do architecture search that uses an RNN to guide the mutation operation. The method and the motivation of the idea as long with the related work are all clearly described. However, the experiments section does not show a big uplift of the method versus the baselines and the number of types of tasks is relatively small (artificial and text). \n\nCons:\n- No image task\n- No large scale task to show the scalability\n- No baselines that are not coming from AUTO-ML to show the relative performance of a classical method']","[-50, -20, -20]","[0, 60, 50]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several shortcomings of the paper, such as poor explanations, confusing notations, and unconvincing conclusions. However, it's not entirely negative as it acknowledges the paper's proposal of a new class of agents. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state their criticisms plainly, using phrases like 'Doesn't explain', 'Very poor explanation', and 'Confusing notation', which are critical but not impolite. The reviewer also offers suggestions for improvement, which is constructive but not particularly polite in tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they express more significant concerns in the cons section. The reviewer points out limitations in the experiments, lack of evidence for scalability, and questions the significance of the method's advantage over existing approaches. However, the score is not deeply negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their critiques, such as 'To my knowledge,' and 'In my opinion,' which softens the impact of the criticisms. The reviewer also balances their feedback by mentioning both pros and cons, which is a polite approach to reviewing. There are no rude or harsh statements, and the criticisms are presented as constructive feedback rather than attacks on the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and clarity of the paper's idea, they express significant concerns about the experimental results and limitations. The reviewer points out that the method doesn't show a big improvement over baselines and the scope of tasks is limited. The 'Cons' section further emphasizes these limitations. However, the score isn't deeply negative because the reviewer does recognize positive aspects of the paper.\n\nThe politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They begin with positive observations about the paper's clarity and novelty before moving on to criticisms. The criticisms are presented as factual observations rather than harsh judgments. The reviewer uses phrases like 'does not show' and 'relatively small' rather than more negative language. The 'Cons' are listed objectively without personal attacks or overly critical language.""]"
"['CAML seems an interesting meta-learning algorithm. I like the idea that the context parameters are used to modulate the whole network during the inner loop of meta-learning, while the rest of the network parameters are adaped in the outer loopand shared across tasks. Also, it is good to see that CAML is competitive with on few shot CNNs.\n\nThe paper is very well presented. Experiments are reasonably solid.\n\nIf I understood correctly, although CAML has achieved better accuracy it seems CAML still requires a decent amount of parameter/network structure optimisation. Would be good if the paper has a section talking about practical tricks of how to find the best CAML hyperparameter quickly.', 'They are proposing a meta-learning method inspired by previous method, MAML. Their idea is separating the parameters in to two groups of context and shared parameters. The context parameters are learned through back-propagation of inner-loop and represents embedding for individual task. Shared-parameters on the other hand are shared between all tasks, and are learned in the outer-loop. \n\nCompared to MAML, the pros of their method is as follows:\n- Less sensitive to learning rate: thus more robust to hyper parameters.\n- Does not prone to overfit as MAML does.\n- It is easier to implement, more efficient from memory view point.\n\nCons in general,\n-  In Mini-ImgeNet data set, although they are beating MAML, but they are not able to beat other competitors in 5-shot classification.\n- They could have explored applying their method to deep residual networks and compare their results.\n', ""The paper talks about Meta-Learning where some of the parameters of the models adapt to the new task (context parameters) and rest of the parameters are kept fixed (shared parameters). The authors propose a more general approach and show how CAML works for supervised learning and reinforcement learning paradigms. \n\nquality - The paper is written with good mathematical notation and in general is of high quality. The references to related work and motivation of the problem is good.\n\nclarity - While the paper is clear in many parts, it can be a lot better. Specifically it is unclear why authors chose regression, classification and RL to make their point without landing either one of them fully confidently.\n\noriginality - the idea is good and general enough to be applicable for many situations. While variants of this idea have been tried with fine-tuning for transferred learning I still think this work can classify as original and novel.\n\nsignificance of this work - The significance of meta learning is good but based on the experiments authors conducted I am worried it has little significance. \n\npros and cons - Overall, while I am supportive of a weak accept because of the idea and it's broad applicability I feel authors should maybe chose one of the tasks and show much more value in using the CAML framework. The three tasks they chose are all toy problems and do not instill confidence in the validity of CAML for either large scale experiments or in setups where distribution is changing but tasks remain same. It would be great to strengthen the paper with a more cleaner story on the experiments section and show CAML achieves SOA convincingly. "", 'Summary\nCAML is a gradient-based meta-learning method closely related to MAML. It divides model parameters into disjoint sets of task-specific parameters $\\phi$ which are adapted to each task and task-independent parameters $\\theta$ with are meta-learned across tasks. $\\phi$ are then interpreted as an embedding and fed as input to the model (parameterized by $\\theta$). Experiments demonstrate that this approach performs on par with MAML while adapting far fewer parameters. An additional benefit is that this approach is less sensitive to the adaptation learning rate and is easier to implement and faster to compute.\n\nStrengths\nWhile not really explained in the paper, this work connects gradient-based to embedding-based meta-learning approaches. Adaptation is via gradient descent, but the adapted parameters are then re-interpreted as an embedding.\nThe method has the potential to perform on par with MAML while being simpler and faster.\nThe paper is well-written.\n\nWeaknesses\nThe field of meta-learning variants is crowded, and this paper struggles to carve out its novelty. \nRusu et al (LEO) optimize a context vector, which is used to generate model parameters. Reducing the generative model to a point estimate, how is this different from generating the FiLM parameters as a function of context as done in CAML? \nLee and Choi (MT-nets) propose a general formulation for learning which model parameters to adapt. CAML is simpler in that the model parameters to adapt are chosen beforehand to be inputs. \nSnell et al. / Oreshkin et al. are prototype-based methods infer context via a neural network rather than optimizing for it.\n\nIn this context, CAML appears to be yet another point drawn from the convex hull of choices already explored in episodic meta-learning (these choices can be broadly grouped into task encoding and conditional inference). The paper must then rest on its experimental results, which are at present unconvincing.\n\nOn the whole, the experimental results seem weak and analysis results largely uninformative. The method is benchmarked on the toy tasks of sinusoid regression and a 2-D point mass, as well as mini-ImageNet few-shot classification. The sinusoid and point mass navigation are toy and compared only to MAML, so it is hard to draw conclusions from those experiments. For mini-ImageNet, while CAML outperforms MAML, it seems that the pertinent comparison is with MT-NET (which CAML does not outperform) and LEO (missing fair comparison?).\n\nQuestions regarding experiments\n - CAML is robust to the adaptation learning rate, but isn’t this true of any scheme that separates meta-learned and adapted parameters into disjoint sets? (e.g. also true of Lee and Choi?) \n - The visualizations of the context parameters are nice, but interpreting much higher dimensional context vectors (which would be necessary for harder tasks) is more difficult, so I’m not sure what to take away from this? It’s very unsurprising that the 2-D context vector encodes x and y position in the point mass experiment, for example. \n - I am confused by the comparison between adapting input parameters versus subsets of nodes at each layer or entire layers for the sinusoid regression task. Adapting subsets of nodes at each layer roughly corresponds to Lee and Choi, yet the reported numbers are quite different? \n - In Table 3, which CAML is a fair comparison (in terms of network size and architecture) to MT-NET? \n\nEditorial Notes\nIntro paragraph 3: fine-tuning image classification features for a semantic segmentation task is not a good example of task independent parameters, since fine-tuning end-to-end gives significant improvements.\nRelated work paragraph 2: Initializing context parameters to zero is not the only difference with Rei et al (2015), and seems a strange thing to highlight?\nTables 1 and 2: state what the task is in the caption\n']","[80, 60, 20, -30]","[90, 50, 60, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the CAML algorithm, describing it as 'interesting' and 'competitive'. They also praise the paper's presentation and experiments. The only slight criticism is a suggestion for additional information, which doesn't significantly detract from the overall positive tone. The politeness score is 90 (very polite) due to the use of respectful and constructive language throughout. The reviewer uses phrases like 'I like the idea' and 'it is good to see', which are encouraging. Even when making a suggestion, they frame it politely as 'Would be good if'. The overall tone is professional, appreciative, and supportive, without any harsh or critical language."", 'The sentiment score is 60 (positive) because the review starts by objectively describing the proposed method and then lists several pros, indicating a generally positive view. The cons mentioned are relatively minor and presented as areas for improvement rather than severe criticisms. The politeness score is 50 (slightly polite) because the language is professional and neutral, without any harsh criticisms or overly effusive praise. The reviewer presents both pros and cons in a balanced manner, using objective language throughout.', ""The sentiment score is slightly positive (20) because while the reviewer expresses support for a 'weak accept' and acknowledges the paper's good qualities (e.g., 'good mathematical notation', 'high quality', 'good' references and motivation), they also raise several concerns and suggest significant improvements. The overall tone is cautiously optimistic but with reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balancing criticism with praise, and phrases suggestions constructively (e.g., 'it would be great to strengthen the paper'). They avoid harsh or dismissive language, instead offering specific, actionable feedback in a professional manner."", ""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper (e.g., 'well-written', 'potential to perform on par with MAML'), they express significant concerns about its novelty and experimental results. Phrases like 'struggles to carve out its novelty', 'experimental results seem weak', and 'unconvincing' indicate a generally negative sentiment. However, the criticism is not entirely harsh, hence a moderately negative score rather than an extremely negative one. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms (e.g., 'I am confused by...', 'Questions regarding experiments') and acknowledge positive aspects before presenting concerns. The review avoids personal attacks or overly harsh language, demonstrating a polite approach to academic criticism.""]"
"['This paper suggests to rethink about the bias-variance tradeoff from statistical machine learning in the context of neural networks. Based on some empirical observations, the main claims in this work are that (1) it is not always the case that the variance will increase when we use bigger neural network models (particularly, by increasing the network width); (2) the variance should be decomposed into two parts: one part accounts for the variance caused by random initialization of network parameters/optimization and the other part is caused by ""sampling of the training set"".\n\nFor the first claim is based the empirical observation that increasing the number of hidden units did not cause the incrase of variance (as in figure 1). However, to my understanding, it only means increasing the number of hidden units is probably not a good way to increase the network capacity. In other words, this cannot be used as an evidence that the bias-variance tradeoff is not valid in neural network learning.\n\nFor the second claim, I don\'t like the way that they decompose the variance into two parts. To be clear, the classical bias-variance tradeoff doesn\'t consider the optimization error as an issue. For a more generic view of machine learning errors, please refer to ""The Tradeoffs of Large Scale Learning"" (Bottou and Bousquet, 2008). In addition, if the proposed framework wants to include the optimization error, it should also cover some other errors caused by optimization, for example, early stopping and the choice of a optimization algorithm.\n\nBesides these high-level issues, I also found the technical parts of this paper is really hard to understand. For example,\n\n- what is exactly the definition of $p(\\theta|S)$? The closely related case I can think about is in the Baysian setting, where we want to give a prior distribution of model (parameter). But, clearly, this is not the case here. \n- similar question to the ""frequentist risk"", in the definition of frequentist risk, model parameter $\\theta$ should be fixed and the only expectation we need to compute is over data $S$\n- in Eq. (5), I think I need more technical detail to understand this decomposition.', ""The paper offers a different and surprising view on the bias-variance decomposition. The paper shows, by a means of experimental studies and a simplified theoretical analysis, that variance decreases with the model complexity (in terms of the width of neural nets) , which is opposite to the traditional bias-variance trade-off.\n\nWhile the conclusion is surprising, it is somewhat consistent with my own observation. However, there are potential confounding factors in such an experimental study that needs to be controlled for. One of these factors is the stability of the training algorithm being used. The variance term (and the bias) depends on the distribution p(theta|S) of the model parameters given data S. This would be the posterior distribution in Bayesian settings, but the paper considers the frequentist framework so this distribution encodes all the uncertainty due to initialisation, sampling and the nature of SGD optimizer being used. The paper accounts for the first two, but how about the stability of the optimiser? If the authors used a different optimizer for training, what would the variance behave then? A comment/discussion along this line would be interesting.\n\nIt is said in Section 3.1 that different random seeds are used for estimating both the outer and inter expectation in Eq. 5. Should the bootstrap be used instead for the outer expectation as this is w.r.t. the data? Another point that isn't clear to me is how the true conditional mean y_bar(x) = E(y|x)  is computed in real-data experiments, as this quantity is typically unknown. \n\n"", 'This paper studies variance-bias tradeoff as a function of depth and width of a neural network. Experiments suggest that variance may decrease as a function width and increase as a function of depth. Some analytical results are presented why this may the case for width and why the necessary assumptions for the depth are violated.\n\nMain comment on experiments: if I am correct the step size for optimization is chosen in a data-dependent way for each size of the network. This is a subtle point since it leads to a data-dependent hypothesis set. In other words, in this experiments for each width we study variance of neural nets that can be found in fixed number of iterations by a step size that is chosen in data-dependent way. It may be the case that as width grows the step size decreases faster and hence hypothesis set shrinks and we observe decreasing variance. This makes the results of experiments with width not so surprising or interesting.\n\nFurther comments on experiments: it probably worth pointing out that results for depth are what we would expect from theory in general.\n\nMore on experiments: it would be also interesting to see how variance behaves as a function of width for depth other than 1.\n\nOn assumptions: it is not really clear why assumptions in 5.2 hold for wide shallow networks at least in some cases. Paper provides some references to prior work but it would be great to give more details. Furthermore, some statements seems to be contradicting: sentence before 5.2.1 seems to say that assumption (a) should hold for deep nets while sentence at the end of page 8 seems to say the opposite.\n\nOverall: I think this paper presents an interesting avenue of research but due to aforementioned points is not ready for publication.  \n\n\n']","[-50, 50, -50]","[20, 80, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's main claims and methodology. They disagree with the authors' interpretation of results and find the technical parts 'really hard to understand'. However, it's not entirely negative as they engage with the content and offer some constructive criticism. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively polite language such as 'I don't like' and 'I think I need more technical detail' rather than harsh or rude phrasing. They also acknowledge the authors' observations and provide references, which shows a level of respect. The tone is professional and academic, albeit critical."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's surprising and interesting findings, and notes consistency with their own observations. However, they also raise some concerns and suggest areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'A comment/discussion along this line would be interesting'), and acknowledges the value of the work. The reviewer maintains a professional and courteous tone while providing specific, actionable feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the paper presents 'an interesting avenue of research', they ultimately conclude it is 'not ready for publication'. The review points out several issues with the experiments and assumptions, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer sees potential in the research direction. The politeness score is 50 because the reviewer uses respectful and constructive language throughout. They phrase criticisms as suggestions ('it probably worth pointing out', 'it would be great to give more details') and use hedging language ('if I am correct', 'it may be the case'). The reviewer also acknowledges positive aspects ('interesting avenue of research') before concluding it's not ready for publication, which softens the overall critique.""]"
"['Authors establish a connection between communication reduction in distributed optimization and dithered quantization. This allows us to understand prior approaches in a new perspective, and also motivates authors to develop two new distributed training algorithms which communication overhead is significantly reduced. The first algorithm, DQSG, uses dithered quantization to reduce the communication bits. The second algorithm, NDQSG, uses nested dithered quantization to further reduce the amount of needed communication. The usefulness of these algorithms are empirically validated by computing the raw communication bits and average entropy of them. Therefore, dithered communication seems to provide both theory and algorithm which are useful.\n\nThe paper is clearly written. It provides a succinct review of dithered quantization and previous works, and figures provide a good insight into why the algorithm works, especially Figure 3.\n\nTheorems in this paper are mostly about plugging in properties of dithered quantization into standard results in stochastic optimization, but they are still useful. The analysis of NDQSG does not seem to be as complete as that of DQSG, however. With NQSG, now workers are divided into two groups, and there would be an interesting tradeoff between assignments to these two: how should we balance two groups? This might be tricky to analyze, but it is still useful to clarify limitations and provide conjectures. At least, this could be analyzed empirically.\n\npros:\n* establishing a connection to other topic of research often facilitates productive collaboration between two fields\n* provides a new perspective to understand prior work\n* provides new useful algorithms\n\ncons:\n* experiments were conducted on small models and small datasets\n* unclear models are large enough to demonstrate the need for communication reduction; in other words, it is unclear wall-time would actually be reduced with these algorithms.', 'Overall, this paper is well written and clearly present their contribution.\nAlthough the idea seems to be interesting and novel, but not enough evidence to prove the efficiency, from both theoretical and numerical perspective, even though many numerical experiments are proposed.\nIn general, this paper is high level in the articles assigned to me.', 'In this paper, the authors propose to apply dithered quantization (DQ) to the stochastic gradients computed through the training process. Though an extra noise is added to the gradient, it improves the quantization error. Hence after the noise is removed at the update server, it achieves superior results when compared against unquantized baseline.\n\nThe authors also propose a nested scheme to further reduce communication cost.\n\nThis method strictly improves over previous approaches such as QSGD and TernGrad in terms of quantization error. However, the improved quantization performance does not show up in the experiments. In Table 3, it is clear that DQSG does not significantly improve over QSG and TernGrad once there are 8 workers. And they all use the same amount of bits in communication.\n\nThe proposed NDQSG though capable of reducing the communication cost by 30%, its accuracy on CIFAR-10 shows noticeable drop.\n\nOverall, I think this method is promising, but further tuning is required to make it practical.']","[70, 50, 20]","[80, 75, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its strengths such as establishing connections, providing new perspectives, and developing useful algorithms. The reviewer uses phrases like 'clearly written,' 'useful,' and 'provides good insight.' However, it's not a perfect score due to some cons mentioned at the end. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout, acknowledging the authors' contributions and providing constructive feedback. The reviewer balances praise with suggestions for improvement, maintaining a courteous tone. The use of 'pros' and 'cons' lists also demonstrates a fair and balanced approach to the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the paper is well-written and presents a clear contribution. They also mention that the idea seems interesting and novel, and that the paper is of high quality compared to others they've reviewed. However, they express concerns about the lack of evidence for efficiency, which prevents a higher positive score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, starting with positive aspects before mentioning concerns. They avoid harsh criticism and use phrases like 'seems to be' and 'not enough evidence' rather than making definitive negative statements. The overall tone is constructive and professional."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the method as 'promising' and notes that it 'strictly improves over previous approaches'. However, they also point out limitations, such as the lack of significant improvement with 8 workers and accuracy drop on CIFAR-10, which tempers the positivity. The overall tone suggests cautious optimism rather than strong enthusiasm.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They present their observations and criticisms in a factual manner without using harsh or dismissive language. The use of phrases like 'I think' and 'further tuning is required' suggests a constructive approach rather than outright rejection. However, the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a neutral professional tone.""]"
"['This paper presents an approach to evaluate the quality of segmentations. To achieve this, a variational auto-encoder (VAE) is trained on the ground truth masks to extract shape-relevant information in the feature space, assuming that incorrect segmentations will be far from the normal distribution. Then, a regression model is trained to predict the quality of the segmentation based on the shape-learned features. The authors use several datasets focusing on pancreas segmentation to evaluate their quality-assessment approach, showing competitive performance with respect to other approaches.\n\nThe paper is well written, easy to follow in general, and the methodology is sound. Nevertheless, I have some concerns related to the applicability of this approach.\n\n- Closely related works in the literature are missing:\n\nThere is a closely related recent work that used auto-encoders on the sets of ground-truth masks to build representations of shape and constrain the outputs of deep networks: Otkay et al., Anatomically Constrained Neural Networks (ACNN): Application to Cardiac Image Enhancement and Segmentation, IEEE TMI 2017\n\nThis work does not focus directly on quality assessment. However, I believe the loss in this work, which evaluates the difference between the obtained segmentation (characterized by the outputs of a deep network) and an auto-encoder description of shape, can be used directly as a criterion for evaluating the quality of segmentation (on validation data) in term of consistency with the shape prior. I think this work is very closely related and should be discussed. \n\nAlso, a quick google search provided some missing references related to this work. I think including comparisons to the recent work in [1], for example, would be appropriate. As the focus is on quality assessment of medical image segmentation, I would suggest a deeper review of the literature.\n\n[1] Vanya V Valindria, Ioannis Lavdas, Wenjia Bai, Konstantinos Kamnitsas, Eric O Aboagye, Andrea G Rockall, Daniel Rueckert, and Ben Glocker. Reverse classification accuracy: Predict- ing segmentation performance in the absence of ground truth. IEEE Transactions on Medical Imaging, 2017. \n[2] S. Chabrier, B. Emile, C. Rosenberger, and H. Laurent, “Unsupervised performance evaluation of image segmentation,” EURASIP Journal on Applied Signal Processing, vol. 2006, pp. 217–217, 2006. \n[3] Gao H, Tang Y, Jing L, Li H, Ding H. A Novel Unsupervised Segmentation Quality Evaluation Method for Remote Sensing Images. Sensors. 2017 Oct 24;17(10):2427.\n\n- The proposed quality assessment uses the learned shape features.  Even though it is strong prior information, there  might be situations where the predicted segmentation might be plausible in terms of shape, but is not a good segmentation. \n\n-  I wonder how this approach works in problems with a high size/shape variation. For example, in the case of tumors, where their shape is unpredictable and each unknown case can be seen as a ‘rare’ example.\n\n- To better capture the shape in the proposed approach, images need to be aligned, which limits the applicability of this approach to aligned volumes only. \n\n- This approach gives a global hint about a given segmentation result, as a whole. I think it would be more interesting to provide local information on a segmentation, as it may happen that a predicted contour is generally correct, but there are some crispy borders in some points due to low contrast, for example. Even though the quality assessment would say that the prediction is correct, the contour may be unusable for certain applications, where a minimal surface distance is required (e.g., radiotherapy).\n\n- As the quality assessment is based on shape and not in image information, it would be interesting to see how accurately it predicts the performance on different image modalities (for example, the method is trained on ground truth masks corresponding to CT images and quality is assessed in segmentations performed in MRI).\n\nIf I understood correctly, comparison with other methods is done with the same dataset under the same conditions (i.e., all the images are pre-aligned). As the other methods might not have the limitation of requiring aligned images, it would be interesting to compare also the performances in this situation.\n\nHow the training (or the VAE) is adapted for DeepLab-3, as it is based on 2D convolutions?\n\nMinor: The paper needs a proof-read to fix some issues (e.g. ‘the properties of F is encoded’)\n', 'This paper explores the idea of having a VAE modelling the probability distribution of the real segmentations, in order to quantify the quality of the predicted segmentation (using another network). The paper refines this idea by applying regression over two parameters. The overall idea is interesting and novel to the best of my knowledge. Experimental results look convincing.\n\nThe paper does a good job at presenting the motivation, reads well in general, and it is well written (except the paragraph Entropy Uncertainty in Sec. 4.2 which contains several typos).\n\nSome comments:\nS(F(X); θ) looks good enough as an estimator. It would be good to see how it does by itself, reporting that as an ablation experiment, assessing how important it is to carry out the second step (fitting a, b).\nIn the last paragraph of Sec. 2, I am not sure what it is meant by ""Variational autoencoder(VAE) (Kingma & Welling, 2013), compared with AE, has stronger representation capability and can also serve as a generative model"". No doubt about the latter point, but not sure about the former.\nSec. 3.3 is somewhat confusing, for example: what is E in eq. 9 should be L?\n\nRevision: in light of the relevant papers brought up by AnonReviewer3 and AnonReviewer4, that have not been discussed in the paper, I modify my rating to 6.', 'The authors present a method to detect poor quality segmentation results by using a VAE to understand the statistical distribution of segmentation masks, and detect outliers from that distribution in predictions. Method is compared to a few baselines to show improved results.\n\nPros:\n\n1) The idea seems slightly novel, simple, and elegant, with respectable results.\n\nCons:\n\n1) This method is related to Out-of-Distribution (OOD) detection, which is an entire field unto itself. None of the relevant literature around OOD has been covered by this paper, including several recent ICLR papers:\n\nHendrycks, Gimpel, ""A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS"" ICLR 2017\nLiang et al. ""ENHANCING THE RELIABILITY OF OUT-OF-DISTRIBUTION IMAGE DETECTION IN NEURAL NETWORKS"" ICLR 2018\n\n2) The method is not compared to more naive approaches, such as building a network to take as input both modalities of original image and segmentation mask, and predict (classify) poor quality. \n\n3) The method assumes segmentation masks have some strong statistical prior. This may be the case for organs, but can completely break down in other cases, such as skin lesion segmentation ( http://challenge2018.isic-archive.com ). In this circumstance, reviewer questions if more naive approach in (2) above would work better.\n\n\nReviewer believes authors have a good line of research, but that it requires additional literature review and experiments before it is ready for publication. \n\n\nEDIT: Reviewer has considered the response by the authors. Key details of the baseline regressor are missing, such as the exact network structure used. As a result: 1) Reviewer is unable to determine if the baseline is a proper fair comparison. 2) Authors have confirmed the methods reliance on strong shape prior, but this caveat is not clearly mentioned in the paper as a requirement for the method to work. Furthermore, authors did not quantify what affect this reliance has by adding experiments on datasets with weak shape priors mentioned by reviewer. As a result, reviewer is lowering score. Reviewer encourages authors to continue this line of research, but carefully consider the feedback given to make the work stronger before publication.\n', 'Summary:\n      The paper tries to predict the quality of output of a segmentation algorithm applied to medical images. The approach of this paper is to looks at the ""true"" shape of the segmentation on the training samples and learn a VAE for the shape feature on them  for training samples.  For the test samples (that are new and are segmented only the algorithm whose quality is to be predicted), a linear function of the loss function of the learnt VAE applied to the output for the segmentation is used to predict quality. The linear function is tuned to the VAE loss of the output of the specific segmentation algorithm on the training samples.\n\n The basic premise is that VAE minimizes the gap between between the log likelihood of the true shape and the VAE loss function. Therefore, the gap should be small for ""good"" shapes while very bad for ""bad/wrong"" shapes. Therefore the VAE loss trained on the good shapes on the training examples can indicate the goodness of a segmentation algorithm\'s output.\n\nPros:\n  I think the authors have compared to the number of baselines on three medical imaging datasets and show that their method via various metrics clearly outperforms others on this specific medical imaging application.\n\nI like the primary technical idea behind the paper of detecting low quality outputs by projecting to the range space of a VAE and looking at its likelihood.\n\nCons:\n1)  I dont know about the apriori assumption that shape of the segmentation will be the right feature to actually focus on. How general is this assumption for medical imaging tasks ?\n\n2) Authors say - ""Variational autoencoder(VAE) (Kingma & Welling, 2013), compared with AE, has stronger representation capability"" - Why does the VAE have stronger representation capability?  - I dont understand this part.  Is it because it outputs the probabilities z given Y and Y given z that is somehow more useful ?\n\n3) Can GANs be used instead of VAEs? Is there a natural loss function that could be used in this case during quality prediction?\n\n\nDisclaimer: I am not an expert in the area for segmentation of medical images.\n']","[-20, 60, -50, 50]","[60, 80, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and the methodology is sound, they express several concerns about the applicability of the approach and point out missing related works. The review lists multiple limitations and suggestions for improvement, which outweigh the initial positive comments.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They begin with positive remarks about the paper's writing and methodology, and frame their concerns as suggestions or questions rather than harsh criticisms. Phrases like 'I believe,' 'I think,' and 'I wonder' are used to soften their critiques. The reviewer also provides specific references and examples to support their points, which is helpful and considerate.\n\nOverall, while the review expresses several concerns, it does so in a polite and professional manner, maintaining a respectful tone throughout."", ""The sentiment score is 60 (positive) because the reviewer describes the paper's idea as 'interesting and novel' and the experimental results as 'convincing'. They also mention that the paper is generally well-written and does a good job presenting motivation. However, the score is not higher due to some criticisms and the final revision lowering the rating. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive feedback and balancing positive comments with areas for improvement. They phrase criticisms as suggestions or questions rather than direct attacks. The reviewer also acknowledges their own potential oversight by modifying their rating based on other reviewers' comments, showing humility and openness to other perspectives."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('slightly novel, simple, and elegant'), they express significant concerns and ultimately recommend against publication in the current state. The reviewer lists more cons than pros and suggests substantial additional work is needed. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive feedback, but there are some direct criticisms and the overall tone becomes more negative in the edit. The reviewer uses phrases like 'Reviewer believes' and 'Reviewer encourages' which maintain a professional tone, but also directly states shortcomings and lowers their score in the edit."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper. They express appreciation for the primary technical idea and the comparative analysis, but also raise concerns about assumptions and methodological choices. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert'), and frames criticisms as questions or suggestions rather than direct attacks. The reviewer also begins with positive aspects before moving to concerns, which is a polite approach in academic discourse.""]"
"[""The paper describes a cache side-channel attack on a deep learning model. In a cache side-channel attack, the attacker sets up a process on the same machine where the victim process (that is running the training or evaluation job for the DNN model) is running. It is assumed that the victim process uses a common shared library for DNN computations as the attacking process. The attacking process flushes the cache, then observes access times for key functions. The paper shows that, based on the speed of accessing previously flushed functions, the attacker can discover the high-level network architecture, namely the types of layers and their sequence. The paper shows that, by spying on such cache access patterns in the Tensorflow library, this method can reliably extract the above high-level information for 11 different network architectures. It also describes a few counterattack alternatives whereby the victim can obfuscate its cache access patterns for self-protection.\n\nThe significance of the results is not clear to me. The extracted information is very high level. What realistic attacks can be constructed from such a coarse-grained fingerprinting? The experimental results show that the fingerprint can be used to map the architecture to one of the 13 well-known architectures (VCC16, ResNet, DenseNet, Inception, etc.). But so what? What does the victim lose by revealing that it's using one of a few very well known types of DNNs (the ones tested in this paper). There may very well be a good reason why this is very dangerous, but that is not explained in the paper. Not being familiar with this line of research and its significance, I looked up several of the related papers (Suciu et al., 2018, Tramer et al., 2017, Papernot et al., 2017, Yan et al., 2018). None of them could explain why this particular type of fingerprinting is dangerous.\n\nOf the cited previous work, Yan et al., 2018 seems to present the most closely related approach. The method described in that paper is very similar: cache side attack on a shared library through a co-located attacker process. They monitor at a finer grain -- Generalized Matrix Multiplications -- and are thus able to infer more details such as the size of the layers. This also makes the inference problem harder -- they were able to narrow down the search space of networks from >4x10^35 to 16 (on VGG16). On the surface, the results presented in this paper seem stronger. But they are actually solving a much easier problem -- their search space is one of 13 well-known networks. To me, Yan et al.'s approach is a much more powerful and promising setup.\n\nOverall, while the paper is clearly written and presents the idea succinctly, it is derivative of previous research, and the results are not stronger. I'm not an expert in this area, so it's possible that I missed something. Based on my current understanding, however, I recommend reject."", 'This paper performs cache side-channel attacks to extract attributes of a victim model, and infer its architecture accordingly. In their threat model, the attacker could launch a co-located process on the same host machine, and use the same DL framework as the victim model. Their evaluation shows that: (1) their attacks can extract the model attributes pretty well, including the number of different types of layers; (2) using these attributes, they train a decision tree classifier among 13 CNN architectures, and show that they can achieve a nearly perfect classification accuracy. They also evaluate some defense strategies against their attacks.\n\nModel extraction attack under a black-box setting is an important topic, and I am convinced that their threat model is a good step towards real-world attacks. As for the novelty, although Yan et al. also evaluate cache side-channel attacks, that paper was released pretty shortly before ICLR deadline, thus I would consider this work as an independent contribution at its submission.\n\nI have several questions and comments about this paper:\n\n- One difference of the evaluation setup between this paper and Yan et al. is that in Yan et al., they are trying to infer more detailed hyper-parameters of the architecture (e.g., the number of neurons, the dimensions of each layer, the connections), but within a family of architectures (i.e., VGG or ResNet). On the other hand, in this paper, the authors extract higher-level attributes such as the number of different layers and activation functions, and predict the model family (from 5 options) or the concrete model architecture (from 13 options). While I think inferring the model family type is also an interesting problem, this setup is still a little contrived. Would the classifier predict the family of a model correctly if it is not included in the training set, say, could it predict ResNet32 as R (ResNet)?\n\n- In Table 3, it looks like the errors in the captured computation sequences show some patterns. Are these error types consistent across different runs? Could you provide some explanation of these errors?\n\n- In Table 5, my understanding is that we need to compare the avg errors to the numbers in Table 2. In this case, the errors seem to be even larger than the sum of the attribute values. Is this observation correct? If so, could you discuss what attributes are most wrongly captured, and show some examples?\n\n- It would be beneficial to provide a more detailed comparison between this work and Yan et al., e.g., whether the technique proposed in this work could be also extended to infer more fine-grained attributes of a model, and go beyond a classification among a pre-defined set of architectures.\n\n- The paper needs some editing to fix some typos. For example, in Table 5, the captions of Time (Baseline) and Time (+TinyNet) should be changed, and it looks confusing at the first glance.\n', 'This paper considers the problem of fingerprinting neural network architectures using cache side channels. In the considered threat model, the attacker runs a process co-located with the victim\'s, and uses standard FLUSH+RELOAD attacks to infer high-level architectural information such as the number and types of layers of the victim\'s ML model. The paper concludes with the discussion of some ""security-through-obscurity"" defenses.\n\nI don\'t quite understand the threat model considered in this paper. The main motivating factor given by the authors for uncovering model architecture details is for facilitating black-box attacks against ML models (e.g., for adversarial examples or membership inference). \nYet, in the case of adversarial examples for instance, knowledge of the architecture is often considered a given as keeping it secret has very little influence on attacks. There are black-box attacks that require no knowledge of the architecture and only a few queries (e.g., Black-box Adversarial Attacks with Limited Queries and Information, Ilyas et al., ICML\'18). \nSo overall, learning such coarse-grained features about a model just doesn\'t seem particularly useful, especially since architecture-level details are often not considered private or secret to begin with.\n\nAfter architectural details have been extracted, the end-goal attacks on ML models considered by the authors (e.g., model stealing, adversarial examples, etc.) require query access anyways. Thus, additionally assuming co-location between the adversary and the victim\'s model seems to unnecessarily strengthen the attacker model.\n\nMaybe the most interesting scenario to consider for cache side-channels in ML is when ML models are run on trusted hardware (e.g., Oblivious Multi-Party Machine Learning on Trusted Processors, Ohrimenko et al.; or this work also submitted to ICLR: https://openreview.net/forum?id=rJVorjCcKQ).\nCache side channels are much more relevant to that threat model (i.e., ML code running in a trusted hardware enclave hosted by a malicious party). And indeed, there have been many cache side-channel attack papers against trusted hardware such as Intel\'s SGX (e.g., Software Grand Exposure: SGX Cache Attacks Are Practical, Brasser et al.)\n\nBut given what we know about the strength of these cache side channel attacks, one would expect to be able to extract much more interesting information about a target model, such as its weights, inputs or outputs. In the above trusted hardware scenario, solely extracting architecture-level information would also not be considered a very strong attack, especially since coarse-grained information (e.g., a rough bound on the number of layers), can be trivially obtained via timing side channels.\n\nMinor comments:\n- In the introduction, you say that white-box attacks for adversarial examples are rendered ineffective by gradient masking. This isn\'t true in general. Only ""weak"" white-box attacks can be rendered ineffective this way. So far, there are no examples of models that resist white-box attacks yet are vulnerable to black-box attacks.\n- What exactly causes the cache-level differences you observe? Can you give some  code examples in the paper that showcase what happens? Are the TensorFlow code lines listed in Table 1 from a specific commit or release?\n- The defenses discussed in Section 5 are all forms of ""security through obscurity"" that seem easily defeated by a determined attacker that adapts its attack (and maybe uses a few additional observations).\n\n--REVISION--\nI thank the authors for their rebuttal and clarifications on the threat model and end goals of their attacks. I remain somewhat unconvinced by the usefulness of extracting architectural information. For most of the listed attacks (e.g., building substitute models for adversarial examples, or simply for model extraction) it is not clear from prior work that knowledge of the architecture is really necessary, although it is of course always helpful to have this knowledge. As I mentioned in my review, with current (undefended) ML libraries, it should be possible to extract much more information (e.g., layer weights) using cache side channels.']","[-70, 50, -50]","[20, 80, 50]","[""The sentiment score is -70 because the reviewer expresses significant doubts about the paper's significance and novelty. They state that the 'significance of the results is not clear', question the practical implications of the findings, and ultimately recommend rejection. The reviewer also mentions that the paper is 'derivative of previous research' and that the results are 'not stronger' than existing work. However, it's not entirely negative as they acknowledge that the paper is 'clearly written' and presents the idea 'succinctly'.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Not being familiar with this line of research...' and 'I'm not an expert in this area, so it's possible that I missed something', which show humility and openness to other perspectives. The reviewer also provides detailed explanations for their concerns, which is a courteous way to give feedback. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the topic and the novelty of the work, stating it's 'an important topic' and 'an independent contribution'. However, they also raise several questions and suggest improvements, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Would the classifier predict...', 'It would be beneficial to...'), and acknowledges the paper's strengths before offering critiques. The reviewer also uses phrases like 'I am convinced' and 'I think', which show consideration for the authors' perspective."", ""The sentiment score is -50 because the reviewer expresses significant skepticism about the usefulness and novelty of the paper's approach. They question the threat model, the relevance of the extracted information, and the overall contribution. However, it's not entirely negative as they do suggest potential improvements and areas where the work could be more relevant. The politeness score is 50 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I don't quite understand' and 'Maybe the most interesting scenario' which soften the criticism. They also provide specific suggestions for improvement and reference relevant literature, showing engagement with the work. The language is not overly formal or polite, but it maintains a respectful tone throughout.""]"
"['This interesting paper tackles the problem of joint source-channel coding, by means of learning.\n\nFrom 100kft heights, especially given the choice of VIMCO gradient estimates, this is effectively a ""let\'s embed a source-channel-decoder simulator and differentiate through it"", and find a solution that is better than source|channel factorized classic methods, or hand-tuned approaches.\n\nThe method and results are good. The authors also show some interesting results about the representations learned, about how decoded samples (images) change smoothly when the (discrete) embedding (the-codes) changes over deltas of hamming_d()=1bit. This is very good results IHMO. One limitation of this method is the fixed-code-length.\n\nJumping straight to my main main issue with this paper: no code was made available, at least not at this time.\n\nWhile the authors do provide an extensive appendix with hyper-parameter specs, usually in my experience when dealing with discrete / monte-carlo methods, it\'s usually rather hard to reproduce results. I really strongly advise the authors to provide fully reproducible code for this paper, to help further research on this topic.\n\nBesides that I have three technical comments / request regarding this paper:\n\n1// the choice of BSC channel - while this is the easiest most natural choice, and we should certainly have results on BSC, I am left wondering why the authors didn\'t try other more complex / more realistic channels? The authors only mention this as potential area of future research in the last sentence of the conclusions. \n\nThere are several reasons for this comment: first of all, it is well known that even classic joint source-channel coding methods do shine on complex channels, such fading/erasure channels and/or in general channels with correlated error sequences. Such channels are indeed key in modern wireless communications, and are easy to simulate. Given that more-complex channels could be introduced in the channel model p(y_hat|y) -  it would not change the rest of the method - it would be particularly interesting to see what results this method achieve in these more complex environments.\n\n2// I would like to hear more about the choice of VIMCO. Understood the authors statement to ""preserve the hard discreteness"" ~ that said methods like Gumbel-SM and several others also referenced in the paper ~ have been used  successfully to solve for propagating gradients through discrete units. This is where, in my opinion, experiments comparing VIMCO approximation results to at least one other method could allow to decide / validate the best architecture. \n\nThis is also because, in my previous experience, this type of networks with discrete units may be hard to train. I would like to hear from the authors about how stable the training was under different hyper-parameters, and perhaps see some convergence curves for the loss function(s).\n\n3// it\'s not 100% clear to me where the limitation of fixed code-length come into play from the architecture. Could the authors please point this out clearly?\n\nThank you!\n', ""Summary of paper: For the finite-bit case of the noisy communication channel model, it is suboptimal to optimize source coding (compression of input) and error correction (fault tolerance for inherent noise in the channel) separately. The authors propose a neural network model (NECST) that is very similar to the standard VAE, except using binary latents with corruption (e.g.,  random bit flipping in the style of a binary symmetric channel). They use VIMCO to optimize through the discrete units. In their experiments, they show that they can outperform a JPEG+ideal channel code model, but perform similarly to a VAE+LDPC (LDPC is a classic error correcting code) setup.\n\nFirst of all, the paper is quite well written and easily readable. Great work on explaining the motivation and the model -- the writing is clear and explains background knowledge extremely well.\n\nThe main contribution in the model is the use of discrete binary latents, instead of the standard continuous latents in a VAE. However, I am uncertain about the novelty of this contribution. There have been numerous works examining discrete latent variables in autoencoders (a random sampling: [1, 2, 3, 4]) and beyond. Furthermore, the method of training through discrete latents is also standard (VIMCO, though one can also imagine using more recent advances like REBAR or RELAX). The only difference would be the addition of noise to the discrete. I would be curious to see how that compares to recent works that have also added noise to discrete latents [5].\n\nThus, it strikes me that the main contribution of this work would be in comparing against the current best techniques for coding. However, the experiments section is weak, and does not provide significant evidence that the NECST model is better than the alternatives. NECST outperforms JPEG+ideal channel coding, but doesn't do much better than a VAE+LDPC baseline. This suggests that most of the gains comes from the encoder (source coding) model q(\\hat{y} | x), instead of the joint training of source coding and error correcting code. It is not surprising that using a neural network to generate codes would provide significant gains. It's not clear that error correcting code aspect (noise in the latents) is particularly important.\n\nFurthermore, in the classification results, the MLP model trained on the discrete codes gets 93% accuracy on noiseless MNIST inputs. You can easily get this accuracy by training logistic regression directly on the pixels. Despite what the authors write, this result suggests that the codes are not very useful for downstream learning. Furthermore, it is unclear why adding random noise to the inputs would significantly improve some of the weaker classifiers. The only reason I can think of is data augmentation, but this has nothing to do with the NECST model.\n\nIn conclusion, this is a well written paper, but the novelty is not apparent and the experimental results are weak, and so I am not convinced this is suitable for ICLR.\n\nAdditional Questions:\n* How is the runtime computed? Specifically, for NECST, do you batch the data and then divide the forward pass time by the batch size? If this is how runtime is computed, it's not surprising that NECST does better, given that batching is cheap with modern hardware. If the actual forward pass time for a single example is cheaper than that of LDPC's belief propagation, then that would be quite promising.\n* The authors state that VAEs optimize a lower bound on the marginal log-likelihood p(X), whereas NECST optimizes a lower bound on the mutual information I(X, Y), where Y is the noised code. The authors however do not discuss why one should optimize for mutual information compared to marginal log-likelihood. What are the advantages and disadvantages between the two?\n\n[1] Semi-Supervised Learning with Deep Generative Models (https://arxiv.org/abs/1406.5298)\n[2] Discrete Variational Autoencoders (https://arxiv.org/abs/1609.02200) \n[3] Neural Discrete Representation Learning (https://arxiv.org/abs/1711.00937)\n[4] Discrete Autoencoders for Sequence Models  (https://arxiv.org/abs/1801.09797)\n[5] Theory and Experiments on Vector Quantized Autoencoders (https://arxiv.org/pdf/1805.11063.pdf)"", 'The authors set out to tackle an old problem (joint source-channel coding) with a principled approach and a fresh perspective. However, I find the paper quite limited both in terms of modeling choices as well as evaluation methodology. Specifically:\n\n- The mutual information maximization approach is appropriate, but hardly novel. Besides being highly related to ELBO maximization, there have been several recent papers on rate-distortion optimization, as well as on deriving variational bounds for MI (see, for instance, Alemi et al.).\n\n- The experimental setup is somewhat niche: in the context of image compression, both the fixed-rate constraint as well as the use of a binary symmetric channel are unusual. The vast majority of image compression methods are variable-rate, and for good reason: generic images tend to carry vastly different amounts of self-information, such that a fixed-rate code is almost guaranteed to achieve suboptimal *average* performance in terms of rate-distortion. Additionally, the vast majority of images today are sent over channels that already perform error correction, such as packet-switched networks (e.g., the Internet) or digital storage media, so that it\'s unclear why this particular case of joint source-channel coding would be practically relevant.\n\n- I find the claim that the model is ""competitive against industry standard compression"" hardly justified based on the presented data. First, JPEG is now almost 40 years old. Since its inception, newer industry standards have exceeded it multiple times over in terms of rate-distortion performance. Second, JPEG was designed as a compression method for generic images. Comparing its performance on Omniglot and CelebA datasets is unfair, because the presented model can be trained to exploit special probabilistic structure in these datasets, while JPEG cannot. A widely used and accessible dataset better suited to compare against exisiting image compression methods would be the Kodak set, for example. And third, as explained above, JPEG is a variable-rate compression algorithm. How exactly were the number of bits required for JPEG to achieve the same distortion as NECST computed? To produce the plot in Figure 1, did the authors first compute an average rate for each average distortion, or was the computation done for each individual image, and then averaged to produce Figure 1 in a second step? This distinction could make a big difference.\n\n- Regarding Sections 5.3 and 5.4: Could the authors please justify why they just double the length of the VAE representation? Wouldn\'t it be fairer towards LDPC to compare NECST to a VAE+LDPC code with various amounts of redundancy? Similarly, could the authors please justify comparing runtime only against a fixed 50 iterations of LDPC, rather than comparing against a range of possible values to make sure they are giving LDPC the benefit of the doubt?\n']","[60, -50, -60]","[80, 50, 20]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting' and states that 'The method and results are good.' They also mention 'very good results' regarding some aspects of the study. However, they do raise some issues and requests for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'I really strongly advise' and 'Thank you!' They also frame their criticisms as requests or areas for improvement rather than direct attacks. The reviewer maintains a professional and courteous tone while providing constructive feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the paper is well-written and explains background knowledge extremely well, they express significant doubts about the novelty of the contribution and the strength of the experimental results. The reviewer concludes that they are 'not convinced this is suitable for ICLR', indicating an overall negative sentiment despite some positive aspects. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the strengths of the paper (e.g., 'Great work on explaining the motivation and the model') while offering constructive criticism. They maintain a professional tone, avoiding harsh language even when pointing out weaknesses. The reviewer also asks additional questions at the end, showing engagement with the work despite their criticisms."", ""The sentiment score is -60 because the reviewer expresses significant criticisms and limitations of the paper, using phrases like 'quite limited', 'hardly novel', and 'hardly justified'. While they acknowledge the authors' attempt to tackle an old problem with a fresh perspective, the majority of the review focuses on shortcomings. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'Could the authors please justify' and 'I find', which are polite ways to express concerns. However, the critique is direct and doesn't use many softening phrases, keeping the score only slightly positive. The reviewer also provides specific suggestions for improvement, which is a constructive approach.""]"
"['In this paper, the authors consider CNN models from the lens of kernel methods. They build upon past work that showed that such models can be seen to lie in appropriate RKHS, and derive upper and lower bounds for the kernel norm. These bounds can be used as regularizers that help train more robust neural networks, especially in the context of euclidean perturbations of the inputs, and training GANs. They show that the bounds can also be used to recover existing special cases such as spectral norm penalizations and gradient regularization. They derive generalization bounds from the point of view of adversarial learning, and report experiments to buttress their claims.\n\nOverall, the paper is a little confusing. A lot of the times, the result seem to be a derivative of the work by Bietti and Mairal, and looks like the main results in this paper are intertwined with stuff B+M already showed in their paper. It\'s hard to ascertain what exactly the contributions are, and how they might not be a straightforward consequence of prior work (for example, combining results from Bietti and Mairal; and generalization bounds for linear models). It might be nice to carefully delineate the authors\' work from the former, and present their contributions. \n\nPage 4: Other Connections with Lower bounds: The first line "" ""we may also consider ... "". This line is vague. How will you ensure the amount of deformation is such that the set \\bar{U} is contained in U ?\n\nPage 4 last paragraph: ""One advantage ... complex architectures in practice"" : True, but the tightness of the bounds *do* depend on ""f"" (specifically the RKHS norm). It needs to be ascertained when equality holds in the bounds you propose, so that we know how tight they are. What if the bounds are too loose to be practical?\n\neqn (8): use something else to denote the function \'U\'. You used \'U\' before to denote the set. \n\neqn (12): does \\tilde{O} hide polylog factors? please clarify. \n\n\n\n', ""This paper looks at adversarial examples from the context of RKHS norms for neural networks.  The work builds conceptually on the work of Bietti and Mairal (2018), who investigate approximate RKHS norms for neural networks (including computation via a specialized convolutional kernel), and Xu et al., (2009) which looks at robustness properties of kernel classifiers.  The authors discuss how the RKHS norm of neural network functions provide robustness guarantees for the resulting classifier, both in terms of a straightforward robustness property for a given example, as well as in terms of generalization guarantees about robustness.\n\nOverall, I think there are some interesting ideas in this work, but ultimately not enough to make a compelling independent paper.  The core issue here is that the RKHS properties are used only in a very minimal manner to actually provide much analysis or insight into the robustness properties of the network.  For example, the upper bound in (8) seems to be central here to illustrating how a bound on the RKHS norm can be upper bounded as a function of the operator l2 norm of the inner weight matrices (though the actual form of the bound isn't mentioned), and the latter term could thus provide a certified bound on the robustness loss of a classifier.  However, there are two big issues here: 1) it's trivial to directly bound the l2 robustness of a classifier by the product of the weight spectral norms and 2) the actual regularization term the authors proposed to use (the sum of spectral norms) is notably _not_ an upper bound on either the robust loss or the RKHS norm; naturally, this penalty along with the constrained version will still provide some degree of control over the actual robustness, but the authors don't connect this to any real bound.  I also think the authors aren't properly acknowledging just how similar this is to past work: the Parseval networks paper (Cisse et al., 2017), for instance, presents a lot of similar discussion of how to bound generalization error based based upon terms involving operator norms of the matrices, and the actual spectral normalization penalty that the authors advocate for has been studied by Miyato et al. (2018).  To be clear, both of these past works (and several similar ones) are of course cited by the current paper, but from a practical standpoint it's just not clear to me what the takeaways should be here above and beyond this past work, other than the fact that these quantities _also_ bound the relevant RKHS norms.  Likewise the generalization bound in the paper is a fairly straightforward application of existing bounds given the mechanics of the RKHS norm defined by previous work.\n\nTo be clear, I think the RKHS perspective that the authors advocate for here is actually quite interesting.  I wasn't particularly familiar with the Bietti and Mairal (2018) work, and going through it in some detail for reviewing this paper, I think it's an important directly for analysis of deep networks, including from a perspective of robustness.  But the results here seem more like a brief follow-on note to the past work, not a complete set of results in and of themselves.  Indeed, because the robustness perspective here can largely be derived completely independently of the RKHS framework, and because the resulting training procedures seem to be essentially identical to previously-proposed approaches, the mere contribution of connecting these works to the RKHS norm doesn't seem independently to be enough of a contribution in my mind.\n\nOne final, though more minor, point: It's worth pointing out that (globally) bounding the Lipschitz constant seems top stringent a condition for most networks, and most papers on certifiable robustness seem to instead focus on some kind of local Lipschitz bound around the training or test examples.  Thus, it's debatable whether even the lower bound on the RKHS norm is really reasonable to consider for the purposes of adversarial robustness.\n"", 'Regularizing RKHS norm is a classic way to prevent overfitting. The authors\nnote the connections between RKHS norm and several common regularization and\nrobustness enhancement techniques, including gradient penalty, robust\noptimization via PGD and spectral norm normalization. They can be seen as upper\nor lower bounds of the RKHS norm.\n\nThere are some interesting findings in the experiments. For example, for\nimproving generalization, using the gradient penalty based method seems to work\nbest.  For improving robustness, adversarial training with PGD has the best\nresults (which matches the conclusions by Madry et al.); but as shown in Figure\n2, because adversarial training only decreases a lower bound of RKHS norm, it\ndoes not necessarily decrease the upper bound (the product of spectral norms).\nThis can be shown as a weakness of adversarial training if the authors explore\nfurther and deeper in this direction.\n\nOverall, this paper has many interesting results, but its contribution is\nlimited because:\n\n1. The regularization techniques in reproducing kernel Hilbert space (RKHS) has\nbeen well studied by previous literature. This paper simply applies these\nresults to deep neural networks, by treating the neural network as a big\nblack-box function f(x).  Many of the results have been already presented in\nprevious works like Bietti & Mairal (2018).\n\n2. In experiments, the authors explored many existing methods on improving\ngeneralization and robustness. However all these methods are known and not new.\nIdeally, the authors can go further and propose a new regularization method\nbased on the connection between neural networks and RKHS, and conduct\nexperiments to show its effectiveness.\n\nThe paper is overall well written, and the introductions to RKHS and each\nregularization techniques are very clear. The provided experiments also include\nsome interesting findings. My major concern is the lack of novel contributions\nin this paper.']","[-20, -50, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because the reviewer expresses confusion about the paper's contributions and their relation to prior work. They state that 'the paper is a little confusing' and that 'It's hard to ascertain what exactly the contributions are.' However, the score is not deeply negative because the reviewer acknowledges the paper's content and provides constructive feedback. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'It might be nice to...' and asking clarifying questions rather than making harsh criticisms. They also provide specific, actionable feedback without using confrontational language. The reviewer's approach is constructive and respectful, even while pointing out areas for improvement."", ""The sentiment score is -50 because the reviewer expresses significant criticisms of the paper, stating that there are 'not enough [ideas] to make a compelling independent paper' and that the work seems more like 'a brief follow-on note to the past work'. However, the reviewer does acknowledge some 'interesting ideas', preventing the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the potential of the work ('I think the RKHS perspective that the authors advocate for here is actually quite interesting') and providing detailed, constructive feedback. The reviewer also uses phrases like 'To be clear' to soften criticisms, showing consideration for the authors' feelings while still conveying necessary critiques."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges 'interesting findings' and that the paper is 'well written', they also express concerns about the 'limited' contribution and 'lack of novel contributions'. The overall tone is mixed, leaning slightly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and uses phrases like 'ideally' and 'my major concern' rather than harsh or dismissive language. The reviewer provides constructive feedback and explains their reasoning clearly, which contributes to the polite tone.""]"
"[""The paper proposes a learnable bloom filter architecture. While the details of the architecture seemed a bit too complicated for me to grasp (see more on this later), via experiments the authors show that the learned bloom filters are more compact that regular bloom filters and can outperform other neural architectures when it comes to retrieving seen items.\n\nA bloom filter is fairly simple, K hash functions hash seen items into K bit vectors. During retrieval, if all of the bits hashed to are 1 then we say we've seen the query. I think there's simpler ways to derive a continuous, differentiable version of this which begs the question why the authors chose a relatively more elaborate architecture involving ZCA transform and first/second moments. Perhaps the authors need to motivate their architecture a bit better.\n\nIn their experiments, a simple LSTM seems to perform remarkably well (it is close to the best in 2 (a), (b); and crashes in (c) but the proposed technique is also outperformed by vanilla bloom filters in (c)). This is not surprising to me since LSTMs are remarkably good at remembering patterns. Perhaps the authors would like to comment on why they did not develop the LSTM further to remedy it of its shortcomings. Some of the positive results attained using neural bloom filters is a bit tempered by the fact that the experiments were using a back up bloom filter. Also, the neural bloom filters do well only when there is some sort of querying pattern. All of these details would seem to reduce the applicability of the proposed approach.\n\nThe authors have addressed most (if not all) of my comments in their revised version. I applaud the authors for being particularly responsive. Their explanations and additional experiments go a long way towards lending the insights that were missing from the original draft of the paper. I have upped my rating to a 7."", 'SUMMARY\nThe paper proposes a neural network based architecture to solve the approximate set membership problem, in the distributional setting where the in-set and out-of-set elements come from two unknown and possibly different distributions.\n\n\nCOMMENTARY\nThe topic of the paper is interesting, and falls into the popular trend of enhancing classical data structures with learning algorithms. For the approximate set membership problem, this approach was already suggested by (Kraska et al. 2018) and studied further in (Mitzenmacher 2018a,b). The difference in the current paper is that the proposed approach relies on ""meta-learning"", apparently to facilitate online training and/or learning across multiple sets arising from the same distribution; this is what I gather from the introduction, even though as I write below, I feel this point is not properly explained.\n\nMy main issue with the paper is that its conceptual contribution seems limited and unclear. It suggests a specific architecture whose details seem mostly arbitrary, or at least this is the impression the reader is left with, as the paper does rather little in terms of discussing and motivating them or putting them in context. Moreover, since the solution ultimately relies on a backup Bloom Filter as in (Kraska et al. 2018), it is hard to not view it as just an instantiation of the model in (Kraska et al. 2018, Mitzenmacher 2018a) with a different plugging of learning component. It would help to flesh out and highlight what the authors claim are the main insights of the paper.\n\nAnother issue I suggest revising pertains to the writing. The problem setting is only loosely sketched but not properly defined. How exactly do different subsets coming into play? Specifically, the term ""meta-learning"" appears in the title and throughout the paper, but is never defined or explained. The authors should write out what exactly they mean by this notion and what role it plays in the paper. This is important since to my understanding, this is the main point of departure from the aforementioned recent works on learning-enhanced Bloom Filters.\n\nThe experiments do not seem to make a strong case for the empirical advantage of the Neural Bloom Filter. They show little to no improvement on the MNIST tasks, and some improvement on a non-standard database related task. One interesting thing to look at would be the workload partition between the learning component and the backup filter, meaning what is the rate of false negatives emitted by the former and caught by the latter, and how the space usage breaks down between them (vis-a-vis the formula in Appendix B). For example, it seems plausible that on the class familiarity task, the learning component simply learns to be a binary classifier for the chosen two MNIST classes and mostly ignores the backup filter, whereas in the uniform distribution setting, the learning component only memorizes a small number of true and false positives and defers almost the entire task to the backup filter. I am not sure what to expect on the intermediate exponential distribution task.\n\nOther comments/questions:\n1. For the classical Bloom Filter, do the results reported in the experimental plots reflect the empirical false-positive rate measured in the experiment, or just the analytic bound?\n2. On that note, it is worth noting that the false positive rate of the classical Bloom Filter is different than the one you report for the neural-net based architectures. The Bloom Filter FP probability is over its internal randomness (i.e. its hash functions) and is independent of the distribution of queries, which need not be randomized at all. For the neural-net based architectures, the measured FP rate is w.r.t. a specific distribution of queries. See the discussion in (Mitzenmacher 2018a), sections B-C.\n3. The works (Mitzenmacher 2018a,b) should probably at least be referenced in the related work section.\n\n\nCONCLUSION\nWhile I like the overall topic of the paper, I currently find the conceptual contribution to be too thin, raising doubts on novelty and significance. In addition, the presentation is somewhat lacking in clarity, and the practical merit is not well established. Notwithstanding the public nature of ICLR submissions, I would suggest more work on the paper prior to publication.\n\n\nREFERENCES\nM. Mitzenmacher, A Model for Learned Bloom Filters and Related Structures, 2018, see https://arxiv.org/pdf/1802.00884.pdf.\nM. Mitzenmacher, Optimizing Learned Bloom Filters by Sandwiching, 2018, see https://arxiv.org/pdf/1803.01474.pdf.\n\n(Update: score revised, see below.)', 'The paper proposes a method whereby a neural network is trained and used as a data structure to assess approximate set membership. Unlike the Bloom filter, which uses hand-constructed hash functions to store data and a pre-specified method for answering queries, the Neural Bloom Filter learns both the Write function and the Read function (both are ""soft"" values rather than the hard binary values used in the Bloom filter). Experiments show that, when there is structure in the data set, the Neural Bloom Filter can achieve the same false positive rate with less space.\n\nI had a hard time understanding how the model is trained. There is an encoding function, a write function, and a query function. The paper talks about one-shot meta-learning over a stream of data, but doesn\'t make it clear how those functions are learned. A lot of details are relegated to the Appendix. For instance B.2 talks about the encoder architecture for one of the experiments. But even that does not contain much detail, and it\'s not obvious how this is related to one-shot learning. Overall, the paper is written from the perspective of someone fully immersed in the details of the area, but who is unable to pop out of the details to explain to people who are not already familiar with the approach how it works. I would suggest rewriting to give an end-to-end picture of how it works, including details, without appendices. The approach sounds promising, but the exposition is not clear at all.']","[60, -50, -20]","[80, 20, 50]","[""The sentiment score is 60 (positive) because the reviewer acknowledges improvements in the revised version, applauds the authors for being responsive, and has increased their rating. The initial paragraphs express some concerns, but the final paragraph indicates a positive shift in opinion. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout, use of phrases like 'I applaud the authors,' and constructive feedback. The reviewer maintains a professional and courteous demeanor even when expressing critiques, and ends on a very positive note."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's conceptual contribution, clarity, and practical merit. They state that the contribution seems 'limited and unclear', the writing needs revision, and the experiments don't make a strong case for the method's advantage. However, they do mention some positive aspects like the interesting topic, which prevents the score from being lower. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They use phrases like 'I suggest revising' and 'It would help to', which are polite ways of giving feedback. However, the overall critical tone and direct statements of the paper's shortcomings prevent the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential of the approach ('The approach sounds promising'), they express significant concerns about the clarity of the paper ('I had a hard time understanding', 'the paper is written from the perspective of someone fully immersed in the details of the area, but who is unable to pop out of the details to explain'). The reviewer suggests a major rewrite, indicating substantial dissatisfaction with the current presentation.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement ('I would suggest rewriting to give an end-to-end picture') and balance criticism with positive remarks ('Experiments show that... the Neural Bloom Filter can achieve the same false positive rate with less space'). The language used is respectful and focuses on the paper's content rather than making personal criticisms.""]"
"['Quality: The overall quality of this paper is good. It adopts a simple but novel idea on SISR and shows clear improvement against existing method (e.g., SRGAN). \n\nClarify: This paper is well written and easy to follow. It shows a clear motivation for adopting the implicit probabilistic model.\n\nOriginality: To the best of my knowledge, this paper is the first work to learn multi-modal probabilistic model for SISR.\n\nSignificance: While the results can be further improved (still look a bit blurred), this paper shows an interesting and important direction to learn better mappings for SISR.\n\nPros:\n+ The writing is clear.\n+ The proposed method is well motivated and easy to understand.\n+ The experimental results include both objective and subjective evaluations.\n\nCons:\n- The two-stage architecture is similar to the following generative models and SR methods. It’s suggested to discuss them as well.\n[a] Denton, E. L., Chintala, S., & Fergus, R. “Deep generative image models using a￼ laplacian pyramid of adversarial networks”. NIPS, 2015.\n[b] Karras, T., Aila, T., Laine, S., & Lehtinen, J. “Progressive growing of gans for improved quality, stability, and variation”. ICLR 2018.\n[c] Lai, W. S., Huang, J. B., Ahuja, N., & Yang, M. H. “Deep laplacian pyramid networks for fast and accurate super-resolution.” CVPR 2017.\n[d] Wang, Y., Perazzi, F., McWilliams, B., Sorkine-Hornung, A., Sorkine-Hornung, O., & Schroers, C. “A Fully Progressive Approach to Single-Image Super-Resolution.”. CVPR Workshops 2018.\n\n- In the hierarchical sampling (section 2.4), it’s not clear how to generate the upper noise vector “conditioned on the lower noise vector”. \n\n- The hierarchical sampling seems to improve the efficiency of training. I wonder does it affect the results of testing?\n\n- In the implementation details (section 2.5), I don’t understand why you need to transfer the the feature activations from GPU to CPU? I think all the computation can be done on GPU for most common toolboxes. Projecting the activations to a lower dimension with a “random Gaussian matrix” sounds harmful to the results.\n\n- How do you generate the low-resolution images? Are you using bicubic downsampling or other approaches? This detail should be clarified.\n\n- While the evaluation with PSNR and SSIM is a reference to show the quality, many literatures already show that PSNR and SSIM are not correlated well with human perception. It is suggested to also evaluate with some perceptual metrics, e.g., LPIPS [e].\n[e] Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. “The unreasonable effectiveness of deep features as a perceptual metric.” CVPR 2018.\n\n- In Figure 7, how do you generate different results from the same input image for SRGAN? From my understanding, SRGAN doesn’t take any noise vector as input and cannot generate multi-modal results.\n\n- I feel that the comparison with only SRGAN is not enough. There are some GAN-based SR methods [f][g]. It’s also suggested to compare with MSE-based state-of-the-art SR algorithms [h][i].\n\n[f] Sajjadi, M. S., Schölkopf, B., & Hirsch, M. “Enhancenet: Single image super-resolution through automated texture synthesis.“ ICCV 2017.\n[g] Wang, X., Yu, K., Dong, C., & Loy, C. C. “Recovering realistic texture in image super-resolution by deep spatial feature transform.” CVPR 2018.\n[h] Lim, B., Son, S., Kim, H., Nah, S., & Lee, K. M. “Enhanced deep residual networks for single image super-resolution.” CVPR Workshops 2017.\n[i] Zhang, Y., Tian, Y., Kong, Y., Zhong, B., & Fu, Y. “Residual dense network for image super-resolution.” CVPR 2018.\n\n', 'This paper proposes a technique to find a maximum-likelihood estimate of the super-resolved images under latent variables without computing it. Paper is mostly clearly written and except for some sections, it provides enough details. The work is original enough but might need some improvement or more explanation in experiments/result section.\n\nPros:\n-The idea seems to be original enough, simple and easy to implement.\n-A nice follow-up of the recent work in NN search and Implicit maximum likelihood estimation. \n-Many details that could be helpful for further research in the area are given.\n\nCons:\n-Regarding methodology, an unclear point in the paper is how different networks trained according to algorithm 1. Is each sub-network trained separately? Is the visual perception based feature space pre-trained and fixed, or is it jointly retrained with the super-resolution network? \n\n-Another critical point is post-training, particularly the way learned parameters are used could be explained better: Given a super-resolution model f, how the super-resolution of a single image is performed? What is the sampling variation? How likely such a network can be productionized in real-time systems (e.g., digital displays or embedded systems)? How does the proposed approach compared to GAN based methods with regards to that? Is multi-modality a problem in this case? Any way to choose one specific mode in a conscious way?\n\n-My main concern about the paper is the results section: Authors perform both large-scale offline comparison (imagenet) and a small subset human evaluation. The results in human evaluation need some explanation. This comparison is identical to several previous 1-1 comparisons performed in literature and almost every single such comparison it has been found that state of the art techniques (e.g., 10+ years of super-resolution algorithms) significantly outperform bicubic interpolation. However, Table 2 in the paper suggests that both SRGAN and SRIM barely beats bicubic interpolation. For example, authors in https://arxiv.org/pdf/1209.5019.pdf showed that a relatively older supervised technique beat bicubic 90% of the time. There seems to be some explanation needed here: Is it the sample size? Are the samples from both SRIM and SRGAN very variable?\n', '- Summary\nThis paper proposes a method based on implicit maximum likelihood estimation for single-image super-resolution. The proposed method aims at avoiding common artifacts such as high-frequency noise and shape distortion. The proposed method shows better performance than SRGAN in terms of PSNR, SSIM, and human evaluation of realism on the ImageNet dataset.\n\n- Pros\n  - The proposed method shows better performance than SRGAN in terms of PSNR, SSIM, and human evaluation.\n  - The selection of the evaluation methods is appropriate. In the field of image super-resolution tasks, both signal accuracy (e.g., PSNR) and perceptual quality (e.g., human evaluation) are important.\n\n- Cons\n  - The experiments are conducted thoroughly in the ImageNet, but the selection of the dataset is not appropriate. It would be better to apply the proposed method to other datasets which are used recent papers.\n  - Also, the selection of the methods to be compared is not appropriate. It would be better to provide recent state-of-the-art methods and compare the proposed method with them.\n\nThe proposed approach is interesting and promising, but the selection of the methods and datasets to be compared is not appropriate.']","[60, 20, 20]","[80, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by stating that the overall quality of the paper is good, praising its novel idea and clear improvement over existing methods. They also highlight several pros, including clear writing and well-motivated methods. While there are some cons and suggestions for improvement, the overall tone remains positive. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It's suggested to' and 'I wonder' when making recommendations, which maintains a polite and collaborative tone. The reviewer also balances criticism with praise, acknowledging the paper's strengths before discussing areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's originality, clarity, and potential contributions to the field. However, they also express several concerns and suggest areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They frame their concerns as questions or suggestions rather than harsh criticisms, and use phrases like 'might need some improvement' instead of more negative alternatives. The reviewer also starts with positive points before moving on to concerns, which is a polite approach in academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the proposed method's better performance and describes it as 'interesting and promising'. However, they also point out significant cons, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout, balancing praise with constructive criticism. They avoid harsh language, instead using phrases like 'it would be better' when suggesting improvements. The review maintains a respectful tone while providing both positive and negative feedback.""]"
"['This  seems like a very interesting concept, creating adversarial agents for each class that essentially compete with each other.  It seems like this might be a very promising method for arguing for even more abstract classes like ""circus"" vs ""zoo"" \n\nI wise more had been said about why the Honest Advocate outperformed the standard Advocate on the MIMIC dataset.  \n\nThe authors state:\n\n""Advocates can effectively compete to generate higher quality evidence, though this effect was\nlargely localized to a few class-pairs (e.g. shirts v.s. pullovers). ""\n\nDoes it do this on things that are essentially very similar?  \n\nOverall, I think this is a great idea. I have been looking for some similar work and consider this work to be similar in the multi-generative aspect: ""MEGAN: Mixture of Experts of Generative Adversarial Networks for Multi-modal Image Generation"" - Park, Yoo, Bahng, Choo and Park, IJCAI 2018, but I cannot find similar work using the generative experts as collective adversaries for discrimination.\n\nThe paper is clear and well written.  Improvements for the paper would be going into more detail about why the method works.  It would have been great to have seen a data set on which the method performs poorly - that would give additional insight into its strengths and weaknesses.\n\n', 'The paper proposes a novel network architecture for classification problems that is based on decomposing the network into two parts classed the advocates and the judge. The advocates learn by competing with each other to provide a judge-convincing ""evidence"" -- an attention map over the input that supposedly highlight the most class-relevant parts of the input.\nI find the very general idea interesting because it could potentially help to improve interpretability of neural networks by explicitly putting in the network a corresponding bottleneck.\nHowever, in its current form the approach has a number of drawbacks:\n\n1) The input to the judge network scales linearly with the number of classes which potentially prevents from learning on large-scale datasets such as ImageNet.\n2) The attention / saliency map might be very difficult to compute for complex data if relies an autoencoding-like computation. \n3) There is no guarantee or an intuition on why would the advocates learn to provide evidences that are interpretable to humans. \n\nThe provided experiments are conducted on rather simple datasets and to argue on wide applicability of the method I suggest using more visually-diverse datasets like Cifar. \nI also find the gains on classification accuracy quite marginal and perhaps less important than the interpretability of the evidences which has not been convincingly demonstrated.', 'This paper presents a novel concept of supervised learning, advocacy learning. In this framework, supervised learning procedure is given by two subnetworks, advocates and judge. Advocates generate evidence in the form of attention for individual classes and judge decide the final class labels.\n\nThe main idea looks interesting, and the paper is clear enough to deliver the idea. However, this paper has the following major issues.\n\n1. There is no formal justification of the idea. Although the idea looks interesting, there is no theoretical background and no clear intuition.\n\n2. Experiment is weak and even inconsistent. Evaluation is performed on very small datasets only, where all baseline methods already show very high accuracy and accuracy gain given by the proposed method is very marginal. In particular, Table 1 and 2  have inconsistent results; advocacy network is better in Table 1 while worse in Table 2 compared to honest advocacy network. To make the idea more convincing, it is required to test it on much larger datasets, at least ImageNet scale, and more desirable to show results in other tasks such as object detection and image segmentation.\n\n3. I am not sure if advocacy network has any separate supervision to enforce it to be learned in a class-conditional manner. Also, in honest advocacy network, each subnetwork can look at only a part of dataset (data corresponding to the class), and I wonder if there is any problem given by data deficiency issue.\n\nOverall, the paper does not look ready for publication because the idea is clearly justified neither theoretically nor empirically.']","[80, -20, -60]","[70, 60, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses strong interest in the concept, calling it 'very interesting' and 'a great idea'. They also mention it being 'very promising' and 'similar' to other valuable work. The politeness score is 70 (polite) due to the overall constructive tone and the use of phrases like 'I think this is a great idea' and 'The paper is clear and well written'. The reviewer offers suggestions for improvement in a respectful manner, without harsh criticism. The slightly lower politeness score (compared to sentiment) is due to the direct nature of some comments, such as 'I wish more had been said...' which, while not impolite, is less overtly courteous than the rest of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the general idea interesting, they point out several drawbacks and limitations of the approach. The reviewer also suggests that the gains in classification accuracy are marginal and that the interpretability hasn't been convincingly demonstrated. However, it's not entirely negative as they do acknowledge potential benefits.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They start by acknowledging the interesting aspects of the work before presenting their criticisms. The criticisms are presented as 'drawbacks' rather than flaws, and suggestions for improvement are offered constructively (e.g., 'I suggest using more visually-diverse datasets'). The tone remains objective and focused on the work rather than personal."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges that the main idea is interesting and the paper is clear, they list several major issues and conclude that the paper is not ready for publication. The politeness score is 20 because the reviewer uses relatively neutral language and acknowledges some positive aspects, but doesn't use overtly polite phrasing. They present their criticisms directly but without harsh language. The reviewer begins with a positive note about the interesting concept and clear presentation, which slightly elevates the politeness score above neutral. However, the overall tone remains professional rather than explicitly polite.""]"
"['Summary:\nThis paper proposes a novel optimization strategy regarding softmax cross-entropy loss, to extract the effective features of well generalization in the framework of metric learning.\nThe authors focus on the ""temperature"" parameter in the softmax and through analyzing the role of the temperature in terms of gradient, propose the approach of heating-up softmax in which the temperature is varied from low to high in training.\nAnd, the effects of normalization such as by l2 and BatchNorm are discussed in the framework of heated-up softmax.\nThe experimental results on metric learning tasks demonstrate the effectiveness of the proposed method in comparison with the other methods.\n\nComments:\nPros:\n+ The idea of heating up the temperature in softmax is interesting, and seems novel in the literature of metric learning.\n+ The performance improvement, especially produced by batchNorm-based normalization, is shown.\n\nCons:\n- The formulation of tempered softmax with normalization is already presented in [Wang et al., 2017].\n- The reason why the heating-up approach contributes to better metric learning is not clearly provided in a well convincing way.\n- It lacks an important ablation study to fairly validate the method.\n- The discussion/comparison is limited to the simple softmax function.\n\nAlthough the reviewer likes the idea of heating up softmax, this paper can be judged as a borderline slightly leaning toward reject, due to the above weak points, the details of which are explained as follows.\n\n- Formulation\nThe softmax equipped with temperature for the normalized features and weights are shown in [Wang et al., 2017]. The only difference from that work is the way to deal with temperature; in [Wang et al., 2017], the temperature is ""optimized"" as a trainable parameter, while it is dealt with in a hand-crafted way of heating up in this work. Honestly speaking, it is unclear which approach is better, though the optimization in [Wang et al., 2017] seems elegant as stated in that paper. The only way to validate this work compared to [Wang et al., 2017] is to empirically evaluate those two methods in the experiments. Such a comparison experiment is not found and it is a main flaw of this paper.\n\n- Justification of the method\nThe gradients of the softmax cross-entropy loss parameterized with a temperature T are well analyzed in Sections 3.1&3.2. But, in Section 3.3, the reviewer cannot find the clear and convincing explanation for why the temperature T should be increased in the training. My question is: why don\'t you use alpha=4 consistently throughout the training?\n It might be related to the process of simulated annealing (though ""temperature"" is usually cooled down in SA), and more interestingly, it would also be possible to find connection with the work of [Guo et al., 2017]. In [Guo et al., 2017], the temperature in the softmax is optimized as a post processing for calibrating the classifier outputs. Though the calibration task itself is a little bit apart from the metric learning of the authors\' interest, we can find in that paper an interesting result that the temperature is heated up to increase the confidence of the classifier outputs, which is quite similar to the process of fine-tuning by heating up softmax as done in this work. Therefore, the reviewer guesses that the effectiveness of heating up softmax can also be interpreted from the viewpoint of [Guo et al., 2017].\n\nThere is also less description about Figure 1; in particular, the reviewer cannot understand what Figure 1(d) means.\n\n- Ablation study\nTo empirically resolve the above concerns, it is necessary to present the empirical comparison with the ""static"" softmax.\nNamely, the methods of HLN/HBN should be carefully compared to LN/BN of ""alpha=4"", not only those of alpha=16 shown in Table 1&2; the comparison in Table 3 seems unfair since the authors apply the static softmax without normalization.\nAnd, it would be better to show the performance of heated-up softmax ""without"" normalization to show the important role of the normalization, as done in [Wang et al., 2017].\nIn summary, since the proposed method is composed of a heating-up approach and feature normalization, the authors are required to validate the method from those two aspects, respectively, for increasing the significance of this paper.\n\n- Other loss function\nFor achieving a compactness in feature representation, the simple softmax requires both temperature and normalization. It, however, is also conceivable to employ the other types of loss function for that purpose, such as [a] which is based on the (Mahalanobis) distance with taking into account the margin between categories. The distance based loss also embeds features into localized clusters, which satisfies the authors\' objective in this work. To validate the proposed method, it is required to compare the method with such a different types of loss function.\n\n[a] Wan, W., Zhong, Y., Li, T., & Chen, J. (2018). Rethinking Feature Distribution for Loss Functions in Image Classification, In CVPR2018, pp. 9117–9126.', 'The introduction and the title does not match. Metric learning does not require to specify the dimension; while the embedding has to specify the reduced dimension. I feel confused that the authors mix these two concepts.\n\nThe objective in (1) is very close to that of t-SNE[5], where it uses the KL as the objective. Then other update formula are similar.  \n\nThis paper facilitates the effect of temperature in the Softmax function to heuristically learn a compact and spread-out embedding. However, such an idea have been widely used and investigated in Reinforcement learning [1], Knowledge distillation [2], classification [3] and discrete variable optimization [4] and t-SNE visualization [5] etc. Thus, the insight about the temperature effect on the embedding from the second last layer, cannot be novel any more. Based on this, the proposed ``heating-up” strategy to leverage its effect on the embedding is heuristic, since the temperature parameter is manually set instead of automatically learning. In this case, I do expect the authors should provide more in-depth theoretical analysis. \n\nThe authors do not present more experimental results on the correlation between the final performance and this temperature setting. \n\nBesides, as the alpha increases or decreases, the side-effect on the learning rate setting for the optimization have not clearly analyzed, which leaves more concerns on tuning performance. \n\n\n[1] Sutton, R. S. and Barto A. G.\xa0Reinforcement Learning: An Introduction. The MIT Press, Cambridge, MA, 1998.\n[2] Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network. NIPS 2015.\n[3] Guo, Chuan, et al. ""On calibration of modern neural networks.""\xa0ICML 2017.\n[4] Jang E, Gu S, Poole B. Categorical reparameterization with gumbel-softmax. ICLR 2017.\n[5] Maaten L, Hinton G. Visualizing data using t-SNE[J]. Journal of machine learning research, 2008, 9(Nov): 2579-2605.', 'This paper presents an interesting idea to improve the softmax embedding performance with heated-up strategy. It is well-written and the proposed method is easy to implement. Several experiments on metric learning datasets demonstrate the effectiveness of the proposed method.\n\nThe motivation to find a balance between the compactness and ""spread-out"" embedding is reasonable. The major weakness is the intermediate temperature selection, it might be a little tricky. How to generalize it to other applications?\n\nThe authors claim that ""heated-up"" strategy produces well generalized feature, but the rationale behind is unclear. And there is no quantitative analysis to support this point. \n\nThe starting temperature aims at pushing the “incorrect” samples to “boundary” samples and pushing the “boundary” samples to “centroid” samples. I would like to see the ratio of #incorrect/total and #boundary/total changed with different temperature in training process, i.e., alpha = 16, 4, 1. This experiment may help to verify the idea.\n\nAs mentioned in Section 3, multiple strategies could be defined to increase the temperature. It is interesting to design a multiple heat-up strategy. Does it help to improve the learning speed?\n']","[-30, -70, 60]","[60, -20, 70]","[""The sentiment score is -30 because while the reviewer finds the idea interesting, they ultimately lean towards rejecting the paper due to several weaknesses. They state it's a 'borderline slightly leaning toward reject' and list more cons than pros. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'it would be better to' and 'the reviewer cannot understand' rather than more direct criticisms. The reviewer also provides detailed explanations for their concerns, showing engagement with the work despite their overall negative assessment."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several issues with the paper, including mismatched concepts, lack of novelty, heuristic approach, insufficient experimental results, and unclear analysis. The reviewer uses phrases like 'I feel confused,' 'cannot be novel any more,' and 'leaves more concerns,' indicating a negative sentiment. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the criticism or offer positive feedback. Phrases like 'The authors do not present' and 'I do expect the authors should' come across as somewhat demanding and impolite. However, the reviewer does use some neutral language and provides references, which prevents the score from being extremely negative."", ""The sentiment score is 60 (positive) because the reviewer starts by describing the paper as 'interesting' and 'well-written', and notes that experiments demonstrate the effectiveness of the proposed method. However, it's not extremely positive as the reviewer also points out some weaknesses and areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions (e.g., 'I would like to see...', 'It is interesting to design...'). The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a polite approach to peer review.""]"
"['\nSummary:\nThis paper proposes MetaMimic, an algorithm that does the following:\n(i) Learn to imitate with high-fidelity with one-shot. The setting is that we have access to several demonstrations (only states, no actions) of the same task. During training, we have pixel observations plus proprioceptive measurements). At test time, the learned policy can imitate a single new demonstration (consisting of only pixel observations) of the same task.\n(ii) When given access to rewards, the policy can exceed the human demonstrator by augmenting its experience replay buffer with the experience gained while learning (i). Therefore, even in a setting with sparse rewards and no access to expert actions (only states), the policy can learn to solve the task.\n\nOverall Evaluation:\nThis is a good paper. In my opinion however, it does not pass the bar for ICLR.\n\nPros:\n- The paper is well written. The contributions are clearly listed, the methods section is easy to follow and the authors explain the choices they make. The illustrations are clear and intuitive.\n- The overview of hyperparameter choice and tuning / importance factor in the Appendix is useful.\n- Interesting pipeline of learning policies that can use demonstrations without actions.\n- The results on the simulated robot arm (block stacking task with two blocks) are good.\n\nCons:\n- The abstracts oversells the contribution a bit when saying that MetaMimic can learn ""policies for high-fidelity one-shot imitation of diverse novel skills"". The setting that\'s considered in the paper is that of a single task, but different demonstrations (different humans from different starting points). This seems restrictive, and could have been motivated better.\n- Experimental results are shown only for one task; block stacking with a robot arm in simulation.\n- Might not be a good topical fit for ICLR, but more suited for a conference like CoRL or a workshop. The paper is very specific to imitation learning for a manipulation / control tasks, where we can (1) reset the environment to the exact starting position of the demonstrations, (2) the eucledian distance between states in the demonstration and visited by the policy is meaningful (3) we have access to both pixel observations and proprioceptive measurements. The proposed method is an elegant way to solve this, but it\'s unclear how well it would perform on different types of control problems, or when we want to transfer policies between different (but related) tasks.\n\nQuestions:\n- Where does the ""task stochasticity"" come from? Only from the starting state, and from having different demonstrations? Or is the transition function also stochastic?\n- The learned policy is able to do one-shot imitation, i.e., given a new demonstration (of the same task) the policy can follow this demonstration. Do I understand correct that this mean that there is *no* additional learning required at test time?\n- It is not immediately clear to me why the setting of a single task but new demonstrations is interesting. Could the authors comment on this? One setting I could imagine is that the policy is trained in simulation, but then executed in the real-world, given a new demonstration. (If that\'s the main motivation though, then the experiments might have to support that this is possible - if no real-world robot is available, maybe the same simulator with a slightly different camera angle / light conditons or so.)\n- The x-axis in the figures says ""time (hours)"" - is that computation time or simulated time?\n\nOther Comments:\n- In 3.2, I would be interested in seeing the following baseline comparison: Learn the test task from scratch using the one available demonstration, with the RL procedure (Equation 2, but possibly without the second term to make it fair). In Figure 5, we can see that the performance on the training tasks is much better when training on only 10 tasks, compared to 500. Then why not overfit to a single task, if that\'s what we\'re interested in? \n- An interesting baseline for 3.3 might be an RL algorithm with shaped rewards: using an additional reward term that is the eucledian distance to the *closest* datapoint from the demonstration. Compared to the baselines shown in the results section, this would be a fairer comparison because (1) unlike D4PG we also have access to information from the demonstrations and (2) no additional information is needed like the action information in D4PGfD and (3) we don\'t have the need for a curriculum.\n\nNitpick (no influence on score):\n[1. Introduction]\n- I find the first sentence, ""One-shot imitation is a powerful way to show agents how to solve a task"" a bit confusing. I\'d say one-shot imitation is a method, not a way to show how to solve a task. Maybe an introductory sentence like ""Expert demonstrations are a powerful way to show agents how to solve a task."" works better?\n- Second sentence, the chosen example is ""manufacturing"" tasks - do you mean manipulation? When reading this, I had to think of car manufacturing - a task I could certainly not imitate with just a few demonstrations.\n- Add note that with ""unconditional policy"" you mean not conditioned on a demonstration.\n[2. MetaMimic]\n- [2.1] Third paragraph: write ""Figure 2, Algorithm 1"" or split the algorithm and figure up so you can refer to them separately.\n- [2.1] Last paragraph, second line: remove second ""to""', 'This paper presents an RL method for learning from video demonstration without access to expert actions. The agent first learn to imitate the expert demonstration (observed image sequence and proprioceptive information) by producing a sequence of actions that will lead to the similar observations (require a renderer that takes actions and outputs images). The imitation loss is a similarity metric. Next, the agent explores the environment with both the imitation policy and task policy being learned; an off-policy RL algorithm D4PG is used for policy learning. Experiments are conducted on a simulated robot block stacking task.\n\nThe paper is really clearly written, but presenting the approach as ""high-fidelity"", ""one-shot"" learning is a bit confusing. First, it\'s not clear what\'s the motivation for high-fidelity. To me this is an artifact due to having to imitate the visual observation instead of the actions, which is a legitimate constraint, but not the original goal. Second, the one-shot learning setting consists of training on a set of stochastic demonstrations and testing on another set collected from a different person; both for the same task. Usually one-shot learning tests on slightly different tasks or environments, whereas here the goal is to generalize to novel demonstrations. It\'s not clear why do we care imitation per se in addition to the task reward.\n\nWhat I find interesting is the proposed approach for learning for video demonstration without action labels. Currently this requires an executor to render the actions to images, what if we don\'t have such an executor or only have a noisy / approximate renderer? In the real world it\'s probably hard to find a good renderer, it would be interesting to see how this constraint can be relaxed.\n\nQuestions:\n- While the authors have shown the average rewards of the two sets are different, I wonder what\'s the variance of each person\'s demonstration. \n- In Fig 5, on the validation set, in terms of imitation loss there aren\'t that much difference between the policies, but in terms of task reward, the \'red\' policy goes to zero while others policies\' rewards are still similar. Any intuition for why seemingly okay imitation doesn\'t translate to task reward?\n\nOverall, I enjoyed reading the paper and the experiments are comprehensive. The current presentation angle seems a bit off though.', 'Summary\n\nThis work porposes a approach for one-shot imitation with high accuracy, called ""high fidelity imitation learning"" by the authors. Furthermore, the work addresses the common problem of exploration in imitation learning, which would help to rescue from off-policy states.\n\nReview\n\nIn my opinion, the main claims of this paper are not validated sufficiently in the experiments. I would expect the experiments to be designed specifically to support the claims made, but little evidence is provided:\n\n- The authors claim that the method allows one-shot generalization to an unknown trajectory. To test this hypothesis the authors only provide experiments of generalization towards trajectories of a different demonstrator on the same task of stacking cubes. I would expect experiments with truly different trajectories on a different task than stacking cubes to test the hypothesis of one-shot imitation.\nUntil then I see no evidence for a ""one-shot"" imitation capability of the proposed method.\n\n- That storing the trajectories of early training can act as replacement for exploration as rescue from off-policy states: This is never experimentally validated. This hypothesis could easiliy be validated with an ablation study, were the results of early would not be added to the replay buffer.\n\n- High fidelity imitation: In the caption of Figure 7 the authors note that the unconditional task policy is able to outperform the demonstration videos. Thus the trajectories of the unconditional task policy allow a higher reward then the demonstrations.\nCould the authors please comment on how the method still achieves high fidelity imitation even when the results of the unconditional task policy are added to the replay buffer? In prinicipal these trajectories allow a higher reward than the demonstration trajectories that should be imitated.\n\nMainly due to the missing experimental validation of the claims made I recommend to reject the paper.', '**Summary**\n\nThe paper looks at the problem of one-shot imitation with high accuracy of imitation. The main contributions: \n1. learning technique for high fidelity one-shot imitation at test time. \n2. Policies to improve the expert performance through RL.  \n\nThe main improvements of this method is that demo action and rewards are not needed only state trajectories are sufficient. \n\n\n** Comments **\n- The novelty of algorithm block\nThe main method is very similar to D4PG-fd. The off-policy method samples from a replay buffer which comprises of both the demos and the agent experience from the previous learner iterates. \n\n1. From a technical perspective, what is the advantage of training an imitation learner from a memory buffer of the total experience? \nIf the task reward is not accessed, then when the imitation learner is training, then the data should not be used for training the task policy learner. On the other hand if task reward is indeed available then what is the advantage of not using it. \n\n2. A comparison with a BC policy to generate more experience data for the task policy agent/learning might also be useful. \n\n* Improved Comparisons\n- Compare with One-Shot Performance\nSince this is one of the main contributions, explicit comparison with other one-shot imitation papers needs to be quantified with a clearly defined metric for generalization. \n\nThis comparison should be both for short-term tasks such as block pick and place (Finn et al, Pathak et al, Sermanet et al.) and also for long-term tasks as shown in (Duan et al. 2017 and also in Neural Task Programming/Neural Task Graph line of work from 2018)\n\n- Compare High-Fidelity Performance\nIt is used as a differentiator of this method but without experimental evidence.\nThe results showing imitation reward are insufficient. The metric should be independent of the method. An evaluation might compare trajectory tracking error: for objects, end-effector, and joint positions. This is available as privileged information since the setup is in a simulation.\n\nFurthermore, a comparison with a model-based trajectory tracking with a learned or fitted model of dynamics is also very useful.\n\n- Compare Policy Learning Performance\nIn addition to D4PG variants, performance comparison with GAIL will ascertain that unconditional imitation is better than SoTA. \n\n\n* Tracking a reference (from either sim or demos) is a good idea that has been explored in sim2real literature[2,3] and imitation learning [4]. It is not by itself novel. The authors fail to acknowledge any work in this line as well as provide insight why is this good and when is this valid. For instance, with highly stochastic dynamics this may not work!\n\n\n- ""Diverse Novel Skills"" \nThe experiments are limited to a rather singular pick and place task with a 3-step structured reward model. It is unfair to characterize this domain as very diverse or complex from a robotics perspective. More experiments on continuous control would help.\n\n- Bigger networks\n""In fig. 3 we demonstrate that indeed a large ResNet34-style network (He et al., 2016) clearly outperforms"" -- but Fig 3 is a network architecture diagram. It is probably fig 6!\n\n- The authors are commended for presenting a broad overview of imitation based methods in table 2\n\n** Questions **\n\n1.  How different if the imitation learner (trained with imitation reward) from a Behaviour Cloning Policy. \n\n2. How is the local context considered in action generation in sec 2.1. \nThe authors reset the simulation environment to o_1 = d_1. \nThen actions are generated with  \\pi_{theta} (o_t, d_{t+1}). \na. Is the environment reset every time step?\nb. If not how is the deviation of the trajectory handled over time? \nc. how is the time horizon for this open loop roll out chosen. \n\n3. How is this different for a using a tracking based MPC with the same horizon? The cost can be set the same the similarity metric between states. \n\n4. The architecture uses a deep but simplistic model. When the major attribution of the model success is to state similarity -- especially image similarity -- why did the authors not use image comparators something like the Siamese model?\n\nSuggestion:\nThe whole set of experiments are in a simulation. \nThe authors go above and beyond in using Mitsuba for rendering images. But the images used are Mujoco rendered default. It would nice if the authors were more forthcoming about this. All image captions should clearly state -- Simulated robot results, show images used for agent training. The Mitsuba renders are only used for images but nowhere in the algorithm. So why do this at all, and if it has to be used please do it with a disclaimer. Right now this detail is rather buried in the text. \n\nReferences:\n1. Neural Task Programming, Xu et al. 2018 (https://arxiv.org/abs/1710.01813)\n2. Preparing for the Unknown: Learning a Universal Policy with Online System Identification (https://arxiv.org/abs/1702.02453)\n3. Adapt: zero-shot adaptive policy transfer for stochastic dynamical systems (https://arxiv.org/abs/1707.04674)\n4. A survey of robot learning from demonstration, Argall et al. 2009\n']","[-20, 50, -80, -20]","[70, 80, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('This is a good paper', 'The paper is well written', 'Interesting pipeline'), they ultimately conclude that it 'does not pass the bar for ICLR'. The cons outweigh the pros, and there are several critical questions and suggestions for improvement. The politeness score is relatively high (70) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive ones. They use phrases like 'Could the authors comment on this?' and 'I would be interested in seeing' which are polite ways of suggesting improvements. Even criticisms are phrased diplomatically, such as 'The abstracts oversells the contribution a bit'. The reviewer also takes care to explain their reasoning and provide detailed feedback, which is a courteous approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses enjoyment in reading the paper and acknowledges its comprehensive experiments. However, they also point out some concerns about the presentation and framing of the work. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions or suggestions rather than harsh criticisms. They use phrases like 'I enjoyed reading the paper' and 'What I find interesting is...' which contribute to a polite tone. The reviewer also balances critique with positive feedback, maintaining a professional and courteous demeanor throughout the review."", ""The sentiment score is -80 because the reviewer recommends rejecting the paper and states that the main claims are not sufficiently validated. The review is predominantly critical, pointing out several shortcomings in the experimental design and evidence provided. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'In my opinion' and 'Could the authors please comment', which add a degree of politeness. However, the overall tone is still quite direct and critical, hence the relatively low positive score. The reviewer also provides specific suggestions for improvement, which is a constructive approach, albeit in the context of a rejection recommendation."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The authors are commended for presenting a broad overview of imitation based methods'), the majority of the review focuses on limitations, missing comparisons, and areas for improvement. The reviewer raises several critical questions and points out gaps in the methodology and results presentation.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'The authors are commended' and offer specific suggestions for improvement rather than harsh criticisms. The questions are framed politely, and the reviewer provides helpful references. However, the score is not higher because the review is quite direct in pointing out shortcomings and doesn't use many overtly polite phrases or softening language.""]"
"['Overall this paper contributes many interesting insights into the specific application of empathetic dialog into chatbot responses.  The paper in particular is contributing its collected set of 25k empathetic dialogs, short semi-staged conversations around a particular seeded emotion and the results of various ways of incorporating this training set into a generative chatbot.\n\nWhile the results clearly do not solve the problem of automating emapthy, the paper does give insights into which methods perform better than others (Generation vs Retrieval) and explicitly adding emotion predictions vs using an ensemble of encoders.\n\nThere is a lot in this paper, and I think it could have been better organized.\nI am more familiar with emotion related research and not language to language translation, so I would have appreciated a better explanation of the rationale for using BLEU scores.  I did some online research to understand these Bilingual Evaluation Understudy Scores and while it seems like they measure sentence similarity, it is unclear how they capture ”relevance” at least according to the brief tutorial that I read (https://machinelearningmastery.com/calculate-bleu-score-for-text-python/).  I did not see the paper describing the use of this score in the references but perhaps I missed it – could you please clarify why this is a good metric for relevance?  It seems that these scores are very sensitive to sentence variation.  I am not sure if you can measure empathy or appropriateness of a response using this metric.\nFor your data collection you have 810 participants and 24,850 conversations.  Are the 810 participants all speakers or speakers and listeners combined?  How many conversations did each speaker/listener pair perform 32?  (one for each emotion) or 64? (two for each emotion) Was the number variable?  If so what is the distribution of the contribution – e.g. did one worker generate 10,000 while several hundred workers did only three of four?  Was it about even?  Just for clarity – how did you enroll participants?  Was it through AMT?  What were the criteria for the workers?  E.g. Native English speaker, etc.\n\nIn your supplemental material, I found the interchanging of the words “context” and “emotion” confusing.  The word context is used frequently throughout your manuscript: “dialog context,” “situational context” - emotions are different from situations, the situational utterance is the first utterance describing the emotion if I read your manuscript correctly.  Table 6 should use “Label” or “Emotion” instead of the more ambiguous “Context.”  \n\nMy understanding is that speakers were asked to write about a time when they experienced a particular feeling and they were given a choice of three feelings that they could write about.  You then say that workers are forced to select from contexts they had not chosen before to ensure that all of the categories were used.  From this I am assuming that each speaker/listener worker pair had to write about all 32 emotions – is this correct?  Another interpretation of this is that you asked new workers to describe situations involving feelings that had not been chosen by other workers as data collection progressed to ensure that you had a balanced data set.  This would imply that some emotional situations were less preferred and potentially more difficult to write about.  It would be interesting if this data was presented.  It might imply that some emotion labels are not as strong if people were forced to write about them rather than being able to choose to write about them.  \nWere these dialogs ever actually annotated?  You state in section 2, Related Work “we train models for emotion detection on conversation data that has been explicitly labeled by annotators” – please describe how this was done.  Did independent third party annotators review the dialogs for label correctness?  Was a single rater or a majority vote used to decide the final label.  For example, in Table 1, the label “Afraid” is given to a conversation that could also have reasonable been generated by the label “Anxious” a word explicitly used in the dialog.  I am guessing that the dialogs are just labeled according to the label / provocation word and that they were not annotated beyond that, but please make this clear.  \nIn the last paragraph you state “A few works focus..” and then list 5.  This should rather be “several other works have focused on “ …  \nConversely, you later state in section 3 “Speaker and Listener”, “We include a few example conversations from the training data in Table 1,” this should more explicitly be “two.”\nAlso in section 3 when you describe your cross validation process, you state “We split the conversations into approximately 80/10/10 partitions.  To prevent overlap of <<discussed topics>> we split the data so that all the sets of conversations with the same speaker providing the prompt would be in the same partition.  \nIn your supplemental material you state that workers were paired.  Each worker is asked to write a prompt, which also seems to be the first utterance in the dialog they will start.  You state each worker selects one emotion word from a list of three which is somehow generated (randomly?) form your list of 32 .  I am assuming each worker in the pair does this, then the pair has a two “conversations” one where the first worker is the speaker and another where the second worker is the speaker – is this correct?  It is not entirely clear from the description. Given that you have 810 workers and 24,850 conversations, I am assuming that each worker had more than one conversation.  My question is  - did they generate a new prompt / first utterance for each conversations.  I am assuming yes since you say there are 24,850 prompts/conversations.  For each user are all of the situation/prompts they generate  describing the same emotion context?  E.g. would one worker write ~30 conversations on the same emotion.  This seems unlikely, and it seems more likely that given the number of conversations ~30 per participant is similar to the number of emotion words that you asked each worker to cycle through nearly all of the emotions or that given they were able to select, they might describe the same emotion, e.g. “fear” several times.  If the same worker was allowed to select the same emotion context multiple times was it found that they re-used the same prompt several times?  I am assuming that this is the case and that this is what you mean when you say that you “prevent overlap of discussed topics” between sets when you exclude particular workers.  Is this correct?  Or did you actually look and code the discussed topics to ensure no overlap even across workers (e.g. several people might have expressed fear of heights or fear of the dark).\n\nIn section 4, Empathetic dialog generator, you state that the dialog model has access to the situation description given by the speaker (also later called the situational prompt) but not the emotion word prompt.  Calling these both prompts makes the statement about 24,850 prompts/conversations a bit ambiguous.  A better statement would be 24,850 conversations based on unique situational prompts/descriptions (if they are in fact unique situational prompts.  I am assuming they are not if you are worried about overlapping “discussed topics” which I am assuming are the situational prompts since the dialogs are very short and heavily keyed off these initial situational prompts)\n\nIn your evaluation of the models with Human ratings you describe two sets of tests.  In one test you say you collect 100 annotations per model.  More explicitly, did you select 100 situational prompts and then ask workers to rate the response of each model?  Was how many responses was each worker shown?  How many workers were used?  Are the highlighted numbers the only significant findings or just the max scores?  Annotations is probably not the correct word here.\n\nPlease also describe your process for assigning workers to the second human ratings task.     \n\nSince the two novel aspects of your paper are the new dataset and the use of this dataset to create more empathetic chatbot responses (""I know the feeling"") I have focused on these aspects of the paper in my review.\n\nI found the inclusion of Table 7 underexplained in the text.  The emotion labels for all these datasets are not directly comparable so I would have liked to have seen more explanation around how these classifications were compared.  It would also be helpful to know how more similar emotions such as ""afraid"" and ""anxious"" were scored vs ""happy"" and ""sad"" confusions \n', 'The paper describes a new study about how to make dialogs more empathetic.\nThe work introduced a new dataset of 25k dialogs designed to evaluate the\nrole that empathy recognition may play in generating better responses \ntuned to the feeling of the conversation partner.  Several model\nset-ups, and many secondary options of the set-ups are evaluated.\n\nPros:\n\nA lot of good thoughts were put into the work, and even though the techniques\ntried are relatively unsophisticated, the work represents a serious attempt\non the subject and is of good reference value.\n\nThe linkage between the use of emotion supervision and better relevancy is interesting.\n\nThe dataset by itself is a good contribution to the community conducting studies in this area.\n\nCons:\n\nThe conclusions are somewhat fuzzy as there are too many effects\ninteracting, and as a result no clear cut recommendations can be made\n(perhaps with the exception that ensembling a classifier model trained\nfor emotion recognition together with the response selector is seen\nas having advantages).\n\nThere are some detailed questions that are unaddressed or unclear from\nthe writing.  See the Misc. items below.\n\nMisc.\n\nP.1, 6th line from bottom: ""fro"" -> ""from""\n\nTable 1:  How is the ""situation description"" supposed to be related to the\nopening sentence of the speaker?  In the examples there seems to be substantial\noverlap.\n\nFigure 2, distribution of the 32 emotion labels used:\nthis is a very refined set that could get blurred at the boundaries between similar emotions.\nAs for the creators of those dialogs,  does everyone interpret the same emotion label the same way?\ne.g. angry, furious; confident, prepared; ...; will such potential ambiguities impact the work?\nOne way to learn more about this is to aggregate related emotions to make a coarser set,\nand compare the results.\n\nAlso, often an event may trigger multiple emotions, which one the speaker chooses to focus on\nmay vary from person to person.  How may ignoring the secondary emotions impact the results?\nTo some extent this is leveraged by the prepending method (with top-K emotion predictions).\nWhat about the other two methods?\n\nP. 6, on using an existing emotion predictor:  does it predict the same set of emotions\nthat you are using in this work?\n\n', 'The overall goal of the paper is to make end-to-end dialogue systems more empathetic, so that they can respond more appropriately and in ways that acknowledge how the users are feeling. The authors make two contributions towards that goal: (1) they introduce a crowdsourced dataset (EmpatheticDialogue) annotated with fine-grained emotion labels. (2) They show improvements on dialogue generation (in terms of empathy, but also relevance and fluency) using a multi-task objective, ensemble of encoders, and a more ad-hoc technique that consists of prepending inferred emotion labels to the input.\n\nIn terms of technical novelty, the work is relatively incremental: (A) The use of multi-task objectives in sequence models [1] is relatively common nowadays (there is little mathematical details in the paper, so it’s hard to see how the approach of the paper really differs from extensive related work.). (B) Prepending predictions: prepending class labels to the input is also relatively common (e.g., in multilingual NMT to select a language). [2] presents a similar approach for polite response generation, where they prepend a label using a politeness classifier.\n\nI also have some doubts about the two claimed contributions of the paper (the authors actually list 3 contributions in the introduction, but for convenience I lump the 2 non-data ones together):\n\n(1) Dataset: The dataset was crowdsourced by giving workers an emotion label (e.g., afraid) and asking them to define a situation in which that emotion might occur and inviting them to have a conversation on that situation. The problem with prompting workers for specific emotions is that this assumes they are good actors and this is likely to produce exchanges that are rather cliché and overdone (e.g., Table 1: the label “afraid” yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather cliché and incorporate little details that would make them sound real).  The authors justify this dataset by pointing out that existing real-world datasets underrepresent rare emotions (e.g., afraid), but that’s just a reflection of how these emotions are distributed in the real world. Better subsampling strategies would enable a better balance in the distribution without having to give up on real-world data (filtering using emojis, hashtags, etc.).  As the paper shows quantitative gains using this dataset, it is probably ok to use but, qualitatively, this dataset is probably not for everyone working on emotion in NLP. \n\n(2) Improvement in empathetic dialogue generation: The paper shows improvements across the board compared to a Transformer baseline, but the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.) is crucially needed to get better empathetic dialogues, since the authors did not control for training data size and model capacity. Indeed, the authors exploited different amounts of data (out of-domain, or both in- and out-of-domain), different model capacities (going from baseline Transformer to model ensembles), and sometimes richer input (e.g., pre-trained emotion classifier). The results might only be showing that more data or more model capacity helps, which would of course not be surprising at all. The fact that generated outputs improve in all aspects (not only empathy, but in attributes completely unrelated to empathy such as fluency and relevance) suggests that the improvement is due to more data or capacity (e.g., perhaps yielding better encoder).  More statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.\n\nAbout the use of Reddit: this might not be the best background dataset, as it’s mostly strangers talking to other strangers, presumably causing the baseline to be weak on empathy. Twitter or other social-network type datasets (letting you follow people rather topics) *might* be better suited as it comparatively involves more exchanges between people who actually know each other and who are thus more likely to behave empathetically.\n\nOverall, the paper doesn’t really attempt to make major technical contribution, and instead (1) introduces a dataset and (2) makes empirical contributions, but I think there are problems with both.\n\nTypos:\n\nIntroduction: “fro”\nReferences: Elizaa \n\n[1] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser  \nMulti-task Sequence to Sequence Learning\nhttps://arxiv.org/abs/1511.06114\n\n[2] Tong Niu and Mohit Bansal\nPolite Dialogue Generation Without Parallel Data\nhttps://arxiv.org/pdf/1805.03162.pdf']","[50, 50, -60]","[70, 70, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and interesting insights, while also providing constructive criticism and suggestions for improvement. The overall tone is balanced, recognizing both strengths and areas for clarification. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges their own potential lack of understanding in some areas. The reviewer consistently uses phrases like 'please clarify', 'I would have appreciated', and 'could you please explain', which maintain a polite and constructive tone even when pointing out issues or requesting more information."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several pros of the paper, including the good thoughts put into the work, the interesting linkage between emotion supervision and relevancy, and the valuable dataset contribution. However, they also point out some cons, such as fuzzy conclusions and unaddressed questions, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the effort and value of the work. They present criticisms constructively, using phrases like 'somewhat fuzzy' and 'unclear from the writing' rather than harsh language. The reviewer also offers suggestions for improvement and asks questions, which is a polite way of pointing out potential issues. The use of 'Pros' and 'Cons' sections helps organize the feedback in a professional manner."", ""The sentiment score is -60 because the reviewer expresses significant doubts and criticisms about the paper's contributions and methodology. They describe the work as 'relatively incremental' and point out several issues with both the dataset and the claimed improvements in dialogue generation. The reviewer questions the novelty and effectiveness of the authors' approach. However, the score is not extremely negative as the reviewer does acknowledge some potential value in the work.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and academic tone throughout. They use phrases like 'I have some doubts' and 'the authors do not satisfactorily address' rather than more harsh language. The reviewer also offers constructive suggestions and references to related work. However, the politeness is not extremely high as the criticism is quite direct and the tone is not particularly warm or encouraging.""]"
"['This is a paper about sentence embedding based on orthogonal decomposition of the spanned space by word embeddings. Via Gram-Schmidt process, the sequence of words in a sentence is regarded as a sequence of incoming vectors to be orthogonalized. Each word is then assigned 3 scores: novelty score, significance score, and uniqueness score. Eventually, the sentence embedding is achieved as weighted average of word embeddings based on those scores. The authors conduct extensive experiments to demonstrate the performance of the proposed embedding. I think the idea of the paper is novel and inspiring. But there are several issues and possible areas to improve:\n\n1. What if the length of the sentence is larger than the dimension of the word embedding? Some of the 3 scores will not be well-defined.\n\n2. Gram-Schmidt process is sensitive to the order of the incoming vectors. A well-defined sentence embedding algorithm should not. I suggest the authors to evaluate whether this is an issue. For example, if by simply removing a non-important stop word at the begging of the sentence and then the sentence embedding changes drastically, then it indicates that the embedding is problematic.\n\n3. I’m confused by the classification between training-free sentence embedding and unsupervised sentence embedding? Don’t both of them require training word2vec-type embedding?\n\n4. The definition of the three scores seems reasonable, but requires further evidence to justify. For example, by the definition of the scores, do we have any proof that the value of \\alpha indeed demonstrated the related importance level?', ""Paper overview: This paper proposes a new geometry-based method for sentence embedding from word embedding vectors, inspired by Arora et al (2017). The idea is to quantify the novelty,significance and corpus-wise uniqueness of each word. In order to do so, they analyze geometrically how the word vector of the target word relates to 1) the subspace created by the word-vectors in its context 2) its alignment with the meanings in its context (using SVD) 3) its presence in the all the corpus. For each of these aspects, they output a score or weight. The final sentence representation is a weighted average, using these scores, of the word vectors of the sentence.  \n\nRemarks and questions: \n     1) In table 1, Glove and word2vec are word representations, how is the sentence representation computed here? \n     2) The authors are not comparing to what is now considered the state of the art methods, such as Quick thoughts vectors (ICLR 2018, 'an efficient framework for learning sentence representations' by Logeswaran et al.), Transformer (Attention is all you need by Vaswani et al.) and ELMo (Deep contextualized word representations, by Peters et al.). \n\n\nPoints in favor:\n    1) Results: The method gives the best performance for non-training methods with an +2 point improvement on average, although it cannot beat training methods (see Table 3, for instance). \n   2) On the result tables, it should be reported also the std, not just the average, so the reader can evaluate if the difference between the methods is statistically significant.\n    3) Inference speed: the method is fast (see table 5) \n    4) stability of the results: The method is robust to slight changes in the hyperparameters such as the size of the window, number of principal components used, etc (see Fig 2)\n\n\nPoints against: \n     The methods presented in the paper are not novel. The main novelties are the geometrical analysis on the contribution of each word of the sentence to the sentence overall semantic meaning, and the definition of the scores (eqs 4,6,8) that allow to improve the weighted average sentence representation (eq 9), an idea already present in Arora et al.'s paper. \n\n\n Conclusion: \n     Although the geometric analysis of the paper is interesting, I dont think it is sufficient to justify a paper at ICLR, unless, after comparison with the other methods proposed previously, the proposed model is still competitive and the difference is statistically significant. "", 'The paper presented a new training-free way of generating sentence embedding. The proposed work is along the same motivation from Arora et al.,  2017. A systematic analysis has been done on a number of tasks to show the strong performance (close or higher than the specifically ""supervised"" strategies). \n\n- I suggest the author to re-ward the category terms of the existing methods. Un-supervised and training-free are confusing. Unsupervised and supervised should be all in a group of training-required methods. unsupervised in this paper is more task-agnostic but domain specific and supervised is to extract sentence emb that is prediction task specific. \n\n- The evaluation tasks are rich but not clearly stated. For instance, the supervised taske are only discussed at high-level. Not clear what each task is and how one should interpret the results from each experiments.  The way author presented it suggests the detail here were not important. It is also good to include discussion on how the baseline algorithms are tuned and/or trained on these tasks. Readers cannot reproduce the same results based on the current paper. \n\n- Notation and Math: \n--r-1 in (4) is not clear as \\mathbf{r} is not defined properly\n--based on sec 2.2., it is easy to motivate the novelty score from subspace projection rather than QR/GS; \n-- a_n and a_s are both functions of r_{-1} which is the perp. energy of the words w.r.t. its contexts. Is there a fundamental difference?\n-- Figure 1 is a little bit confusing. Not clear what is word and what is a sentence/corpus. \n-- in Eq(8), better not to use r as it confuses with the GS coeffs. \n-- 2.4.1 is a bit confusing, sentence embeddings c_1, \\ldot, c_N are introduced, but so far no sentence embedding has been formally introduced. Is this initialized from some heuristic? It is confusing in the sense that eq (9) c_s are defined by a_u, but a_u defined in eq (8) depends on sigma_d that relies on X^{c}, which is a funcion of all c_s\'s. \n-- there are several parameters for GEM, please add some discussion on how these are selected in each of the evaluated tasks. \n']","[50, -20, 50]","[75, 60, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the paper's novel and inspiring idea, which is a positive aspect. However, they also list several issues and areas for improvement, balancing out the overall sentiment. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh criticism. They use phrases like 'I think' and 'I suggest' which maintain a polite tone. The reviewer also acknowledges the positive aspects of the paper before presenting their concerns, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Points in favor'), they ultimately conclude that the paper's novelty is insufficient for ICLR publication without further improvements. The reviewer states, 'I dont think it is sufficient to justify a paper at ICLR,' which indicates a negative overall sentiment. However, the score is not deeply negative because the reviewer does recognize some merits of the work. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They offer constructive feedback, balance positive and negative points, and use neutral language like 'Remarks and questions' rather than harsh criticisms. The reviewer also provides specific suggestions for improvement, which is a polite way to offer critique."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novel approach and systematic analysis, showing strong performance. However, they also provide several suggestions for improvement, indicating a balanced view. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering suggestions with phrases like 'I suggest' and 'It is good to include,' rather than using harsh or demanding language. The reviewer also acknowledges the strengths of the paper before providing constructive criticism, which is a polite approach to peer review.""]"
"['The main idea of this paper is that a \'realistic\' way to attack GCNs is by adding fake nodes. The authors go on to show that this is not just a realistic way of doing it but it can done in a straightforward way (both attacks to minimize classification accuracy and GAN-like attacks to make fake nodes look just like real ones). \n\nThe idea is neat and the experiments suggests that it works, but what comes later in the paper is mostly rather straightforward so I doubt whether it is sufficient for ICLR. I write ""mostly"" because one crucial part is not straightforward but is on the contrary, incomprehensible to me.  In Eq (3) (and all later equations) , shouldn\'t X\' rather than X be inside the formula on the right? Otherwise it seems that the right hand side doesn\'t even depend on X\' (or X_{fake} ). \nBut if I plug in X\', then the dimensions for weight matrices  W^0 and W^1 (which actually are never properly introduced in the paper!) don\'t match any more. So what happens? To calculate J you really need some extra components in W0 and W1. Admittedly I am not an expert here, but I figure that with a bit more explanation I should have been able to understand this. Now it remains quite unclear...and I can\'t accept the paper like this.\n\nRelatedly, it is then also unclear what exactly happens in the experiments: do you *retrain* the network/weights or do you re-use the weights you already had learned for the \'clean\' graph? \n\nAll in all: \nPRO:\n- basic idea is neat \nCON:\n- development is partially straightforward, partially incomprehensible.\n\n(I might increase my score if you can explain how eq (3) and later really work, but the point that things remain rather straightforward remains). ', 'The authors propose a new adversarial technique to add “fake” nodes to fool a GCN-based classifier. The basic approach relies on a greedy heuristic to add edge/node features, and the authors also present a GAN-based approach, which allows the model to add “fake” nodes that are not easily distinguishable from regular nodes. The primary motivation behind the idea of adding “fake” is that it is unrealistic to change the features/edges of existing nodes. Experimental results show that adding a large number (20% in most cases) of fake nodes can significantly degrade accuracy of a GCN, and results show that the GAN-based approach is somewhat effective at making the “fake” nodes less distinguishable.  In terms of strengths, the GAN-based approach is well-motivated and it appears that the authors were thorough in their experiments on Cora/Citseer (e.g., with a number of ablation/sensitivity studies).\n\nHowever, while interesting, this paper has a number of areas where it could be substantially improved:\n\n1) With regards to the motivation: It is not clear what substantive technical novelty there is in the idea of “adding fake nodes”, compared to existing approaches that simply modify existing nodes in an adversarial way. Intuitively, the approach of Zugner et al can already handle this case of ""adding new nodes"". One just adds a set of nodes with random/null edges/features to the graph, treats this as their “attacker node” set and then runs Zugner et al\'s greedy algorithm. Some clarification on why this simple application of Zugner et al\'s approach does not work would be useful and/or empirical results using their method as a baseline would be useful. (Also, Zugner et al was published in KDD 2018, so the citation should be corrected). \n\n2) In Zugner et al, they derive approximations and algorithms that allow them to compute the score of adding/removing an edge in constant time. The greedy approach in this work appears quite expensive as every greedy update requires an expensive gradient computation. Some discussion of computational complexity would improve the paper. \n\n3) Results are only provided on two small datasets (presumably due to the large computational cost for the approach). These two very small datasets are not indicative of many real-world scenarios, and additional results on larger (and more diverse) datasets would greatly strengthen the paper. \n\n4) Adding 20% fake nodes seems like a prohibitively large number. Even 5% fake nodes is extremely large. It is unclear what real-world applications could admit such drastic numbers of fake nodes, and some comments on this would greatly strengthen the paper. \n\n5) The GAN method is interesting and well-motivated, but it is not clear if this method offers any utility beyond the “distribution matching” approach of Zugner et al (Section 4.1 of their paper). A comparison between these methods is necessary to justify the utility of the proposed GAN-greedy approach. \n', 'This paper presents an idea of adding fake nodes to attack a graph network model, by a GAN style trainning procedure.\n\nHowever I concern about the experimental parts, which are only evaluated on small settings. \n\nPlus, the notations are inconsistant, whereas the objective function in (3) has nothing to do with $X_{fake}$. I tend to believe that this should be a typo.\n\nThe greedy optimization should generally be highly costed, although it works well for learning sparse representation in previous literature, however, in the graph setting, I am not sure that this is a good fit for $O(|V|^2)$ variables. Perhaps the author need to argue why this is efficient, or to propose other methods.']","[-30, -20, -30]","[20, 50, 20]","[""The sentiment score is -30 because while the reviewer acknowledges the 'neat' basic idea, they express significant doubts about the paper's suitability for ICLR. They point out that parts of the paper are 'straightforward' and other parts are 'incomprehensible', which are strong negative critiques. The reviewer also states they 'can't accept the paper like this', indicating a largely negative sentiment despite some positive aspects. The politeness score is 20 because the reviewer uses generally polite language, acknowledging positive aspects and framing criticisms as personal confusion (e.g., 'incomprehensible to me') rather than direct attacks. They also offer a chance for improvement ('I might increase my score if...'). However, the politeness is not extremely high as the criticism is still quite direct."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they list several substantial areas for improvement. The review starts with positive comments about the thoroughness of experiments and the well-motivated GAN-based approach. However, the bulk of the review focuses on areas needing improvement, including questions about technical novelty, computational complexity, limited dataset usage, and concerns about the practicality of adding large numbers of fake nodes. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout. They acknowledge the paper's strengths before presenting criticisms, and phrase their concerns as suggestions for improvement rather than outright dismissals. The use of phrases like 'could be substantially improved' and 'would greatly strengthen the paper' maintain a respectful tone while clearly communicating the need for revisions."", ""The sentiment score is -30 because the review starts with a neutral description of the paper but then expresses concerns about the experimental parts and points out inconsistencies and potential issues. The overall tone is more negative than positive, but not extremely negative. The politeness score is 20 because the reviewer uses polite language such as 'I concern' and 'I tend to believe,' which softens the criticism. They also suggest improvements rather than outright dismissing the work. However, the language is not overly formal or excessively polite, maintaining a professional tone.""]"
"['The authors propose a method for image restoration, where the restored image is the MAP estimate. A pretrained GAN is utilized to approximate the prior distribution of the noise-free images. Then, the likelihood induces a constraint which is based on the degradation function. In particular, the method tries to find the latent point for which the GAN generates the image, which if gets degraded will match the given degraded image. Also, an optimization algorithm is presented that solves the proposed constrained optimization problem.\n\nI find the paper very well written and easy to follow. Also, the idea is pretty clean, and the derivations are simple and clear. Additionally, the Figures 2,3 are very intuitive and nicely explain the theory. However, I think that there are some weaknesses (see comments):\n\nComments: \n\n#1) I do not understand exactly what the ""general method"" means. Does it mean that you propose a method, where you can just change the F, such that to solve a different degradation problem? So you provide the general framework where somebody has to specify only the F?\n\n#2) Clearly, the efficiency of the method is highly based on the ability of the GAN to approximate well the prior distribution of the noise-free images.\n\n#3) There are several Equations that can be combined, such that to save enough white space in order to discuss further some actual technical details. For instance, Eq. 2,3 can be easily combined using the proportional symbol, Eq. 8,9,10,11 show actually the same thing.\n\n#4) I think that the function F has to be differentiable, and this should be mentioned in the text. Also, I believe that some actual (analytic) examples of F should be provided, at least  in the experiments. The same holds for the p(Omega). This parameter Omega is estimated individually for each degraded image?\n\n#5) Before Eq. 8 the matrix V is a function of z and should be presented as such in the equations.\n\n#6) I believe that it would be nice to include a magnified image of Fig. 3, where the gradient steps are shown. Also, my understanding is that the optimization goal is to find first a feasible solution, and then find the point that maximizes f. I think that this can be clarified in the text.\n\n#7) The optimization steps seem to be intuitive, however, there is not any actual proof of converge. Of course, the example in the Figure 3 is very nice and intuitive, but it is also rather simple. I would suggest, at least, to include some empirical evidences in the experiments that show convergence.\n\n#8) In the experiments I think that at least one example of F and p(Omega) should be presented. Also, what the numbers in Table 4 show? Which is the best value that can be achieved? These numbers correspond to several images, or to a unique image? \n#9) I think that MNIST is almost a toy experiment, since the crucial component of the proposed method is the prior modeling with the GAN. I believe that a more challenging experiment should be conducted e.g. using celebA dataset.\n\nMinor comments:\n\n#1) In the paragraph after Eq. 4 the equality p_r(x)=p_G(x) is very strong assumption. I would suggest to use the \\simeq symbol instead.\n\n#2) After Eq. 6 the ""nonnegative"" should be ""nonzero"".\n\n#3) Additional density estimation models can be used e.g. VAEs, GMM. Especially, I believe that the VAE will provide a way to approximate the prior easier than the GAN.\n\n#4) In Section 2 paragraph 2, the sentence ""However, they only ... and directly"" is not clear what means.\n\nIn general, I find both the proposed model and optimization algorithm interesting. Additionally, the idea is nicely presented in the paper. Most of my comments are improvements which can be easily included. The two things that make me more skeptical, is the convergence of the proposed algorithm and the experiments. The MNIST is a relatively simple experiment, and I would like to see how the method works in more challenging problems. Also, I think that additional methods to compute the image prior should be included in the experiments.', 'This paper proposed a general method for image restoration based on GAN. In particular, the latent variable z is optimized based on the MAP framework. And the results are obtained by G(z). This method looks reasonable to achieve good results. However, the idea is very related to Yeh et al.’s work which has already published but not mentioned at all. \n\nYeh, Raymond A., et al. ""Image Restoration with Deep Generative Models."" 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018.\n\nBoth the proposed method and Yeh et al.’s method optimize the latent variable z of the generator using MAP, although the loss functions are slightly different. In addition, the applications are very similar: image inpainting, denoising, super-resolution etc. Yeh et al.’s method should be the right baseline instead of the nearest neighbor algorithm. \n\nIn addition, the results seem very weak. There are tons of algorithms for image inpainting, denoising, and super-resolution, but the proposed method was not compared with them. The paper claims that only the nearest neighbor algorithm can handle different degradations. This is not true. For example, total variation regularization can do all these tasks. \n\nSome other comments: what are the parameters of the degradation in the applications? For example, in image inpainting, does the proposed method learn the mask as well? So it is blind inpainting? \n', 'This paper proposed a framework to incorporate GAN into MAP inference process for general image restoration. \n\nFirst, the motivation of the proposed framework is not convincing for me. That is, authors assumed that they have a degradation function F and all the inference process is just based on this known function. However, in real world scenarios, it is actually challenging to obtain exact degradation information. Thus we may only apply the proposed model on a few tasks with exactly known F.\n\nSecond, due to the norm based constraints, authors actually need to optimize a highly nonconvex optimization problem. Moreover, due to the trace based loss function, the computational cost will also be very high. Please notice that standard MAP based methods only need to solve a simple convex optimization model (e.g., TV) and these methods can also be applied for different restoration tasks. Actually, we only need to specify particular fidelity terms for different tasks. Moreover, very recent works have also successfully incorporate both generative and discriminative network architectures (e.g., [1,2]) into the optimization process. Therefore, I cannot find any advantage in the proposed method, compared with these existing MAP based image restoration approaches.\n\nFinally, the experimental part is also too weak to evaluate the proposed method. As I have mentioned above, actually a lot of methods have been developed to address general image restoration tasks. Some works actually also incorporate generative and/or discriminative networks into MAP inference process for these tasks. Thus I believe authors must compare their method with these state-of-the-art approaches. Moreover, authors should conduct experiments on state-of-the-art benchmarks, including natural images. This is because the digitals images in MNIST do not have rich texture and detail structures, thus are not very challenging for standard image restoration methods. \n\n\n[1]. Kai Zhang, Wangmeng Zuo, Shuhang Gu, Lei Zhang: Learning Deep CNN Denoiser Prior for Image Restoration. CVPR 2017: 2808-2817\n[2]. Jiawei Zhang, Jin-shan Pan, Wei-Sheng Lai, Rynson W. H. Lau, Ming-Hsuan Yang: Learning Fully Convolutional Networks for Iterative Non-blind Deconvolution. CVPR 2017: 6969-6977\n']","[50, -50, -70]","[80, 20, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'very well written and easy to follow' with 'clean' ideas and 'simple and clear' derivations. They also compliment the intuitive figures. However, they mention 'some weaknesses' and provide a list of comments and suggestions for improvement, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I think that...', 'I would suggest...'), and balances negative points with positive ones. They also use polite phrases like 'I find' and 'I believe' when expressing opinions. The review concludes on a positive note, stating that most comments are 'improvements which can be easily included', further demonstrating a courteous approach."", ""The sentiment score is -50 because the reviewer acknowledges the reasonableness of the method but expresses significant concerns about the originality of the idea and the weakness of the results. The reviewer points out that a similar method has already been published and not cited, and that the paper's comparisons and claims are inadequate. This indicates a predominantly negative sentiment, though not entirely dismissive. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism or personal attacks. The reviewer presents concerns as factual observations (e.g., 'This is not true') rather than using more confrontational language. However, the tone is more matter-of-fact than overtly polite, hence a slightly positive but not high politeness score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses skepticism about the motivation, questions the advantages of the proposed method, and criticizes the experimental part as 'too weak'. There are no positive comments about the paper's contributions or merits. The politeness score is 20 because while the reviewer's tone is critical, they maintain a professional and academic tone throughout. They use phrases like 'not convincing for me' and 'I cannot find any advantage' rather than more harsh language. The reviewer also provides constructive feedback and suggestions for improvement, which adds to the politeness score. However, the overall critical nature of the comments prevents a higher politeness score.""]"
"['The paper investigates the use of multi-objective optimization techniques in GAN-setups where there are multiple discriminators. Using multiple discriminators was proposed in Durugkar et al, Arora et al, Neyshabur et al and others. The twist here is to focus on the Pareto front and to import multiple gradient descent and hypervolume-maximization based methods into GANs. \n\nThe results are decent. The authors find that optimizing with respect to multiple discriminators increases diversity of samples for a computational cost. However, just scaling up (and carefully optimizing), can yield extremely impressive samples, https://arxiv.org/abs/1809.11096. It is unclear how the tradeoffs in optimizing against multiple discriminators stack-up against bigger GANs. \n\nFrom my perspective, the paper is interesting because it introduces new methods into GANs from another community. However, the results themselves are not sufficient for publication. \n', 'This paper studies the problem of training of Generative Adversarial Networks employing a set of discriminators, as opposed to the traditional game involving one generator against a single model. Specifically, this paper claims two contributions:\n1.\tWe offer a new perspective on multiple-discriminator GAN training by framing it in the context of multi-objective optimization, and draw similarities between previous research in GANs variations and MGD, commonly employed as a general solver for multi-objective optimization.\n2.\tWe propose a new method for training multiple-discriminator GANs: Hypervolume maximization, which weighs the gradient contributions of each discriminator by its loss.\n\nOverall, the proposed method is empirical and the authors show its performance by experiments. \n\nFirst, I want to discuss the significance of this work (or this kind of work). As surveyed in the paper, the idea of training of Generative Adversarial Networks employing a set of discriminators has been explored by several previous work, and showed some performance improvement. However, this idea (methods along this line) is not popular in GAN applications, like image-to-image translation. I guess that the reason may be that: the significant computational cost (both in FLOPS and memory consumption) increase due to multiple discriminators destroys the benefit from the small performance improvement. Maybe I’m wrong. In Appendix C Figure 10, the authors compares the wall-lock time between DCGAN, WGAN-GP and multiple-discriminator, and claims that the proposed approach is cheaper than WGAN-GP. However, WGAN-GP is more expensive due to its loss function involves gradients, while the proposed method does not. If directly compared with DCGAN, we can see an obvious increase in wall-clock time (FLOPS). In addition, the additional memory consumption is hidden there, which is a bigger problem in practice when the discriminators are large. SN-GAN have roughly the same computational cost and memory consumption of DC-GAN, but inception and FID are much higher. From my perspective, a fair comparison is under roughly the same FLOPS and memory consumption. \n\nThe paper is well-written. The method is well-motivated by the multi-objective optimization perspective. Although the presentation of the Hypervolume maximization method (Section 3.2) is not clear, the resulting loss function (Equation 10) is simple, and shares the same form with other previous methods. The hyperparameter \\eta is problematic in the new formulation. The authors propose the Nadir Point Adaption to set this parameter. \n\nThe authors conduct extensive experiments to compare different methods. The authors emphasize that the performance is improved with more discriminators, but it’s good to contain comparison of the computational cost (FLOPS and memory consumption) at the same time. There are some small questions for the experiments. The reported FID is computed from a pretrained classifier that is specific to the dataset, instead of the commonly used Inception model. I recommend the authors also measure the FID with the Inception model, so that we have a direct comparison with existing reported scores.\n\nOverall, I found that this work is empirical, and I’m not convinced by its experiments about the advantage of multiple-discriminator training, due to lacking of fair computational cost comparison with single-discriminator training. ', 'Clarity:\nThe work is a clear introduction/overview of this area of research. The reviewer enjoyed the connections to Multiple-Gradient Descent and clear distinctions/contrasts with previous approaches to weighting the outputs of multiple discriminators. All in all, the paper is quite clear in what its contributions are and how it differs from previous approaches. The details and motivations of the Hypervolume Maximization  (HVM) method (especially as it relates to and interacts with the slack method of picking the nadir point) were a bit harder to follow intuitively given the standalone information in the paper.\n\nOriginality:\nAdapts a technique to approximate MGD called HVM (Miranda 2016) and applies it to multi-discriminator training in GANs. As far as the reviewer is aware, this is a novel application of HVM to this task and well motivated under the MGD interpretation of the problem.\n\nSignificance:\nUnclear. This work in isolation appears to present an improvement over prior work in this sub-field, but it is not obvious that the findings in these experiments will continue to be robust in more competitive settings. For instance, the worst performing model on CIFAR10, WGAN-GP (according to the experiments run) WGAN-GP also holds near SOTA Inception scores on CIFAR10 when appropriately tuned. Without any experimental results extending beyond toy datasets like MNIST and CIFAR10 the reviewer is not confident whether fundamental issues with GAN training are being addressed or just artifacts of small scale setups. Closely related previous work (Neyshabur 2017) scaled to 128x128 resolution on a much more difficult dataset - Imagenet Dogs but the authors did not compare in this case.\n\nQuality:\nSome concerns about details of experiments (see cons list and significance section for further discussion).\n\nPros:\n+ The work provides a clear overview of previous work on approaches using multiple discriminators.\n+ The connections of this line of work to MGD and the re-interpretation of various other approaches in this framework is valuable.\n+ The author provides direct comparisons to similar methods, which increases confidence in the results.\n+ On the experiments run, the HVM method appears to be an improvement over the two previous approaches of softmax weighting and straightforward averaging for multiple discriminators.\n\n\nCons:\n- Performance of GANs is highly dependent on both model size and compute expended for a given experiment (see Miyato 2018 for model size and training iterations and Brock 2018 for batch size). Training multiple discriminators (in this paper up to 24) significantly increases compute cost and effective model size. No baselines controlling for the effects of larger models and batch sizes are done.\n- The paper lacks experiments beyond toy-ish tasks like MNIST and CIFAR10 and does not do a good job comparing to the broader established literature and contextualizing its results on certain tasks such as CIFAR10 (reporting ratios to a baseline instead of absolute values, for instance). The absolute inception score of the baseline DCGAN needs to be reported to allow for this. Is the Inception Score of the authors DCGAN implementation similar to the 6 to 6.5 reported in the literature?\n- Figure 3 is slightly strange in that the x axis is time to best result result instead of just overall wallclock time. Without additional information I can not determine whether it is admissible. Do all models achieve their best FID scores at similar points in training? Why is this not just a visualization of FID score as a function of wallclock time? A method which has lower variance or continues to make progress for longer than methods which begin to diverge would be unfairly represented by the current Figure.\n\nAdditional comments:\n\nIn section 3.1 Eq 5 appears to be wrong. The loss of the discriminator is presented in a form to be minimized so exponentiating the negative loss in the softmax weighting term as presented will do the opposite of what is desired and assign lower weight to higher loss discriminators. \n\nIn Fig 6 FID scores computed on a set of 10K samples are shown. The authors appear to draw the line for the FID score of real data at 0. But since it is being estimated with only 10K samples there will be sampling error resulting in non-zero FID score. The authors should update this figure to show the box-plot for FID scores computed on random draws of 10K real samples. I have only worked with FID on Imagenet where FID scores for random batches of 10K samples are much higher than 0. I admit there is some chance the value is extremely low on CIFAR10 to make this point irrelevant, however.\n']","[-30, -20, 20]","[50, 60, 60]","[""The sentiment score is -30 because while the reviewer acknowledges the paper as 'interesting' for introducing new methods, they ultimately conclude that 'the results themselves are not sufficient for publication'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging the paper's merits ('The results are decent', 'the paper is interesting') before offering criticism. They provide constructive feedback and context for their assessment without using harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'well-written', 'well-motivated'), they express significant concerns about the work's significance and experimental comparisons. The reviewer is not fully convinced by the paper's contributions, stating 'I'm not convinced by its experiments about the advantage of multiple-discriminator training'. However, the score is not deeply negative as the reviewer does recognize some merits in the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I want to discuss', 'Maybe I'm wrong', and 'I recommend', which show consideration for the authors' perspective. The reviewer also balances criticism with positive comments, acknowledging the paper's strengths alongside its weaknesses. However, the score is not extremely high as the review is still direct in its criticisms and doesn't use overly deferential language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several positive aspects of the paper, such as its clarity, originality, and improvements over previous approaches. However, they also express significant concerns about the experimental design and the paper's overall significance, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout, balancing praise with constructive criticism. They use phrases like 'The reviewer enjoyed...' and 'The work provides a clear overview...', while also tactfully expressing concerns without harsh language. The reviewer offers detailed feedback and suggestions for improvement, which is a polite way to help the authors enhance their work.""]"
"[""In this paper the authors propose an extension to successor features (SF). Akin to UVFAs, they condition on some goal state by concatenating to the current state after some shared preprocessing. The authors claim three contributions: 1) introducing the USF, 2) proposing an appropriate deep learning architecture for it, and 3) showing experimentally that USFs improve transfer both within a goal set and to novel goals.\n\nClaims 1) and 2) don't seem particularly noteworthy. Extending SF to be goal-conditioned is very straightforward, doesn't leverage anything unique to the SF formalism (e.g. the reward weights w already encode a goal in some sense), and doesn't attempt to extend its theoretical grounding. The architecture is likewise unsurprising, and the lack of ablations or alternatives make it seem rather unmotivated.\n\nThe usage of a Q-learning loss instead of a reward-prediction loss for updating phi is mentioned without citation. This seems quite novel, and could be a significant contribution if its advantage was demonstrated experimentally.\n\nThe experiments appear to show a significant advantage for USFs. For the training-goal-set advantage, it would be useful to know the architecture of multi-goal DQN. One hypothesis is that the extra weight-sharing is what is giving USFs an edge, and this should be ruled out. It is briefly mentioned that UVFAs weren't considered due to their stated instability, but its unclear how they differ from the multi-goal DQN.\n\nThe novel-goal results are impressive at first glance, but there is a glaring omission. Hindsight experience replay (HER) is mentioned but not evaluated, and would very likely trivialise the train/test goal-set distinction (unless the test goals were never previously visited). As these results are the primary contribution of this paper, this must be addressed prior to publication acceptance.\n\nEdit: The addition of HER experiments push this up a bit (5-->6). I'm still concerned about how significant the contribution is (as it is a straightforward extension to SFs), but the empirical results are now quite strong."", 'I like the idea of Universal Successor Features, it seems a bit incremental but I think it is worth exploring. There is some missing aspects and better comparison that can be made for the paper. I believe for the final camera ready these comparisons should be added. Specifically the related work section seems to not be in a desired depth. \n\nFrom experiments perspective, there is sufficient experiments that can demonstrate the value of the model. It is a simple model but an elegant application and correctly used for the purpose of the tasks in the paper. I have the following questions which their answers may be good additions to the paper:\n\n1. Have you tried analyzing what successor features and goal-specific features learn? For example, one point of addressing this is: what does the agent seem to avoid or do, under your framework (but not normal DQN). \n2. The tasks in this paper seemed a bit simplistic, how does the model work on more complex applications (games)? It is hard to establish proper comparison, even though your claims are sufficiently supported. \n3. What is your explanation of cases where blue is under green? One could assume they would meet eventually like top-left in Figure 3. \n\nI strongly suggest a rewrite of the related works section and a redo of the graphics. Using PDF may help with odd aspect ratio for text (Fig 4).  ', '\nSummary: This paper proposes a generalisation of the SFs framework to a goal conditioning representation that could, in principle, generalise over a collection of goals at test time. This is akin to universal value functions [1] (and more generally GVFs). Although I like the idea  and it seems a very interesting direction for generalisation to new goals, I do think the execution, the particular instantiation and (lack of) in-depth evaluation with (at least some of the) existing methods in literature -- including UVFAs [1] and the different ways SFs have been used for generalisation [2,3,4] -- is unfortunately letting it down.\n\n\nClarity: Reasonably well-written, easy to follow. A couple of things in the experimental section can be improved:\n- It’s not totally clear to me what the their baseline Multi-goal DQN is. Does it have the same architecture as Figure 1, but just using (2).\n- In the plots, the only difference between DQN and DQN+USF is that the second as the additional loss L_{\\psi} ? Or is there any other difference? \n\n\nOriginality and Significance: \nI’m a bit split here: I like in principle the idea, but I think this instantiation is (fairly) incremental with respect to the current literature. Even the claimed contributions are a bit thin. Suitability of SFs to any TD-based learning, comes from SRs/SFs satisfying a Bellman eq. which was point out, explored and paired with control algorithms before [2,4]. Also, the particular way of learning the features \\phi, without going through the rewards, was already proposed and explored in [3]. That might be a missing reference. \n\nThe experiments seems to show slight improvements with respect to a baseline (Multi-DQN). It is not clear to me exactly what this is or if it would dominated even something vanilla UVFAs. I think this is a missing and somewhat mandatory comparison. I know the authors noted that is was because ‘UVFAs are prone to instabilities and may require further prior knowledge’, but I think that refers only to the two-stage (factorisation) procedure proposed in the original paper, not the common adoption in the literature. At the end of the day, the proposed architecture in Fig. 1 is a kind of UVFA, just with a bit more structure, so it would be surprising to me if UVFAs would actually fail in these environments. But if that’s the case, that’s a very interesting data point that the additional structure actually helps considerably beyond the incremental advantage exemplified here. \n\n\nOther comments/questions:\n\n1) Clarification on the training procedure. The value function $Q(s,a,g)$  are training via eq. (3) with the i) actual reward (coming from the environment) or ii) the ‘fictitious’ reward coming from r(s,a,s’|g) = \\phi(s,a,s’)^T w(g)? Note that these are very different and only one ensures compatibility between the rewards and the value functions in learning.\nThe SFs will give you the value function for the reward r(s,a,s’|g) = \\phi(s,a,s’)^T w(g) and if this is not align with the real reward, the corresponding value function obtained via SFs will not be the value function optimising the real reward. As far as I can see there’s not criteria that forces this to be the case.\n\n2) Comparison with SF transfer literature. Although discussed in the related work section, there is no quantitative comparison to the way SFs were shown to transfer knowledge[2,4], via evaluation and (generalised) policy improvement. Because these ways of generalisation are very different, it’s not clear go they would stack against each other, or in which scenarios one would be more appropriate than the other.\nTo give a more concrete example: The training procedure in 3.1 makes sure that there’s fairly good coverage of the whole state-space by sampling goals conditioned on the room. Now if one would train SFs on these train tasks only (even independently), we would have policies that would know how to go to any of the rooms. And for the test tasks we would have the evaluation of these policies to the collection of goals. Which means that applying the methodology of transfer in [2,4] we would zero-shot get policies that reach any of the states encountered in the path of the 12 goals used in the train phase. And even if the test goals are not part of this collection, it stands to reason that a policy that can already go to the goal’s room and be easily adaptable to reaching the test goal -- aka the evaluation the policy that already reached that room is a good starting point for the improvement step [4].\n\nNote: I am willing to reconsider when/if the above have been reconciled/resolved.\n\nReferences:\n[1] Schaul, T., Horgan, D., Gregor, K. and Silver, D., 2015, June. Universal value function approximators. In International Conference on Machine Learning (pp. 1312-1320).\n\n[2] Andre Barreto, Will Dabney, Remi Munos, Jonathan J Hunt, Tom Schaul, Hado P van Hasselt, and ´ David Silver. Successor features for transfer in reinforcement learning. In Advances in Neural Information Processing Systems, pp. 4055–4065, 2017.\n\n[3] Machado, M.C., Rosenbaum, C., Guo, X., Liu, M., Tesauro, G. and Campbell, M., 2018. Eigenoption Discovery through the Deep Successor Representation, International Conference on Learning Representations, 2018.\n\n[4] Barreto, A., Borsa, D., Quan, J., Schaul, T., Silver, D., Hessel, M., Mankowitz, D., Zidek, A. and Munos, R., 2018, July. Transfer in deep reinforcement learning using successor features and generalised policy improvement. In International Conference on Machine Learning (pp. 510-519).']","[-20, 50, -30]","[20, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express significant concerns about the novelty and significance of the main contributions. The reviewer points out that the first two claimed contributions are not particularly noteworthy, and raises issues with the experimental results, especially the omission of comparison with Hindsight Experience Replay. However, the score is not deeply negative as the reviewer does note some positive aspects, like the 'impressive at first glance' novel-goal results, and the edit indicates some improvement after additional experiments were added. The politeness score is slightly positive (20) because the reviewer maintains a professional and objective tone throughout, avoiding harsh language. They offer constructive criticism and suggestions for improvement rather than outright dismissal. The use of phrases like 'it would be useful to know' and 'this must be addressed' are direct but not impolite. The overall tone is more matter-of-fact than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the idea and finds it worth exploring, despite noting it's somewhat incremental. They also mention sufficient experiments demonstrating the model's value. However, they point out missing aspects and suggest improvements, balancing the positive aspects. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I believe for the final camera ready these comparisons should be added'), and offers suggestions rather than demands. The use of phrases like 'I like the idea' and 'I strongly suggest' maintain a collegial tone. The reviewer also asks questions to prompt improvements rather than making blunt criticisms."", ""The sentiment score is -30 because while the reviewer acknowledges liking the idea in principle, they express significant concerns about the paper's execution, lack of in-depth evaluation, and incremental nature compared to existing literature. The overall tone is more negative than positive, but not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. They use phrases like 'I like the idea' and 'I'm willing to reconsider,' which maintain a polite tone even while expressing concerns. The reviewer also provides detailed feedback and suggestions for improvement, which is a courteous approach in academic peer review.""]"
"['UPDATE:\nThanks for your response. As you mentioned, methods like [1] and [2] do perform open-ended recombination. Note that these methods perform not only texture transfer but also color transfer, while the proposed method seems to perform mostly only color transfer. As shown in Figure 6, essentially what the method does is transfer the color of the style image to the content image, sometimes with a little tweak, making the image distorted. One could say that in terms of image style transfer, the proposed method actually underperforms [1] and [2]. \n\nHence I agree with R2 that comparison is still necessary for the submission to be more convincing and complete.\n\n------------------------------\n\nThis paper proposed to use a mechanism of leakage filtering to separate styles and content in the VAE encoding, and consequently enable open-ended content-style recombination. Essentially the model tries to maximize the similarity between images in S^+ and minimize the similarity between those in S^-.\n\nI have several questions:\n\nOne concern that I have is the relationship/difference between this work and previous work on style transfer, especially universal/zero-shot style transfer as in [1,2]. In the introduction and related work sections, the authors argue that most previous work assumes that content classes in testing are the same as those in training, and that they are not general purpose. Note that various works on style transfer already address this issue, for example in [1, 2]. For those models, content is represented by high-level feature maps in neural networks, and style is represented by the Gram matrix of the feature maps. The trained model is actually universal (invariant to content and styles). Actually these methods use even less supervision than STOC since they do not require labels (e.g., digit labels in MNIST).\n\nThis brings me to my second concern on proper baselines. Given the fact that previous universal/zero-shot style transfer models focus on similar tasks, it seems necessary to compare STOC to them and see what the advantages of STOC is. Similar experiments can be conducted for the data augmentation tasks.\n\nIn Sec. 4, the authors mentioned that U-Net skip connection is used. Does it affect the effectiveness of the content/style separation, since the LF objective function is mostly based on the encoding z, which is supposed ‘skipped’ in STOC. Will this lead to additional information leakage?\n\nIt is not clear how the last term of L_{LF} is computed. Could you provide more details?\n\nThe organization and layout of figures could be improved. The title/number for the first section is missing.\n\nMissing references:\n\n[1] Universal style transfer via feature transforms, 2017\n[2] ZM-Net: Real-time zero-shot image manipulation network, 2017\n[3] Structured GAN, 2017', 'SUMMARY\nThe paper considers several methods for building generative models that disentangle image content (category label) and style (within-category variation). Experiments on MNIST, Omniglot, and VGG-Faces demonstrate that the proposed methods can learn to generate images combining the style of one image and the content of another. The proposed method is also used as a form of learned data augmentation, where it improves one-shot and low-shot learning on Omniglot.\n\nPros:\n- The paper is well-written and easy to follow\n- The proposed methods CC, CE, PM, and LF are all simple and intuitive\n- Improving low-shot learning via generative models is an interesting and important direction\n\nCons:\n- No comparison to prior work on generation results\n- Limited discussion comparing the proposed methods to other published alternatives\n- No ablations on Omniglot or VGG-Faces generation\n- Low-shot results are not very convincing\n\nCOMPARISON WITH PRIOR WORK\nThere have been many methods that propose various forms of conditional image generation in generative models, such as conditional VAEs in [Sohn et al, 2015]; there have also been previous methods such as [Siddharth et al, 2017] which disentangle style and content using the same sort of supervision as in this paper. Given the extensive prior work on generative models I was a bit surprised to see no comparisons of images generated with the proposed method against those generated by previously proposed methods. Without such comparisons it is difficult to judge the significance of the qualitative results in Figures 3, 5, and 6. In Figure 3 I also find it difficult to tell whether there are any substantial differences between the four proposed methods.\n\nThe proposed predictiability minimization is very related to some recent approaches for domain transfer such as [Tzeng et al, 2017]; I would have liked to see a more detailed discussion of how the proposed methods relate to others.\n\nOMNIGLOT / VGG-FACES ABLATIONS\nThe final model includes several components - the KL divergence term from the VAE, two terms from LF, and a WGAN-GP adversarial loss. How much do each of these terms contribute the quality of the generated results?\n\nLOW-SHOT RESULTS\nI appreciate low-shot learning as a testbed for this sort of disentangled image generation, but unfortunately the experimental results are not very convincing. For one-shot performance on Omniglot, the baseline Histogram Embedding methods achieves 0.974 accuracy which improves to 0.975 using STOC. Is such a small improvement significant, or can it be explained due to variance in other factors (random initializations, hyperparameters, etc)?\n\nFor low-shot learning on Omniglot, the proposed method is outperformed by [Antoniou et al, 2017] at all values of k. More importantly, I’m concerned that the comparison between the two methods is unfair due to the use of different dataset splits, as demonstrated by the drastically different baseline accuracies. Although it’s true that the proposed method achieves a proportionally larger improvement over the baseline compared with [Antoniou et al, 2017], the differences in experimental setup may be too large to draw a conclusion one way or the other about which method is better.\n\nOVERALL\nAlthough the paper is well-written and presents several intuitive methods for content/style decomposition with generative models, it’s hard to tell whether the results are significant due to incomplete comparison with prior work. On the generation side I would like to see a comparison especially with [Siddharth et al, 2017]. For low shot learning I think that the proposed method shows some promise, but it is difficult to draw hard conclusions from the experiments. For these reasons I lean slightly toward rejection.\n\nMISSING REFERENCES\nSiddharth et al, “Learning Disentangled Representations with Semi-Supervised Deep Generative Models”, NIPS 2017\n\nSohn, Lee, and Yan, “Learning structured output representation using deep conditional generative models”, NIPS 2015\n\nTzeng, Hoffman, Darrell, and Saenko, “Adversarial Discriminative Domain Adaptation”, CVPR 2017\n', 'In this paper, the authors study an interesting problem called open-ended content style recombination, i.e., recombining the style of one image with the content of another image. In particular, the authors propose a VAE (variational autoencoder) based method (i.e., Style Transfer onto Open-Ended Content, STOC), which is optimized over a VAE reconstruction loss and/or a leakage filtering (LF) loss. More specifically, there are four variants of STOC, including CC (content classifier), CE (content encoding), PM (predictability minimization, Section 2.1) and LF (leakage filtering, Section 2.2). The main advantage of STOC is its ability to handle novel content from open domains. Experimental results on image synthesis and data set augmentation show the effectiveness of the proposed method in comparison with the state-of-the-art methods. The authors also study the comparative performance of four variants, i.e., CCF, CE, PM and LF.\n\nOverall, the paper is well presented.\n\nSome comments/suggestions:\n\n(i) The authors are suggested to include an analysis of the time complexity of the proposed method (including the four variants).\n\n(ii) The authors are suggested to include more results with different configurations such as that in Table 1 in order to make the results more convincing.\n']","[-30, -20, 70]","[60, 60, 80]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper, they express several significant concerns and criticisms. The reviewer points out that the proposed method may underperform compared to existing methods and agrees with another reviewer that more comparisons are necessary. This indicates a generally negative sentiment, though not extremely so.\n\nThe politeness score is 60 because the reviewer uses respectful and professional language throughout. They phrase their criticisms as questions or concerns rather than direct attacks, and use polite phrases like 'Could you provide more details?' However, the tone is not overly deferential or excessively polite, maintaining a neutral professional tone overall.\n\nThe reasoning behind these scores is based on the content and phrasing of the review. The reviewer raises multiple substantive concerns about the paper's methodology and comparisons, indicating a negative sentiment. However, they also acknowledge some positive aspects and frame their criticisms constructively. The language used is consistently polite and professional, avoiding harsh or rude phrasing, but also not going out of its way to be excessively courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-written', 'simple and intuitive methods', 'interesting direction'), they express several significant concerns and ultimately lean towards rejection. The cons outweigh the pros, and phrases like 'not very convincing' and 'difficult to draw hard conclusions' indicate a generally negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciate', 'I would have liked to see', and 'I'm concerned that' to express criticisms politely. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite approach. However, the score is not higher because the review is still direct in its criticisms and doesn't use overly deferential language."", ""The sentiment score is 70 (positive) because the reviewer states that the paper is 'well presented' and describes the authors' work as 'interesting'. They also highlight the 'main advantage' of the proposed method and mention that experimental results show its effectiveness. The lack of major criticisms and the overall positive tone suggest a favorable view. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, such as 'the authors are suggested to' when providing recommendations. They also acknowledge the paper's strengths before offering suggestions for improvement. The reviewer maintains a professional and constructive tone without any harsh or rude comments.""]"
"['This paper discusses conditions under which  the convergence of training models with low-precision weights do not rely on model dimension. Extensions to two kinds of non-linear quantization methods are also provided. The dimension-free bound of the this paper is achieved through a tighter bound on the variance of the quantized gradients.  Experiments are performed on synthetic sparse data and small-scale image classification dataset MNIST.\n\nThe paper is generally well-written and structure clearly. However, the bound for linear quantization is not fundamentally superior than previous bounds as the ""dimension-free"" bound in this paper is achieved by replacing the bound in other papers using l2 norm with l1 norm. Note that l1 norm is related to the l2 norm as: \\|v\\|_1 <= \\sqrt{d}\\|v\\|_2, the bound can still be dependent on  dimension, thus the title may be misleading. Moreover, the assumptions  1 and 2 are much stronger than previous works, making the universality of the theory limited. The analysis on non-linear quantization is interesting, which can really theoretically improve the bound. It would be nice to see some more empirical results on substantial networks and  larger datasets which can better illustrate the efficacy of the proposed non-linear quantization.\n\nSome minor issues:\n1. What is HALP in the second contribution before Section 2?\n2. What is LP-SVRG in Theorem 1?\n3. What is \\tilde{w} in Theorem 2?', 'The paper considers the problem of low precision stochastic gradient descent. Specifically, they study updates of the form x_{t + 1} = Q (x_t - alpha * g_t), where g_t is a stochastic gradient, and Q is a quantization function. The goal is to produce quantization functions that simultaneously increase the convergence rate as little as possible, while also requiring few bits to represent. This is motivated by the desire to perform SGD on low precision machines.\n\nThe paper shows that under a set of somewhat nonstandard assumptions, previously studied quantization functions as well as other low precision training algorithms are able to match the performance of non-quantized SGD, specifically, losing no additional dimension factors. Previous papers, to the best of my knowledge, did not prove such bounds, except under strong sparsity conditions on the gradients. I did not check their proofs line-by-line however they seem correct at a high level.\n\nI think the main discussion about the paper should be about the assumptions made in the analysis.  As the authors point out, besides the standard smoothness and variance conditions on the functions, some additional assumptions about the function must be made for such dimension independent bounds to hold. Therefore I believe the main contribution of this paper is to identify a set of conditions under which these sorts of bounds can be proven. \n\nSpecifically, I wish to highlight Assumption 2, namely, that the ell_1 smoothness of the gradients can be controlled by the ell_2 difference between the points, and Assumption 4, which states that each individual function (not just the overall average), has gradients with bounded ell_2 and ell_1 norm at the optimal point. I believe that Assumption 2 is a natural condition to consider, although it does already pose some limitations on the applicability of the analysis. I am less sold on Assumption 4; it is unclear how natural this bound is, or how necessary it is to the analysis. \n\nThe main pros of these assumptions are that they are quite natural conditions from a theoretical perspective (at least, Assumption 2 is). For instance, as the authors point out, this gives very good results for sparse updates. Given these assumptions, I don’t think it’s surprising that such bounds can be proven, although it appears somewhat nontrivial.  The main downside is that these assumptions are somewhat limiting, and don’t seem to be able to explain why quantization works well for neural network training. If I understand Figure 4b correctly, the bound is quite loose for even logistic regression on MNIST. However, despite this, I think formalizing these assumptions is a solid contribution.\n\nThe paper is generally well-written (at least the first 8 pages) but the supplementary material has various minor issues.\n\nSmaller comments / questions:\n\n- While I understand it is somewhat standard in optimization, I find the term “dimension-independent“ here somewhat misleading, as in many cases in practice (for instance, vanilla SGD on deep nets), the parameters L and kappa (not to mention L_1 and kappa_1) will grow with the dimension.\n\n- Do these assumptions hold with good constants for training neural networks? I would be somewhat surprised if they did.\n\n- Can one get dimension independent bounds for quantized gradients under these assumptions?\n\n- The proofs after page 22 are all italicized.\n\n- The brackets around expectations are too small in comparison to the rest of the expressions.', 'This paper provides an in-depth study of the quantization error in low-precision training and gives consequent bounds on the low-precision SGD (LP-SGD) algorithm for convex problems under various generic quantization schemes. \n\n[pros]\nThis paper provides a lot of novel insights in low-precision training, for example, a convergence bound in terms of the L1 gradient Lipschitzness can potentially be better than its L2 counterpart (which is experimentally verified on specially designed problems). \n\nI also liked the discussions about non-linear quantization, how they can give a convergence bound, and even how one could optimally choose the quantization parameters, or the number of {exponent, significance} bits in floating-point style quantization, in order to minimize the convergence bound.\n\nThe restriction to convex problems is fine for me, because otherwise essentially there is not a lot interesting things to say (for quantized problems it does not make sense to talk about “stationary points” as points are isolated.)\n\nThis paper is very well-written and I enjoyed reading it. The authors are very precise and unpretentious about their contributions and have insightful discussions throughout the entire paper.\n\n[cons]\nMy main concern is that of the significance: while it is certainly of interest to minimize the quantization error with a given number of bits as the budget (and that’s very important for the deployment side), it is unclear if such a *loss-unaware* theory really helps explain the success of low-precision training in practice.\n\nAn alternative belief is that the success comes in a *loss-aware* fashion, that is, efficient feature extraction and supervised learning in general can be achieved by low-precision models, but the good quantization scheme comes in a way that depends on the particular problem which varies case by case. Admittedly, this is a more vague statement which may be harder to analyze or empirically study, but it sounds to me more reasonable for explaining successful low-precision training than the fact that we have certain tight bounds for quantized convex optimization. \n\n[a technical question]\nIn the discussions following Theorem 2, the authors claim that the quantization parameters can be optimized to push the dependence on \\sigma_1 into a log term -- this sounds a bit magical to me, because there is the assumption that \\zeta < 1/\\kappa, which restricts setting \\zeta to be too large (and thus restricts the “acceleration” of strides from being too large) . I imagine the optimal bound only holds when the optimal choice of \\zeta is indeed blow 1/\\kappa?']","[-20, 60, 60]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'generally well-written and structure clearly', they express several criticisms. They point out that the bound is not 'fundamentally superior', the title may be 'misleading', and the assumptions are 'much stronger than previous works'. The reviewer also suggests more empirical results would be beneficial. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses polite and professional language throughout. They begin with positive aspects, use phrases like 'It would be nice to see', and frame criticisms as suggestions or observations rather than direct attacks. The reviewer also ends with 'minor issues', which is a constructive way to provide feedback. However, the score is not extremely high as the review is still direct in its criticisms."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions and solid theoretical work, despite some reservations about assumptions. They use phrases like 'solid contribution' and 'well-written', indicating overall positive sentiment. However, they also raise concerns about the applicability of the assumptions, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'I think', 'I believe', and 'I wish to highlight', which maintain a polite and considerate tone. The reviewer also provides specific, helpful feedback without using harsh or dismissive language."", ""The sentiment score is 60 (positive) because the reviewer expresses significant appreciation for the paper's novel insights, well-written nature, and precise contributions. They use phrases like 'I liked', 'very well-written', and 'I enjoyed reading it'. However, the score is not higher due to the 'main concern' about the significance and applicability of the theory to real-world scenarios. The politeness score is 80 (very polite) because the reviewer maintains a respectful and professional tone throughout. They balance praise with constructive criticism, using phrases like 'My main concern is' rather than direct criticism. The reviewer also acknowledges the paper's strengths before presenting concerns, and frames their technical question politely.""]"
"['In the paper, the authors try to propose an adaptive learning rate method called predictive local smoothness.  They also do some experiments to show the performance. \n\nThe following are my concerns:\n\n1. The definition of the L(x_t) is confusing. In (8), the authors define L(x_t), and in (10), the authors give another definition.  Does the L(x_t) in (10) always guarantee that (8) is satisfied? \n\n2. In theorem 1, \\mu^2 = \\frac{1}{n} \\sum_{i=1}^n L_i^2(x_t) + \\frac{2}{n^2}  \\sum_{i<j}^n L_i(x_t) L_j(x_t) > v. It looks like that \\mu > (1-\\rho^2) v, no matter the selection of \\rho.  Why?\n\n3. How do you compute L_i(x_t)  if x is a multi-layer neural network?\n\n4. The experimental results are too weak. In 2018, you should at least test your algorithm using a deep neural network, e.g. resnet. The results on a two-layer neural network mean nothing. \n\n5. sometimes, you algorithm even diverge. for example, figure 3 second column third row.  \n\n\n', 'This paper considers the finite-sum optimization problem that is typically seen in machine learning, and proposes methods that adaptively adjust the learning rate by estimating the local Lipschitz constant of the gradient. \n\nThe contributions of the paper seem very limited.  The proposed method which estimates the local Lipschitz constant of the gradient, named local predictive local smoothness (PLS) method in the paper (equation (10)), has been proposed in [1] long ago (see equation (11) in [1]) and is very well-known to the community. It is quite surprising that the authors claim to be the first to propose this while completely ignoring previous works.\n\nI also believe that there are major issues with the analysis for the methods. For example, I do not understand how equation (9) could possibly hold for general functions, and how it could be possible to transform their method into the linear system in (11). Therefore I do not think this paper is technically correct. \n\nIn summary, I believe this paper is limited in its contribution and also has major issues in terms of technical correctness, and is well below the standard for ICLR. \n\nReference: \n\n[1] Magoulas, G. D., Vrahatis, M. N., & Androulakis, G. S. (1997). Effective backpropagation training with variable stepsize. Neural networks, 10(1), 69-82.\n\n', ""The paper proposes to use an estimate of the 'local' smoothness constructed by taking the difference of the gradients along the previous step. This is a simple idea and has been considered before in literature. The authors seem to take a very simplistic approach to the problem which seems to not work at all in high dimensions. I am reasonable certain that the analysis is incorrect as it is impossible to get linear convergence via SGD or even with GD in general settings. Looking at the proof which is written in a very unreadable way reveals that they make multiple assumptions which holds basically in the case of a quadratic and then further only in one dimension. In which case such a rate with GD is trivial. \n\nSo the theory is blatantly wrong. Regarding the experiments they also look shaky at best and sometimes they diverge. I believe the paper is much below standard for ICLR. "", '\n# Unrealistic assumptions and trivial theory\n\nThis papers proposes a method to adjust the learning rate of stochastic gradient methods. The problem is of great importance but the theoretical results and presentation contain many issues that make the paper unfit for publication.\n\nThe main issue that I see is that the assumption made are unrealistic and make the theory trivial. First, for gradient descent, the authors assume that the gradient is of the form L(x_t) (x_t - x*). Under this assumption, gradient descent converges on a single step with step size 1 / L(x_t). In the stochastic setting, they assume that *each* stochastic gradient is of the form L_i(x_t) (x_t - x*), Eq. (11). Again, SGD in this scenario converges in a single iteration with step size 1 / L_i(x_t).\n\nNo wonder in this scenario the authors are able to obtain linear convergence of SGD to arbitrary precision (which is known to be impossible even for quadratics).\n\n\n# Other Issues\n\n* Motivation of Eq. (9) is not discussed in sufficient detail. It is unclear to me how to obtain (9) from (7) as the authors mention. Regarding notation, L(x_t) is a scalar, hence (9) could be written more simply as \\nabla f(x_t) = L(x_t) (x_t - x*). Why the need for the Kronecker product?\n\n* The authors should clearly state what are the assumptions in the theorem statement. For theorem 1 these are not clearly stated, and phrases like ""Theorem 1 provides a simple condition for the linear convergence of SGD"" give the wrong impression that the Theorem is widely applicable.\n\n\n# Minor\n  * Belo Eq. (10): ""where \\epsilon_1 is a parameter to prevent ||x_t - x_{t-1}|| going to zero: . I guess what the authors meant is to prevent *the denominator* going to zero, you do want ||x_t - x_{t-1}|| to go to zero as you approach a stationary point\n']","[-50, -80, -90, -80]","[0, -20, -50, -20]","[""The sentiment score is -50 because the review is predominantly critical, listing several concerns about the paper's methodology and results. The reviewer points out confusing definitions, questionable mathematical assertions, and weak experimental results. However, it's not entirely negative as the reviewer acknowledges the authors' attempt to propose a new method.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite or rude language. The concerns are stated directly and objectively without personal attacks or overly harsh criticism, but also without any particular courtesies or softening language."", ""The sentiment score is -80 because the review is highly critical of the paper. The reviewer states that the contributions are 'very limited', claims the main method has been proposed long ago, expresses surprise at the authors' claim of originality, believes there are 'major issues' with the analysis, and concludes that the paper is 'well below the standard for ICLR'. These are all strong negative statements indicating a very unfavorable view of the paper. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and lacks the softening phrases often used in more polite academic discourse. Phrases like 'It is quite surprising' and 'I do not think this paper is technically correct' are direct criticisms without much attempt to cushion the blow. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or overly harsh language, which is why the score is not lower."", ""The sentiment score is -90 because the reviewer is highly critical of the paper, stating that the theory is 'blatantly wrong', the analysis is 'incorrect', and the paper is 'much below standard for ICLR'. The reviewer also criticizes the experiments as 'shaky at best'. There are no positive comments about the paper. The politeness score is -50 because while the reviewer doesn't use explicitly rude language, the tone is dismissive and harsh. Phrases like 'very simplistic approach', 'impossible to get', 'written in a very unreadable way', and 'blatantly wrong' are quite blunt and could be considered impolite in academic discourse. However, the reviewer does maintain some level of professional language, avoiding personal attacks or extremely rude expressions, which is why the score is not lower."", ""The sentiment score is -80 because the review is highly critical, stating the paper is 'unfit for publication' and that the assumptions are 'unrealistic' and make the theory 'trivial'. The reviewer points out major flaws in the theoretical framework and presentation. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and dismissive. Phrases like 'No wonder' and 'It is unclear to me' convey a somewhat condescending tone. The reviewer does not soften criticisms or offer much encouragement, which contributes to the slightly impolite tone. However, the review maintains a professional structure and provides specific feedback, which prevents it from being extremely impolite.""]"
"[""This paper proposes runs variational inference with discrete mean-field distributions. The paper claims the proposed method is able to give a better estimation of uncertainty from the model. \n\nRating of the paper in different aspects ( out of 10)\nQuality 6, clarify 5, originality 8, significance of this work 5 \n\nPros: \n\n1. The paper proposes a generic discrete distribution as the variational distribution to run inference for a wide range of models. \n\nCons:\n\n1. When the method begins to use mean-field distributions, it begins to lose fidelity in approximating the posterior distributions. Even the model is able to do a good job in approximating marginal distributions, it is hard to evaluate whether the model is gaining benefit overall. \n\n2. I don't see a strong reason for using discrete distributions. In one dimensional space, a distribution can be approximated in different ways. Using discrete distributions only increases the difficulty of reparameterization. \n\n3. In the experiment evaluation, the algorithm seems only marginally outperforms competing methods. \n\n\nDetailed comments: \n\nIn the motivation of the paper, it cites low-precision neural networks. However, low-precision networks are for a different purpose -- small model size and saving energy. \n\nequation 6 is not clear to me.\n\nIn equation 10, how are these conditional probabilities parameterized? Is it like: z ~ Bernoulli( sigmoid(wz) ) ?\n\nIt is nice to have a brief introduction of the evaluation measure SGR. \n\nIn table 3, 1st column, the third value seems to be the largest, but the fourth is bolded. \n"", 'The authors consider uncertainty estimation in deep latent variable models. They propose to use quantised latent variable and argue that this solves the overconfidence problem, commonly encountered in variational inference. The proposed approach relies on optimizing an information bottleneck objective instead of  the ELBO.\n\nWhile the approach is of interest, a number of questions, central to the work, remain. For example, it is not clear how parameter \\beta is chosen/optimised, how the number of bins C is chosen and how the annealing scheme is tuned. The authors do not discuss the quantisation parameters, such as bin size and location, which are likely to have a major effect on the performance (and the complexity). Then the authors propose to use a hierachical set of latent variables without properly justifying the need, nor discuss how to select the depth and its impact on the performance. Finally the authors propose yet another extension based on a matrix-factorization with little justification.\n\nOverall, this paper does not fully develop the ideas proposed in the paper or discuss them in sufficient detail. The experiments do not provide additional intuition on what\'s going on and why this helps and are insufficiently documented/made accessible to be convincing. For example, I am not sure what to conclude from experiments that rely on no (or ""light"") hyperparameter tuning, when the proposed method has many and not discussion is provided about how to set them or how sensitive results are to their actual value. More importantly, the initial claim that uncertainty is better captured relies on SGR, a metric which is not standard and mentioned in passing without being properly defined. The evaluation further depends on a ""selective classifier"" which is not detailed, but critical to understanding the experiments.\n\nFinally, the presentation of Section 3 could be significantly improved. For example, I would suggest distinguishing the neural network parameters of the encoder and the decoder as well as the encoder and decoder networks.  I would also refrain using notations like ""..."" or and always specify what is left and right of an equality. Please spell out all abbreviations at least once in the paper and define all important quantities and concepts.\n\n', 'The authors propose “Stochastic Quantized Activation Distributions” (SQUAD). It quantizes the continuous values of a network activation under a finite number of discrete (non-ordinal) values, and is distributed according to a Gumbel-Softmax distribution. While the topic is interesting, the work could improve by making more precise the benefit of (relaxed) discrete random variables. This will also allow the authors to more precisely display in the experiments why this particular approach is more natural than other baselines (e.g., if multimodality is the issue, compare to a mixture model; if correlation is a difficulty, compare to any structured distribution such as a flow).\n\nDerivation-wise, the method ends up resembling Gumbel-Softmax VAEs but under an information bottleneck (discriminative model) setup rather than under a generative model. Unfortunately, that in and of itself is not original. \n\nThe idea of quantizing a continuous distribution over activations using a multinomial is interesting. However, by ultimately adding Gumbel noise (and requiring a binning procedure), the resulting network ends up looking a lot like continuous values but now constrained under a simplex rather than the real line. Given either the model bias against a true Categorical latent variable, or continuous simplex-valued codes, it seems more natural as a baseline to compare against a mixture of Gaussians. They have a number of hyperparameters that make it difficult to compare without a more rigorous sensitivity analysis (e.g., bin size).\n\nGiven that the number of bins they use is only 11, I’m also unclear on what the matrix factorization approach benefits from. Is this experimented with and without?']","[-20, -50, -20]","[50, 20, 50]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros and originality of the paper, there are more cons listed and the overall evaluation seems lukewarm. The reviewer points out several weaknesses and areas for improvement, and the numerical ratings given are mostly average or slightly above average. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout. They provide constructive criticism without using harsh language, and balance negative points with positive ones. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback.', ""The sentiment score is -50 because the review expresses several concerns and criticisms about the paper, indicating a generally negative sentiment. The reviewer points out multiple areas where the paper lacks clarity, justification, or sufficient detail. However, it's not entirely negative as the reviewer acknowledges that 'the approach is of interest' at the beginning.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, despite the criticisms. They use phrases like 'I would suggest' and 'Please spell out' which are polite ways of giving feedback. The reviewer also acknowledges positive aspects before diving into criticisms. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many overtly polite phrases or softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the topic as interesting, they express several concerns and suggest improvements. The review points out limitations in the originality and effectiveness of the proposed method, and questions some of the methodological choices. However, it's not entirely negative as it recognizes some positive aspects. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism without being harsh or dismissive, using phrases like 'could improve' and 'I'm unclear' rather than more confrontational language. The reviewer also acknowledges the interesting aspects of the work, which contributes to the polite tone.""]"
"[""# Paper summary\nThis paper advances a method for accelerating semantic segmentation on video content at higher resolutions. Semantic segmentation is typically performed over single images, while there is un-used redundancy between neighbouring frames. The authors propose exploiting this redundancy and leverage block motion vectors from MPEG H.264 video codec which encodes residual content between keyframes. The block motion vectors from H264 are here used to propagate feature maps from keyframes to neighbouring non-keyframe frames (in both temporal directions) avoiding thus an additional full forward pass through the network and integrate this in the training pipeline. Experimental results on CamVid and Cityscapes show that the proposed method gets competitive results while saving computational time.\n\n\n# Paper strengths\n- This paper addresses a problem of interest for both academic and industrial purposes.\n- The paper is clearly written and the authors argument well their contributions, adding relevant plots and qualitative results where necessary.\n- The two-way interpolation with block motion vectors and the fusion of interpolated features are novel and seem effective.\n- The experimental results, in particular for the two-way BMV interpolation, are encouraging.\n\n\n# Paper weaknesses\n\n- The idea of using Block Motion Vectors from compressed videos (x264, xvid) to capture motion with low-cost has been previously proposed and studied by Kantorov and Laptev [i] in the context of human action recognition. Flow vectors are obtained with bilinear interpolation from motion blocks between neighbouring frames. Vectors are then encoded in Fisher vectors and not used with CNNs as done in this paper. In both works, block motion vectors are used as low-cost alternatives to dense optical flow. I would suggest to cite this work and discuss similarities and differences.\n\n\n- Regarding the evaluation of the method, some recent methods dealing with video semantic segmentation, also using ResNet101 as backbone, are missing, e.g. low latency video semantic segmentation[ii]. Pioneer Clockwork convnets are also a worthy baseline in particular in terms of computational time (results and running times on CityScapes are shown in [ii]). It would be useful to include and compare against them.\n\n- In Section 4.1.2 page 7 the authors mention a few recent single-frame models ((Yu et al. (2017); Chen et al. (2017); Lin et al. (2017); Bilinski & Prisacariu (2018)) as SOTA methods and the current method is competitive with them. However I do not see the results from the mentioned papers in the referenced Figures. Is this intended?\n\n- On a more general note related to this family of approaches, I feel that their evaluation is usually not fully eloquent. Authors compare against similar pipelines for static processing and show gains in terms of computation time. The backbone architecture, ResNet-101 is already costly for high-resolution inputs to begin with and avoiding a full-forward pass brings quite some gains (though a part of this gain is subsequently attenuated by the latency caused by the batch processing of the videos). There are recent works in semantic segmentation that focus on architectures with less FLOPs or memory requirements than ResNet101, e.g. Dilated ResNets [iii], LinkNet[iv]. So it could be expected that image-based pipelines to be getting similar or better performance in less time. I expect the computational gain on such architectures when using the proposed video processing method to be lower than for ResNet101, and it would make the decision of switching to video processing or staying with frame-based predictions more complex. \nThe advantage of static image processing is simpler processing pipelines at test time without extra parameters to tune. It would be interesting and useful to compare with such approaches on more even grounds.\n\n\n# Conclusion \nThis paper takes on an interesting problem and achieves interesting results. The use of Block Motion Vectors has been proposed before in [i] and the main novelty of the paper remains only the interpolation of feature maps using BMVC. The experimental section is missing some recent related methods to benchmark against.\nThis work has several strong and weak points. I'm currently on the fence regarding my decision. For now I'm rating this work between Weak Reject and Borderline  \n\n# References\n\n[i] V. Kantorov and I. Laptev, Efficient feature extraction, aggregation and classification for action recognition, CVPR 2014\n[ii] Y. Li et al., Low-Latency Video Semantic Segmentation, CVPR 2018\n[iii] F. Yu et al., Dilated Residual Networks, CVPR 2017\n[iv] A. Chaurasia and E. Culurciello, LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation, arXiv 2017\n"", 'This paper presents a feature interpolation strategy for fast semantic segmentation in videos. They first compute features of keyframes, then interpolate intermediate frames based on block-motion vectors (BMV), and finally fuse the interpolated features as input to the prediction network. The experiments show that the model outperforms one recent, closely related work wrt inference time while preserving accuracy.\n\nPositive:\n1. Efficient inference. The strategy cuts inference time on intermediate frames by 53%, while achieves better accuracy and IOU compared to the one recent closely related work.\n\n2. The ablation study seems sufficient and well-designed. The paper presents two feature propagation strategies and three feature fusion methods. The experiments compare these different settings, and show that interpolation-BMV is indeed a better feature propagation.\n\nNegative:\n\n1. Limited novelty. The algorithm is close to the optical-flow based models Shelhamer et al. (2016) and Zhu et al. (2017). The main difference is that the optical-flow is replaced with BMV, which is a byproduct of modern cameras.  \n\n2. Insufficient experimental comparison with other baselines. In experiments, the paper compares the proposed model with only one baseline Prop-flow, which is not a sufficient comparison to show that the paper really outperforms the state-of-art model. For example, the authors should also compare with “Clockwork convnets for video semantic segmentation.”     \n\n3. Some technical details are not clear. For example, in section 3.1, the paper mentions that the task network is built by concatenating three components but never clarifies them. Also, in algorithm 2, line 13 shows that F is a function with two entries, but line 8 indicates that F is a feature.\n\n\n\n\n', 'In this paper, the authors propose a novel segmentation scheme that combines the block motion vectors for feature warping, bi-directional propagation, and feature fusion. Experiments demonstrate its effectiveness compared with alternative methods. However, I still have several concern:\n1. As  the block motion vectors are generally rough estimation, it may damage the performance of the tasks. The authors should further clarify how the imperfect estimation influence the performance, e.g., the Blocking artifacts. \n2. The features are actually abstract representation of an image while the motion vectors are actually obtained via the pixel comparison. The authors should further justify the motion estimation could be used to the latent feature directly. \n3.  The authors are expected to conduct more comprehensive experiments. Motion vectors are consistent in the current dataset. The authors are expected to demonstrate when the motion are chaotic. \n']","[-20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and conclude with a 'Weak Reject to Borderline' rating. The reviewer's tone is generally constructive but leans towards criticism. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides detailed, constructive feedback. They use phrases like 'I would suggest' and 'It would be interesting and useful' which contribute to a polite tone. The reviewer also provides specific recommendations for improvement, which is a courteous approach in academic peer review."", 'The sentiment score is slightly negative (-20) because while the review acknowledges some positive aspects (efficient inference, well-designed ablation study), it also points out significant limitations (limited novelty, insufficient experimental comparisons, unclear technical details). The negative points seem to outweigh the positives, but not drastically. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present both positive and negative points objectively, without using harsh or judgmental language. The reviewer provides constructive criticism and suggestions for improvement, which is a polite approach in academic peer reviews.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and effectiveness of the proposed method, they express several concerns and request further clarifications and experiments. This indicates a mixed but slightly critical view of the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language, framing their points as suggestions ('The authors should...', 'The authors are expected to...') rather than demands. They also begin with a positive acknowledgment of the paper's contributions before moving on to their concerns, which is a polite approach. The language is professional and constructive throughout, without any rudeness, but also without overtly polite phrases, hence the moderate positive score.""]"
"['This paper presents a method for generating 3D objects. They train a VAE to generate voxel occupancy grids. Then, they allow a user to generate novel shapes using the learned model by combining latent codes from existing examples. \n\nPros:\n- The idea of linking affordances to 3D object generation is interesting, and relevant to the machine learning and computer vision communities.\n\n- They propose to evaluate the quality of the shape based on a physical simulation (Section 4.4.3), which is an interesting idea.\n\nCons:\n- This paper is not well written. The method is described in too much detail, and the extra length (10 pages) is unnecessary. Cross entropy, VAEs, and many of the CNN details can usually just be cited, instead of being described to the reader.\n\n- The paper uses suggestive terminology, like ""functional essence"" and ""functional arithmetic"" for concepts that are fairly mundane (see Lipton and Steinhardt, 2018 for an extended discussion of this issue). For example, the ""functional essence"" of a class is essentially an average of the VAE latent vectors (Section 3.3.1). The paper claims, without sufficient explanation, that this is computation is motivated by the idea that ""form follows function"".\n\n- The results are not very impressive. There is no rigorous evaluation. They propose several nice metrics to use (eg. affordance simulation), but the results they present for each metric are quite limited. The qualitative results are also not particularly compelling.\n\n- The paper should more thoroughly evaluate the importance weighting that is described in Section 3.3.2.\n\n - The technical approach (combining VAE vectors to make new shapes) is not particularly novel[\n\nOverall:\n\nThe paper should not be accepted in its current form, both due to the confusing writing, and the lack of careful evaluation.\n', '\nThis paper proposed a 3D shape generation model. The model is essentially an auto-encoder. The authors explored a new way of interpolation among encoded latent vectors, and drew connections to object functionality.\n\nThe paper is, unfortunately, clearly below the bar of ICLR in many ways. It’s technically incremental: the paper doesn’t propose a new model; it instead suggests new way of interpolating the latent vectors for shape generation. The incremental technical innovation is not well-motivated or justified, either: the definitions of new concepts such as ‘functional essence’ and ‘importance vector’ are ad-hoc. The results are poor, much worse compared with the state-of-the-art shape synthesis methods. The writing and organization can also be improved. For example, the main idea should be emphasized first in the method section, and the detailed network architecture can be saved for a separate subsection or supplementary material. \n\nIt’s good that the authors are looking into the direction of modeling shape functionality. This is an importance area that is currently less explored. I suggest the authors look into the rich literature of geometry modeling in the computer graphics and vision community, and improve the paper by drawing inspiration from the latest progress there. \n', 'This paper is addressing several research challenges as a method to generate objects with desired functionalities, a method to extract form-to-function mapping, a method to operationally support a functionality arithmetic. The work illustrated in this paper is really interesting and is addressing relevant and open problems in the domain of product design.\n\nNevertheless the manuscript has a couple of weaknesses, one concerned with the presentation and another related to the design of the study. \n\nThe lack of a consistent choice for the lexicon is sometimes misleading. It is not always clear whether the use of different terms is addressing synonyms or to discriminate between two distinct concepts. For example let consider the following pairs: functionality versus affordance, function versus functional, class versus category, feature versus shape. \n\nThe study addresses several questions. Not always is clear what is the purpose or better the research questions that are driving the design of the experiments. While in the manuscript the are many repetition of the objectives of the study, less attention is devoted to explain what are the working hypothesis underlying the proposed methods. For example, one of the objective is a method to generate objects with desired functionalities. Only in the final Section there is a brief mention of the dichotomy between meash-based versus voxel-based. As reported in Section 2 there are in literature other works but there is not a claim on what is the specific purpose of the present study. The contrast of voxel versus mesh looks like a motivation but it only a speculation. A similar comment might address the dichotomy deterministic (ontology) versus probabilistic (autoencoder). In this case the experiment design should provide some empirical evidence about this contrast.\n\nA minor comment. Figure 7a is illustrating the functional essence of table. According to the caption Figure 5a is illustrating the same functional essence for the same category/class table. Should the pictures look the same? \n']","[-60, -60, -20]","[-20, 20, 60]","[""The sentiment score is -60 because the review is predominantly negative. While it mentions a few pros, the cons outweigh them significantly. The reviewer states that the paper should not be accepted in its current form, citing issues with writing, lack of evaluation, and unimpressive results. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical. The reviewer uses phrases like 'not well written,' 'suggestive terminology,' and 'results are not very impressive' without much softening language. However, they do start with some positive points and use some neutral language, preventing the score from being extremely negative."", ""The sentiment score is -60 because the review is largely negative, stating the paper is 'clearly below the bar of ICLR in many ways', 'technically incremental', and that 'results are poor'. However, it's not entirely negative as it acknowledges some positive aspects like exploring shape functionality. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language such as 'unfortunately' and offer constructive suggestions. They also acknowledge the potential of the research direction. The reviewer maintains a professional tone throughout, avoiding harsh or rude language, but also doesn't go out of their way to be overly polite or soften their criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting and relevant work, they also point out several weaknesses. The review starts positively but then uses phrases like 'Nevertheless the manuscript has a couple of weaknesses' and provides detailed criticism. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, even when critiquing. They use phrases like 'The work illustrated in this paper is really interesting' and frame their criticisms as suggestions or observations rather than harsh judgments. The reviewer also uses polite hedging language like 'Not always is clear' instead of more direct criticism.""]"
"['Based on the CapsNet concept of Sabour the authors proposed a trace-back method to perform a semantic segmentation in parallel to classification. The method is evaluate on MNIST and the Hippocampus dataset.\n\nThe paper is well-written and well-explained. Nevertheless, I think it would be useful to have some illustrations about the network architecture. Some stuff which is explained in text could be easily visualized in a flow chart. For example, the baseline architecture and your Tr-CapsNet could be easily explained via a flow chart. With the text only, it is hard to follow. Please think about some plots in the final version or in the appendix. One question which is aligned to that: How many convolutional filters are used in the baseline model?\n\nAdditionally, think about a pseudo-code for improved understandability. \n\nSome minor concerns/ notes to the authors:\n1.\tAt page 5: You mentioned that the parameters lambda1 and lambda 2 are important hyper-parameters to tune. But in the results you are not explaining how the parameters were tuned. So my question is: How do you tuned the parameters? In which range do you varied the parameters?\n2.\tPage 6; baseline model: Why do you removed the pooling layers?\n3.\tI’m curious about the number of parameters in each model. To have a valid discussion about your model is better than the U-Net-6 architecture, I would take into account the number of parameters. In case that your model is noticeably greater, it could be that your increased performance is just due to more parameters. As long as your discussion is without the number of parameters I’m not convinced that your model is better. A comparison between models should be always fair if two models are architectural similar.\n4.\tWhy is the magnitude of lambda1 so different between the two dataset that you used?\n5.\tCould you add the inference times to your tables and discuss that in addition?\n6.\tWhat kind of noise is added to MNIST?\n7.\tWhat is the state-of-the-art performance on the Hippocampus dataset?\n8.\tWhat would be the performance in your experiments with a MaskRCNN segmentation network?\n9.\tI’m not familiar with the Hippocampus dataset. I missed a reference where the data is available or some explaining illustrations. \n10.\tFor both datasets, more illustrations about the segmentation performance would be fine to evaluate your method. At least in the appendix…\n\t\nMy major concern is that both datasets are not dealing with real background noise. I’m concerned that the results are not transferable to other datasets and that the method shines promising just because of the simple datasets only. For example, due to the black background MNIST digits are well separated (if we skip that you added some kind of noise). So, from that point of view your results are not convincing and the discussion of your results appearing sparse and not complete.\nTo make your results transparent you could think about to publish the code somewhere.\n', 'This paper proposes a traceback layer for capsule networks to do semantic segmentation. Comparing to previous works that use capsule networks for semantic segmentation, this paper makes explicit use of part-whole relationship in the capsule layers. Experiments are done on modified MNIST and Hippocampus dataset. Results demonstrate encouraging improvements over U-Net. The writing could be tremendously improved if some background of the capsule networks is included. \n\nI have a question about the traceback layer. It seems to me that the traceback layer re-uses the learned weights c_{ij} between the primary capsules and the class capsules as guidance when “distributing” class probabilities to a spatial class probabilistic heatmap. One piece of information I feel missing is the affine transformation that happens between the primary capsule and the class capsule. The traceback layer doesn’t seem to invert such a transformation. Should it do so? \n\nSince there have been works that use capsule networks for semantic segmentation, does it make sense to compare to them (e.g. LaLonde & Bagci, 2018) ?', 'Authors present a trace-back mechanism to associate lowest level of Capsules with their respective classes. Their method effectively gets better segmentation results on the two (relatively small) datasets. \n\nAuthors explore an original idea with good quality of experiments (relatively strong baseline, proper experimental setup). They also back up their claim on advantage of classification with the horizontal redaction experiment. \nThe manuscript can benefit from a more clear description of the architecture used for each set of experiments. Specially how the upsampling is connected to the traceback layer.\nThis is an interesting idea that can probably generalize to CNNs with attention and tracing back the attention in a typical CNN as well.\n\nPros:\nThe idea behind tracing the part-whole assignments back to primary capsule layer is interesting and original. It increases the resolution significantly in compare to disregarding the connections in the encoder (up to class capsules). \n\nThe comparisons on MNIST & the Hippocampus dataset w.r.t the U-Net baseline are compelling and indicate a significant performance boost. \n\nCons:\nAlthough the classification signal is counted as the advantage of this system, it is not clear how it will adopt to multi-class scenarios which is one of the major applications of segmentation (such as SUN dataset).\n\nThe assumption that convolutional capsules can have multiple parents is incorrect. In Hinton 2018, where they use convolutional Capsule layers, the normalization for each position of a capsule in layer below is done separately and each position of each capsule type has the one-parent assumption. However, since in this work only primary capsules and class capsules are used this does not concern the current experiment results in this paper.\n\nThe related work section should expand more on the SOTA segmentation techniques and the significance of this work including [2].\n\nQuestion: \nHow is the traceback layer converted to image mask? After one gets p(c_k | i) for all primary capsules, are primary capsule pose parameters multiplied by their p(c_k |i ) and passed all to a deconv layer? Authors should specify in the manuscript the details of the upsampling layer (s) used in their architecture. It is only mentioned that deconv, dilated, bilinear interpolation are options. Which one is used in the end and how many is not clear. \n\n\nComments:\nFor the Hippocampus dataset, the ensemble U-Net approach used in [1] is close to your baseline and should be mentioned cited as the related work, SOTA on the dataset. Also since they use all 9 views have you considered accessing all the 9 views as well?\n\n\n[1]: Hippocampus segmentation through multi-view ensemble ConvNets\nYani Chen ; Bibo Shi ; Zhewei Wang ; Pin Zhang ; Charles D. Smith ; Jundong Liu\n[2]: RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation\nGuosheng Lin, Anton Milan, Chunhua Shen, Ian Reid']","[20, 50, 60]","[80, 75, 70]","[""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging that the paper is 'well-written and well-explained'. However, they also express several concerns and suggestions for improvement, which tempers the overall positivity. The politeness score is high (80) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and provides detailed, constructive feedback. They use phrases like 'Please think about', 'I'm curious about', and 'Could you add' which maintain a polite tone while conveying their points. The reviewer also balances criticism with positive remarks and acknowledges their own potential lack of familiarity with some aspects ('I'm not familiar with the Hippocampus dataset'). The overall tone is professional and aimed at improving the paper rather than being overly critical."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and improvements over previous work, using phrases like 'encouraging improvements' and 'makes explicit use of part-whole relationship'. However, they also point out areas for improvement in the writing and raise questions about the methodology, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as suggestions or questions (e.g., 'The writing could be tremendously improved if...', 'Should it do so?'), and acknowledges the paper's strengths before offering critiques. The tone is constructive and professional, without any harsh or rude language."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the originality of the idea, the quality of experiments, and the significant performance boost shown in the results. They use phrases like 'interesting idea', 'good quality of experiments', and 'compelling' to describe the work. However, they also point out some cons and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They balance praise with constructive criticism, use phrases like 'can benefit from' instead of more direct criticisms, and frame their points as questions or suggestions rather than demands. The reviewer also acknowledges the potential of the work to generalize to other areas, which shows respect for the authors' contribution.""]"
"['Partially observable Markov decision processes (POMDPs) are a widely-used framework to model decision-making with uncertainty about the environment and under stochastic outcome. In conventional POMDP models, the observations that the agent receives originate from fixed known distribution. However, in a variety of real-world scenarios the agent has an active role in its perception by selecting which observations to receive. Due to the combinatorial nature of such a selection process, it is computationally intractable to integrate the perception decision with the planning decision. \n\nThe author proposes a new form of POMDPs called AP2-POMDP, which takes active perception into account. The AP2-POMDP problem restricts the maximum number of sensors that can be selected by an agent. The agent also faces the planning problem to select the sensors. To prevent such expansion of the action space, the authors propose a greedy strategy for observation selection and obtain a near optimal bound based on submodular optimization.\n\nThe author also proposes a greedy-based scheme for the agent to find an almost optimal active perception action by minimizing the uncertainty of beliefs. The author also uses theories to prove the near-optimal guarantees of this greedy method. The author also proposes a novel perception-aware point-based value iteration to calculate the value function and obtain the policy. The author also operates an interesting simulation experiment, which shows less uncertainty of the robot when taking planning actions when using the proposed solver.\n\nThe contribution is significant in reinforcement community. The writing is in general clear. It can be improved with minor modifications, for example, explaining math equations better in English. \n\nMy main comment for the authors is whether they have considered the scenario where the perception and the planning actions are connected. I agree with the authors that the best strategy for perception is to reduce uncertainty (and indeed, the greedy approach yields a near-optimal performance), given the restricted situation that the perception and planning are two separated processes. Nonetheless, in most real-world applications, the two processes are coupled, and therefore, we face, immediately, the trade-off between exploration and exploitation. I wonder if the authors have considered how they can extend their approach to such scenarios. \n\nA few minor comments:\n\n\t\n(i) The authors should add a legend and perhaps, more explanation in the captions of Figure 5. The colors of the heat-map are confusing. If dark blue and dark red represent lowest and highest frequency, what about other colors? Are there obstacles placed in the grid? If so, are they placed as shown in Figure 3(b)?\n\t\n(ii) What is the effect of k, the maximum number of sensors to be placed? Can the authors provide a figure showing the change of performance with varying k?\n\t\n(iii) It will be more convincing if the author deploys this algorithm to real-world robots and demonstrate its effectiveness. \t\n\n', 'This work addresses the problem of decomposing the observation acquisition from action planning in POMDPs.  Unfortunately, the paper has two major weaknesses.  First it is hindered by a confusing motivation, and the lack of clarity on the real purpose of the work is a problem throughout. Second the experiments are insufficient given current standards in the literature.\n\n1. Motivation:  The introduction suggests that the main motivation is to reduce the computational cost of treating all observations within planning (“one must establish a trade-off between optimality and tractability”), though later, different reasons are offered (“power, processing capability, and cost constraints”).  It seems that each of these poses different constraints, and depending on which we are most concerned with, a different approximation scheme should be selected. For example, if the real concern is tractability of the POMDP solution, I don’t see why it’s not possible to just acquire all the sensor information, and afterwards decide how to approximate the tracking (this by the way is what most point-based POMDP methods effectively do).  For the proposed AP^2-POMDP, possibly a more reasonable motivation is high cost of observation acquisition; a clean argument would have to be made about the class of problems for which this constraint is crucial, why cardinality of sensor is the right way to articulate this constraint.\n\n2. Experimental results:  The domains selected for the experiments are too simple, given current standards in the literature.  Looking at the 1D and 2D domains is fine to illustrate specific properties of your methods.  But it does not support the claim that the proposed model is more scalable than standard POMDPs.  In such simple domains, why not include results for a point-based method?  They should work in the 1D domain, probably also in the 2D domain.  Also, the setting for the 1-D domain, with a camera in every cell, seems very artificial.  First, if sensors are expensive, why put a camera in every cell?  And if they are not expensive, then why do we need to reason about which sensor to use at each step?  And why just read from k cameras at every step?  These questions point back to the concern regarding what is the real motivation for this work.  For the 2D domain, there are not even quantitative results on cumulative reward.  To be convincing, the results would need to be on substantially more complex domains; there are several POMDP benchmarks that could be considered, e.g. those in the work of Kurniawati et al.\n\nOther comments:\n-\tAssumption 1 states that the observations from sensors are mutually independent give the state and action.  Can you explain why this is reasonable?  Or whether this is a strong assumption (unlikely to be met in practice)?\n-\tSome of the bounds seem like they could be very loose in practice, even (in the worse case) worse than the default bound of (R_max-R_min)/(1-\\gamma). For example in Thm 3, in the case where the L1 distance between the 2 beliefs is 2, this is worse than the default bound.  Did you check what is the bound for the domains in the experiments?  Is it tighter than this?\n-\tA key statement is on p.8: “this added complexity is significantly lower than concatening the combinatorial perception actions with the planning actions”.   It is important to support this statement, ideally with both a precise complexity analysis, and with empirical results showing the lesser performance of standard point-based methods.\n\nMinor comment:\n-\tThe referencing style is broken and should be fixed, in particular proper use of Author (year) in the text.\n-\tThe derivations in the top part of p.4 (Eqn 2-4 & surrounding text) are confusing, given that these apply to a standard POMDP, whereas on the previous page your present the AP^2-POMDP model. It might be better in Sec.2 to first (briefly) introduce POMDPs, with Eqn 2-4, then introduce AP^2-POMDP in Sec.3.\n-\tP.5: “It is worth noting that the objective function does not explicitly depend on perception actions”. This is a confusing statement; V depends on observations through b_t.  The next sentence clarifies this, but it would be better to avoid the confusing statement.\n-\tAlg.2:  Add a reference beside the title (unless you claim it is new).  Maybe Pineau et al. 2003.\n-\tP.7: “can be combined with any sampling and pruning method in other solvers” -> Add references for such sampling & pruning methods.\n\n\n', 'This paper proposes a planning algorithm for a restricted class of POMDPs where the sensing decisions do not have any bearing on the hidden state evolution, or any material cost in terms of reward. A sensing decision consists of querying k out of n sensors which yield independent measurements of the hidden state. In this setting, the authors propose an optimization 2-stage optimization strategy, the first stage tries to find the optimal ""planning"" action in a point-based fashion, whereas the second aims to find the the sensor configuration that reduces the entropy of the post-update belief-state. The key observation is that the entropy minimization step is submodular and can be approximated greedily. This in turn translates to policy approximation bounds via information geometric arguments. \n\nThe positive: the paper is well written (save for some contained parts), the algorithm looks to be generally sound. Altogether the paper makes good points and is an interesting read. \n\nThe negative: \n* first, I think there is some wide-spread misuse of the term ""nearly optimal"". When talking about near-optimality, this usually refers to finding a (controllably) bounded approximation to the optimal policy/value function. However, here this refers to the error relative to the approximate solution produced by the 2-stage procedure of minimizing entropy, then making a planning decision. It is not clear to me to begin with that this approach would produce bounded policies/value functions. As a counter example, consider a state space consisting of two state variables S1, S2 which evolve independently with additive reward  R(S1, a)  + R(S2, a) with  R(S1, a) !=0, while R(S2, a) = 0 for all actions a. Now, there could be a sensing configuration that collapses the uncertainty over S2 completely, but does nothing over S1, and a different one that give some small reduction of uncertainty  over S1 and nothing over S2. The former may outperform the latter to any degree in terms of belief state entropy, but it will not lead to an optimal policy, since that entropy reduction is not value directed. Unless I misunderstand something, in which case the authors should clarify. \n\n* Second,  the particular assumptions in this paper are quite restrictive. This paper generally reads like a solution that was fit to a problem. This really hurts the story of the paper. It would be a vast improvement if the authors could find at least one plausible problem where there\'s a compelling case for this particular configuration of assumptions and try to evaluate how well they do on that problem relative to some reasonable baseline.\n\nRemarks: \n* The belief state notation used in this paper impacts undue suffering upon the reader. It comes in the form of expressions with multi-level sub/superscipts and accents such as: ""b prime subscript b tilde superscript a superscipt pr comma omega"". This is extremely hard to parse and possibly unnecessary, as b prime subscript b tilde and b tilde are the only configurations of accents and subscripts that appear. These could just be called alpha and beta and the rest is clear from the context. \n* The claim in theorem 4, the argmax is the same under both directions of the KL divergence, is not obvious. It is definitely not true for minimization, otherwise the I-projection and the M-projection would coincide. This should be argued. Alternatively, this point can be alltogether skipped, since Pinsker\'s bound, which is the only place this is used, does not depend on the direction of KL.\n\nOverall, this paper raises some nice points, but with these problems it is not a clear accept. ']","[60, -70, -20]","[70, 20, 50]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the significance of the contribution, praises the clear writing, and offers constructive feedback for improvement. The overall tone is supportive, with phrases like 'The contribution is significant' and 'The writing is in general clear.' However, it's not extremely positive as the reviewer does suggest some improvements and raises questions about the approach. The politeness score is 70 (polite) due to the respectful and constructive nature of the feedback. The reviewer uses phrases like 'I wonder if the authors have considered' and 'It will be more convincing if' rather than making demands. The suggestions are framed as questions or gentle recommendations, maintaining a courteous tone throughout the review."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'two major weaknesses' and criticizes the motivation, clarity, and experimental results. The reviewer uses phrases like 'unfortunately', 'confusing motivation', 'lack of clarity', and 'insufficient experiments', which all contribute to the negative sentiment. However, it's not entirely negative as the reviewer acknowledges the work's attempt to address a problem in POMDPs.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'can you explain', 'it might be better', and provide specific suggestions for improvement. The reviewer also balances criticism with positive acknowledgments of the work's intentions. However, the score is only slightly positive because the criticism is direct and the overall tone is more neutral than overtly polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'generally sound', 'interesting read'), they raise significant concerns about the paper's methodology and assumptions. The reviewer points out 'wide-spread misuse' of a term, 'quite restrictive' assumptions, and suggests the paper 'reads like a solution that was fit to a problem'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticism with praise, and using phrases like 'Unless I misunderstand something, in which case the authors should clarify' which show respect for the authors. The reviewer also offers constructive suggestions for improvement, which contributes to the polite tone.""]"
"['This paper presents a new adversarial defense based on ""cleaning"" images using a round trip through a bidirectional gan.  Specifically, an image is cleaned by mapping it to latent space and back to image space using a bidirectional gan.  To encourage the bidirectional gan to focus on the semantic properties, and ignore the noise, the gan is trained to maximize the mutual information between z and x, similar to the info gan.\n\nPros:\n\t1. The paper presents a novel (as far as I am aware) way to defend against adversarial attacks by cleaning images using a round trip in a bidirectional gan\n\nCons:\n\t1. The method performs significantly worse than existing techniques, specifically adversarial training.\n\t\ta. The authors argue ""Although better than FBGAN, adversarial training has its limitation: if the attack method is harder than the one used in training(PGD is harder than FGSM), or the perturbation is larger, then the defense may totally fail. FBGAN is effective and consistent for any given classifier, regardless of the attack method or perturbation.""\n\t\tb. I do not buy their argument, however, because one can simply apply the strongest defense (PGD 0.3 in their results) and this outperforms their method in *all* attack scenarios.  And if someone comes out with a new stronger attack there\'s no guarantee their method will be strong defense against that method\n\t2. The paper is not written that well.  Even though the technique itself is very simple, I was unable to understand it from the introduction, and didn\'t really understand what they were doing until I reached the 4th page of the paper. \n\t\n\nMissing citation:\nPixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples  (ICLR 2018)\n', 'This work proposes to defend against adversarial examples by “denoising” the input image through an autoencoder (a BiGAN trained similar to InfoGAN) before classifying it with a standard CNN. The robustness of the model is evaluated on the L_infinity metric against FGSM and PGD.\n\nMy main criticism is as follows:\n* Novelty: several defences are based on a similar principle and the contributions of this paper are unclear.\n* Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims.\n* Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD).\n\n### Novelty\nThe only prior work against which the paper compares is DefenseGAN. The only advantage over DefenseGAN being stated is performance (because no intermediate optimisation step is used). However, besides DefenseGAN there are several other defences that project the input onto the learned manifold of “natural” inputs, including (see prior work section in [1] for an up-to-date list):\n\n* Adversarial Perturbation Elimination GAN\n* Robust Manifold Defense\n* PixelDefend (autoregressive probabilistic model)\n* MagNets\n\n### Insufficient evidence\nThe only attacks employed are two gradient-based techniques (FGSM and PGD). It is known that gradient-based techniques may suffer from gradient-masking (see also next point) and that the effectiveness of different attacks various greatly (which is why one should use many different attacks). Hence, a full evaluation of the model should include score-based and decision-based attacks.\n\n### Gradient masking\nIn Figure 5 (b) the FGSM attack performs better than PGD for epsilon = 0.05 (66.4% vs 71.5%). PGD, however, should be strictly more powerful than FGSM if the gradients and the hyperparameters are ok.\n\nGradient masking is the primary reason for why 95% of all proposed defences turned out to be ineffective, and there are good reasons to believe that the same might affect this defence. The robustness evaluation has to be much more thorough and convincing before any substantiated claims about the bidirectional architecture proposed here can be derived. In addition, the difference to prior work has to be made much clearer.\n\n[1] Schott et al. “Towards the first adversarially robust neural network model on MNIST”', 'Summary:\nThis paper gives a novel adversarial defense that consists of denoising images before classification. The denoising procedure consists of passing an image through a bidirectional GAN, which the authors use to map inputs to the latent space and then back to the original input space. \n\nNovelty:\nThe exact mechanism through which this paper operates is novel, but many similar defenses have been proposed before that involve a latent space mapping followed by a mapping back to the original space; examples include DefenseGAN and PixelDefend. \n\nConcerns:\n- The evaluation is not thorough enough: Only two attacks are considered (FGSM and PGD, with the former being strictly weaker than the latter)\n- DefenseGAN is similar in defense mechanism but the authors do not attempt to use the attacks of Athalye et al 2018 (ICML 2018) in their evaluation. We thus do not have strong lower bounds on adversarial robustness.\n- In Figure 5b, the attack FGSM performs better than PGD, but FGSM is the single step case of PGD. This indicates that the attacks were not tuned properly, as you should always have PGD as a stronger attacker than FGSM\n- The method does not perform as well as adversarial training in standard defense tasks\n- Several writing/clarity errors (detailed below)\n\nSmaller edits:\nPage 2: paragraph 2: second last line: ""feed"" instead of ""fed""\nPage 2: bullet 1: under our contribution: line 3: ""which are unchanged"" instead of ""which is unchanged""\nPage 3: paragraph 3: second last line: ""two distribution"" missing an s (plural)\nPage 3: Section 2.2: paragraph 2: line 2: ""here are two most famous attacks"" missing ""the"" before ""two most famous""\nPage 4: Section 3.2: first paragraph: line 4: ""the latent codes is decomposed"" should be ""are"" instead of ""is""\nPage 5: Paragraph 1: line 9: ""E are trained"" should be ""E is trained""\nPage 5: Section 4: Paragraph 1: last line: ""are those have access "" should be ""are those which have access"" missing which/that\nPage 6: Last paragraph: Line 1: ""the attacker can only access to the classifier"" there is no need for ""to""\n']","[-50, -70, -30]","[20, 20, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), they list more significant 'Cons' that outweigh the positives. The reviewer criticizes the method's performance, disagrees with the authors' arguments, and points out issues with the paper's writing quality. However, it's not entirely negative as they do recognize the novelty of the approach. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language like 'I do not buy their argument' instead of more harsh criticisms. They also start with positive points before moving to criticisms. However, the review isn't overly polite or complimentary, maintaining a mostly neutral, matter-of-fact tone."", ""The sentiment score is -70 because the review is predominantly critical, highlighting major issues with novelty, insufficient evidence, and potential gradient masking. The reviewer expresses skepticism about the paper's contributions and robustness of the proposed method. However, it's not entirely negative as it acknowledges some aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'My main criticism is' and provide specific examples and references to support their points, which is constructive. The language is not overtly polite, but it's not rude either, striking a balance typical of academic peer reviews."", ""The sentiment score is -30 because while the reviewer acknowledges the novelty of the paper, they express several significant concerns about the evaluation, methodology, and writing clarity. The overall tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'concerns' and 'smaller edits' rather than harsh language, and provide detailed explanations for their critiques. The reviewer also acknowledges the paper's contributions before diving into the concerns, which adds to the politeness. However, the score is not higher as the review is primarily focused on critiques rather than praise.""]"
"[""This is a well-written paper studying the important problem of dynamic network embedding. Please find below some pros and cons of this paper.\nPros:\n\n* Studies the important problem of network embedding under a more realistic setting (i.e., nodes & edges evolve over time).\n* Introduces an interesting architecture that uses two forms of attention: structural and temporal.\n* Demonstrated the effectiveness of the temporal layers through additional experiments (in appendix) and also introduced a variant of their proposed approach which can be trained incrementally using only the last snapshot.\n\nCons:\n\n* The authors compared against several dynamic & static graph embedding approaches. If we disregard the proposed approach (DySAT), the static methods seem to match and even, in some cases, beat the dynamic approaches on the compared temporal graph datasets. The authors should compare against stronger baselines for static node embedding, particularly GAT which introduced the structural attention that DySAT uses to show that the modeling of temporal dependencies is necessary/useful. Please see [1] for an easy way to train GCN/GAT for link prediction.\n* There are actually quite a number of work done on network embedding on dynamic graphs including [2-4]. In particular, [2-3] support node attributes as well as the addition/deletion of nodes & edges. The author should also compare against these work.\n* The concept of temporal attention is quite interesting. However, the authors do not provide more analysis on this. For one, I am interested to see how the temporal attention weights are distributed. Are they focused on the more recent snapshots? If so, can we simply retain the more relevant recent information and train a static network embedding approach? Or are the attention weights distributed differently?\n\n[1] Modeling Polypharmacy Side Effects with Graph Convolutional Networks. Zitnik et. al. BioInformatics 2018. \n[2] Attributed Network Embedding for Learning in a Dynamic Environment. Li et. al. In Proc. CIKM '17. \n[3] Streaming Link Prediction on Dynamic Attributed Networks. Li et. al. In Proc. WSDM '18. \n[4] Continuous-Time Dynamic Network Embeddings. Nguyen et. al. In Comp. Proc. WWW '18. "", 'This paper proposes a model for learning node embedding vectors of dynamic graphs, whose edge topology may change. The proposed model, called Dynamic Self-Attention Network (DySAT), uses attention mechanism to represent the interaction of spatial neighbouring nodes, which is closely related to the Graph Attention Network. For the temporal dependency between successive graphs, DySAT also uses attention structure inspired by previous work in machine translation. Experiments on 4 datasets show that DySAT can improve the AUC of link prediction by significant margins, compared to static graph methods and other dynamic graph methods. Though the attention structures in this paper are not original, combining these structures and applying them on dynamic graph embedding is new.\n\nHere are some questions:\n\n1. What will happen if a never-seen node appears at t+1? The model design seems to be compatible with this case. The structural attention will still work, however, the temporal attention degenerates to a “static” result --- all the attention focus on the representation at t+1. I am curious about the model performance in this situation, since nodes may arise and vanish in real applications.\n\n2. What is the performance of the proposed algorithm for multi-step forecasting? In the experiments, graph at t+1 is evaluated using the model trained up to graph_t. However, in real applications we may don’t have enough time to retrain the model at every time step. If we use the model trained up to graph_t to compute node embedding for the graph_{t+n}, what is the advantage of DySAT over static methods?\n\n3. What is the running time for a single training process?\n', 'This paper describes learning representation for dynamic graphs using structural and temporal self-attention layers. They applied their method for the task of link-prediction. However, I have serious objections to their experimental setup. I have seen people used sets of edges and pairs of vertices without an edge for creating examples for link-prediction on a static graph, however, working with a real-world dynamic graph, you can compute the difference between G_t and G_{t+1} as the changes that occur in G_t+1 1) Why are you not trying to predict these changes?  Moreover, 2) why do you need examples from snapshot t+1 for training when you have already observed t snapshots of the graph? \n3) The selected graphs are very small comparing to the dynamic graphs available here http://konect.uni-koblenz.de/networks/.  \n']","[50, 60, -70]","[75, 70, -20]","[""The sentiment score is 50 (slightly positive) because the review begins by calling it a 'well-written paper' and lists several pros before moving on to cons. The balance of pros and cons suggests a moderately positive view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as requests (e.g., 'The authors should...'). The reviewer also acknowledges the paper's contributions before offering critiques, which is a polite approach. The language is professional and objective, without any harsh or rude phrasing."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the novelty and effectiveness of the proposed model, noting significant improvements in link prediction and the innovative combination of attention structures. The reviewer's tone is generally positive, highlighting the strengths of the paper while also raising thoughtful questions. The politeness score is 70 (polite) as the reviewer maintains a respectful and professional tone throughout. They use neutral language to present their questions and observations, avoiding harsh criticism or demanding language. The reviewer's approach of posing questions rather than making direct criticisms demonstrates a considerate and constructive attitude towards the authors' work."", ""The sentiment score is -70 because the reviewer expresses 'serious objections' to the experimental setup and raises multiple critical questions about the methodology. The tone is predominantly negative, questioning the fundamental approach of the study. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical without any softening phrases or positive comments. The reviewer uses phrases like 'Why are you not...' and 'why do you need...', which come across as somewhat confrontational. The review also lacks any positive remarks or constructive suggestions, focusing solely on perceived flaws in the study.""]"
"['Summary: The paper proposes a new architecture to defend against adversarial examples. The authors propose a network with new type of hidden units (RBFI units). They also provide a training algorithm to train such networks and evaluate the robustness of these models against different attacks in the literature. \n\nMain concern: I think the idea  proposed here of using RBFI units is very interesting and intuitive. As pointed out in the paper, the RBFI units make it difficult to train networks using standard gradient descent, because the gradients can be uninformative. They propose a new training algorithm based on ""pseudogradients"" to mitigate this problem. However, while evaluating the model against attacks, only gradient based attacks are used (like PGD attack of Madry et al., or Carlini and Wagner). It\'s natural to expect that since the gradients are uninformative, these attacks might fail. However, what if we considered similar ""pseudogradient"" based attacks? In particular, just use the same training procedure formulation to attack (where instead of minimizing loss like in training, we maximize loss)?\nI think this key experiment is missing in the paper and without this evaluation, it\'s hard to claim whether the models are more robust fundamentally, or it\'s just gradient masking. \n\n\nRevision: After the authors revision, I change my score since they addressed my main complaint about results using pseudogradient attacks \n', 'This paper proposes an infinity norm variant of the RBF as the activation function of neural networks. The authors demonstrate that the proposed unit is less sensitive to the out-liar generated by adversarial attacks, and the experimental results on MNIST confirmed the robustness of the proposed method against several gradient-based attacks.\n\nIntuitively, the idea should work well against the features of adversarial examples which are far from the center of the cluster of ""normal"" features. However, the experiments are not convincing enough to show this point, and the entire method looks like a simple gradient mask technique. In my opinion, two types of experiments should be further considered:\n\n1. Pseudo-gradient-based attacks. Since the networks are trained using Pseudo gradients, all the attacks utilized in this paper should be pseudo-gradient-based as well.\n\n2. Black-Box attacks which do not rely on the information provided by gradients, such as transferable adversarial examples.\n\nFurthermore, the robustness revealed on the ""noise"" attack is interesting, I wish the authors could provide an analysis of the effects on feature distributions using different types of attacks.', 'This paper introduces a new neural network layer for the purposes of defending against ""white-box"" adversarial attacks (in which the adversary is provided access to the neural network parameters). The new network unit and its activation function are constructed in such a way that the local gradient is sparse and therefore is difficult to exploit to add adversarial shifts to the input. To train the networks in the presence of a sparse gradient signal, the authors introduce a ""pseudogradient"", and optimize this proxy-gradient to optimize the parameters. This training procedure shows competitive performance (after training) on the permutation-invariant MNIST dataset versus other more standard network architectures, but is more robust to both adversarial attacks and random noise.\n\nHigh-level comments:\n- Using only a single dataset, and one on which the classification problem is rather easy, is cause for concern. I would need to see performance on another dataset, like CIFAR 10, to be more convinced that this is a general pipeline. In Sec 4, the authors mention that, using the pseudogradient, ""one may be concerned that ... we may converge ... and yet, we are not at a minimum of the loss function"". They claim that ""in practice it does not seem to be a problem"" on their experiments. This claim is a bit weak considering only a single, simple dataset was used for training. It is not obvious to me that this would succeed for more complex datasets.\n- I would also like to see an additional set of adversarial attacks that are ""RBFI-aware"". A motivated attacker who is aware of this technique might replace the gradient in the adversarial attack with the pseudogradient instead; I expect such an attack would be effective. While problematic in general, I do not think this is necessarily an overall weakness of the paper (since we, the community, should be investigating methods like these to obfuscate the process of exploiting neural network models), but I would still like to see results showing the impact/performance of adversarial training over the pseudo-gradient. (I do not expect this will be very much effort.)\n- What is the purpose of showing robustness of your network models to random noise? It is nice/interesting to see that your results are more robust to random noise, but what is the intuition for why your network performs better?\n\nWording and minor comments:\n- The abstract is rather lengthy, but should probably contain somewhere a spelling-out of RBFI, since it informs the reader that the radial basis function (with infinity-norm) is the structure of the new network unit.\n- Sec 4: ""...indicate that pseudogradients work much better than regular gradients"" :: Please be more clear that this is context specific ""...than regular gradients for training RBFI networks"".\n- Sec. 4 :: Try to be consistent to how you specify ""z"" in this section, you alternate between the \'infinity-norm\' definition and the \'max\' definition from Eq. (2). Try to homogenize these.\n- In general, the paper was well-proofed and well-written and was easy to read (high clarity).\n- To my knowledge, this work is a rather unique foray into solving this problem (original).\n\nOverall, I think this work is an interesting idea to address a rather important concern in the Deep Learning community. While the idea has merit, the small set of experiments in this paper is not sufficiently compelling for me to immediately recommend publication. With a bit more work put into exploring the performance of this method on other datasets, this paper could be made more complete. (Also, since I am aware that space is limited, some of the details on the adversarial attacks from other publications can probably be moved to an appendix.)\n']","[50, -20, -20]","[75, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting and intuitive idea proposed in the paper, and mentions that their main concern was addressed in the revision. However, it's not overwhelmingly positive as there were initial concerns. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the merits of the work, and frames their concerns as suggestions rather than criticisms. The phrases 'I think' and 'It's natural to expect' soften the critique. The reviewer also positively notes that they changed their score after the authors addressed their main complaint, showing a fair and constructive approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential of the proposed method, they express significant concerns about the experimental design and the convincingness of the results. The reviewer states that 'the experiments are not convincing enough' and suggests that the method 'looks like a simple gradient mask technique.' However, the score is not deeply negative because the reviewer offers constructive feedback and shows interest in further analysis.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'In my opinion' and 'I wish the authors could provide,' which are polite ways of offering suggestions. The reviewer also acknowledges the potential of the idea and the interesting aspects of the work. However, the score is not extremely high as the criticism, while constructive, is quite direct."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's merits and interesting ideas, they express significant concerns about the limited dataset used and the need for more experiments. The reviewer states they cannot 'immediately recommend publication' without additional work. However, the score is not deeply negative as the reviewer sees potential in the work with some improvements. The politeness score is high (80) because the reviewer uses respectful and constructive language throughout. They offer specific suggestions for improvement, acknowledge the paper's strengths (e.g., 'well-proofed and well-written'), and frame criticisms politely (e.g., 'I would need to see...' rather than demanding changes). The tone is professional and helpful rather than harsh or dismissive.""]"
"['This paper proposes two gated deep learning architectures for sensor fusion. They are all based on the previous work \nNaman Patel et al\'s modality fusion with CNNs for UGV autonomous driving in indoor environments (IROS). By having the grouped features, the author demonstrated improved performance, especially in the presence of random sensor noise and failures.\n\n#Organization/Style:\nThe paper is well written, organized, and clear on most points. A few minor points:\n1) The total length of the paper exceeds 8 pages. Some figures and tables should be adjusted to have it fit into 8 pages.\n2) The literature review is limited.\n3) There are clearly some misspellings. For example, the ""netgated"" is often written as ""negated"".\n\n#Technical Accuracy:\nThe two architecture that the author proposes all based on the grouped features, which to my point of view, is a very important and necessary part of the new model. However, the author failed to rigorously prove or clearly demonstrated that why this is effective to our new model.  Moreover, how to make groups or how many groups are needed are not clearly specified. The experiments used only two completely different datasets, none of them are related to the previous sensor fusion method they are trying to compete. I\'m afraid this method cannot generalize to a common case.\n\nIn addition, if we look at Table 4 and Table 5, we can find the first Group-level Fusion Weight actually increases, which seems contradictory to the result shown in Table 6.\n\n#Adequacy of Citations: \nPoor coverage of literature in sensor fusion. There are less than 10 references are related to sensor fusion.\n\nOverall, it is not an ICLR standard paper.', 'Overview and contributions: The authors improve upon several limitations of the baseline negated architecture by proposing 1) a coarser-grained gated fusion architecture and 2) a two-stage gated fusion architecture. The authors show improvements in driving mode prediction and human activity recognition in settings where all modalities are observed as well as settings where there are noisy or missing modalities.\n\nStrengths:\n1. The model seems interesting and tackles the difficult problem of multisensor fusion under both normal and noisy settings.\n2. Good results obtained on standard benchmarks with improvements in settings where all modalities are observed as well as settings where there are noisy or missing modalities.\n\nWeaknesses:\n1. I am worried about the novelty of the proposed approach. The main idea for the fusion-group gated fusion architecture is to perform additional early fusion of sensory inputs within each group which reduces the number of group-level fusion weights and therefore the number of parameters to tune. The two-stage gated fusion architecture simply combines the baseline model and the proposed fusion-group model. Both these ideas seem relatively incremental.\n2. Doesn\'t the final two-stage gated fusion architecture further increase the number of parameters as compared to the baseline model? I believe there are several additional FC-NN blocks in Figure 3 and more attention gating weights. I find this counterintuitive since section 2.2 motivated ""Potential Over-fitting"" as one drawback of the baseline Netgated architecture. How does the increase in parameters for the final model affect the running time and convergence? \n\nQuestions to authors:\n1. I don\'t understand Tables 4,5,6. Why are the results for Group-level Fusion Weight in the middle of several columns? Which features are being used in which groups? Please make this clear using vertical separators.\n2. For the proposed two-stage gated fusion architecture, do the 2 branches learn different things (i.e focus on different portions of the multimodal inputs)? I would have liked to see more visualizations and analysis instead of just qualitative results.\n\nPresentation improvements, typos, edits, style, missing references:\n1. General poor presentation of experimental results. Tables are not clear and bar graphs are not professionally drawn. The paper extends to 9 pages when a lot of space could be saved by making the presentation of experimental results more compact. I believe the guidelines mention that more pages can be used if there are extensive results, but I don\'t think the experimental results warrant the extra page.', '\nThis paper tackles the problem of sensor fusion, where multiple (possibly differing) sensor modalities are available and neural network architectures are used to combine information from them to perform prediction tasks. The paper proposed modifications to a gated fusion network specifically: 1) Grouping sets of sensors and concatenating them before further processing, and 2) Performing multi-level fusion where early sensor data representations are concatenated to produce weightings additional to the those obtained from features concatenated at a later stage. Experimental results show that these architectures achieve performance gains from 2-6%, especially when sensors are noisy or missing. \n\nStrengths\n\n + The architectures encourage fusion at multiple levels (especially the second one), which is a concept that has been successful across the deep learning literature\n \n + The paper looks at an interesting topic, especially related to looking at the effects of noise and missing sensors on the gating mechanisms. \n\n + The results show some positive performance gains, although see caveats below. \n\nWeaknesses\n \n - The related work paragraph is extremely sparse. Fusion is an enormous field (see survey cited in this paper as well [1]), and I find the small choice of fusion results with a YouBot to be strange. A strong set of related work is necessary, focusing on those that are similar to the work. As an example spatiotemporal fusion (slow fusion [2]) bears some resemblence to this work but there are many others (e.g. [3,4] as a few examples).\n \n   [1] Ramachandram, Dhanesh, and Graham W. Taylor. ""Deep multimodal learning: A survey on recent advances and trends."" IEEE Signal Processing Magazine 34.6 (2017): 96-108.\n \t   Ramach\n   [2] Karpathy, Andrej, et al. ""Large-scale video classification with convolutional neural networks."" Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2014\n   [3] Mees, Oier, Andreas Eitel, and Wolfram Burgard. ""Choosing smartly: Adaptive multimodal fusion for object detection in changing environments."" Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on. IEEE, 2016.\n   [4] Kim, J., Koh, J., Kim, Y., Choi, J., Hwang, Y., & Choi, J. W. (2018). Robust Deep Multi-modal Learning Based on Gated Information Fusion Network. arXiv preprint arXiv:1807.06233.\n\n - The paper claims to provide a ""deep understanding of the relationships between sensory inputs, fusion weights, network architecture, and resulting performance"". I don\'t think it really achieves   \n    this with the small examples of weights for some simple situations.\n\n - It is very unclear whether the architectures have more or less parameters. At one point it is stated that the original architecture overfits and the new architecture has less parameters (Sec 2.2 and 3). But then it is stated for fairness the number of neurons is equalized (5.2), and later in that section that the new architectures have additional neurons. Which of these is accurate?\n\n - Related to the previous point, and possibly the biggest weakness, the experimental methodology makes it hard to tell if performance is actually improved. For example, it is not clear to me that the performance gains are not just a result of less overfitting (for whatever reason) of baselines and that the fixed number of epochs therefore results in stopping at a better performance. Please show training and validation curves so that we can see whether the epochs chosen for the baselines are not just chosen after overfitting (in which case early stopping will improve the performance). As another example, there are no variances shown in the bar graphs. \n\n - The examples with noise and failures are limited. For example, it is also not clear why an increase of noise in the RPM feature (Table 5) actually increases the weight of that group in the two-stage architecture. What does that mean? In general there isn\'t any principled method proposed for analyzing these situations. \n\nSome minor comments/clarifications:\n  - What is the difference between these gated networks and attentional mechanisms, e.g. alpha attention (see ""Attention is all you need"" paper)?\n  - What is a principled method to decide on the groupings?\n  - There are several typos throughout the paper\n    * ""in the presence of snesor"" => ""in the presence of sensor""\n    * Throughout the paper: ""Predication"" => ""Prediction""\n    * ""Likelihood of stucking the training""\n  - Tensorflow is not a simulation environment\n\nOverall, the paper proposes architectural changes to an existing method for fusion, and while positive results are demonstrated there are several issues in the experimental methodology that make it unclear where the benefits come from. Further, the paper lacks novelty as multi-level fusion has been explored significantly and the changes are rather minor. There is no principled method or concepts that drive the architectural changes, and while the authors claim a deeper investigation into the networks\' effectiveness under noise and failures the actual analysis is too shallow. ']","[-60, -20, -30]","[20, 60, 50]","[""The sentiment score is -60 because the review is generally negative, especially in the final line stating 'it is not an ICLR standard paper.' The reviewer points out several issues with the paper, including organization, technical accuracy, and inadequate citations. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the paper being 'well written, organized, and clear on most points.' The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They avoid harsh or rude language, instead using phrases like 'a few minor points' and offering specific suggestions for improvement. However, the tone is not overly polite or deferential, maintaining a professional and somewhat detached stance throughout."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express significant concerns about the novelty and clarity of the work. The reviewer points out weaknesses and asks critical questions, indicating more negative than positive sentiment overall. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, even when expressing criticisms. They offer constructive feedback and frame their concerns as questions or suggestions rather than harsh criticisms. The reviewer also acknowledges the strengths of the paper before discussing weaknesses, which is a polite approach to peer review.', ""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they list more weaknesses and express significant concerns about the methodology and novelty of the work. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses professional and respectful language throughout, balancing positive and negative feedback. They provide constructive criticism and suggestions for improvement rather than harsh criticism. The reviewer also uses phrases like 'please show' and 'it is not clear to me' which maintain a polite tone even when pointing out issues.""]"
"[""Statistics based on KNN distances are ubiquitous in machine learning. In this paper the authors propose to apply the existing LID metric to GANs. The metric can be decomposed as follows: (1) Given a point x in X, compute the k-nearest neighbors KNN(x, X) and let those distances be R1, R2, …, Rk. Now, rewrite LID(x, X) = [max_over_i (log Ri) - mean_over_i (log Ri)] to uncover that the distribution of (log-)distances is summarized as a function of the max distance and the mean distance. (2) To extend the metric to two sets, A and B, define CrossLID(A; B) = E_(x in A) [LID(x, B)]. To see why CrossLID is useful, let X be the observed data and G the generated data. First consider CrossLID(A, B) where A=B=X which determines a lower-bound which is essentially the average (over elements of A) LID statistic determined by the underlying KNN graph of X. Now, keep A=X, and progressively change B to G (say by replacing some points from X with some points from G). This will induce a change of the distance statistics of some points from A, which will be detected on the individual LID scores of those points, and will hence be propagated to CrossLID. As a result, LID close to the baseline LID detects both sample quality issues as well as mode dropping/collapse issues. In practice, instead of computing this measure in the pixel space, one can compute it in the feature space of some feature extractor, or in some cases directly in the learned feature space of the generator. Finally, given some labeling of the points, one can keep track of the CrossLID statistic for each mode and use this during training to oversample modes for which the gap between the expected CrossLID and computed one is large.\n\nClarity: I think the clarity can be improved -- instead of stating the (rather abstract) properties of LID, the readers might benefit from the direct discussion of the LID estimator and a couple of examples, derive the max - mean relationship for the MLE estimator and provide some guiding comments. In a later section one might discuss why the estimator is so powerful and generally applicable. Secondly, the story starts with “discriminability of the distance measure” and the number of latent variables needed to do it, but I felt that this only complicated matters as many of these concepts are unclear at this point. \nOriginality: Up to my knowledge, the proposed application is novel, albeit built on an existing (well-known) estimator. Nevertheless, the authors have demonstrated several desirable properties which might be proven useful in practice.\nSignificance of this work: The work is timely and attempts to address a critical research problem which hinders future research on deep generative models.\n\nPro:\n- Generally well written paper, although the clarity of exposition can be improved. \n- Estimator is relatively easy to compute in practice (i.e. the bottleneck will still be in the forward and backward passes of the DNNs).\n- Can be exploited further when labeled data is available\n- Builds upon a strong line of research in KNN based estimators.\n- Solid experimental setup with many ablation studies.\n\nCon:\n- FID vs CrossLID: I feel that many arguments against FID are too strong. In particular, in “robustness to small input noise” and “robustness to input transformation” you are changing the underlying distribution *significantly* -- why should the score be invariant to this? After all, it does try to capture the shift in distribution. In the robustness to sample size again FID is criticized to have a high-variance in low-sample size regime: This is well known, and that’s why virtually all work presenting FID results apply 10k samples and average out the results over random samples. In this regime it was observed that it has a high bias and low variance (Figure 1 in [1]). In terms of the dependency of the scores to an external model, why wouldn’t one compute FID on the discriminator feature space? Similarly, why wouldn’t one compute FID in the pixel space and get an (equally bad) score as LID in pixel space? Given these issues, in my opinion, Table 1 overstates the concerns with FID, and understates the issues with CrossLID. \n- FID vs CrossLID in practice: I argue that the usefulness comes from the fact that relative model comparison is sound. From this perspective it is critical to show that the Spearman’s rank correlation between these two competing approaches on real data sets is not very high -- hence, there are either sample quality or mode dropping/collapsing issues detected by one vs the other. Now, Figure 1 in [1] shows that this FID is sensitive to mode dropping. Furthermore, FID is also highly correlated with sample quality (page 7 of [2]).\n- A critical aspect here is that in pixel space of large dimension the distances will tend to be very similar, and hence all estimators will be practically useless. As such, learning the proper features space is of paramount importance. In this work the authors suggest two remedies: (1) Compute a feature extractor by solving a surrogate task and have one extractor per data set. (2) During the training of the GAN, the discriminator is “learning” a good feature space in which the samples can be discriminated. Both of these have significant drawbacks. For (1) we need to share a dataset-specific model with the community. This is likely to depend on the preprocessing, model capacity, training issues, etc.. Then, the community has to agree to use one of these. On the other hand, (2) is only useful for biasing a specific training run. Hence, this critical aspect is not addressed and the proposed solution, while sensible, is unlikely to be adopted.\n- Main contributions section is too strong -- avoiding mode collapse was not demonstrated. Arguably, given labeled data, the issue can be somewhat reduced if the modes correspond to labels. Similarly, if the data is well-clusterable one can expect a reduction of this effect. However, as both the underlying metric as well as the clustering depends on the feature space, I believe the claim to be too strong. Finally, if we indeed have labels or some assumptions on the data distribution, competing approaches might exploit it as well (as done with i.e. conditional GANs).\n- In nonparametric KNN based density estimation, one often uses statistics based on KNN distances. What is the relation to LID?\n\nWith respect to the negative points above, without having a clear cut case why this measure outperforms and should replace FID in practice, I cannot recommend acceptance as introducing yet another measure might slow down the progress. To make a stronger case I suggest:\n(1) Compute Spearman's rank correlation between FIDs and CrossLIDs of several trained models across these data sets.\n(2) Compute the Pearson's correlation coefficient across the data sets. Given that your method has access to dataset specific feature extractors I expect it perform significantly better than FID.\n \n[1] https://arxiv.org/pdf/1711.10337.pdf\n[2] https://arxiv.org/pdf/1806.00035.pdf\n\n========\nThank you for the detailed responses. I have updated my score from 5 to 6."", 'The paper is clear regarding motivation, related work, and mathematical foundations. The introduced cross-local intrinsic dimensionality- (CLID) seems to be naive but practical for GAN assessment. In general, the experimental results seem to be convincing and illustrative. \n\nPros: \n- Clear mathematical foundations and fair experimental results.\n- CLID can be applied to favor GAN-based training, which is an up-to-date research topic.\n- Robustness against mode collapse (typical discrimination issue).\n\nCons:\n-The CLID highly depends on the predefined neighborhood size, which is not studied properly during the paper. Authors suggest some experimentally fixed values, but a proper analysis (at least empirically), would be useful for the readers.\n- The robustness against input noise is studied only for small values, which is not completely realistic.', 'The paper proposes a new metric to evaluate GANs. The metric, Cross Local Intrinsic Dimensionality (CrossLID) is estimated by comparing distributions of nearest neighbor distances between samples from the real data distribution and the generator. Concretely, it proposes using the inverse of the average of the negative log of the ratios of the distances of the K nearest neighbors to the maximum distance within the neighborhood. \n\nThe paper introduces LID as the metric to be used within the introduction, but for readers unfamiliar with it, the series of snippets “model of distance distributions” and “assesses the number of latent variables” and “discriminability of a distance measure in the vicinity of x”  are abstract and lack concrete connections/motivations for the problem (sample based comparison of two high-dimensional data distributions) the paper is addressing.\n\nAfter an effective overview of relevant literature on GAN metrics, LID is briefly described and motivated in various ways. This is primarily a discussion of various high-level properties of the metric which for readers unfamiliar with the metric is difficult to concretely tie into the problem at hand. After this, the actual estimator of LID used from the literature (Amsaleg 2018) is introduced. Given that this estimator is the core of the paper, it seems a bit terse that the reader is left with primarily references to back up the use of this estimator and connect it to the abstract discussion of LID thus far.\n\nFigure 1 is a good quick overview of some of the behaviors of the metric but it is not clear why the MLE estimator of LID should be preferred (or perform any differently) on this toy example from a simple average of 1-NN distances. The same is also appears to be true for the motivating example in Figure 8 as well.\n\nTo summarize a bit, I found that the paper did not do the best job motivating and connecting the proposed metric to the task at hand and describing in an accessible fashion its potentially desirable properties.\n\nThe experimental section performs a variety of comparisons between CrossLID, Inception Score and FID. The general finding of the broader literature that Inception Score has some undesirable properties is confirmed here as well. A potentially strong result showing where CrossLID performs well at inter-class mode dropping, Figure 4, is unfortunately confounded with sample size as it tests FID in a setting using 100x lower than the recommended amount of samples. \n\nThe analysis in this section is primarily in the form of interpretation of visual graphs of the behavior of the metrics as a quantity is changed over different datasets. I have some concerns that design decisions around these graphs (normalizing scales, subtracting baseline values) could substantially change conclusions. \n\nAn oversampling algorithm based on CrossLID is also introduced which results in small improvements over a baseline DCGAN/WGAN and improves stability of a DCGAN when normalization is removed. A very similar oversampling approach could be tried with FID but is not - potentially leaving out a result demonstrating the effectiveness of CrossLID.\n\nThe paper also proposes computing CrossLID in the feature space of a discriminator to make the metric less reliant on an external model. While this is an interesting thing to showcase - FID can also be computed in an arbitrary feature space and the authors do not clarify or investigate whether FID performs similarly.\n\nThese two extensions, addressing mode collapse via oversampling and using the feature space of a discriminator are interesting proposals in the paper, but the authors do not do a thorough investigation of how CrossLID performs to FID here.\n\nSeveral experiments get into some unclear value judgements over what the behavior of an ideal metric should be. The authors of FID argue the opposite position of this paper that the metric should be sensitive to low-level changes in addition to high-level semantic content. It is unclear to me as the reader which side to take in this debate. \n\nI have some final concerns over the fact that the metric is not tested on open problems that GANs still struggle with. Current SOTA GANs can already generate convincing high-fidelity samples on MNIST, SVHN, and CIFAR10. Exclusively testing a new metric for the future of GAN evaluation on the problems of the past does not sit well with me. \n\nSome questions:\n* Could the authors comment on run time comparisons of the metric with FID/IS?\n* How much benefit is there from something like CrossLID compared to the simplest case of distance to 1-NN in feature space? More generally an analysis of how the benefits of CrossLID as you increase neighborhood size would help illuminate the behavior of the metric.\n* For Table 2, what are the FID scores and how do they correlate with CrossLID and Inception Score?\n\nPros: \n+ Code is available!\n+ The metric appears to be more robust than FID in small sample size settings.\n+ A variety of comparisons are made to several other metrics on three canonical datasets.\n+ The paper has two additional contributions in addition to the metric. Addressing mode collapse via adaptive oversampling and utilizing the features of the discriminator to compute the metric in.\nCons:\n- No error bars / confidence intervals are provided to show how sensitive the various metrics tested are to sample noise. \n- Authors test FID outside of recommended situations (very low #of samples (500) in Figure 4) without noting this is the case. The stated purpose of Figure 4 is to evaluate inter-class mode dropping yet this result is confounded by the extremely low N (100x lower than the recommended N for FID).\n- It is unclear whether metric continues to be reliable for more complex/varied image distributions such as Imagenet (see main text for more discussion)\n- Many of the proposed benefits of the model (mode specific dropping and not requiring an external model) can also be performed for FID but the paper does not note this or provide comparisons.\n']","[20, 60, -30]","[60, 50, 50]","[""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper's novelty, timeliness, and solid experimental setup, they also raise several significant concerns and suggest major revisions. The overall tone is constructive but leans towards skepticism about some of the paper's claims. The politeness score is 60 (moderately polite) as the reviewer uses professional language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also thanks the authors for their detailed responses at the end, indicating a respectful dialogue."", ""The sentiment score is 60 (positive) because the review starts with positive comments about the paper's clarity, motivation, and mathematical foundations. It also mentions that the experimental results are 'convincing and illustrative'. The reviewer lists more pros than cons, indicating an overall positive sentiment. However, it's not extremely positive due to the presence of some cons. The politeness score is 50 (slightly polite) because the language used is professional and constructive. The reviewer presents both pros and cons in a balanced manner without using harsh or critical language. They use phrases like 'seems to be' and 'would be useful' which soften potential criticisms. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, professional tone overall."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Code is available!', 'The metric appears to be more robust than FID in small sample size settings.'), the overall tone is critical. The review points out several shortcomings in the paper's methodology, presentation, and conclusions. The reviewer expresses concerns about the motivation, accessibility, and thoroughness of the research. However, the criticism is not entirely negative, which is why the score is not lower.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms ('I found that the paper did not do the best job...', 'I have some concerns...') rather than harsh or dismissive statements. The reviewer also acknowledges positive aspects of the paper and provides constructive feedback and questions for improvement. The tone is not overly formal or excessively polite, but it remains courteous and appropriate for academic discourse.""]"
"['This paper investigates a meta-learning approach for the contextual bandit problem. The goal is to learn a generic exploration policy from datasets, and then to apply the exploration policy to contextual bandit tasks. The authors have adapted an algorithm proposed for imitation learning (Ross & Bagnell 2014) to their setting. Some theoretical guarantees straightforwardly extracted from (Ross & Bagnell 2014) and from (Kakade et al 2008) are presented. Experiments are done on 300 supervised datasets.\n\nMajor concerns:\n\n1 This paper investigates a problem that does not correspond to the real problem: how to take advantage of a plenty of logs generated by a known stochastic policy (or worst unknown deterministic policy) for the same (or a close) contextual bandit task? \nMost of companies have this problem. I do not know a single use case, in which we have some full information datasets, which are representative of contextual bandit tasks to be performed. If the full information datasets does not correspond to the contextual bandit tasks, it is not possible to learn something useful for the contextual bandit task. \n\n2 The experimental validation is not convincing.\n\nThe experiments are done on datasets, which are mostly binary classification datasets. In this case, the exploration task is easy. May be it is the reason why the exploration parameter \\mu or \\epsilon = 0 provides the best results for MELEE or \\epsilon-greedy?\n\nThe baselines are not strong. The only tested contextual bandit algorithm is LinUCB. However a diagonal approximation of the covariance matrix is used when the dimension exceeds 150. In this case LinUCB is not efficient. There are a lot of contextual bandit algorithms that scale with the dimension.\n\n\n3 The theoretical guarantees are not convincing. \n\nThe result of Theorem 1 is a weak result. A linear regret against the expected reward of the best policy is usually considered as a loosely result. Theorem 2 shows that there is no theoretical gain of the use of the proposed algorithm: the upper bound of the expected number of mistakes obtained when Banditron is used in MELEE is upper than the one of Banditron alone.\n\nMinor concerns:\n\nThe algorithms are not well written. POLOPT function has sometimes one parameter, sometimes two and sometimes three parameters. The algorithm 1 is described in section 2, while one of the inputs of the algorithm 1 (feature extractor function) is described in section 3.1. The algorithm 1 seems to return all the N exploration policies. The choice of the returned policy has to be described.\n\nIn contextual bandits, the exploration policy is not handcrafted. The contextual bandit algorithms are designed to be optimal or near optimal in worst case: they are generic algorithms.\n', 'This paper proposes a new method (Melee) to explore on contextual bandits. It uses a supervised full information data set to evaluate (using counterfactual estimation) and select (using imitation learning) a proper exploration strategy. This exploration strategy is then used to augment an e-greedy contextual bandit algorithm.\n\nThe novelty is that the exploration strategy is learned from the data, as opposed to being engineered to minimize regret. The edge of Melee stems from the expected improvement for choosing an action against the standard bandit optimization recommendation.\n\nPros:\n- using data to learn exploration strategy in tis manner is a novel idea for bandits\n- good experimental results\n- well written paper\n\nCons:\n- Practical impact may be minimal. This setting is seldom encountered in reality.\n- No comparison with Thompson sampling bandits, which also use data in devising an exploration strategy. I suggest authors compare to better suited bandits and exploration strategies, beyond basic e-greedy and UCB.\n- Article assumes knowledge of imitation learning. which is not a given in bandit literature. I suggest a simple explanation or sketch of the imitation algorithm.\n- Theoretical guarantees questionable. Theorem 1 talks about ""no-regret algorithm"". you then extend this notion and claim ""if we can achieve low regret .... then ...."". It is unclear to me how this theorem allows you to make such claim. A low regret is > no-regret, and hence a bound on no-regret may not generalize to low regret.\n- May want to add noise to augmentation data, to judge robustness of method.\n\nOverall, given the novelty of the idea and the good results, I am inclined to accept, with major modifications. Improvements of the method and analysis are likely to follow. Given the flaws though, I am not fighting for this paper.\n\nMinor comments:\nsec 2.1: you may want to explain why you require reward to be [0,1]\nAlg 1: explain Val and rho in algorithm.\nsec 2.3: what is ""ergo"". Also, you may want to refer to f as ""function"" and to pi as ""policy"". referring to f as policy may be confusing (even though it is a policy). For example: ""(line 8) on which it trains a new policy""\nEnd of 2.4: ""as discussed in 2.4"" should be ""in 2.3""\nsec 3.3: why is epsilon=0 the best? is it because synthetic data has no noise? This result surprises me.\n\n\n\n\n', 'The paper proposes to train exploration policies for contextual bandit problems through imitation learning on synthetic data-sets. An exploration policy takes the decision of choosing an action on each time-step (balancing explore/exploit) based on the history, the confidences of taking different actions suggested by a policy optimizer (bet expert policy given the history). The idea in this paper is to generate many multi-class supervised learning data-sets and sun an imitation learning algorithm for training a good exploration policy. I think this is a novel idea and I have not seen this before. Moreover some intuitive features for training the exploration policy, like the historical counts of the arms, the time-step, arms rewards variances are used on top the the confidence scores from the policy optimizer. It is shown empirically that these extra features add value. \n\nOverall I think this is a well-written paper with very thorough experimentation. The results are also promising. It would be interesting to gain some insights from the learnt policy, in order to improve hand-designed policies. For example, in a few data-sets it would be interesting to see whether the learnt policy is similar to epsilon greedy in the early stages and switches to greedy after a point, or which of the hand-designed strategies like bagging/cover is the learnt policy most similar to in terms of choice of actions, however I am not sure how such an analysis can be done.  It would also be fair to discuss the offline training time and online run-time of the algorithm with respect to others.  Also, I think the paper should provide a brief introduction to imitation learning, as it is commonly not known in the bandit community. ']","[-70, 50, 80]","[20, 70, 70]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses 'major concerns' about the paper's problem formulation, experimental validation, and theoretical guarantees. They state that the paper investigates a problem that 'does not correspond to the real problem,' the experimental validation is 'not convincing,' and the theoretical guarantees are 'not convincing.' These are strong criticisms that indicate a negative sentiment towards the paper's core aspects. However, it's not at the extreme negative end as the reviewer does provide some constructive feedback and acknowledges some aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'Major concerns:' and 'Minor concerns:' to organize their feedback, which is a polite way to structure criticism. The language is not overtly rude, but it's also not particularly warm or encouraging, hence a slightly positive score rather than a neutral or negative one."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the idea and good experimental results, and is inclined to accept the paper with major modifications. However, they also point out several cons and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They maintain a professional tone, even when pointing out flaws, and use phrases like 'I suggest' rather than making demands. The reviewer also acknowledges the paper's strengths alongside its weaknesses, demonstrating a balanced and courteous approach to the review."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'novel', 'well-written', with 'thorough experimentation' and 'promising' results. The reviewer also mentions that they 'have not seen this before', indicating originality. The only slight criticism is a suggestion for additional analysis, but this is framed constructively. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise generously and frame their suggestions as interesting possibilities rather than demands. The use of phrases like 'I think' and 'It would be interesting' softens the tone, making it collaborative rather than critical. The reviewer also acknowledges the difficulty of implementing their suggestions ('I am not sure how such an analysis can be done'), showing consideration for the authors' perspective.""]"
"[""This paper tried to analyze the high-dimensional geometry of adversarial examples from a geometric framework. The authors explained that there exists a tradeoff between being robust to different norms. They further proved that it is insufficient to learn robust decision boundaries by training against adversarial examples drawn from balls around the training set. Moreover, this paper showed that nearest neighbor classifiers do not suffer from this insufficiency.\n \nIn general, I think this paper is very interesting and enlightening. The authors analyzed the most robust boundary of norm 2 and norm infinity in different dimensions through a simple example and concluded that the single decision boundary cannot be robust in different norms. In addition, the author started from a special manifold and proposed a bound (ratio of two volumes) to prove the insufficiency of the traditional adversarial training methods and then extended to arbitrary manifold. It is good that this might provide a new way to evaluate the robustness of adversarial training method. However, I have some concerns: 1) Is it rigorous to define the bound by vol_X/vol_pi? In my opinion, the ratio of the volume of intersection (X^\\del and \\pi^\\del) and vol \\pi^\\del may be more rigorous? 2) I don't know if such bound can be useful or easily applied in other work? In my opinion, it might be difficult, since the volume itself appears difficult to calculate. \nI think the paper is a bit complicated or heavy in mathematics, and not easy to follow (though I believe I have well understood it). Some typos and minor issues are also listed as below. \n\nMinor concerns:\n1. At the end of the introduction, 3 attacking methods, FGSM, BIM, and PGD, should be given their full names and also citations are necessary.\n2. Could you provide a specific example to illustrate the bound in Eq. (3), e.g. in the case of d=3, k=1.\n3. In Page 7, “Figure 4 (left) shows that this expression approaches 1 as the codimension (d-k) of Pi increases.”  I think, the subfigure shows that the ratio approaches 1 when d and k are all increased.\n"", 'This paper gives a theoretical analysis of adversarial examples, showing that (i) there exists a tradeoff between robustness in different norms, (ii) adversarial training is sample inefficient, and (iii) the nearest neighbor classifier can be robust under certain conditions. The biggest weakness of the paper is that theoretical analysis is done on a very synthetic dataset, whereas real datasets can hardly be conceived to exhibit similar properties. Furthermore, the authors do not give a bound on the probability that the sampling conditions for the robust nearest neighbor classifier (Theorem 1) will be satisfied, leading to potentially vacuous results.\n\nWhile I certainly agree that theoretical analysis of the adversarial example phenomenon is challenging, there have been prior work on both analyzing the robustness of k-NN classifiers (Wang et al., 2018 - http://proceedings.mlr.press/v80/wang18c/wang18c.pdf) and on demonstrating the curse of dimensionality as a major contributing factor to adversarial examples (Shafahi et al., 2018 - https://arxiv.org/abs/1809.02104, concurrent submission to ICLR). I am very much in favor of the field moving in these directions, but I do not think this submission is demonstrating any meaningful progress.\n\nPros:\n- Rigorous theoretical analysis.\n\nCons:\n- Results are proven for particular settings rather than relying on realistic data distribution assumptions.\n- Paper is poorly written. The authors use unnecessarily complicated jargon to explain simple concepts and the proofs are written to confuse the reader. This is especially a problem since the paper exceeds the suggested page limit of 8 pages.\n- While it is certain that nearest neighbor classifiers are robust to adversarial examples, their application is limited to only very simple datasets. This makes the robustness result lacking in applicability.\n- Weak experimental validation. The authors make repeat use of synthetic datasets and only validate their claim on MNIST as a real dataset.', 'This paper studies the geometry of adversarial examples under the assumption that dataset encountered in practice exhibit lower dimensional structure despite being embedded in very high dimensional input spaces. Under the proposed framework, the authors analyze several interesting phenomena and give theoretical results related to the necessary number of samples needed to achieves robustness. However, the theory in this paper is not very deep.\n\nPros:\n\nThe logic of this paper is very clear and easy to follow. Definitions and theories are illustrated with well-designed figures.\n\nThis paper shows the tradeoff between robustness under two norm and infinity norm for the case when the manifolds of two classes of data are concentric spheres.\n\nWhen data are distributed on a hypercube in a k dimensional subspace, the authors show that balls with radius \\delta centered at data samples only covers a small part of the ‘\\delta neighborhood’ of the manifold. \n\nGeneral theoretical results on robustness and minimum training set to guarantee robustness are given for nearest neighbor classifiers and other classifiers.\n\nCons:\n\nMost of the theoretical results in this paper are not very general. The tradeoff between robustness in different norms are only shown for concentric spheres; the ‘X^\\epsilon is a poor model of \\mathcal{M}^\\epsilon’ section is only shown for hypercubes in low dimensional subspaces. \n\nSection 5 is not very convincing. As is discussed later in the paper, although $X^\\delta$ only covers a small part of \\mathcal{M}^\\delta, robustness can be achieved by using balls centered at samples with larger radius.\n\nMost of the analysis is based on the assumption that samples are perfectly distributed to achieve the best possible robustness result. A more interesting case is probably when samples are generated on the manifold following some probabilistic distributions. \n\nTheorems given in Section 6 are reasonable, but not very significant. It is not very surprising that nearest neighbor classifier is more robust than ‘x^\\epsilon based’ algorithms, especially when the samples are perfectly distributed. \n']","[60, -60, 20]","[70, -20, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by stating the paper is 'very interesting and enlightening' and praises several aspects of the work. However, they also express some concerns and suggest the paper is complicated, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I have some concerns'), and offers specific suggestions for improvement. The tone is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several weaknesses of the paper, including the use of synthetic datasets, potentially vacuous results, and lack of meaningful progress. The few positive aspects mentioned (rigorous theoretical analysis) are outweighed by the criticisms. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism. Phrases like 'poorly written,' 'unnecessarily complicated jargon,' and 'proofs are written to confuse the reader' are quite harsh and contribute to a less polite tone. The reviewer does acknowledge some positive aspects and uses some neutral language, which prevents the score from being even lower."", ""The sentiment score is slightly positive (20) because the review begins with a neutral summary of the paper's content, followed by a balanced list of pros and cons. The reviewer acknowledges the paper's clear logic, well-designed figures, and interesting theoretical results, which are positive aspects. However, they also point out limitations such as the lack of depth in the theory and the limited generalizability of some results, which tempers the overall sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to present both the strengths and weaknesses of the paper, avoiding harsh criticism or overly effusive praise. The reviewer's approach of listing pros and cons separately also contributes to the polite and constructive nature of the feedback.""]"
"['This work proposes a hybrid VAE-based model (combined with an adversarial or maximum mean discrepancy (MMD) based loss) to perform timbre transfer on recordings of musical instruments. Contrary to previous work, a single (conditioned) decoder is used for all instrument domains, which means a single model can be used to convert any source domain to any target domain.\n\nUnfortunately, the results are quite disappointing in terms of sound quality, and feature many artifacts. The instruments are often unrecognisable, although with knowledge of the target domain, some of its characteristics can be identified. The many-to-many results are clearly better than the pairwise results in this regard, but in the context of musical timbre transfer, I don\'t feel that this model successfully achieves its goal -- the results of Mor et al. (2018), although not perfect either, were better in this regard.\n\nI have several further concerns about this work:\n\n* The fact that the model makes use of pitch class and octave labels also raises questions about applicability -- if I understood correctly, transfer can only be done when this information is present. I think the main point of transfer over a regular generative model that goes from labels to audio is precisely that it can be done without label information.\n\n* The use of fully connected layers also implies that it requires fixed length input, so windowing and stitching are necessary for it to be applied to recordings of arbitrary length. Why not train a convolutional model instead?\n\n* I think the choice of a 3-dimensional latent space is poorly justified. Why not use more dimensions and project them down to 3 for visualisation and interpetation purposes with e.g. PCA or t-SNE? This seems like an unnecessary bottleneck in the model, and could partly explain the relatively poor quality of the results.\n\nI appreciated that the one-to-one transfer experiments are incremental comparisons, which provides valuable information about how much each idea contributes to the final performance.\n\nOverall, I feel that this paper falls short of what it promises, so I cannot recommend acceptance at this time.\n\n\n\nOther comments:\n\n* In the introduction, an adversarial criterion is referred to as a ""discriminative objective"", but ""adversarial"" (i.e. featuring a discriminator) and ""discriminative"" mean different things. I don\'t think it is correct to refer to an adversarial criterion as discriminative.\n\n* Also in the introduction, it is implied that style transfer constitutes an advance in generative models, but style transfer does not make use of / does not equate to any generative model.\n\n* Some turns of phrase like ""recently gained a flourishing interest"", ""there is still a wide gap in quality of results"", ""which implies a variety of underlying factors"", ... are vague / do not make much sense and should probably be reformulated to enhance readability.\n\n* Introduction, top of page 2: should read ""does not learn"" instead of ""do not learns"".\n\n* Mor et al. (2018) do actually make use of an adversarial training criterion (referred to as a ""domain confusion loss""), contrary to what is claimed in the introduction.\n\n* The claim that training a separate decoder for each domain necessarily leads to prohibitive training times is dubious -- a single conditional decoder would arguably need more capacity than each individual separate decoder model. I think all claims about running time should be corroborated by controlled experiments.\n\n* I think Figure 1 is great and helps a lot to distinguish the different domain translation paradigms.\n\n* I found the description in Section 3.1 a bit confusing as it initially seems that the approach requires paired data (e.g. ""matching samples"").\n\n* Section 3.1, ""amounts to optimizing"" instead of ""amounts to optimize""\n\n* Higgins et al. (2016) specifically discuss the case where beta in formula (1) is larger than one. As far as I can tell, beta is annealed from 0 to 1 here, which is an idea that goes back to ""Generating Sentences from a Continuous Space"" by Bowman et al. (2016). This should probably be cited instead.\n\n* ""circle-consistency"" should read ""cycle-consistency"" everywhere.\n\n* MMD losses in the context of GANs have also been studied in the following papers:\n- ""Training generative neural networks via Maximum Mean Discrepancy optimization"", Dziugaite et al. (2015)\n- ""Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy"", Sutherland et al. (2016)\n- ""MMD GAN: Towards Deeper Understanding of Moment Matching Network"", Li et al. (2017)\n\n* The model name ""FILM-poi"" is only used in the ""implementation details"" section, it doesn\'t seem to be referred to anywhere else. Is this a typo?\n\n* The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I\'m not convinced that they are significant. Why does the MMD version constitute an improvement? Or is it simply more stable to train?\n\n* The descriptor distributions in Figure 3 don\'t look like an ""almost exact match"" to me (as claimed in the text). There are some clearly visible differences. I think the wording is a bit too strong here.', 'Summary\n-------\nThis paper describes a model for musical timbre transfer which builds on recent developments in domain- and style transfer.\nThe proposed method is designed to be many-to-many, and uses a single pair of encoders and decoders with additional conditioning inputs to select the source and target domains (timbres).\nThe method is evaluated on a collection of individual note-level recordings from 12 instruments, grouped into four families which are used as domains.\nThe method is compared against the UNIT model under a variety of training conditions, and evaluated for within-domain reconstruction and transfer accuracy as measured by maximum mean discrepancy.\nThe proposed model seems to improve on the transfer accuracy, with a slight hit to reconstruction accuracy.\nQualitative investigation demonstrates that the learned representation can approximate several coarse spectral descriptors of the target domains.\n\n\nHigh-level comments\n-------------------\nOverall, this paper is well written, and the various design choices seem well-motivated.\n\nThe empirical comparisons to UNIT are reasonably thorough, though I would have preferred more in-depth evaluation of the MoVE model as well.  Specifically, the authors introduced an extra input (control) to encode the pitch class and octave information during encoding.  I infer that this was necessary to achieve good performance, but it would be instructive to see the results without this additional input, since it does in a sense constitute a form of supervision, and therefore limits the types of training data which can be used.\n\nWhile I understand that quantifying performance in this application is difficult, I do find the results difficult to interpret.  Some of this comes down to incomplete definition of the metrics (see detailed comments below).\nHowever, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer). The transfer metrics (MMD and kNN) are opaque to the reader: for instance, in table 1, is a knn score of 43173 qualitatively different than 43180?  What is the criteria for bolding here?  It would be helpful if these scores could be calibrated in some way, e.g., with reference to\nMMD/KNN scores of random partitions of the target domain samples.\n\nSince the authors do additional information here for each sample (notes), it would be possible to pair generated and real examples by instrument and note, rather than (in addition to) unsupervised, feature-space pairing by MMD.  This could provide a slightly stronger version of the comparison in Figure 3, which shows that the overall distribution of spectral centroids is approximated by transfer, but does not demonstrate per-sample correspondence.\n\n\n\nDetailed comments\n-----------------\nAt several points in the manuscript, the authors refer to ""invertible"" representations (e.g., page 4, just after eq. 1), but it seems like what they mean is approximately invertible or decodable.  It would be better if the authors were a little more careful in their use of terminology here.\n\nIn the definition of the RBF kernel (page 4), why is there a summation? \n What does this index? How are the kernel bandwidths defined?\n\nHow exactly are reconstruction errors calculated: using the NSGT magnitude representation, or after resynthesis in the time domain?\n', 'The authors proposed a Modulated Variational auto-Encoders (MoVE) to perform musical timbre transfer. The authors define timbre transfer as applying parts of the auditory properties of a musical instrument onto another. It replaces the usual adversarial translation criterion by a Maximum Mean Discrepancy (MMD) objective. By further conditioning our system on several different instruments, the proposed method can generalize to many-to-many transfer within a single variational architecture able to perform multi-domain transfers.\nSome detailed comments are listed as follow,\n1 The implementation steps of the proposed method (MoVE) are not clear. Some details are missing, which is hardly reproduced by the other researchers.\n2 The experimental settings are not reasonable. The current experimental settings are not matched with the practice environment. \n3 The proposed method can transfer the positive knowledge. However, some negative knowledge information can be also transferred. So how to avoid the negative transferring? \n4 For the model, the optimization details or inferring details are missing, which are important for the proposed model.\n']","[-60, 50, -20]","[20, 75, 50]","[""The sentiment score is -60 because the review is largely negative, stating the results are 'quite disappointing' and that the paper 'falls short of what it promises'. The reviewer cannot recommend acceptance. However, it's not entirely negative as they do acknowledge some positive aspects like the incremental comparisons and the helpful Figure 1. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I appreciated that...' and provide specific, actionable feedback. The language is not overly harsh, but rather aims to be helpful while still conveying the significant concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer states the paper is 'well written' and the design choices are 'well-motivated', indicating overall approval. However, they also raise several concerns and suggestions for improvement, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I would have preferred' and 'it would be helpful if' rather than making demands. The reviewer also provides detailed explanations for their suggestions, showing engagement with the work. The tone remains professional and courteous throughout, even when pointing out areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the proposed method in the first paragraph, the subsequent comments are all critical, pointing out missing details, unreasonable experimental settings, and potential issues with negative knowledge transfer. These criticisms outweigh the initial positive acknowledgment. The politeness score is moderately positive (50) because the reviewer uses neutral language and frames criticisms as 'comments' rather than direct attacks. The use of phrases like 'Some detailed comments are listed as follow' maintains a professional tone. However, the review doesn't go out of its way to be overtly polite or encouraging, keeping it from scoring higher on the politeness scale.""]"
"['This paper proposes a new application of embedding techniques for mathematical problem retrieval in adaptive tutoring. The proposed method performs much better than baseline sentence embedding methods. Another contribution is on using negative pre-training to deal with an imbalanced training dataset. \n\nTo me this paper is just not good enough - the method essentially i) use ""a professor and two teaching assistants"" to build a ""rule-based concept extractor"" for problems, then ii) map problems into this ""concept space"" and simply treat them as words. There are several problems with this approach. \n\nFirst, doing so does not touch the core of the proposed application. For tutoring applications, the most important thing is to select a problem that can help students improve; even if you can indeed select a problem that is the most similar to another problem, is it the best one to show a student? There are no evaluations on real students in the paper. Moreover, the main difference between math problems and other problems is that there are math expressions; I do not think that using words/concept labels only is enough without touching on the math expressions.\n\nSecond, the proposed method does not sound scalable - the use of a professor and two teaching assistants to construct the concept extractor, and the use of an expert TA to select a small set of informative words. I am not sure how this will generalize to a larger number of problem spanning many different domains.\n\nI also had a hard time going through the paper - there aren\'t many details. Section 2.1 is where the method is proposed, yet most of the descriptions there are unclear. Without these details it is impossible to judge the novelty of the ""rule-based concept extractor"", which is the key technical innovation.', 'This paper proposes a method for mathematical problem embedding, which firstly decomposes problems into concepts by an abstraction step and then trains a skip-gram model to learn concept embedding. A problem can be represented as the average concept (corresponding to those in the problem) embeddings. To handle the imbalanced dataset, a negative pre-training method is proposed to decrease false and false positives. Experimental results show that the proposed method works much better than baselines in similar problem detection, on an undergraduate probability data set. \nStrong points:\n(1)\tThe idea of decomposing problems into concepts is interesting and also makes sense. \n(2)\tThe training method for imbalanced datasets is impressive. \nConcerns or suggestions:\n1.\tThe main idea of using contents to represent a problem is quite simple and straightforward. The contribution of this paper seems more on the training method for imbalanced data sets. But there are no comparisons between the proposed training method and previous related works. Actually, imbalance data sets are common in machine learning problems and there are many related works. The comparisons are also absent in experiments.\n2.\tThe experimental data set is too small, with only 635 problems. It is difficult to judge the performance of the proposed model based on so small data set. \n3.\tThe proposed method, which decomposes a problem into multiple concepts, looks general for many problem settings. For example, representing a movie or news article by tags or topics. In this way, the proposed method can be tested in a broader domain and on larger datasets.\n4.\tFor the final purpose, comparing problem similarity, I am wondering what the result will be if we train a supervised model based problem-problem similarity labels?', 'The paper proposed a hierarchical framework for problem embedding and intended to apply it to adaptive tutoring. The system first used a rule-based method to extract the concepts for problems and then learned the concept embeddings and used them for problem representation. In addition, the paper further proposed negative pre-training for training with imbalanced data sets to decrease false negatives and positives. The methods are compared with some other word-embedding based methods and showed 100% accuracy in a similarity detection test on a very small dataset. \n\nIn sum, the paper has a very good application but not good enough as a research paper. Some of the problems are listed as follows:\n1.\tLack of technical novelty.  It seems to me just a combination of several mature techniques. I do not see much insight into the problem. For example, if the rule-based concept extractor can already extract concepts very well, the “problem retrieval” should be solved by searching with the concepts as queries. Why should we use embedding to compare the similarity? Also, the title of the paper is about problem retrieval but the experiments are about similarity comparison, there seems a gap. \n2.\tData size is too small, and the baselines are not state-of-the-art. There are some unsupervised sentence embedding methods other than the word-embedding based models. \nSome clarity issues. For example, Page 6. “is pre-trained on a pure set of negative samples”— what is the objective function? How to train on only negative samples?\n']","[-70, 20, -50]","[-20, 60, 20]","[""The sentiment score is -70 because the reviewer expresses strong negative opinions about the paper, stating it's 'just not good enough' and listing several significant problems with the approach. They criticize the method's relevance, scalability, and lack of detail. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and dismissive. Phrases like 'just not good enough' and 'I had a hard time going through the paper' come across as somewhat impolite. The reviewer doesn't soften their criticisms or offer many positive comments, which contributes to the slightly negative politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some strong points of the paper, such as the interesting idea of decomposing problems into concepts and the impressive training method for imbalanced datasets. However, the reviewer also raises several concerns and suggestions, which temper the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, presenting both positive aspects and concerns in a constructive manner. The reviewer uses phrases like 'interesting,' 'impressive,' and 'I am wondering,' which contribute to a polite tone. The concerns are framed as suggestions rather than harsh criticisms, further maintaining a courteous approach."", ""The sentiment score is -50 because the review starts with some positive aspects but quickly shifts to a more critical tone, stating that the paper is 'not good enough as a research paper' and listing several significant problems. The reviewer points out lack of technical novelty, small data size, and clarity issues, which outweigh the initial positive comments. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively neutral language and provide specific, constructive feedback. Phrases like 'It seems to me' and 'Some clarity issues' soften the criticism slightly. The reviewer also acknowledges the 'very good application' at the beginning, showing some politeness in recognizing positive aspects before critiquing.""]"
"[""Paper summary:\n\nGiven a pre-trained VAE (e.g. over images), this paper is about inferring the distribution over missing variables (e.g. given half the pixels, what is a plausible completion?). The paper describes an approach based on variational inference with normalizing flows: given observed variables, the posterior over the VAE's latents is inferred (variationally) and plausible completions for missing variables are sampled from the VAE decoder.\n\nTechnical quality:\n\nThe presented method is technically correct. The evaluation carefully compares different types of normalizing flow and HMC, and seems to follow good practices.\n\nI have a suggestion for improving the GVI method. The way it's described in the paper, GVI requires computing the determinant of a DxD matrix, which costs O(D^3), and there is no guarantee that the matrix is invertible. However, this approach over-parameterizes the covariance matrix of the modelled Gaussian. Without losing any flexibility, you can use a lower triangular matrix with strictly positive diagonal elements (e.g. the diagonal elements can be parameterized as the exp of unconstrained variables). That way, the determinant costs O(D) (it's just the product of diagonal elements) and you ensure that the matrix is invertible (because the determinant is strictly positive), without hurting expressivity. You can think of this as parameterizing the Cholesky decomposition of the covariance matrix.\n\nAlso, there are more flexible normalizing flows, such as Inverse Autoregressive Flow, that can be used instead of the planar flow used in the paper.\n\nClarity:\n\nThe paper is written clearly and in full detail, and the mathematical exposition is clear and precise.\n\nSome typos and minor suggestions for improvement:\n- It'd be good to move Alg. 1 and Fig. 1 near where they are first referenced.\n- Page 2: over to \\theta --> over \\theta\n- Eq. 3: p_\\theta appears twice in the middle.\n- one can use MCMC to attempt sampling --> one can use MCMC to sample\n- Eq. 5: should be q_\\psi as subscript of E.\n- Fig. 7, caption: should be GVI vs. NF.\n- In references, should be properly capitalized: Hamiltonian, Langevin, Monte Carlo, Bayes, BFGS\n- Lemma 1: joint divergence is equivalent to --> joint divergence is equal to\n- Lemma 1: in the chain rule for KL, the second KL term should be averaged w.r.t. its free variables.\n\nOriginality:\n\nIn my opinion, there is little original contribution in this paper. The inference method presented (variational inference with normalizing flows) is well-known and already in use. The paper applies this method to VAEs, which is a straightforward application of a well-known inference method to a relatively simple graphical model (z -> {x, y}, with x, y independent given z).\n\nI don't see the need for introducing a new term (cross-coder). According to the paper, a cross-coder is precisely a normalizing flow (i.e. an invertible smooth transformation of a simple density). I think new terms for already existing ideas add cognitive load to the community, and are better avoided.\n\nSignificance:\n\nIn my opinion, constructing generative models that can handle arbitrary patterns of missing data is an important research direction. However, this is not exactly what the paper is about: the paper is about inference in a given generative model. Given that there is (in my opinion) no new methodology in the paper, I wouldn't consider this paper a significant contribution.\n\nI would also suggest that in a future version of the paper there is more motivation (e.g. in the introduction) of why the problem the paper is concerned with (i.e. missing data in generative models) is significant. Is it just for image completion / data imputation, or are there other practical problems? Is it important as part of another method / solution to another problem?\n\nReview summary:\n\nPros:\n- Technically correct, gives full detail.\n- Well and clearly written, precise with maths.\n- Evaluation section interesting to read.\n\nCons:\n- No original contribution.\n- Could do a better job motivating the importance of the problem.\n\nMinor points:\n- I don't completely agree with the way VAEs are described in sec. 2.1. As written, it follows that VAEs must have a Gaussian prior and a conditionally independent decoder. Although these are common choices in practice, they are not necessary: for example, one could take the prior to be a Masked Autoregressive Flow and the decoder a PixelCNN.\n- Same for observation 1. This is not an observation, but an assumption; that is, the paper assumes that the decoder is conditionally independent. This is of course an assumption that we can satisfy by design, but it's a design choice that restricts the decoder in a specific way."", 'This paper proposes the use of unamortized Black Box Variational Inference for data imputation (given a fixed VAE with a factorized decoder), where the choice of variational distribution is a standard flow model. \n\nThe exploitation of the decoder factorization and the choice to set q(y | z) = p(y | z) was explored in the Bottleneck Conditional Density Estimation paper.\n\nTo my understanding, this paper fails to contextualize their work with the existing literature and is simply an exercise in the rote application of existing inference procedures to a well-established inference problem (data imputation). \n\nUnless the authors can convince me of the novelty of their approach or what I have overlooked in their proposal, I do not recommend this paper for acceptance.\n\nReferences:\nRanganath, et al. Black Box Variational Inference. AISTATS 2014.\nShu, et al. Bottleneck Conditional Density Estimation. ICML 2017.', '(apologies for this belated review)\n\nSummary\n\nThe authors consider the task of imputing missing data using variational auto-encoders. To do so, they assume a fixed pre-trained generative model, perform variational inference to infer a posterior on latent variables given a partial image, and then use this approximate posterior to predict missing pixels. They compare a variety of parameterizations of the variational distribution to HMC inference, and evaluate on MNIST, Celeb-A and the Anime data. \n\nComments\n\nThere are many things about this paper that I don’t understand. My main concern is that I fail to follow why the authors are interested in this task. In what settings would we be interested in performing non-autoencoding variational inference in order to impute missing data? Moreover, in cases where are interested in performing such imputations, what would we like to use the results for? This paper seems like a nice demo, but I’m not entirely convinced I see a compelling application. \n\nMy second concern is about the baselines that are considered. If I were interested in carrying out this inference task, my inclination would not be to run an HMC chain to convergence, but instead to do something like annealed importance sampling (AIS), where at each step I run an iteration of HMC on a large batch of samples on a sequence of target densities that interpolate between the prior and full joint p(x, Z). If computational cost is a concern, I imagine this would not be more expensive than training a density estimator. Moreover, whereas HMC is generally not known to be a good method for estimating marginal likelihoods, AIS methods generally perform much better.\n\nFinally I find the language used in this paper confusing. Cross-coding seems a misnomer for the technique that the authors propose. Isn’t this simply a form of variational inference in which qψ(Z) approximates pθ(Ζ | x)? The term “-coding” suggests that we somehow define an encoder that accepts the query as input. Moreover, isn’t the XCoder network just a neural density estimator? \n\nFinally, Lemma 1 seems like a really roundabout way of deriving a lower bound. The authors could instead just write:\n\n\tlog p(x)\n\t>=\n\tE_q(Z,Y)[log p(x, Y, Z) - log q(Z, Υ)]\n\t=\n\tE_q(Z,Y)[log p(x | Ζ) + log p(Y | Z) + log p(Z) - log q(Z) - log p(Υ | Z)]\n\t=\n\tE_q(Z,Y)[log p(x | Ζ) + log p(Z) - log q(Z)]\n\t=\n\tE_q(Z)[log p(x, Ζ) - log q(Z)]\n\nThis avoids confusing terminology such as cross-coding, and shows that what the authors are doing is in fact just variational inference. Am I missing something here?\n\nI am also confused about how the comparison to HMC is set up. If you’re training qψ(Z), then you presumably need generate a certain number samples at training time. Shouldn’t you add this number of samples number of samples you generate in HMC, in order to get a more apples to apples comparison in terms of the amount of computation performed? As it stands, it is hard to evaluate whether these methods are given a similar number of samples. \n\nFinally, I am not quite sure what to make of the experimental evaluation. We see some scatter plots on MNIST with a 2D latent space, and some faces of celebrities in which there is arguably some sample diversity, although most of this diversity arises in blurry looking hairstyles. However, since the authors condition on the eyes, rather than, say, the nose or mouth, it is hard to know how good a job the network is doing at generalizing to multiple plausible faces. \n\nOverall, I find it difficult to judge the merit of this paper. Is this task in fact hard? Is it useful? Are the results good? Maybe the authors can give us some additional guidance on these questions.\n\nQuestions\n\n- I’m a bit worried that not all the samples that we see in Figure 6 may have equally high probability under the posterior. Could the authors compute and report importance weights?\n\n\tW = p(x, Z) / q(Z)\n\t\n- Could the authors say something about the effective sample size that we obtain when using the learned distribution q(Z) as a proposal? \n\t\n\tESS = (Σ_k w^k)^2 / (Σ_k (w^k)^2)\n\n- Should it be the case that the ESS is low, and the weights are high variance, could the authors generate a sufficient number of samples to ensure the the ESS = 25 (i.e. the number of images in the figure) and then show the 25 highest-weight samples (or resample 25 images with probability proportional to their weight)?\n\n\t\nMinor \n\n\n- Equation (3): There’s an extra p_θ in the first integral\n\n- In the proof in Appendix 6.1 \n\n\tKL[ qψ(Z) ‖ pθ(Z | x) ] + KL[ qψ(Y | Z) ‖ pθ(Y | Z, x)]\n\nit would be clearer to explicitly denote the expectation over qψ(Z)\n\n\tKL[ qψ(Z) ‖ pθ(Z | x) ] + E_qψ(Z)[ KL[ qψ(Y | Z) ‖ pθ(Y | Z, x)] ]\n\t\n(I had to google lecture notes to find out that this expectation is sometimes implicit, which \nas far as I know is not very standard). \n']","[-20, -80, -50]","[60, -20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('technically correct', 'well and clearly written'), they also express significant criticisms. The reviewer states there is 'little original contribution' and doesn't consider the paper 'a significant contribution'. However, the tone isn't entirely negative, as they offer constructive feedback and suggestions for improvement. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offers balanced feedback with both pros and cons, and phrases criticisms constructively (e.g. 'I would suggest', 'In my opinion'). They also acknowledge the paper's strengths and provide detailed, helpful feedback for improvement, which demonstrates respect for the authors' work."", ""The sentiment score is -80 because the reviewer expresses strong negative sentiment towards the paper. They state that the paper 'fails to contextualize their work' and is 'simply an exercise in the rote application of existing inference procedures'. The reviewer also does not recommend the paper for acceptance, which is a clear negative sentiment. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is quite dismissive and critical. Phrases like 'fails to contextualize' and 'simply an exercise in rote application' come across as somewhat harsh. The reviewer also directly challenges the authors to convince them of the novelty, which could be seen as slightly confrontational. However, they do use some neutral language and provide references, which prevents the score from being extremely low."", ""The sentiment score is -50 because the reviewer expresses several significant concerns and criticisms about the paper, including lack of clarity on the task's importance, questionable baselines, confusing terminology, and unclear experimental evaluation. However, they do acknowledge some positive aspects like 'nice demo' and 'arguably some sample diversity', preventing an extremely negative score. The politeness score is 20 because while the reviewer maintains a professional tone and offers constructive feedback, they use some direct language like 'I fail to follow' and 'I find it difficult to judge the merit of this paper'. The reviewer also apologizes for the late review and phrases some criticisms as questions, which adds to the politeness. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['In this paper, the authors study the problem if learning for observation, a reinforcement learning setting where an agent is given a data set of experiences from a potentially arbitrary number of demonstrators. The authors propose a method which deploys these experience to initialize a place. Then estimate the value of this policy in order to improve it.\n\nThe paper is well written and it is easy to follow. \n\nMost of the theoretical results are interesting and the derivations are kinda straightforward but not fully matching the main claim in the paper. Mainly the contribution in this paper heavily depends on an assumption that Q^D and Q^\\beta are close to each other. This assumption simplifies the many things resulting in a simple algorithm. But this assumption is too strong while the main challenge in the line of learning from observation comes from the fact that this assumption does not hold. Under this assumption and the similarity in distributions mentioned in proposition 4.2 make the contribution of this paper significantly weak.\n\nPlease let me know if you do not actually use this assumption in your results and justification.', ""The paper plugs the ideas of TRPO/PPO into the value based RL. Though there is no big surprise in terms of the tools used, this is interesting to know that safe policy improvement is possible in this setting. \n\nNevertheless for a conference as ICLR which is interested in the performance of ML tools, I have two concerns:\n\n- The scores obtained on all tests tasks on Atari game are quite far from the state of the art. As an example OpenAI announced to be able to score 74k at Montezuma's revenge with a single demonstration using PPO and a carefull selection of the initializations states (see  blog post https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration/). I understand that the setting is not directly comparable but the goal of RL is to learn good policies. This remark would vanish is the authors could come with a real use case where for some reason their approach is the best performer.\n\n- The proposed approach is benchmarked wrt few algorithms while there exist a lot in the safe RL literature. The setting is often slightly different but adaptation is often possible. In particular I'd like more positioning wrt what is proposed by the work of Petrik&all (https://papers.nips.cc/paper/6294-safe-policy-improvement-by-minimizing-robust-baseline-regret.pdf the paper is cited but the first author is incorrect). What are the deep differences that make this paper setting more interesting (in terms of what can be done from an applied perspective) or more challenging in terms of mathematical tools. Here I feel the core difference is a comparison against an average of policies which becomes the new baseline to beat.\n\nAlso not that at EWRL'18 an alternative approach for value based safe RL was presented https://arxiv.org/pdf/1712.06924.pdf\n"", 'The paper looks at learning a policy from multiple demonstrators which should also be safely improved by an reinforcement learning signal. They define the policy as a mixture of policies from the single demonstrators. The paper gives a new way to estimate the value function of each policy where the overall policy is defined as mixture of the single policies. The paper subsequently looks at the standard error of the value function estimation and then define the policy improvement step in the presence of value estimation error. The resulting reroute constraint for the policy improvement step is evaluated on the taxi toy task as well as on 4 different atari domains. \n\nThis paper presents an interesting ideas which is also based on an exhaustive theoretical derivation. However, the paper is lacking clarity and motivation which makes it almost impossible to understand at the first pass. Moreover, the presented results are promising but not exhaustive and the resulting algorithm is also restricted to discrete action domains. More comments see below:\n\n- The paper consists of 2 parts, the average behavior policy and its value function and the safe policy improvement step. The relation between these two parts are not clear. Is the policy improvement step only working if the policy is defined as in section 4 and the value function computed as in section 4? \n- Proposition 4.2 needs to be much better motivated and explained. It is totally unclear at this part of the paper why proposition 4.2 is used.\n- Please explain why proposition 4.2 indicates that Q^D \\approx Q^\\beta\n- The selection type of S in the taxi example is also unclear.\n- How would we solve Equation 8 with continuous actions / parametrized policies \\pi? Without this extension, the algorithm is quite restricted. \n- the figure captions need to be much more exhaustive. I am not sure I understand the x axis of Figure 4 (right). What iterations are shown here? We only do one improvement step of the behavior policy, without any resembling, is that right?\n- Could we also use a similar policy update for policy improvement in reinforcement learning?\n- Could you add an algorithm box for estimating the Q-function? Do we estimate every Q-function in isolation using MC estimates and then just use the weighted average?\n- It would be interesting to also compare the value function learning method proposed in the paper in isolation to other value function learning methods such as DQN. while the presented method is simple (learn from MC estimates), this is also known to be very data inefficient.\n']","[-20, -20, -20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'easy to follow', 'interesting' theoretical results), they express significant concerns about the paper's main contribution. The reviewer states that the paper's assumption is 'too strong' and makes the contribution 'significantly weak'. This criticism outweighs the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. The reviewer also asks for clarification politely at the end, showing consideration for the authors' perspective. The language is professional and avoids harsh or rude phrasing, maintaining a courteous tone even when expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting aspects, they express significant concerns about the performance and benchmarking. The reviewer states that the scores are 'quite far from the state of the art' and requests more comparisons with existing algorithms. However, it's not entirely negative as they recognize the paper's contribution to safe policy improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism. They phrase their concerns as suggestions for improvement rather than outright criticisms, using phrases like 'I'd like more positioning' and 'This remark would vanish if...'. The tone is professional and constructive, offering specific examples and references to support their points."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents 'interesting ideas' and 'promising' results, they also state that the paper 'is lacking clarity and motivation' and is 'almost impossible to understand at the first pass'. The reviewer also points out several limitations and areas needing improvement. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges positive aspects of the paper, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'Please explain', 'It would be interesting to', and 'Could you add' which maintain a constructive tone. The reviewer also provides specific, detailed feedback which is helpful and considerate to the authors.""]"
"['The submission presents an extension to the Allamanis et al ICLR\'18 paper on learning from programs as graphs. The core contribution is the idea of introducing extra nodes and edges into the graph that correspond to (potentially rare) subwords used in the analyzed program code. Experiments show that this extended graph leads to better performance on two tasks, compared to a wide range of baseline methods.\n\nOverall, this is a nice paper with a small, incremental idea and substantial experiments that show its practical value. I only have minor comments / questions on the actual core content. However, the contribution is very incremental and of interest to a specialized subsegment of the ICLR audience, so it may be appropriate to reject the paper and redirect the authors to a more specialized venue.\n\nMinor comments:\n- There\'s a bunch of places where \\citep/\\citet are mixed up (e.g., second to last paragraph of page 2). It would make sense to go through the paper one more time to clean this up.\n- Sect. 4: I understand the need to introduce context, but it feels that more space should be spent on the actual contribution here (step 3). For example, it remains unclear why this extra nodes / edges are only introduced for subwords appearing in variables - why not also for field names / method names?\n- Sect. 5: It would be helpful if the authors would explicitly handle the code duplication problem (Lopes et al., OOPSLA\'17), or discuss how they avoided these problems. Duplicated data files occurring in several folds are a significant risk to the validity of their experimental findings, and very common in code corpora.\n- Table 1: It is unclear to me what the ""Pointer Sentinel"" model can achieve. Without edges connecting the additional words to where they occur, it seems that this should not be performing different than ""Closed Vocab"", apart from noise introduced by additional nodes.\n- Table 1: Do Pointer Sentinel/GSC use a CharCNN to embed node labels of nodes that are not part of the ""cache"", or a closed vocabulary? [i.e., what\'s the embedding of a variable ""foo""?] If not, what is the performance of the GSC model with CharCNN-embeddings everywhere? That would be architecturally simpler than the split variant, and so may be of interest.\n- Page 6: When truncating to 500 nodes per graph: How many graphs in your dataset are larger than that?\n- Page 7: Do you really use attention over all nodes, instead of only nodes corresponding to variables? How do you deal with results where the model picks a non-variable (e.g., a corresponding cache node)? Does this happen?\n', 'The paper introduces a new way to use a subword embedding model 2 tasks related to codes: fill-in-blank and variable naming. \n\n* pros: \n- the paper is very well written. \n- the model is easily to reimplement. \n- the experiments are solid and the results are convincing. \n\n* cons: \n- the title is very misleading. In fact, what the paper does is to use a very shallow subword embedding method for names. This approach is widely used in NLP, especially in machine translation. \n- the work is progressing, meaning that most of it is based on another work (i.e. Allamanis et al 2018). \n\n* questions: \n- how to build the (subword) vocabulary? \n', '(updated with some summaries from discussion over the initial review)\n\nThe paper discusses the topics of predicting out-of-vocabulary tokens in programs abstract syntax trees. This could have application in code completion and more concretely two tasks are evaluated:\n - predicting a missing reference to a variable (called FillInTheBlank)\n - predicting a name of a variable (NameMe)\n\nUnfortunately, the paper proposes overly complex and strange formulations of these tasks, heavy implementation with unnecessary (non-motivated) neural architectures and as a result, does not demonstrate state-of-the-art performance or precision on comparable tasks. Figure 1 shows the complexity of the approach, with multiple steps of building a graph, introducing the vocabulary cache to then produce a vector at every node of the input tree of the program (instead of creating architecture for a given task), yet simple analysis over which variables can be chosen is missing.\n\nThe FillInTheBlank task is badly defined already on the running example. The goal is to select a variable to fill in a blank and already in the example on Figure 2, one of the candidate variables is out of scope at the location to fill. The motivation for the proposed formulation with building a graph and then computing attention over nodes in that graph is unclear and experiments do not help it. For example, [1] (also cited in the paper) solves the same problem more cleanly by considering only the variables in the scope*. There is no good experimental comparison to that work, but it is unlikely it will perform worse. Also [1] does not suffer from vocabulary problems for that task.\n\nSummary discussion below: the experiments here are incomparable on many levels with prior works: different architecture details, different even smaller dataset than from [1]. There is a third-party claim that on a full system, the general idea improves performance, but I take it with a grain of salt as no clean experiment was yet done. The reviewer notes that the authors disagree the baselines are not meaningful.\n\nThe NameMe tasks also shows the weakness of the proposed architectures. This work proposes to compute vectors at every node where a variable occurs and then to average them and decode the variable name to predict. In comparison, several prior works introduce one node per variable (not per occurrence), essentially removing the long distance relationships between occurrences of the same variable variables and removing the need to average vectors and enforcing the same name representation at every occurrence of the variable [name]. The setup here is incomparable to specialized naming prior works, one feature (a node per variable) is replaced with another (a node per subtoken), but for baselines authors choose to only to be similar to [1]. Also, while not on the same dataset, [2,3] consistently get higher accuracy on a related and more complicated task of predicting multiple names at the same time over multiple programming languages and with much simpler linear models. This is not surprising, because they propose simpler architectures better suited for the NameMe task.\n\n[1] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs\nwith graphs. ICLR 2017\n[2] Veselin Raychev, Martin Vechev, and Andreas Krause. Predicting program properties from Big\nCode\n[3] Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav. A General Path-Based Representation for Predicting Program\n\n* corrected text\n']","[20, 50, -70]","[60, 75, -20]","[""The sentiment score is slightly positive (20) because the reviewer describes it as a 'nice paper' with 'substantial experiments that show its practical value'. However, they also note it is 'very incremental' and suggest it may be more appropriate for a specialized venue, tempering the positivity. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'it would be helpful' and 'I understand the need to', while providing constructive feedback. They avoid harsh criticism and frame suggestions as questions or gentle recommendations. The review maintains a professional and respectful tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer lists both pros and cons, but the pros are more substantial and positive. They mention the paper is well-written, easily replicable, and has solid experiments with convincing results. The cons are less severe, mainly focusing on the title being misleading and the work being based on previous research. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout. They present both positive and negative aspects in a balanced way, using phrases like 'very well written' and 'solid experiments' for praise, while tactfully presenting criticisms as 'misleading' and 'progressing' rather than using harsher language. The reviewer also poses a question at the end, which is a polite way to suggest areas for improvement or clarification."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer uses phrases like 'Unfortunately', 'overly complex', 'strange formulations', 'badly defined', and states that the paper 'does not demonstrate state-of-the-art performance'. They also criticize the methodology and experimental comparisons. The few positive aspects (potential applications) are overshadowed by the criticisms. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use phrases like 'badly defined', 'weakness of the proposed architectures', and 'overly complex' without much softening language. However, they do provide detailed explanations for their criticisms, which prevents the score from being lower.""]"
"['Summary: \nThis paper presents three small improvements for training binarized neural networks: (1) a modified straight-through estimator, (2) a novel regularizer to push weights to +/- 1, and (3) the use of scaling factors for the binarized weights. Using the methods presented, the validation accuracies on ImageNet and CIFAR-10 are improved by just under 2 percentage points.\n\n  Pros:\n    - Decent improvement in the performance of the binarized network in the end\n    - The presented regularizers make sense and seem effective. The modified straight-through estimator seems reasonable as well, although the authors do not compare to recent work with a similar adjustment. \n\n  Cons:\n    - The paper is poorly written and confusing. It reads as if it was written in one pass with no editing or re-writing to clarify contributions or key points, or ensure consistency.\n    - While the final numbers are acceptable, the experiments themselves could be stronger and could be presented more effectively.\n   - The novelty of the scale factors is questionable.\n\n\nQuestions and comments:\n\n1. How exactly is the SS_\\beta activation used? It is entirely unclear from the paper, which contradicts itself in multiple ways. Is SS_\\beta used in the forward pass at all for either the weight or activation binarization? Or is only its derivative used in the backward pass? If the latter, then you are not replacing the activation anywhere but are simply using a different straight-through estimator in place of the saturated straight-through estimator (e.g., see [1]).\n   (a) At the beginning of Section 3.3, you say that you modify the training procedure by replacing the sign binarization with the SS_\\beta activation. This sounds like it is referring to the activation function at each layer; however, the pseudocode says that you are using sign() as the per-layer activation. \n   (b) Further, Figure 4 shows that you are using the SS_\\beta function to do weight binarization. However, again, the pseudocode shows that you are using sign() to do the weight binarization. \n\n2. In [1], the authors used a similar type of straight-through estimator (essentially, the gradient of tanh instead of hard_tanh) and found that to be quite effective. You should compare to their method. Also, it\'s possible that SS_\\beta reduces to tanh for some choice of \\beta -- is this true?\n\n3. The use of scale factors seems to greatly increase the number of parameters in the network and thus greatly decrease the compression benefits gained by using binarization, i.e., you require essentially #scale_factors =  a constant factor times the number of actual parameters in the network (since you have a scale factor for each convolutional filter and for each column of each fully-connected layer). As a result of this, what is the actual compression multiplier that your network achieves relative to the original network?\n\n4. For the scale factor, how does yours differ from that used in Rastegari et al. (2016)? It seems the same but you claim that it is a novel contribution of your work. Please clarify.\n\n5. Why did learning \\beta not work? What was the behavior? What values of \\beta did learning settle on? \n\n6. I assume that for each layer output y_i = f(W_i x_i), the regularizer is applied as R(y_i) while at the same time y_i is passed to the next layer -- is this correct? The figures do not clearly show this and should be changed to more clearly show how the regularizer is computed and used, particularly in relation to the activation.\n\n7. In the pseudocode:\n   (a) What does ""mostly bitwise operations"" mean? Are some floating point?\n   (b) Is this the shift-based batchnorm of Hubara et al. (2016)?\n\n8. For Table 1:\n   (a) I assume these are accuracies? The caption should say.\n   (b) Why are there no comparisons to the performance of other methods on this dataset?\n   (c) Any thoughts as to why your method performs better than the full-precision method on this dataset for VGG?\n\n8. For Table 2:\n   (a) Does Table 2 show accuracies on ImageNet? You need to make this clear in the caption.\n   (b) What type of behavior do the runs that do not converge show? This seems like a learning rate problem that is easily fixable. Are there no hyperparameter values that allow it to converge?\n   (c) What behavior do you see when you use SS_1 or SS_2, i.e., \\beta = 1 or \\beta = 2? Since lower \\beta values seem better.\n   (d) The regularization seems to be the most useful contribution -- do you agree?\n   (e) Why did you not do any ablations for the scale factor? Please include these as well.\n\n9. For Table 3, did you compute the numbers for the other approaches or did you use the numbers from their papers? Each approach has its own pros and cons. Please be clear.\n\n10. Are there any plots of validation accuracy versus epoch/time for the different algorithms in order to ensure that the reported numbers were not simply cherry-picked from the run? I assume that you simply used the weights from the end of the 50th epoch -- correct? \n\n11. Is there evidence for your introductory claims that \'quantizing weights ... make neural networks harder to train due to a large number of sign fluctuations\' and \'maintaining a global structure to minimize a common cost function is important\' ? If so, you should cite this evidence. If not, you should make it clear that these are hypotheses. \n\n12. Why are there not more details about the particular architectures used? These should be included in the appendices to aid those who would like to rerun your experiments. In general, please include more experiment details in the body or appendices.\n\n\nDetailed comments:\n- R(l) is not defined in Figure 1 and thus is confusing. Also, its replacement of \'Error\' from the original figure source makes the figure much more confusing and less clear.\n\n- Typos:\n   - \'accustomed\' (p.1)\n   - \'the speed by quantizing the activation layers\' doesn\'t make sense (p.1)\n   - \'obtaining\' (p.4)\n   - \'asymmetric\' doesn\'t make sense because these are actually symmetric functions across the y-axis (p.4)\n   - \'primary difference is that this regularization ...\' --> \'primary difference is that their regularization ...\' (p.4)\n   - \'the scales with 75th percentile of the absolute value ... \' is very confusing and unclear (p.7)\n   - \'the loss metric used was the cross-entropy loss, the order of R_1.\' I do not know what you\'re trying to say here (p.8)\n\n- Citations: Fix the capitalization issues, typos, and formatting inconsistencies.\n\n\n[1]  Friesen and Domingos. Deep Learning as a Mixed Convex-Combinatorial Optimization Problem. ICLR 2018.\n\n\n-------------------\n\nAfter reading the author response, I do not think the paper does a sufficient job of evaluating the contributions or comparing to existing work. The authors should run ablation experiments, compare to existing work such as [1], and evaluate on additional datasets. These were easy tasks that could have been done during the review period but were not.\n\nIf I wanted to build on top of this paper to train higher accuracy binary networks, I would have to perform all of these tasks myself to determine which contributions to employ and which are unnecessary. As such, the paper is currently not ready for publication.\n', 'The authors of this paper aim to reduce the constraints required by neural networks so they can be evaluated on lower-power devices. Their approach is to quantize weights, i.e. rounding weights and hidden units so they can be evaluated using bit operations. There are many challenges in this approach, namely that one cannot back-propagate through discrete weights or discrete sign functions. The authors introduce an approximation of the sign function, which they call the SignSwish, and they back-propagate through this, quantizing the weights during the forward pass. Further, they introduce a regularization term to encourage weights to be around learned scales. They evaluate on CIFAR-10 and Imagenet, surpassing most other quantization methods. \n\nThe paper is pretty clear throughout. The authors do a good job of motivating the problem and placing their approach in the context of previous work. I found Figures 1 and 2 helpful for understanding previous work and the SignSwish activation function, respectively. However, I did not get much out of Figures 3 or 4. I thought Figure 3 was unnecessary (it shows the difference between l1 and l2 regularization), and I thought the psuedo-code in Algorithm 1 was a lot clearer than Figure 4 for showing the scaling factors. Algorithm 1 helped with the clarity of the approach, although it left me with a question: In section 3.3, the authors say that they train by ""replacing the sign binarization with the SS_\\beta activation"" and that they can back-propagate through it. However, in the psuedo-code it seems like they indeed use the sign-function in the forward-pass, replacing it with the signswish in the backward pass. Which is it?\n\nThe original aspects of their approach are in introducing a new continuous approximation to the sign function and introducing learnable scales for l1 and l2 regularization. The new activation function, the SignSwish, is based off the Swish-activation from Ramachandran et al. (2018). They modify it by centering it and taking the derivative. I\'m not sure I understand the intuition behind using the derivative of the Swish as the new activation. It\'s also unclear how much of BNN+\'s success is due to the modification of the Swish function over using the original Swish activation. For this reason I would\'ve liked to see results with just fitting the Swish. In terms of their regularization, they point out that their L2 regularization term is a generalization of the one introduced in Tang et al. (2017). The authors parameterize the regularization term by a scale that is similar to one introduced by Rastegari et al. (2016). As far as I can tell, these are the main novel contributions of the authors\' approach. \n\nThis paper\'s main selling point isn\'t originality -- rather, it\'s that their combination of tweaks lead to state-of-the-art results. Their methods come very close to AlexNet and VGG in terms of top-1 and top-5 CIFAR10 accuracy (with the BNN+ VGG even eclipsing the full-precision VGG top-1 accuracy). When applied to ImageNet, BNN+ outperforms most of the other methods by a good margin, although there is still a lot of room between the BNN+ and full-precision accuracies. The fact that some of the architectures did not converge is a bit concerning. It\'s an important detail if a training method is unstable, so I would\'ve liked to see more discussion of this instability. The authors don\'t compare their method to the Bi-Real Net from Liu et al. (2018) since it introduces a shortcut connection to the architecture, although the Bi-Real net is SOTA for Resnet-18 on Imagenet. Did you try implementing the shortcut connection in your architecture? \n\nSome more minor points:\n- The bolding on Table 2 is misleading. It makes it seem like BNN+ has the best top-5 accuracy for Resnet-18, although XNOR-net is in fact superior. \n- It\'s unclear to me why the zeros of the derivative of sign swish being at +/- 2.4beta means that when beta is larger, we get a closer approximation to the sign function. The derivative of the sign function is zero almost everywhere, so what\'s the connection?\n- Is the initialization of alpha a nice trick, or is it necessary for stable optimization? Experiments on the importance of alpha initialization would\'ve been nice. \n\nPROS:\n- Results. The top-1 and top-5 accuracies for CIFAR10 and Imagenet are SOTA for binarized neural networks.\n- Importance of problem. Reducing the size of neural networks is an important direction of research in terms of machine learning applications. There is still a lot to be explored.\n- Clarity: The paper is generally clear throughout.\n\nCONS:\n-Originality. The contributions are an activation function that\'s a modification of the swish activation, along with parameterized l1 and l2 regularization. \n-Explanation. The authors don\'t provide much intuition for why the new activation function is superior to the swish (even including the swish in Figure 2 could improve this). Moreover, they mention that training is unstable without explaining more. ', '1. The abstract of this paper should be further refined. I could not find the technical contributions of the proposed method in it.\n\n2. The proposed method for training BNNs in Section 3 is designed by combining or modifying some existing techniques, such as regularized training and approximated gradient. Thus, the novelty of this paper is somewhat weak.\n\n3. Fcn.3 is a complex function for deep neural networks, which integrates three terms of x. I am worried about the convergence of the proposed method.\n\n4. Fortunately, the performance of the proposed method is very promising, especially the results on the Imagenet, which achieves the highest accuracy over the state-of-the-art methods. Considering that the difficulty for training BNNs, I vote it for acceptance.  \n\n---------------------------------\n\nAfter reading the responses from authors, I have clearer noticed some important contributions in the proposed methods:\n\n1) A novel regularization function with a scaling factor was introduced for improving the capability of binary neural networks; \n2) The proposed activation function can enhance the training procedure of BNNs effectively;\n3) Binary networks trained using the proposed method achieved the highest performance over the state-of-the-art methods.\n\nThus, I think this is a nice work for improving performance of  binary neural networks, and some of techniques in this paper can be elegantly applied into any other approaches such as binary dictionary learning and binary projections. Therefore, I have increased my score.']","[-60, 50, 50]","[20, 70, 70]","[""The sentiment score is -60 because the review is overall quite critical, pointing out numerous issues with the paper such as poor writing, confusing explanations, questionable novelty, and insufficient experiments. However, it does acknowledge some positive aspects like 'decent improvement' and 'effective regularizers', preventing an even lower score. The politeness score is 20 because while the reviewer uses professional language and offers constructive feedback, there are some blunt criticisms (e.g. 'poorly written and confusing') that prevent a higher politeness rating. The reviewer asks many questions and provides detailed suggestions for improvement, which is helpful but not overly polite in tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as state-of-the-art results, importance of the problem, and overall clarity. However, they also point out several weaknesses, including concerns about originality and lack of explanation for certain aspects. The balanced critique suggests a moderately positive sentiment.\n\nThe politeness score is 70 (fairly polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The authors do a good job' and 'I found... helpful,' which are courteous. The critique is constructive, offering both pros and cons, and suggestions for improvement. The reviewer asks questions rather than making accusatory statements. However, it's not extremely polite as it doesn't use overly deferential language or excessive praise."", ""The sentiment score is 50 (slightly positive) because the review starts with some criticisms but ends on a positive note, especially after the author's response. The reviewer initially points out weaknesses but ultimately votes for acceptance due to promising performance. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the difficulty of the task, and shows willingness to reconsider their initial assessment based on the authors' response. The reviewer provides constructive feedback and uses phrases like 'I think this is a nice work' which contribute to a polite tone.""]"
"['In this paper, authors propose a deep generative model and a variant for graph generation and conditional graph generation respectively. It exploits an encoder which is built based on GCN and GraphSAGE, a autoregressive LSTM decoder which generates the graph embedding, and a factorized edge based probabilistic model for generating edge and node type. For conditional generation, authors also propose a discriminating training scheme based on maximizing the mutual information. Experiments on ZINC dataset show that the proposed method is promising.\n\nStrength:\n\n1, The problem this paper tries to tackle is very challenging and of great significance. Especially, the conditional graph generation direction under the deep learning context is novel. \n\n2, The overall model is interesting although it is a bit complicated as it combines quite a few modules.\n\nWeakness:\n\n1, In the reconstruction experiment, comparisons with several recent competitive methods are missing. For example, the methods which have been already discussed in the related work, Li et al. (2018a), You et al. (2018a) and You et al. (2018b). Moreover, it is not explained whether the comparison setting is the same as Jin et al. (2018) and what the size of the latent code of their method is. It seems less convincing by just taking results from their paper and do the comparison.\n\n2, Authors motive their work by saying in the abstract that “other graph generative models are either computationally expensive, limiting their use to only small graphs or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters”. However, if I understood correctly, in Eq. (7), authors compute the soft adjacency tensor which is a dense tensor and of size #node by #node by #edge types. Therefore, I did not see why this method can scale to large graphs.\n\n3, The overall model exploits a lot of design choices without doing any ablation study to justify. For example, how does the pre-trained discriminator affect the performance of the conditional graph generation? Why not fine-tune it along with the generator? The overall model has quite a few loss functions and associated weights of which the values are not explained at all.\n\n4, Conditional generation part is not written clearly. Especially, the description of variational mutual information phase is so brief that I do not understand the motivation of designing such an objective function. What is the architecture of the discriminator?\n\n5, How do authors get real attributes from the conditionally generated molecules? It is not explained in the paper.\n\nTypos:\n\n1, There are a few references missing (question mark) in the first and second paragraphs of section 2.\n\n2, Methods in the experiment section are given without explicit reference, like GCPN.\n\n3, Since edge type is introduced, I suggest authors explicitly mention the generated graphs are multi-graph in the beginning of model section. \n\nOverall, I do not think this paper is ready for publishing and it could be improved significantly.\n\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nUpdate:\n\nThanks for the detailed explanation. The new figure 1 is indeed helpful for demonstrating the overall idea. \n\nHowever, I still found some claims made by authors problematic. \nFor example, it reads in the abstract that ""...or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters..."". \nClearly, Li et al. 2018b has a differentiable formulation which falls under your description.\n\nBesides, I suggest authors adjust the experiment such that it focuses more on comparing conditional generation. \nAlso, please set up some reasonable baselines based on previous work rather than saying it is not directly comparable.\nDirectly taking numbers from other papers for a comparison is not a good idea given the fact that these experiments usually involve quite a few details which could potentially vary significantly.\n\nTherefore, I would like to keep my original rating. \n', 'This paper proposed a variant of the graph variational autoencoder [1] to do generative modeling of graphs. The author introduced an additional conditional variable (e.g., property value) into the decoder. By backpropagating through the discriminator, the model is able to find the graph with desired property value. \n\nOverall the paper reads well and is easy to follow. The conditional generation of graphs seems also helpful regarding the empirical performance. However, there are several concerns regarding the paper:\n\n1) The edge factorization-based modeling is not new. In fact [1] already uses the node embeddings to factorize the adjacency matrix. This paper models extra information including node tags and edge types, but these are not fundamental differences compared to [1].\n\n2) The paper claims the method is ‘cheaper’ and ‘scalable’. Since essentially the computation cost is similar to [1] which requires at least O(n^2) to generate a graph with n nodes, I’m not super confident about the author’s claim. Though this can be parallelized, but the memory cost is still in this order of magnitude, which might be too much for a sparse graph. Also there’s no large graph generative modeling experiments available.\n\n3) Continue with 2), the adjacency matrix of a large graph (e.g., graph with more than 1k nodes) doesn’t have to be low rank. So modeling with factorization (with typically ~256 embedding size) may not be suitable in this case. \n\nSome minor comments:\n4) Regarding Eq (2), why the lstm is used, instead of some simple order invariant aggregation?\n\n5) the paper needs more refinement. E.g., in the middle of page 2 there is a missing citation. \n\n[1]  Kipf & Welling, Variational Graph Auto-Encoders, https://arxiv.org/pdf/1611.07308.pdf\n', 'The paper proposes a conditional graph generation that directly optimizes the properties of the graph. The paper is very weak.\n1. I think almost all probabilistic graph generative models are differentiable. If the  objective is differentiable function of real   \n    variables, it is usually differentiable.\n\n2.  The authors claim that existing works Simonovsky and Komodakis (2018) and Cao & Kipf (2018) are restricted to use small graphs with predefined maximum size. This work does not overcome the limitation of small graphs issue too.\n\n3. The authors do not show any measure on validity, novelty or uniqueness which are now standard in literature.\n   Also I do not find any comparison with molGAN paper which tackles a similar objective.\n\n4. Could the authors show if the decoding process is permutation invariant? I am not really sure of that. I was trying to prove that thing formally, but I failed.\n\n\n ']","[-60, -20, -80]","[20, 60, -20]","[""The sentiment score is -60 because the reviewer expresses significant concerns and states the paper is not ready for publishing. They list more weaknesses than strengths and request major revisions. However, it's not entirely negative as they acknowledge some strengths and the potential significance of the work. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They acknowledge positive aspects before discussing weaknesses, which is a polite approach. The tone is direct but not rude, with phrases like 'I suggest' and 'Thanks for the detailed explanation' showing some courtesy. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('reads well', 'easy to follow', 'helpful regarding the empirical performance'), they express several significant concerns about the paper's claims and novelty. The reviewer points out that some key aspects are not new, questions the scalability claims, and raises concerns about the method's suitability for large graphs. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects first, and frames criticisms as 'concerns' rather than outright flaws. The reviewer also uses phrases like 'I'm not super confident' instead of more aggressive language. The tone is professional and constructive, offering specific points for improvement."", ""The sentiment score is -80 because the review starts with 'The paper is very weak' and lists several critical points without any positive remarks. This indicates a strongly negative sentiment towards the paper. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and doesn't use any softening language or positive reinforcement. The reviewer directly states weaknesses and uses phrases like 'I think almost all...', 'This work does not overcome...', and 'I do not find any comparison...' which come across as somewhat dismissive. The lack of any encouraging or constructive feedback also contributes to the slightly impolite tone.""]"
"['In this paper, the effect of batch normalization to the maximum eigenvalue of the Fisher information is analyzed. The techinique is mostly developed by Karakida et al. (2018). The main result is an informal bound of the maximum eigenvalue, which is given without proof. Though, the numerical result corresponds to the derived bound.\n\nThe paper is basically well written, but the technical part has several notational problems. For example, there is no definition of ""\\otimes"", ""\\odot"", and ""Hess"" operators.\n\nThe use of the mean-field theory is an interesting direction to analyze batch normalization. However, in this paper, it seems failed to say some rigorous conclusion. Indeed, all of the theoretical outcomes are written as ""Claims"" and no formal proof is given. Also, there is no clear explanation of why the authors give the results in a non-rigorous way, where is the difficult part to analyze in a rigorous way, etc. \n\nAside from the rigor issue, the paper heavily depends on the study of Karakida et al. (2018). The derivation of the bound (44) is directly built on Karakida\'s results such as Eqs. (7,8,20--22), which reduces the paper\'s originality.\n\nThe paper also lacks practical value. Can we improve an algorithm or something by using the bound (44) or other results?', 'Interesting application of MFT on FIM to understand Batch Normalization\n\nThis paper applies mean field analysis to networks with batch normalization layers. Analyzing maximum eigenvalue of the Fisher Information Matrix, the authors provide theoretical evidence of allowing higher learning rates and faster convergence of networks with batch normalization. \n\nThe analysis reduces to providing lower bound for maximum eigenvalue of FIM using mean-field approximation. Authors provide lower bound of the maximum eigenvalue in the case of fully-connected and convolutional networks with batch normalization layers. Lastly authors observe empirical correlation between smaller \\gamma and lower test loss. \n\nPro: \n - Clear result providing theoretical ground for commonly observed effects. \n - Experiments are simple but illustrative. It is quite surprising how well the maximum learning rate prediction matches with actual training performance curve. \n\t\n\nCon:\n - While mean field analysis a-priori works in the limit where networks width goes to infinity for fixed dataset size, the analysis of Fisher and Batch normalization need asymptotic limit of dataset size. \n - Although some interesting results are provided. The content could be expanded further for conference submission. The prediction on maximum learning rate is interesting and the concrete result from mean field analysis\n - While correlation between batch norm \\gamma parameter and test loss is also interesting, the provided theory does not seem to provide good intuition about the phenomenon. \n\nComments:\n- The theory provides the means to compute lower bound of maximum eigenvalue of FIM using mean-field theory. In Figure 1, is \\bar \\lambda_{max} computed using the theory or empirically computed on the actual network? It would be nice to make this clear. \n- In Figure 2, the observed \\eta_*/2 of dark bands in heatmap is interesting. While most of networks without Batch Norm, performance is maximized using learning rates very close to maximal value, often networks using batch norm the learning rate with maximal performance is not the maximal one and it would be interesting to provide theoretical \n- I feel like section 3.2 should cite Xiao et al (2018). Although this paper is cited in the intro, the mean field analysis of convolutional layers was first worked out in this paper and should be credited. \n', 'This paper studies the effect of batch normalization via a physics style mean-field theory. The theory yields a prediction of maximal learning rate for fully-connected and convolutional networks, and experimentally the max learning rate agrees very well with the theoretical prediction.\n\nThis is a well-written paper with a clean, novel result: when we fix the BatchNorm parameter \\gamma, a smaller \\gamma stabilizes the training better (allowing a greater range of learning rates). Though in practice the BatchNorm parameters are also trained, this result may suggest using a smaller initialization. \n\nA couple of things I was wondering:\n\n-- As a baseline, how would the max learning rate behave without BatchNorm? Would the theories again match the experimental result there?\n\n-- Is the presence of momentum important? If I set the momentum to be zero, it does not change the theory about the Fisher information and only affects the dependence of \\eta on the Fisher information. In this case would the theory still match the experiments?']","[-50, 50, 80]","[20, 75, 70]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as lack of rigor, heavy dependence on previous work, and lack of practical value. However, it's not entirely negative as it acknowledges that the paper is 'basically well written' and the approach is 'interesting'. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They avoid harsh or personal attacks, instead focusing on specific aspects of the paper that could be improved. The use of phrases like 'it seems' and 'can we' softens the criticism. However, the review is not overly polite or complimentary either, maintaining a professional tone throughout."", ""Sentiment score (50): The review begins with a neutral description of the paper's content, followed by a balanced list of pros and cons. The reviewer acknowledges the paper's interesting application and clear results, while also pointing out areas for improvement. This mix of positive and constructive criticism suggests a moderately positive sentiment.\n\nPoliteness score (75): The language used throughout the review is professional and respectful. The reviewer uses phrases like 'Interesting application' and 'Clear result' to highlight positive aspects. Even when presenting criticisms, the tone remains constructive rather than harsh, using phrases like 'could be expanded further' instead of more negative language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. The overall tone is courteous and aimed at helping the authors improve their work."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well-written' with a 'clean, novel result' and expresses that the experimental results 'agree very well with the theoretical prediction'. The overall tone is appreciative of the work. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, praising the paper's qualities and framing their questions as curiosities ('I was wondering') rather than criticisms. The reviewer also suggests potential implications of the work, showing engagement. The language is professional and constructive, without any harsh or dismissive comments.""]"
"['Authors propose a new method called TriMap, which captures higher orders of structure with triplet information, and minimize a roust loss function for satisfying the chosen triplets.\n \nThe proposed method is motivated by the misleading selection approach for a dimensionality reduction method using local measurements. And then, authors resort to an evaluation based on visual clues based on a number of transformations. Authors then claim that any DR method preserving the global structure of the data should be able to handle these transformations.  An example on MNIST data illustrate these properties, but it is still not clear what are the visual clues as the criterion to select a good DR method and what are the global structures.\n \nAuthors discussed the results in Figure 4 for six real-world datasets, but there is no convincing evidence from the corresponding domains or reference researches for the support of the global structure in the learned embedding space.  It will be good to add some convincing evidences for the conclusion.\n \nAs the method highly depends on the subset of sampled triplets, it is interesting to see how the global structure changes if a different set of triplets is used.  In addition, it is unclear why sampled triplets can achieve a global structure of data instead of pairwise relations. From the experiments, triplets are also sampled according to the pairwise nearest neighbor graph.', 'In this paper, the authors present a novel dimensionality reduction method named TriMap. TriMap attempts to improve upon the widely-adopted t-SNE algorithm by incorporating global distances through the use of triplets, rather than pairwise comparisons. The authors compare to t-SNE, as well as a newer method called LargeVis which also claims to impose a global distances metric. The authors show that their method is more robust to the addition or removal of clusters and outliers and provides a more meaningful global distance relative to the methods against which they compare.\n\nTechnical Quality\nThe authors’ method is clear and well described and addresses a poignant issue in dimensionality reduction. However, the authors fail to compare their method to a number of relevant dimensionality reduction algorithms which also claim to provide solutions with globally meaningful distances. Such methods include force-directed graph drawing (Fruchterman & Reingold, 1991), diffusion maps (Coifman & Lafon, 2006) and PHATE (Moon et al., 2017). \n\nAdditionally, the handling of outliers is a concern. While the authors claim that the retention of outliers as disconnected from the manifold is a desirable quality of their technique, the presence of many outliers in a dataset (for example, in the Tabula Muris and lyrics datasets) has the potential to mask the interesting portion of the dimensionality reduction. It may be worth commenting on the desirability to identify and remove outliers, and the provision of such a technique in the software upon its release.\n\nFinally, the runtime comparison is of concern. It is common to perform most DR methods on high-dimensional PCA representation of the data, particularly in single-cell genomics (e.g. the Tabula Muris dataset in Part 3.) In this context, both UMAP and PHATE successfully embed the Tabula Muris dataset in less than the reported TriMap time (3.5 and 5 minutes respectively, compared to 15 minutes reported for TriMap.)\n\nNovelty\nThe authors’ method appears to provide improved results over the compared alternatives, however, it is worth noting that triplet-based embedding is not novel in its own right (van der Maaten & Weinberger, 2012), though one could argue novelty is warranted here due to claimed substantial improvements of results. In this case, the authors should include a comparison to competing triplet-based methods, at least in the appendix. \n\nPotential impact\nThe authors’ method has the potential to be used widely across many fields, as a direct replacement for t-SNE. Its adoption is contingent on compelling evidence that it produces results substantially better than UMAP (which is currently heralded as an upcoming replacement for t-SNE in some fields) and other competing methods. The authors may find it worthwhile to provide such comparisons, if not in the main body of the paper at least in the appendix. \n\nClarity\nThe paper is easy to read and makes its point in a reasonably concise manner. Detailed explanation of experiments v) and vi) could be relegated to the appendix. More precise statement of the authors’ tests in Part 2 could be provided by quantifying the results of the tests in a more precise way; it is not clear what the authors seek to achieve by drawing the dotted lines between clusters in Figure 1a, or by providing AUC values in Figure 1.\n\nDetailed Comments\n•\tIn the definition of Equation 2, it is not until one paragraph later than q_{ij}^{~(t’)} is defined – this is confusing and hard to read.\n•\tThe captions for Figures 1 and 3 would be substantially clearer with more detail on the dataset analyzed and in Figure 1, some discussion of the purpose of each subplot.\n•\tThe Figure 3 caption needs a semicolon or period before introducing the bottom panel.\n•\tThe claim that the authors’ heuristic triplet sampling (nearest-neighbor and random sampling) is sufficient to approximate full triplet sampling should be shown in the appendix.\n•\tThe collaboration network analyzed in Part 3 is naturally a graph; it would make sense to cluster and visualize this using a graph-based clustering, rather than coercing it to Euclidean coordinates.\n\n(Note: after reading the revised manuscript I have changed my recommendation from a 6 to a 5)\n\nReferences\nCoifman, R. R., & Lafon, S. (2006). Diffusion maps. Applied and computational harmonic analysis, 21(1), 5-30. https://doi.org/10.1016/j.acha.2006.04.006\nMoon, K. R., van Dijk, D., Wang, Z., Burkhardt, D., Chen, W., van den Elzen, A., ... & Krishnaswamy, S. (2017). Visualizing transitions and structure for high dimensional data exploration. bioRxiv, 120378. https://doi.org/10.1101/120378\nFruchterman, T. M., & Reingold, E. M. (1991). Graph drawing by force‐directed placement. Software: Practice and experience, 21(11), 1129-1164. https://doi.org/10.1002/spe.4380211102\nL. van der Maaten and K. Weinberger. Stochastic triplet embedding. In 2012 IEEE International Workshop on Machine Learning for Signal Processing, pp. 1–6, Sept 2012. doi: 10.1109/MLSP.2012.6349720.\n', 'Motivated by the observation that most of previous dimensionality reduction methods focus on preserving \nlocal pairwise neighboring probabilities and lack in preserving global properties, this paper proposes a \nmethod called TriMap to optimize a loss function preserving similarities among triplets of data points. A large \nnumber of triplets are sampled either based on nearest neighbor calculations or random sampling. Experimental \nresults on several datasets show that TriMap identifies outliers and preserves global data properties better \nthan previous approaches based on pairwise data point comparisons.\n\nMajor:\n\nThe idea in this paper is well motivated and the loss function based on probability ratio is novel. However, \nthere are some major concerns about method analyses and experimental evaluations,\n\n1. Data embedding based on triplets has been presented in (van der Maaten and Weinberger, 2012). The authors \nneed to present detailed explanations and formal analysis why the proposed method significantly outperforms the \nprevious one. A recent dimensionality reduction method compares data points only to data cluster centers (Parametric \nt-distributed stochastic exemplar centered embedding, Min et al., 2018), does it preserve global data properties? Does \nits trivial combination with standard t-SNE well preserve both local and global data properties?\n\n2. Preserving local pairwise neighborhood structure is often the most important part in high-dimensional data \nvisualization, because only local similarities can be confidently trusted in a high-dimensional space. Even if preserving \nglobal data properties is important, the very local neighborhood structure should also be preserved. However, the \nproposed method TriMap is significantly worse than t-SNE according to AUC under the precision-recall curve. \n\n3. Standard quantitative evaluations based on 1NN error rate and quality scores (van der Maaten & Hinton 2008, Min \net al. 2018) should be added to the experiments. For preserving global data properties, quantitative evaluations on all \nthe datasets will make the experiments much more convincing.\n\n4. In the abstract, the claim that TriMap scales linearly is inaccurate, the triplet sampling requires nearest neighbor \ncalculations, which has computational complexity of at least O(nlogn)\n\n5. This paper proposed two variants of triplet sampling, nearest neighbor triplets and random triplets. Detailed experimental \ncomparisons about them should be provided in the paper.\n\n\n6. The running time comparisons in Table 1 must be wrong or highly biased with improper hyperparameter setting. Based \non tree accelerations, t-SNE can produce impressive visualization on MNIST-scale datasets within 15 minutes (please \ncheck the experimental details PP. 3235-3238 in van der Maaten, Journal of Machine Learning Research 2014).\n\n7. The authors mentioned partial observation, outliers and subclusters in the global information, but the authors do not specifically define \nwhat the global information should be rigorously, and the paper does not theoretically prove or explain via experiments how the global \ninformation is kept by TriMap.\n\n8. In the experiments, the authors applied PCA before TriMap to reduce the dimensionality while PCA is not applied in tSNE and LargeVis. The authors do not explain why the settings are different in the three methods.\n\nMinor:\n\n9. In the algorithm, the authors show different equations for different t and t’, but are not evaluated in experiments.\n\n(After reading the rebuttal, I raised the rating from 5 to 6.)']","[-20, 20, -20]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method and its motivations, they express several concerns and uncertainties about the approach. They point out unclear aspects, lack of convincing evidence, and request additional information, indicating a somewhat critical stance. However, the tone is not entirely negative, as they also suggest improvements and show interest in further exploration of the method. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They phrase their criticisms as suggestions ('it will be good to add...') and express interest in seeing more ('it is interesting to see...'). The reviewer maintains a constructive tone without using harsh or dismissive language, even when pointing out limitations or requesting clarifications."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential impact of the method, stating it 'has the potential to be used widely across many fields' and 'provides improved results over the compared alternatives'. However, they also raise several concerns and suggest additional comparisons, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'it may be worth commenting on' and 'the authors may find it worthwhile', which are polite ways of suggesting improvements. The review maintains a professional tone, balancing praise with areas for improvement, without using any rude or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well motivated', 'novel'), they raise several major concerns and criticisms about the method and experimental evaluations. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge strengths before presenting concerns, and use phrases like 'the authors need to' rather than more accusatory language. The review maintains a balanced and objective tone, even when pointing out potential errors or shortcomings.""]"
"[""This paper proposes Deep Overlapping Community detection model (DOC), a graph convolutional network (GCN) based community detection algorithm for network data. The model is a simple combination of GCN and existing framework for community detection. The proposed algorithm is compared to baselines on various datasets, and demonstrated to be accurate in many cases.\n\nI think the paper does not deal with one of the most important aspects of network modeling - the degree heterogeneity of nodes. Many works reported that lack of degree corrections would result in bad estimates of community structures [1,2,3]. Probably including the degrees as feature of nodes would be helpful. \n\nRegarding the stochastic gradient descent by edge subsampling, I think the authors should mention [4], where the idea of edge subsampling in stochastic gradient descent setting was introduced before this work. Also, it is worth noting that we may lose some important distributional properties in graphs if we naively subsample from it [5]. For instance, sampling from positive and negative pairs to balance the class contribution may distort the sparsity and degree distributions of subsampled graphs. \n\nIf we choose to use Bernoulli-Poisson link function, we can reduce the time complexity of likelihood and gradient computation to O(N + E), where N is the number of nodes and E is the number of edges, with the auxiliary variable trick introduced in [6]. In that case we don't really have to worry about subsampling. Why didn't you consider applying this to your model?\n\nRegarding the experiments, I think some important baselines are missing [3, 6]. Also, I wonder whether the proposed algorithm would scale to the graphs with more than 100,000 nodes. \n\nReferences\n[1] B. Karrer and M. E. J. Newman. Stochastic blockmodels and community structure in networks. Physical Review E, 83(1):016107, 2011.\n[2] P. K. Gopalan, C. Wang, and D. Blei. Modeling overlapping communities with node popularities. NIPS 2013.\n[3] A. Todeschini, X. Miscouridou and F. Caron. Exchangeable Random Measures for Sparse and Modular Graphs with Overlapping Communities. CoRR 2016.\n[4] J. Lee, C. Heakulani, Z. Ghahramani, L. F. James, and S. Choi. Bayesian inference on random simple graphs with power law degree distributions. ICML 2017.\n[5] P. Orbanz. Subsampling large graphs and invariance in networks. CoRR 2017.\n[6] M. Zhou. Infinite edge partition models for overlapping community detection and link prediction. AISTATS 2015"", 'This paper presents an overlapping community detection method. The idea is to use a graph neural network (namely, the graph convolutional network) with node embeddings constrained to be non-negative. The non-negative embeddings helps to learn the community membership of each node (and each node can belong to multiple communities). \n\nThe idea is natural, though not novel. The only main novelty, as compared to various other recently proposed graph embedding approaches, lies in making the node embeddings non-negative. Rest of the pieces are fairly standard, including the link functions, such as Bernoulli-Poisson.  Therefore the paper is quite thin in technical novelty.\n\nIn addition to the limited technical novelty, I have a few other concerns as well, including some on the experimental evaluation:\n\n- Real-valued node embeddings obtained from shallow/deep graph embedding methods can be used with *overlapping* versions of k-means. This can be a solid baseline.\n\n- The paper relies on subsampling the edges and non-edges to speed-up optimization. However, the encode still seems to use the entire adjacency matrix. If that is not the case, please clarify.\n\n- The reported results are only on overlapping community detection. Most of the shallow/deep graph embedding methods can also be used for link prediction task (many of the recent paper report such results). It will be nice to provide results on this task.  \n\n- There has been some recent work on using deep generative models for overlapping community detection with node side information. For example, see ""Deep Generative Models for Relational Data with Side Information"" (Hu et al, 2017). Interestingly, they too use Bernoulli-Poisson link (but not GCN).\n\n- None of the baselines are deep learning methods. As I pointed out, one can use real-valued embeddings from such methods with overlapping k-means (or other overlapping clustering methods). Link-prediction results can also be compared.\n\nIn summary, I think the paper lacks both in terms of technical novelty as well as experimental evaluation and therefore doesn\'t seem to be ready. I would encourage the authors to consider the suggestions above.', ""The current paper considers the overlapping community detection problem and suggests to use the so-called graph neural networks for its solution.\n\nThe approach starts from BigCLAM model and suggests to parametrize factor matrices (or embedding vectors) via neural network with graph adjacency matrix and node attributes as inputs. The obtained algorithm is tested on several datasets and its reported performance is superior to competitors.\n\nThis paper basically tries to introduce the dependence between embedding vectors for graph nodes, which recently became de facto standard approach in machine learning for graphs. The paper is very well aligned with recent literature on ML for graphs, which is focused on combining different ideas of deep learning, tailoring them to particular graph problem and reporting results on some datasets. Unfortunately, very rarely interesting new ideas appear in these papers, and current paper is not an exception.\n\nI apologize for such a pessimistic view, but I don't see the results significantly interesting for the ICLR community and don't recommend acceptance. Some additional algorithmic/computational/theoretical insights are needed.\n\nI have couple of minor issues to discuss:\n1. For the sake of generality, I would recommend to use the general formula instead of particular 3-layer case in equation 3.\n2. I don't think that it is really appropriate to call 3-layer model a 'deep learning model', I would recommend to just name it 'neural network'\n\nAlso, I think that experimentally paper is pretty strong, but it would be nice to see the repository with algorithm code and experiments available.""]","[-20, -60, -60]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('accurate in many cases'), they primarily focus on limitations and missing elements in the paper. They point out several areas for improvement and missing comparisons, suggesting the work is incomplete or not fully developed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions ('Probably including...', 'I think...') and asking questions rather than making blunt statements. They also provide helpful references to support their points, which is a constructive approach. The reviewer maintains a professional tone without using overly harsh language, even when pointing out shortcomings."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty and experimental evaluation. They state the paper 'lacks both in terms of technical novelty as well as experimental evaluation' and 'doesn't seem to be ready'. However, it's not entirely negative as they do acknowledge some merits and provide constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer suggestions for improvement. Phrases like 'I would encourage the authors to consider the suggestions' and 'It will be nice to provide results on this task' indicate a polite tone despite the overall negative assessment."", ""The sentiment score is -60 because the reviewer expresses a generally negative view of the paper. They state that the paper lacks 'interesting new ideas' and doesn't see the results as 'significantly interesting for the ICLR community'. The reviewer also doesn't recommend acceptance, which is a clear negative sentiment. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the paper being 'very well aligned with recent literature' and being 'experimentally pretty strong'.\n\nThe politeness score is 20 because while the reviewer maintains a professional tone throughout, there are instances of direct criticism. The reviewer apologizes for their 'pessimistic view', which shows an attempt at politeness. They also use phrases like 'I would recommend' when giving suggestions, which is a polite way to offer criticism. However, the overall tone is quite frank and doesn't go out of its way to be overly polite, hence the relatively low positive score.""]"
"['This paper presents an a particular architecture for conditional discriminators in the cGAN framework. Different to the conventional approach of concatenating the conditioning information to the input, the authors propose to process them separately with two distinct convolutional networks fusing (by element-wise addition) intermediate features of the conditioning branch into the input branch at each layer.\n\nPros:\n+ The writing is mostly clear and easy to follow.\n+ I feel that exploring better conditioning strategies is an important direction. Quite often the discriminator discards additional inputs if no special measures against this behaviour are taken.\n+ The proposed method seem to outperform the baselines\n\nCons:\n- I’m generally not excited about the architecture as it seems a slight variation of the existing methods. See, for example, the PixelCNN paper [van den Oord et al., 2016] and FiLM [Perez et al., 2017].\n- Theoretical justification of the approach is quite weak. The paper shows that the proposed fusion method may result in higher activation values (in case of the ReLU non-linearity, other cases are not considered at all) but this is not linked properly to the performance of the entire system. Paragraph 3 of section 3.1 (sentence 3 and onward) seems to contain a theoretical claim which is never proved.\n- It seems that the authors never compare their results with the state-of-the-art. The narrative would be much more convincing if the proposed way of conditioning yielded superior performance compared to the existing systems. From the paper it’s not clear how bad/good the baselines are.\n\nNotes/questions:\n* Section 3.1, paragraph 1: Needs to be rephrased. It’s not totally clear what the authors mean here.\n* Section 3.1, paragraph 4: “We observed that the fusion …” -  Could you elaborate on this? I think you should give a more detailed explanation with examples because it’s hard to guess what those “important features” are by looking at the figure.\n* Figure 4: I would really want to see the result of the projection discriminator as it seems to be quite strong according to the tables. The second row of last column (which is the result of the proposed system) suspiciously resembles the ground-truth - is it a mistake?\n* Figure 5: It seems that all the experiments have not been run until convergence. I’m wondering if the difference in performance is going to be as significant when the model are trained fully.\n\nIn my opinion, the proposed method is neither sufficiently novel nor justified properly. On top of that, the experimental section is not particularly convincing. Therefore, I would not recommend the paper in its present form for acceptance.', 'This paper proposes a new method to input data to a conditional discriminator network. The standard setup would simply concatenate the ""condition"" image with the ""output"" image (i.e., the real image, or the generator\'s output corresponding to the condition). The setup here is to feed these two images to two separate encoders, and gradually fuse the features produced by the two. The experiments show that this delivers superior performance to concatenation, on three image-to-image translation tasks.\n\nI think this is a good idea, but it\'s a very small contribution. The entire technical approach can be summarized in 2-3 sentences, and it is not particularly novel. Two-stream models and skip connections have been discussed and explored in hundreds of papers. Applying these insights to a discriminator is not a significant leap. \n\nThe theoretical ""motivation"" equations in Sec. 3.1 are obvious and could be skipped entirely. \n\nIn summary, the paper makes sense, but it does not present substantively new ideas. I do not recommend the paper for acceptance. ', 'This paper presents a new method for incorporating conditional information into a GAN for structured prediction tasks (image conditioned GAN problems). The proposed method is based on fusing features from the generated and conditional information in feature space and allows the discriminator to better capture higher-order statistics from the data. The proposed method also increases the strength of the signals passed through the network where the real or generated data and the conditional data agree. The proposed method is conceptually simpler than joint CNN-CRF models and enforces higher-order consistency without being limited to a very specific class of high-order potentials. Thorough experimental results on Cityscapes and NYU v2 verify the efficacy of the proposed method.  I believe this paper shows a promising approach to solve the structured prediction problems that I have not seen elsewhere so far. The paper is written clearly, the math is well laid out and the English is fine.']","[-60, -50, 90]","[20, 20, 70]","[""The sentiment score is -60 because the review is overall negative. While the reviewer acknowledges some pros, such as clear writing and the importance of the research direction, they express significant concerns about the novelty, theoretical justification, and experimental results. The conclusion explicitly states they would not recommend the paper for acceptance. The politeness score is 20 because the reviewer uses generally polite language, acknowledging positive aspects and phrasing criticisms as observations rather than attacks. However, they don't go out of their way to be overly polite, maintaining a professional tone throughout."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('I think this is a good idea'), they ultimately do not recommend the paper for acceptance, citing it as a 'very small contribution' with 'not particularly novel' ideas. The overall tone is critical, especially towards the end. The politeness score is 20 because the reviewer uses relatively neutral language and offers some positive comments, but doesn't go out of their way to be overly polite. They present their criticisms directly but without harsh language, maintaining a professional tone throughout."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, describing it as a 'promising approach' and praising its clarity, mathematical presentation, and language. They also highlight the novelty and efficacy of the proposed method. The politeness score is 70 (polite) due to the respectful and professional tone throughout the review. The reviewer uses phrases like 'I believe' to soften their assertions and provides specific, constructive feedback without any harsh criticism. The language is formal and appropriate for academic discourse, showing respect for the authors' work.""]"
"['This method deals with compressing tiny videos using an end-to-end learned approach. However, the paper has a significant number of limitations, which I will discuss below.\n\n1. The method has only been trained on very small videos due to the fact that fully connected layers are used. I don\'t really understand why was this necessary, and it\'s not explained in the paper at all. Just this fact makes it completely infeasible for any ""real"" application.\n2.  The evaluation was done on very limited domains. Of huge concern to me is the fact that very good results are presented on the sprites dataset. However, that dataset can be literally encoded by providing an index in a lookup table of sprites, so it\'s absolutely ludicrous to compare learned methods on that set to general video compression methods. The results look a lot less exciting when looking at the Kinetics 64x64 dataset. \n3. The evaluation (again) is problematic because the results refer to PSNR. PSNR for video is a very overloaded term. In fact, just the way to compute PSNR is not very clear for video. Video compression papers in general compute it in one of two ways: take the mean squared error over all the pixels in the video, then compute PSNR; or compute per frame PSNR then average. Additionally, none of the papers in this domain use RGB, because the human visual system is much more sensitive to detail preservation (the Y/luminance channel) than they are to chroma (color) changes. When attempting to present results for video, I would recommend to use PSNR-Y (and explain which type it is!), while also mentioning which ITU recommendation is used for defining the Y channel (there are multiple recommendations). \n4. It is not very clear how the global code is obtained. It is implied that all frames get processed in order to come up with f, but does this mean that they\'re processed via an LSTM model, or is there a single fully connected layer which takes as input all frames? In terms of modeling f, it sounds like the hyperprior model from Balle et al is employed, but again it\'s not clear to me how (is it modelling an entire video or a sequence?). I would really like to see a diagram for the network structure that computes f.\n\nOnt he positives of the paper: I applaud the authors with respect to the fact that they made an effort to explain how the classical codecs were configured and being explicit about the chroma sampling that\'s employed. \n\nI think all the problems I mentioned above can be fixed, so I don\'t want to reject the paper per se. If possible, should the authors address my concerns (i.e., add more details), I think this could be an interesting ""toy"" method. ', ""Summary\n=======\nThis work on video compression extends the variational autoencoder of Balle et al. (2016; 2018) from images to videos. The latent space consists of a global part encoding information about the entire video, and a local part encoding information about each frame. Correspondingly, the encoder consists of two networks, one processing the entire video and one processing the video on a frame-by-frame basis. The prior over latents factorizes over these two parts, and an LSTM is used to model the coefficients of a sequence of frames. The compression performance of the model is evaluated on three datasets of 64x64 resolution: sprites, BAIR, and Kinetics600. The performance is compared to H.264, H.265, and VP9.\n\nReview\n======\nRelevance (9/10):\n-----------------\nCompression using neural networks is an unsolved problem with potential for huge practical impact. While there has been a lot of research on deep image compression recently, video compression has not yet received much attention.\n\nNovelty (6/10):\n---------------\nThis approach is a straightforward extension of existing image compression techniques, but it is a reasonable step towards deep video compression. \n\nWhat's missing from the paper is a discussion of how the proposed model would be applied to model video sequences longer than a few frames. In particular, the global latent state will be less and less useful as videos get longer. Should the video be split into multiple sequences treated separately? If yes, how should they be split and what is the impact on performance?\n\nEmpirical work (2/10):\n----------------------\nUnfortunately, the experiments focus too much on trying to make the algorithm look good at the expense of being less informative and potentially misleading.\n\nExisting video codecs such as H.265 and software like ffmpeg are optimized for longer, high-resolution videos, but even the most realistic dataset used here (Kinetics600) only contains short (10 frames) low-resolution videos. I suggest the authors at least add the performance of classical codecs evaluated on the entire video sequence to their plots. The current reported performance can be viewed as splitting the videos into chunks of 64x64x10, which makes sense for an autoencoder which has been trained to learn a global representation of short videos, but is clearly not necessary and detrimental to the performance of the classical codecs. I think adding these graphs would provide a more realistic view of the current state of video compression using deep neural nets.\n\nFor the classical codecs, were the binary files stripped of any file format container and headers before counting bits? This would be crucial for a fair comparison, especially for small videos where the overhead might be significant.\n\nMore work could be done to ensure the reader that the hyperparameters of the classical codecs such as GOP or block size have been sufficiently tuned.\n\nWhat is the frame rate of the videos used? I.e., how much time do 10 frames correspond to?\n\nThe videos were downsampled before cropping them to 64x64 pixels. What was the resolution before cropping?\n\nThe authors observe that the Kalman prior performs worse than the LSTM prior. This may be due to limitations of the encoder, which processes images frame-by-frame, which makes it hard to decorrelate frames while preserving information. I am wondering why the frame encoder is not at least processing one neighboring frame. (Note: A sufficiently powerful encoder could represent information in a fully factorial way; e.g. Chen & Gopinath, 2001).\n\nClarity:\n--------\nThe paper is well written and clear."", 'The paper is well written and the basic ideas are reasonably well explained and supported. However, several aspects are insufficiently explained. Several examples follow.\n\nIn Figure 1, it is not clear at all how the bitstream is formed; frames 1 to T are compressed jointly with frame t; but frame t is part of the set of frames from 1 to T. How the global state updated when compressing frame t+1? Using frames 2 to T+1?\n\nWriting that you use a Laplacian distribution because l1 regularized loss typically outperforms the l`2 loss for autoencoding images is clearly an insufficient justification, if not backed by experiments or references. Moreover, the authors seem to confuse regularization with loss; by using a Laplace density for the generative model, they are using a l1 loss, not an l1 regularizer. \n\nThere is absolutely no information about implementation details.\n\nThe video sequences used in the experiments are extremely small, both in spatial and temporal terms. A collection of 10 64*64 frames has fewer pixels than even a moderately sized still image. As the authors acknowledge, standard video codecs are far from optimized for video sequences of this size, making the comparisons unfair. The extreme compression results on the sprites and BAIR datasets may be quite misleading, since the data lives in a very low dimensional manifold, due to the simplicity of the scenes. For the more realistic Kinetics dataset, the proposed method is competitive with H264 and H265, but only in a very limited range of bit rates. In fact, the authors do not explain why they have not show results for wider ranges of bitrates.\n\n\n']","[-50, -40, -20]","[20, 50, 50]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several significant limitations of the paper. However, it's not entirely negative as the reviewer acknowledges some positives and suggests the issues can be fixed. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They also end on a positive note, suggesting the paper could be interesting if concerns are addressed. The use of phrases like 'I applaud the authors' and 'I don't want to reject the paper per se' contribute to a polite tone despite the critical content."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects (relevance 9/10, novelty 6/10, clarity), they are highly critical of the empirical work (2/10) and point out several significant shortcomings. The overall tone suggests disappointment with the experimental design and results presentation. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and explaining their concerns in detail. They use polite language like 'I suggest' and 'I am wondering' rather than making blunt criticisms. However, some phrases like 'Unfortunately, the experiments focus too much on trying to make the algorithm look good' are more direct, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'well written' and the ideas are 'reasonably well explained and supported', they follow this with several criticisms. The reviewer points out insufficient explanations, lack of implementation details, and potential issues with the experimental setup and comparisons. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They begin with positive comments and phrase their criticisms as observations or questions rather than direct attacks. The reviewer maintains a respectful tone, even when pointing out significant issues, which contributes to the politeness of the review.""]"
"['The paper aims at studying the setting of perturbed rewards in a deep RL setting. Studying the effect of noise in the reward function is interesting. The paper is quite well-written. However the paper studies a rather simple setting, the limitations could be discussed more clearly and there are one or two elements unclear (see below).\n\nThe paper assumes first the interesting case where the generation of the perturbed reward is a function of S*R into the perturbed reward space. But then the confusion matrix does *not* take into account the state, which is justified by ""to let our presentation stay focused (...)"". I believe these elements should at least be clearly discussed. Indeed, in that setting, the theorems given seem to be variations of existing results and it is difficult to understand what is the message behind the theorems.\n\nIn addition, it is assumed that the confusion matrix C is known or estimated from data but it\'s not clear to me how this can be done in practice.  In equation 4, how do you have access to the predicted true rewards?\n\nAdditional comments:\n- The discount factor can be 0 but can not, in general, be equal to 1. So the equation in paragraph 2.1 ""0 < γ ≤ 1"" is wrong.\n- The paper mention that ""an underwhelming amount of reinforcement learning studies have focused on the settings with perturbed and noisy rewards"" but there are some works on the subject (e.g., https://arxiv.org/abs/1805.03359) and a discussion about the differences with the related work would be interesting.', '## Summary\n\nThe authors present work that shows how to deal with noise in reward signals by creating a surrogate reward signal. The work develops a number of results including: showing how the surrogate reward is equal in expectation to the true reward signal, how this doesn\'t affect the fixed point of the Bellman equation, how to deal with finite and continuous rewards and how the convergence time is affected for different levels of noise. They demonstrate the value of this approach with a variety of early and state-of-the-art algorithms on a variety of domains,, and the results are consistent with the claims.\n\nIt would be useful to outline how prior work approached this same problem and also to evaluate the proposed method with existin approaches to the same problem. I realise that this is the first method that estimates the confusion matrix rather than assuming it is known a priori but there are obvious ways around this, e.g. the authors first experiment assumes the confusion matrix is known, so this would be a good place to compare with other competing techniques. Also, the authors have a way of estimating this, so they could plug it into the other algorithms too.\n\nI also have some concerns about the clarity and precision of the proofs, although I do not have any reason to doubt the Lemma/Theorem correctness (see below).\n\nThe weakest part of the approach is in how the true reward is estimated in order to estiamate the confusion matrix. It uses majority vote (which is only really possible in the case of finite rewards with noise sufficiently low that this will be a robust estimate). Perhaps some other approaches could be explore here too.\n\nFinally, there is discussion about adversarial noise in rewards at the beginning but I am not sure the theory really addresses it nor the evaluations.\n\nNonetheless, given that I do not know whether the claim of originality is true (in terms of the estimation of the confusion matrix). If it is, then the work is a significant and interesting advance, and is clearly widely applicable in domains with noisy rewards. It would be interesting to see a more tractable approach for continous noise too, but this would probably involve assumptions (smoothness? Gaussianity?), and doesn\'t impact the value of this work.\n\n## Detailed notes\n\nThere is a slight sloppiness in  notation in equation (1). This uses \\tilde{r} as a subscript of e, but r is +1 or -1 and the error variables are e_+ and e_- (not e_{+1} and e_{-1}).\n\n\nThe noise levels in Atari (Figure 3) show something quite interesting which could be commented upon. For noise below 0.5 the surrogate reward works roughly  similarly to the noisy reward, but when the noise level goes above this, the surrogate reward clearly exploits the increased information content (similar to a noisy binary channel with over 0.5 noise). This may have  implications for adversarial noise.\n\nThere are also some issues with the proofs which I spotted outlined below:\n\n### Lemma 1 proof\nThe proof of Lemma 1, I think, fails to achieve its objective. The first pair of equations is not a rewrite of equation (1). I believe that the authors intend for this to be a consequence of Equation (1) but do not really demonstrate this clearly. Also, the authors seem to switch between binary rewards -1 and +1 and two levels of reward r- and r+ leading to some confusion. I would suggest the latter throughout as it is more general but involves no more terms.\n\nI suggest the following as an outline for the proof. It would help for them to define what they mean by the different rhats (as they currently do) and explain that these values are therefore:\n\n  rhat- = [(1 - e+) r- - e- r+ ]/(1 - e+ - e-)\n  rhat+ = [(1 - e-) r+ - e+ r-]/(1- e+ - e-)\n\nfrom equation (1). What is left is for them to actually prove the Lemma, namely that the expected value of rhat is:\n\n  E(rhat ) = p1(rhat=rhat-) rhat- + p(rhat=rhat+) rhat+ = E(r)\n\nwhere the probabilities relate to the surrogate reward taking their respective values. And just stylistically, I would avoid writing ""we could obtain"" and simply write ""we obtain"".\n\nLemma 2 achieves this more clearly with greater generality.\n\n\n### Theorem 1 proof\nAt the end of p13, the proof of the expected value loses track of the chosen action a. I would suggest the authors replace: $$\\mathbb{P}\'(s,s\',\\hat{r})$$ with $$\\mathbb{P}\'(s,a, s\',\\hat{r})$$ then define it. Likewise $$\\mathbb{P}(s,s\')$$ should be $$\\mathbb{P}(s,a,s\')$$ (and also defined).\n\nI am also a little uncomfortable with the switch from: $$max_{b \\in \\mathcal{A}} | Q(s\',b) - Q*(s\',b)|$$ in the second to last line of p13, which refers to the maximum Q value associated with some state s\', to  $$||Q-Q*||_{\\infty}$$ in the next line which is the maximum over all states and actions. The equality should probably be an inequality there too.\n\nThroughout this the notation could be much better defined, including how to interpret the curly F and how it acts in the conditional part of an expectation and variance.\n\nFinally, there is a bit too free a use of the word ""easily"" here. If it were easy, then the authors could do it more clearly I think. Otherwise, please refer to the appropriate result in the literature.\n', '\nThis paper investigates reinforcement learning with a perturbed reward signal. In particular, the paper proposes a particular model for adding noise to the reward function via a confusion matrix, which offers a nuanced notion of reward-noise that is not too complicated so-as to make learning impossible. I take this learning setting to be both novel and interesting for opening up areas for future work. The central contributions of the work are to 1) leverage a simple estimator to prove the convergence of Q-Learning under the reward-perturbed setting along with the sample-complexity of a variant of (Phased) Q-Learning which they call ""Phrased"" Q-Learning, and 2) An algorithmic scheme for learning in the reward-perturbed setting (Algorithm 1), and 3) An expansive set of experiments that explore the impact of various reward models on learning across different environment-algorithm combinations. The sample complexity term extends Phased Q-Learning to incorporate aspects of the reward confusion matrix, and to my knowledge is novel. Further, even though Theorem 1 is unsurprising (as the paper suggests), I take the collection of Theorem 1, 2, and 3 to be collectively novel.\n\nIndeed, the paper focuses on an interesting and relatively unexplored direction for RL. Apart from the work cited by the paper (and perhaps work like Krueger et al. (2016), in which agents must pay some cost to observe true rewards), there is little work on learning settings of this kind. This paper represents a first step in gaining clarity on how to formalize and study this problem. I did, however, find the analysis and the experiments to be relatively disjointed -- the main sample complexity result presented by the paper (Theorem 2) was given for Phased Q-Learning, yet no experiments actually evaluate the performance of Phased Q-Learning. I think the paper could benefit from experiments focused on simple domains that showcase how traditional algorithms do in cases where it is easier to understand (and visualize) the impact of the reward perturbations (simple chain MDPs, grid worlds, etc.) -- and specifically experiments including Phased Q-Learning. \n\nPros:\n\t- General, interesting new learning setting to study.\n\t- Initial convergence and sample complexity results for this new setting.\n\t- Depth and breadth of experimentation (in terms of diversity of algorithms and environments), includes lots of detail about the experimental setup.\n\nCons:\n\t- Clarity of writing: lots of typos and bits of math that could be more clear (see detailed comments below) [Fixed]\n\t- The plots in Section 4 are all extremely jagged. More trials seem to be required. Moreover, I do think simpler domains might help offer insights into the reward perturbed setting. [Fixed]\n\t- The reward perturbation model is relatively simple.\n\nSome high level questions/comments:\n\t- Why was Phrased Q-Learning not experimented with?\n\t- Why use majority voting as the rule? When this was introduced it sounded like any rule might be used. Have you tried/thought about others?\n\t- Your citation to Kakade\'s thesis needs fixing; it should read:\n\t\t""Kakade, Sham Machandranath. On the sample complexity of reinforcement learning. Ph.D Thesis. University of London, 2003.""\n\n\t\t(right now it is cited as ""(Gatsby 2003)"" throughout the paper)\n\t- You might consider picking a new name for Phrased Q-Learning -- right now the name is too similar to Phased Q-Learning from [Kearns and Singh NIPS 1999].\n        - As mentioned in the ""cons"" section, the confusion matrix is still a somewhat simple model of reward noise. I was left wondering: what might be the next most complicated form of adding reward noise? How might the proposed algorithm(s) respond to this slightly more complex model? That is, it\'s unclear how general the results are, or if they are honed too tightly to the specific proposed reward noise model. I was hoping the authors could respond to this point.\n\n\t\nSection 0) Abstract:\n\t- Not immediately clear what is meant by ""vulnerability"" or ""noisy settings"". Might be better to pick a more clear initial sentence (same can be said of the ""sources of noise..."""")\n\nSection 1) Introduction:\n\t- ""adversaries in real-world"" --> ""adversaries in the real-world""\n\t- You might consider citing Loftin et al. (2014) regarding the bulleted point about ""Application-Specific Noise"".\n\t- ""unbiased reward estimator aided reward robust reinforcement learning framework"" --> this was a bit hard to parse. Consider making more concise, like: ""unbiased reward estimator for use in reinforcement learning with perturbed rewards"".\n\t- ""Our solution framework builds on existing reinforcement learning algorithms, including the recently developed DRL ones"" --> cite these up front So, cite: Q-Learning, CEM, SARSA, DQN, Dueling DQN, DDPG, NAF, and PPO, and spell out the acronym for each the first time you introduce them.\n\t- ""layer of explorations"" --> ""layer of exploration""\n\nSection 2) Problem Formulation\n\t- ""as each shot of our"" --> what is \'shot\' in this context?\n\t- ""In what follow,"" --> ""In what follows,""\n\t- ""where 0 < \\gamma \\leq 1"" --> Usually, $\\gamma \\in [0,1)$, or $[0,1]$. Why can\'t $\\gamma = 0$?\n\t- The transition notation changes between $\\mathbb{P}_a(s_{t+1} | s_t)$ and $\\mathbb{P}(s_{t+1} | s_t, a_t)$. I\'d suggest picking one and sticking with it to improve clarity.\n\t- ""to learn a state-action value function, for example the Q-function"" --> Why is the Q-function just an example? Isn\'t is *the* state-action value function? That is, I\'d suggest replacing ""to learn a state-action value function, for example the Q-function"" with ""to learn a state-action value function, also called the Q-function""\n\t- ""Q-function calculates"" --> ""The Q-function denotes""\n\t- ""the reward feedbacks perfectly"" --> ""the reward feedback perfectly""\n\t- I prefer that the exposition of the perturbed reward MDP be done with C in the tuple. So: $\\tilde{M} = \\langle \\mathcal{S}, \\mathcal{A}, \\mathcal{R}, C, \\mathcal{P}, \\gamma \\rangle$. This seems the most appropriate definition, since the observed rewards will be generated by $C$.\n\t- The setup of the confusion matrix for reward noise over is very clean. It might be worth pointing out that $C$ need not be Markovian. There are cases where C is not just a function of $\\mathcal{S}$ and $\\mathcal{R}$, like the adversarial case you describe early on.\n\n\nSection 3) Learning w/ Perturbed Rewards\n\t- Theorem 1 builds straightforwardly on Q-Learning convergence guarantee (it might be worth phrasing the result in those terms? That is: the addition of the perturbed reward does not destroy the convergence guarantees of Q-Learning.)\n\t- ""we firstly"" --> ""we first""\n\t- ""value iteration (using Q function)"" --> ""value iteration""\n\t- ""Definition 2. Phased Q-Learning"" --> ""Definition 2. Phrased Q-Learning"". I think? Unless you\'re talking about Phased Q from the Kearns and Singh \'99 work.\n\t- ""It uses collected m samples"" --> ""It uses the collected m samples""\n\t- Theorem 2: it would be helpful to define $T$ since it appears in the sample complexity term. Also, I would suggest specifying the domain of $\\epsilon$, as you do with $\\delta$.\n\t- ""convergence to optimal policy"" --> ""convergence to the optimal policy""\n\t- ""The idea of constructing MDP is similar to"" --> this seems out of place. The idea of constructing which MDP? Similar to Kakade (2003) in what sense?\n\t- ""the unbiasedness"" --> ""the use of unbiased estimators""\n\t- ""number of state-action pair, which satisfies"" --> ""number of state-action pairs that satisfy""\n\t- ""The above procedure continues with more observations arriving."" --> ""The above procedure continues indefinitely as more observation arrives."" Also, which procedure? Updating $\\tilde{c}_{i,j}$? If so, I would specify.\n\t- ""is nothing different from Eqn. (2) but with replacing a known reward confusion"" --> ""replaces a known reward confusion""\n\n\n4) Experiments:\n\t- Diverse experiments! That\'s great. Lots of algorithms, lots of environment types.\n\t- I expected to see Phrased Q-Learning in the experiments. Why was it not included?\n\t- The plots are pretty jagged, so I\'m left feeling a bit skeptical about some of the results. The results would be strengthened if the experiments were repeated for more trials.\n\n5) Conclusion:\n\t- ""despite of the fact"" --> ""despite the fact""\n\t- ""finite sample complexity of Q-Learning with estimated surrogate rewards are given"" --> It\'s not really Q-Learning, though. It\'s a variant of Q-Learning. I\'d suggest being explicit about that.\n\nAppendix:\n\n\t- ""It is easy to validate the unbiasedness of proposed estimator directly."" --> ""It is easy to verify that the proposed estimator is unbiased directly.""\n\t- ""For the simplicity of notations"" --> ""For simplicity""\n\t- ""the Phrased Q-Learning could converge to near optimal policy"" --> """"the algorithm Phrased Q-Learning can converge to the near optimal policy""""\n\t- ""Using union bound"" --> ""Using a union bound""\n\t- Same comment regarding $\\gamma$: it\'s typically $0 \\leq \\gamma < 1$.\n\t- Bottom of page 16, the second equation from the bottom, far right term: $c.j$ --> $c,j$.\n\t- ""Using CauchySchwarz Inequality"" --> ""Using the Cauchy-Schwarz Inequality""\n\n\nReferences:\n\tLoftin, Robert, et al. ""Learning something from nothing: Leveraging implicit human feedback strategies."" Robot and Human Interactive Communication, 2014 RO-MAN: The 23rd IEEE International Symposium on. IEEE, 2014.\n\n\tKrueger, D., Leike, J., Evans, O., & Salvatier, J. (2016). Active reinforcement learning: Observing rewards at a cost. In Future of Interactive Learning Machines, NIPS Workshop.']","[-20, 50, 60]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting', 'quite well-written'), they express several concerns and limitations of the paper. The overall tone suggests that significant improvements are needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'could be discussed more clearly' and 'it's not clear to me' which maintain a polite tone while expressing concerns. The reviewer also provides specific suggestions and additional references, which is helpful and courteous."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the value and significance of the work, they also point out several areas for improvement and express some concerns. The overall tone is constructive and appreciative of the work's potential impact, but not overwhelmingly positive. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledges the potential importance of the work, and frames criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'It would be useful to...', 'I also have some concerns...', and 'Perhaps some other approaches could be explored...' demonstrate a considerate approach to feedback. The reviewer also balances critiques with positive observations, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the novelty and interest of the paper's topic, and lists several pros. They do mention some cons and areas for improvement, but these are balanced against the positive aspects. The overall tone is constructive and encouraging. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or gentle recommendations rather than demands. They acknowledge the strengths of the work while providing detailed, helpful feedback for improvement. The use of phrases like 'I think', 'you might consider', and 'I was left wondering' contribute to the polite tone.""]"
"[""This work proposes to use duality gap and minimax loss as measures for monitoring the progress of training GANs. The authors first showed a relationship between duality gap(DG) and Jensen-Shannon divergence and non-negativeness on DG. Then, a comprehensive discussion was presented on how to estimate and efficiently compute DG. A series of experiments were designed on synthetic data and real-world image data to show 1) how duality gap is sensitive to capture non-convergence during training and 2) how minimax loss efficiently reflects the sample quality from generator. \n\n\nI was not very familiar with GANs, thus I'm not sure on the significance of paper and would like to see opinions from other reviews on this. For reviewing this paper, I also read the cited works such as Salimans (2016), Heusel (2017). Compared with them, the theoretical contribution of this work seems less significant. Also, I'm not quite impressed by the advantages of proposed metrics. However, this work is nicely written, the ideas are delivered clearly, experiments are nicely designed. I kind of enjoying reading this paper due to its clarity.\n\n\nOther concerns:\n\nThere are two D_1 in Equation Mixed Nash equilibrium.\n"", ""The focus of the submission is GANs (generative adversarial network), a recent and popular min-max generative modelling approach. Training GANs is considered to be a challenging problem due to the min-max nature of the task. The authors propose two duality-inspired stopping criteria to monitor the efficiency and convergence of GAN learning.  \n\nThough training GAN can have some useful applications, the contribution of the submission is pretty moderate. \ni) Duality-inspired approaches, embedded also in optimization have already been proposed: see for example 'Xu Chen, Jiang Wang, Hao Ge. Training Generative Adversarial Networks via Primal-Dual Subgradient Methods: A Lagrangian Perspective on GAN. ICLR-2018.'.\nii) The notion of generator and discriminator networks with unbounded capacity (which is an assumption in 'Proposition 1') lacks formal definition. I looked up the cited Goodfellow et al. (2014) work; it similarly does not define the concept. Based on the informal definition it is not clear whether they exist or are computationally tractable. \n\nMinor comments:\n-MMD is a specific instance of integral probability metrics when in the latter the function space is chosen to be the unit ball of a reproducing kernel Hilbert space; they are not synonyms.\n-mixed Nash equilibrium: E_{v\\sim D_1} should be E_{v\\sim D_2}.\n-It might be better to call Table 1 as Figure 1.\n-References: abbreviations and names should be capitalized (e.g., gan, mnist, wasserstein, nash, cifar). Lucic et al. (2017) has been accepted to NIPS-2018."", ""In this paper, the authors proposed the duality gap as the criterion for evaluating the training of GAN. To justify the proposed criterion, the authors designed empirical experiments on both synthetic and real-world datasets to demonstrate the ability of the duality gap for detecting divergence, mode collapse, sample equality, as well as the generalization to other application domains besides image generation. Comparing with the existing criteria, e.g., FID and INC, the duality gap shows better ability and computational efficiency. \n\n\nHowever, the paper ignores rich literatures in optimization that uses the duality gap as the criterion for characterizing the convergence of algorithms for min-max saddle point problem, e.g., [1]. In fact, in optimization community, using duality gap to screening the convergence on saddle point problem is a common knowledge. [1] even provides the finite-step convergence rate when the saddle point problem is convex-concave. This paper is only introducing that into machine learning community. Therefore, the novelty of the paper seems not enough. \n\nSecondly, the duality gap is only able to screen the optimization convergence and the solution quality w.r.t. **the same objective**. It is not valid to compare different GANs with different losses function using the duality gap. Theoretically, for any loss function derived from some divergences, e.g. [2], the global optimal solution  can always achieve zero duality gap. In other words, for different GANs, with different objectives, the duality gap cannot distinguish which one is better. In such sense, the title is very misleading. \n\nThirdly, how the evaluate such criterion in practice in GAN scenario is not clearly explained. Considering the neural network parametrization of both the generator and discriminator, the argmax_v M(u, v) and argmin_u M(u, v) is not tractable. Without the optimal solution, what is the meaning of the ``duality gap'' should be explained. What will happen if we only obtain the suboptimal solutions which themselves are model collapsed? Without such discussion in both theoretical and/or empirical aspects, I am not very convincing about the conclusion. \n\nFinally, if one follows the Fenchel dual view of GAN in [2, 3], the min-max is the variational form of some divergences, which the GANs are directly optimizing. It is straightforwardly to see the better min-max value is, the smaller divergence between generated samples and ground-truth is, and thus, the better quality of the generator is. The fact that min-max objective is indeed able to characterize the quality of generator is obvious and well-known. Otherwise, there is not need to use such objective in the optimization to train the model. \n\n\n[1] Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). Robust stochastic approximation approach to stochastic programming. SIAM J. on Optimization, 19(4):1574–1609.\n\n[2]  I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), pages 2672–2680, 2014.\n\n[3] S. Nowozin, B. Cseke, and R. Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. arXiv:1606.00709, 2016""]","[-20, -30, -50]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nicely written', 'ideas are delivered clearly', 'experiments are nicely designed'), they express concerns about the significance of the paper's contribution and are 'not quite impressed by the advantages of proposed metrics'. The overall tone suggests mild disappointment or lack of enthusiasm. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise ('I was not very familiar with GANs'), and frames criticisms in a constructive manner. They even mention 'enjoying reading this paper due to its clarity', which is a polite way to offer praise even while expressing concerns."", ""The sentiment score is -30 because while the reviewer acknowledges the focus on GANs and the authors' proposal, they state that the contribution is 'pretty moderate' and point out limitations in the work. They also mention that similar approaches have already been proposed, indicating a somewhat negative view of the paper's novelty. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They provide specific examples and references to support their points, which is helpful. The tone is not overly harsh, but rather matter-of-fact. The use of phrases like 'it might be better' and offering minor comments shows a degree of politeness and consideration for the authors."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper in the first paragraph, the majority of the review is critical. The reviewer points out several significant issues, including lack of novelty, misleading title, and unclear explanations. These criticisms outweigh the initial positive comments, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I am not very convincing' rather than more harsh language. The reviewer also provides specific references and explanations for their criticisms, which is a polite way to offer feedback. However, the review is not overly polite or deferential, maintaining a neutral to slightly positive politeness level.""]"
"['The paper propose to incorporate an additional class for adversarial and out-distribution samples in CNNs. The paper propose to incorporate natural out-distribution images and interpolated images to the additional class, but the problem of selecting the out-distribution images is itself an important problem. The paper presents a very simple approaches for selecting the out-distribution images that relies on many hidden assumptions on the images source or the base classier, and the interpolation mechanism is also too simple and there is the implicit assumption of low complexity images. There exists more principled approaches for selecting out-distribution images that has not considered here like those based on uncertainty estimation or recently proposed direct out-distribution detectors.\nIn summary, the quality of the paper is poor and the originality of the work is low. The paper is easily readable.', 'The idea of having a separate class for out-distribution is a very interesting idea but unfortunately previously explored. In fact, in machine learning and NLP there is the OOV class which sometimes people in computer vision also use. Some of the claims in the paper can be further substantiated or explored. For example in abstract there is a simple claim that is presented too strong: We also demonstrate that training such an augmented CNN with representative out-distribution natural datasets and some interpolated samples allows it to better handle a wide range of unseen out-distribution samples and black-box adversarial examples without training it on any adversaries. This claim is bigger than just CNNs and needs to be studied in a theoretical framework not an empirical one. Also, one simple way to stop these adversarial cases would be to explore using Sigmoid as opposed to softmax. In general it is very unlikely that you will be able to choose every variation of out-distribution cases. Much easier if you just try to solve the problem using a set of n Sigmoids (n total number of classes) and consider each output a probability distribution. \n\nHowever, the studies in this paper are still valuable and I strongly recommend continuing on the same direction. ', 'This paper proposed to add an additional label for detecting OOD samples and adversarial examples in CNN models. This research direction seems interesting, however, the idea of using an extra label for OODs is not new and was previously explored in different domains. I would expect the describe how their method is different, and keep the research from that point.\nAdditionally, there are several claims in this paper which I\'m not convinced are true, such as the over-generalization of CNNs, the choice of OODs (recent studies have shown NNs are not well calibrated, so using softmax as the confidence might not be the best idea), etc.\nReg. the results, did the authors compare their method to existing adv. example detection methods, such as Ma, Xingjun, et al. ICLR (2018) ""Characterizing adversarial subspaces using local intrinsic dimensionality."" ? or some other method? \nMoreover, in Table 2. I\'m not sure what should I conclude from the ""Naive Model Error"" on OOD samples.\n']","[-70, -20, -30]","[-20, 50, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper's quality is 'poor' and its originality is 'low'. They criticize the approach as 'very simple' and relying on 'many hidden assumptions'. The reviewer also points out that better approaches exist which were not considered. The only positive comment is that the paper is 'easily readable'. For politeness, the score is -20. While not overtly rude, the language is quite direct and critical without much attempt to soften the criticism or offer encouragement. Phrases like 'quality of the paper is poor' and 'originality of the work is low' are particularly blunt. However, it's not extremely impolite, as it doesn't use personal attacks or overly harsh language."", ""The sentiment score is slightly negative (-20) because the reviewer points out that the main idea has been previously explored and some claims are presented too strongly. However, they also mention that the studies are valuable and encourage continuing in the same direction, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the value of the work, and provides constructive feedback. They use phrases like 'very interesting idea' and 'strongly recommend continuing' which contribute to the polite tone. The reviewer also offers suggestions for improvement without being harsh or dismissive."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the research direction as interesting, they express several concerns and criticisms about the paper. They point out that the idea is not new, question some of the claims made, and ask for comparisons with existing methods. These criticisms outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is mildly positive (20) as the reviewer uses relatively neutral language and phrases their criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I would expect' and 'I'm not sure what should I conclude' which maintain a respectful tone while still conveying their concerns. The reviewer also acknowledges the potential interest of the research direction, which adds to the politeness of the review.""]"
"['The paper presents the use of an invertible transformtion layer in addition to the conventional variational autoencoder to map samples from decoder to image space, and shows it improves over both synthesis quality and diversity. \nThe paper is well motivated, and the main motivation is nicely presented in Fig.1, and the main idea clearly shown in Fig.2 in an easy-to-understand manner. Existing works are properly discussed in the context before and after the main method. Convincing results are presented in the experimental section, with ablation tests in Tables 1-3, quantitative comparison in Table 4, and qualitative visual images in Figs.4-5. \n\nI incline to my current score after reading the response and other reviews.', ""It is well known that optimizing divergences of different directions leads to different learning behaviors - the mode covering behavior of maximum likelihood training and the mode missing behavior of GAN training. This paper makes a good presentation in explaining coverage-driven training and quality-driven training. \nTechinically, this paper make two contributions. First, extend VAEs by using deterministic invertible transformation layers to map samples from the decoder to the image space. Second, use the loss Eq. (8) to train the generator.\n\nHowever, there are some unclear issues.\n\nFirst, the differences between losses may not fully explain the behavior of GANs [I. J. Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. arXiv:1701.00160, 2017], as also seen from some recent studies. For example, using the sum of two divergences [Chen et al., 2018] does not make a significant improvement. \nAlso shown in Table 1, CQ performs better than VAE, but is inferior to GAN.\nUsing the two-term loss Eq. (8) may not be the key for improvement.\n\nOnly after adding the additional flow-based layers, CQF outperforms GAN. Therefore, in Table 1, it would be better to include the result of VAE using the additional flow-based layes for ablation study. \n\nSecond, it is also not clear from the paper that such VAE using the additional flow-based layes is new or not.\n\nThird, the results are not as good as the state-of-the-art. In Table 4, SN-GANs perform the best in three out of four cases.\n\nFourth, the model consists of three networks - encoder, decoder and discriminator. Evaluation about the model's inference capability is necessary in addition to showing its generation capability, since it is equipped with a decoder.\n\nSome typos:\nP5: L_Q(p*)+L_Q(p*) ?\nTable 4: QSF ?"", ""\nThe paper proposes to alleviate two issues with VAEs and GANs\nMode covering behaviour of the MLE loss used in VAEs causing blurry image samples despite high likelihood scores (Coverage driven training in the paper)\nPoor likelihood scores in GAN based models despite great looking amples (Quality driven training in the paper)\n\nBoth of these issues are well known and have been previously described in the literature (e.g. MLE models: bishop 2006, GANs: arjovsky et. al. 2017 or sonderby et. al. 2017)\n\nThe main contribution of the paper are described in the Eq (8) augmenting the VAE ELBO (L_C term) with a GAN-discriminator based loss (L_Q term). Combining the fact that the L_Q loss (essentially MLE) minimises KL[data|model] and L_Q discriminator loss used minimises KL[model|data] the authors show that this in theory minimizes a lower bound on the forward and reverse KL divergence i.e. somewhere between mode-covering and mode-seeking behavior\n\nAs a secondary contribution the authors show that adding a flow based module to the generative model p(x|z) increases both the likelihood and the fidelity of the samples. \nThe experimental section seems sound with extensive results on CIFAR10 and some additional results on STL, LSUN, CelebA and ImageNet. \n \nComments\nOverall i find the paper well written and easy to understand and the experiments seems sound. My main criticism of the paper is the novelty of the proposed model. Adding a VAE and a GAN has been done before (e.g. Larsen 2016 as the authors cite as well). Outside of generative models the combination of MLE and GAN based losses have been studied in e.g. Super-Resolution (Shi et. al. 2016). In both papers of these papers the GAN based losses are added for exactly the same reasons as provided in this work i.e. to increase the sample fidelity. \n\nI’m unsure if adding a flow to the output of the VAE generative model have been done before, however in spirit the approach is quite similar in the ideas in “Variational Lossy Autoencoder” (Chen 2016) or PixelVAEs (Gulrajani 2016) where local covariance is added through conditional factorization.\n \t \t \t\t\t\t\t\nQuestions\nQ1) One criticism of the results is that the authors claim that the model achieves likelihood values competitive with state-of-the-art where the results seems to suggest that a more sound conclusion is that the the likelihoods are better than GANs but worse than MLE models such as PixelCNN++. Similarly for the Inception/FID scores where the model is better than VAEs but most of the time slightly worse than pure GAN models. ?\n\nQ2) I find the claim “we propose a unified training approach that leverages coverage and quality based criteria” a bit overreaching. The loss in Eq(8) is simply the sum of a VAE and a GAN based loss and as such does not provide any unification of the two ?\n\nQ3) Related to the previous question The KL-divergence interpretation of the GAN based loss assumes a bayes optimal discriminator. In practice this is usually never achieved why it is not really known what divergence GANs minimize if any (see e.g Fedus et. al. 2017 for a non-divergence minimization view). If the KL-divergenve minimization interpretation does not hold the proposed model is essentially a VAE with an auxiliary GAN loss biasing the model towards mode-seeking training? \n\nQ4) There haven’t been many successful GAN usages outside of of the CNN-realm which suggests that a successful GAN is tightly connected to the inductive bias provided by CNNs for images. Have the authors tried there model on something else than images? (I suspect that the GAN based L_Q loss will be hard to apply outside of the realm of images)\n\t\nOverall i find the paper well written and easy to understand and the experiments seems sound.  However I think that closely related variants of the main contributions in the paper have been tried elsewhere which somewhat reduces the novelty of the proposed model. Given my comments above I think the paper is marginally below acceptance however I could be be convinced otherwise by e.g. a solid use-case for models like this?\n\nLastly, I'm sorry for the late review (I was called upon late to review the paper) - I hope that you will find the time for a proper rebuttal to my questions. ""]","[80, -20, -20]","[50, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, noting it is 'well motivated' with 'convincing results' and 'properly discussed' existing works. The reviewer also mentions 'easy-to-understand' figures and 'nicely presented' motivation. The politeness score is 50 (somewhat polite) as the reviewer uses neutral, professional language without overly formal or informal expressions. They provide constructive feedback without harsh criticism, maintaining a respectful tone throughout. The final sentence indicates the reviewer has considered other perspectives, showing a fair and open-minded approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('good presentation', 'two contributions'), they raise several critical issues and limitations. The review points out that the paper's main claims may not fully explain the observed behaviors, the results are not state-of-the-art, and there are missing evaluations. These criticisms outweigh the initial positive comments.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin with positive observations before moving to criticisms, which are presented as 'unclear issues' rather than outright flaws. The reviewer also offers constructive suggestions for improvement and even points out typos, which shows attention to detail without being overly harsh. The tone remains objective and academic throughout, avoiding personal attacks or overly negative language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written and easy to understand', 'experiments seems sound'), they express significant concerns about the novelty of the work and conclude it is 'marginally below acceptance'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, phrases criticisms as questions or suggestions rather than direct attacks, and even apologizes for the late review. The reviewer maintains a professional and constructive tone, even when expressing concerns.""]"
"['This paper provides an algorithm that excludes the bad training data in the training process and obtain a more accurate model for both supervised and unsupervised learning problem. The paper gives the theoretical guarantee for mixed linear regression and Gaussian mixture model, and also conducts the experiments for deep image classification and deep generative models.\n\nMajor Concerns:\n1, As said in related work, a soft version of this paper’s method has been proposed in the previous work, and the major seems to be that there is no initialization in the previous work which only leads to local convergence. Therefore, based on my understanding, the only innovation in this paper is that it gives the initialization process so that the algorithm can converge to the global optimal solution. But even this innovation only successes on some specific problems (Section 4-7). There are too few innovations.\n\n2, In Section 4, for mixed linear regression, Theorem 1 and Theorem 2 together can not guarantee the global optimal solution for the algorithm. The author should demonstrate  “strict inequality” property in the 3rd line in Theorem 2, because it should correspond to the  “strict inequality” property in the 2nd line in Theorem 1.\n\n3. Another angle to view the target problem in paper is from the outlier detection problem. The sparse learning formulation and theory can be conducted to solve this problem. Many existing theoretical analysis methods and optimization methods can be applied. For example, authors can refer to \n\nA Robust AUC Maximization Framework With Simultaneous Outlier Detection and Feature Selection for Positive-Unlabeled Classification, 2017\n\nThe comparison to these type of methods need to be included. \n\nMinor Concerns:\n1, Theorem 2 does not give the probability, only mentioning “high probability”. How high? I do not find the probability in the proof as well. The same concern happens to Theorem 4. I think that\n\n2, In Section 6 and 7, the author does not compare with other algorithms, which can not show the advantage of this algorithm.', ""This paper introduces a framework for situation when the training samples are not pure. The idea is a simple approach by training a model and removing a portion of examples from the training set based on the loss of the model. The authors provide some theoretical study on two models: linear regression and Gaussian mixture model and utilize deep neural network to show their framework performs well experimentally. \n\nMy main problem with this work is the difficulty in understanding whether the reason our training model produces a large loss on some examples is due to them being bad examples or is because the model is not good enough and needs improvement. For example, one can always overtrain a classifier such that it classifies the training examples perfectly. Now the question become how much should I train my classifier. In case of Deep Neural Networks for example, the number of epochs can change the loss occurred by classifiers on the examples and it is not easy to know when to stop training in order to utilize the procedure introduced in this work.\n\n\nThe theoretical work is related to linear regression and Gaussian Mixture model but the experiments are relayed to Deep Neural Nets! So I am not sure if this setup makes sense. Either both should be for DNN or neither should be.\n\nI am not sure if I understand Section 5 and the discussion related to the Gaussian Mixture Model. In Gaussian Mixture model, there are multiple components and each commonest has its own parameteres. So not sure (1) why the authors assume only mean parameter. (2) Given that Gaussian mixture model assumes multiple components, doesn't it automatically address the problem by putting the samples from different distribution in a different component?\n\nPage 5 typo: closest point closest to\n\nThe parameter \\tau is set to 5 percent less that the true ratio of good samples (correct labels). This seems a pretty bias choice and implicitly applied that one needs to know the true value of this ratio which is a huge expectation. The authors need to investigate the effect of the changes of this value on the performance of their proposed framework! To me, it seems that the results can be hugely affected by the value of this parameter. \n\nThe experiment with GAN is very wired. How can you expect to have a data set with 20 percent of its examples be bad cases. The authors need to justify that such cased can happen in real applications. \n"", 'The authors propose an iterative method for discarding outlying training data: first, learn a model on the entire training dataset; second, identify the training examples that have high loss under the learned model; and then alternate between re-learning the model on the training examples that do not have high loss, and re-identifying the training examples with high loss under the new model. This method works for both supervised and unsupervised learning, and the authors show that in theory, their method has some convergence properties in the mixed linear regression and Gaussian mixture model settings. The authors also run some experiments on neural networks and datasets with synthetic noise to show the benefits of their proposed method.\n\nThe problem of noisy datasets is relevant to almost all machine learning problems in the real world, and the authors\' method shows promise as a straightforward way to increase performance on such noisy data. However, my opinion is that the authors need to make a stronger case, theoretically and/or experimentally, for why their method should be preferred to other methods. Detailed comments follow.\n\n== Experiments ==\n1) No comparisons are provided to other outlier detector methods (e.g., based on nearest neighbors, distance to centroid, influence functions, etc.) or techniques that also purport to deal with noisy labels (e.g., by modifying the learning algorithm or loss function). While there are too many existing methods to expect the authors to benchmark against all of them, it\'s important to at least have a couple of representative comparisons. \n\n2) It\'d be nice to have an ablative analysis to tease out the factors behind the gain in accuracy. For example, is the iteration important, or would a single pass suffice? How robust is the algorithm to tau, the fraction of data to discard? (The authors do test initializing randomly vs. initializing on the full dataset.) \n\n3) The systematic label noise scenario seems to favor the authors\' method (though the authors claim that it is a harder scenario than random label noise). It\'d be helpful to see if the method works against random noise.\n\n== Theory ==\n4) The assumptions seem very restrictive. For example, for mixed linear regression (section 4), the features of all examples are assumed to be drawn i.i.d. from an isotropic Gaussian (so even the bad samples are drawn from the same distribution as the good samples; and all features are independent). To my knowledge, this is not a ""standard and widely studied"" assumption. For the Gaussian mixture model (section 5), a similar isotropic Gaussian assumption is made for each mixture. \n\n5) Beyond the independence assumptions mentioned above, the initialization results make additional assumptions on the ""bad"" data (e.g., average distance of the good vs. bad parameters) that I found hard to parse. How strong are these assumptions? Do they hold on real datasets?\n\n6) The convergence results (Theorems 1 and 3) have a constant term sigma in them. This is surprising and seems to me to considerably weaken the result -- one would expect that the dependence on sigma will decrease with n.\n\nI think either a strong experimental or strong theoretical section would be sufficient for me to recommend acceptance. However, the paper currently shows potentially interesting experimental/theoretical results but does not do a comprehensive job of either side.']","[-50, -40, -20]","[20, 20, 60]","[""The sentiment score is -50 because the review is generally critical, pointing out several major concerns and limitations of the paper. The reviewer acknowledges some positive aspects (e.g., theoretical guarantees and experiments) but emphasizes the lack of innovation and insufficient comparisons. The politeness score is 20 because the language used is professional and constructive, without personal attacks. The reviewer uses phrases like 'Based on my understanding' and provides specific suggestions for improvement, which maintains a respectful tone despite the critical content. The review is structured and objective, focusing on the paper's content rather than using harsh or impolite language."", ""The sentiment score is -40 because the reviewer expresses several concerns and criticisms about the paper, including the difficulty in understanding the approach, inconsistencies between theoretical work and experiments, and issues with parameter choices. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the theoretical study and experimental performance. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'My main problem with this work is...' and 'I am not sure if I understand...', which are polite ways to express concerns. The reviewer also offers constructive feedback and suggestions for improvement, which is a polite approach to criticism. However, the language is not overly formal or deferential, keeping the score relatively close to neutral."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the relevance and potential of the proposed method, they express significant concerns about the lack of comparisons to other methods, the need for stronger theoretical or experimental justification, and limitations in the assumptions and results. The overall tone suggests that major revisions are needed before the paper can be accepted. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the promise of the work and framing criticisms as suggestions for improvement rather than outright dismissals. They use phrases like 'it'd be nice to have' and 'it'd be helpful to see' when requesting additional analyses, which maintains a constructive tone. The reviewer also balances critique with positive comments, such as noting the relevance of the problem and the potential of the method.""]"
"['In this paper, the authors proposed \'defensive distinction\' to address questions: Are adversarial examples distinguishable from natural examples? Are adversarial examples generated by different methods distinguishable from each other?\n\nI have some major concerns about this submission.\n\n1) The presentation of this work should further be improved. It contains many vague sentences. For example, ""Unfortunately, even state-of-the-art defense approaches such as adversarial training and defensive distillation still suffer from major limitations and can be circumvented."" I really hope I can see some justifications based on authors\' approach for this argument. Also, the definition of \'AdvGen-Model\' is not clear. Do you mean Adversarial attack generator knows the network model (i.e., white-box attack)? It is also not clear that how representative scenarios and cases in Table 1 affect the implementation of the proposed experiments (implementation details rather than results). \n\n2) The technical contribution of this paper is weak, and the experiments are not enough to support its main claim. MNIST is a simple dataset, please try larger and more complex datasets. The contribution of the current version is limited. \n\n ', ""Defensive Distinction (DD) is an interesting model for detecting adversarial examples. However, it leaves some key aspects of defense and distinction out. Firstly, one can argue that if you know the adversaries of your model you can simply regularize the model for them. Even if regularization doesn't work fully, the DD model still suffers since it can have its own adversarial examples. From distinction perspective, it would be hard to believe that every single adversarial example will be detected, at least not without some solid theoretical background. It seems that  and natural examples are being thrown at the DD model without an elegant approach. \n\nI have the following concerns about the visualization and understanding of what DD does, which I believe should have been the focus of this paper. It was not immediately clear, what the message of the paper is or the claimed message was too weak: detecting adversarial examples using a classifier. It was not immediately clear why this is a good idea (since an adversarial example can be an adversary of both original network and DD) or what the DD learns.\n\nFurthermore, from experimental perspective, it is not sufficient to just perform experiments on one dataset, specially if the claim is big. You should consider running your model on multiple datasets and reporting what each DD learned. Furthermore, you should establish better comparison and back your claims with proper references. Some claims were too strong to believe without reference. \n\nI do look forward to seeing more about the visualization and intriguing properties which may arise from continuation of your studies. In the current state, I vote to reject until a more clear demonstration of your work comes out. \n"", 'Summary: The authors propose two research questions: (1) Are adversarial examples distinguishable from natural examples? And (2) are adversarial examples generated by different methods distinguishable from each other? They find positive answers to both questions according to their experiments, and propose a method for detecting adversarial examples.\n\nThe authors take the viewpoint of varying how much the defender knows about its attackers. How they define whether a defender “knows” an attackers’ model, source examples, or adversarial generation parameters, is through keeping characteristics of various test sets the same with the training set. For example, to test the effectiveness of when the defender “knows” the adversarial generation parameters, they will have a test set where the adversarial generation parameters are the same with the training set, but will possibly vary other characteristics. They do all their experiments on MNIST.\n\nIn the first experiment (Section 4.2), the authors find that a deep neural network binary classifier for detecting adversarially-tainted images does well when the adversarial generation parameters are known, and not as well when unknown. Thus, the author’s conclude “it is always beneficial for defenders to train a DDP-Model by using adversarial examples generated based on a variety of parameters. Meanwhile, the exact model architecture, and the exact natural examples used by attackers are not influential in the accuracy of the defenders’ models.”\n\nIn the second experiment (Section 4.3), the authors test whether a neural network is able to classify an image as adversarial if images from a particular adversarial generation method is left-out of the training samples, but all others are included. They conclude that the network has the hardest time when samples from L-BFGS and JSMA are left-out of the training sample.\n\nIn the last experiment (Section 4.4), the authors test whether a deep neural network can classify adversarially-generated images according the the generation method. The answer is affirmative, and they conclude, “Similar to what is observed for a DDP-Model in Section 4.2 and 4.3, it is also beneficial for defenders to train a DDS-Model by using adversarial examples generated based on a variety of parameters; meanwhile, the exact model architecture and the exact natural examples used by attackers are not influential in the accuracy of the defender’s models.”\n\n\nStengths: The authors’ research questions are interesting and worthy of more investigation, namely whether we can detect adversarial examples. They also have nice experiments and make nice heuristic conclusions.\n\n\nWeaknesses: The main complaint I have is that the authors only use the MNIST dataset. And we know that the MNIST dataset is special, so I would have liked to see the same tests on different datasets, and possibly different model architectures. I think this will be a much better contribution to the field with these additions.\n\n\nOther comments:\nThe paper is clearly written and their experimental methodology seems original, and examining whether adversarial examples can be distinguished from untainted examples is important. But only using MNIST currently severely lowers the significance of this work. I think with more datasets and perhaps different model architectures, this can become a nice contribution to the field.\n\nPerhaps a minor point, but their terminology of “natural” might not be the best, as MNIST is not usually considered as a “natural image,” although I am aware that what the author say is “natural” means “original,” or “untainted”. I would maybe suggest the authors change this terminology.']","[-70, -60, 50]","[20, 20, 80]","[""The sentiment score is -70 because the reviewer expresses 'major concerns' about the submission and points out several weaknesses, including poor presentation, vague sentences, weak technical contribution, and insufficient experiments. The use of phrases like 'should further be improved' and 'the contribution of the current version is limited' indicate a negative sentiment towards the paper. However, it's not entirely negative as the reviewer acknowledges the authors' attempt to address important questions.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone. They use phrases like 'I really hope I can see' and 'please try' which are constructive and polite ways of suggesting improvements. The reviewer also avoids personal attacks or overly harsh language. However, the directness of the criticism prevents a higher politeness score."", ""The sentiment score is -60 because the review is generally critical and recommends rejection. The reviewer points out several weaknesses and concerns about the paper, such as leaving out key aspects, lack of theoretical background, and insufficient experiments. However, it's not entirely negative as the reviewer acknowledges the model as 'interesting' and expresses interest in future work. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They avoid harsh or rude phrasing, instead using more neutral terms like 'I have the following concerns' and 'It was not immediately clear'. The reviewer also ends on a somewhat positive note, expressing interest in future work. However, the overall tone is still more critical than overtly polite, hence the relatively low positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strengths of the paper, calling the research questions 'interesting and worthy of more investigation' and praising the 'nice experiments and heuristic conclusions'. However, they also point out significant weaknesses, particularly the limited use of only the MNIST dataset, which 'severely lowers the significance of this work'. This balance of positive and negative comments results in a slightly positive overall sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They offer criticism in a gentle manner, using phrases like 'The main complaint I have...' and 'I would have liked to see...'. The reviewer also provides specific suggestions for improvement and ends on a positive note, suggesting how the paper could become 'a nice contribution to the field'. This approach demonstrates professional courtesy and respect for the authors' work.""]"
"['The paper deals with a problem of expressiveness of a piecewise linear neural network, characterized by the number of linear regions of the function modeled. This is one of the widely accepted measure of expressiveness of a linear model. As such, it has been studied before. The main contributions of the paper are:\n1) Different algorithms are proposed that allow to compute the bounds faster, leveraging probabilistic algorithms\n2) Tighter bounds are obtained \nI find the results somewhat interesting. However, I do not think there is a lot of practical value in having faster algorithms for obtaining the bounds, as they are not used in practice anyway. I am also not convinced that the quest for tighter-and-tighter bounds in this approach is the right scientific direction. I find the paper to be an interesting contribution, but of a marginal value to the progress of the domain and for the improvement of our understanding of the models.', ""Summary:\nThis paper builds off of previous work that has studied the counting of linear regions in deep neural networks. The function learned by a deep neural network with piecewise linear activations (such as Relus) is itself piecewise linear on the input, and a measure of expressiveness of the network has been to count the number of linear regions.\n\nHowever counting linear regions in a typical neural network is usually intractable, and there have been a sequence of upper and lower bounds proposed. Upper bounds are based on counting hyperplane arrangements (Zaslavsky, 1975; Raghu 2017; Montufar 2017; Serra 2018), and lower bounds based on counting regions in specific networks.\n\nThis paper improves the upper bound proposed in Serra (2018) by improving on a dimensionality constraint: the upper bound can be tightened if the dimensionality of the ambient space is shown to be smaller than the maximum possible value (number of neurons.) The paper defines A_l(k) -- the number of active neurons in layer l given k active neurons in layer l-1, and I_l(k) similar for inactive neurons, and proves an improved upper bound. \n\nFor the lower bound, the paper extends the existing MBound algorithm to probabilistically count the number of linear regions, with experiments (Figure 1) demonstrating the speed of this lower bound algorithm compared to counting.\n\nClarity: The presentation for this paper is relatively clear, but it is quite technical, so some parts are hard to follow, without knowing the prior work in detail.\n\nOriginality: Defining A_l(k) and I_l(k) for a refined upper bound, as well as the idea of using a probabilistic lower bound is new compared to prior work.\n\nComments on Quality and Significance: \n\nThe theoretical results presented in this paper are interesting and novel, both the bounds and the adaptation of existing methods (Nemhauser 1978; Gomes 2006) for purposes of estimating bounds. However, I'm uncertain as to the practical applications. One thing that was unclear to me was what Proposition 3, 4 mean for the quantities A_l(k) and I_l(k) in practice (in trained networks). The text makes a comment on the weights and biases having the same number of positive/negative elements but that is likely to only be true for random networks.  It would be interesting to see Figure 1 left for random and trained networks. \n\nGiven the long line of work in this area however, I think this paper will be interesting to the community.\n"", ""This paper contributes to the study of the number of linear regions in ReLU neural networks. An approximate probabilistic counting algorithm is used to estimate the lower bound of that quantity, whereas an upper bound is derived analytically. The probabilistic counting algorithm is shown to be much more efficient than exact counting, and is adapted from the SAT literature. The new upper bound uses the weights of the network, a new technique compared to previous work on these bounds, and is shown to be sometimes tighter than the older bound.\n\nOverall, I am positive about the paper. Although I could not verify all proofs in detail, the ones I did verify were sound. The probabilistic counting algorithm seems like a good fit for this type of neural network problems, and is adapted and implemented nicely.\n\nIn my opinion, the paper can be improved substantially on these fronts:\n- Motivation: Can you point me to a reference where the number of linear regions is used as a measure of expressiveness, formally? I ask because the scope of the work in this paper is very much tied to that question.\n\n- Clarity: this issue must be addressed. The paper is quite technical (that's fine), but also difficult to parse. For example, it is not clear what's new in 4.1.\n\nMinor:\n- Figure1/Table1: please move them to experiments. You do not describe the tables and results early, which makes it useless at that stage of the paper. Why not just move them to experiments and describe/discuss these results in detail there?\n- Notation: In page 3, paragraph 2, you use x in many different shapes and forms (e.g. bold). Please consider making that notation consistent.""]","[-20, 60, 70]","[50, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the results 'somewhat interesting' and an 'interesting contribution', they also express doubts about the practical value and overall impact of the work. Phrases like 'I do not think there is a lot of practical value' and 'marginal value to the progress of the domain' indicate a generally lukewarm reception. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms in a constructive manner. They use phrases like 'I find' and 'I am not convinced' to express personal opinions rather than making harsh declarative statements. The tone is professional and measured, avoiding any rudeness while also not being overly effusive in praise."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's interesting and novel theoretical results, and states that it will be interesting to the community. However, they express some uncertainty about practical applications and request clarification on certain points, which prevents a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or questions rather than direct attacks. They use phrases like 'interesting and novel' and 'will be interesting to the community', which contribute to a polite tone. The reviewer also balances positive feedback with constructive criticism in a professional manner."", ""The sentiment score is 70 (positive) because the reviewer states they are 'positive about the paper' and praises aspects like the soundness of proofs and the good fit of the probabilistic counting algorithm. However, it's not 100 as they also suggest substantial improvements. The politeness score is 80 (polite) due to the constructive tone, use of phrases like 'in my opinion,' and the way suggestions are framed as questions or polite requests (e.g., 'Can you point me to...', 'please move them...'). The reviewer maintains a respectful and professional tone throughout, offering both praise and constructive criticism.""]"
"['Authors propose a supervised method for predicting adjacency matrix for a set of points. Loss function consists of 4 terms: intersection over union loss with respect to target adjacency, cross entropy loss, symmetry penalty and L2 regularization of parameters. Learning process consists of alternating node feature updates parametrized by GCN-like layers and updates of the adjacency matrix (different across layers).\n\nMy main concern is the heuristic nature of the method without any successful real data application. I do not see this work as impactful or of interest to ICLR community.\n\nDirectly regarding the content I have following comments and questions:\n\nWord ""structure"" seems to be used in several meanings. For example ""We consider the problem of predicting the structure of a given set of points (which we assume are the nodes of a graph) and an initial structure (connections of the points)."" It only becomes somewhat clear later what is actually the learning problem studied in this paper.\n\n""The learned convolutions"" - convolution is a particular mathematical operation. I believe authors should refer to the weights of their architecture instead.\n\nSymmetry penalty of equation 14 seems unnecessary. When optimizing for symmetric matrix it should be recognized that corresponding symmetric entries are identical variables. Hence it is sufficient, and mathematically appropriate, to correct the gradient computed without symmetric consideration. Correction is simply sum of the gradient with itself transposed (without diagonal entries).\n\n""We compare against traditional generative models for graphs: mixed-membership stochastic block models (MMSB) "" - could you please elaborate on how you use MMSB for graph generation. The use-case I am familiar with is community detection.\n', 'This paper proposes a supervised learning method for predicting the connectivity of a graph based on both the features of nodes in the graph as well as the overall graph structure, rather than just the structure of the graph or just the node features. The approach is evaluated on two synthetic datasets, a “community” dataset and a “geometric figures” dataset.\n\nUnfortunately, I do not think this paper as it stands currently is ready for publication at ICLR for the following reasons: (1) the comparison and discussion with prior literature is lacking; (2) the experiments are rather weak; and (3) the significance and novelty of the method itself seems limited.\n\n1. I am very surprised there was no discussion of [1] (or even better, a comparison to), which is another method which uses information about the full graph (via message-passing) to infer the connectivity of the graph in an unsupervised way. The discussion of the literature on graph neural networks in general is a bit weak, missing important references such as [2-4]. Such approaches, especially message-passing style approaches like [4], do exactly what the current paper suggests has not been done: they make predictions based on information in the nodes while considering the structure of the graph as a whole (via message-passing). Although [4] does not explicitly make edge predictions the approach is straightforward to generalize to making edge predictions, see [5].\n\n2. The experiments in the paper only test the proposed method on very toy domains, and thus feel weak. The results in Table 2, for example, suggest that the proposed method has reached ceiling-level performance and thus to really tell the difference between GLN_f, GLN_c, and any other methods, more difficult problems are called for. The geometric figures dataset, in particular, does not seem to me like it would test the claim that the paper would like to make: that it is important to take into account the fully structure of the graph when predicting edges. Indeed, there is a very simple rule that can be applied in the geometric figures case which does not use global graph information (if the two nodes have the same color, connect them, if they are different colors, do not connect them). It is therefore unsurprising that GLN_c actually does slightly better than GLN_f (according to Table 2) on geometric figures.\n\nAdditionally, the experiments do not provide much insight into the architecture itself. For example, the present architecture is meant to repeat the embedding and link-prediction steps some number of times, and in the experiments it seems that these steps are repeated four times. But how important is the repetition in practice? It would be nice to see the effect of repetitions on final performance, to demonstrate whether this is in fact an important component of the model or not. Similarly, there are several different loss functions but it is not obvious to what extent these losses contribute to the final performance of the model. It would be nice if there could be some ablation studies that train the model with different combinations of losses to see which are actually important.\n\n3. Finally, I have some concerns about the model itself. If I understand correctly, both f_l and c_l depend on a number of learned parameters which is a function of the number of nodes in the graph. This is unfortunate, as one of the strengths of the graph neural network approach is that GNNs usually have a number of parameters that is independent of the size of the graph, thus allowing GNNs to scale to graphs of arbitrary size. However, that is not the case in this model. Moreover, the architecture of f_l and c_l do not seem particularly novel. f_l just involves passing the node embeddings through a MLP to produce the link predictions. c_l involves something closer to message-passing, though where weighted combinations are learned on a per-node basis (rather than sharing the same function across all nodes). This could be interesting, even though it sacrifices the scale-free nature of GNNs, if it could be shown to actually outperform existing GNN approaches on more realistic datasets. However, given the lack of experiments demonstrating this, it is hard to say how significant the approach is.\n\n[1] Kipf, Fetaya, Wang, Welling & Zemel (2018). Neural Relational Inference for Interacting Systems. ICML 2018.\n[2] Gori, M., Monfardini, G., and Scarselli, F. (2005). A new model for learning in graph domains. IJCNN 2005.\n[3] Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. (2009). The graph\nneural network model. IEEE Transactions on Neural Networks, 20(1):61–80.\n[4] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017). Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212.\n[5] Battaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., ... Pascanu, R. (2018). Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261.', 'This papers presents a supervised method to learn from network data. The method alternates two steps: a node embedding step (using convolutions) and an adjacency matrix update (using local convolutions or fully connected layers). These steps are stacked forming a NN that is used to represent the learning steps. The objective function is composed of a linear combination of typical losses such as cross-entropy, intersection over union and other regularization terms. The linear coefficients are treated as hyper-parameters. The methods are evaluated on graph generation and edge prediction tasks, showing results comparable to the state-of-the-art.\n\nOverall, the paper is clearly written and addresses an important problem. However, I found the proposed method rather heuristic and not very well theoretically principled. Why should one use the proposed architecture (stacking learning steps)? What is the latent structure that this method is trying to learn, a particular sequence of graphs? Which one? Where do the supposed benefits come from? In general, both the architecture and loss (or combination of losses) need to be better justified.\n\nRegarding experiments, on the positive side, the authors consider a representative set of methods. However, the tasks are too simple. I miss some sensitivity analysis, e.g., on the different loss functions or the number of layers. It is not clear how the method scales on the size of the networks and the depth of the layers.\n\nminor:\n\n- specify better how the ground truth is used in the objective\n- How was the noise added? uncorrelated noise over the features?\n- the loss function is referenced before being presented\n- ""set of node embedding"" -> ""set of node embedings""']","[-70, -70, -20]","[20, 20, 50]","[""The sentiment score is -70 because the reviewer expresses significant concerns about the paper, stating that they don't see the work as impactful or of interest to the ICLR community. The main criticism is the heuristic nature of the method and lack of successful real data application. This indicates a strongly negative sentiment towards the paper's contribution and relevance.\n\nThe politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'My main concern is...' and 'could you please elaborate...', which are polite ways of expressing concerns and asking for clarification. The reviewer also provides specific comments and questions, which is a constructive approach. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the reviewer clearly states the paper is not ready for publication and lists several major criticisms. They use phrases like 'Unfortunately, I do not think this paper as it stands currently is ready for publication' and 'the experiments are rather weak'. The reviewer provides detailed explanations for their concerns, indicating a strongly negative sentiment towards the paper's current state. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I am very surprised' and 'It would be nice if' rather than using harsh or dismissive language. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is clearly written and addresses an important problem, they express significant concerns about the theoretical foundations and experimental depth of the work. The reviewer points out that the proposed method seems 'rather heuristic and not very well theoretically principled' and that both the architecture and loss function need better justification. They also mention that the experimental tasks are 'too simple' and lack sensitivity analysis.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They begin with positive aspects ('clearly written', 'addresses an important problem') before moving on to criticisms. The language used for critiques is constructive rather than harsh, using phrases like 'I found' and 'I miss' instead of more direct accusations. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. The minor points at the end are presented neutrally without negative connotations.""]"
"['This paper proposes a specific measure of difficulty for training examples called “easiness”. Easiness is based on training the model N times and counting the number of times an example is classified correctly. Based on this measure, they introduce “matching rate” as a measure of similarity of two architectures. Two architectures are suggested to be similar if the set of easy and hard examples is similar. The rest of the paper presents comparisons of architectures. Considering the problems below, I don’t see any reliable contribution in this paper.\n\n- Why this specific definition of easiness? Can you compare to simply using “loss” as a measure for the difficulty of an example?\n- e_t seems to be measuring the variance of training on a single example. If there is only one example that is always classified correctly, the denominator can be simplified to K. It doesn’t tell us how many training iterations it takes to fit that example.\n- Why this specific formulation for “matching rate”? Why not a more common measure of similarity between sets such as intersection over union (IoU)? Can you suggest any references using a similar similarity score?\n- Numbers in Table 1 do not seem particularly big to support the claim in section 4 that “...CNNs start learning from the *same* examples even if CNN architectures are different”. 0.20 is definitely bigger than random 0.1 for the matching rate but it still means only a 20% match.\n- Random 0.1 is redundant in table 1.\n- In section 4, define “contradicted patterns”.\n- Are all images in Figure 1 for one model? How does it compare to visualizing examples according to their loss?\n- The conclusion in section 5 says “... different CNNs start learning from similar patterns”. As mentioned above, “easiness” and consequently “matching rate” do not provide information about the progress of training and only final trained models. Regardless, this conclusion does not seem particularly unexpected or informative.\n- Section 6 proposes to test a model on data with a different structure from data provided in training. This is a distribution mismatch and the model is not trained to handle.', 'This paper extends the observation made in Arpit et al (2018) that deep networks prioritize learning simple patterns that are shared across many training examples. This paper further digs in this direction by defining a measure of ""easiness"" of a sample and making several empirical observations using this measure. This paper finds that the set of examples that can be identified as easy and hard for different architectures have a large intersection across architectures. It is also shown qualitatively that the set of easy examples have visually similar characteristics while hard examples are different from easy examples and also from one another. By artifically alterning the training images by changing color, structure and frequency components in individual examples, it is shown that the training process targets different characteristics that is dataset dependent. The effect of dropping samples from the set of easy and hard examples is studied and it is shown that dropping a small fraction of easy examples does not hurt generalization significantly (due to redundancy in patterns contained in such examples) while dropping even a smaller fraction of hard examples hurts generalization more significantly.\n\nOverall i find the above empirical observations and some of the other arguments in this paper interesting but i think there is a lot of scope for improvement in the paper. In its current form, I find the language of this paper quite informal in a number of places, and some of the claims/deductions made in the paper are not well justified and they need to be changed accordingly. If these issues are fixed, I will improve my score. Specifically the issues are:\n\n1. The notion of ""easiness"" introduced in Eq. (1) is clearly inspired by the experiment in Fig. 1 of Arpit et al (2018), and is also very similar. However, there is no mention of this in the paper.\n\n2. Based on the experiments in table 1, it is mentioned in section 4 that ""CNNs start learning from the *same* examples even if CNN examples are different."" This statement is simply inaccurate. There is a decent fraction of easy and hard examples that are shared across different architectures in some cases. But this does not imply what the authors have claimed. The claim seems very careless.\n\n3. In the sentence following ""Why there are easy and hard examples?"", the authors introduce the hypothesis of frequent patterns that are not *contradicted across classes*. I find this terminology unusual. What does it mean by patterns being contradiction? These sentences need to be re-worded.\n\n4. Following this hypothesis, it is mentioned that ""SGD force the model not to use contradicted patterns"". Grammar aside,  the argument of SGD forcing the model sounds very informal. Even beyond that, I am not sure I see the basis for making such a claim. This whole paragraph (and the one that follows) sounds like a hypothesis that the authors have in mind about the observation made in table 1, but it is put forth as if they are facts.\n\n5. In section 5, based on the experiment that shows that easy examples are visually similar, the authors write, ""This result *implies* that different CNNs start learning from similar patterns."". This is again bad deduction. The qualitative results at best *suggest* that different CNNs start learning from similar patterns, but do not imply it.\n\n6. The experiment in section 6 was interesting but the text was hard to follow and did not describe the results clearly.\n\n7. In section 7, it is mentioned that ""Randomly removing examples consistently produces the best performance."" This sentence is misleading. Randomly dropping samples clearly hurts performance compared to baseline. The claim should be that randomly removing examples hurts the performance least compared with dropping easy and hard examples.\n\n8. Finally, the authors mention at multiple instances that the observations made in this paper cannot be explained by the hypothesis set forth by Arpit et al (2018). I am not sure I understand the relevance of this claim. Explaining the observations made in this paper is never mentioned as a goal in Arpit et al (2018). These statements need to be fixed.', 'The paper formulates a definition of easy and hard examples and studies the properties and the training implications of such examples. The paper does not attempt to present insights that change training for the better (although suggests this could be future work), so the primary value it claims to add is our understanding of neural networks. I think the paper presents findings that most deep learning practitioners already find intuitive, which is why I think the paper falls short in its primary mission. An exposé like this could be valuable for an introductory text in deep learning, but I do not think the analysis meets the bar for a cutting edge insight and do not think it should be accepted.\n\nStrengths:\n- Quantifying easy and hard and using that as a starting point for further analysis is not a bad starting point at all.\n- The experiments form a good starting point for interesting analysis.\n- The paper is easy to follow and understand.\n\nWeaknesses:\n- The biggest weakness is that I just didn\'t find any of conclusions from this study to be that surprising or interesting. I think it\'s pretty obvious that neural networks start by learning the most immediately discriminative features (""frequent patterns""). The visual examples of easy and hard examples are not surprising at all (I think you get similar clusters if you just show bottom and top of model confidences, which I think many of us have). In section 7.1, the result that most misclassified examples are hard examples is presented as a surprising result. This is confusing, because this exactly what I would have expected given how you define easy/hard. It would be far more surprising if misclassified examples were all considered easy under your definition.\n- The paper only scratches the surface. In Figure 2, the results for the two different datasets are quite different. This means only two datasets is probably not enough for us to understand what is going on here in general. Just the conclusion that datasets may be different in terms of easy/hard samples does not take the analysis far enough. It\'s also unclear what the reader should make of these conclusions.\n- In Table 1, let\'s say the bottom 30% of samples are actually equally easy. This would mean that the ""easy"" examples are just a random 1/3 of those samples. Basically, I\'m worried about the implications of having a hard cut-off at 10% and if there are situations where the bottom 10% actually changed quite a bit, but the broader picture of easy really didn\'t change that much. I guess I\'m saying that I didn\'t quite gain confidence that definitions of easy/hard and matching rate are the correct way to go here and there might be a better metric that can look at the continuum of easy/hard from e = 0 to 1. You could have some kind of distance function where if an example moved from 5th percentile to 12th percentile, it would constitute a distance of 7. This is perhaps not the right thing either, but presenting an alternative metric and showing that the numbers (up to scale) and conclusions are unchanged would be nice.\n\nOther comments:\n- The new terminology of ""contradicted pattern"" and ""non-contradicted pattern"" is a bit confusing. Why aren\'t you just calling these ""non-discriminative"" and ""discriminative""? If a mantis and a ladybird are both typically on a leaf, the leaf is not discriminative for this task. However, if a mantis and a boat are typically on differently colored backgrounds, the background is discriminative.\n\nMinor comments:\n- page 1, ""easy and hard examples differ on various CNNs architectures"" -> ""CNN""\n- page 2, ""as a criteria"" -> ""criterion""\n- page 2, ""We then redefine easy and hard"" -> don\'t you mean just ""define""? Or do you mean that the words already have casual meanings, so this is a redefinition? I still think ""define"" is less confusing here.\n- page 2, I think it\'s confusing that both easy and hard use the threshold \\tau, suggesting it is the same. Maybe put a subscript to make it clear that the two \\taus are different.\n- page 6, ""accuracy does not drop"" -> could use a ""does not *even* drop"" for clarity\n- page 7, ""7.1 Do misclassified examples in validation dataset are hard examples"": ""Do""->""Are"", remove ""are""']","[-80, -30, -60]","[-20, 20, 50]","[""The sentiment score is -80 because the review is highly critical and dismissive of the paper's contributions. The reviewer states 'I don't see any reliable contribution in this paper' and raises numerous concerns about the methodology and conclusions. The politeness score is -20 because while the language is not overtly rude, it is quite direct and lacks any positive reinforcement or constructive framing. The reviewer uses phrases like 'Why this specific...?' and 'Numbers... do not seem particularly big to support the claim' which, while not impolite, do not soften the criticism. The review also lacks any acknowledgment of potential merits or positive aspects of the work, which contributes to its slightly impolite tone."", ""The sentiment score is -30 because while the reviewer finds some aspects of the paper interesting, they also point out numerous issues and areas for improvement. The overall tone suggests that the paper needs significant revisions before it can be considered acceptable. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I find' and 'I think' to soften criticism. However, they are also direct in pointing out flaws, which prevents the score from being higher. The reviewer offers constructive feedback and suggests ways to improve the paper, which contributes to the slightly positive politeness score."", ""The sentiment score is -60 because the reviewer's overall assessment is negative, stating that the paper 'falls short in its primary mission' and 'should not be accepted'. However, they do acknowledge some strengths, which prevents the score from being extremely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They balance negative feedback with positive points and use phrases like 'I think' to soften their criticisms. The reviewer also provides detailed explanations for their concerns, which is a polite way to give feedback. However, the directness of some statements (e.g., 'I do not think it should be accepted') prevents the score from being higher.""]"
"['The paper addresses the robustness of deep neural networks to adversarial example attacks. It uses a bilateral filtering as a preprocessing step to recover clean data from adversarial ones. It can also get combined with adversarial training and be trained end-to-end. The paper is well written, the background and introduction is clear. However I have comments about their implementation and experimental results:\n\n1. They are claiming to have a very high distortion while their model can still perform well.  They have to make sure obfuscated gradients has not happened and they have implemented the back-propagation from attack to defense correctly. \n\n2. Also if they had consider black-box threats as well as white-box one, it would have been more informative of how their method actually performs. Specially, in order to check whether obfuscated gradients has happened, the black-box threats are better choice, which they have not tried.  \n\nSo considering the above, there might be an issue in what they are claiming, so they might reconsider their method. Maybe reviewing their codes by some experts in this topic can give a good evaluation. \n\n(I have to mention that I am not an expert in Adversarial networks)\n\n\n\n', ""1. The numbers in Table 1 should be compared with the %-age of examples that were actually fooled to begin with by using each adversarial attack scheme under study. Only then can the recovery performance of the hand-tuned bilateral filtering be put into perspective.\n2. In case of the adaptive filtering method, the parameters for bilateral filtering are predicted by a standalone classifier. For the experiments to be fair, any incoming image, whether adversarially perturbed or not, must be filtered using the parameters predicted by the classifier. Thus, are the results in the column titled 'clean' pertaining to when natural (unperturbed images) are filtered and tested? If not, then what are the accuracy values in that case.\n3. Also in Table 2, the case (B) measures the ability of the adaptive filtering to change the predicted label from the adversarial label to a 'new' one.  In this case, it is important to measure/verify whether the 'new' label is benign or malignant (which may well depend on the specific task of classification and the semantic associations of the output classes). Without this analysis for the 'new' class, it seems irrelevant and even misleading to quote this measure.\n4. It is unclear what the relation between the results in Table 2 and Table 3 is. How are the values in the two tables linked, if at all?\n5. In Table 3., once again, what does 'clean' column report? Are the natural images adaptively filtered and then tested for accuracy? If not, then do also report those numbers in a separate column. \n6. It is really evident in Table 3 that as the adaptive filtering is applied and the robustness seems to improve (as measured in terms of the accuracy figures for the various attack schemes), the accuracy for natural/clean images consistently and significantly drops. There has not been discussed anywhere in the paper. What does this imply? It should be highlighted in text and maybe even graphically, plotting the tradeoff between robustness gain (on adversarial images) and accuracy loss (on clean images). \n7. Some claims in the paper are unsubstantiated: (a) 2nd para, pg 7 - an adversarial detector or a human eye would be able to detect those attacks. Do the authors have any quantitative figures to share on how well a detector or human subjects would fare at this task? (b) Larger perturbations are visually discernible and thus less adversarial? Again, from the images in row 2, fig2, one can notice that there is a higher quotient of noise but this doesn't in any way interfere with the recognisability of those images by a human. How are they less adversarial when humans are not affected by the perturbations as concerns the classification task?\n8. What does the column title 'natural' in Table 5 correspond to, especially as it is a subcolumn of an attack scheme? Also, the numbers in Table 5 seem to be the fooling rates. This is inconsistent with the remaining tables where accuracies are being presented. Do you think it would be better to convert these to accuracy figures too?\n\nI am interested in knowing the authors' responses on the above points before I can propose my final rating."", 'The paper proposes the use of bilateral filtering as a defense to adversarial examples (AE). Bilateral Filtering (BF) is a smoothening technique that averages pixels that are close to each other both in position and value. As a result BF preserves sharp edges and the denoised images appear to be of higher quality than those produces via simple Gaussian smoothing.\nFirst, the method is evaluated on black-box attacks by constructing AE for the undefended network and then applying the defense. The method is then tested on white-box attacks which attack the defended system end-to-end with first order methods. Finally, the authors propose combining their defense with adversarial training.\n\nOverall, I find the main idea of the paper interesting. BF seems like a natural approach to remove low-magnitude perturbations from the image while preserving the salient characteristics of the image. Thus, if it did not hurt classification accuracy significantly it might be considered as part of a cheap preprocessing pipeline that protects the model from simple attacks. However, as shown in Table 3 and 6, BF reduces the accuracy of the original model by at least 5% on ImageNet and CIFAR10.\n\nMy main objection about the paper is that BF is proposed as a defense that is extremely robust against even the best attacks. However, the evaluation is clearly incomplete for such a claim and fails to pass simple sanity checks.\n\n*Epsilon values used to claim robustness are way too high*. Table 4 reports an L_infinity bound of 0.793 (almost 40% the image range) and L_2 of 187 (again roughly a quarter of the L2 radius of the image domain). One can change the class of the image completely (even for humans) with a smaller epsilon bound. This is a very clear indication that the attacks used are not sufficient to properly evaluate the robustness of the defense. Even in the images produced by the authors (Figure 2) it is clear that these perturbations are sufficient in terms of magnitude to completely distort the image.\n\n*Only first-order attacks are considered*. From the point about epsilon values above, it is fairly clear that the defense is not easy to attack with first-order methods. This is understandable since BF, even if ""fully differentiable"", will lead to vanishing gradients for certain pixels. I think it is necessary that the authors to evaluate their defense on other attacks such as a) a straight-through approximation of BF (see BPDA from https://arxiv.org/abs/1802.00420), b) a finite-differences-based attack (see SPSA from https://arxiv.org/abs/1802.05666). As a sanity check, I would even recommend evaluating using the nearest neighbor of each image from a wrong class. It is clear that this attack will always succeed and the L_p distance will be smaller than those reported here.\n\nI believe that these are fundamental issues about the paper that need to be addressed before even considering the paper for acceptance and I thus recommend rejection at this time.\n\nOther comments and concerns:\n--Table 6: what is the performance of BFNet without adversarial training? This is a necessary baseline to understand the results of the table.\n\n-- I am confused by the adaptation of adversarial training to BFNet (last equation of section 3.4). The equations themselves are confusing since x is used twice (as a parameter to f and sampled from D). My first guess would be that the method is performing end-to-end adversarial training from the loss to the input x (before BF). It appears however that adversarial training is performed with respect to the image *after* applying the BF filter. If this is the case, it goes against the fundamental principles of adversarial training.\n\n-- I do not see the point of adaptive filtering (AF) as a defense. BF is attractive because it is simple. Adding a classifier to figure out the right parameters seems dubious at best. The idea seems fundamentally flawed given that the classifier is only trained on known attacks and might thus not capture new, different attacks. Lastly, since the classifier is a ML model, it will clearly be susceptible to adversarial perturbations. So the adversary can choose an attack that fools the original model and forces the classifier to choose bad BF parameters. I would suggest that the authors completely remove AF from future versions of their paper.\n\n-- The performance on ImageNet is significantly better than the performance on MNIST and CIFAR10. This is counter-intuitive since a much harder dataset both from a standard and adversarial point of view.\n\nMinor comments to authors:\n-- A JPEG compression-based defense can be bypassed (https://machine-learning-and-security.github.io/papers/mlsec17_paper_54.pdf).\n-- Last paragraph of page 3 is too informal (""less holes for adversarials to maneuver on"").\n-- Top of page 4: you seem to confuse ""iterative methods"" with ""small magnitude"" attacks. One can use iterative attacks to create large adversarial perturbations (e.g. PGD).\n-- I would suggest normalizing to the more common [0, 1] range as the current numbers can be confusing.\n-- I am confused by Tables 2, 3. First row of Table 2 shows that on 95% of the clean inputs the label is not changed after BF. But table 3 shows that the accuracy drop from 78.8% to 71.7%. What is going on here?\n-- Last part of first paragraph of 4.2 is hard to understand.\n-- End of page 8, ""the higher dimensionality of CIFAR10 makes it harder than MNIST"". Yet the paper claims excellent performance on ImageNet.']","[-20, -50, -70]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written with a clear background and introduction, they express significant concerns about the implementation and experimental results. The reviewer suggests there might be issues with the authors' claims and recommends reconsidering their method, which indicates a somewhat negative sentiment overall. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges their own lack of expertise in the field, and offers constructive criticism rather than harsh judgments. They use phrases like 'I have comments' and 'they might reconsider' which maintain a polite tone while expressing concerns."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several issues and requesting clarifications. However, it's not entirely negative as the reviewer expresses interest in the authors' responses before making a final decision. The politeness score is 50 because the language used is professional and constructive. The reviewer uses phrases like 'It is unclear,' 'Do you think,' and 'I am interested in knowing' which maintain a respectful tone. The critique is presented as a list of points to address rather than harsh criticisms. The reviewer also offers suggestions for improvement, which is a polite way of providing feedback. The closing statement indicates openness to further discussion, which is a positive and polite approach."", ""The sentiment score is -70 because the reviewer recommends rejection and points out several fundamental issues with the paper. The review starts with some positive comments about the idea being interesting, but quickly moves to major criticisms about the evaluation methodology and claims made in the paper. The reviewer states that the paper 'fails to pass simple sanity checks' and that there are 'fundamental issues' that need to be addressed. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I find the main idea of the paper interesting' and 'I believe that these are fundamental issues' rather than using harsh or dismissive language. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score.""]"
"['Based on my understanding, this paper describes a novel approach for addressing the large batch training problem. The authors propose increasing the batch size based on reductions in the largest eigenvalue of the Hessian. This is combined with adversarial training using the fast gradient sign method to reduce the total number of iterations required for training and improve generalization performance. Unfortunately, although the numerical results seem quite promising, the algorithm and its explanation and details are not described clearly in the paper, which makes me lean towards rejection. I describe this more fully below:\n\n1. Description of the Algorithm\n\nThe description of the algorithm in Section 3.1 is simply not clear, and lacks clear exposition motivating why the algorithm ought to work. To add to this confusion, there appear to be some inconsistencies between the (brief) description of the method and the description given in the Main Contributions and Limitations section in the Introduction. \n\nAs an example, in Section 3.1, the approach for computing the eigenvalue of the Hessian is not described. Which eigenvalue is computed? How is this done? What is the batch size used in this computation? Is it computed over the full training set? The Limitations section briefly describes this (power iteration to tolerance <= 10^-2), but this should be elaborated on in Section 3.1. In fact, the limitations should not be discussed until a clear description of the algorithm is given.\n\nThe introduction makes this even more confusing by claiming the second order information is computed by “backpropagating the Hessian operator”. This seems to imply that the 3rd derivative information is computed for second-order information. Later in the Introduction, the authors claim to use Hessian matvecs to perform the power iteration. I believe that the authors mean that the Hessian-vector product is obtained by differentiating the product g’v (a scalar quantity). \n\nIn addition, it was not described how the learning rate is changed in the algorithm. Later in the experiments, none of the additional hyperparameters in the procedure are given, such as the duration factor, kappa, the hyperparameters in the adversarial training, and more. This all ought to be included for completeness.\n\n2. Questions about Details of the Algorithm\n\nIf it is indeed the case that the authors are using power iteration to compute the largest eigenvalue, why not use Lanczos method as it typically works better for symmetric matrices? In addition, if the intention was to compute the largest eigenvalue of the Hessian, one must be wary that the power iteration/Lanczos method computes the eigenvalue with largest magnitude (the absolute value of lambda), which may mean that it’s possible that the algorithm is utilizing negative curvature information rather than positive curvature information (particularly in the earlier epochs), which may contradict their intuition based on flat minima. This needs to be addressed.\n\nSecondly, there is no explanation as to why increasing the batch size would lead to consistent decrease in the eigenvalues of the Hessian. This is certainly not true for all optimization problems. Even if the flat minima/sharp minima hypothesis is assumed, is it possible for the iterates after increasing the batch size to still tend towards sharper minimizers after being in a flat region? This intuition and explanation needs to be expanded on (and argued for) in order for the algorithm to make any conceptual sense.\n\nLastly, why is the duration factor needed to increase the batch size if the eigenvalue condition fails? if the duration factor is removed, how does the batch size evolve? Is it necessary? How is the duration factor tuned?\n\n3. Inconsequential Theoretical Results\n\nThe authors also prove a theorem bounding the expected optimality gap with adaptive batch sizes. On closer look, this is a simple adaptation of the result by Bottou, Curtis, and Nocedal [2] and does not utilize any of the algorithmic mechanisms described in the paper. Hence, the theoretical result is not novel, does not provide any additional insight on the algorithm, and could be applied to any adaptive/changing batch size SG algorithm. In my opinion, this ought to be removed. (Assumption 2 is also mentioned in the main paper, but is only described in the Appendix.)\n\n4. Additional Considerations\n\nThe paper is missing much work done by Nocedal’s group on increasing batch sizes (some of which utilize the L-BFGS approximation to the Hessian); see [1, 3].\n\nOther relevant work by Sagun, Bengio, and others on large batch training, flat minima, and the Hessian in deep learning ought to be included as well; see [4-7]. \n\nLastly, the algorithm demonstrates some significant improvements on the number of iterations. However, efficiency with respect to epochs is not discussed. It may make sense to plot test loss/error against epochs and batch size against iterations for clarity.\n\nTypos/Grammatical Errors:\n- Page 2: Should not state “(We refer to this method as ABS)”, easier to include by including (ABS) after Adaptive Batch Size in the beginning of the bullet point.\n- Page 6: Section 4: “information” not “informatino”\n- Page 6: Section 4: “the” not “teh”\n- Page 7: Section 4.1: “confirms” not “confirming”\n- Page 7: Section 4.1: no “a” in “a very consistent performance”\n\nSummary:\n\nOverall, although the paper presents some promising numerical results, it lacks a detailed description and explanation of the algorithm to be worthy of publication. It leaves many aspects of the algorithm open to the reader’s interpretation, and I do not believe I could reproduce the results with the information provided. The manuscript needs significant changes to the detail, structure, and writing before it can be considered for publication.\n\nReferences:\n[1] Bollapragada, Raghu, et al. ""A progressive batching L-BFGS method for machine learning.""\xa0arXiv preprint arXiv:1802.05374(2018).\n[2] Bottou, Léon, Frank E. Curtis, and Jorge Nocedal. ""Optimization methods for large-scale machine learning.""\xa0SIAM Review\xa060.2 (2018): 223-311.\n[3] Byrd, Richard H., et al. ""Sample size selection in optimization methods for machine learning.""\xa0Mathematical programming134.1 (2012): 127-155.\n[4] Chaudhari, Pratik, et al. ""Entropy-sgd: Biasing gradient descent into wide valleys.""\xa0arXiv preprint arXiv:1611.01838(2016).\n[5] Jastrzębski, Stanisław, et al. ""DNN\'s Sharpest Directions Along the SGD Trajectory.""\xa0arXiv preprint arXiv:1807.05031(2018).\n[6] Sagun, Levent, et al. ""Empirical Analysis of the Hessian of Over-Parametrized Neural Networks.""\xa0arXiv preprint arXiv:1706.04454\xa0(2017).\n[7] Zhu, Zhanxing, et al. ""The Regularization Effects of Anisotropic Noise in Stochastic Gradient Descent.""\xa0arXiv preprint arXiv:1803.00195\xa0(2018).', 'This paper studies the large batch size training of neural networks, and incorporates adversarial training and second-order information to improve the efficiency and effectiveness of the proposed algorithm. In particular, the authors use second-order information to automatically generate the step size and batch size in each iteration, and apply adversarial training as a regularization method to improve the test performance. Finally, the authors demonstrate their algorithm and compare it with the baseline algorithms on a wide range of datasets. This paper is clearly written and has the following strength:\n\n1.\tThis paper proposes an adaptive method for SGD training, which proves its convergence for strongly convex optimization.\n2.\tThis paper incorporates the adversarial training and robust optimization into the adaptive SGD training, and shows that this combination significantly improves the test performance.\n3.\tThe authors perform experiments on different datasets, which show that the proposed method enjoys less training time and higher accuracy when using large batch size.\n\nHowever, this paper also has the following weakness:\n\n1.\tThe theoretical analysis is somewhat trivial, and the assumption on the objective function is rather strong, which is not consistent with the nonconvex loss functions that are widely applied in training neural networks.\n2.\tTheorem 1 provides convergence rate of SGD on strongly convex objective functions. However, the authors do not carefully characterize the learning rate to ensure that the loss function achieve \\epsilon-accuracy. Moreover, in order to make the last term in (5) be smaller than \\epsilon, the learning rate \\eta_0 should be in the order of O(\\epsilon), which is no longer a tuning-free parameter.\n3.\tThe authors mention that the proposed algorithm converges faster than basic SGD, but it is not clearly demonstrated from Theorem 1.\n4.\tI am confused about how to determine the number of iterations for different algorithm as shown in Table 1s and 2? Do you stop each algorithm when they attain the same training error on the training dataset?\n5.\tIt is also confused that the number of iterations for ABS and ABSA are relatively larger than that of BL (Tables 1 and 2), but the training time of BL is longer than those of ABS and ABSA as reported in Table 3?\n6.\tSome minor flaws. In (9) it should be \\|\\nabla L(\\Theta)\\|^2; in Lemma 3, the expectation on the left side should be taken conditioned on \\theta_t.\n', 'The authors propose using information from the Hessian to grow the batch size as the training progresses. It is well-known that larger batch sizes can be used for later stages of optimization (ie, https://arxiv.org/abs/1711.00489, https://arxiv.org/abs/1706.05699), but they are missing motivation as to why use Hessian information for this.\n\nFurthermore, the description of the algorithm is lacking detail and is essentially unreproducible in current form.\n\nThe main description of their method is Algorithm 1 box, which suggests to grow batch size when ""eigenvalue"" is much smaller than previous eigenvalue. Is that the top eigenvalue? How is it estimated? Why is that the criterion? Note that for stochastic least squares problem one benefits from later batch sizes in later stages of optimization even though Hessian doesn\'t change.\n\nIn section Section 4.3 they start talking a bit about computing Hessian, referring to non-existent figure 6 for details of block approximation.\n\nAuthors mention that Hessian computation is not supported in major frameworks but don\'t provide explanation of how they compute it (did they not use a major framework for ImageNet experiments?).\n\nNote that a single row of Hessian (hence full Hessian) can be computed in all major frameworks by differentiating an element of the gradient. IE, in PyTorch https://gist.github.com/apaszke/226abdf867c4e9d6698bd198f3b45fb7, and also eigenspectrum of Hessian can be approximated -- https://github.com/noahgolmant/pytorch-hessian-eigenthings']","[-60, 50, -50]","[50, 70, 0]","[""The sentiment score is -60 because the reviewer leans towards rejection, citing unclear algorithm description, inconsistencies, and lack of details. However, they do acknowledge promising numerical results, which prevents the score from being even lower. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific recommendations for improvement and using phrases like 'Unfortunately' and 'I believe' to soften criticism. They also provide a detailed review with references, showing respect for the authors' work. The language is not overly formal or polite, but it avoids rudeness, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting the paper's strengths, including its clear writing and contributions to the field. However, it also points out several weaknesses, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits before presenting criticisms. The criticisms are framed as observations or questions rather than harsh judgments. The use of phrases like 'I am confused about' and 'It is also confused that' indicate a polite way of pointing out potential issues without being accusatory. The review maintains a professional tone throughout, even when discussing weaknesses."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings and lack of details. The reviewer mentions missing motivation, lack of detail in the algorithm description, and absence of explanation for Hessian computation. However, it's not entirely negative as the reviewer acknowledges the well-known concept the authors are building upon. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact, without being overtly polite or rude. The reviewer states criticisms plainly without using harsh language, but also doesn't use particularly courteous phrases. The tone is professional and focused on the content rather than being either especially polite or impolite.""]"
"['Summary:\n\nThis paper proposes layer wise training of neural networks using classification auxiliary tasks for training each layer. Experiments are presented on CIFAR10 and Imagenet. Accuracies close to end to end training are obtained. \n\nThe layer wise training is repeated for J steps, the auxiliary tasks are trained on top of the shallow one layer (of width M ) with a network  of depth k and width tilde{M}. Layerwise training is done using sgd with momentum, and the learning rate is decayed through epochs. \n\nNote that the layer wise training is done with large width M than typical end to end networks in use. \n\nThe authors argue and test the hypothesis that auxiliary tasks  encourage the linear separability of CNN features. \n\nTo reduce the size of the learned network the author propose a layer wise compression using the filter removal technique of Molchanov et al .\n\nReproducibility:\n\nThis empirical  work has been investigated for a while with mild success, the authors should make their code available to the community to confirm and reproduce  their findings.  I encourage the authors to make their code available during the review/discussion period. \n\n\nSignificance of the work:\n\nFrom reading the paper it is not clear what is the main ingredient that makes this layer wise training  successful, negative results would help in understanding what is important for the accuracy. \n\nSome more ablation studies and negative results will be insightful and here are few suggestions in that direction:\n\n- Authors claim that they used invertible downsampling as max or average pooling  lead to information loss. Does the layer wise training give worst results with average or max pooling? If so please report those numbers to know what is the implications of this choice of pooling.  \n\n- On the width of the networks, seems it is key for the success of the approach.  What if  you train wider networks with J that is small? (  J=3 for instance but much  wider networks, instead of J=8 now for imagenet.)\n\n- To answer the same question above one needs also to see what are the accuracies for J=8 with thiner networks (smaller M )?\n\n- Would the accuracy  with the layer wise training reach a  plateau if one uses an architecture with J higher than 8? \n\n- Transferability of the learned features: end to end features are know to be transferable. It would be good to see if this still holds using the network layer wise trained on imagenet for CIFAR10 or other datasets. \n\nOther Questions:\n- Section 3.2 is vague. In Proposition 3.1 and  Proposition 3.2 can you add some text to explain what are the implicitions of the claims? “Thus our training permits to extend some results on shallow CNN to deeper CNNs …” which shallow results ?\n\n- “For k>1 batch normalization was useful “ is this only on the auxiliary problems networks  or you used also batch norm for the layer ?\n\n- The ensemble used is Z=\\sum_{j=1}^J 2^j z_j , this uses the network of J layers ,  also the O(J) auxiliary networks  of depth k. Please report the number of parameters for all models (single and ensembles) in Table 1 and Table 2. \n\n- In the conclusion: “The framework can be extendable to the parallel training …” how would this possible since one needs the output of the first training to do the training of the next layer. can you elaborate on what is meant here?\n\nMinor:\npage 2 bottom have competitorsand -> have competitors and \nthe non linearity rho in equation 1 and throughout the paper put a bracket for its argument \\rho(x) not \\rho x\nPage 6 , Imagenet paragraph : W —> We\nsection 4.2 we define linear separability etc… a space is missing before Further \nsection 4.3 we report our results .. (Imagenet) a space is missing after ImageNet)\n\nOverall Assessment: \nThis is a good paper, making the code available and adding more ablation studies and explanations of width versus depth and the choice of pooling will make the contributions easier to understand. ', ""This paper is of reasonable quality and clarity, rather modest originality, perhaps considerable significance in some applications.\n\nStrengths:\n- I think this kind of method could be useful for data of very high dimensionality, when it is not possible to train everything end to end.\n- The experiments seem to be conducted correctly.\n- The paper is well written.\n\nWeaknesses:\n- (minor) Abstract: it's kind of funny to say that CIFAR-10 is a large scale image recognition problem.\n- What the authors are proposing is quite similar to Lee et al. [1], which was not mentioned in the paper as well as a wide range of papers, which were mentioned. I think it is kind interesting for people to revise these techniques from 10 years ago, but this method is just not that novel.\n- The authors highlight that their goal is not using this method as a pre-training strategy, but it would be interesting to see whether it would indeed work better if after the layer-wise training, the whole network would be trained end-to-end.\n- Maths in this paper is mostly decorative. \n- When comparing different models or training methods (e.g. layer-wise trained AlexNet and end-to-end trained AlexNet), it would make sense to do some hyperparameter search. It is very risky to conclude anything otherwise.\n- I would like to see a wall clock time comparison between this and end-to-end training.\n\n[1] Lee et al. Deeply-Supervised Nets. 2015."", ""\n\nThe authors propose to train deep convolutional neural networks in a layerwise fashion. This is contrary to the traditional joint end-to-end training of deep CNNs. As their motivation, the authors quote computational and memory benefits at the time of training in addition to being able to extend shallow-network analytical frameworks to the individual network layers thus allowing for a theoretical interpretation of their optima.\n\nTheir method is simple and clearly explained. (Note: In the 10th line on Pg. 4, is there a 'j' missing in the subscript of x^n?)\nThe experimental results are interesting. The authors are able to demonstrate 'some' architecture that, in solely a layerwise training, is able to show competitive results with respect to AlexNet when trained in an end-to-end manner on ImageNet. These results can seem questionable as both the architectures and training routines are being varied and hence the precise contribution of the layerwise training is unclear. However, as per my understanding, the aim of the paper wasn't to show that a layerwise training can work better that end-to-end training. The aim was, on the contrary to show, that 'even' a layerwise training can offer competitive performance for 'some' network and hence may come handy when memory is limited. Their underlying claim, which could be more clearly stated is that the memory benefits during training can be enjoyed when the individual layers of a network (net1) are smaller in parameter count as compared to another net (net2) although the net1 in totality maybe larger than net2. This is because net1 will be trained in a layerwise fashion, while net2 would be trained in an end-to-end manner. I would like to see the authors confirm or reject this understanding and rationalise their experimental regimen.\n\nFurther, I would like to know how their work compares to the following:\nhttps://arxiv.org/abs/1703.07115\nhttps://arxiv.org/abs/1611.02185\n\nFinally, while the authors state that the layerwise training makes the individual layers amenable to theoretical analysis/interpretation, no such discussion is presented/initiated in the paper. The only analysis presented is on the ability of the individually trained layers to linear separate the data. To round the analysis, it should also be extended to the representations learned by end-to-end trained networks.  \n\nAll in all, while the paper raises some interesting ideas, its execution in terms of a method that learns a classifier on each individual layer is rather simplistic. Don't get me wrong, simple can indeed be elegant, but at the minute the comparisons are not very convincing.\n""]","[50, 20, -20]","[70, 60, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'good' and presents a balanced view, noting both strengths and areas for improvement. They recognize the significance of the work while also requesting additional experiments and clarifications. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I encourage the authors' and 'it would be good to see,' which maintain a collegial tone. The reviewer also provides specific, actionable feedback and even points out minor typographical errors in a helpful manner."", ""The sentiment score is slightly positive (20) because the reviewer starts by stating the paper is of 'reasonable quality and clarity' and mentions several strengths. However, they also list more weaknesses than strengths and describe the originality as 'modest', which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms constructively (e.g., 'it would be interesting to see...'). They avoid harsh language and present weaknesses as suggestions for improvement rather than outright criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns and criticisms. The reviewer states that the experimental results can seem questionable, the comparisons are not very convincing, and the execution is rather simplistic. However, they also note that the method is clearly explained and raises interesting ideas, which prevents the score from being more negative.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like to see' and 'I would like to know' when making requests, which is polite. The reviewer also acknowledges positive aspects of the paper and prefaces criticisms with phrases like 'Don't get me wrong,' showing an attempt to be fair and not overly harsh. However, the score is not higher because the review does contain direct criticisms and questioning of the paper's approach and results.""]"
"['The paper proposes a hybrid model-free and model-based RL agent for the task of navigation. Reaching the target is decomposed into a set of sub-goals, and the plan is updated as the agent explores the environment. The method has been tested in the House3D environment for the task of RoomNav, where the goal is to navigate towards a certain room. \n\nThe idea of integrating RL agents with semantic knowledge is interesting. However, the paper has several major issues that should be addressed in the rebuttal:\n\n(1) The experiment results in Figure 3 and Figure 4 are based on groundtruth room information. The only experiment that is fully automatic is the one in Figure 5. However, there is no difference between the proposed method and the baselines in that case. So the proposed method is not effective without groundtruth information.\n\n(2) The only evaluation metric that is used is ""Success Rate"". That metric is not sufficient for evaluation of navigation agents since it does not include episode length information. All of the results should be based on the protocol mentioned in ""On Evaluation of Embodied Navigation Agents"", arXiv 2018. \n\n(3) There is no termination action according to Appendix B. So the agent does not know if it is at the target or not. It seems the agent will stop if it issues ""stay still"" three times. That is different from termination action. Also, it is confusing what 450 pixels means for a scene classifier that works on the image.\n\n(4) The paper is written in a convoluted way:\n   (a) It is not clear if the semantic model is trained along with the RL model end-to-end or not.\n   (b) Regarding multi-target sub-policies, is there a separate policy for each pair of intermediate targets? \n   (c) Regarding inference and planning on M, what is \\tau exactly? How is the length of the plan determined? \n   (d) Why is the model updated only after a fixed number of steps? That increases the episode length. \n\n(5) The number of T_i\'s is manually set to 8. That causes serious generalization issues. How do we know how many T_i\'s exist in a new environment?\n\n\nMinor comments:\n- The paper mentions ""An example of such environments is House3D which contains 45k real-world 3D scenes"". House3D includes only synthetic scenes. They should not be called real-world scenes.\n- How is the reward shaping done?\n\n****\nFinal comments after reading the response and the reviews:\n\nRegarding the fairness of the review, success rate is not sufficient to evaluate navigation agents. A random agent can achieve 100% success if it is given enough time. So it is totally fair to ask for a metric (such as SPL) that is a function of both success rate and episode length. \n\nI am going to increase the rating to 5 since some of my concerns have been addressed. There are still a number of issues:\n\n- The authors did not run the experiments with the termination action. I disagree that this is orthogonal to the focus of the paper. This is not just an additional action. It indicates whether the agent has learned anything or it is just a combination of better obstacle avoidance and luck. The SPL numbers are so low (maximum SPL is 6.19%) so adding the termination action will probably make the method similar to random.\n\n- There is a huge gap between success rate and SPL numbers. For instance, success rate is 66.4, while SPL is 5.84 (note that for some reason the SPL numbers are multiplied by 10 in the table). I doubt that the agent has learned anything meaningful in comparison to the baseline. I understand that the task is hard, but this gap is so huge.\n\n- A separate policy is trained for each sub-target. This doesn\'t scale. There should be one policy for all targets. \n\n', 'The contributions of this paper are in the area of semantic modelling, where the authors propose an approach called LEAPS consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. The fundamental premise of the proposed approach is that when placed in an unseen environment the agent plans with the semantic model based on new observations. Particularly, the authors propose to learn a Bayesian model over the semantic level and infer the posterior structure via the Bayes rule. The proposed approach is validated with experiments in visual navigation tasks using a 3D environment that contains diverse human-designed indoor scenes with real world objects. Finally, the authors show the key role of using semantic context compared to the baselines that do not consider semantic context.\n\nThe parer is interesting, well structured and and clearly written. Also, the addressed topic of incorporating semantic model in the context of learning and planning is very interesting.\n\nThe related work is extensively presented with pertinent and up-to-date literature. Furthermore, the background section presents well the DRL notations.\n\nIn section 5, how the values for e.g between dinning room and garage 0.05, dinning room and kitchen 0.7 are learned, and how generalisable is this approach to other applications - because the way those priors are determined do not seem very explicit?\n\nFurthermore in the experiments it does not seem explicit how the semantic model is updated in light of new information, I think this deserves further explanation or to be clearly pinpointed?\n\nAlso, what are the key requirements that make  the semantic model interpretable. Because, the way the validation is conducted in this paper, it seems that ithe nterpretability is quite specific to House3D - is it generalisable to other applications and under which conditions?\n\nOtherwise, I believe that the questions asked in the experiments section are well answered with the experimental results\n', 'This work proposes a hybrid model for robot visual navigation in synthetic indoor environments, specifically a combination of a  high-level planning scheme (model-based) with a low-level behavior based approach (model-free) . The main contribution is on the high-level based planning that is based on semantic cues from the environment, specifically the construction of a semantic prior about rooms connectivity. By using this prior the system is able to generalize to new environments simplifying an initial robot exploration phase. \n\nThe semantic prior is implemented by the construction of a graph representation that encodes room connectivity. Links between rooms (nodes) are given by Bernoulli variables which are inferred by previous experiences and an exploration phase in the current environment.  \n\nResults are one of the weaker parts of the paper, success rates are very low, even for short planning horizons (figures 3,4,5).  Furthermore, it is not clear the real relevance of the semantic prior because relative performance with respect to baselines is not significant. In general, while a room connectivity prior can be of help, I believe is not so critical for indoor robot navigation. There are prior works on Robotics that has shown more impact using structural priors, such as, presence of corridors, doors, etc, or ""object-room"" spatial relations. The low success rate is even more critical if one considers that the validation is based on synthetic environments.\n\nIn general the paper is easy to follow, although, there are some details missing, specially in terms of model description. My main concern is that the paper is limited in technical novelty and it suffers from a lack of practical significance.']","[-60, 60, -50]","[20, 80, 20]","[""The sentiment score is -60 because the review is predominantly critical, pointing out several major issues with the paper. The reviewer states that 'the paper has several major issues that should be addressed' and proceeds to list 5 significant problems. The positive aspects mentioned (e.g., 'The idea of integrating RL agents with semantic knowledge is interesting') are outweighed by the criticisms. However, it's not entirely negative, as the reviewer does offer constructive feedback and acknowledges some positive aspects, hence not scoring at the extreme negative end.\n\nThe politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional and respectful tone throughout. They use phrases like 'should be addressed' and 'It is not clear' rather than more confrontational language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. However, the score is only slightly positive as the review doesn't go out of its way to be overtly polite or cushion the criticisms with excessive praise."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting, well structured and clearly written' and mentions that the topic is 'very interesting'. They also praise the related work section and the background information. However, it's not extremely positive as the reviewer raises several questions and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms as questions or suggestions for improvement rather than direct criticisms. The reviewer maintains a professional and constructive tone throughout the review."", ""The sentiment score is -50 because the review is generally critical of the paper. While it acknowledges the proposed model and its implementation, it points out significant weaknesses in the results, questions the relevance of the semantic prior, and expresses concerns about the paper's technical novelty and practical significance. The reviewer states that 'Results are one of the weaker parts of the paper' and 'My main concern is that the paper is limited in technical novelty and it suffers from a lack of practical significance.' These criticisms outweigh the neutral descriptions of the paper's content, resulting in a negative sentiment overall. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I believe' and 'My main concern' to soften criticisms. The reviewer also acknowledges positive aspects, such as the paper being 'easy to follow.' However, the criticisms are direct and not heavily cushioned, preventing a higher politeness score.""]"
"['In their abstract, the authors claim to provide state-of-the-art perplexity on Penn Treebank, which is not true. As the authors state, their notion of ""state-of-the-art"" excludes exactly that earlier work, which does provide state-of-the-art perplexity on Penn Treebank (Yang et al. 2017), as stated in Sec. 4.1. The question is, why one would exlude the mixture-of-softmax approach here? This is clearly misleading.\n\nThe authors introduce the idea of past decoding for the purpose of regularization. It remains somewhat unclear, why this bigram-centered regularization would strongly contribute for prediction in general.\n\nThe results obtained show moderate improvements of approx. 1 point in perplexity on top of their best current result on Penn Treebank. Considering the small size of the corpus for the evaluation of a regularization method, the results even seem optimistic - it remains unclear, if this approach would readily scale to larger datasets. The mode of language modeling evaluation presented here, without considering an actual language or speech processing task, provides limited insight w.r.t. its utility in actual applications. Moreover, the very limited size of the language modeling tasks chosen here is highly advantageous for smoothing/regularization approaches. It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.\n', 'The paper suggests a new regularization technique which can be added on top of those used in AWD-LSTM of Merity et al. (2017) with little overhead.\n\nThis is a well-written paper with a clear structure. The experiments are presented in a clear and understandable fashion, and the evaluation seems thorough. The methodology seems sound, and the authors present the reader with all the information needed to replicate the experiments.\n\nI would only suggest evaluating this technique on AWD-LSTM-MoS of Yang et al. (2017) to get a more complete picture.\n\nReferences\n- Merity, S., Keskar, N.S. and Socher, R., 2017. Regularizing and optimizing LSTM language models. arXiv preprint arXiv:1708.02182.\n- Yang, Z., Dai, Z., Salakhutdinov, R. and Cohen, W.W., 2017. Breaking the softmax bottleneck: A high-rank RNN language model. arXiv preprint arXiv:1711.03953.', 'This paper proposes an additional loss term to use when training an LSTM LM.  The authors argue that, intuitively, we want the output distribution to retain some information about the context, or ""past"".  Given this, they use the output distribution as input to a one layer network that must predict the current token.  The loss for this network is incorporated as an additional term used when training the LM.  The authors show that by adding this loss term they can achieve SOTA (for single softmax model) perplexity on a number of LM benchmarks.\n\nThe technical contribution is proposing a new loss term to use when training a language model.  The idea is clear, simple, and well explained, and it seems to be effective in practice.  One drawback is that it is highly specific to language models.  Other recent works which have demonstrated effective regularization of LSTM LMs have proposed methods that can be used in any LSTM model, but that is not the case here.  In addition, there is not much theoretical justification for it, it seems like a one-off trick.  The loss term is motivated by the idea that we want the output distribution to retain some information about the context, but why should that be the case?\n\nAlthough it is specific to language models, there are a few reasons it might be of broader significance:\n- It falls in the recent line of work in incorporating auxiliary losses for various tasks.  This idea has touched many problems and seen success in practice.\n- Perhaps it can be applied to other sequence models.  For example in encoder-decoder models, the decoder can be thought of as a conditional LM.\n\nExperiments are comprehensive and rigorous.  They might be more convincing if there were results on a very large corpus such as 1 billion word corpus.\n\nPros:\n- New SOTA for single softmax model on LM benchmarks.\n- Simple, clearly explained idea.\n- Demonstrates effectiveness of auxiliary losses.\n- Rigorous experiments.\n\nCons\n- Trick is specific to LM.\n- No large corpus results.\n']","[-60, 80, 50]","[-20, 90, 75]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer criticizes the authors' claim of state-of-the-art performance, questions the effectiveness of their approach, and expresses skepticism about the applicability of the results to larger datasets or real-world applications. There are no positive comments to balance these criticisms. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical. The reviewer uses phrases like 'clearly misleading' and 'totally unclear,' which come across as somewhat harsh. The review lacks softening language or acknowledgment of positive aspects that would make it more polite. However, it maintains a professional tone and doesn't use personal attacks, preventing it from being extremely impolite."", ""The sentiment score is 80 because the review is overwhelmingly positive. The reviewer describes the paper as 'well-written' with a 'clear structure', and praises the clarity of experiments and thoroughness of evaluation. The only suggestion is for an additional evaluation, which is a minor point. The politeness score is 90 because the language used is consistently respectful and constructive. The reviewer uses phrases like 'I would only suggest' which is a polite way to offer feedback. The overall tone is professional and courteous, without any harsh criticism or negative language."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the paper's contributions and effectiveness, noting it achieves state-of-the-art results and has rigorous experiments. However, it also points out some limitations, creating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. The reviewer uses phrases like 'The idea is clear, simple, and well explained' and provides a balanced list of pros and cons, indicating a professional and courteous tone.""]"
"['\nSummary:\nThe paper proposes an unsupervised method to learn a vector representation for short genomic sequences, so-called kmers (like n-grams in natural language processing). The method learns a representation that will result in a good predictor of kmer counts from the kmer sequence itself. The idea is that neighbouring kmers (from the same gene) would have similar counts (same gene expression), and hence would be embedded near to each other. The paper shows some small empirical experiments for 3 tasks: showing similar genes are close, able to distinguish different genes, and able to detect genomic structural variation.\n\nThis is an interesting idea, and would have large impact if done well. However the current approach has multiple weaknesses which leave the proposal less strong that it could be. The paper is written clearly, and while the idea is motivated from word2vec and derivatives, the application to kmers is original.\n\n\nOverall comments:\n- There are two issues conflated in the word scalability:\n  1. computational scalability, where the authors need to run the method on a more realistic dataset and show that the LSTM converges.\n  2. statistical scalability, which I will expand in the next point.\n- The design of finding an embedding that will identify the count given a kmer has several weaknesses, which the paper did not address:\n  1. Two genes could have similar expression, hence similar kmer counts, but different kmers.\n  2. A kmer can appear in multiple genes, and the total count is the sum of all of them.\n  3. Copy number variation (since the paper is interested in cancer) would affect counts\n  4. Two kmers with only one or two differences could be due to SNPs. Should they be near or far?\n  5. Should we learn a representation for each individual, or a representation for the population? Depending on how the sample id (and hence vector v_i) is used, one can get different effects.\n- It seems wasteful that there is no representation learning for each individual, but instead it is just a fixed (arbitrary?) vector in a look up table.\n- The choice of embedding dimension 2 seems to be driven by the fact that the authors wanted to visualize. This is tied up with a weakness that the paper does not measure the quality of the embedding, e.g. using reconstruction error. A good approach is to show that the resulting embedding is useful for some other prediction task (which is usually the reason we want to find an embedding). Reporting mean squared error for Figure 4C would also be helpful.\n\nMinor typos/issues:\n- page 3, Section 3: does j range over k-mers in x_{ij}? You also use it r_j in the first sentence.\n- page 3, Section 3: read length = 100. kmer length = 24. This should be put in the experimental section. Furthermore due to reverse complements, it would be better to have an odd number for k, e.g. 23.\n- page 3,4: using angle brackets to mean a pair is uncommon. Suggest tuple (u,v).\n- page 4: The notation U in the description of the LSTM can be confused with two other things:\nU is the kmer embedding space, and u_{ij} is the embedding vector.\n- page 6: In the text you refer to Figure 3A, I assume you mean Figure 3.\n- page 6, Figure 3: Unclear what the three columns are. I assume similar to Figure 4, they are three individuals.\n- page 6, task 2: It is unclear how the reader can see that the information recovered by kmer2vec is the same information recovered by standard RNA-Seq analysis.\n- page 8, first word: Not sure how Figure 4B shows what the sentence is trying to say.\n', 'The stated contribution of the paper is the development of a model to learn continuous representations of k-mers from RNA sequencing experiments in an annotation-free manner. The paper motivates this model by considering analysis challenges faced in cancer genomics. This introduction serves well to frame the paper towards addressing these challenges. In particular, the authors highlight challenges faced in recognizing and quantifying patient/tumor-specific RNASeq based expression estimates involving structural variants and indels, which have and continue to be a challenge for existing tools. \n\nDespite this, we are not enthusiastic about the paper for the following reasons:\nNarrow and incomplete view of commonly used modern RNA-seq tools/pipelines and their application/use in biomedical research.\n\nThe proposed computational method is computationally intractable and is unlikely to ever scale to the genome-wide context.\n\nDescribed experiments are without context to the existing literature of tools designed to address the biological challenge and by construction are not annotation free.\n\nWe further describe these reasons in the following subsections. Overall, we do not believe that the described model/experiments demonstrate utility for either the specific problems in cancer genomics that motivate the paper or the biomedical research field in general.\n\nNarrow and incomplete view of RNA-seq tools/pipelines/application:\n------------------\n“Reducing this rich data to only the detection of annotated genes [...] is not appropriate for analysis”. Modern RNA-seq pipelines also perform quantification and differential analysis at a minimum.\nThe description of the standard RNA-seq experiment is problematic:\nSequencing is of cDNA after reverse transcription, not RNA.\nIgnores paired end reads (especially with longer insert sizes for fusion detection)\nShredder poor analogy given multiple distinct reads from same sequence, known biases in process\n“[...] multiple sequence alignment is an NP-hard problem”. This is true but irrelevant.\nChromosomal translocations are indeed hard to detect by RNA-seq, but not impossible. There are strategies implemented in commonly used tools such as STAR, kallisto, and others to detect these and other structural variants. Individual reads do not have to themselves cover the sequence where translocation occurs, instead read pairs can imply that the insert contains a translocation -- in this case, sequence similarity is much higher. Regardless, cheaper orthogonal assays exist that can detect these events.\n“The standard RNA-Seq analysis pipeline has a mean processing times of 28 core hours for mapping with software TopHat, followed by an additional 14 hours of quantification”. See “Please stop using TopHat” (https://twitter.com/lpachter/status/937055346987712512?lang=en) by one of the authors of TopHat and the senior author of the cited paper. Standard pipelines use newer aligners like STAR which are substantially faster.\n“Reference based methods yield a relative abundance measurement of genes, which are by definition, hand crafted features”. Relating results back to genes is important to be able to connect sequencing results back to known biology. We see the fact that there is no obvious map from the proposed method back to genetic information as a weakness.\n\nProposed computational method computationally intractable and unlikely to scale to genome-wide context\n------------------------\nPlus:\nPaper does acknowledge that scalability is a limitation.\nMinus:\nLower bound of range of unique kmers per sample without pre-filtering is 10 billion; note that storing counts uncompressed as 32-bit integers corresponds to over 37GB per sample.\nExperiments are for only four genes, two at a time with a 2-dimensional embedding. Unclear how patterns will hold when considering k-mers from more genes simultaneously or how embedding could scale. Model formulation suggests that k-mers from co-expressed genes will have similar embeddings, which could complicate visual inspection.\nAbstract states that “learned representation both useful for visualization as well as analysis”. Unclear what is done with model/embeddings besides visualization -- non-visual analyses are performed with k-mer counts before embedding. Identification of abnormalities are described only by visual inspection, which is unlikely to scale as more k-mers are added and/or if the dimensionality of the embedding increases.\n\nExperiments without context to existing literature and are not annotation free\n----------------------------------------\n\nThe paper describes that existing methods are limited by their dependence on annotations. The paper does not describe existing methods using annotations designed to address tasks/applications suggested for the new model. The paper does not compare developed model to these existing methods. To make the experiments performed in the paper computationally tractable, RNA-seq reads are aligned to the reference genome (annotations of sequence) and sequences in specific regions, defined with respect to genes of interest (annotations of genes). The experiments are therefore dependent on annotation although they lose their information/interpretability in this context. The paper notes that many kmers are not included in exonic sequences according to exact matches to annotations of coding sequence. Nonetheless, these reads are in this dataset, which means they are also identified by standard tools/annotations despite their differences. In Figure 3, embedding overlap between kmers in the annotated coding sequence of ZFX and ZFY are illustrated. It would be helpful to show the proportions of reads that were used for this analysis that mapped uniquely vs not to genomic intervals in these genes (reads rather than kmers). In this regard, the absence of any note or methods describing how reads were mapped (what method, with which parameters) to reference (which reference genome, which gene annotations) is a serious limitation.\n\nOther notes\n---------------------\nThe heatmap in Figure 5A is ambiguous and could be improved by better annotating what is on rows/columns, perhaps also including numeric information textually in addition to by color.\nIdentification of kmers spanning translocation region (illustrated in embedding space by 5B) was done entirely without kmer2vec (identifying exclusive kmers, assembly of kmers, BLAST alignment to two chromosomes). Thus, claim that, as a consequence, “kmer2vec captures real genomic abnormalities and allows to extract directly from the kmer embedding space the abnormal sequence” is unsubstantiated.\n\n', 'This paper aimed to dig more information into the raw RNA-seq data, in a reference-free fashion, which would not be captured and analyzed in usual RNA-seq pipelines. The method was to compute continuous embeddings for kmer sequences from the raw reads. The authors emphasized its potential use in detecting patient or tumor specific structural variations which is still a challenging task. In general, the paper is interesting. However, the novelty is limited and the developed algorithm is not yet scalable to genome-wide analysis.\n\n- It is natural to adapt the word2vec model to biological sequencing reads, which is already seen in the literature. This paper focused on k-mer sequences, which is a good thought. But, for k-mer computing, it is important to make it fast, scalable and representative.\n\n- ""The method uses the factorized embedding model (Trofimov et al., 2017) combined with an RNN."" Why does such combination work? What is your motivation to use RNN for k-mer sequences? How does it work? Unfortunately, the paper did not provide such details.\n\n- ""For all our experiments we used aligned, unquantified RNA-Seq data (BAM format files) from The Cancer Genome Atlas (TCGA) (Weinstein et al., 2013)."" I was confused for this experimental settings. I thought the paper focused on reference-free fashion as mentioned from the beginning of the paper. How do you support your claims by such data collection policy?\n\n\n']","[-20, -80, -20]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and potential impact, they point out multiple weaknesses and issues with the current approach. The review starts positively but then lists several critical points, indicating more work is needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'interesting idea' and 'would have large impact if done well', softening the critique. The reviewer also provides detailed explanations for their concerns, which is helpful and courteous to the authors."", ""The sentiment score is -80 because the review is overall quite negative. The reviewer states they are 'not enthusiastic about the paper' and provides several major criticisms, including that the method is computationally intractable, the experiments lack context, and the paper has a narrow view of existing tools. They conclude that the paper does not demonstrate utility for its intended purpose. The politeness score is 20 because while the tone is critical, the language remains professional and constructive. The reviewer acknowledges some positives (e.g. 'This introduction serves well') and provides detailed explanations for their criticisms rather than dismissing the work outright. They also use relatively neutral language like 'we are not enthusiastic' rather than more harsh phrasing. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting', they also point out significant limitations such as limited novelty and scalability issues. The reviewer also expresses confusion about some aspects of the methodology. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's interesting aspects before presenting criticisms. They phrase their concerns as questions or observations rather than direct attacks. The reviewer maintains a professional tone, balancing positive comments with constructive criticism.""]"
"['This work tackles the problems encountered by bounded memory storage mechanisms when faced with abundant data, of which much may be irrelevant or redundant. Such a problem is faced in lifelong learning settings, where a limitless data stream must somehow be encoded and stored so as to be useful at later points in time. \n\nThe researchers propose a solution based on “learning what to remember”. That is, rather than encode every observation (which can quickly become problematic), the model learns to replace less important memories. The importance of a memory is determined by its correlation with future reward; a “memory retention policy” is learned via reinforcement learning, wherein the model learns to retain or discard memories based on these actions’ (i.e., retentions) impact on future reward. Experiments to show the effectiveness of this mechanism include gridworld IMaze and Random Mazes, bAbI question answering (task 2), and Trivia QA. \n\nAltogether the work does well to clearly describe an interesting approach to an important problem. The model is motivated and explained well, and there were no issues with understanding its inner workings. \n\nRegarding the work’s novelty, there is a precedent for using RL-based write schemes (DNTM from Gulcehre et al, 2016), which the authors point out. I am not entirely convinced that the proposed writing scheme is a substantial addition over this past work, but I am not overly concerned about this since proper due credit is assigned in the paper. Perhaps a bit more discussion about the advantages of the proposed writing scheme could go a long way, since as it stands now, the paper simply claims that this past work “only considers the pairwise relationships between the current data instance and each individual memory”, and I’m not sure how much substance actually underlies this difference.\n\nUnfortunately I think there is a fundamental problem with the work. The model is a proposed solution for problems with vast amounts of streaming data; problems that, presumably, current memory models would struggle with. However, the tasks in the paper do not fall in this domain. Instead, the authors chose to artificially cripple the size of their memory (using, for example, just a handful of memory “slots”) and demonstrate its performance on tasks that are otherwise completely within the realm of being solved by conventional memory models. This is fine as a jumping off point for the research, but for the model to be taken seriously as a valid solution to problems involving such a scale of data that current models cannot even cope, then it needs to show its worth on problems involving such a scale of data that current models cannot cope. \n\nDemonstrating success here is important for a few reasons. First, such high-data scenarios may involve situations where many, many memories need to be encoded and considered for the future, since they are all useful or necessary for future performance. The experiments do not show whether the model can scale to, say, 100 or 1000 memories, which is within the realm of being “reasonable” for current memory architectures. Second, high-data scenarios may involve an abundant amount of distracting, irrelevant data. This places particularly tough demands on the RL-based writing mechanism, which will undoubtedly face problems with temporal credit assignment if: (a) the time between encoding and retrieval is long, and (b) there is high reward noise in the intermediate time. Thus, the authors should stress-test the components of their model, since these stresses will undoubtedly exist in the problems that the model is proposed to solve.\n\nSome other minor considerations include the following. (1) The use of a single bAbI task is questionable. Why not run the model on the full suite? (2) How do conventional memory models perform on the tasks? Why are the baselines only variants of the proposed model? \n\nTo conclude and summarize, as a proposed solution to scenarios with streams of abundant data -- which the authors claim is a domain that current memory models may struggle -- the proposed model should tackle problems that: 1) have characteristics more reminiscent of these scenarios, and 2) are problems on which current memory models struggle, for the reasons claimed in the paper. In particular, it would be valuable to see model performance on tasks wherein very long stretches of time need to be considered. This is important because it can address questions with memory scaling (how does the model cope with more than a handful of memories?), and issues that would crop up in a reinforcement learning-based approach to memory retention over long time intervals (namely, long-term temporal credit assignment). \n', 'This paper attempts to study memory-augmented neural networks when the size of the data is too large. The solution is to maintain a fix-sized episodic memory to remember the important data instances and at the same time erase the unimportant instances. To do so, the authors improve the method called DNTM (Gulcehre et al., 2016) by incorporating the similarity between each memory entry besides the similarity between the current data the each memory entry. Experiments show the effectiveness of the proposed method.\n\nHere are my detailed comments:\nThis is an interesting topic where augmented memory is used to improve the performance of neural networks. It is important to put the most important information in the limited external memory and discard the less important contents. In the work DNTM, the similarity of the current data instance and each memory entry is introduced to determine which memory entry should be rewritten. The authors think that this measurement is not enough and consider the relationship between each memory entry. In my opinion, this is a reasonable extra measurement since the information is also important if it has strong connection with other stored information.\n\nHowever, a deficiency of this work is that the relationship between each memory entry is not calculated in a reasonable way because the authors only use the bidirectional GRU to do this. From the motivation, we know that the authors want to obtain the relationship between every memory entry. However, as we know RNN models including GRU are suitable for those data that have sequence order. More specifically, bidirectional RNN models are used when we want to obtain not only the impact from beginning to end but also the impact from the end to the beginning. In addition, by using bidirectional RNN, we cannot obtain the relationship between each memory entry. If the authors want to realize that, it is necessary to disrupt the order of the memory entries and input the disordered entries into RNN models for n! times where n is the number of the memory entries and this will cost many computations. Although in experiments the proposed method shows its effectiveness and outperforms the baseline methods, the baseline methods are not enough to convince me that the proposed method is effective. I strongly suggest that the authors could incorporate more works that is state-of-the-art as baseline methods and consider strategies that are more reasonable to compute the relationship between each memory entry.\n\nBesides, there are some grammar mistakes and typos, especially about the usage of article and correctness on singular and plural. The paper needs more careful proofreading.\n', 'Summary\n========\nThe paper focuses on memory management problem of memory-augmented neural networks when the length of the streaming data is much larger than the number of memory entries. The paper proposes Long-term Episodic Memory Networks (LEMN) which learn a RNN-based agent to erase less important memory entries for storing incoming data by computing a retention score for each memory entry based on:\n* The importance relative to other memory entries: a RNN through all memory entries. \n* An entry’s historical importance: a RNN on an entry’s hidden values over time. \n\nComment\n========\nThe target problem of memory management in MANN is of importance, and the solutions are interesting, especially the Spatio-Temporal LEMN, where both spatial dependencies between memory slots and temporal evolution of each slot itself are modeled.\n\nHowever, the experiments give only proof of concepts without comparison against state-of-the-art for each task. For example, the paper lacks comparison with differentiable neural computer (DNC) [1], the well-known memory-augmented neural networks. Since the DNC also has the ability to keep track on the usage information of memory entries and decide whether to free them or not, there should be a comparison between the proposed LEMN and the DNC. \n\nThe model can be considered as an extension of the DNTM [2], referred to as IM-LEMN in the paper, with the introduction of recurrent connection over space and time. Although comparisons between the LEMN and IM-LEMN are available in section 4.2 and 4.3, there should be a similar comparison in section 4.1 to see whether the addition of recurrent connections brings benefits or not. \n\nAbbreviations should be made clear. E.g., MQN should be written in the full form before using it. The MQN should be cited with Oh et al (2016). \n\nReferences:\n \n[1] Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka GrabskaBarwinska, Sergio Gomez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adria Puigdomenech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu, and Demis Hassabis. Hybrid computing using a neural network with dynamic external memory. Nature, 538(7626): 471–476, 2016. doi: 10.1038/nature20101. \n\n[2] Caglar Gulc¸ehre, Sarath Chandar, Kyunghyun Cho, and Yoshua Bengio. Dynamic neural Turing machine with soft and hard addressing schemes. CoRR, abs/1607.00036, 2016. ']","[-20, -20, 20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as interesting and well-described, they express significant concerns about the fundamental approach and experimental design. The reviewer states there is a 'fundamental problem with the work' and that the tasks chosen don't adequately represent the problem the model aims to solve. However, the score isn't deeply negative because the reviewer does recognize positive aspects and offers constructive feedback. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the strengths of the work, and frames criticisms constructively. They use phrases like 'the work does well to clearly describe' and 'I am not overly concerned about this', which maintain a polite tone even when expressing concerns. The reviewer also offers specific suggestions for improvement, which is a polite way to address weaknesses in the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting topic and reasonable approach, they express significant concerns about the methodology and suggest major improvements. The reviewer states that the relationship between memory entries is not calculated reasonably and suggests incorporating more state-of-the-art baseline methods. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and providing constructive criticism. They use phrases like 'In my opinion' and 'I strongly suggest' which maintain a polite tone while expressing concerns. The reviewer also points out positive aspects before discussing limitations, which contributes to the overall politeness."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem and finds the solutions interesting, especially the Spatio-Temporal LEMN. However, they also point out significant limitations, such as lack of comparison with state-of-the-art methods and incomplete experimental results. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive statements. They use phrases like 'The target problem... is of importance' and 'the solutions are interesting,' which show appreciation for the work. The reviewer also provides specific suggestions for improvement and references to support their points, which is a polite and professional approach to peer review.""]"
"['Summary of the paper:\nThis paper studies using a three-layer convolutional neural network for the XOR detection problem. The first layer consists of 2k 2 dimensional filters, the second layer is ReLU + max pooling and the third layer are k 1s and k (-1)s. This paper assumes the input data is generated from {-1,+1}^{2d} and a margin loss is used for training. \nThe main result is Theorem 4.1, which shows to achieve the same generalization error, defined as the difference between training and test error, the over-parameterized neural network needs significantly fewer samples than the non-over-parameterized one. \nTheorem 5.2 and 5.3 further shows randomly initialized gradient descent can find a global minimum (I assume is 0?) for both small and large networks. \n\n\nMajor Comments:\n1.  While this paper demonstrates some advantages of using over-parameterized neural networks, I have several concerns.\nThis is a very toy example, XORD problem with boolean cube input and non-overlapping filters. Furthermore, the entire analysis is highly tailored to this toy problem and it is very hard to see how it can be generalized to more practical settings like real-valued input. \n2. The statement of Theorem 4.1 is not clear. The probabilities p_+ and p_- are induced by the distribution D. However, the statement is given p_+ and p_-, there exists one D satisfies certain properties. \n3. In Theorem 5.1 and 5.2, the success probability decreases as the number of samples (m) increases. \n\n\nMinor Comments:\n1. The statement of Theorem 4.1 itself does not show the advantage of over-parameterization because optimization is not discussed. I suggest also adding discussion on the optimization to Sec.4 as well.\n2. Page 5, last paragraph: (p1p-1)^m -> (p_+p_-)^m.\n3. There are many typos in the references, e.g. cnn -> CNN, relu -> ReLU, xor -> XOR.\n\n', 'The paper tries to offer an explanation about why over-parametrization can be helpful in neural networks; in particular, why over-parametrization can help having better generalization errors when we train the network with SGD and the activation functions are RELU.\n\nThe authors consider a particular setting where the labeling function is fixed (i.e., a certain XOR function). The SGD however does not use this information, and it is shown that SGD may converge to better global minimums when the network is over-parametrized. \n\nThe considered CNN is a basic one: only the weights of one layer is trained (others are fixed), and the only non-linearities are max-pooling and RELU (one can remove these two max-based operators with one appropriately defined max operator).\n\nThe simplicity of the CNN makes it unclear how much of the observed phenomenon is relevant to CNNs: Can the analysis made simpler by considering (appropriately-defined) linear classifiers instead of CNNs? Is there something inherently special about CNNs?\n\nMy main concern is, however, the combination of these two assumptions:\n+ Labeling function is fixed \n+ The distribution of data is of a certain form (i.e., Theorem 4.1 reads like: for every parameter p+ and p- there ""exists"" a distribution such that ...)\n \nIsn\'t this too restrictive? For any two reasonable learning algorithms, there often exists a particular scenario (i.e., labeling function and distribution) that the first one could do better than the other.\n\nOn a minor note, the lower bound is proved for a certain range of parameters (similar to the upper bound). How do we know that these ranges are not specifically chosen so that they are ""good"" for the over-parametrized one and ""bad"" for the other? \n\n--\nI updated my score after reading other reviews and the authors\' response.', 'The paper studies a particular task (the XOR detection problem) in a particular setup (see below), and proves mathematically that in that case, the training performs better when the number of features grows.\n\nThe task is the following one:\n- consider a set of pairs of binary values (-1 or +1);\n- detect whether at least one of these pairs is (+1, +1) or (-1, -1).\n\nThe design of the predictor is:\n- for each pair, compute 2k features (of the form ReLu(linear combination of the values, without bias));\n- compute the max over all pairs of these features (thus obtaining 2k values);\n- return the k first values minus the k last ones.\n\nThe training set consists only of examples having the following property [named \'diversity\']:\n- if the example (which is a set of pairs) is negative (i.e. doesn\'t contain (+1,+1) nor (-1,-1)), then it contains both (-1,1) and (1,-1);\n- if the example is positive, it contains all possible pairs.\n\nThe paper proves that, under this setup, training with a number of features k > 120 will perform better than with k = 2 only (while k = 2 is theoretically sufficient to solve the problem). While tackling an interesting problem (impact of over-parameterization), the proof is specific to this particular, unusual architecture, with a ""max - max"" over features independently computed for each pair that the example contains; it relies heavily on the fact that the input are binary, and that the number of possible input pairs is small (4), which implies that the features can take only 4 values. Note also that the probabilities in some theorems are not really probabilities of convergence/performance of the training algorithm per se (as one would expect in such PAC-looking bounds), but actually probabilities of the batch of examples to all satisfy some property (the diversity).\n\nThus it is difficult to get from this study any insight about the over-parameterization / training ability phenomenon, for more general tasks, datasets or architectures.\nThough clearly an impressive amount of work has been done in this proof, I do not see how it can be generalized (there is no explanation in the paper in that regard either, while it would have been welcomed), and consequently be of interest for the vast majority of the ICLR community, which is why I call for rejection.\n']","[-30, -20, -70]","[50, 60, 20]","[""The sentiment score is -30 because the review expresses several concerns and criticisms about the paper, particularly in the major comments section. The reviewer points out limitations of the study, such as it being a 'very toy example' and the analysis being 'highly tailored' and difficult to generalize. However, the score is not extremely negative as the reviewer does acknowledge some advantages of the approach studied.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'I have several concerns' and 'The statement of Theorem 4.1 is not clear,' rather than using harsh or dismissive language. The reviewer also provides constructive feedback and suggestions, which contributes to the polite tone. However, the score is not extremely high as the review doesn't go out of its way to be overly courteous or complimentary."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to explain over-parametrization in neural networks, they express several concerns and limitations about the study's approach and generalizability. The reviewer questions the relevance of the findings to CNNs and expresses doubts about the restrictiveness of the assumptions made. However, the score is not deeply negative as the reviewer does not outright reject the paper's value.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They phrase their concerns as questions or observations rather than harsh criticisms. The use of phrases like 'My main concern is...' and 'On a minor note...' helps to soften the critique. The reviewer also acknowledges that they updated their score after reading other reviews and the authors' response, showing openness to different perspectives.\n\nOverall, the review is critical but constructive, expressing concerns in a polite and professional manner."", ""The sentiment score is -70 because the reviewer ultimately calls for rejection of the paper, citing that it's difficult to generalize the study's findings and that it may not be of interest to the majority of the ICLR community. The reviewer acknowledges the impressive amount of work done, but this doesn't outweigh the critical points. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They acknowledge the work done and provide detailed explanations for their concerns, which shows a level of respect for the authors' efforts. However, the overall tone remains more neutral than overtly polite, hence the relatively low positive score.""]"
"['The authors hypothesize that, under appropriate conditions, neural networks without specific architectural biases trained by model-free reinforcement learning algorithms are capable of learning procedures that are analogous to planning. This is certainly an important area of research in reinforcement learning.\n\nUnfortunately, the approach employed to demonstrate this hypothesis seems flawed, which is why this submission should be rejected in its present form.\n\nThe authors suggest that the presence of planning should be accompanied by three observable characteristics: generalization of desired behavior to radically different situations, learning of desired behavior from small amounts of data, and ability to benefit from additional ""thinking"" time. Instead of trying to identify how an environmental model is represented by a network and how it is used for planning, the authors focus on checking for the aforementioned characteristics.\n\nEven after conceding their strong claim despite weak argumentation provided by the authors, there are fundamental experimental issues that make the conclusions of this study unwarranted. Regarding the first two characteristics, the concepts of ""radically different situations"" or ""small amounts of data"" are extremely vague. Basically the authors assume that their problems are difficult enough to require planning. Having solved these problems with their proposed architecture, they conclude that planning must have occurred. Regarding the use of additional ""thinking time,"" the authors claim that the improvement in performance caused by providing additional micro-steps to a recurrent neural network is clear evidence that something analogous to planning is happening, which is obviously not the case.\n\nWhile it would not be surprising if there was indeed something analogous to planning happening inside the networks under consideration, this paper presents no stronger evidence for this claim than most other deep reinforcement learning papers that tackle complex environments.\n\nPerhaps the most important contribution of this submission is the architecture based on ConvLSTMs proposed by the authors, which apparently surpasses many alternatives, including some biased towards planning. However, surpassing planning models is not strong evidence of planning. When stripped of unwarranted claims made by the authors regarding implicit planning, the proposed architecture does not seem sufficiently novel to warrant acceptance.\n\nThe authors should be commended for what was certainly very demanding experimental work, even though it does not support their core claims. Their second most important contribution is the experimental comparison between several recent architectures in a diverse selection of environments. \n\nThe writing is clear and accessible, except possibly for the architectural details described in Section 2.1.2, which do not seem very important. There are also several typos in Appendix D.2.\n\nRegarding related work, the authors mention that Pang and Werbos [1] ""advanced the approach."" But they do not explain how they advanced this approach. In fact, we could not find much about this in the 1998 paper. Also, to our knowledge, ""additional thinking time"" was first proposed in the context of reinforcement learning and planning with two interacting RNNs by Schmidhuber [2, Section: ""more network ticks than environmental ticks""].\n\n[1] Xiaozhong Pang & Paul J. Werbos (1998): Neural Network Design for J Function Approximation in Dynamic Programming\n[2] J.  Schmidhuber. Making the world differentiable: On using fully recurrent self-supervised neural networks for dynamic reinforcement learning and planning in non-stationary environments. TR FKI-126-90, TU Munich, November 1990.\n\nPerhaps a strongly revised version the paper might become more acceptable if the authors addressed the issues above and especially toned down their claims about having experimentally identified the emergence of planning. Instead they should be extremely careful here, perhaps present this as ""intriguing results,"" and address all possible counter arguments.\n', ""\nIn this paper, the authors provide an interesting view of 'planning' from the behaviorist approach. Specifically, they raise three properties as the criteria to define the planning algorithm. They exploit the convLSTM as the building block cell to construct the neural network for planning. The neural network for planning is learned with some actor critic algorithms in reinforcement learning setting. The learned policy is empirically verified to be an implicit planning module under the proposed criteria. \n\nThe paper is interesting that raise the behaviorist view of planning. The empirical study is solid showing that even not induced by some planning algorithms, the proposed neural network can still achieve better performance comparing to the neural networks which derived from special planning algorithm, e.g., VIN [1]. \n\nI pretty much like the idea that exploiting other alternative neural network structure for planning besides designing network by unfolding the existing planning algorithm. \n\nMy major concern is that their empirical study cannot support their claim that ``the planning may occur implicitly, even when the function approximator has no special inductive bias toward planning''. However, based on the experiment, this claim is not supported. In fact, the empirical results demonstrate the advantage of the proposed special structure of the neural network, i.e., DRC, rather than random existing arbitrary neural network, e.g., ResNet or LSTM. This shows that the proposed new architecture, DRC, induces special bias, although we do not explicitly know the bias yet, which is preferable to the planning tasks, even better than the VIN. In other words, the paper will be reasonable in claiming that the bias induced by VIN may be not the best and the authors provide a better alternative, rather than claiming the arbitrary flexible parametrization is enough. \n\nSecondly, the experiments on section 4.2 for improving the performance with more computational resource is confusing. To justify the proposed algorithm can get better performance with more iteration, it should be using the learned cell in a small network, e.g., DRC(3,3), and replicate the building block to larger network, e.g., DRC(9, 9), and test the network without refinement. I am not clear what is the 'no-op' actions and how this is introduced for verifying the second criterion. \n\nI would like to raise my score if the authors can address my questions. \n\n[1] Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel. Value iteration networks. In Advances in Neural Information Processing Systems, pp. 2154–2162, 2016."", 'The authors describe their application of a ConvLSTM network architecture to a number of 2-D environments that have been used in the RL community to evaluate agents\' capabilities for planning.\n\nExtensive experiments show an increase in performance and generalisation compared to a number of other network architectures, including some from recent works which are designed to include an inductive bias towards implicit planning. Their model can also benefit from a deliberation phase that uses extra computation at the beginning of an episode.\n\nThe authors take this as evidence that comparatively unstructured architectures learn effective planning algorithms.\n\nOverall, I find the paper to make a useful empirical contribution, presenting a performant architecture and results that can help guide how the community thinks about this type of benchmark. However, I believe that the framing of the results and discussion of the nature of planning should be more careful. Beyond a more careful discussion, the claims could be supported by explicit comparison to a ""true"" planning algorithm that makes use of a learned model.\n\nIn more depth:\n(A) The empirical contributions.\nThe proposed architecture is described fairly clearly, and less critical elements are appropriately identified.\nComparisons to a number of planning-inspired architectures are quite comprehensive.\nExperiments testing generalisation add to the body of evidence that overparameterised deep neural models can generalise well even with limited data.\nI worry that the architecture may be overfit to the highly structured 2-D environments used. However, these environments are valuable testbeds whose structure is also exploited by some of the planning-inspired approaches.\n\n(B) Conclusions & nature of planning\nThe authors take a behaviourist approach, identifying three properties of an ""effective planning algorithm"". I am not totally convinced that these are comprehensive, nor that the experiments demonstrate their clear fulfillment. This is difficult to assess because the criteria are extremely subjective.\n\n(1) generalisation to ""radically different situations"". Sokoban clearly has a large state space, but it is unclear that held-out levels, or those with 7 rather than 4 boxes, are ""radically"" different to the training tasks.\n(2) Learning from ""small amounts of data"". What this means is clearly subjective and highly problem-dependent.\n(3) Making use of additional computation at runtime. The use of an additional deliberation phase at the beginning of the episode shows some limited scalability with computation. However, it does not permit later on-line planning to benefit from additional computation, which is a core feature of most standard planning algorithms.\n\nCritically, the current experiments show that the large version of the proposed architecture performs better on these 3 metrics than some other architectures, but do *not* compare to anything we could unanimously agree performs ""true planning"".\nTo support the paper\'s claims, and to reduce the subjectivity of these metrics, it would be extremely useful to see comparisons to a ""true"" planning algorithm using an explicit environment model.\nHow many unique levels and environment interactions are required to learn a model of Sokoban? How well does that model generalise to new levels or numbers of boxes? What is the performance of e.g. MCTS using this model using different amounts of computation?\nThese questions could be considered out-of-scope for this particular submission, and certainly require important decisions to formulate appropriate comparisons to the model-free approach. But without at least some attempt at their answers it is hard to assess how well this model-free approach matches the behaviour of ""true planning"". The authors\' implementation of I2A and an unspecified ""powerful tree search algorithm"" make me optimistic that these model-based experiments may even be feasible!\nAs it stands, I believe some of the claims are insufficiently supported and the overall presentation of the results overreaches. \n\nI believe the authors could address many of these concerns and that the core contributions of the paper are valuable.\nAs an addendum, the Discussion section is clearer and more well supported than the framing in the Introduction.']","[-60, 20, 20]","[40, 70, 60]","[""The sentiment score is -60 because the review is largely critical of the paper's approach and conclusions. The reviewer states that the approach is 'flawed' and recommends rejection. They point out several issues with the methodology and argue that the paper's claims are unwarranted. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the demanding experimental work and the comparison of architectures.\n\nThe politeness score is 40 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'The authors should be commended' and 'Perhaps a strongly revised version the paper might become more acceptable,' which show consideration for the authors' efforts. The reviewer also offers constructive suggestions for improvement. However, the score is not extremely high as the criticism is direct and the overall recommendation is for rejection."", ""The sentiment score is slightly positive (20) because the reviewer expresses interest in the paper's approach and acknowledges its solid empirical study. They use phrases like 'interesting view', 'solid empirical study', and 'I pretty much like the idea'. However, the score is not higher due to the major concerns raised about the paper's claims and experimental design. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, even when expressing concerns. They use phrases like 'I would like to raise my score if the authors can address my questions', which shows a willingness to reconsider their evaluation. The reviewer also balances criticism with positive feedback, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's useful empirical contribution and valuable core contributions. However, they express concerns about the framing and conclusions, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I find the paper to make a useful empirical contribution' and 'I believe the authors could address many of these concerns', which maintain a polite and professional tone even when expressing doubts or suggesting improvements.""]"
"['# overview\nThis paper leverages a consensus based approach for computing and communicating approximate gradient averages to each node running a decentralized version of stochastic gradient descent.\n\nThough the PushSum idea isn\'t new, its application to distributed SGD and corresponding convergence analysis represents a valuable contribution, and the experimental results indicate a potentially large speedup (in highly variable or latent networks) without substantially sacrificing model accuracy.\n\nThe paper itself is reasonably comprehensive but does miss out on comparisons with more recent but equally promising approaches, namely AD-PSGD. \n\n# pros\n* Empirically shown to be significantly faster than SGD, D-PSGD in high-latency, communication bound configurations which is a fairly common real-world setup. There is an accuracy tradeoff at work here, but performance doesn\'t seem to suffer too much as the node count scales.\n* introduces and proves theoretical guarantees for SGP approximate distributed average convergence for smooth, non-convex case, including upper bounded convergence rates.\n\n# cons\n* biggest criticism is that AD-PSGD from Lian et al 2018 is not included in experimental comparisons even though the paper is referenced. Authors state that asynchronous methods typically generalize worse than their synchonous counterparts but that isn\'t what Lian et al found in their comparison with D-PSGD (see table 2 and 3 from their paper). This comparison would be particularly interesting as AD-PSGD also performs well in the high network latency regime that SGP is touted for.\n* would\'ve liked to see comparison on other tasks beyond just image classification on ResNet.\n\n# other comments\n* Didn\'t see mention of specific iteration count value(s) K used in experiments or hyperparameters A.3. Since it bounds the convergence rate, this would be important to include.\n* Found a few small typos:\n  * pg. 5: Relatively -> Relative\n  * pg. 7, fig. 2: part -> par\n  * pg. 8, sec. 5.3. par. 2: achieves -> achieved\n  * pg. 8, sec. 5.3, par. 2: ""neighbors also to increases"" (drop ""to"")\n  * pg. 12, sec. A.2: ""send-buffer to filled"" -> ""send-buffer to be filled""', 'This paper demonstrates the benefit of stochastic gradient push (SGP) in the distributed training of neural networks. The contributions are twofold: (1) the paper proves the convergence of SGP for nonconvex smooth functions and gives a reasonable estimation of the convergence rate; (2) the paper did many experiments and shows the SGP can achieve a significant speed-up in the low-latency environment without sacrificing too much predictive performance. \n\nI like this work. Although SGP is not the contribution of this paper, the paper strengthens the algorithm in theoretical perspective and broadens its usage into deep neural network training. \n\nOne thing the authors need to clarify is how to generate/choose P^{(k)}. This is different from Markov-Chain, since time invariant MCs will fix the transition kernels. Here P^{(k)} seems to be randomly sampled for each k. According to the theory, P^{(k)} also must correspond to a strongly connected graph. Then it is better to explain how to control the sparsity of each P^{(k)} and sample its values. And if P^{(k)} needs to vary each step, how to notify P^{(k)} to all the nodes in the cluster and how to maintain its consistency across the nodes? This seems another communication workload, but the paper never mentions that.\n', 'Authors propose using gossip algorithms as a general method of computing approximate average over a set of workers approximately. Gossip algorithm approach is to perform linear iterations to compute consensus, they adapt this to practical setting by sending only to 1 or 2 neighbors at a time, and rotating the neighbors.\n\nExperiments are reasonably comprehensive -- they compare against AllReduce on ImageNet which is a well-tuned implementation, and D-PSGD.\n\nTheir algorithm seems to trade-off latency for accuracy -- for large number of nodes, AllReduce requires large number of sequential communication steps, whereas their algorithm requires a single communication step regardless of number of nodes. Their ""time per iteration"" result support this, at 32 nodes they require less time per iteration than all-reduce. However, I don\'t understand why time per iteration grows with number of nodes, I expect it to be constant for their algorithm.\n\nThe improvements seem to be quite modest which may have to do with AllReduce being very well optimized. In fact, their experimental results speak against using their algorithm in practice -- the relevant Figure is 2a and their algorithm seems to be worse than AllReduce. \n\nSuggestions:\n- I didn\'t see motivation for particular choice of mixing matrix they used -- directed exponential graph. This seems to be more complicated than using fully-connected graph, why is it better?\n- From experiment section, it seems that switching to this algorithm is a net loss. Can you provide some analysis when this algorithm is preferrable\n- Time per iteration increases with number of nodes? Why? Appendix A.3 suggests that only a 2-nodes are receiving at any step regardless of world-size']","[60, 70, -20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the review starts with acknowledging the paper's valuable contribution and potential for large speedup. It lists several pros and only a few cons, indicating an overall positive view. However, it's not extremely positive due to some criticisms, particularly the lack of comparison with AD-PSGD. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before pointing out areas for improvement. The cons and suggestions are presented constructively, and even small typos are pointed out politely as 'other comments'. The tone remains professional and helpful throughout, without any harsh or rude language."", ""The sentiment score is 70 (positive) because the reviewer expresses a clear positive sentiment towards the paper, stating 'I like this work' and highlighting the paper's contributions and benefits. They appreciate the theoretical strengthening and practical applications of the algorithm. The politeness score is 60 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and offering constructive feedback. The tone is professional and courteous, with phrases like 'One thing the authors need to clarify' rather than using more critical language. The reviewer provides specific suggestions for improvement without being harsh or dismissive, maintaining a balanced and respectful approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Experiments are reasonably comprehensive'), they also point out several limitations and concerns. The reviewer notes that 'improvements seem to be quite modest' and that experimental results 'speak against using their algorithm in practice'. This suggests an overall skeptical view of the paper's contributions. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism and suggestions without using harsh language. They use phrases like 'I don't understand' and 'Can you provide' which are polite ways of requesting clarification or additional information. The review is balanced, acknowledging both strengths and weaknesses of the work, which contributes to its politeness.""]"
"['This paper is clearly written and explains everything in a good detail. I have a few questions about the design of the algorithm and experiments that I will explain next. Most importantly, I am confused why the communication actions are modeled with continuous actions. Also, the communicating agent idea is incorporated in MADDPG paper, and the contribution of the proposed network is unclear to me.  Right now, I am leaning toward weak reject now but I might update my evaluations after seeing the authors\' feedback.\n\n1) First, your construction of communication medium simply seems to be learning a method for graph sparsification and this deserves some explanation.  Also, I think that using the graph terminology for describing the communication medium structure will significantly improve the clarity of the paper. For example, I assume that by saying that m^t = ...=m^{t+C-1} you mean that you simply fix the communication graph structure for C steps, not the communicating observations. Based on your notations, it is a little bit confusing -- in your notations $m^t$ is the set of observation that flows through the graph which should be different than $m^{t+1}$.\n\n2) Even MADDPG is very challenging to train! Now, this paper utilizes two MADDPG, and that is something that concerns me a lot. I don\'t think that replicating the results of this paper is possible by other people. How much was the cost of the hyper-parameters search? \n\n3) Why the decision of where to send the observations is modeled with a continuous control action? It can be simply modeled with discrete action in a more efficient way, right? What I mean is that $c_i$ can be a binary which tells whether send an observation or not. Am I missing anything?\n\n4) In section 2, you argue that in the original MADDPG paper, there is no inter-agent communication. As far as I remember, they have some experiments for cooperative communication or covert communication in which the communication is allowed between the agents. I would like to know more about this statement; maybe I am missing something. Why you are not designing the communication network which is a differentiable medium such as Foerster 2015? Isn\'t that efficient?\n\n5) In alternating case, I don\'t see (intuitively) why the communication should help to improve upon MADDPG. My intuition is that each agent will be the gifted one 1/3 on average. This means that the agents cannot perceive who gives the correct information and the policy should converge to a point where the communication does not give any new information.\n\n6) I would like to see what will happen with C=1? I think this hyper-parameter deserves some analysis to see how it affects the performance of the proposed method.\n\n7) In section 5, you say that in original DDPG, there is no real need for inter-agent communication"". This is a little bit strict statement, I guess. For example in the case with full observability, the agents can send messages which conveys their intention and help each other.\n\n\n\nMinor:\n* I would suggest using partially observability terminology instead of saying noisy observation because I think it includes a more general class of the problems to solve.\n* ""that a coupled through a communication medium"" -> ""that are coupled through a communication medium""\n* In section 4.2, it is unclear to me what is the exploration strategy. Please explain more.\n* section 5.2: Using the term lower bound is not accurate. Try changing it to something else or use with quotations: ""lower bound""\n* What will happen you choose the top-k rule for sending the information? For example, does top-2 (two-to-one) rule improve the results? The experiments might be added in future.\n-----------------------------------\npost rebuttal: the authors have responded to my main questions, and I would like to increase my score, but I cannot agree with them on possile future extensions of this work, e.g. in learning from pixels.', 'This paper studies multi-agent reinforcement learning where the agents need to communicate information when observations are noisy.  The agents thus need to learn what information should be sent to other agents.\n\nThe authors claim ""we do not assume the existence of explicit rewards guiding the communication action,"" which however is questionable.  The ""extrinsic reward"" used to guide the communication action is simply the cumulative reward between two communication actions.  The reward is explicitly given.\n\nThe key assumption is that communication is not performed every step.  Then standard cumulative reward until the next communication can be used as immediate reward for the previous communication.  Should this assumption be considered as an assumption of the domain where the proposed approach can be applied, or is this assumption rather a technique that one should use even when communication can be performed every step?  In the latter case, the effectiveness is sparse communication is not demonstrated.\n\nIn addition, the intrinsic reward for guiding environmental actions is unclear.  In the experiment, the standard reward is simply used as intrinsic reward.  So, intrinsic reward is just standard (extrinsic) reward?  In general, how should we design intrinsic reward?  What is the advantage of not using the standard reward as intrinsic reward?\n\nThe experimental settings are too ideal for the proposed approach, and it is unclear how the proposed approach work in practical settings.  In particular, sequential decision making is not essential in the experimental settings.  What are the real applications in mind?\n', 'This paper addresses the challenge of learning in extremely noisy environments. The fundamental idea is to combine deep reinforcement learning of individuals, in which individuals can choose whether they share information in order to maximise the overall reward, which is a substantial difference from existing solutions in the area. To achieve this, the authors propose a hierarchical approach in which agents learn from experience, before deciding whether to share information. \n\nTo explore the performance, the authors modify an existing scenario and implement baselines that represent idealised outcomes and contemporary approaches with varying levels of communication among agents. The proposed approach performs favourable compared to alternative approaches, despite its strongly decentralised operation, and is surprisingly close (and in some cases exceeds) the ideal solution with optimal communication. \n\nThe paper is well structured and systematic in the introduction of the underlying concepts in order to retrace the complex architectural setup. Experiment and alternative architectures are described in sufficient level of detail. \n\nThe quality of the presentation is high and accessible. Prospects for future work are highlighted. At this stage, observations are limited to a single observation at a time. The authors could be more explicit about potential further challenges in using the current solution and discuss its versatility in other scenarios. However, overall, the described hierarchical approach provides an interesting avenue to address the issue of noisy observations, which warrants discussion. ']","[-30, -30, 80]","[50, 20, 70]","[""The sentiment score is -30 because the reviewer expresses several concerns and is 'leaning toward weak reject', indicating a somewhat negative sentiment. However, they also mention positive aspects like the paper being 'clearly written' and explaining things in 'good detail', which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and offers constructive feedback. They maintain a professional tone without being overly formal or deferential. The reviewer also acknowledges the possibility of changing their evaluation based on the authors' feedback, which shows openness and fairness."", ""The sentiment score is -30 because the review expresses several concerns and criticisms about the paper, questioning key claims and assumptions. However, it's not entirely negative as it acknowledges the paper's focus and doesn't dismiss it outright. The politeness score is 20 because the reviewer uses neutral, professional language without personal attacks. They pose questions and raise concerns in a constructive manner, though they don't use overtly polite phrases. The reviewer maintains a respectful tone while critically examining the paper's content."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They highlight the paper's novel approach, favorable performance compared to alternatives, and its potential to address challenges in noisy environments. The reviewer also praises the paper's structure, systematic presentation, and high-quality accessibility. The score is not 100 as there are some minor suggestions for improvement.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths and provide constructive feedback without harsh criticism. The tone is supportive and encouraging, particularly when discussing the paper's contributions and potential. However, it's not 100 as it maintains a formal, objective tone rather than being overly deferential or complimentary.""]"
"['If the stated revisions are incorporated into the paper, it will be a substantially stronger version. I\'m leaning towards accepting the revised version -- all my concerns are addressed by the authors\' comments.\n---\nThe paper uses a Seq2Seq network to re-rank candidate items in an information retrieval task so as to account for inter-item dependencies in a weakly supervised manner. The gain from using such a re-ranker is demonstrated using synthetic experiments as well as a real-world experiment on live traffic to a recommender system.\n\nParagraph below eqn2: for *any* fixed permutation. Figure1 and notation indicates that, at each step of decoding, the selected input x_j is fed to the decoder. The text suggests the embedding of the input e_j is fed to the decoder (which is consistent with ""go"" being a d-dimensional vector, rather than the dimensionality of x).\n\nSingle step decoder with linear cost: Is there a missing footnote? If not, why call it p^1? Simpler notation to just call it p.\nEqn7: Role of baseline. In REINFORCE, b(x) is typically action-independent (e.g. approximating the state value function induced by the current policy). L_pi(theta) is action dependent (depends on the permutation sampled from P_theta). So, I\'m unclear about the correctness of Eqn7 (does it yield an unbiased policy gradient?)\n\nEqn5: Expected some discussion about the mismatch between training loss (per-step cross entropy) vs. testing loss (e.g. NDCG@k). Does a suitable choice of w_j allow us to recover standard listwise metrics (that capture interactions, e.g. ERR)?\n\nExpt implementation: Why was REINFORCE optimizing NDCG@10 not regularized?\nExpt cascade click model: Expected an even simpler experiment to begin with; [Is the Seq2Slate model expressive enough to capture listwise metrics?] Since the relevances are available, we can check if Seq2Slate trained to the relevance labels yields NDCG performance comparable to LambdaMART, and whether it can optimize metrics like ERR.\n\nTable1: On the test set, is NDCG&MAP being computed w.r.t the ground truth relevances? So, is the claim that Seq2Slate is more robust when clicks are noisy in a one-sided way (i.e. relevant items may not receive clicks)? Not clear how much of this benefit comes from a more expressive model to predict relevances (see suggested expt above) vs. Seq2Slate from clicks. NDCG & MAP definitely don\'t account for inter-item dependencies, so unclear what is being tested in this experiment.\n\nFor diverse-clicks, eta=0 while for similar-clicks, eta>0 (in a dataset dependent way). Why? Can expt numbers for the 3 choices of eta be added to the appendix? [Seems like cherry-picking otherwise]\n\nCan Ai et al, 2018 be benchmarked on the current expt setup? Is it identical to the single-step decoder proposed in the paper?\n\nComment: Would be more accurate to call seq2slate a re-ranker throughout the text (in the abstract and intro, the claim is seq2slate is a ranker).\n\nExpected to see training time and inference time numbers. Since Seq2Slate does extra computation on top of, e.g. LambdaMART, it is useful to know how scalable it can be during training, and when the extra perf is worth the O(n^2) or O(n) [for single-step decoding] during inference.\n\nGeneral comments:\nClarity: The paper is well written and easy to follow. There are a few notation choices that can be improved/clarified.\nOriginality: This work seems closely related to Ai et al, SIGIR 2018. Going from a single-shot decoding to sequential decoding is an incremental step; the real-world experiment seemed the most novel and compelling contribution (however, it is unclear how one can reproduce it).\nSignificance: The paper addresses a significant real-world problem. Many high-impact applications of ranking rely on being able to model inter-dependencies well.\nQuality: The paper has interesting contributions, but can be substantially stronger (see some of the specific comments above). For instance, A careful study of the computational vs. performance trade-off, fine-grained comparison of different decoding architectures, better understanding of which architectural choices allow us to model any arbitrary ranking metric more effectively vs. which ones are more robust to click noise vs. which ones capture inter-item dependencies.\n', 'The authors consider the problem of re-ranking an initial ranker that doesn’t consider interactions between items (e.g., a point-wise ranker) with a pointer-network approach that considers these interactions when re-ordering the input ranking. Notably, this is performed during decoding as opposed to {pairwise, list-wise} learning to rank approaches that consider interactions during training, but emit an item-wise score during inference. Operationally in practice, this has to be trained from click-through data for which the authors consider both a RL approach (Reinforce) and supervised training (a sequence-level hinge loss function) and decoded either with a single-step greedy policy or a sampling procedure. Experiments are conducted on learning-to-rank benchmarks where interactions are introduced to test the validity of the method and on a real-world, large-scale recommendation engine — showing solid improvements in both cases.\n\nFrom a high-level perspective, the methodological innovation (a pointer-network trained on sequence loss from logged data), setting (re-ranking a slate to consider interactions), and empirical analyses are largely ‘incremental’ — although I think non-trivial to put together and the paper itself is well-written and fairly convincing. In framing the paper this way, I would have expected some comparison to sub-modular methods on the ‘diverse-clicks’ generated data for completeness, although I would be surprised if the Seq2Slate method doesn’t perform better (but all the more reason to conduct). In addition to reporting how to resolve some of the details of applying this, the most interesting results may very well be the real-world experiments as the result improvements are fairly impressive (such that I intend to play with this myself). Thus, as the focus is on details and empirical results over methodological innovation, this paper reads a bit like an industry-track paper — but I find the results interesting overall and am marginally inclined to accept.\n\nEvaluating the paper along the requested dimensions:\n\n= Quality: The paper clearly states its motivation, proposes a model, discusses practical issues, and provides convincing experiments (given the constraints of proprietary data, etc.). I didn’t observe any technical flaws and everything was relatively self-contained and easy to read. I could think of a few more experiments regarding submodular-based models, possibly different settings of the ‘diverse-click’ data for a sensitivity analysis, and a more direct comparison to [Ai, et al., SIGIR18], but this isn’t required to make the results sufficiently convincing. (6/10)\n\n= Clarity: The paper is very clearly written. (7/10)\n\n= Originality: This is the weakest aspect of the paper from a methodological perspective. It is a fairly straightforward application of pointer-networks. Even the path forward is fairly straightforward as outlined in the conclusion. One additional pointer that is methodologically similar, but for ‘discrete choice’ as opposed to re-ranking is [Mottini & Acuna-Agost, Deep Choice Model Using Pointer Networks for Airline Itinerary Prediction; KDD17] (which honestly, is probably a better venue for this specific work). Non-trivial and complete, but not particularly innovative. (5/10)\n\n= Significance: Methodologically, probably will influence some work regarding re-ranking methodologically. From a practical perspective, seems very promising. A few more experiments would make this case stronger, but has real-world data. (6/10)\n\n=== Pros ===\n+ extends a widely used model (pointer-networks) to the re-ranking setting\n+ discusses practical issues in getting this to work at scale\n+ shows that it works in a real-world setting \n+ contextualization within existing research shows good understanding of related work\n\n=== Cons ===\n- is a fairly direct application of pointer-networks with the innovation being in the details (i.e., is more of an ‘industry’ paper)\n- additional experiments around ‘diverse-clicks’ settings (to see how smooth the performance curve) and submodular comparisons may have been interesting\n\nIn summary, I think there is room for improvement (some outlined in the conclusion), but is an interesting finding with promise that I plan to try myself. Thus, I lean toward an accept. ', 'This paper formulates the re-ranking problem as a sequence generation task and tackles it with the pointer-network architecture. The paper formulates the problem clearly. The proposed model is trained on click-through log and outputs a ranking list of candidate items. The authors discuss two different potential approaches to train the model and conduct synthetic experiments as well as a real-world live experiment. The model also ran in a live experiment (A/B testing).  \n\nSome issues I concern about:\n\nIn Equation 7,  why do the authors introduce the baseline function into supervised learning?  I guess this is due to the advantage function in REINFORCE. But the authors should state the reason and correctness of this derivation.\n  \nIn Section 4, implementation details part:\n“R=NDGC@10” should be “R=NDCG@10”, (and maybe the authors could give a citation for each metric).\n“baseline b(x) in Eq(3) and Eq(6)” should be “baseline b(x) in Eq(3) and Eq(7)”, and why do the authors use the same baseline function for REINFORCE and supervised learning?  \nCan the author specify why Seq2Slate with REINFORCE is not regularized while all other models are trained with L2- regularization?\n\nIn Section 4.1,  I think the authors can give a direct comparison between their models and [Ai, et al., SIGIR18]. Compared with [Ai, et al., SIGIR18], where the authors use more metrics (i.e. Expected Reciprocal Rank), there are fewer metrics used in this paper. Especially, I want to see the performance of Seq2Slate with REINFORCE (reward as NDCG) on other metrics.  \n\n \nIn Section 4.2:\nWhy the authors do not conduct real-world data experiments on Seq2Slate with REINFORCE? I am wondering whether the time complexity of REINFORCE is too high for experiments on large scale datasets.  \n[Important] The authors stated that their model is sensitive to input order. However, it seems that they do not specify the input order of training sequences in Section 4.1. Is the order fixed? And in my opinion, the robustness of the model can be improved by shuffling the input sequence during the training stage, just like data augmentation in computer vision. I suggest the authors conduct the extended experiments.  \n\nGeneral comments:\n\nQuality (6/10): The paper uses the Seq2Seq architecture for the learning-to-ranking task, which is self-contained and has no obvious flaws. Experiments could be more perfect, especially, the author can add more metrics. The authors also give a comparison of their proposed training variants along with a detailed analysis of how their models can adapt to different types of data. In addition, a live experiment (A/B testing) is conducted.\n\n  \nClarity (6/10): The paper is well written in general, some typos shall be fixed.\n\nSignificance (6/10): The authors validated their model on both synthetic data (based on two learning to rank benchmark datasets) and real-world data. I think the authors can use more metrics besides MAP and NDCG.\n  \nOriginality (5/10): The paper can be regarded as an adaption of the Seq2Seq framework with pointer networks on learning-to-rank tasks. Although the authors give an analysis on why the traditional training approach (teacher forcing) cannot be applied to their tasks and give two alternative approaches, this paper stills seems to a direct application with minor innovation on training approaches and loss functions.\n  \nIn summary, I think this is a good paper addressing the (re)ranking problem with pointer networks, but it is more suitable for conferences focusing on application and industry like SIGIR or KDD instead of the deep learning conference ICLR.']","[50, 60, 20]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by stating that if revisions are incorporated, the paper will be 'substantially stronger' and they are 'leaning towards accepting the revised version'. This indicates a generally positive outlook, but not overwhelmingly so. The rest of the review provides a mix of positive comments and constructive criticism, maintaining a balanced tone. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering suggestions and asking questions rather than making demands. They acknowledge the paper's strengths ('well written', 'easy to follow', 'interesting contributions') while providing detailed, constructive feedback. The reviewer also uses phrases like 'Expected to see' and 'Can ... be added' which are polite ways of suggesting improvements without being forceful."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses a generally favorable view of the paper, stating they are 'marginally inclined to accept' and find the results 'interesting overall'. They highlight several positive aspects like clear writing, convincing experiments, and promising real-world results. However, they also note some weaknesses, particularly in originality, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful and constructive tone. They offer balanced feedback, acknowledging both strengths and areas for improvement without using harsh language. The reviewer also demonstrates engagement with the work by mentioning their intention to try the method themselves, which adds a collegial tone to the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear formulation, experimental design, and real-world testing. However, they also raise several concerns and suggest improvements, indicating a mixed but generally positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and provides a balanced assessment of the paper's strengths and weaknesses. The reviewer also uses polite phrases like 'I think' and 'I suggest' when offering opinions or recommendations, contributing to the overall courteous tone of the review.""]"
"['The problem addressed in this paper is worth the attention of the community. Not so much for it being of strong interest to the majority of ICLR attendees, but due to the fact that it deals with data of origin (finance) and properties (high-order Markov chain dependencies) that have never been considered in the past.\n\nHowever, apart from this merit, the paper as is stands now suffers from major prohibitive shortcomings. Specifically, the authors have failed to provide a detailed account of the novel network architecture introduced in this paper. Their description is too vague, and misses crucial details. For instance, they use a convolutional structure (layer?) at some point. How is this configured? Why do they need a convolutional layer, since they present it with a vector output from a preceding dense layer? What about the CDA network (both its configuration and its training procedure)? These are crucial aspects that the authors have failed to describe at all.\n\nIn the same vein, technical details concerning the selection of the training algorithm hyper-parameters are also missing from the experimental section. Although not as glaring an omission as the previously described ones, these are also crucial for the replicability of the presented research results. \n\nFinally, the authors have failed to provide comparisons to alternative baselines. For instance, why not train a simple LSTM and use to generate new samples. Why not use a recurrent variational autoencoder? Eventually, since the time-series we are dealing with are governed by a high-order Markov chain, we not fit and sample from a high-order hidden Markov model? These are crucial questions that must be adequately addressed by the authors. ', 'The objective of this paper is to use GAN for generating the order stream of stock market data.   The novelty of the paper is the formulation of the order stream and the use of GAN for generating the stock data.   This is a paper for the application of GAN and there are limited contribution to the technical aspect of machine learning.    The paper is clearly written.   There are two main assumptions used in the paper; one is the Markov chain and the second one is the stationary distribution.   In real case, both assumptions are unlikely  to be satisfied.  The orders are mostly affected by many external factors and financial data are known to be non-stationary.  The authors may have to justify these assumptions. \n\nAnother issue is the evaluation of the results.  The paper uses five statistics to evaluate the generated data.  What we can conclude is that the generated data follow similar statistics with the real data.   But we do not know if the generated data offer extra information about the market.  The paper has used synthetic data in the experiments.  So it means that we could have models that generate data that look like real data.  If so, what are the benefits of using GAN to generate the data ?  \n\n', 'This paper proposes a Generative Adversarial Network (GAN) methodology to learn the distribution of limit orders that arrive on an equity market. The proposed approach captures the (mostly discrete) structure in the generated orders; modeling is carried out with a conditional Wasserstein-GAN with a recurrent neural networks in both the generator and critic used to capture the time dependency, and convolutional layers to capture other conditioning information. Experiments are provided on both synthetic and real data.\n\nOverall, the paper is well written and easy to follow. The application of WGAN to modeling financial market microstructure is novel and appropriate: microstructure is probably one of the areas of finance where generative models can be trained with ample data, and overfitting risks can therefore be controlled to some extent. In this respect, the paper brings a valuable contribution, both to finance by proposing a direct generative model of a complex process, and to machine learning by showing a useful application of GANs outside of the traditional domains.\n\nMy main reservation with the paper is that the experimental results could be more convincing. In particular, results for real data are shown for only two stocks, representing respectively 20k and 230k orders. Although the trained model captures some aspects of the distribution (e.g. inter-arrival times), it misses others, such as important aspects of the (univariate) price distribution, as well as the best bid-ask dynamics. As they stand, the results appear mostly anecdotal, and lack either a breadth or depth of analysis. It would be sensible for the authors to:\n\n1. Compare their models to other limit-order book simulation models proposed in the financial econometrics literature;\n2. Characterize the sensitivity of the learned distribution on the architecture hyperparameters.\n\nFor these reasons, it appears difficult to recommend acceptance of the paper in its current state.']","[-50, -20, -30]","[20, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges the problem's worth and novelty, they express major concerns about the paper's shortcomings. The review starts positively but quickly shifts to highlighting significant issues, using phrases like 'major prohibitive shortcomings' and 'failed to provide.' The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'worth the attention' and 'crucial aspects,' while avoiding harsh language. However, the repeated use of 'failed' and the direct criticism slightly lowers the politeness score. The reviewer provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'novelty'), they raise significant concerns about the paper's assumptions and the value of the results. The reviewer questions the validity of the main assumptions and the practical benefits of the approach, which outweigh the positive comments. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They offer constructive criticism without harsh or dismissive language, and phrase their concerns as suggestions ('The authors may have to justify these assumptions') rather than direct criticisms. The review maintains a respectful tone while still clearly communicating the perceived weaknesses of the paper."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's novelty and valuable contribution, they express significant reservations about the experimental results and conclude that it's difficult to recommend acceptance in its current state. This indicates a slightly negative overall sentiment. The politeness score is 60 because the reviewer uses respectful and constructive language throughout, acknowledging the paper's strengths before presenting criticisms, and offering specific suggestions for improvement. The tone is professional and courteous, avoiding harsh or dismissive language even when expressing concerns.""]"
"['The work releases a large-scale multimodal dataset recorded from the X-Plane simulation, as a benchmark dataset to compare various representation learning algorithms for reinforcement learning. The authors also proposed an evaluation framework based on some simple supervised learning tasks and disentanglement scores. The authors then implemented and compared several representation learning algorithms using this dataset and evaluation framework. \n\npros:\n1.  Releasing this dataset as a benchmark for comparing representation learning algorithms can potentially impact the community greatly;\n2. The authors combined several existing work on measuring representation learning algorithms and proposed an evaluation framework to evaluate the quality of learned representation using supervised learning tasks and disentanglement scores;\n3. The authors implemented an extended list of representation learning algorithms and compared them on the dataset;\n\ncons:\n1. the paper lacks clarification and guideline to convince the readers of the usefulness of the dataset and the evaluation framework. The authors spent almost half of the space explaining different existing representation learning algorithms. A more convincing story would be to find a few well-established representation learning algorithms to corroborate on the reliability of the dataset and the evaluation metrics;\n2. More details should be put into describing the dataset. It is not clear why this dataset is particularly suited for evaluating representation learning in the context of reinforcement learning. Do the authors have insight on the difficulty of the task? While having multi-modality is appreciated, it might worth thinking a separate dataset focusing on a single modality, e.g., image;\n3.  Given that the authors designed the dataset for evaluating representation learning for reinforcement learning, it is worth evaluating these algorithms on solving the main task using some standard RL techniques on top of the learned representations.\n4. Table 4 is difficult to parse. ', 'The paper looks into contribution of data set for multi-modal learning using X-Flight simulator in various settings. The authors also contribute code for evaluation of the learning representation tasks and present the results for the data using various setups from autoencoders to dynamics model, using sensor only data and combining image and sensor data, and predicting various timesteps.\n\nImprovements\nMultimodal datasets have been made available previously in Image, video, text combinations, where the outcome was clear (for e.g learning caption etc.), however, in this dataset, the task is more challenging (for e.g predicting the various sensor readings or landing outcome). The paper would benefit from \n- adding clarification on the Learning tasks, as some of the descriptions/settings and result discussion need more explanation. An e.g predicting the timesteps ahead can be meaning different things, depending on when the start time is, sampling rate and the time to land. \n- measure of the scale where only MSE is mentioned for the tasks in the results\n- why the time with lower latent dimensions was same as with higher\n- the explanation for some of the measure being out of whack for some settings is attributed to challenges with the data set and e.g. is provided for images with nighttime landing. A quantitative number around such cases/for the e.g. in the training data, and test data would be good\n', 'Overview and contributions:\nThe authors present a newly collected dataset and evaluation framework for learning representations for landing an airplane. The dataset is collected from the X-Plane simulation environment and consists of 8011 landings, each landing consists of time series data from 1090 sensors. Their evaluation metric is a combination of disentanglement score, regression tasks, and failure classification. The authors test a combination of baseline models from basic autoencoders to dynamic actions-aware encoders. The writing is generally clear but I have doubts about the proposed evaluation metrics, experiments, and significance of the dataset (details below).\n\nStrengths:\n1. The task seems to be novel and complex. The authors have done a good job of collecting the dataset and ensuring that the data is clean and comprehensive.\n2. The authors have performed a comprehensive job of evaluating the combinations of baseline models for their proposed task.\n\nWeaknesses:\n1. Table 4 on evaluation results, while comprehensive, lacks some explanation. The issue with MSE is that it is hard to interpret what these values mean. Specifically, how difficult is this task? How well can a human perform on this task? How well are the baselines doing relative to human-level performance, and is there room for improvement? The answers to these questions are important towards whether this new dataset will be a strong benchmark for representation learning.\n2. There is less novelty in terms of the models presented for evaluation since they are composed of existing models. What are some state-of-the-art models for similar tasks, and do they constitute fair comparison?\n\nQuestions to authors:\n1. Refer to weakness points 1 and 2.\n2. What biases do you think might exist in the dataset during the collection process? How might these biases affect what the models learn, and how can they be mitigated?\n3. How do you ensure that all sensors are active at all times and that all sensors provide useful information for predicting the label? Are there cases where the multisensor data is noisy in certain modalities or missing in other modalities? If so, what are some models that can remain robustness to noisy or missing modalities?\n4. Why do you think disentangled representations will help? Sure, they have been generally shown to help learn more interpretable representations, and help in flexible generation from disentangled factors. But in terms of discriminative or generative performance on your newly proposed dataset, does learning disentangled representations help? What are some models that can learn effectively learn such disentangled representations?\n\nPresentation improvements, typos, edits, style, missing references:\nSection 3, line 7, \'with with a frequency\' -> \'with\'\nI would suggest referring to some recent work on multimodal temporal fusion, such as ""Memory Fusion Network for Multi-view Sequential Learning. Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik Cambria, Louis-Philippe Morency, AAAI 2018""\n\n']","[20, 50, -20]","[50, 75, 60]","['The sentiment score is slightly positive (20) because the review starts with acknowledging the potential impact of the work and lists several pros. However, it also includes a substantial list of cons, which balances out the positive aspects. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both pros and cons in a professional manner without using harsh or overly critical language. The reviewer offers constructive feedback and suggestions for improvement rather than outright criticism.', ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and the challenging nature of the task, while also providing constructive feedback for improvements. The review starts with a neutral summary of the paper's content and then moves on to suggest improvements, indicating a balanced perspective. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing suggestions as ways the paper would 'benefit from' certain additions rather than criticizing what's missing. The reviewer also acknowledges the challenges of the task and provides specific, constructive feedback without using harsh or negative language. The use of phrases like 'The paper would benefit from' and 'would be good' contribute to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express significant doubts about the evaluation metrics, experiments, and significance of the dataset. The review points out more weaknesses than strengths and raises several critical questions. However, it's not entirely negative as the reviewer recognizes the novelty of the task and the comprehensive nature of the dataset collection and model evaluation. The politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They frame criticisms as 'weaknesses' and 'questions' rather than direct attacks, and use phrases like 'I would suggest' for improvements. The reviewer also acknowledges the authors' efforts in certain areas, which contributes to the polite tone.""]"
"[""Summary\nThis paper proposes label propagation network (LPN), a neural network to learn label prediction and similarity measure (weights) between data points simultaneously in semi-supervised setting. The proposed method simulates label propagation steps with the forward pass of LPN, enabling backpropagation through label propagation steps.\n\nStrong points\n- Learning both weights and label predictions in SSL seems to be novel (provided that the author's claim in the related work section is right).\n- Good performance.\n- The paper is generally well written.\n\nConcerns\n- Replacing the label propagation by forward pass of a neural network is an attractive idea, but because of that the convergence guarantee is lost.  As Figure 4 shows, LPN without bifurcation mechanism seems to suffer from convergence issue as the number of evaluation step grows. I guess that the algorithm may go wrong even with bifurcation mechanism for some data, for example if the bifurcation rate grows too fast/slow.\n- The original label propagation works with weights without entropy. Does introducing entropy term (e(h_i;theta)) is always helpful? For instance, if some data points erroneously get certain during initial iterations, the whole algorithm may fail.\n- The performance reported for GCN is quite different from what is presented in the GCN paper, and authors explain that this is due to the different experimental setting. For me the performance gap is quite significant to be originated from different experimental setting. Could you elaborate on this? Also, how many GCN layers were used?\n- Too many hyperparameters to tune.\n\nMinor points\n- I think the line above Eq (4) should be like \\tilde w_ij = w_ij / sum_k w_ik.\n- Eq (10) is quite misleading. The original weight w_ij should be symmetric (w_ij = w_ji), but this is not. Also, considering the intuition behind the label propagation, I think Eq (10) should be like alpha_ij(h_i, h_j) = exp(e(h_j) + d(h_i, h_j)), not e(h_i) as written the paper.\n- In the experiments setting, the authors calling their algorithm as DeepLP_alpha and DeepLP_phi. I guess these should be LPN_alpha and LPN_phi.\n"", '**** After Revision ***********\nI thank the authors for diligently revising the paper according to the reviewers\' suggestions. I have increased my score for the paper. I still think the experimental evaluation can be more thorough. For example, it would be good to show the effect of varying the \\tau parameter and the number of available labels (k). It would also be good to experiment with the Flickr graph without any sparsification and to add uncertainty estimates to the results in Table 1. \n**** After Revision ***********\n\nThis paper proposes a framework for non-linear label propagation where the weights are learned simultaneously. There are model specific and experimental setup design decisions that require justification. There also needs to be a number of ablation studies to justify the effectiveness of the different components of this framework.  Finally, there seems to be an insufficient comparison (both experimentally and theoretically) to the large amount of related literature. \n- What is the total number of parameters in the proposed network? Please clarify how this is ""relatively few parameters"" as compared to other methods. \n- Please compare how your method for learning weights relates to the following papers and the references therein [1,2]\n[1] Online Learning of Multiple Tasks and Their Relationships. Saha et al, AISTATS, 2011. \n[2] Convex Learning of Multiple Tasks and their Structure, Cilberto et al, 2015. \n- It would be good to have an ablation study in order to discern what is the contribution of learning the weights vs propagating labels (instead of embeddings). \n- For clarity, please specify that \\theta are the parameters to be learned. \n- Please explain the intuition of using entropy and KL divergence for the attention weights. Shouldn\'t the attention for an edge be inversely proportional to the entropy i.e. the attention should be higher if the neighboring node\'s label is more certain?\n- Instead of the bifurcation mechanism proposed in section 3.2, isn\'t it possible to use a threshold to round the resulting prediction to a hard label?\n- In equation 13, are the hyper-parameters a, b tuned using cross-validation? Can\'t we learn the \\tau in the same training procedure? Please justify this design decision?\n- What is the performance if the loss in equation 14 is replaced by the standard empirical loss? There needs to be an ablation study on this. \n- If the node features are available, how are they used in this framework?\n- In the experimental section, why is k chosen to be equal to 1%? Please show results while varying this. \n- Please justify the line ""parameterizes w using a small number (~20) of informative features based on the raw features (e.g., dimensionality reduction), the graph (e.g., edge betweenness), and the labeled set (e.g., distance from labeled nodes). "" Isn\'t it possible to get similar performance by reducing the number of parameters so that model doesn\'t overfit?\n- Please clearly state what is the difference in the framework from the Kipf and Welling, 2016 paper?\n- Why isn\'t there a comparison to methods like Graph-Sage?\n- Please explain this line ""LPNnobif degrades with large T, and even \\tau slightly above 1 makes a difference""\n- Finally, please explain the trend in the results in Table 1. For example, why is the performance of the proposed method poor on the Flickr dataset, but better on the DBLP dataset?\n- It would good to have uncertainty estimates for the results reported in Table 1. ', ""This paper presents an interesting idea for the following task: given a graph and a subset of labelled nodes, infer the labels on the remaining nodes. Here the authors will make prediction for absent labels based on local averages on the graph of the neighbouring soft labels. The main originality is that the local average is weighted and the weights are learnt. \n\nI had trouble understanding the details of the algorithm and the authors should be more careful in their description of the algorithm. Some points to clarify:\n- section 3.1, I am not sure to understand the 'dynamic weights'. The main point here seems to be the use of an attention mechanism (which does not vary in time) applied to inputs varying in time?\n- section 3.2, I do not understand equation (13). What is \\theta^\\tau, it does not appear in the right-hand term?\n\nI think that using the term time is misleading. Time might refer to epochs in an optimization process, whereas time in Section 3 seems to refer to a number of layers as described in equation (6).\n\nPlease, be more explicit on the use of raw features. How are the similarities described in appendix B incorporated in the loss?\n\nOverall, I think this paper requires a lot of clarification before being published.""]","[20, -20, -50]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because the review starts with acknowledging the paper's novelty, good performance, and well-written nature. However, it also raises several concerns, which balance out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging strengths before presenting concerns, and phrases criticisms as questions or suggestions rather than direct attacks. The reviewer also uses phrases like 'I think' and 'Could you elaborate on this?', which maintain a polite tone. The concerns are presented objectively without harsh language, contributing to the overall politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' efforts to revise the paper ('I thank the authors for diligently revising the paper'), they still express concerns about the experimental evaluation and request further improvements. The reviewer states 'I still think the experimental evaluation can be more thorough' and provides several suggestions for additional experiments and analyses. This indicates that the reviewer is not fully satisfied with the current state of the paper, despite some improvements.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin with a polite acknowledgment of the authors' efforts and use phrases like 'it would be good to' and 'please' when making suggestions. The reviewer maintains a constructive tone, offering specific recommendations for improvement rather than harsh criticism. However, the score is not higher because the review is primarily focused on pointing out areas for improvement rather than offering praise, which is typical for academic peer reviews but doesn't reach the highest levels of politeness."", ""The sentiment score is -50 because while the reviewer acknowledges the paper presents an 'interesting idea', they express significant concerns about the clarity of the algorithm description and state that 'this paper requires a lot of clarification before being published'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 20 because the reviewer uses polite language such as 'please' and frames criticisms as requests for clarification rather than direct attacks. However, the overall tone is more neutral than overtly polite, hence the moderate positive score. The reviewer maintains a professional tone throughout, balancing critique with acknowledgment of the paper's potential merits.""]"
"['This paper presents a multiview framework for sentence representation in NLP tasks. Authors propose two architectures, one using a generative objective, while the other uses a discriminative objective. Both combine a recurrent based encoding function and a linear model. Large experiments have been conducted on several NLP tasks and datasets, showing improvement of the introduced frameworks compared to baselines.\n\nThe paper is globally well written and has a clear presentation. But I\'m not sure to understand why authors motivate their work on the asymmetric information processing in the two hemispheres of the human brain. It sounds like a nice motivation, but the work presented here does not show any clear answer for this, except the idea of combining two different encoders for sentence representation..\n\nMy main concern is about the term multiview since the merging step is somewhat trivial (min/max/averaging vectors or concatenation). This is far from significant works on multiview learning, see: ""Multi-view learning overview: Recent progress and new challenges"".\n\nTable 3, where G and D refer respectively to Generative and Discriminative models. But what differences between G1, G2, G3 ; D1, D2, D3 ?\n\nInvertible constraint is a nice idea for using inverse of the decoder as the encoder. Is it really to take advantages of decoder information on the encoder/representation part? Or also to reduce the amount of parameters learnt in the model? Moreover, it is unclear on the ablation study: did you consider the original encoder ; or still the inverse of decoder but without the constraint? Unfortunately, it seems to not give significant gain, according to ablation study in table 6.\n\nIn this current form, I feel this paper does not give sufficient novelty to be accepted at ICLR.', 'After reading through the authors\' comments and rereading parts of the submission, I have become a little more positive about this paper. \n\nI am still unsure about the contributions to the ICLR community. The authors merely state ""We believe our contributions to ICLR community are clear and valuable"" without backing up this claim with an argument. \n\nBut in the rest of the authors\' comment, they make some good points. I think those points should be made more prominently in the paper itself. I would suggest that the authors describe their approach as using different, complementary encoders of the input sentence and consensus maximization. If they wish to describe this as multi-view learning, that\'s fine, but I think using the term ""consensus maximization"" (or something more descriptive like that) in prominent places would be helpful. \n\nIf the approach is applicable beyond sentence embedding learning, then it would behoove the authors to describe the approach in a general way so that readers will see how they can apply it to their own tasks. As currently written, the paper is very much focused on sentence embedding learning, which causes me to think that the paper is more appropriate for an NLP venue. But it is true that ICLR publishes papers that are application-specific, so I can\'t consider this to be a deal-breaker for the paper.\n\nI raised my score to a 6.\n\n--------------------------------- original review follows: ----------------------------------\n\nThis paper describes experiments in learning sentence embeddings from unlabeled text. The paper compares a few different compositional architectures and training objectives. The story of the paper focuses on the training of multiple architectures jointly for a single sentence, then ensembling those architectures at test time to represent sentences. One architecture is an RNN and the other is a word averaging model, and the idea is that these two architectures capture different ""views"" of the sentence. \n\nPros:\n\nAs a general-purpose method to get sentence embeddings without using any resources other than unannotated text documents, this approach has strong results, including solid performance on the SentEval tasks and relatively-low training times. \n\nIt was also nice to see how the results depend on the domain of the training data. Review data definitely helps on the several sentiment-related tasks, which provides further evidence of a worrisome aspect of SentEval. \n\nCons:\n\nOverall, the paper feels incremental and is likely a better fit for an NLP conference. What are the generalizable contributions to the ICLR community? Given the known differences between RNNs and word averaging models for sentences (especially on the SentEval tasks, which, as the authors note, was discussed by Hill et al.), it\'s entirely unsurprising that combining the two would be a good idea. But even if this were not the case, the ubiquity of ensembles outperforming single models in deep learning also makes it unsurprising that combining these two kinds of model architectures would be beneficial. So I\'m just not sure if there is a significant contribution beyond the NLP results. These results seem solid (though a bit incremental), but if the primary contribution is empirical, then the paper would be a better fit for an NLP venue. \n\nIn addition, I\'m not sure if ""multi-view"" is an appropriate description of the approach. In Sec. 1, we find the sentence ""Compared to earlier work on multi-view learning (de Sa, 1993; Dhillon et al., 2011) that takes data from various sources or splits data into disjoint populations, our framework processes the exact same input data in two distinctive ways.""  Therefore, maybe it\'s not quite accurate to describe this approach using the term ""multi-view learning""? I think it would make more sense to use a different term rather than stretch the definition for a well-known one. \n\nI kept expecting the paper to present results when combining the generative and discriminative objectives, but as far as I can tell, this was never done. What would happen if one were to use multitask learning and just optimize the sum of the two losses? \n\nI\'d suggest citing and comparing to the results from ""Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning"" by Subramanian et al. (ICLR 2018) and the Byte mLSTM from ""Learning to generate reviews and discovering sentiment"" by Radford et al. \n\nI\'m not sure how excited we should get about not using any annotations or structured resources for learning sentence embeddings. The authors do not motivate this goal. \n\n\nBelow are more specific comments/questions:\n\nSec. 2.2 contains the sentence ""Ideally, the inverse of h should be easy to compute so that during testing we can set g = h^-1."" At this point in the paper, it is not clear what g is going to be applied to at test time, since presumably the following sentence is not going to be available at test time, right? I think it would be good to discuss how the model is going to be used at test time before discussing the inverse of h. \n\nSec. 2.3: \nIn Eq. (3), why does the denominator sum always start at 1 no matter what i and j are? That is, why would the denominator always sum over the first N sentences in the dataset?\n\nI think the pooling methods in Table 2 should be described in Section 2. \n\nIn Table 2, it is not clear what h_i^{M_i} is. If M_i is the number of words in sentence i, that should be mentioned somewhere. \n\nSec. 3.1:\n""For a given sentence input s with M words, suggested by (Pennington et al., 2014; Levy et al., 2015), the representation is calculated as z = (\\hat{z}_f + \\hat{z}_g) / 2, where \\hat{z} refers to the post-processed and normalised vector, and is mentioned in Table 2.""  I don\'t understand. Where is this mentioned in Table 2?\n\n\nMinor issues follow:\n\nSec. 1:\n""Distributional hypothesis"" --> ""the distributional hypothesis""\n""in machine learning community"" --> ""in the machine learning community""\n""and distributional hypothesis"" --> ""and the distributional hypothesis""\n""the linear/log-linear models"" --> ""linear/log-linear models""\n""based on distributional hypothesis"" --> ""based on the distributional hypothesis""\n""contraint"" --> ""constraint""\n\nSec. 2:\n""marry RNN-based sentence encoder"" --> ""marry RNN-based sentence encoders"" or ""marry the RNN-based sentence encoder""\n\nSec. 2.1:\n""only hidden state"" --> ""only the hidden state""\n\nSec. 2.2:\n""prior work with generative objective"" --> ""prior work with generative objectives""\n\nSec. 2.3:\n""with discriminative objective learns"" --> ""with the discriminative objective learns""\n\nSec. 3.1:\nIn Table 3, I don\'t see where superscript 5 is shown in the table.\n\nSec. 3.2:\nIn Table 5, the numbered superscripts at the top of the table do not show up next to the methods in the actual table rows. \n', ""This paper is about a multi-view framework for learning sentence representations. Two objective functions (a generative one and a discriminative one) are proposed that make use of two encoders, one of them is based on an RNN and the other on a linear projection of averaged word embeddings. Each of these objective functions has a multi-view framework where their respective objective functions are in part based on making sure their is some relationship between the two different encoders. This multi-view framework is shown to be helpful over having independent encoders in their ablation study.\n\nThe authors evaluate on the SentEval benchmark (a collection of tasks where a shallow neural network is learned and the sentence embeddings are kept fixed) and a collection of STS tasks (where the cosine between two vectors is used to estimate their semantic similarity).\n\nThe results are impressive. A closer examination of them though leaves me with some questions and thoughts.\n\nRegarding the SentEval numbers, I would like to know the dimensionality of your models in Table 5. I am somewhat unclear of how the final embeddings were produced, it seems that you concatenate mean, max, min, and last_h from the RNN encoder and then mean, max, min from the projection encoder. Is that correct? That would make your feature vector 7*1024 dimensions, which is a bit bigger than most of what you compare to (some of these methods are 4096 dims). With this type of evaluations, larger feature vectors do help performance, thought I am certain that you would have nice performance even if your dimension was reduced (this is from looking at the ablation). I think making the dimensions more explicit and clarifying in the text how the final feature vector was created would be helpful for readers.\n\nAnother thing to consider in the evaluation, is that a paper recently pointed out that max pooling in a certain way in SentEval can artificially inflate results for some of these datasets. I noticed that max-pooling is used in your experiments. This paper also shows how big of an effect larger feature vectors have on performance: https://openreview.net/forum?id=BkgPajAcY7. I'd like to know if your results are affected by this max-pooling operation as is the case for several well-known papers in this area.\n\nI also noticed that a lot of the best SentEval numbers came from using the book review dataset. This makes a lot of sense in that a lot of these are based on sentiment and is something that was in part used by (Radford et al. 2017) to obtain strong performance on these tasks. A similar thing happens with the STS data and the news domain as noted in this paper.\n\nI noticed you did the principal component removal trick for InferSent, but it did not have a large effect on performance. How big of an effect did if have with your methods? I'm glad you included it in InferSent, but I'd like to see this as well in the ablation.\n\nOverall I do think this paper has value for the community. It shows how strong results can be obtained using just raw text and using less parameters and training faster than other recent approaches. I do think a lot of the gains here are due to clever design choices in their experiment (for instance using different types of raw data which help more on certain tasks, removing the first principal component, etc.) but putting everything together to get very competitive results with across all these tasks with an interesting approach and an accompanying analysis is a nice contribution.\n\nMinor comment: The paper was tough to understand in parts due to symbols/abbreviations not being defined or motivated clearly. It'd be nice if the authors could define the symbols/abbreviations that are in the tables in the captions. An example of this would be WR in Table 4. The left-most column in Table 6 could also be clearer (I know it is in the text, but I was confused about what f1 and f2 represent etc. in my first pass). This also occurs in the text as well like when g is introduced in Section 2.2.\n\nPROS:\n- Interesting and novel model combining RNNs and word-averaging\n- I find the multiview framework to be a nice contribution, having the models tied in this way also improves performance.\n- Model is fast to train and requires only raw text\n- Competitive results with SOA on many datasets - both those requiring a trained classifier using the fixed embedding and STS tasks.\n\nCONS\n- Some of their gains are due to choice of dataset for training or removing the first principal component - advantages that other comparable models may or may not have. Not really a con though, more of an observation. I would like to see an ablation to see the effect of removing the first principal component.\n\n""]","[-50, 20, 60]","[50, 60, 80]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('globally well written', 'clear presentation', 'nice idea'), they express significant concerns and ultimately conclude that the paper lacks sufficient novelty for acceptance. This indicates a generally negative sentiment, though not extremely harsh. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives and framing criticisms as questions or personal opinions ('I'm not sure', 'My main concern', 'I feel'). They avoid harsh or accusatory language, maintaining a professional and constructive tone even while expressing doubts about the paper's suitability."", ""The sentiment score is 20 (slightly positive) because the reviewer begins by stating they have become 'a little more positive' about the paper and raised their score. However, they still express some reservations about the paper's contributions. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers constructive suggestions, and acknowledges the authors' good points. They maintain a professional tone while providing both positive and negative feedback. The reviewer also uses phrases like 'I would suggest' and 'I think' which soften their criticisms. However, they don't go out of their way to be overly polite or complimentary, maintaining a fairly neutral academic tone overall."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's value, impressive results, and interesting contributions, while also raising some questions and suggesting improvements. The overall tone is constructive and appreciative of the work. The politeness score is 80 (quite polite) due to the reviewer's respectful language, use of phrases like 'I'd like to know' and 'I'm glad you included', and the balanced presentation of both pros and cons. The reviewer offers critiques in a considerate manner, framing them as questions or suggestions rather than direct criticisms.""]"
"['The paper considers sparse kernel design in order to reduce the space complexity of  a convolutional neural network. In specifics, the proposed procedure is composed of following steps: 1) remove repeated layers, 2) remove designs with large degradation design, and 3) further remove design for better parameter efficiency.\n\nThe paper proposed the composition of group convolution, pointwise convolution, and depthwise convolution  for the sparse kernel design, which seems pretty promising. In addition, the authors discussed the efficiency of each convolution compositions.\n\nI failed to appreciate the idea of information field, I didn\'t understand the claims that ""For one output tensor, sizes of information fields for all activations are usually the same"". When introducing a new concept, it\'s very important to make it clear and friendly. The author could consider more intuitive, high level, explanation, or some graphic demonstrations. Also, I couldn\'t see why this notion is important in the rest of the paper.\n\nPersonally I\'m so confused by the theorem. It looks like a mathematical over-claim to me. It claims that the best efficiency is achieved when M N = C. However, is it always the case? What is M N \\neq C? What does the theorem mean for real applications?\n\nAll the reasoning and derivation are assuming the 3 x 3 spatial area and 4 way tensor. I would assume these constant are not important, the paper could be much stronger if there is a clear notion of general results.', 'Standard dense 2D convolution (dense in space and channels) may waste parameters. This paper points out the many ways that sparser convolutional operators (“kernels”) may be combined into a single combined operator that may be used in place of dense convolution.\n\nThe paper waxes grandiose about the exponentially many ways that operations may be combined but then defines and tries only four. While trying four alternatives may be quite interesting, the paper could have avoided grandiose language by just stating: “We tried four things. If you restrict yourself to kernels with 3x3 receptive field and no repeated operations <and probably other assumptions>, there are only four unique combinations to be tried.” Perhaps a page of text could have been saved.\n\nThe paper also defines “information field” as the product of the operator’s (spatial) receptive field and the number of channels that each unit can see. Authors proceed to make broad claims about how information field is an important concept that predicts performance. While this may indeed turn out to be an important concept, it is not shown as such by the paper.\n\nClaims:\n\n“…we identify a easily measurable quantity named information field behind various sparse kernel designs, which is closely related to the model accuracy.”\n\n“During the process to reduce the design space, we find an unified property named information field behind various designs, which could directly indicate the final accuracy.”\n\nBut the paper does not substantiate these claims.\n\nSince information field is defined as the product of the receptive field and the number of channels seen, it would seem necessary to show, say, at least some experiments with varying receptive field sizes and number of channels. Then it might be shown, for example, that across a wide array of network sizes, widths, depths, holding all but information field constant, information field is predictive of performance. But these experiments are not done.\n\nReceptive fields: the paper *only ever tries 3x3 receptive fields* (Table 2, 3, 4). So absolutely no support is given for the relevance of two out of the three components (i size, j size) comprising information field!\n\nNumber of channels: as far as I can tell, Table 2 and 3 contain the only results in this direction. Reading off of Table 2: for networks of the same depth (98), info size 256 works a bit better than 128*, and 512 works a bit better than 256. \n\n* (see also Table 3 lines 4 vs 5 show the same 256 vs 128 effect.)\n\nCool. But *two comparisons* are not even close to enough to support the statement “we find an unified property named information field behind various designs”. It is enough to support the statement “for this single network we tried and using 3x3 receptive fields, we found that letting units see more channels seemed to help.” Unfortunately, this conclusion on its own is not a publishable result.\n\n\n\nTo make this paper great, you will have to close the gap between what you believe and what you have shown.\n\n(1) You believe that information field is predictive of accuracy. So show it is predictive of accuracy across sufficiently many well-controlled experiments.\n\n(2) It may also be that the PWGConv+DW+PWGConv combination is a winning one; in this case, show that swapping it in for standard convolution helps in a variety of networks (not just ResNet) and tasks (not just ImageNet).\n\n\n\nOther minor notes:\n\n - Equations are critical in some parts of some papers, but e.g. triple nested sums probably aren’t the easiest way of describing group convolution.\n\n - The part about regexes seemed unnecessary. If 1000 different designs were tried in a large automated study where architectures were generated and pruned automatically, this detail might be important (but put it in SI). But if only four are tried this detail isn’t needed: we can see all four are different.\n\n - Figure 1 is a great diagram!\n\n - How efficient are these kernels to compute on the GPU? Include computation time.\n\n - “Efficiency given the total amount of parameters.” These equations and scaling properties seemed to miss the point. For example, “It can be easily verified that given the total number of parameters the greatest width is reached when the best efficiency is achieved.” This is just saying that standard convolution scales poorly as F -> infinity. This doesn’t seem like the most useful definition of efficiency. A better one might be “How many params do you need to get to x% accuracy on ImageNet?” Then show curves (# of params vs accuracy) for variants of a few popular model architectures (like ResNet or Xception with varying width and depth).\n\n - 3.3.2: define M and N\n', 'This paper addressed an interesting problem of reducing the kernel to achieve CNN models, which is important and attracts lots of research work. However, the methods don\'t have very good justifications. \nFor example, in Section 3.1, the authors mentioned that ""Specifically, in normal CNNs it is quite common to have multiple stages/blocks which contain repeated patterns such as layers or structures."" It is still unclear why it is better to replace these so-called repeated patterns. \nThe defined ""information field"" is not clearly explained and the benefits are also not demonstrated.']","[-20, -50, -50]","[50, 20, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some promising aspects of the paper, they express confusion and criticism about several key points. The reviewer fails to appreciate the concept of 'information field', finds the theorem confusing, and suggests the paper could be stronger with more general results. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful language throughout. They express their criticisms in a constructive manner, using phrases like 'I failed to appreciate' and 'I'm so confused' rather than making harsh judgments. The reviewer also offers suggestions for improvement, which is a polite way to address weaknesses in the paper. The tone is professional and objective, avoiding any personal attacks or overly negative language."", ""Sentiment score: The review is generally critical, pointing out several shortcomings of the paper. The reviewer states that the paper makes grandiose claims without sufficient evidence, lacks necessary experiments to support its main concepts, and needs significant improvements to be publishable. However, the reviewer also acknowledges some positive aspects, such as the interesting nature of the four alternatives tried and the quality of Figure 1. This mix of criticism and limited praise suggests a moderately negative sentiment, hence the score of -50.\n\nPoliteness score: The language used is professional and constructive, avoiding personal attacks or harsh language. The reviewer offers specific suggestions for improvement and uses phrases like 'To make this paper great' and 'Cool', which add a positive tone. However, some phrases like 'waxes grandiose' and 'missed the point' are slightly critical. Overall, the review maintains a polite and constructive tone while being critical, resulting in a mildly positive politeness score of 20."", ""The sentiment score is -50 because the review starts with a positive note about the paper addressing an interesting problem, but then quickly shifts to criticism. The reviewer states that the methods 'don't have very good justifications' and points out unclear aspects of the paper, indicating a generally negative sentiment. However, it's not entirely negative, hence the score is not lower. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer states their criticisms directly but without using harsh or offensive language. They use phrases like 'it is still unclear' and 'is not clearly explained' which are neutral ways of expressing concerns.""]"
"['This paper presents an iterative approach to separate unobserved distribution signal from a mixture with observed distribution. The proposed approach looks reasonable to me, however, the experiment and analysis are insufficient.\n1. At test time, does the input also go through the same number of iterations (10)? I would like to see how the separated results evolve over iterations.\n2. It is not clear what is the quality of samples generated by GLO. In the image separation task, GLOM performs better than GAN, but worse in other tasks. Analysis is needed here.\n3.  I noticed that only in the music separation task, finetuning is significantly better than vanilla NES. Is it because generative models can synthesize more realistic data samples? For example, would the generator learn to synthesize X+B with temporal synchronization? More analysis is also needed here.\n\n============================\n\nI think the reviewer addressed my questions and concerns in the rebuttal, so I raised my rating to 6.', 'This paper describes a signal separation method called neural egg separation (NES).\nThe separation problem is tackled in a semi-supervised setting where the observed mixture contains a target signal and a background noise, with access to the distributions of target and mixture signals.\n\nThe strength of the paper is that it describes the importance of the problem setup for practical use with some motivating examples. \nHowever, some unclear notations weaken the claim of the paper.\n\nSpecific comments follow.\n* The loss in (1) is unclear.\nAssuming latex grammar, \\| \\| is usually used to denote a vector norm, but (1) has two values inside. \nI would write \\ell(T(y_i), b_i) to show a loss function, instead of the \\| \\| style.\nMore importantly, the loss should be explicitly defined. Does this mean the l2 error?\n\n* The iterative separation process of (2) is even unclear.\nDoes T^m(b_j + x_i^m) share the parameter of that from previous iterations like T^{m-1}?\nOr are the parameters fixed throughout the iterations?\n\n* Use of \\cdot.\nThere may be a confusion between the inner product and element-wise product with the \\cdot operator.\nRight after (5), there is an inequality z \\cdot z \\leq 1, which is meant to be the inner product.\nOn the other hand, the use of \\cdot in (8) looks like the element-wise product to describe a masking operation.\n\nClarifying the objective and overall procedures is necessary for presenting the proposed method.\n\n=================================\nEDIT: I confirmed the revisions regarding the notation issues, but there still have confusing parts.\n* Definitions of norm operator \\| \\| is unclear.\n  * L_1 is mentioned below (1), and used other parts (3) or Algorithm 1. Equation (12) in Appendix uses |W1|_1^2, which looks like the l1 norm as well. Use consistent notations.\n  * Equations (12, 13, 14) uses \\|\\|_2 or \\|\\|_1 to specify the type of norm, whereas (5), (6), (7) and other parts after (15) use \\|\\|. This confuses me. What do you mean by \\|\\| without subscript?\n  * \\|\\| operator taking to symbols is a weird notation for me. Usually, norm is defined for a single vector (or a matrix). For example in (5), I would write \\| b - G(z_b) \\|, if you want to measure the difference between b and G(z_b).\n\nThe experimental result is impressive, as the other reviewers mention. I strongly recommend clarifying the notation to better deliver the method.', 'This article presents an interesting if heuristic approach to source separation, NES, buttressed by the use of GLO masking for initialization, with promising results on data generated from synthetic source mixing.\n\nThe paper is well written and on the whole clear. My main concern with the work is the empirical nature of the NES iterative procedure. As far as I can tell there is no guarantee of convergence (nor discussion concerning this point). Since i am not familiar with the tasks, it is hard for me to judge the quality of the empirical results -- though the results do seem promising.\n\nre: Bags & shoes task / table 1: ""...  Finetuning from GLOM, helped NES achieve stronger performance, nearly identical to the fully-supervised upper bound. It performed better than finetuning from AM (which achieved 22.5/0.85 and 22.7/0.86)"": I can\'t place the first number in the table, therefore i\'m not quite sure what is being pointed out here.\n\nre: Music task / table 3: ""... GLOM was much better than AM initialization (that achieved 0.9 and 2.9)"": I don\'t see either number in the table. I\'d assumed that GLOM was used to fine-tune NES, so I was expecting to see the 2.9 under ""FT"". \n\n== \n\nI think the authors\' response is reasonable. They have added clarifying material to the paper addressing my concerns. I have raised my rating from a 5 to a 6.']","[-20, -20, 60]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer states the approach 'looks reasonable', they also note that 'experiment and analysis are insufficient'. They list several areas needing more analysis or clarification, indicating overall dissatisfaction with the current state of the paper. However, the final line suggests some improvement after rebuttal, slightly moderating the negative sentiment. The politeness score is moderately positive (50) as the reviewer uses polite, professional language throughout. They phrase criticisms as requests for more information or analysis rather than direct attacks, and acknowledge the authors' efforts in addressing concerns in the rebuttal. The tone is constructive and respectful, even when pointing out shortcomings."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's strength in describing the importance of the problem setup, they also point out several unclear notations and issues that weaken the paper's claims. The reviewer suggests that clarifications are necessary, indicating that the paper has significant room for improvement. However, the score is not deeply negative as the reviewer also notes some positive aspects and the experimental results are described as 'impressive'. The politeness score is moderately positive (60) because the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement without using harsh or critical tones. The use of phrases like 'I would write...', 'Clarifying... is necessary', and 'I strongly recommend...' show a respectful approach to providing feedback. The reviewer also acknowledges the paper's strengths and the impressive experimental results, further contributing to the polite tone."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'interesting' and 'promising', and mentions that the authors' response was 'reasonable' and addressed their concerns, leading to an improved rating. However, they also express some concerns about the empirical nature of the approach and lack of discussion on convergence, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, acknowledging the paper's strengths, and framing criticisms constructively. They use phrases like 'interesting approach', 'well written', and 'promising results', which contribute to a polite tone. The reviewer also admits when they are not familiar with certain aspects, showing humility. The increase in rating after the authors' response further indicates a respectful and open-minded approach.""]"
"['The paper starts by establishing that biases play an important, negligible role in existing DNNs.\nSpecifically, they help improve classification performance, and networks trained with biases do make use of biases.\n\nThen, the authors recognize that the state of the art DNNs use ReLU and variants, which are a piece-wise linear function.\nOver the linear regions, the entire DNN can be collapsed into a single linear model f(x) = Wx + b.\n\nThen the authors argue that the existing gradient-based attribution methods (for interpreting DNNs) often ignore the attribution of the `b` terms in the heatmap.\nThat is, when backpropagating the DNN outputs back to the input, the gradient of (Wx + b) wrt x is exactly W only (ignoring the contribution of b).\n\nThe paper then proposes a method for backpropagating biases.\nFrom the presented results, I only can conclude that bias backpropagation does show a different heatmap compared to regular gradient-based methods.\nHowever, it is unclear how much this BBp result is advancing our understanding of DNNs.\nThe result for this is still preliminary.\n\n- Clarity\nResearch is well motivated, and paper presentation shows a nice, coherent story.\n\n- Originality\nAFAIK, the direction of looking at bias attribution is novel.\n\n- Significance\nThe significance of the paper is limited because (1) the paper only considers the positive region of ReLUs; (2) the empirical results are preliminary and do not show a convincing usefulness of BBp.\nSuggestions: authors may design a toy dataset or find a dataset that has some inherent biases (e.g. data imbalance) to show that DNNs do capture interesting information in the biases. From there, hopefully the impact of BBp can be clearer.\n\nAt the moment, the paper appears not ready for publication.', 'Summary of the paper\nThis paper proposes a method for attributing the output of a neural network to bias terms. The method is restricted to networks that have piecewise-linear activation functions. Computation is recursive, starting from bias attribution to the activation of the penultimate layer, such that the final attribution is of the same size as the input data point and sums up to the bias term when the network is written as a linear function (for that input).\n\nStrengths \n- The idea of mapping the bias term back to the input is interesting as it shows a common behaviour of the network on inputs that choose the same pieces of the piecewise linear functions. \n- Other gradient-based methods overlook the bias term when piecewise-linear activations are involved, so this method closes that gap. \n\nQuestions for authors\n- The separability of the bias and gradient terms is possible only for piecewise linear activation functions, and would not generalize to other activations (e.g., LSTMs in NLP). \n- Except for the 1-2 examples pointed out by the authors, it is not clear from the visualizations that bias attribution shows something qualitatively different. For instance, in “airplane”, “horse” and “fireguard”, gradient also highlights a region similar to bias attributions (although, technically they are complementary). \n- While the authors qualitatively compare with other attribution methods, they only experimentally compare with gradient. It would be instructive to compare with more refined gradient-based attribution methods such as Integrated Gradients or DeepLift and show empirically that looking at bias attribution is better over simply looking at other attribution-based methods. Integrated Gradients specifically argues that it removes extraneous attribution to background (http://www.unofficialgoogledatascience.com/2017/03/attributing-deep-networks-prediction-to.html). \n- To have substantial content for a full publication, it may be good to address what insights one can derive from bias attributions. For instance, cluster inputs based on bias attributions, and show how different sets of inputs may be affected by different kinds of biases. For e.g., do all images of birds show similar bias attributions? Or, for instance, does a picture of a house (which may have the same kind of edges as a chair) have the same bias attribution as that of a chair? \n\nConclusion\nI think the paper is interesting, but for a full publication, a thorough comparison with other methods is required, as well as showing more insights as to how bias attribution is useful (another e.g., can it be combined with gradient-attribution for a “richer” visualization?) \n', 'Summary:\nThe paper\'s main contribution is to attribute the bias term seen at the output to each of the input dimension appropriately.  The other claim is that together with gradient information , this could enhance existing explainability methods.\n  \nThe paper considers DNNs with piecewise linear activation functions. Then the final DNN output is a piece linear function. So for any given point x, the point lies in one of the linear pieces and there fore, can be written as a linear model. The gradient term can be computed using back propagation methods (although back propagating keeping the weights fixed and keeping the input as the variable). However there are no know existing works that attribute the bias of the linear piece at the final layer to the input dimensions. This paper provides a method to do it such that when you add the vector contribution of all the dimension in the input - it results in the bias vector at the output layer.\n\nThe basic idea is to distribute dimension wise bias attribution  at layer \\ell to layer \\ell-1 by using N_{\\ell} x N_{\\ell-1} attribution matrix where N_{\\ell} is the dimension of layer \\ell. This is done using two methods - one using exponential weights and the other using some sort of variance measure from a fixed average bias.\n\nThe authors then show using examples from STL-10 and Imagenet datasets, how the gradients and biases attributed to the inputs compare for explanation purposes.\n\nStrengths:\n\nThe notion of attributing final layer biases to input layer is novel. Its important given that it carries important information regarding the final classification output.\n\nWeaknesses:\n\na) This paper lacks quite a bit on comparison with existing work. For example, LRP (layer wise relevance propagation) has been referred to by the authors. However, there is no comparison with LRP heat maps. This website - http://www.explain-ai.org/ - documents state of the LRP methods with code, videos, papers (some of which have been cited by the authors). I think the authors could produce heat map produced by LRP for all these different examples in page 8. For instance, pls look at Image A in Fig .2 in https://arxiv.org/pdf/1708.08296.pdf. There is \'cup\' and a \'volcano\' in the same picture. The paper compares gradient based heatmaps and LRP based ones. LRP based ones are very crisp (for this image of course). LRPcode is readily available from a well maintained project page - http://www.explain-ai.org/. Will the heat maps of grad/bias look crisper than LRP ? Other papers and more examples of LRP can be found at http://www.explain-ai.org/\n\nLRP takes the final probability weight at the output layer and assigns recursively to other neurons in the penultimate very similar to what the current paper does for bias. However, the attribution mechanism (the weights) are different. A couple of variations are explored in this survey (https://arxiv.org/pdf/1708.08296.pdf).\n\nb)  This point is related to the first- The authors say ""Therefore, the interpretation of the DNN’s behavior on the input data should be exclusive to the information embedded in the linear model."" - I disagree a little bit here. It is true that behavior of the DNN on the input is exclusive to the linear piece. However, interpretation of the behavior/ explanation of it is another matter. For example, I quote two methods in the literature that have been used for explanation of an input sample - but does not use the linear piece or the gradient information.\n     1)  Pls look at - https://arxiv.org/pdf/1703.02647.pdf - (Figure 3 + Section A.8 in the appendix). The paper used streaming submodularity algorithms to actually assemble a part of the image with everything else ""blacked out"" to determine which sparse parts of the image are responsible for the final output. They have exhaustive comparisons with LIME too. These methods actually rely on behavior of DNN far away from the actual x to explain the behavior at x. ""Zeroing out irrelevant"" parts is one of the ways of explaining adopted by LIME and these approaches. Ideally the authors should compare with these too.\n \n 2) In this paper - https://arxiv.org/abs/1802.07623 - authors provide pertinent negatives - what should ""not be"" there in the image so that the label does not change - In fact for MNIST data, this produces very interesting additional explanations that is not produced by methods (including LRP and LIME) that rely on things in the image. Again the explanation is not at all related to the linear piece.\n\nIn general, linear pieces are so close by , the nearby movement and possibly change of gradients can also provide useful explanation of the behavior.\n\n\nOverall - at least the authors must discuss the above references + also survey works that highlights ""relevant parts of the image"" like LIME and streaming sub modularity etc. Further an actual comparison to LRP (code is easily available) is crucial to evaluate the efficacy of the proposed methods given that the authors of LRP have compared with gradient based methods. Comparison with LIME would also be interesting and desirable.\n\n\n']","[-50, 20, -20]","[50, 70, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., 'Research is well motivated', 'novel' direction), they ultimately conclude that 'the paper appears not ready for publication' and that 'the significance of the paper is limited'. This indicates an overall negative sentiment, though not extremely harsh. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They acknowledge the paper's strengths before discussing its limitations, which is a polite approach. The reviewer also uses phrases like 'AFAIK' (as far as I know) and 'may' when making suggestions, which adds a courteous tone to the critique."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths and interesting ideas, but also raises several questions and suggests improvements for a full publication. The overall tone is constructive rather than dismissive. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'it would be instructive' and 'it may be good to' which maintain a polite and collaborative tone. The conclusion summarizes the review's main points in a balanced way, acknowledging the paper's interest while suggesting areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they primarily focus on weaknesses and areas for improvement. The reviewer points out a lack of comparison with existing work, disagrees with some of the authors' statements, and suggests several additional references and comparisons that should be included. However, the score is not deeply negative as the reviewer does recognize the novelty of the paper's main contribution.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's content and their critiques, avoiding harsh or dismissive statements. The reviewer also balances criticism with recognition of the paper's strengths. The use of phrases like 'I think the authors could...' and 'Ideally the authors should...' suggests recommendations rather than demands, which contributes to the polite tone.""]"
"['I am upgrading my reviews after the rebuttal, which actually has convinced me that there is something interesting going on in this paper. However, I\'m not entirely convinced as the approach seems to be ad hoc. the intuitions provided are somewhat satisfactory, but it\'s not clear why the method works.. for example, the approach is highly sensitive to the hyperparameter ""drop rate"" and there is no way to find a good value for it. I\'m inclined towards rejection as, even though results are almost satisfying, I yet don\'t understand what exactly is happening. Most of the arguments seems to be handwavy. I personally feel like a paper as simple as this one with not enough conceptual justifications, but good results (like this one), should go to a workshop. \n\n======\nThe authors propose to randomly drop a few parameters at the beginning and fix the resulting architecture for train and test. The claim is that the resulting network is robust to adversarial attacks.\n\nMajor concerns:\nAn extremely simple approach of pruning neural networks (randomly dropping weights) with no justification whatsoever. There are so many other network pruning papers available. If the point is to use pruned network then the authors must provide analysis over other pruning schemes as well.\n\nAnother major concern (technical contributions): How is the idea of randomly dropping weights different from Deep Expander Networks (Prabhu et al., ECCV 2018)? Please clarify.\n\nMinor suggestion: Another simple approach to test the hypotheses would be to try dropout at test time and see the performance.', 'The authors propose a simple method for increasing the robustness of convolutional neural networks against adversarial examples. This method is simple but seems to achieve surprisingly good results. It consist in randomly remove neurons from the network architecture. The deleted neurons are selected before training and remain deleted during the training and test phase.  The authors also study the adversarial examples that still fool the network after applying their method and find than those examples also fool human. This finding raises the question of what is an adversarial example if both humans and networks are fooled by the same example. \n\nUsing Random Masks in neural network is not a new idea since it was already proposed for DropOut or DropConnect (Regularization of Neural Networks using DropConnect, ICML2013) and in the context of adversarial attacks (Dhillon et al. 2018)  as reported by the authors. The discussion (Section 2) about the impact of random masks on what convolution layers capture in the spatial organisation of the input is interesting: whereas standard CNNs focus on detecting the presence of a feature in the output, random mask could force the CNN layers to learn how a specific feature distributes on the whole input maps. This limitation of the CNN has already been pointed up and solutions have been proposed for example Capsule Networks (Dynamic Routing Between Capsules, NIPS 2017). This intuition is experimentally supported by a simple random shuffle by block of the input image  (Appendix A).\n\nIn Section 3, the authors present a large number of experiments to demonstrate the robustness of their method. Most of the details are given in the 13 (!) pages of appendix. Experiments against black-box attack, random noise, white-box attack, grey-box are presented. Most of the experiments are on CIFAR10 but one experiment is also presented on MNIST. One could regret that only one architecture of CNN is tested (ResNet18) except for gray-box attack, for which DenseNet121 and VG19 are tested. One could ask why the type of models tested is not consistent across the different experiments.  For black-box attack, random masks compare favourably to Madry’s defence. For white box defence, Random Mask is not compared to another defence method, which seems a weakness to me but I am not familiar enough with papers in this area to estimate if this is a common practice. In most of the experiments, the drop ratio is between 0.5 and 0.9, which seems to indicate that the size the initial network could be reduced by more than 50% to increase the robustness to attack. This ratio is larger than what is usually used for dropout (0.5 at most).  \n\nIn section 3.3, different strategies for random masks are explored : where to apply random masks, random mask versus random channels, random masks versus same masks. Results are given in table 2. The caption of Table 2 could be more explicit : what are the presented percent ?\n\nExperiments on masking shallow versus deep layers are interesting. Best results for robustness are obtained with masking shallow layers at quite a high ratio (0.9). One could ask if this result could be due to the type or the parameters of adversarial attacks which are not adapted to such a high sparseness on shallow layers or to the specific kind of sparseness induced by the masks. A comparison to a regular network with the same number of free parameters as the masked network could give insight on this aspect. \n\npros : simple to implement, good robustness shown agains a variety of attack types\ncons : mainly tested on a single architecture (ResNet) and on a single datatbase CIFAR. Maybe not robust against the latest techniques of adversarial attack.', ""This paper proposes a surprisingly simple technique for improving the robustness of neural networks against black-box attacks. The proposed method creates a *fixed* random mask to zero out lower layer activations during training and test. Extensive experiments show that the proposed method without adversarial training is competitive with a state-of-the-art defense method under blackbox attacks.\n\nPros:\n -- simplicity and effectiveness of the method\n -- extensive experimental results under different settings\n\nCons:\n -- it's not clear why the method works besides some not-yet-validated hypotheses.\n -- graybox results seem to suggest that the effectiveness of the method is due to the baseline CNNs and the proposed CNNs learning very different functions; source models within the same family still produce strong transferable attacks. It would have been much more impressive if different randomness could result in very different functions, leading to strong defense in the graybox setting.""]","[-30, 60, 50]","[20, 70, 75]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects and good results, they are still inclined towards rejection due to lack of conceptual justifications and concerns about the approach being ad hoc. The overall tone is more negative than positive, but not extremely negative. The politeness score is 20 because the reviewer uses respectful language and provides constructive feedback, even when expressing concerns. They use phrases like 'I personally feel' and offer suggestions, which adds a polite tone. However, the language is not overly formal or deferential, keeping the score moderately positive rather than extremely high."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the method's simplicity and effectiveness, noting 'surprisingly good results' and listing several pros. However, they also point out some limitations and areas for improvement, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'One could regret' and 'One could ask' instead of direct criticisms. The reviewer also acknowledges their own potential lack of familiarity in some areas, showing humility. The overall tone is professional and courteous, while still providing thorough and honest feedback."", ""The sentiment score is 50 (slightly positive) because the review begins with a positive tone, highlighting the 'surprisingly simple technique' and its effectiveness. The reviewer notes pros such as simplicity and extensive experimental results. However, there are also cons mentioned, which balance out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, presenting both pros and cons in a balanced manner without harsh criticism. The use of phrases like 'surprisingly simple' and 'extensive experiments' shows appreciation for the authors' work, while the cons are presented as constructive feedback rather than blunt criticism.""]"
"['This work introduces a novel defense method ""Neural Fingerprinting"" against adversarial examples.\nIn the training process, this method embeds a set of characteristic labeled samples so that responses of the model around real data show a specific pattern.  The defender can detect if a given query is adversarial or not by checking the pattern at test time.\n\nStrong point:\nThe strong point is that the proposed method seems to be appropriate and technically original. The performance is well investigated and compared with several competitors.  The organization is good and the idea is clearly stated. \n  \nWeak point:\nOne question is that why the proposed method can be protective against the adaptive CW attack. In the public discussion, the authors mention that the defense works successfully because the landscape of the fingerprinting loss is non-convex and no gradient method is guaranteed to find a suitable solution. If this is correct, did you repeatedly try the gradient-based attack with changing random seeds? By doing so, the attack might work successfully with a certain probability.\n\nComments:\nThe presented method seems to have a certain similarity with digital watermarking of deep neural networks, for example:\nhttps://gzs715.github.io/pubs/WATERMARK_ASIACCS18.pdf\nIt would be interesting to mention to these methods in the related work section.\n\n', 'This paper proposes a method for the detection of adversarial examples via what the authors term ""neural fingerprinting"" (NeuralFP). Essentially, a reference collection of perturbations are applied to the training data so as to learn the effects on the classification decision. The premise here is that on average, normal examples from a common class would have similar changes in the classification decision when reference perturbations are applied, whereas adversarial examples (particularly those off the local submanifold) may have a markedly different set of changes from what was expected for the targeted class. These reference perturbations as well as the anticipated output perturbations together form the ""fingerprints"".\n\nTo measure the difference between observed outputs and fingerprints, the average (squared?) Euclidean distance is used. Given a fixed set of input fingerprints (presumably chosen so as to provide coverage of the range of possible perturbation directions), the authors use the distance formula as a regression loss (""fingerprint loss"") to train the choice of output fingerprints. Although the authors do not explicitly state it this way, this secondary training objective encourages a K-Means style clustering of output perturbations where the output fingerprints serve as cluster representatives. \n\nThis learning formulation is to my mind is both very innovative and extremely effective, as demonstrated by the authors\' experimental results. Their experiments show superlative performance (near perfect detection!) against essentially the full range of state-of-the-art attacks. They give careful attention to the mode of attack, and show excellent performance even for adaptive white-box attacks, in which existing attack methods are given the opportunity to minimize the fingerprint loss.\n\nThe presentation of the paper is excellent - clear, well-motivated, and detailed, with careful attention given to experimental concerns such as the choice of perturbation directions (the recommendation is to choose them at random), and the number of fingerprints to pick.\n\nOverall, the reported results are so good, and the approach so convincing, that one wonders what the weaknesses of the approach might be (if any). Questions that do come to mind are:\n* Can an adversarial strategy can be developed that could execute a successful attack while minimizing the fingerprint loss. \n* Another issue is whether the NeuralFP would work on more challenging data sets where the classes are highly fragmented - at what rate would the benefits of NeuralFP fade as the classification performance degrades? \n* What happens to performance if the perturbation directions are chosen so as to better conform with the local sub-manifolds... would fewer perturbations be required? (It would seem that reducing the number of perturbations needed could have a significant effect on training time.)\n\nOverall, this is a very strong and important result, fully deserving of acceptance.\n\nP.S. Two sets of typos that need attention:\n* In Equation 3, the Euclidean norm is taken. In Equation 5, the squared Euclidean norm is taken. Presumably, one of these is a typo. Which?\n* In the definition of delta-min and delta-max in the first paragraph of Section 2.2, y-hat should be w-hat.\n\n', 'This paper proposes a new technique for detecting adversarial examples by introducing ""fingerprints"" into the landscape while training, and exploiting the fingerprints at test time to detect adversarial examples. The idea is novel and the paper is well-written, but concerns about gradient masking prevent me from recommending acceptance just yet.\n\nPositives: \nThe paper is extremely well-written, and the approach is clear and presented well. The authors also clearly put significant effort into the evaluation, and accurately/consistently describe threat models that they consider. The approach is also clearly novel, and is interesting. \n\nConcerns:\nMy biggest concern is that this detection mechanism masks gradients in its loss function. The two reasons I strongly believe this is the case are (a) Figure 5 and (b) the authors themselves state that their loss is highly non-convex and that no gradient-based method may be able to find a solution. This, however, does not guarantee robustness (see [1] for why such “unfriendly” landscapes can usually be circumvented)\n\nSome concrete evaluation concerns and experiments that the authors can run to alleviate them:\n- Figure 5 shows adversarial robustness even against eta = 0.25---at this value of epsilon, the attacker should be able to create realistic images of other classes (even without PGD), so this suggests that the loss is somehow making examples hard to find rather than removing them. The authors should address this issue.\n- Showing that at a sufficiently high eta attacks start to succeed is also useful\n- Running SPSA, CarliniL2-FP, and PGD for *many* more iterations and using *many* more steps for binary search (right now it looks like the binary search is looking in a space of size 10^6 with 10 steps, which only has a granularity of about 5k, which means you never see any value < 5k in a bisection search, which casts into doubt all of these results)\n- The AUC should monotonically degrade with eta (this is another indication the attacks might not be running for long enough)\n- The method does not seem to be specific to L-infinity constraint. To this end, a version of Figure 5 in the L2 case would be extremely useful in understanding the detection method.\n\nI also apologize if some of these concerns about gradient masking seem unsubstantiated; that said, I tried to run the code given in the paper, but got several OOM and other errors (utils modules not found, and PyTorch deprecations), even on a machine with 8 12GB-memory GPUs. If the authors can provide instructions for running the code I will be happy to test it and alleviate some of my own concerns. I also tried to reimplement the approach, but did not manage to finish before the review deadline. If I am able to reimplement the approach I will update my review accordingly.\n\nSome smaller comments on the paper:\nA consolidated set of tables for attack parameters in an appendix is needed\n- Page 4 last paragraph line 4 find the subset that “satisfies” instead of “satisfy”\n- Page 5 paragraph 1 line 1 defender,for needs a space before for\n- Page 5 paragraph right before theorem 1 last line Here, for detection needs a , after detection \n- Page 7 paragraph 1 line 2 (2 hidden layers the 2 should be written two\n- Page 7 second last paragraph line 2 “is chosen” instead of “are chosen”\n- Page 7 last paragraph line 2 “across attacks” needs a , after \n- Page 9 table 6 label line 2 “does not shown” should be “show” instead of “shown” \n- Page 9 last line “measure of robustness” remove ""of""\n\n[1] https://arxiv.org/pdf/1802.00420.pdf']","[60, 90, -20]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer starts by highlighting the novelty of the method and its strong points, describing it as 'appropriate and technically original' with good performance and clear organization. The weak point mentioned is framed as a question rather than a criticism, suggesting a generally positive view. The politeness score is 70 (polite) due to the constructive tone throughout. The reviewer uses respectful language, frames criticisms as questions or suggestions, and offers additional resources. The use of phrases like 'Strong point' and 'Weak point' helps structure the feedback clearly and professionally. The reviewer also acknowledges the authors' previous responses in the public discussion, showing engagement and respect for their work."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, using phrases like 'very innovative and extremely effective', 'superlative performance', 'excellent performance', and 'very strong and important result, fully deserving of acceptance'. The reviewer also provides constructive questions and suggestions, indicating a thorough and positive engagement with the work. The politeness score is 80 (quite polite) due to the consistently respectful and professional tone throughout the review. The reviewer uses phrases like 'to my mind' and 'one wonders' to soften potential criticisms, and offers praise alongside constructive feedback. The reviewer also politely points out typos at the end, framing them as needing 'attention' rather than as errors. The language is formal and courteous throughout, maintaining a positive and supportive tone even when raising potential issues or questions."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's novelty and good writing, they express significant concerns about gradient masking and cannot recommend acceptance. The positive aspects are balanced against these concerns, resulting in a slightly negative overall sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and offers constructive feedback. They even apologize for potential unsubstantiated concerns and express willingness to update their review. The reviewer also provides detailed suggestions for improvement and points out minor grammatical errors in a helpful manner.""]"
"['This paper proposes a new architecture for adversarial training that is able to improve both accuracy and robustness performances using an attention-based model for feature prioritization and L2 regularization as implicit denoising. The paper is very clear and well written and the contribution is relevant to ICLR. \n\nPros:\n\n- The background, model and experiments are clearly explained. The paper provides fair comparisons with a strong baseline on standard datasets.\n- Using attention mechanisms to improve the model robustness in an adversarial training setting is a strong and novel contribution \n- Both quantitative and qualitative results are interesting. \n\n', 'Summary: This paper argues that improved resistance to adversarial\nattacks can be achieved by an implicit denoising method in which model\nweights learned during adversarial training are encouraged to stay\nclose to a set of reference weights using the ell_2\npenalty. Additionally, the authors claim that by introducing an\nattention model which focuses the model training on more robust\nfeatures they can further improve performance. Some experiments are\nprovided.\n\nFeedback: My main concerns with the paper are:\n\n* The experimental section is fairly thin. There are at this point a\n  large number of defense methods, of which Madry et al. is only one. In\n  light of these, the experimental section should be expanded. The\n  results should ideally be reported with error bars, which would help\n  in gauging significance of the results.\n\n* The differential impact of the two contributions is not entirely\n  clear. The results in Table 1 suggest that implicit denoising can\n  help, yet at the same time, Table 2 suggests that Black-box\n  performance is better if we just use the attention model. Overall,\n  this conflates the contributions unnecessarily and makes it hard to\n  distingish their individual impact.\n\n* The section on gradient maps is not clear. The authors argue that if\n  the gradient map aligns with the image the model depends solely on\n  the robust features. While this may be (somewhat more) intuitive in\n  the context of simple GLMs, it\'s not clear why it should carry over\n  to DNNs. I think it would help to make these intuitions much more\n  precise. Secondly, even if this were the case, the methodology of\n  using a neural net to classify gradient maps and from this derive a\n  robustness metric raises precisely the kinds of robustness questions\n  that the paper tries to answer. I.e.: how robust is the neural net\n  classifying the gradient images, and how meaningful are it\'s\n  predictions when gradient maps deviate from ""clean"" images.\n\nOverall, I feel this paper has some potentially interesting ideas, but\nneeds additional work before it is ready for publication.', 'This paper studies adversarial training of robust classification models. It is based on PGD training in [madry17]. It proposes two points: 1) add attention schemes, 2) add a feature regularization loss. The results on MNIST and CIFAR10 demonstrate the effectiveness. At last, it did some diagnostic study and visualization on the attention maps and gradient maps.\n\n1. Can you provide detailed explanations/intuitions why attention will help train a more robust models?\n\n2. Two related adversarial training papers are missing ""Ensemble Adversarial Training"" (ICLR2018) and ""Adversarial Logit Pairing"" (ICML2018). Also, feature (logit) regularization has been studied in ALP paper on ImageNet.\n\n3. For Table 2 on CIFAR10, I would like to see PGD20 (iterations) + 2 (step size in pixels), PGD100 + 2 and PGD200 + 2. Also, I am interested in seeing CW loss which is based on logit margin. \n\n4. I would like to see results using the ""wide"" model in [madry17] paper for ALP and LRM. I think results from large-capacity models are more convincing.\n\n5. I would like to see results on CIFAR100, which is a harder dataset, 100 classes and 500 images per class. I think CIFAR10 alone is not sufficient for justification nowadays (maybe enough one year ago). Since ImageNet is,  to some extent, computationally impossible for schools, I want to see the justification results on CIFAR100.\n\n##### Post-rebuttal\n\nI appreciate the additional results in the rebuttal. I raise the score but it is still slightly below the acceptance. The reasons are 1) incremental novelty; 2) insufficient experiments. Also, I found in table 3 that, the larger-capacity model is less robust than the smaller-capacity model against white-box iterative attacks? This is strange.\n']","[90, -50, -20]","[80, 50, 60]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer states that the paper is 'very clear and well written' and the contribution is 'relevant to ICLR'. They list several pros, including clear explanations, fair comparisons, a 'strong and novel contribution', and interesting results. There are no cons mentioned, indicating a highly positive sentiment. The politeness score is 80 because the language used is professional and respectful. The reviewer uses phrases like 'clearly explained' and 'fair comparisons', which are polite ways of giving positive feedback. The tone is objective and constructive throughout, without any harsh or critical language. While not overly effusive, the review maintains a consistently courteous and professional tone."", ""The sentiment score is -50 because while the reviewer acknowledges some 'potentially interesting ideas', they express several major concerns and state that the paper 'needs additional work before it is ready for publication'. This indicates a generally negative sentiment, though not entirely dismissive. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'My main concerns' and 'I feel' which maintain a polite tone while expressing criticism. The reviewer also ends on a somewhat positive note, acknowledging the potential of the ideas presented."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express several concerns and request significant additional experiments and justifications. The overall tone suggests the paper is not quite ready for acceptance in its current form. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases requests as 'I would like to see' rather than demands, and acknowledges the authors' efforts in the rebuttal. The reviewer also provides specific, constructive feedback for improvement rather than harsh criticism.""]"
"[""Summary:\nThe authors present an empirical analysis of how the size of SGD batches affects neural networks' training time.   \n\nStrengths:\nAs mini-batches training is highly popular nowadays, the problem emphasized by the authors may have a high impact in the community. Together with recent analysis on the generalization properties of over-parametrized models, the paper may help understand more general open problems of neural networks' training. A nice contribution of the paper is the observation that different phases of scaling behaviour exist across a range of datasets and architectures.  \n\nWeaknesses:\nBased on empirical evaluation, the paper cannot make any claim about the generality of the obtained results. Even if the authors' analysis is based on a large set of benchmarks, it is hard to asses whether and how the results extend to cases that are not included in Section 4. In particular, it is not clear how the definition of different training phases can help the practitioner to tune the training parameters, as the size and range of the different regimes depend so strongly on the model's architecture and dataset at hand.  \n\nQuestions:\n- have the properties of mini-batches training been explored from a formal/theoretical perspective? do those results match and confirm the proposed empirical evaluation?\n- how are the empirical results obtained in the experiment section expected to depend on the specific dataset/benchmark? For example,  given a particular architecture, what are the key features that define the three training phases (shape of the nonlinearity, number of layers, underlying distribution of the dataset)?\n- what is a  batch size that does not allow one to 'fully utilize our available compute'?\n- does the amount of over-parameterization in the model have any effects on the definition of the training phases? How are the results obtained in the paper linked to the generalization gap phenomenon?"", ""This paper empirically investigates the effect of batch size on the convergence speed of the mini-batch stochastic gradient descent of popular deep learning models. The fact that there is a diminishing return of batch size is not very surprising and there is a well-known theory behind it, but the theory doesn't exactly tell when we will start to suffer from the diminishing return. Therefore, it is quite valuable for the community to have an empirical analysis across popular ML tasks and models. In this regard, however, It would've been even nicer if the paper covered more variety of popular ML models such as Machine Translation, Speech Recognition, (Conditional) Image Generation, etc which open source implementations are readily available. Otherwise, experiments in this paper are pretty comprehensive. The only additional experiment I would be interested in is to tune learning rate for each batch size, rather than using a base learning rate everywhere, or simple rules such as LSR or SRSR. Since the theory only gives us asymptotic form of the optimal learning rate, empirically you should be tuning the learning rate for each batch size. And this is not totally unrealistic, because you can use a fraction of computational time to do cross-validation for searching the learning rate.\n\npros:\n* findings provide us useful direction for future research (that data-parallelism centered distributed training is going to hit the limit soon)\n* extensive experiments across 5 datasets and 6 neural network architectures\n\ncons:\n* experiments are a bit too much focused on image classification\n* error bars in figures could've provided greater confidence in robustness of findings"", 'The work presented relates to the impact batch-size on the learning performances of common neural network architectures.\n\nPro: having comprehensive study of the limit of gradient-based methods is very useful in practice. This work can help practitioner to limit the number of machines used for optimization.\n\nCons: very little can be deduced from these experiments:\n- ""Increasing the batch size beyond a certain point yields no improvement in wall-clock time to convergence, even for a system with perfect parallelism."" was a know fact (they cite Ma et al (2017) who even proved it theoretically.\n- ""Increasing the batch size leads to a significant increase in generalization error, which cannot be mitigated by existing techniques."". It is not clear that all the regularization techniques have been tried by the authors, the increase of generalization error is very small, and there is no explanation or insight given by the authors to explain this phenomenon, making this finding of limited interest.\n- ""Dataset size is not the only factor determining the computational efficiency of large batch training."" is something obvious to say, as there are plenty of factors that determine the computational efficiency (network connection, map-reduce implementation, etc.)\n\nEven the suggestions for future work of the authors in the conclusion does not help much: they suggest to look at ""alternative forms of parallelism"", without citing or giving any clue of what could be such alternative forms. \nAlso, there is no discussion around lock-free\n\nThe authors refer to Ma et al. (2017) for a theoretical analysis of the effect of the batch size, but they skip all the past and very relevant literature on the topic of the effect of the batch size on the convergence. For example, it is recommended to increase the size of the batch size as the iterations increase.\n\nFinally, there is no discussion on the lock-free gradient descent, that is often suggested as an alternative to batching.\n\nIn conclusion, I\'m not convinced there is enough material to accept this paper at the next ICLR conference.']","[50, 60, -70]","[75, 70, 20]","[""The sentiment score is 50 (slightly positive) because the review begins by highlighting the strengths of the paper, noting its potential high impact and nice contribution. However, it also points out significant weaknesses, creating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively where appropriate, and framing criticisms as 'weaknesses' rather than direct attacks. The reviewer also poses questions in a constructive manner, inviting further discussion rather than being dismissive. The language used is professional and objective, without any harsh or rude comments."", ""The sentiment score is 60 (positive) because the reviewer starts by highlighting the value of the paper's empirical investigation, describing it as 'quite valuable for the community'. They also mention 'extensive experiments' as a pro. However, it's not extremely positive due to some criticisms, such as the focus on image classification and suggestions for additional experiments. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'It would've been even nicer if' and 'The only additional experiment I would be interested in' to soften their critiques. The reviewer also balances positive and negative feedback, listing both pros and cons of the paper."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer lists several cons and criticisms, stating that 'very little can be deduced from these experiments' and concluding that they're 'not convinced there is enough material to accept this paper'. The few positive comments are outweighed by the numerous criticisms. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'It is not clear that...' and 'I'm not convinced...' rather than using harsh or rude language. The reviewer also acknowledges some positive aspects ('Pro: having comprehensive study...') before delving into criticisms, which adds to the politeness.""]"
"['\n[Summary]\nThis paper proposed an algorithm for zero-shot translation by using both dual learning (He et al, 2016) and multi-lingual neural machine translation (Johnson et al 2016). Specially, a multilingual model is first trained following (Johnson et al 2016) and then the dual learning (He et al 2016) is applied to the pre-trained model using monolingual data only. Experiments on MultiUN and WMT are carried out to verify the proposed algorithm. \n\n[Details]\n1.\tThe idea is incremental and the novelty is limited. It is a simple combination of dual learning and multilingual NMT. \n\n2.\tMany important multilingual baselines are missing. [ref1, ref2]. At least one of the related methods should be implemented for comparison.\n\n3.\tThe Pseudo NMT in Table 3 should also be implemented as a baseline for MultiUN experiments for in-domain verification.\n\n4.\tA recent paper [ref3] proves that using more monolingual data will be helpful for NMT training. What if using more monolingual data in your system? I think using $1M$ monolingual data is far from enough.\n\n5.\tWhat if using more bilingual sentence pairs? Will the results be boosted? What if we use more language pairs?\n\n6.\tTransformer (Vaswani et al. 2017) is the state-of-the-art NMT system. At least one of the tasks should be implemented using the strong baseline.\n\n[Pros] (+) A first attempt of dual learning and multiple languages; (+) Easy to follow.\n[Cons] (-) Limited novelty; (-) Experiments are not enough.\n\nReferences\n[ref1] Firat, Orhan, et al. ""Zero-resource translation with multi-lingual neural machine translation."" EMNLP (2016).\n[ref2] Ren, Shuo, et al. ""Triangular Architecture for Rare Language Translation."" ACL (2018).\n[ref3] Edunov, Sergey, et al. ""Understanding back-translation at scale.""EMNLP (2018). \n\nI am open to be convinced.\n\n==== Post Rebuttal ===\nThanks the authors for the response. I still have concerns about this work. Please refer to my comments ""Reply to the rebuttal"". Therefore, I keep my score as 5.\n\n', 'Pros:\n- The paper address the problem of zero-shot translation. The proposed method is essentially to bootstrap a Dual Learning process using a multilingual translation model that already has some degree of zero-shot translation capabilities. The idea is simple, but the approach improves the zero-shot translation performance of the baseline model, and seems to be better than either pivoting or training on direct but out-of-domain parallel data.\n- The paper is mostly well written and easy to follow. There are some missing details that I\'ve listed below.\n\nCons:\n- There is very little comparison to related work. For example, related work by Chen et al. [1], Gu et al. [2] and Lu et al. [3] are not cited nor compared against.\n\nMisc questions/comments:\n- In a few places you call your approach unsupervised (e.g., in Section 3: ""Our method for unsupervised machine translation works as follows: (...)""; Section 5.2 is named ""Unsupervised Performance""). But your method is not unsupervised in the traditional sense, since you require lots of parallel data for the target languages, just not necessarily directly between the pair. This may be unrealistic in low-resource settings if there is not an existing suitable pivot language. It\'d be more accurate to simply say ""zero-shot"" (or maybe ""semi-supervised"") in Section 3 and Section 5.2.\n- In Section 3.1 you say that your process implements the three principles outlined in Lample et al. (2018b). However, the Initialization principle in that work refers to initializing the embeddings -- do you pretrain the word embeddings as well?\n- In Section 4 you say that the ""UN corpus is of sufficient size"". Please mention what the size is.\n- In Section 4.2, you mention that you set dropout to p=0.65 when training your language model -- this is very high! Did you tune this? Does your language model overfit very badly with lower dropout values?\n- In Section 5.2, what is the BLEU of an NMT system trained on the es->fr data (i.e., what is the upper bound)? What is the performance of a pivoting model?\n- In Section 5.3, you say you use ""WMT News Crawl, all years."" Please indicate which years explicitly.\n- In Table 3, what is the performance of a supervised NMT system trained on 1M en-fr sentences of the NC data? Knowing that would help clarify the impact of the domain mismatch.\n- minor comment: in Section 4.3 you say that you trained on Tesla-P100, but do you mean Pascal P100 or Tesla V100?\n\n[1] Chen et al.: http://aclweb.org/anthology/P17-1176\n[2] Gu et al.: http://aclweb.org/anthology/N18-1032\n[3] Lu et al.: http://www.statmt.org/wmt18/pdf/WMT009.pdf', 'This paper can be considered as a direct application of dual learning (He et al. (2016)) to the multilingual GNMT model. The first step is to pre-train the GNMT model with parallel corpora (X, Z) and (Y, Z). The second step is to fine-tune the model with dual learning.\n\n1. I originally thought that the paper can formulate the multilingual translation and zero dual learning together as a joint training algorithm. However, the two steps are totally separated, thus the contribution of this paper is incremental. \n\n2. The paper actually used two parallel corpora. In this setting, I suggest that the author should also compare with other NMT algorithm using pivot language to bridge two zero-source languages, such as ``A Teacher-Student Framework for Zero-Resource Neural Machine Translation``. It is actually unfair to compare with the completely unsupervised NMT, because the existence of the pivot language can enrich the information between two zero-resource languages. The general unsupervised NMT is often considered as ill-posed problem. However, with parallel corpus, the uncertainty of two language alignment is greatly reduced, making it less ill-posed. The pivot language also plays the role to reduce the uncertainty.']","[-30, 50, -50]","[50, 75, 0]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('A first attempt', 'Easy to follow'), they express significant concerns about the paper's novelty, experimental rigor, and comparisons to baselines. The overall tone suggests the reviewer is not fully convinced of the paper's merits. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They also express openness to being convinced, which adds a polite tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral professional tone overall."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting pros of the paper, noting that the idea is simple but effective, and the paper is mostly well-written. However, they also point out cons, such as lack of comparison to related work. The overall tone is balanced but leans positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively as questions or suggestions, and acknowledges the paper's strengths. They use phrases like 'Please mention' and 'It'd be more accurate to' rather than making blunt demands. The reviewer also provides helpful references and specific suggestions for improvement, showing engagement with the work."", ""The sentiment score is -50 because the reviewer expresses some disappointment with the paper's contribution, calling it 'incremental' and suggesting that it falls short of what they initially expected. They also point out that the comparison with unsupervised NMT is 'unfair'. However, it's not entirely negative as they do acknowledge the paper's approach and offer constructive suggestions. The politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. They directly state their criticisms and suggestions without using overly harsh language or excessive pleasantries. The review focuses on the content and methodology rather than personal comments, which is appropriate for a scientific peer review.""]"
"['This paper proposed a multi-Level framework for learning node embeddings for large-scale graphs. The author first coarsens the graphs into different levels of subgraphs. The low-level subgraphs are obtained with the node embeddings of the higher-level graphs with a graph convolutional neural network. By iteratively applying this procedure, the node embeddings of the original graphs can be obtained. Experimental results on several networks (including one network with ~10M node) prove the effective and efficiency of the proposed method over existing state-of-the-art approaches.   \n\nStrength:\n- scaling up node embedding methods is a very important and practical problem\n- experiments show that the proposed methods seems to be very effective. \nWeakness:\n- the proposed method seems to be very heuristic\n- some claims in the papers are wrong according to existing literatures\n\nOverall, the paper is well written and easy to follow. The proposed method is simple but heuristic.  However, the performance seems to be quite effective according to the experiments. The reasons that why the method works need to be better explained, which can significantly the quality of the paper and its impact in the future.\n\nDetails:\n-- In the introduction part, ""However, such methods rarely scale to large datasets (e.g., graphs with over 1 million nodes) since they are computationally expensive and often memory intensive"". This is not TRUE! In the paper of LINE (Tang et al. 2015). It shows the LINE model can easily scale up to networks with one million nodes with a few hours. \n-- The authors use Equation (7) to learn the parameters of the graph convolutional neural network. I am really surprised that this method works. Especially the learned parameters are shared across different layers. \n-- Have you tried and compared different approaches of graph coarsening?\n-- In Figure 2. (a), according to Equation (1), in the second step, the weight of the edge between A and DE should be 2/sqrt(3)*sqrt(4)?', 'In this submission, the authors propose a three-stage framework for large-scale graph embedding. The proposed method first constructs a small graph by graph coarsening, then applies any existing graph embedding method, and last refines the learned embeddings. It is useful, however, the experimental results are not convincing and cannot support the authors\' claims about the proposed method.\n\nFirst, in many places, the authors claim that the embedding quality of the proposed method is improved. For example, the last sentence of Section 1, and ""MILE improves quality"" paragraph on Page 7. However, the experimental results fail to support this. As the proposed method is for the large-scale graph, let\'s focus on the results of YouTube dataset and Yelp dataset first. For Youtube dataset ((d) of Table 2), when m is set to be 8, for all the cases, the performance drops. For Yelp dataset (Figure 3), the authors do not provide Micro-f1 for the original graph (m = 0) or m = 1, 2, so it is hard or impossible to demonstrate that the quality of the proposed method is still good. \n\nSecond, the comparison with existing methods is not sufficient. For the most important Yelp dataset (as this dataset fits the motivation scenario (large-scale graph) of this submission), the authors fail to report any comparison. Thus it might not be weak to demonstrate the benefit of the proposed method.\n\nThird, some experiment details are missing. For example, how the authors compute the running time of the proposed method? All the three stages are included? How the authors implement the existing methods? Are these implementations good enough to ensure a fair comparison? \n\n*******\nSome other questions:\na) On page 2, the authors mention that the proposed method ""can be easily extended to directed graph"". However, based on my understanding, directly graph will affect both the graph coarsening and embedding refining steps, and it seems not so easy to extend. Do the authors have the solution and experiments for directed graph? It would be interesting to see such results, which enlarges the application scope of the proposed method.\n\nb) The toy example on page 3 is very clear. However, for real-world graphs, does the proposed graph coarsening work well? For example, one property the proposed method utilizes is ""structurally equivalent"". What is the percentage of the nodes that can have such property for real-world graphs? \n\n********\nSome other comments:\nGenerally speaking, this submission studies a very practical task. Although the authors claim that the proposed method has great efficiency while the embedding quality is comparable good or even better than the existing methods, I think that there is an efficiency-quality trade-off based on the experimental results in this submission. When m increases, the graph coarsening step causes more information loss, and thus the quality may decrease. Embedding refining step can be regarded as a procedure to reduce such information loss, but may not improve the embedding quality better than the original graph. So to me, it would be more meaningful to study such efficiency-quality trade-off for large-scale graph embedding.', 'This paper proposes a multi-level embedding (MILE) framework, which can be applied on top of existing network embedding methods and helps them scale to large scale networks with faster speed. To get the backbone structure of graph, MILE repeatedly coarsens the graph into smaller ones using a hybrid matching technique, and GCN is used for the refinement of embeddings.\n\n[+] The paper is well-written and the idea is clearly presented.\n[+] MILE is able to reduce computational cost while achieving comparable, or sometimes even better embedding quality. \n[+] MILE is general enough to apply to different underlying embedding strategies.\n[-] Most of the baseline methods are of similar type, since LINE, DeepWalk, node2vec and NetMF can all be unified to matrix factorization framework. There have been many new network embedding methods proposed in the past two years. It would be interesting to see how much MILE can help scale these methods.\n\nOverall, though there have already been hundreds of papers on network embedding in the past 2~3 years, I think this paper can be an interesting addition to this fast-growing area. Therefore, I would recommend to accept it.\n']","[50, -50, 70]","[70, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both strengths and weaknesses of the paper, but overall seems to view it favorably. They note that the method is 'very effective' and the paper is 'well written and easy to follow'. However, they also point out some weaknesses and areas for improvement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively. They use phrases like 'need to be better explained' rather than harsh criticism. The tone is professional and constructive, offering specific suggestions for improvement."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's experimental results and claims. They state that the results 'are not convincing and cannot support the authors' claims,' which is a strong negative sentiment. However, the reviewer also acknowledges some positive aspects, such as the usefulness of the method and the clarity of the toy example, preventing the score from being extremely negative. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would be interesting to see' and frame criticisms as questions or suggestions, which is polite. However, the review doesn't go out of its way to be overly courteous, keeping it from scoring higher on politeness."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its strengths and recommending acceptance. The reviewer uses phrases like 'well-written,' 'clearly presented,' and 'interesting addition,' indicating a favorable opinion. However, it's not 100 as there is a minor criticism about the baseline methods. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They balance positive feedback with a suggestion for improvement, and use phrases like 'it would be interesting to see' rather than demanding changes. The overall tone is professional and courteous, without being overly formal or effusive.""]"
"[""The paper proposes a new way of defining CNNs for omnidirectional images. The method is based on graph convolutional networks, and in contrast to previous work, is applicable to other geometries than spherical ones (e.g. fisheye cameras). Since standard graph CNNs are unable to tell left from right (and up from down, etc.), a key question is how to define anisotropic filters. This is achieved by introducing several directed graphs that have orientation built into the graph structure.\n\nThe paper is fairly well written, and contains some new ideas. However, the method seems ad-hoc, somewhat difficult to implement, and numerically brittle. Moreover, the method is not equivariant to rotations, and no other justification is given for why it makes sense to stack the proposed layers to form a multi-layer network. \n\nThe results are underwhelming. Only experiments with small networks on MNIST variants are presented. A very marginal improvement over SphericalCNNs is demonstrated on spherical MNIST. I'm confused by the dataset used: The authors write that they created their own spherical MNIST dataset, which will be made publicly available as a contribution of the paper. However, although the present paper fails to mention it, Cohen et al. also released such a dataset [1], which raises the question for why a new one is needed and whether this is really a useful contribution or only results in more difficulty comparing results. Also, it is not stated whether the 95.2 result for SphericalCNNs was obtained from the authors' dataset or from [1]. If the latter, the numbers are not comparable.\n\nThe first part of section 3.2 is not very clear. For example, L^l is not defined. L is called the Laplacian matrix, but the Laplacian is not defined. It would be better to make this section more self contained.\n\nIn the related work section, it is stated that Cohen et al. use isotropic filters, but this is not correct. In the first layer they use general oriented spherical filters, and in later layers they use SO(3) filters, which allows anisotropy in every layer. Estevez et al. [2] do use isotropic spherical filters.\n\nIn principle, the method is applicable to different geometries than the spherical one. However, this ability is only demonstrated on artificial distortions of a sphere (fig 3), not practically relevant geometries like those found fisheye lenses.\n\nIn summary, since the approach seems a bit un-principled, does not have nice theoretical properties, and the results are not convincing, I recommend against acceptance of this paper in its current form.\n\n\n[1] https://github.com/jonas-koehler/s2cnn/tree/master/examples/mnist\n[2] Estevez et al. Learning SO(3) Equivariant Representations with Spherical CNNs"", 'The paper introduces geometry-aware filters based on constructed graphs into the standard CNN for omnidirectional image classification. Overall, the idea is interesting and the authors propose an extrinsic way to respect the underlying geometry by using tangent space projection. Understanding the graph construction and filter definition is not easy from the text description. It would be better to use a figure to illustrate them. \n\n1) How to define the size of the circular area on the tangent plane? \n\n2) Will the filter change greatly with the definition of the weight function in the neighborhood? Since the point locates on the sphere, why not using the geodesic distance instead of the Euclidean distance? \n\n3) It would be better to directly define the filter on the sphere and make it be intrinsic. The same filter on the tangent space may cover different sizes of regions on the sphere; while we prefer the filter has consistent coverage on the sphere. \n\n4) The paper misses the discussion and comparison to Anisotropic CNN (ACNN) and mixture model network (moNet). \n', 'This paper proposed to use graph-based deep learning methods to apply deep learning techniques to images coming from omnidirectional cameras. It solves the problem of distorsions introduced by the projection of such images by replacing convolutions by graph-based convolutions, with in particular a combinaison of directed graphs which makes the network able to distinguish between orientations.\n\nThe paper is fairly well written and easy to follow, and the need for treating omnidirectional images differently is well motivated. However, since the novelty is not so much in the graph convolution method, or in the use of graph methods for treating spherical signals, but in the combined application of the particular graph method proposed to the domain of omnidirectional images, I would expect a more thorough experimental study of the merits of the method and architectural choices.\n\n1. The projected MNIST dataset looks very localized on the sphere and therefore does not seem to leverage that much of the global connectivity of the graph, although it can integrate deformations. Since the dataset is manually projected, why not cover more of the sphere and allow for a more realistic setting with respect to omnidirectional images?\nMore generally, why not use a realistic high resolution classification dataset and project it on the sphere? While it wouldn\'t allow for all the characteristics of omnidirectional images such as the wrapping around at the borders, it would lead to a more challenging classification problem. Papers such as [Khasanova & Frossard, 2017a] have at least used two toy-like datasets to discuss the merits of their classification method (MNIST-012, ETH-80), and a direct comparison with these baselines is not offered in this work.\n\n2. The method can be applied for a broad variety of tasks but by evaluating it in a classification setting only, it is difficult to have an estimate of its performance in a detection setting, where I would see more uses for the proposed methods in such settings (in particular with respect to rotationally invariant methods, which do not allow for localization).\n\n3. I fail to see the relevance of the experiments in Section 4.2 for a realistic application. Supposing a good model for spherical deformations of a lens is known, what prevents one from computing a reasonable inverse mapping and mapping the images back to a sphere? If the mapping is non-invertible (overlaps), then at least using an approximate inverse mapping would yield a competitive baseline.\nI am surprised at the loss of accuracy in Table 2 with respect to the spherical baseline. Can you identify the source of this loss? Did you retrain the networks for the different deformations, or did you only change the projection of the network trained on a sphere? \n\n4. While the papers describes what happens at the level of the first filters, I did not find a clear explanation of what happens in upper layers, and find this point open to interpretation. Are graph convolutions used again based on the previous polynomial filter responses, sampling a bigger region on the sphere? Could you clarify this?\n\n5. I would also like to see a study of the choice of the different scales used (in particular, size of the neighborhood).\n\nOverall, I find that the paper introduces some interesting points but is too limited experimentally in its current form to allow for a fair evaluation of the merits of the method. Moreover, it leaves some important questions open as to how exactly it is applied (impact of sampling/neighborhood size, design of convolutions in upper layer...) which would need to be clarified and tested.\n\nAdditional small details:\n- please do not use notation $\\mathbb{N}_p$ for the neighborhood, it suggests integers\n- p. 4 ""While effective, these filters ... as according to Eq. (2) filter..."" -> article missing for the word ""filter""\n']","[-60, 20, -20]","[20, 60, 60]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several issues with the paper, including that the method seems 'ad-hoc, somewhat difficult to implement, and numerically brittle', the results are 'underwhelming', and the reviewer ultimately recommends against acceptance. However, it's not entirely negative as the reviewer acknowledges some positive aspects like 'new ideas' and 'fairly well written', hence not the lowest possible score. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'fairly well written' and provide specific, constructive feedback. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer starts by stating that the idea is interesting, which is a positive comment. However, they also point out several areas for improvement and raise questions, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions (e.g., 'It would be better to...'), and asks questions rather than making blunt statements. The reviewer also acknowledges the potential of the work while providing constructive feedback. The language is professional and courteous, without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('fairly well written', 'easy to follow', 'well motivated'), they express several concerns and limitations of the paper. The reviewer states that the experimental study is not thorough enough, questions the relevance of some experiments, and suggests that the paper is 'too limited experimentally in its current form'. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses polite and professional language throughout. They phrase criticisms as suggestions or questions ('why not...?', 'I would expect...', 'Could you clarify...?') rather than direct criticisms. The reviewer also acknowledges positive aspects before presenting critiques, which is a polite approach. However, the score is not extremely high as the review is still direct in its criticisms and doesn't use overly deferential language.""]"
"['This paper proposes an unsupervised method for subgoal discovery and shows how to combine it with a model-free hierarchical reinforcement learning approach. The main idea behind the subgoal discovery approach is to first build up a buffer of “interesting” states using ideas from anomaly detection. The states in the buffer are then clustered and the centroids are taken to be the subgoal states.\n\nClarity:\nI found the paper somewhat difficult to follow. The main issue is that the details of the algorithm are scattered throughout the paper with Algorithm 1 describing the method only at a very high level. For example, how does the algorithm determine that an agent has reached a goal? It’s not clear from the algorithm box. Some important details are also left out. The section on Montezuma’s Revenge mentioned that the goal set was initialized using a “custom edge detection algorithm”. What was the algorithm? Also, what exactly is being clustered (observations or network activations) and using what similarity measure? I can’t find it anywhere in the paper. Omissions like this make the method completely unreproducible. \n\nNovelty:\nThe idea of using clustering to discover goals in reinforcement learning is quite old and the paper does a poor job of citing the most relevant prior work. For example, there is no mention of “Dynamic Abstraction in Reinforcement Learning via Clustering” by Mannor et al. or of “Learning Options in Reinforcement Learning” by Stolle and Precup (which uses bottleneck states as goals). The particular instantiation of clustering interesting states used in this paper does seem to be new but it is important to do a better job of citing relevant prior work and the overall novelty is still somewhat limited.\n\nSignificance:\nI was not convinced that there are significant ideas or lessons to be taken away from this paper. The main motivation was to improve scalability of RL and HRL to large state spaces, but the experiments are on the four rooms domain and the first room of Montezuma’s Revenge, which is not particularly large scale. Existing HRL approaches, e.b. Feudal Networks from Vezhnevets et al. have been shown to work on a much wider range of domains. Further, it’s not clear how this method could address scalability issues. Repeated clustering could become expensive and it’s not clear how the number of clusters affects the approach as the complexity of the task increases. I would have liked to see some experiments showing how the performance changes for different numbers of clusters because setting the number of clusters to 4 in the four rooms task is a clear use of prior knowledge about the task.\n\nOverall quality:\nThe proposed approach is based on a number of heuristics and is potentially brittle. Given that there are no ablation experiments looking at how different choices (number of clusters/goals, how outliers are selected, etc) I’m not sure what to take away from this paper. There are just too many seemingly arbitrary choices and moving parts that are not evaluated separately.\n\nMinor comments:\n- Can you back up the first sentence of the abstract? AlphaGo/AlphaZero do well on the game of Go which has ~10^170 valid states.\n- First sentence of introduction. How can the RL problem have a scaling problem? Some RL methods might, but I don’t understand what it means for a problem to have scaling issues.\n- Please check your usage of \\cite and \\citep. Some citations are in the wrong format.\n- The Q-learning loss in section 2 is wrong. The parameters of the target (r+\\gamma max Q) are held fixed in Q-learning.', 'Summary:\nThe authors propose an HRL system which learns subgoals based on unsupervised analysis of recent trajectories. The subgoals are found via anomaly/outlier detection (in this case states with a very high reward) and the clustering together of states that are very similar. The system is evaluated on the 4-rooms task and on the atari game Montezuma’s Revenge.\n\nThe paper cites relevant work and provides a nice explanation of subgoal-based HRL. The paper is for the most part well-written and easy to follow. \n\nThe experiments are unfortunately not making a very convincing case for the general applicability of the the methods. While the system does not employ a model of the environment, k-means clustering based on distances seems to be particularly well-suited for the two environments investigated in the paper. It is known that the 4-rooms experiment is much easier to solve with subgoals that correspond to the rooms themselves. I can only conclude from this experiment that k-means can find those subgoals given the right number (4) of clusters and injecting the knowledge that distances in grid-worlds correlate well with transition probabilities. Similarly, the use of distance-based clustering seems well-suited for games with different rooms like Montezuma’s Revenge but that might not generalize to many other games. \n\nThe anomaly detection subgoal discovery is interesting as a method to speed-up learning but it still requires these (potentially sparse) high reward states to be found first. For tasks with sparse rewards it does make sense to set high reward states as potential subgoals instead of waiting for value to propagate. That said, the reward for the lower level policy is only less sparse in the sense that wasting time gets punished with a negative reward. Subgoal discovery based on rewards should probably also take the ability of the current policy to obtain those rewards into account like some other methods for subgoal discovery do (see for example Florensa et al., 2018). The authors mention that the subgoals were manually chosen by Kulkarni et al. (2016) instead of learned in an unsupervised way but I don’t think that the visual object detection method employed there is that much more problem specific. \n\nLike Kulkarni et al. (2016), the authors compare their method with DQN (Mnih et al. 2015) but it was already known that that baseline cannot solve the task at all and a lot more results on Montezuma’s Revenge have been published since then. A more insightful baseline would have been to compare with at least some other HRL methods that are able to learn the task to some extend like perhaps Feudal Networks (Vezhnevets et al., 2017). Looking at the graph in the Feudal Networks paper for comparison, the results in this paper seem to be on par with the LSTM baseline there but it is hard to compare this on the basis of the number of episodes. Did the reward go up further after running the experiment longer? \n\nSince the results are not that spectacular and a comparison with prior work is lacking, the main contributions of the paper are more conceptual. I think that it is interesting to think more carefully about how sparse reward states and state similarities can be used more efficiently but the ideas in the paper are not original or theoretically founded enough to have a lot of impact without the company of stronger empirical results.\n\nExtra reference:\nCarlos Florensa, David Held, Xinyang Geng, Pieter Abbeel. (2017). Automatic goal generation for reinforcement learning agents. arXiv preprint arXiv:1705.06366.\n\n', 'This paper proposed a model-free HRL method, which is combined with unsupervised learning methods, including abnormality discovery and clustering for subgoal discovery. In all, this paper studies a very important problem in RL and is easy to follow. The technique is sound. Although the novelty is not that significant (combining existing techniques), it showed good results on Montezuma’ revenge, which is considered as a very challenging  problem for primitive action based RL.\n\nAlthough the results are impressive, I still have some doubt about the generalizability of the method. It might be helpful to improve its significance if more diversified domains can be tested.\n\nThe paper can be strengthen by providing some ablation test, for example, is performance under different K for Kmeans? \n\nAlso some important details seems missing, for example, the data used for kmeans, it is mentioned that the input to the controller is four consecutive frame of size 84x84, so the input data dimension is more than 10k, I guess some further dimensionality reduction technique has to be applied in order to run kmeans effectively.\n\nRegarding the comparisons, the proposed method is only compared with one primitive action based method. It might be better to include results from other HRL methods, such as Kulkarni et al.\n\nIs the curve based on the mean of different runs? It might be useful to include an errorbar to show the statistical significance.\n']","[-60, -30, 50]","[20, 50, 70]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses concerns about clarity, novelty, significance, and overall quality of the paper. They mention difficulties in following the paper, lack of important details, limited novelty, unconvincing significance, and potential brittleness of the approach. However, it's not entirely negative as they acknowledge some new aspects of the work.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone throughout. They use phrases like 'I found', 'I was not convinced', and 'I would have liked to see' which soften the criticism. They also provide specific suggestions for improvement and acknowledge some positive aspects. However, some statements are quite direct in their criticism, which prevents a higher politeness score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The paper cites relevant work and provides a nice explanation'), they express significant concerns about the experiments and results. The reviewer states that the experiments are 'not making a very convincing case' and the results are 'not that spectacular'. They also point out limitations in the methodology and lack of comparison with relevant prior work. However, the score is not extremely negative as the reviewer does recognize some merits of the paper.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The paper is for the most part well-written' and 'It is interesting to think more carefully about...', which show appreciation for the authors' work. Even when expressing criticisms, the language is constructive rather than harsh. For example, they suggest improvements like 'A more insightful baseline would have been...' instead of directly criticizing the chosen baseline. The reviewer also provides additional references, which is helpful. While polite, the review doesn't go out of its way to be overly courteous, hence the score of 50 rather than higher."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the problem, the soundness of the technique, and the impressive results on a challenging problem. However, they also express some doubts about generalizability and suggest improvements, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as possibilities rather than demands. They use phrases like 'it might be helpful' and 'it might be better,' which maintain a courteous tone. The review is professional and focuses on the content without any personal attacks or harsh language.""]"
"['The authors present an OOD detection scheme with an ensemble of generative models. When the exact likelihood is available from the generative model, the authors approximate the WAIC score. For GAN models, the authors compute the variance over the discriminators for any given input. They show that this method outperforms ODIN and VIB on image datasets and also achieves comparable performance on Kaggle Credit Fraud dataset.\n\nThe paper is overall well-written and easy to follow. I only have a few comments about the work.\n\nI think the authors should address the following points in the paper.\n- What is the size of the ensemble for the experiments?\n- How does the size of the ensemble influence the measured performance?\n- It is Fast Gradient Sign Method (FGSM), not FSGM. See [1]. Citing [1] for FGSM would also be appropriate.\n\nQuality. The submission is technically sound. The empirical results support the claims, and the authors discuss the failure cases. \nClarity. The paper is well-written and easy to follow while providing useful insight and connecting previous work to the subject of study.\nOriginality. To the best my knowledge, the proposed approach is a novel combination of well-known techniques.\nSignificance. The presented idea improves over the state-of-the-art.\n\n\nReferences\n[1] I. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and Harnessing Adversarial Examples,” in ICLR, 2015.\n-------------------\nRevision. The rating revised to 6 after the discussion and rebuttal.\n ', '- Novelty is minimal and is well below the level required by ICLR.\n\n- The reasoning lists the problems of GANs and then the fact that GAN ensembles would target that, based on a toy example in Figure 2. \n\n- Why to choose GANs though in the first place? Given the buildup, and given the other well-known training issues about GANs, are they the right choice for the basic modeling units, i.e. the ensemble units, in such case? A GANs adversary bases its comparisons on individual data points, rather than on distribution comparisons or on groups of points like MMD, etc. I understand the reasoning behind the choice of generative models (GMs), but it is choosing GANs out of the set of GMs in this particular case that I am referring to. \n\n- The paper is quite well written. The ideas as well as the reasoning flow very smoothly. \n\n- Experiments are well prepared. \n\nRather minor:\n- page 1: ""When training and test distributions differ, neural networks may provide ..."" This is true but may be a clarification here regarding the fact that the neural networks involved with several modeling problems, e.g. the ones trained for domain adaptation or meta-learning tasks, target this shift or difference in domains, and typically provide a way to tackle this problem.\n\n\n\nUodate: Read the rebuttal. My score remains unchanged. ', 'Note to Area Chair: Another paper submitted to ICLR under the title “Do Deep Generative Models Know What They Don’t Know?” shares several similarities with the current submission.\n\nThis paper highlights a deficiency of current generative models in detecting out-of-distribution based samples based on likelihoods assigned by the model (in cases where the likelihoods are well-defined) or the discriminator distribution for GANs (where likelihoods are typically not defined). To remedy this deficiency, the paper proposes to use ensembles of generative models to obtain a robust WAIC criteria for anomaly detection.\n\nMy main concern is with the level of technical rigor of this work. Much of this has to do with the presentation, which reads to me more like a summary blog post rather than a technical paper.\n- I couldn’t find a formal specification of the anomaly detection setup and how generative models are used for this task anywhere in the paper.\n- Section 2 seems to be the major contribution of this work. But it was very hard to understand what exactly is going on. What is the notation for the generative distribution? Introduction uses p_theta. Page 2, Paragraph 1 uses q_theta (x). Eq. (1) uses p_theta and then the following paragraphs use q_theta.\n- In Eq. (1), is theta a random variable?\n- How are generative ensembles trained?  All the paper says is “independently trained”. Is the parameter initialization different? Is the dataset shuffling different? Is the dataset sampled with replacement (as in bootstrapping)?\n- “By training an ensemble of GANs we can estimate the posterior distribution over model deciscion boundaries D_theta(x), or equivalently, the posterior distribution over alternate distributions q_theta. In other words, we can use uncertainty estimation on randomly sampled discriminators to de-correlate the OoD classification errors made by a single discriminator” Why is the discriminator parameterized by theta? What is an ensemble of GANs? Multiple generators or multiple discriminators or both? What are “randomly sampled discriminators”? What do the authors mean by ""posterior distribution over alternate distributions""?\n\nWith regards to the technical assessment, I have the following questions for the authors:\n- In Figure 1, how do the histograms look for the training distribution of CIFAR? If the histograms for train and test have an overlap much higher than the overlap between the train of CIFAR and test set of any other distribution, then ensembling seems unnecessary and anomaly detecting can simply be done via setting a maximum and a minimum threshold on the likelihood for a test point. In addition to the histograms, I\'d be curious to see results with this baseline mechanism.\n- Why should the WAIC criteria weigh the mean and variance equally?\n- Did the authors actually try to fix the posterior collapse issue in Figure 3b using beta-VAEs as recommended? Given the simplicity of implementing beta-VAEs, this should be a rather easy experiment to include.\n\nMinor typos:\n- ODIN and VIB are not defined in the abstract\n- Page 3: “deciscion”\n- Page 2, para 2: “log_\\theta p(x)”']","[80, -60, -50]","[90, 50, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, stating it is 'well-written and easy to follow' and that it 'improves over the state-of-the-art'. The reviewer also notes that the 'empirical results support the claims' and the submission is 'technically sound'. The few comments and suggestions are presented as minor improvements rather than major criticisms. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions in a non-demanding way ('I think the authors should address...') and provide positive feedback alongside the suggestions. The reviewer also acknowledges the authors' work in discussing failure cases and connecting to previous work. The language is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is -60 because the review is predominantly negative, highlighting minimal novelty and questioning the choice of GANs. The reviewer states that the novelty is 'well below the level required by ICLR' and raises concerns about the fundamental approach. However, it's not entirely negative as the reviewer acknowledges that the paper is well-written and the experiments are well-prepared. The politeness score is 50 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I understand the reasoning' and offer specific points for improvement. The language is not overly harsh or rude, but maintains a respectful tone throughout. The reviewer also acknowledges positive aspects of the paper, which contributes to the polite tone."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the technical rigor and presentation of the paper, stating it reads 'more like a summary blog post rather than a technical paper'. They list several major issues with notation, methodology explanations, and experiment details. However, the score is not lower because the reviewer does acknowledge the paper's contribution in highlighting a deficiency in current generative models. The politeness score is 20 because while the reviewer is direct in their criticisms, they phrase most comments as questions or suggestions rather than harsh statements. They use polite language like 'My main concern is...' and 'I'd be curious to see...'. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score.""]"
"[""The paper presents an unsupervised sentence encoding method based on automatically generating inconsistent sentences by applying various transformations either to a single sentence or a pair and then training a model to classify the original sentences from the transformed ones.\n\nOverall, I like the paper as it presents a simple method for training unsupervised sentence models which then can be used as part of further NLP tasks.\n\nA few comments on the method and results:\n\n- The results on Table 2 shows that supervised methods outperform unsupervised methods as well as the consistency based models with MultiTask having the largest margin. It would've been interesting to experiment with training multi-task layers on top of the sentence encoder and see how it would've performed.\n- The detail of the architecture is slightly missing in a sense that it's not directly clear from the text if the output of the BiLSTMs is the final sentence encoding or the final layer before softmax?\n- Also I would've thought that the output of LSTMs passed through nonlinear dense layers but the text refers to two linear layers.\n- When I first read the paper, my eyes were looking for the result when you combine all of the transformations and train a single model :) - any reason why you didn't try this experiment?\n- The paper is missing comparison and reference to recent works on universal language models (e.g. Radford et al 2018, Peters et al 2018, Howard et al 2018) as they rely on more elaborate model architectures and training compared to this paper but ultimately you can use them as sentence encoders. \n- One final note, which could be a subsequent paper is to treat these transformations as part of an adversarial setup to further increase the robustness of a language model such as those mentioned previously."", 'This submission presents a model for self-supervised learning of sentence representations. The core idea is to train a sentence encoder to predict sequence consistency. Sentences from a text corpus are considered consistent (positive examples), while simple editions of these make the negative samples. Six different ways to edit the sequence are proposed. The network is trained to solve this binary classification task, separately for all six possible editions.\nThe proposed approach is evaluated on SentEval giving encouraging results.\n\n+ The proposed approach is interesting. It is similar in some sense to the self-supervised representation learning literature in computer vision, where the network is trained to say- predict the rotation applied to the image.\n\n- If one considers that sentence encoders can be trained using a pretext task, this paper lacks a very-simple-yet-hard-to-beat baseline. Unlike for images, natural language has a very natural self-supervised task: language modeling. Results reported for language-modeling-based sentence representations outperform results reported in the tables by a big margin. Here is at least one paper that would be worth mentioning:\n- Radford, Alec, Rafal Jozefowicz, and Ilya Sutskever. ""Learning to generate reviews and discovering sentiment."" arXiv preprint arXiv:1704.01444 (2017). \nIn order to make things comparable, it would be good to provide reference numbers for an LSTM trained with a LM objective on the same data as the experiments in this paper.\n\n- If I understood correctly, all variants are trained separately (for each of the 6 different ways to edit the sequence). This makes the reading of the results very hard. Table 2 should not contain all possible variants, but one single solution that works best according to some criterion. \nTo this end, why would these models be trained separately? First of all, the main result could be an ensemble of all 6, or the model could be made multi-class, or even multi-label, capable of predicting all variants in a single task.\n\nOverall, I think that this paper proposes an interesting alternative for training sentence representations. However, the execution of the paper lacks in several respects outlines above. Therefore, I lean towards rejection, and await the other reviews, comments and answer from the authors to make my final decision.', ""\n== Clarity == \nThe primary strength of this paper is the simplicity of the approach.\n\nMain idea #1: corrupt sentences (via random insertions/deletions/permutations), and train a sentence encoder to determine whether a sentence has been corrupted or not.\n\nMain idea #2: split a sentence into two parts (two different ways to do this were proposed). Train a sequence encoder to encode each part such that we can tell whether the two parts came from the same sentence or not.\n\nI can see that this would be very easy for others to implement, perhaps encouraging its adoption.\n\n== Quality of results ==\nThe proposed approach is evaluated on the well-known SentEval benchmark.\n\nIt generally does not outperform supervised approaches such as InferSent and MultiTask. However, this is fine because the proposed approach uses no supervised data, and can be applied in domains/languages where supervised data is not available.\n\nThe approach is competitive with existing state-of-the-art sentence representations such as QuickThoughts. However, it is not definitively better:\n\nOut of the 9 tasks with results for QuickThoughts, this approach (ConsSent) performs better on 3 (MPQA +0.1%, TREC +0.4%, MRPC +0.4%). For the other 6 tasks, ConsSent performs worse (MR -1.8%, CR -1.7%, SUBJ -1%, SST -3.8%, SK-R, -2.4%). Taken together, the losses seem to be larger than the gains.\n\nFurthermore, the QuickThoughts results were obtained with a single model across all SentEval tasks. In contrast, the ConsSent approach requires a different hyperparameter setting for each task in order to achieve comparable results -- there is no single hyperparameter setting that would give state-of-the-art results across all tasks.\n\nThe authors also evaluate on the newly-released linguistic probing tasks in SentEval. They strongly outperform several existing methods on this benchmark. However, it is unclear why they did not compare against QuickThoughts, which was the strongest baseline on the original SentEval tasks.\n\n== Originality ==\nThe proposed approach is simple and straightforward. This is on the whole a great thing, but perhaps not especially surprising from an originality/novelty perspective.\n\nTherefore, the significance and impact of this approach really needs to be carried by the quality of the empirical results.\n\nThe sentence pair based approaches (ConsSent-N and C) are conceptually interesting, but don't seem to be responsible for the best results on the linguistic probing tasks.\n\n== Conclusion ==\n\nPros:\n- conceptual simplicity\n- competitive results (better than many previous unsup. sentence representation methods, excluding QuickThoughts)\n- strong results on SentEval's linguistic probing task\n\nCons:\n- no single hyperparameter value (perturbation method and value for k) gets great results across all tasks\n- some important baselines possibly missing for linguistic probing tasks""]","[70, -20, 20]","[80, 50, 60]","[""The sentiment score is 70 (positive) because the reviewer starts by saying they 'like the paper' and describes it as presenting a 'simple method' that can be used in further NLP tasks, which is generally positive. However, it's not extremely positive as the reviewer also provides several suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their comments as suggestions rather than criticisms (e.g., 'It would've been interesting...', 'I would've thought...'), and even suggests potential future work. The reviewer maintains a constructive tone, balancing praise with thoughtful recommendations for enhancement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the approach as 'interesting' and 'encouraging', they ultimately 'lean towards rejection'. They point out several significant shortcomings and areas for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with positive remarks. They use phrases like 'interesting approach' and 'encouraging results', and frame criticisms as suggestions for improvement rather than harsh judgments. The reviewer also indicates openness to changing their opinion based on author responses and other reviews, which adds to the polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges some strengths of the paper (simplicity, competitive results, strong performance on linguistic probing tasks), they also point out several limitations (not outperforming supervised approaches, inconsistent performance across tasks, lack of single optimal hyperparameter). The overall tone suggests cautious approval rather than strong enthusiasm or criticism. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout, balancing praise with constructive criticism. They use neutral language to describe shortcomings (e.g., 'it is unclear why...') rather than harsh or accusatory statements. The review is structured to highlight both pros and cons, demonstrating a fair and balanced approach.""]"
"['Title: DADAM: A consensus-based distributed adaptive gradient method for online optimization\n\nSummary: \n\nThe paper presented DADAM, a new consensus-based distributed adaptive moment estimation method, for online optimization. The author(s) also provide the convergence analysis and dynamic regret bound. The experiments show good performance of DADAM comparing to other methods. \n\nComments: \n\n1) The theoretical results are nice and indeed non-trivial. However, could you please explain the implication to equation (7a)? Does it have absolute value on the LHS? \n\n2) Can you explain more clearly about the section 3.2.1? It is not clear to me why DADAM outperform ADAM here. \n\n3) Did you perform algorithms on many runs and take the average? Also, did you tune the learning rate for all other algorithms to be the best performance? I am not sure how you choose the parameter \\alpha here. What if \\alpha changes and do not base on that in Yuan et al. 2016? \n\n4) The deep learning experiments are quite simple. In order to validate the performance of the algorithm, it needs to be run on more datasets and networks architectures. MNIST and CIFAR-10 and these simple network architectures are quite standard. I would suggest to provide more if the author(s) have time. \n\nIn general, I like this paper. I would love to have discussions with the author(s) during the rebuttal period. \n', 'This paper presents a consensus-based decentralized version of the Adam algorithm for online optimization. The authors consider an empirical risk minimization objective, which they split into different components, and propose running a separate online optimization algorithm for each component, with a consensus synchronization step that involves taking a linear combination of the parameters from each component before applying each component\'s individual parameter update. The final output is a simple average of the parameters from each component. \n\nThe authors study the important problem of distributed optimization and focus on adapting existing state-of-the-art methods to this setting. The algorithm is clearly presented, and to the best of my knowledge, original. The fact that this work includes both theoretical guarantees for the convex and non-convex settings as well as numerical experiments strengthens the contribution.\n\nOn the other hand, I didn\'t find the actual method presented by the authors to be motivated very well. The main innovation with respect to the standard Adam/AMSGrad algorithm is the use of a mixing matrix W, but the authors do not discuss how the choice of this matrix influences the performance of the algorithm or how one should specify this input in practice. This seems like an important issue, especially since all of the bounds depend on the second singular value of this matrix. Moreover, arguments such as Corollary 10 do not actually imply that DADAM outperforms ADAM when this singular value is large, making it difficult to assess the impact of this work. The numerical experiments also do not test for the statistical significance of the results. \n\nThere are also many typos that make the submission seem relatively unpolished.\n\nSpecific comments:\n1. page 1: ""note only"". Typo.\n2. page 2: ""decentalized"". Typo.\n3. page 2: ""\\Pi_X[x]. If \\Pi_X(x)...."" Inconsistent notation.\n4. page 3: ""largest singular of matrix"". Typo.\n5. page 3: ""x_t* = arg min_{x \\in X} f_t(x)"". f_t isn\'t defined in up to this point.\n6. page 4: ""network cost is then given by f_t(x) = \\frac{1}{n} \\sum_{i=1}^n f_{i,t}(x)"" Should the cost be  \\frac{1}{n} \\sum_{i=1}^n f_{i,t}(x_{i,t})? That would be more consistent with the definition of regret presented in Reg_T^C. \n7. page 4: ""assdessed"". Typo.\n8. page 4: "" Reg_T^C := \\frac{1}{n} \\sum_{i=1}^n \\sum)_{t=1}^T f_t(x_{i,t})..."" Why is this f_t and not f_{i,t}?\n9. page 4: ""\\hat{v}_{i,t} = v_3 ..."" You should reference how this assignment in the algorithm relates to the AMSGrad algorithm. Moreover, you should explain why you chose to use a convex combination in the assignment instead of just the max.\n10. page 5: Definition 1. This calculation should be derived and presented somewhere (e.g. in the appendix).\n11. page 5: Assumption 3. The notation for the stochastic gradient is not very clear and easily distinguishable from the notation for the deterministic gradient.\n12. page 5: Theorem 4. D_T can be very large in the bound, which would make the upper bound meaningless. Can you set hyperparameters in such a way to minimize it? Also, what is the typical size of \\sigma_2(W) that one would incur?\n13. page 6: Remark 6. This remark seems misleading. It ignores the log(T) and D_T terms, both of which may dominate the data dependent arguments.\n14. page 6: ""The update rules \\tilde{v}_{i,t}..."". \\tilde{v}_{i,t} is introduced but never defined.\n15. page 6: Last display equation. The first inequality seems like it can be an equality.\n16. page 7: Equation (14). Doesn\'t the presence of \\sigma_2(W) imply that the O(1/T) term may not be negligible? It would also be helpful to give some examples of how large T needs to be in (15a) and (15b) in order for this statement to take effect.\n17. page8: ""distributed federated averaging SGD (FedAvg)"". What is the reference for this? It should be included here. It should probably also be mentioned in the introduction as related work.\n18. page 9: Figure 1. Without error bars, it is impossible to tell the statistical significance of these results. Moreover, how sensitive are these results to different choices of hyperparameters?\n19. page 9: ""obtain p coefficients"". What is p in these experiments?\n20. page 9: Metropolis constant edge weight matrix W"". What is \\sigma_2(W) in this case?\n21. page 10: Acknowledgements. This shouldn\'t be included in the submission.\n\n\n\n\n \n\n\n\n\n\n\n\n  ', 'The proposed DADAM is a sophisticated combination of decentralized optimization and the adaptive moment estimation. DADAM enables data parallelization as well as decentralized computation, hence suitable for large scale machine learning problems. \n\nCorollary 10 shows better performance of DADAM. Besides the detailed derivations, can the authors intuitively explain the key setup which leads to this better performance?\n\nThe experimental results are mainly based on sigmoid loss with simple constraints. The results will be more convincing if the authors can provide studies on more complex objective, for example, regularized loss with both L2 and L1 bounded constraints.  \n\nTh experimental results in Section 5.1 is based on \\beta_1 = \\beta_2 = \\beta_3 = 0.9. From  the expression of \\hat v_{i,t} in Section 2, this setting implies the most recent v_{i,t} plays a more important role than the historical maximum, hence ADAM is better than AMSGrad. I am curious what the results will look like if we set \\beta_3 as a value smaller than 0.5. ']","[70, -20, 60]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, stating 'I like this paper' and 'The theoretical results are nice and indeed non-trivial'. They also show interest in further discussion during rebuttal. However, it's not 100 as they do provide several critiques and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases critiques as questions or suggestions rather than demands (e.g. 'Could you please explain...', 'I would suggest...'), and ends on a positive note expressing interest in further discussion. The tone is consistently professional and constructive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The algorithm is clearly presented, and to the best of my knowledge, original'), they also express significant concerns about the motivation, practical implications, and overall polish of the work. The reviewer points out several issues, including lack of motivation for the method, unclear influence of the mixing matrix W, and numerous typos, which contribute to the negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They balance criticism with positive feedback, use phrases like 'to the best of my knowledge' to avoid sounding overly critical, and provide specific, detailed feedback to help the authors improve their work. The reviewer also uses polite language when pointing out issues, such as 'I didn't find' instead of more direct criticism. However, the score is not extremely high as the review is still quite direct in its criticism and doesn't use overly deferential language."", ""The sentiment score is 60 (positive) because the reviewer begins by praising the proposed DADAM as 'sophisticated' and 'suitable for large scale machine learning problems'. They also mention that Corollary 10 shows better performance. However, the score is not higher because the reviewer suggests improvements and asks for additional experiments, indicating some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing suggestions as requests ('can the authors...') rather than demands. They also express curiosity about potential results, showing engagement with the work. The tone is consistently professional and constructive, without any harsh criticism.""]"
"['This paper aims to distinguish between networks which memorize and those with generalize by introducing a new detection method based on NMF. They evaluate this method across a number of datasets and provide comparisons to both PCA and random ablations (as in Morcos et al., 2018), finding that NMF outperforms both. Finally, they show that NMF is well-correlated with generalization error and can be used for early stopping. \n\nThis is an overall excellent paper. The writing is clear and and focused, and the experiments are careful and rigorous. The discussion of prior work is thorough. The question of how to detect memorization in DNNs is one of great interest, and this makes nice steps towards this goal. As such, it will likely have significant impact.  \n\nMajor comments:\n\n1) The early stopping section could benefit from more experiments. In particular, it would be helpful to see a scatter plot of the time of peak test loss as a function of NMF/Ablation AuC local maxima and to measure the correlation between these rather than simply showing 3 examples.\n\nMinor comments: \n\n1) While the comparisons to random ablations are mostly fair, it is worth noting that the variance on random ablations appears to be lower than that of NMF and PCA. \n\n2) The error bars on the plots are often hard to see. Increasing the transparency somewhat would be helpful.\n\nTypos: \n\n1) Section 1, third paragraph: “We show that networks that networks that generalize…” should be “We show that networks that generalize...”\n\n2) Section 3.1, third paragraph: “Because threshold is the…” should be “Because thresholding is the…”\n\n3) Section 3.2, third paragraph: “In the most non-linear case we would…” should be “In the most non-linear case, we would…”\n\n4) Figure 2 caption: “...with increasing level of…” should be “...with increasing levels of…”\n\n5) Section 4.1.1, second to last line of last paragraph: missing space before final sentence\n\n6) Figure 4a label: “Fahsion-MNIST” should be “Fashion-MNIST”\n', 'This paper propose a new way of analyzing the robustness of neural network layers by measuring the level of ""non-linearity"" in the activation patterns on samples belonging to the same class, and correlate that to the level of ""memorization"" and generalization.\n\nMore specifically, the paper argues that a good representation cluster all the samples in a class together, therefore, in higher layers, the activation pattern of samples from the same class will be almost identical. In this case, the activation matrix will have a small non-negative rank. An approximation algorithm (via non-negative matrix factorization) is then used to compute the robustness and evaluate the robustness (by replacing the activation matrix with its low rank non-negative activation) is measured in a number of experiments with different amount of random label corruptions. The experiments show that networks trained on random labels are less robust than networks trained on true labels.\n\nWhile the concept is interesting, I find the arguments in the paper a bit vague, and the usefulness of the algorithm might be hampered by its computation complexity, which is not discussed in the paper.\n\nFirst of all, the paper lacks a clear notion of ""memorization"". While it is generally accepted that learns on random labels can be called ""memorization"", the paper seem to be defining it as how well is the network clustering points from the same class. Several questions need to be addressed in order for this notion to be justified:\n\n1. Are (well generalized) networks really clustering samples of the same class to a centroid? It would be great if some empirical verifications are shown. Because the networks are using linear classifier in the last layer to classify the samples, it seems only linearly separability would be suffice for the work, which does not necessarily imply clustering.\n\n2. Given two networks (of the same architecture), assume somehow network-1 decides to use the first 9 layers to compute a well clustered representation, while network-2 decides to use the first 5 layers to do the same thing. Do we say network-1 is (more) memorizing in this case?\n\n3. The notion seems to be more about the underlying task than about the networks. Given the measurement, if a task is more complicated, meaning the input samples in the class have higher variance and requiring more efforts to cluster, then it seems the network will be doing more memorization. In other words, while networks will be doing more memorization when comparing a random label task to a true label task, it might also be ""doing more memorization"" when comparing learning on imagenet to learning on MNIST / CIFAR. One the one hand, this does not seem to fit our ""intuition"" about memorization; on the other hand, the heavy dependency on the underlying data distribution makes it difficult to compare results learned on different data -- especially since the measurements are based on per-class samples, ""random labels"" and ""true labels"" have very different class-conditional distributions.\n\nI also have some questions about Figure 2(c). I will continue numbering the question for easier discussion.\n\n4. Why for all cases, the lower layers all have higher AUC than the higher layers (except the last one)? The argument given in the paper is that the lower layers are the feature extraction phase while the upper layers are memorization phase. I think if clearly verified, this is a very interesting observation. But the paper currently do not have experiments to verify the hypothesis. Also more studies on this with different networks would be good. For example, with deeper networks, does the feature extraction phase include more layers?\n\n5. The p=1 and p<1 curves seem to be very different. If one is to sample more densely between p=0.8 and p=1, would there still be a clear phase transition?\n\nSome other questions:\n\n6. Can you add discussions to the computation requirements for the proposed analysis? This is especially important for the cases where the analysis is used during training as tools to help deciding early stopping.\n\n7. For the early stopping experiment, the main text says ""These include the test error (in blue)"" while in the figure the label axis is ""Test loss"". I\'m assuming it is the cross entropy loss given the values are greater than 1. In this case, can you show in parallel the same plots in error rate, as the test error is more important than the test loss and the test loss could sometimes be artificially huge due to high confident mistakes on ambiguous test examples.\n\nSome minor issues:\n\n* Please proof read the paper for typos. E.g. on the 3rd paragraph of the 1st page: ""that networks that networks that"".\n\n* The convention with subplots seem to be putting sub-captions under the figures, not above.\n', 'The contribution of the paper is in proposing a quantitative measure of memorization based on the assumption that the activations at the deeper layers of a *generalizing* deep network should be invariant to intra-class variations. The measure corresponds to how well can the activation matrix of a batch be approximated by a low-rank decomposition. The paper proposes to use approximate non-negative matrix factorization and compares it to PCA. As for “wellness” it uses the final accuracy of the network after the activation is approximated in some layer(s).\n\nThe composition of the paper and its writing makes it an easy read. The work is novel in the way it proposes to measure memorization to the best of the reviewer’s knowledge. However, the novel insights and/or the practical usefulness of the proposed method seem very limited. Also, there are many questions that comes to my mind that I would appreciate the authors to address:\n\nSpecific questions:\nThe experimental setup is unclear:\nIs the linearization-batch taken from the training set or the test set?\nIf it is taken from the training set, for the case that p>0 (noisy labels), is the batch of a single class obtained from noisy labels or non-noisy labels? \nFor the experiments, is there only one fixed batch used? How is this batch selected? How sensitive the evaluation is to the selection of the batch members and its size?\nDo the batches cover the whole set?\n\n- Figure 2.a and 2.b: How come all networks with different label noise levels end up with the same (100%?) accuracy? Are the fixed samples different for each p? (class labels change for each p).\n\n- Figure 2.c: Why should the performance drop more when linearizing the middle layers (3_2:4_2) than the earlier layers. This seems to be in violation of the assumption about class invariance in deeper layers.\n\n- When k=1 for NMF and PCA, the difference of the activations for different samples becomes a matter of scale. In this case, shouldn’t all classifications become the same for all samples? How does this affect the accuracy? Does it make the evaluation very sensitive to the sampling of the batch? It would be interesting to study the property of the basis obtained in this border case. The same questions can be studied as one gradually increases k.\nSection 4.2: It starts with the sentence “In this section we show our technique is useful for predicting good generalization in a more realistic setting“. Indeed, the high correlation of the test performance and the proposed memorization measure in this section is very interesting. However, as for usefulness, it does not seem to provide a better criterion for early stopping or other practicalities of ReLU networks. \n\n- An experiment describing how well are the approximations (i.e. activation matrix reconstruction error) and how that correlate with memorization is missing.\n\nSome general questions that come to my mind:\n\n- the paper assumes (e.g. in page 4) that “When single-class batches are not approximately linear, even in deep layers, we take this as evidence of memorization”. I have a concern here. Apart from the last layer, this form of simplicity of the support for the intermediate layers of a good classifier does not seem to be *necessarily*. That is, it seems to me that as long as the activation matrix of each class is linearly separable from the activation matrices of the others, there is no need for it to become simpler (by reducing the intra-class variations at the deep layers) for the classification loss to be minimized. Does this mean the paper’s assumption for memorization is not necessarily valid?\n\n- The paper relates the memorization to the extent of local linearity of a deep ReLU network. ReLU networks represent piece-wise linear functions. Thus, in order for this relation to be drawn, probably different linear regions (polytopes in the input space) should be considered for the linearization of the activation matrix. In that regard, how can this empirical measurement be translated into a more formal linearity of the global function?\n\n- The rc number as well as the rank k of a good approximation directly depend on the number of samples in the batch. How can one obtain a measure that is independent of the number of samples in the batch?\n\n\nSummary judgment:\n\nThe paper puts forward an interesting observation using a novel approach. However there are questions about the experiments, discussions around the experiments and the usefulness of the observation for training better models and/or giving additional insights to what we know. Considering that, I think the paper would make a very good workshop paper but needs more work to address the bar of an ICLR conference paper. But I am open to discussion with the authors and other reviewers.']","[90, -20, -20]","[80, 60, 60]","[""The sentiment score is 90 because the reviewer describes the paper as 'overall excellent' with 'clear and focused' writing and 'careful and rigorous' experiments. They also mention that the paper will likely have 'significant impact'. The high positive sentiment is only slightly tempered by a few suggestions for improvement. The politeness score is 80 because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They acknowledge the paper's strengths before providing recommendations, and even minor comments and typo corrections are presented in a helpful manner. The language is professional and courteous, though not excessively formal or deferential, hence the score of 80 rather than 100."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the concept interesting, they express several concerns and criticisms about the paper's arguments, methodology, and clarity. The reviewer points out vague arguments, potential issues with the notion of 'memorization', and questions about the experimental results. However, the tone is not entirely negative, as the reviewer acknowledges the interesting concept and provides constructive feedback. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions rather than direct attacks, and offers detailed feedback to help improve the paper. The reviewer maintains a professional tone, uses phrases like 'it would be great if' and 'can you add discussions', and provides numbered points for easy reference, all of which contribute to a polite and constructive review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's novelty and readability, they express significant concerns about its practical usefulness and insights, suggesting it would be more suitable as a workshop paper rather than an ICLR conference paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and expresses openness to discussion. They phrase criticisms as questions or suggestions rather than harsh statements. The reviewer also uses polite phrases like 'I would appreciate' and 'to the best of the reviewer's knowledge', maintaining a professional and courteous tone even while expressing concerns.""]"
"['###### Post-Revision ########################\nThank you for revising the paper and addressing the reviewers\' concerns. The updated version reads much better and I have updated my score. \n\nUnfortunately, I still think that the experimental analysis is not enough to warrant acceptance. I would encourage the authors to have a more detailed set of experiments to showcase the effectiveness of their method and have ablation studies to disentangle the effects of the different moving parts. \n###### Post-Revision ########################\n\nThis paper considers arranging the examples into mini-batches so as to accelerate the training of metric embeddings. The\n- The paper doesn\'t have sufficient experimental evidence to convince me that the proposed method is useful. There is no comparison against baselines. The paper is not clearly written or well organized. Detailed comments below:\n- For example, when introducing focus and context entities, it would be helpful to give examples of this to make it clearer. \n- In section 3, please clarify that after drawing both positive and negative examples, what is the size of the minibatch for which the gradient is calculated? \n- How do you choose the size of the microbatches? If the microbatch size is too small, then the effect of associating examples is small. \n- In the line, ""Instead, we use LSH modules that are available at the start of training and are only a coarse proxy of the target similarity"" Why are you not iteratively refining the LSH modules as the training progresses? Won\'t this lead to an improvement in the performance? \n- In the line ""The coarse embedding can come from a weaker (and cheaper to train) model or from a partially-trained model. In our experiments we use a lower dimension SGNS model."" Could you please clarify what is the additioanal computational complexity of the method? This involves additional computational cost? It doesn\'t seem to me that the results justify this increased computation. Please justify this. \n- In Lemma 3.2, the term s_i is undefined\n- ""In early training, basic coordinated microbatches with few or no LSH refinements may be most effective. As training progresses we may need to apply more LSH refinements. Eventually, we may hit a regime where IND arrangements dominate."" This explanation is vague and has no theoretical or empirical evidence supporting it. Please clarify this. \n- Please fix the size of the axes and the legend in all the figures. \n- For figure 1, how is the step-size chosen? What is the dimensionality of the examples?\n- From figure 3, it is not clear that the proposed methods lead to significant gains over the independently sampling the examples? Are there any savings in the wall clock time for the proposed methods? Why is there no comparison against other methods that have proposed non-uniform sampling of examples for SGD (like Zhang, 2017)? Are the hyper-parameters chosen in a principled way for these experiments? ', 'This paper proposes using structured mini-batches to speed up learning of embeddings. However, it lacks sufficient context with previous work and bench-marking to prove the speed-up. Furthermore, it is difficult to read due to its lack of revision. Sentences are wordy and do not always have sufficient detail. \n\nArgument issues and questions:\n- Since the main claim is a speed-up in training, the authors should support with robust experimentation. Only a synthetic and small test are conducted. \n- Not being an expert in this subject, it was difficult to follow some of the ideas of the paper. They were presented without clear explanation of why they supported the conclusion. For example,  I do not understand Figure 4. It seems COO and IND change places. It is not always clear how the figures support the argument. \n- What impact does the size of the micro-batch have on the speed-up? \n- How does this approach compare to other embedding approaches in terms of speed? There are no benchmarks other than IND. \n\nFormatting issues:\n- On page one, the sentence ""We make a novel case here for the antithesis of coordinated arrangements,\nwhere corresponding associations are much more likely to be included in the same minibatch"" seems contradictory. It reads that you are arguing for ""the antithesis of coordinated arrangements, namely independent arrangements"" when you mean ""the antithesis of independent arrangements, namely coordinated arrangements.""\n- The figures in this paper are all very small with minuscule text and legends. Only after zooming in 200% were they legible. Figure 3, 4, 5, 6, and 7 have no axis labels. It is sometimes clear from the caption what the axes are, but it is hard to follow. \n- Often references are cited in the text without being set off with parentheses or grammatical support. For example at the top of page three: ""One-sided updates were introduced with alternating minimization Csiszar & Tusnády (1984) and for our purposes they facilitate coordinated arrangements and allow more precise matching of corresponding sets of negative examples to positive ones."" This interrupts the sentence making it hard to read. \n\n\n\n\n\n', 'This paper discussed a non-uniform sampling strategy to construct minibatches in SGD for the task of learning embeddings for object associations. An example throughout the paper is learning embeddings for a set F of focus entities and set C of context entities. In general, for focus update, the algorithm draws for each minibatch certain amount of positive samples (i,j), i \\in F and j \\in C. Then for each positive pair, we select certain amount of negative samples (i,j’) for j’ \\in some uniformly randomly selected subset C’. The same algorithm is implemented for context update, and the training alternates between the two. The authors choose similar positive object in one minibatch since it’s more efficient. Therefore, LSH hashing is used to point similar items to similar keys. Two similarity measures are used here, Jaccard similarity and cosine similarity. Some experiments are demonstrated on synthetic data and two real datasets to show the effectiveness of their method.\n\nConcerns:\n1.\tEvery piece of the method has been well studied, and the combination of them proposed in this paper does not seem very novel.\n2.\tAlgorithm 4, which is the hashing for Jaccard similarity, seems wrong. Only using iid exponentials cannot make collision probability equal Jaccard similarity.\n3.\tLittle experiments on real datasets. No comparison with other non-uniform minibatch construction methods (there should be some).\n4.\tNo quantitative analysis. \n5.\tStructure of the paper could be improved. For example, it’s better to put section 4 and 6 together.\n', 'The paper presents a method for improving the convergence rate of Stochastic Gradient Descent for learning embeddings by grouping similar training samples together. The basic idea is that gradients computed on a batch of highly associated samples encode related information in a single update that independent samples might take multiple updates to capture. These structured minibatches are constructed by independently combining subsets of positive examples called “microbatches”. Two methods are presented for constructing these microbaches; first by grouping positive examples by shared context (called “basic” microbatches), second by applying Locality Sensitive Hashing to further partition the microbatches into groups that are more likely to contain similar examples.\n\nThree datasets are used for experimental analysis: a synthetic dataset generated using the stochastic block model, and two large scale recommendation datasets. The presented algorithms are compared to a baseline of independently sampled minibatches using the cosine gap and precision for the top k predictions. The authors show the measured cosine gaps over the course of training as well as the gains in training performance for several sets of hyperparameters.\n\nThe motivation and basic intuition behind the work is clearly presented in the introductory section. The theoretical justification for the structured minibatches is reasonably convincing and invites empirical verification.\n\nGeneral concerns:\nAny method for improving the performance of an optimization process via additional preprocessing must show that the additional overhead incurred from preprocessing the data (in this case, organizing the minibatches) does not negate the achieved improvement in convergence time. This work presents no evidence that this is the case. I expected to see 1) time complexity analysis of each new algorithm proposed for preprocessing and 2) experimental results showing that the overall computation time, including the proposed preprocessing steps, was reduced by this method. Neither of these things are present in this work.\n\nFurthermore, the measured “training gains” are, to my knowledge, not clearly defined. I assume that the authors are using the number of epochs or iterations before convergence as their measure of training performance, but this should be stated explicitly rather than implicitly.\n\nFinally, the experimental results presented do not seem to entirely support the authors’ conclusions. Figures 2, 3, and 4, as well as several of the figures in the appendix, show some parameter settings for which the gains over the baseline are quite limited. This makes me suspect that perhaps the coordinated minibatches aren’t the only variable affecting performance.\n\nI have organized my remaining minor concerns and requests for clarification by section, detailed below.\n\nSection 1\n- In the last paragraph, the acronym SGNS is mentioned before being defined. You should either state the full name of the method (with citation) or omit the mention altogether.\n\nSection 2\n- I would like a few sentences of additional clarification on what “focus” entities vs. “context” entities are in the more general case. I am familiar with what they mean in the context of Skip Gram, but I think more discussion on how this generalizes is necessary here. Same goes for what kappa (“association strength”) means, especially considering that this concept isn’t really present (to my understanding) in Skip Gram.\n- Grammar correction:\n“The negative examples provide an antigravity effect that prevents all embeddings to collapse into the same vector”\n“to collapse” -> “from collapsing”\n\nSection 3\n- Maybe this is just me, but I find the mu-beta notation for the microbatch distributions rather odd. Why not just use a single symbol?\n- I would like a bit more clarification on the proof for lemma 3.1, specifically on the last sentence, “the product of these events …”; that statement did not follow obviously to me.\n\nSection 3.1\n- Remove the period and colon near kappas at the end of paragraph 3. It’s visually confusing with the dot index notation right next to them.\n\nSection 4\n- Typo: “We selects a row vector …” -> “We select a row vector …”\n\nSection 5\n- I don’t understand what Figure 1 is trying to demonstrate. It doesn’t do anything (as far as I can tell) to defend the authors’ claim that COO provides a higher expected increase in cosine similarity than IND.\n\nSection 6\n- All figures in this section should have axis labels. The captions don’t sufficiently explain what they are.\n\nSection 6.2\n- How is kappa computed for the recommendations datasets? This isn’t obvious at all.\n']","[-50, -50, -50, -20]","[20, 20, 0, 60]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, particularly regarding insufficient experimental evidence and lack of clarity. However, they do acknowledge some improvements in the revised version, which prevents the score from being even lower. The politeness score is 20 because the reviewer uses generally polite language (e.g., 'Thank you for revising the paper', 'I would encourage the authors'), but maintains a critical tone throughout. They provide specific, constructive feedback without using overly harsh language, which contributes to a slightly positive politeness score."", ""The sentiment score is -50 because the review starts with a brief positive note about the paper's proposal, but quickly shifts to criticisms about lack of context, insufficient benchmarking, and readability issues. The majority of the review focuses on problems and questions, indicating a generally negative sentiment. However, it's not entirely negative as it acknowledges the paper's novel idea.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding harsh language or personal attacks. They use phrases like 'it is difficult to read' rather than saying it's poorly written. The reviewer also acknowledges their own potential lack of expertise in some areas. However, the score is only slightly positive because the review is quite direct in its criticisms and doesn't include many softening phrases or compliments that would indicate high politeness."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's content and methodology in the first paragraph, the 'Concerns' section lists five significant issues without any positive counterbalance. This indicates a generally negative view of the paper. The politeness score is 0 (neutral) because the reviewer uses professional, matter-of-fact language without being overly polite or rude. They state their concerns directly but without using harsh or inflammatory language. The review focuses on the content and methodology rather than personal criticism, maintaining a neutral tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (clear presentation of motivation and intuition, reasonably convincing theoretical justification), they express several significant concerns and criticisms. These include the lack of time complexity analysis, absence of overall computation time results, unclear definition of 'training gains', and experimental results that don't fully support the authors' conclusions. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I expected to see', 'I would like', and 'Maybe this is just me', which soften their criticisms. They also offer specific suggestions for improvements and clarifications, demonstrating a helpful attitude. The language is formal and respectful, avoiding any harsh or rude expressions.""]"
"['This paper proposed a new hashing algorithm with a new loss function. A multi-indexing scheme is adopted for search.  There is one key issue: in general hashing is not good at multi-indexing search for vector-based search in the Euclidean distance or Cosine similarity. The advantage of hashing is reducing the code size and thus memory cost, but it is still not as good as quantization=based approach. \n\nHere are comments about the experiments.\n(1) Table 1: do other algorithms also use multi-indexing or simply linear scan?\n(2)  Figure 4: HDT-E is better than PQ. It is not understandable. Something important is missing. How is the search conducted for PQ? Is multi-indexing used? It is also strange to compare the recall in terms of #(distance comparisons). \n\n', 'Summary: This paper contributes to the area of learning to hash. The goal is to take high-dimensional vectors in R^n resulting from an embedding and map them to binary codewords with the goal of similar vectors being mapped to close codewords (in Hamming distance). The authors introduce a loss function for this problem that\'s based on angles between points on the hypersphere, relying on the intuition that angles corresponds to the number of times needed to cross to the other side of the hypersphere in each coordinate. This is approximately the Hamming distance under a simple quantization scheme. The loss function itself forces similar points together and dissimilar points apart by matching the Hamming distance to the binomial CDF of the angle quantization. They also suggest a batching scheme that enforces the presence of both similar and dissimilar matches. To confirm the utility of this loss function, the authors empirically verify similarity on ImageNet and SIFT.\n\nStrengths: The main idea, to match up angles between points on the hypersphere and Hamming distance is pretty clever. The loss function itself seems generally useful.\n\nWeaknesses: First, I thought the paper was pretty difficult to understand without a lot of background from previous papers. For the most part the authors don\'t actually state what the input/output/goals are, leaving it implied from the context, which is tough for the reader. The overall organization isn\'t great. The paper doesn\'t contain any theory even for simplified or toy cases (which actually seems potentially tractable here); there is only simple intuition. I think that is fine, but then the empirical results should be extensive, and unfortunately they are not. \n\nVerdict: I think this work contains a great main idea and could become quite a good paper in the future, but the work required to illustrate and demonstrate the idea is not fully there yet. \n\n\nComments and Questions:\n\n- Why do you actually need the embedded points y to be on the unit hypersphere? You could compute distances between points at different radii. The results probably shouldn\'t change much.\n\n- There\'s at least a few other papers that use a similar idea, for example \nGong et al ""Angular Quantization-based Binary Codes for Fast Similarity Search"" at NIPS 2012. Would be good to discuss the differences.\n\n- The experimental section seems very limited for an empirical paper. There\'s at least a few confusing details, noted below:\n\n- The experimental results for ImageNet comparing against other models are directly taken from those reported by Lu et al. That\'s fine, but it does mean that it\'s hard to make comparisons against *any* other paper than the Lu paper. For example, if the selected ImageNet classes are different, then the results of the comparison may well be different. I checked the HashNet paper (Cao et al. 2017), and it papers that their own reported numbers for ImageNet are better than those of the Lu et al paper. That is, I see 0.5059 0.6306 0.6835 for 16/32/64 bit codewords vs Lu\'s result of 0.442 0.606 0.684, which is quoted in this paper. What\'s causing this difference? It would probably be a bit less convenient but ultimately better if the results for comparison were reproduced by the authors, and possibly on a different class split compared to the single Lu paper.\n\n- The comparison against PQ should also consider more recent works of the same flavor as PQ, which themselves outperform PQ. For example, ""Cartesian k-means"" by Norouzi and Fleet, or ""Approximate search with quantized sparse representations"" by Jain et al. These papers also use the SIFT dataset for their experimental result, so it would be great to compare against them.', 'This paper is about learning to hash. The basic idea is motivated by the intuition: given points z_i and z_j on the hypersphere, the angle between the two points is arccos(z_i \\dot z_j), while the probability that a random bit differs between them is arccos(z_i \\dot z_j)/\\pi. This leads to a nice formulation of learning Hamming Distance Target (HDT), although the optimization procedure requires every input has a similar neighbor in the batch.\n\nThe minor issue of this paper is that the writing should be polished. There are numerous typos in paper citing (e.g., Norouzi et al in the 3rd page is missing the reference; Figure 3.2 in the 7th page should be Figure 3; and a number of small typos). But I believe these issues could be fixed easily.\n\nThe major issue is how we should evaluate a learning to hash paper with nice intuition but not convincing results. Below are my concerns of the proposed approach.\n\n1. Learning to hash (including the HDT in this paper) and product quantization (PQ) are not based on the same scenario,  so it is unfair to claim hashing method outperforms PQ.\n\nMost learning to hash methods requires two things in the following:\na) the query samples\nb) similar/dissimilar samples (or we can call them neighbors and non-neighbor) to the query\n\nPQ does not require a) and b). As a result, in PQ based systems, a query can be compared with codewords using Euclidean distance, without mapping to a hash code. This is important especially for novel queries, because if the system does not see similar samples during training, it will probably fail to map such samples to good hash codes. \n\nSuch advantage of PQ (or other related quantization methods) is important for real-world systems, however, not obvious in a controlled experiment setting. As shown in the paper, HDT assumes the queries will be similar in the training and testing stages, and benefits from this restricted setting. But I believe such assumption may not hold in real systems. \n\n2. It is not clear to me that how scalable the proposed method is.\n\nI hope section 1.2 can give analysis on both **space** and time complexity of Algorithm 2. It will be more intuitive to show how many ms it will take to search a billion scale dataset. Currently I am not convinced how scalable the proposed algorithm is. \n\n3. Implementation details\nIn page 5, it is not clear how the hyper parameters \\lamda, \\lamda_w and p_0 are selected and how sensitive the performance is. I am also interested in the comparison with [Johnson Dooze Jegou 2017] “Billion-scale similarity search with GPUs”.\n\n4. Missing literature\nI think one important recent paper is “Multiscale quantization for fast similarity search” NIP 2017\n\n\nTo summarize, I like the idea of this paper but I feel there are still gap between the current draft and real working system. I wish the submission could be improved in the future.\n']","[-30, -20, -20]","[20, 50, 60]","[""The sentiment score is slightly negative (-30) because the reviewer points out a 'key issue' with the proposed algorithm and expresses skepticism about its performance compared to other approaches. The reviewer also mentions that 'something important is missing' and finds some results 'not understandable' and 'strange'. However, the review is not entirely negative as it acknowledges the paper's proposal of a new algorithm and loss function. The politeness score is slightly positive (20) because the reviewer uses neutral language and frames their concerns as questions or observations rather than direct criticisms. The reviewer also uses phrases like 'Here are comments' which maintains a professional tone. While not overtly polite, the language avoids rudeness and maintains a respectful, academic tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'great main idea' and potential, they express several criticisms and state that 'the work required to illustrate and demonstrate the idea is not fully there yet.' The overall tone suggests the paper needs significant improvements before being acceptable. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balances criticisms with acknowledgments of strengths, and phrases suggestions constructively (e.g., 'Would be good to discuss the differences'). The reviewer also uses polite phrases like 'I think' to soften criticisms. However, the score is not higher as the review is still direct in its criticisms without excessive softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice intuition', 'nice formulation'), they express major concerns about the paper's results and methodology. The reviewer states there are 'major issues' and is 'not convinced' about certain aspects, indicating an overall negative sentiment despite some positive elements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively (e.g., 'I hope', 'I wish', 'I like the idea'). The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. The language is professional and courteous, avoiding harsh or rude expressions.""]"
"['In this paper, the authors proposed a fortified network model, which is an extension to denoising autoencoder. The extension is to perform the denoising module in the hidden layers instead of input layer. The motivation of this extension is that the denoising part is more effective in the hidden layers. Overall, this extension is quite sensible, and empirical results justify the utility of this extension. The major issue, which was left as an open question in the end of Section 3, is that when and where to use fortified layers. The authors discussed this issue, but did not solve this issue. Nevertheless, I do believe solving this issue requires a sequence of papers. Overall the paper reads very well, but there are a number of minor places to be improved. \n\n \n(1) a grammar error at ""provide a reliable signal of the existence of input data that do not lie on the manifold on which it the network trained.""\n\n(2) a grammar error at ""This expectation cannot be computed, therefore a common approach is to to minimize the empirical risk""\n\n(3) The sentence ""For a mini-batch of N clean examples, x(1), ..., x(N), each hidden layer h(1)_k, ..., h(N)_k is fed into a DAE loss"" is a little confusing to me. ""h(1)_k, ..., h(N)_k"" is only for one hidden layer, rather than ""each hidden layer"". Right?', 'The method works by substituting a hidden layer with a denoised version. \nNot only it enable to provide more robust classification results, but also to sense and suggest to the analyst or system when the original example is either adversarial or from a significantly different distribution.\nImprovements in adversarial robustness on three datasets are significant.\n\nBibliography is good, the text is clear, with interesting and complete experimentations.', ""This paper presents an approach of fortifying the neural networks to defend attacks. The major component should be a denoising autoencoder with noise in the hidden layer.\n\nHowever, from the paper, I am still not convinced why this defends the FGSM attack. From my perspective, a more specifically designed algorithm could attack the network described in the paper as the old way, and what is the insight of defending the attacks, whether this objective function is harder to find to adversarial examples, or have to use more adversarial examples?\n\nAnother problem rise from Ian Goodfellow's comment. I am trying not to be biased. So if the author could address his comments properly, I am willing to change the rating."", ""This paper proposes a new defense to adversarial examples based on the 'fortification' of hidden layers using a denoising autoencoder. While building models that are robust to adversarial examples is an important and relevant research problem, I am not convinced by the evaluation of the defense.  Specific comments:\n\n- The authors mostly evaluate their defense using FGSM (particularly on CIFAR). To truly establish the merit of a new defense, the authors must benchmark against state-of-the-art defenses such as PGD. It also seems like the epsilon values used for the PGD attacks are fairly small. The authors should report accuracies to a range of epsilon values for the PGD attack, as is standard.\n\n- When the authors attack their models using PGD/FGSM, is this only on the classification loss or does this also include the denoising terms? Similar defenses which use denoisers have been broken once you run PGD on the full model [1].\n\n- I do not really understand the motivation behind using an autoencoder here. Firstly, it is not clear that adversarial examples lie off the data manifold - they could form a very small set on the data manifold and thereby not affect standard generalization. Secondly, have the authors tried a simple regularization loss based on the error between hidden layer representations to a natural examples and the corresponding adversarial example? I think the authors must motivate the use of denoising autoencoders here by comparing to such a simple baseline.\n\nGeneral comment: The results hard to parse given the arrangement of figures and tables. Also, which approach are the authors denoting as ‘baseline adv. Train’ in the tables? \n\nOverall I feel like building defenses to adversarial examples is a challenging problem and the empirical investigation in this paper is not sufficient to illustrate any real progress on this front.\n\n[1] Athalye, A., & Carlini, N. (2018). On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses. arXiv preprint arXiv:1804.03286.\n""]","[60, 90, -30, -60]","[80, 50, 20, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, stating that the extension is 'quite sensible' and that 'empirical results justify the utility of this extension.' They also mention that the paper 'reads very well.' However, they do point out a 'major issue' that was left unresolved, which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'I do believe' and 'Overall the paper reads very well,' which show respect for the authors' work. The reviewer also frames the unresolved issue as an 'open question' rather than a failure, and acknowledges that solving it 'requires a sequence of papers.' The minor corrections are presented neutrally without negative language."", ""The sentiment score is 90 (highly positive) because the review highlights significant improvements in adversarial robustness, praises the bibliography as 'good', and describes the text as 'clear' with 'interesting and complete experimentations'. There are no negative comments, only positive observations about the method's effectiveness and the paper's quality. The politeness score is 50 (moderately polite) because while the language is professional and respectful, it doesn't contain overtly polite phrases. The reviewer states facts and observations in a neutral, academic tone without using particularly warm or courteous language, but also without any rudeness or harshness."", ""The sentiment score is slightly negative (-30) because the reviewer expresses skepticism about the paper's approach and is not convinced by its effectiveness against FGSM attacks. The reviewer also mentions unaddressed comments from another researcher, indicating further concerns. However, the score is not deeply negative as the reviewer shows openness to changing their opinion if the authors address these issues. The politeness score is slightly positive (20) because the reviewer uses professional language and avoids harsh criticism. They express willingness to reconsider their rating, which shows respect for the authors. The reviewer also acknowledges their attempt to avoid bias, which is a polite gesture. However, the politeness is not extremely high as the criticism is still direct and the tone is somewhat skeptical."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's evaluation methods and overall contribution. They state they are 'not convinced by the evaluation of the defense' and feel the paper doesn't 'illustrate any real progress'. However, it's not entirely negative as they acknowledge the importance of the research problem. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am not convinced' and 'I do not really understand' rather than more harsh language. They also offer specific suggestions for improvement, which is constructive. The reviewer balances critique with acknowledgment of the challenging nature of the problem, showing some empathy towards the authors' efforts.""]"

reviews,sentiment_scores,politeness_scores,reasonings
"['The idea proposed in this paper is to aid in understanding networks by showing why a network chose class A over class B.  To do so, the goal is to find an example that is close to the original sample, but belongs to the other class. As is mentioned in the paper, it is crucial to stay on the data manifold for this to be meaningful. In the paper, an approach using a GAN to traverse the manifold is proposed and the experimental evaluation is done on MNIST.\n\nIf my understanding is correct the proposed approach requires:\nFinding a noise code z_0 such that the GAN generates an image G(z_0) close to the original input x. As a metric L2 distance is proposed.\nFind a point close to z_b that is close z_0  s.t. Class B is the most likely class and class A is the second most likely prediction. Specifically it is required that\nThe log likelihood of but classified as class B with the same log likelihood of class B for G(z_b) is the same as the log likelihood of class A for the input x.\nSuch that all other classes have a log likelihood that is at least epsilon lower than both the one of class A and class B.\n\nThe proposed approach is compared to a set of other interpretability methods, which were \nGrad-Cam, lime, PDA, xGEM on MNIST AND Fashion MNIST data. The proposed evaluation is all qualitative, i.e. subjective. It must also be noted that in the methods used for comparison are not used as originally intended.\n\n\nCurrently, I do not recommend this paper to be accepted for the following reasons.\nThe idea of using a GAN is to generate images in input space is not novel by itself. Although the application for interpretability by counterfactuals is. It is unclear to me how much of the appealing results come from the GAN model and how much come from truly interpreting the network. I have detailed this below by proposing a very simplistic baseline which could get similar results.\nThe experimental approach is subjective and I am not convinced by the experimental setup.\nOn the other hand, I do really appreciate the ideas of traversing the manifold. \n\nRemarks \nRelated work and limitations of existing interpretability methods are discussed properly. Of course, the list of discussed methods is not exhaustive. The work on the PPGAN and the “Synthesizing the preferred inputs for neurons in neural networks via deep generator networks” is not mentioned although it seems very related to the proposed approach to traverse the manifold. What that work sets apart from the proposed approach is that is could be applied to imaganet and not just MNIST. \n\nTraversing the manifold to generate explanations is certainly a good idea and one that I completely support. One limitation of the proposed approach is that it is unclear to me whether a point on the decision boundary is desirable or that a point that is equally likely is desirable. My reasoning is that the point on the decision boundary is the minimal change and therefore the best explanation. In such a setup, the GAN is still crucial to make sure the sample remains on the data manifold and is not caused by adverarial effects.\n\nThe exact GAN structure and training approach should be detailed in this paper. Now only a reference is provided. \n\nCan you clarify how the constraints are encoded in the optimization problem?\n\nThe grad cam reference has the wrong citation\n\nI do not understand the second paragraph of section 4.1. As mentioned in the paper, these other methods were not designed to generate this type of application. Therefore the comparison could be considered unfair. \n\nI would propose the following baseline. For image x from class A, find image y from class B such that x-y has minimal L2 norm and is correctly classified. Use y instead of the GAN generated image. Is the result much less compelling? Is it actually less efficient that the entire GAN optimization procedure on these relatively small datasets? \n\n\nI do have to say that I like the experiment with the square in the upper corner. It does show that the procedure does not necesarrily exploits adversarial effects. However, the baseline proposed above would also highlight that specific square?\n\n\nFigure 5 shows that multiple descision boundaries are crossed. Is this behaviour desired? It seems very likely to me that it should be possible to move from 9 to 8 while staying on the manifold without passing through 5? Since the method takes a detour through 5’s is this common behaviour?\n\n\nFINAL UPDATE\n--------------------\nUnfortunately, I am not entirely convinced by the additional experiments that we are truly looking into the classifier instead of analyzing the generative model. \nI believe this to be currently the key issue that, even after the revision, needs to be addressed more thoroughly before it can be accepted for publication. ', '\nThe paper addresses the problem of providing saliency-based visual explanations of deep models tasked at image classification. More specifically, instead of generating visualizations directly highlighting the image pixels that support the the decision of an image belonging to class A, it generates ""contrastive"" visualizations indicating the pixels that should be added or suppressed in order to support the decision of a image belonging to class A and not to class B.\n\nThe method formulates the generation of these contrastive explanations through a generative adversarial network (GAN), where the discriminator D is the image classification model to be explained and the generator G is a generative model trained to produce images from the dataset used to train D.\n\nExperiments on the MNIST and fashion-MNIST datasets compares the performance of the proposed method w.r.t. some methods from the literature.\n\n\nOverall the manuscript is well written and its content is relatively easy to follow. The idea of generating contrastive explanations through a GAN-based formulation is well motivated and seems novel to me.\n\nMy main concern with the manuscript are the following:\n\ni) The proposed method seems to be specifically designed for the generation of contrastive explanations, i.e. why the model predicted class A and not class B. While the generation of this type of explanations is somewhat novel, from the text it seems that the proposed method may not be able to indicate what part of the image content drove the model to predict class A. Is this indeed the case?\n\nii) Although the idea of generating contrastive explanations is quite interesting, it is not that novel. See Kim et al., NIPS\'16, Dhurandhar et al., arXiv:1802.07623. Moreover, regarding the presented results on the MNIST dataset (Sec 4.1) where some of the generated explanations highlight gaps to point differences between digit classes. The work from Samek et al., TNNLS\'17 and  Oramas et al., arXiv:1712.06302 seem to display similar properties in their explanations without the need of explicit constractive pair-wise training/testing. The manuscript would benefit from positioning the proposed method w.r.t. these works.\n\niii) Very related to the first point, in the evaluation section (Sec.4.1) the proposed method is compared against other methods in the literature. Three of these methods, i.e. Lime, GradCam, PDA, are not designed for producing contrastive explanations, so I am not sure to what extend this comparison is appropriate.\n\niv) Finally, the reported results are mostly qualitative. I find the set of provided qualitative examples quite reduced. In this regard, I encourage the authors to update the supplementary material in order to show extended qualitative results of the explanations produced by their method.\nIn addition, I recommend complementing the presented qualitative comparisons with quantitative evaluations following protocols proposed in existing work, e.g. a) occlusion analysis (Zeiler et al., ECCV 2014, Samek et al.,2017), a pointing experiment (Zhang et al., ECCV 2016), or c) a measurement of explanation accuracy by feature coverage (Oramas et al. arXiv:1712.06302).\n\n', 'The paper proposes an approach to provide contrastive visual explanations for deep neural networks -- why the network assigned more confidence to some class A as opposed to some other class B. As opposed to the applicability of previous approaches to this problem -- the approach is designed to directly answer the contrastive explanations question rather adapting other visual saliency techniques for the same. Overall, while I find the proposed approach simple -- the paper needs to address some issues regarding the claims made and should provide more quantitative experimental results justifying the same.\n\n- Apart from some flaws in the claims made in the paper, the paper is easy to follow and understand.\n- Assuming the availability of a latent model over the images of the input distribution, the proposed approach is directly applicable and faster.\n- The authors clearly highlight the problems associated with existing explanation modalities and approaches; ranging from ones applicable to only specific deep architectures to ones using backpropagation based heuristics.\n- The proposed approach to generate contrastive explanations is simple and is structured along the lines of methods utilizing probe images to explain decisions -- except for the added advantage that the provided explanations are instance-agnostic due to the assumption of a latent model over the input distribution.\n\nComments:\n- One of the problems highlighted in the paper regarding existing explanation modalities is the use of another black-box to explain the decisions of an existing deep network (also somewhat of a black-box) which the authors claim their model does not suffer from. The proposed approach provides explanations by operating in the latent space of a learned generative model of the input distribution. The learned generator in itself is somewhat of a black-box itself -- there has been prior work indicating how much of the input distribution are GANs able to capture. As such, conditioning on a generative model to propose such contrastive explanations is to some extent using another black-box (generator) to explain the decisions of an existing one. Thus, the above claim made in the paper does not seem well-founded. Furthermore, in experiments, the paper does not provide any quantitatively convincing results to suggest the generator in use is a good one.\n- While the authors suggest that a latent model over the input distribution needs to be trained only once and is applicable off-the-shelf for any further contrastive explanations regarding any network operating on the same dataset -- learning such a model of the input space is an overhead in itself. In this light, experiments demonstrating comparisons between GANs and VAEs as the reference generative model for explanations would have made the paper stronger (as the proposed approach relies explicitly on how good the generative model is). \n- The paper proposes an interesting experiment to show that the proposed approach is somewhat capable of capturing slightly adversarial biases in the input domain (adding square to the top-left of images of class ‘8’). While I like this experiment, I feel this has not been explored to completion in the sense of experimenting with robustness with respect to structured as well as unstructured perturbations.\n- Typographical Errors: Section 3.1 repeats the use of D for a discriminator as well as the input distribution. Procedure 1 and Procedure 2 share the same titles -- which is slightly misleading. In addition, Procedure 1 is not referenced in the text which makes is hard to understand the utility of the same. In Section 4.1, the use of Gradcam and Lime to generate counterfactual explanations is not very clear and makes it slightly hard to follow. Citations used for Gradcam are wrong -- Sundarajan et al., 2016 should be changed to Selvaraju et al., 2017.\n\nExperimental Issues:\n- Experimental results are provided only on MNIST and Fashion-MNIST. Since the paper focuses explicitly on providing contrastive explanations for choosing a class A over another class B -- experiments on datasets which do not have real-images seem insufficient. Additional experiments on at least ImageNet would have made the paper stronger.\nRegarding contrastive explanations, experiments on datasets where distractor classes (y_probe) are present in addition to the class interest (y_true) seem important -- PASCAL VOC, COCO, etc. Specifically, since the explanations provided are visual saliency maps the paper would have been stronger if there were experiments suggesting -- what needs to change in a region of an image classified as a ‘cat’ to be classified as a ‘dog’ while there is an instance of the class - ‘dog’ present in the image itself. Also, section 7 in Gradcam (https://arxiv.org/pdf/1610.02391.pdf) provides a procedure to generate counter-factual explanations using Gradcam. Is there a particular reason the authors did not choose to adopt the above technique as a baseline?\n- Experimental results provided in the paper are only qualitative -- as such, I do not find the comparisons (and improvements) over the existing approaches convincing enough. Since, there is no clear metric to evaluate contrastive explanations -- human studies to judge the class-discriminativeness (or trust) of the proposed approach would have made the paper stronger.\n\nThe authors adressed the issues raised/comments made in the review. In light of my comments below to the author responses -- I am not inclined towards increasing my rating and will stick to my original rating for the paper.']","[-60, -20, -30]","[20, 60, 50]","[""The sentiment score is -60 because the reviewer does not recommend the paper for acceptance and lists several major concerns. The overall tone is critical, though not entirely negative as the reviewer does appreciate some aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They acknowledge positive aspects and use phrases like 'I do really appreciate' and 'I like the experiment', which maintain a respectful tone. The reviewer also provides detailed explanations for their concerns and suggestions for improvement, which is considerate and helpful to the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'relatively easy to follow', 'well motivated and seems novel'), they express several significant concerns and recommendations for improvement. The overall tone suggests the paper needs substantial work before being acceptable. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positives, and frames criticisms constructively as recommendations (e.g. 'I encourage the authors', 'I recommend'). They avoid harsh language and maintain a professional tone even when pointing out limitations."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'easy to follow', 'clearly highlight problems'), they express significant concerns and suggest many improvements. The overall tone indicates the paper needs substantial work before being acceptable. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives before critiques, and phrases criticisms constructively (e.g., 'the paper needs to address', 'would have made the paper stronger'). However, it's not extremely polite, maintaining a professional, direct tone rather than being overly deferential.""]"
"['The paper addresses the problem of training an object detection network that can achieve good performance on both clean and noisy images.   \nThe proposed approach is based on a gating network that decides whether\nthe image is clean or  noisy. in case of  noisy image a denoising  method is applied.  The network components form a mixture of experts architecture and are  jointly trained after a component-level pretraining.\nHow good is the gate performance? what happen if you use only one of the trained experts for all the clean/noisy  test data? It is not clear how you combined the results of the two experts. Are you computing a weighted average of the original and the enhanced images? Did you try to use a hard decision gating at test time? \n  ', 'The paper presents a synthetic naive approach to analyzing distorted, especially noisy, images through deep neural networks. It uses an existing gating network to discriminate between clean and noisy images, averaging and denoising the latter, so as to somewhat improve the results obtained if no such separation was used. It deals with a well known problem using the deep neural network formulation. Results should be compared to other image analysis methodologies, avoiding smoothing when not required, that can be used for the same purpose.  This should also be reflected in related work in section 2; the reason of including Table 1 in it seems unclear. \n', 'Summary\nThis paper introduced a parameterized image processing technique to improve a robustness of visual recognition systems against noisy input data. The proposed method is composed of two components; a denoising network that suppresses the noise signals in an image, and gating network that predicts whether to use the original input image or the one produced by the denoising network. The proposed idea is evaluated on three tasks of object detection, tracking and action recognition. \n\nOriginality and significance:\nThe originality of the paper is very limited since the paper simply combines the existing image denoising technique with the idea of gating. The practical significance of the work is also limited since the model is trained and evaluated with only synthetically generated noise patterns; it is not surprising that the proposed method (both denoising and gating networks) works under this setting, as the noise is created synthetically under the same setting in both training and testing. To demonstrate the practical usefulness, it would be great if the model is evaluated with the actual source of noises (e.g. noises from input sensors, distortion by image compression, etc).  \n\nClarity:\nI think the title of the paper is misleading; the proposed model is actually not a mixture of preprocessing units, as it combines *a* denoising unit together with identity mapping. The gating network is also not designed to incorporate a mixture of more than two preprocessing units, as it outputs only “on/off switches” instead of weights for K mixture components (K>2).\n\nMinor comments:\n1) the paper argued the importance of lightweight preprocessing but have not provided analysis on computation costs. From the current results, I don’t see the clear benefit of the proposed method (denoising network) over the average filtering considering the tradeoff between computation vs. performance. \n2) In Figure 5, I suggest highlighting the differences among the examples for clarity.\n']","[20, -20, -50]","[50, 0, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's approach to addressing an important problem and describes the proposed method without overtly criticizing it. However, the score is not higher because the reviewer raises several questions, indicating some concerns or areas needing clarification. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames their concerns as questions rather than direct criticisms. The reviewer doesn't use overly formal or polite language, but also avoids any rudeness or harsh criticism, maintaining a professional and constructive tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's approach and its attempt to improve results, they also point out limitations and suggest comparisons with other methodologies. The phrase 'naive approach' implies some criticism. The politeness score is neutral (0) as the language is neither particularly polite nor rude. The reviewer uses direct, matter-of-fact language without personal attacks or overly courteous phrases. They provide constructive criticism and suggestions for improvement in a professional manner."", ""The sentiment score is -50 because the reviewer expresses significant criticisms about the paper's originality, practical significance, and clarity. They state that the 'originality of the paper is very limited' and the 'practical significance of the work is also limited'. However, it's not entirely negative as they do acknowledge some aspects of the work and provide constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional and respectful language throughout. They use phrases like 'I think' and 'I suggest' which soften their critiques. They also provide specific recommendations for improvement, which is a polite way to offer criticism. The reviewer maintains a professional tone without using harsh or rude language, even when pointing out significant flaws in the paper.""]"
"['Thank you for an interesting read.\n\nThe paper proposes adding an adversarial loss to improve the reconstruction quality of an auto-encoder. To do so, the authors define an auxiliary variable y, and then derive a GAN loss to discriminate between (x, y) and (x, decoder(encoder(x))). The algorithm is completed by combining this adversarial ""reconstruction"" loss with adversarial loss functions that encourages the matching of marginal distributions for both the observed variable x and the latent variable z. \n\nExperiments present quite a lot of comparisons to existing methods as well as an ablation study on the proposed ""reconstruction"" loss. Improvements has been shown on reconstructing input images with significant numbers.\n\nOverall I think the idea is new and useful, but is quite straight-forward and has some theoretical issues (see below). The propositions presented in the paper are quite standard results derived from the original GAN paper, so for that part the contribution is incremental and less interesting. The paper is overall well written, although the description of the augmented distribution r(y|x) is very rush and unclear to me.\n\nThere is one theoretical issue for the defined ""reconstruction"" loss (for JS and f-divergences). Because decoder(encoder(x)) is a deterministic function of x, this means p(y|x) is a delta function. With r(y|x) another delta function (even that is not delta(y=x)), with probability 1 we will have mismatched supports between p(y|x) and r(y|x). \n\nThis is also the problem of the original GAN, although in practice the original GAN with very careful tuning seem to be OK... Also it can be addressed by say instance noise or convolving the two distributions with a Gaussian, see [1][2].\n\nI think another big issue for the paper is the lack of discussion on how to choose r(y|x), or equivalently, a(x). \n\n1. Indeed matching p_{\\theta}(x) to p^*(x) and q(z) to p(z) does not necessarily returns a good auto-encoder that makes x \\approx decoder(encoder(x)). Therefore the augmented distribution r(y|x) also guides the learning of p(y|x) and with appropriately chosen r(y|x) the auto-encoder can be further improved.\n\n2. The authors mentioned that picking r(y|x) = \\delta(y = x) will result in unstable training. But there\'s no discussion on how to choose r(y|x), apart from a short sentence in experimental section ""...we used a combination of reflecting 10% pad and the random crop to the same image size..."". Why this specific choice? Since I would imagine the distribution r(y|x) has significant impact on the results of PAGAN, I would actually prefer to see an in-depth study of the choice of this distribution, either theoretically or empirically. \n\nIn summary, the proposed idea is new but straight-forward. The experimental section contains lots of results, but the ablation study by just removing the augmentation cannot fully justify the optimality of the chosen a(x). I would encourage the authors to consider the questions I raised and conduct extra study on them. I believe it will be a significant contribution to the community (e.g. in the sense of connecting GAN literature and denoising methods literature).\n\n[1] Sonderby et al. Amortised MAP Inference for Image Super-resolution. ICLR 2017.\n[2] Roth et al. Stabilizing Training of Generative Adversarial Networks through Regularization. NIPS 2017.', '==============Updated=====================\nThe authors addressed some of my concern, and I appreciated that they added more experiments to support their argument.\nAlthough I still have the some consideration as R3, I will raise the rating to 6.\n\n===========================================\n\nThis paper is easy to follow. Here are some questions:\n\n1. The argument about ALI and ALICE in the second paragraph of the introduction, “… by introducing a reconstruction loss in the form of a discriminator which classifies pairs (x, x) and (x, G(E(x)))”, however, in ALI and ALICE, they use one discriminator to classify pairs (z, x) and (z, G(z)). Therefore, “… the discriminator tends to detect the fake pair (x, G(E(x))) just by checking the identity of x and G(E(x)) which leads to vanishing gradients” is problematic. Therefore, the motivation in the introduction may be some modification.\n\n2. The authors failed to compare their model with SVAE [1] and MINE [2], which are improved versions of ALICE. And we also have other ways to match the distribution such as Triple-GAN [3] and Triangle-GAN [4], I think the authors need to run some comparison experiments.\n\n3. The authors should discuss more about the augment mapping a(x), i.e., how to choose a(x). I think this is quite important for this paper. At least some empirical results and analysis, for example, how inception score / FID score changes when using different choices of a(x).\n\n4. This paper claims that the proposed method can make the training more robust, but there is no such experiment results to support the argument.\n\n[1] chen et al. Symmetric variational autoencoder and connections to adversarial learning, AISTATS 2018.\n[2] Belghazi et al, Mutual Information Neural Estimation, ICML 2018.\n[3] Li et al. Triple Generative Adversarial Nets, NIPS 2017.\n[4] Gan et al. Triangle generative adversarial networks, NIPS 2017.', ""The paper propose a adversary method to train a bidirectional GAN with both an encoder and decoder. Comparing to the existing works, the main contribution is the introducing of an augmented reconstruction loss by training a discriminator to distinguish the augmentation data from the reconstructed data. Experimental results are demonstrated to show the generating and reconstruction performance.\n\nThe problem studied in this paper is very important, and has drawn a lot of researchers' attentions in recent years.  However, the novelties of this paper is very limited. The techniques used to train a bidirectional GAN are very standard. The only new stuff may be is the proposed reconstruction loss defined on augmented samples and reconstructed ones. But this is also not a big contribution, seems just using a slightly different way to guarantee reconstruction. ""]","[20, 20, -30]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's novelty and usefulness, they also point out significant theoretical issues and areas for improvement. The review begins with 'Thank you for an interesting read' and notes that the idea is 'new and useful', but also mentions that it's 'quite straight-forward' and has 'some theoretical issues'. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'I think', 'I would encourage', and 'I believe', and offers constructive criticism. They also acknowledge the paper's strengths before discussing its weaknesses. The reviewer maintains a professional tone, avoiding harsh language even when pointing out flaws, and provides specific suggestions for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the authors addressed some concerns and added more experiments, leading to a raised rating. However, they still have some reservations. The politeness score is moderately positive (50) as the reviewer uses respectful language, appreciates the authors' efforts, and provides constructive feedback without harsh criticism. The review is structured professionally, offering specific questions and suggestions for improvement, which contributes to its polite tone. The language used is neutral to mildly positive, avoiding confrontational or dismissive statements."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the importance of the problem and the experimental results, they express that the paper's novelty is 'very limited' and the main contribution is 'not a big contribution'. The politeness score is slightly positive (20) as the reviewer uses neutral language and acknowledges some positive aspects, but doesn't use overtly polite phrases. They present criticisms in a matter-of-fact manner without harsh language, maintaining a professional tone throughout.""]"
"['The contribution of the paper is to show that WGAN with entropic regularization maximize a lower bound on the likelihood of the observed data distribution. While the WGAN formulation minimizes the Wasserstein distance of the transformed latent distribution and the empirical distribution which is already a nice measure of ""progress"", having a bound on the likelihood can be interesting.\n\nPros:\n+ I like the entropic GAN formulation and believe it is very interesting as it gives access to the joint distribution of latent and observed variables. \n+ While there are some doubtful statements, overall the paper is well written and easy to read.\n\nCons:\n- The assumption of injectivity of the generator could be problematic, as it might not be fulfilled due to mode collapse.\n- I feel the theory is not very deep. Since one has a closed form of the transportation map (Eq. 3.7), the likelihood of the data is obtained by marginalizing out the latent space. However, this assumes that the inner dual maximization problem is solved to stationarity so that Eq 3.7 holds, which is not the case in practice (5 discriminator updates).\n- Thus in Sec. 4.1 for the likelihood at various points in training it is not clear what is actually happening.\n- Sec 4.3 for unregularized GANs might be problematic. In general, the transportation plan is not a density function, so I\'m not certain whether Theorem 1 / Corollary 2 still hold. Furthermore, the heuristic for ""inverting"" G^* is very crude. \n\n- There are also some minor problematic statements in the paper. While they can be easily fixed, they give me doubts:\n  * The original VAE paper is not cited in the introduction for VAEs\n  * The 2013 paper by Cuturi cited on page 2 has nothing to do with ""computational aspects of GANs"". It is about fast computation of approximate OT between two discrete prob. measures. \n  * First-order / second-order Wasserstein distance is I think a bit unusual name for W_1, W_2\n  * On pg. 4, the point of the entropy term is to make the objective strongly convex. Strict convexity has no computational benefits.\n', '\n1. The assumption made by the authors that ""generator is injective"" is problematic or even wrong, as it is well known that GAN suffers from mode collapsing problem. \n\n2. It is very confusing when the authors mentioned the negative Shannon entropy. Because the equation the authors wrote is the Shannon entropy, not the negative version.\n\n3. In the 5th paragraph in the  introduction section, the paper (Cuturi, 2013) has nothing to do with ""improve computational aspect of GAN"", maybe the authors want to cite this paper ""Learning Generative Models with Sinkhorn Divergences"".\n\n4. The authors failed to discuss their paper with ""ON THE QUANTITATIVE ANALYSIS OF DECODERBASED GENERATIVE MODELS"", which uses AIS to estimate the likelihood.\n\nSuggestion:\n1. Please use \\cdot instead of , i.e. F(\\cdot) instead of F(.)\n2. Typo: in Appendix ?? and ??, in section 4', 'Summary\nThe authors notice that entropy regularized optimal transport produce an upper bound of a certain model likelihood. Then, the authors claim it is possible to leverage that upper bound to come up with a measure of \'sample likelihood\', the probability of a certain sample under the model.\n\nEvaluation\nThe idea is certainly interesting and novel, as it allows to bridge two distinct worlds (VAE and GANs). However, I am concerned about the message (or lack of thereof) that is conveyed in the paper. Particularly, the following two points makes me be reluctant to recommend an acceptance:\n\n1)There is no measure on the tightness of the lower bound. How can we tell if this bound isnt tight? All results are dependent on the bound being close to the true value. No comments about this are given.\n2)The sample likelihoods are dependent on a certain ""model"". Here the nomenclature is confusing because I thought GANS were a probabilistic model, but now there is an additional model regarding a function f. How these two relate? What happens if I change f? to which extent the results depend on f?\n3)related to 2): the histograms in figure 2 are interesting, but they are not conclusive that the measure that is being proposed is a \'bona fide\' sample likelihood.\n\n']","[-20, -60, -50]","[50, -20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more criticisms ('Cons') and concerns raised. The reviewer points out several issues with the paper's assumptions, theoretical depth, and problematic statements, which outweigh the positive elements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with praise. They use phrases like 'I like', 'I believe it is very interesting', and 'overall the paper is well written', which maintain a polite tone even when expressing concerns. The reviewer also frames criticisms as 'doubtful statements' or 'problematic' rather than using harsh or dismissive language."", ""The sentiment score is -60 because the review is predominantly critical, pointing out several issues with the paper without offering much positive feedback. The reviewer identifies problematic assumptions, confusing explanations, incorrect citations, and missing discussions. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and lacks softening phrases or positive reinforcement. The reviewer uses phrases like 'problematic or even wrong' and 'failed to discuss,' which come across as somewhat harsh. The suggestions at the end are presented neutrally, slightly mitigating the overall negative tone."", ""The sentiment score is -50 because while the reviewer acknowledges the idea as 'interesting and novel', they express significant concerns and are 'reluctant to recommend an acceptance'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and frames concerns as questions rather than direct criticisms. The reviewer maintains a professional tone without using harsh or rude language, but also doesn't go out of their way to be overly polite or complimentary.""]"
"['\nBrief summary:\u2028This work proposes a way to perform imitation learning from raw videos of behaviors, without the need for any special time-alignment or actions present. They are able to do this by using a recurrent siamese network architecture to learn a distance function, which can be used to provide rewards for learning behaviors, without the need for any explicit pose estimation. They demonstrate effectiveness on 2 different locomotion domains. \n\nOverall impression:\nOverall, my impression from this paper is that the idea is to use a recurrent siamese network to learn distances which make sense in latent space and provide rewards for RL. This is able to learn interesting behaviors for 2 tasks. But I think the writing needs significant work for clarity and completeness, and there needs to be many more baseline comparisons. \n\nAbstract comments:\ntrail and error -> trial and error\n\nIntroduction comments:\n\nAlternative reasons why pose estimation won’t work is because for any manipulation tasks, you can’t just detect pose of the agent, you also have to detect pose of the objects which may be novel/different\n\nFew use image based inputs and none consider the importance of learning a distance function in time as well as space -> missed a few citations (eg imitation from observation (Liu, Gupta, et al))\n\nTherefore we learned an RNN-based distance function that can give reward for out of sync but similar behaviour -> could be good to emphasize difference from imitation from observation (Liu, Gupta, et al) and TCN (Semanet et al), since they both assume some sort of time alignment\n\nMissing related work section. There is a lot of related work at this point and it is crucial to add this in. Some things that come to mind beyond those already covered are:\n1. Model-based Imitation Learning from State Trajectories\n2. Reward Estimation via State Prediction\n3. infoGAIL\n4. Imitation from observation \n5. SFV: Reinforcement Learning of Physical Skills from Videos\n6. Universal planning networks\n7. https://arxiv.org/abs/1808.00928\n8. This might also be related to VICE (Fu, Singh et al), in that they also hope to learn distances but for goal images only.\nIt seems like there is some discussion of this in Section 3.1, but it should be it’s own separate section.\n\nSection 3 comments:\na new model can be learned to match this trajectory using some distance metric between the expert trajectories and trajectories produced by the policy π -> what does this mean. Can this be clarified?\n\u2028The first part of Section 3 belongs in preliminaries. It is not a part of the approach. \n\nSection 3.2\nEquations 9 and 10 are a bit unnecessary, take away from the main point\n\nWhat does distance from desired behaviour mean? This is not common terminology and should be clarified explicitly.\n\nEquation 11 is very confusing. The loss function is double defined.  what exactly Is the margin \\rho (is it learned?) The exact rationale behind this objective, the relationship to standard siamese networks/triplet losses like TCN should be discussed carefully. This is potentially the most important part of the paper, it should be discussed in detail.Also is there a typo, should it be || f(si) - f(sn)|| if we want it to be distances? Also the role of trajectories is completely not discussed in equation 11.\n\nSection 3.3 \nThe recurrent siamese architecture makes sense, but what the positive and negative examples are, what exactly the loss function is, needs to be defined clearly. Also if there are multiple demonstrations of a task, which distance do we use then?\n\nThe RL simulation environment is it made in-house, based on bullet or something else?\n\nData augmentation - how necessary is this for method success? Can an ablation be done to show the necessity of this?\n\nAlgorithm 1 has some typos \n- > is missing in line 3\n- Describe where reward r is coming from in line 10\n\nSection 4.1\nWalking gate -> walking gait\n\nThere are no comparisons with any of the prior methods for performing this kind of thing. For example, using the pose estimation baseline etc. Using the non-recurrent version. Using TCN type of things. It’s not hard to run these and might help a lot, because right now there are no baseline comparisons\n', 'Summary: This paper aims to imitate, via Imitation Learning, the actions of a humanoid agent given only video demonstrations of the desired task, including walking, running, back-flipping, and front-flipping. Since the algorithm does not have direct access to the underlying actions or rewards, the agent aims to learn an embedding space over instances with the hope that distance in this embedding space corresponds to reward. Deep RL is used to optimize a policy to maximize cumulative reward in an effort to reproduce the behavior of the expert.\n\nHigh-level comments:\n- My biggest concern with this paper is the lack of a baseline example that we can use to evaluate performance. The walking task is interesting, but the lack of a means by which we can evaluate a comparison between different approaches makes it very difficult to optimize. This makes evaluation of quality and significance rather difficult. A number of other questions I have stem from this concern:\n    = The paper is missing a comparison between the recurrent Siamese network and the non-recurrent Siamese network. The difficulty in comparing these approaches without a quantitative performance metric.\n    = The authors also mention that they tried using GAIL to solve this problem, but do not show these results. Again, a success metric would be very helpful here.\n    = Finally, a simpler task for which the reward is more easily specified may be a better test case for the quantitative results. Right now, the provided example of walking agents seems to only provide quantitative results.\n- The authors need to be more clear about the structure of the training data and the procedure. As written, the structure of the triplet loss is particular ambiguous: the condition for positive/negative examples is not clearly specified.\n- There are a number of decisions made in the paper that feel rather arbitrary or lack justification. In particular, the ""normalization"" scaling factor fits into this category. Some intuition or explanation for why this is necessary (or why this functional form should be preferred) would be helpful.\n- A description of what the error bars represent in all of the plots is necessary.\n\nMore minor comments and questions:\n- The choice of RL algorithm is not the purpose of this paper. Much of this section, and perhaps many of the training curves, are probably better suited to appear in the Appendix. Relatedly, why are training curves only shown for the 2D environment? If space was a concern, the appendix should probably contain these results.\n- An additional agent that may be a useful comparison is one that is directly provided the actions. It might then be more clear how well. (Again, this would require a way to compare performance between different approaches.)\n- How many demonstrations are there? At training vs testing?\n- Where are the other demonstrations? The TSNE embedding plot mentions other tasks which do not appear in the rest of the paper. Did these demonstrations not work very well?\n\nA Comment on Quality: Right now, the paper needs a fair bit of cleaning up. For instance, the word ""Rienforcement"" is misspelled in the abstract. There is also at least one hanging reference. Finally, a number of references need to be added. For example, when the authors introduce GAIL, they mention GANs and cite Goodfellow et al. 2014, but do not cite GAIL. There is also a lot of good research on Behavioral Cloning, and where it can go wrong, that the authors mention, but do not cite.\n\nConclusion: At this point it is difficult to recommend this paper for acceptance, because it is very hard to evaluate performance of the technique. With a more concrete way of evaluating performance on a different task with a clearer reward function for comparison, the paper could be much stronger, because this would allow the authors to compare the techniques they propose to one another and to other algorithms (like GAIL).\n', ""This paper proposes an imitation learning method solely from video demonstrations by learning recurrent image-based distance model and in conjunction using RL to track that distance.\n\nClarity: The paper writing is mostly clear. The motivation for using videos as a demonstration source could be more clearly stated. One reason is because it would pave the way to learn from real-world video demonstrations. Another reason is that robot's state space is an ill-suited space to be comparing distances over and image space is more suitable. Choosing one would help the readers identify the paper's motivation and contribution.\n\nOriginality: The individual parts of this work (siamese networks, inverse RL, learning distance functions for IRL, tracking from video) have all been previously studied (which would be good to discuss in a relate work section), so nothing stands out as original, however the combination of existing ideas is well-chosen and sensible.\n\nSignificance: There are a number of factors that limit the significance of this work. \n\nFirst, the demonstration videos come from synthetic rendered systems very similar the characters that imitate them, making it hard to evaluate whether this approach can be applied to imitation of real-world videos (and if this is not the goal, please state this explicitly in the paper). Some evaluation of robustness due to variation in the demonstration videos (character width, color, etc) could have been helpful to assure the reader this approach could scale to real-world videos.\n\nSecond, only two demonstrations were showcased - 2D walking and 3D walking. It's hard to judge how this method (especially using RNNs to handle phase mismatch) would work for other motions.\n\nThird, the evaluation to baselines is not adequate. Authors mention that GAIL does not work well, but hypothesize it may be due to not having a recurrent architecture. This really needs to be evaluated. A possibility is to set up a 2x2 matrix of tests between [state space, image space] condition and [recurrent, not recurrent] model. Would state space + not recurrent reduce to GAIL?\n\nFourth and most major to me is that looking at the videos the method doesn't actually work very well qualitatively, unless I'm misunderstanding the supplementary video. The tracking of 2D human does not match the style of the demonstration motion, and matches even less in 3D case. Even if other issues were to be addressed, this would still be a serious issue to me and I would encourage authors to investigate the reasons for this when attempting to improve their work.\n\nOverall, I do not think the results as presented in the submission are up to the standards for an ICLR publication.""]","[-20, -50, -70]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('able to learn interesting behaviors for 2 tasks'), they express several criticisms and concerns. The reviewer states that 'the writing needs significant work for clarity and completeness' and that 'there needs to be many more baseline comparisons.' They also point out multiple areas needing improvement or clarification throughout the review.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'could be good to emphasize,' 'it should be discussed carefully,' and 'needs to be defined clearly' rather than using harsh or dismissive language. The reviewer also offers specific suggestions for improvement and additional references to consider, which is helpful and courteous.\n\nHowever, the politeness score is not higher because the review is quite direct in its criticisms and doesn't use many softening phrases or compliments to balance the negative feedback. The overall tone is professional but matter-of-fact rather than overtly polite."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, particularly the lack of baselines and quantitative metrics for evaluation. The reviewer concludes that it's 'difficult to recommend this paper for acceptance' due to these issues. However, the score is not at the extreme negative end because the reviewer does suggest ways to improve the paper and acknowledges its potential with modifications.\n\nThe politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'My biggest concern' and 'The authors need to be more clear' rather than harsh or dismissive language. The reviewer also offers specific suggestions for improvement and acknowledges the potential of the paper with revisions. However, the score is not at the extreme positive end because the review is direct in its criticism and doesn't use overtly polite language or excessive praise."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several significant limitations of the work, including inadequate evaluation, poor qualitative results, and lack of originality. The phrase 'I do not think the results as presented in the submission are up to the standards for an ICLR publication' clearly indicates a negative recommendation. However, the reviewer does acknowledge some positive aspects, such as clear writing and sensible combination of ideas, which prevents the score from being even lower. The politeness score is 20 because while the reviewer maintains a professional tone throughout, using phrases like 'could be more clearly stated' and 'I would encourage authors to', there are also direct criticisms without much softening language. The reviewer balances constructive feedback with clear statements of the paper's shortcomings, resulting in a slightly positive politeness score.""]"
"['In this paper the authors develop the clever idea to use attractor networks, inspired by Hopfield nets, to “denoise” a recurrent neural network.  The idea is that for every normal step of an RNN, one induces an additional ""dimension"" of recurrency in order to create attractor dynamics around that particular hidden state. The authors introduce their idea and run some basic experiments. This paper is well written and the idea is novel (to me) and worthy of exploration.  Unfortunately, the experiments are seriously lacking in my opinion, as I believe *the major focus* of those experiments should be comparisons to other denoising / regularization techniques.\n\nMAJOR\n\nThe point is taken that RNNs are susceptible to noise due to iterated application of the function. In my experience, countering noise (in the sense of gaussian noise added) isn’t a huge problem in practice because there are many regularization methodologies to handle it. This leads me to the point that I think the experiments need to compare across a number of regularization techniques.  The paper is motivated by discussion of noise, “noise robustness is a highly desirable property in neural networks”, and the experiments show improved performance on smaller datasets, all of which speak to regularization. So I believe comparisons with regularization techniques are pretty important here. \n\nMODERATE\n\nThere is some motivation at the beginning of this piece, in particular about language, and does not contain citations, but should.\n\n“Training is in complete batches to avoid the noise of mini-batch training.”  Please explain, I guess this is not a type of noise that the method handles? \n\nWhat about problems that require graded responses, which is likely anything requiring integration? For example,  what happens in the majority task if the inputs were switched to a non-discrete version, where one must hold analog numbers?\n\n\nMINOR\n\nAny discussion about the (presumably dramatic) increase in training time due to the attractor dynamics unrolling + additional batching due to noise vectors (if I understood correctly)?\n\nWhat are your confidence intervals over?  Presumably, we’d like to get confidence over multiple network instantiations.\n\nPg 1. Articulated neural network? \n\n\nQUESTIONS\n\nDoes using a the ‘c’ variable as a bias instead of an initial condition really matter? \n\nHow does supervised training via eqn (4) relate to the classic training of Hopfield nets? I assume not at all, but it would be useful to clarify?\n\nWhat RNN architecture did you use in the Figure 5 simulations (tanh vanilla RNN or GRU?)\n', ""I think overall I appreciate the idea behind the work. I think the work is quite novel, and it also connects to bodies of literature (hopfield networks -- attractors based and more mainstream GRU/LSTM nets). Here are some notes that I have: \n\n1) There is a citation to anonymous 1994 -- not sure if it helps with anything. Is this work published? Why not, 1994 is quite a bit ago! I can’t see any reason why from 1994 until now this should stay anonymous. \n\n2) Intuitively I like the idea of denoising. Though not sure exact what is denoised and towards what? In particular for hopfield networks (and I think most of the body of work that this paper points to), the idea is you have a set of sequences that you want to *memorize*. So you build a point attractor for each of this sequence, such that when starting the dynamical system in the vicinity of the point attractor (in its basin of attraction) then you converge to it (remembering the wanted sequence). Going back to this work, what is this sequence of patterns that we want to remember? More explicitly, for SDRNN you do backprop to get the h you would want and that make that a target (second loss) of the attractor net. But I'm confused about timescale. If h is not stable for a longer time, do you really converge on the attractor net ? Do we have evidence of that? Is this even meaningful early on in training, it feels like it should hurt.\n\n3) Connecting to this, I would really love to see more analysis, going beyond measuring entropy. How do we now this is not just more capacity and the auxiliary loss just helps the optimization. Particularly since the problems are synthetic, not large scale more analysis should be possible.  How does this compare to training the simple RNN but with gaussian noise on h (to learn to be robust to it). Can we control for capacity between RNN and SDRNN? \n\n4) To that point there is this work (not citet as far as I can tell) : https://arxiv.org/abs/1312.6026. It does have a structure somewhat similar, though none of the denoising perspective or the auxiliary loss used in this work. However the work points out that if you make the network deep in a similar way to how it was done here even though technically it is a more powerful model, gradients do not propagate well. The solution was skip connection. In the baseline that was run you do not have skip connections, and the auxiliary loss might play the role of what skip connections or a more powerful optimizer would have played. "", 'The authors propose to embed in a recurrent neural network (RNN) a multistage subnetwork that is trained to denoise its own state. This is done with an additional denoising cost term that essentially encourages the recurrent subnetwork to suppress noise during as the recurrence is unfolded in time.\nThe authors first demonstrate the denoising properties of this architecture, and then demonstrate its performance on a series of tasks combining it with regular tanh and GRU recurrent units.\n\nThe paper is clear and the main idea is rather interesting, but the presented experimental validations are arguably weak. The demonstration of the denoising properties of the network is rather superficial, in the sense that it does not give much insight into the functioning of the architecture, despite that presumably being the main goal of the section. In particular, it is not clear where the non-monotonic change in denoising as a function of network size comes from. Based on the attractor neural network literature that the authors cite at the beginning of the paper, it could be due to either the presence of spurious attractors, the absence of fixed-point attractors or the fact that the attractor network is trained above capacity. But the authors never go into a detailed analysis that could reveal the detailed functioning of their architecture and merely mention the hypothesis that for large networks denoising performance would decrease because of overfitting.\nAs for the experiments that are presented in the rest of the paper, while relevant, the types of tasks and datasets on which the proposed architecture is being tested are rather small.\n\nHere are some more specific comments and questions:\n- It would help to clarify the training procedure to explicitly mention in step 3 that training proceeds on sequences with added noise.\n- It is not clear how many times in each experiments step 3 is being repeated for each mini-batch, i.e. what computational overhead is required for the training of the SDRNN compared to a regular RNN.  \n- It is not clear whether the recurrent neural net called RNN with attractors (RNN+A) is indeed an attractor neural network. Does the state of the network indeed always converge to an attractor?\n']","[20, 20, -20]","[70, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer expresses that the paper is 'well written' and the idea is 'novel' and 'worthy of exploration'. However, they also state that the experiments are 'seriously lacking', which tempers the positive sentiment. The politeness score is fairly high (70) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'Please explain' and frame suggestions as questions, which maintains a polite tone. The reviewer also provides a balanced perspective, offering both positive feedback and areas for improvement without harsh language."", ""The sentiment score is 20 (slightly positive) because the reviewer starts by appreciating the idea and novelty of the work, which is positive. However, they then raise several questions and concerns, which tempers the positivity. The overall tone is constructive but with significant critiques. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, starting with positive comments and framing critiques as questions or suggestions rather than direct criticisms. Phrases like 'I appreciate', 'I like the idea', and 'I would really love to see' contribute to the polite tone. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the main idea is interesting and the paper is clear, they express significant concerns about the experimental validations being 'arguably weak' and 'rather superficial'. The reviewer also points out that the tasks and datasets used are 'rather small'. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and pose questions without using harsh or dismissive language. The reviewer also acknowledges positive aspects of the paper before presenting their concerns, which is a polite approach to giving feedback.""]"
"['The main claim the authors make is that providing privacy in learning should go beyond just privacy for individual records to providing privacy for data contributors which could be an entire hospital. Adding privacy by design to the machine learning pipe-line is an important topic. Unfortunately, the presentation of this paper makes it hard to follow. \n\nSome of the issues in this paper are technical and easy to resolve, such as citation format (see below) or consistency of notation (see below). Another example is that although the method presented here is suitable only for gradient based learning this is not stated clearly. However, other issues are more fundamental:\n1.\tThe main motivation for this work is providing privacy to a client which could be a hospital as opposed to providing privacy to a single record – why is that an important task? Moreover, there are standard ways to extend differential privacy from a single record to a set of r records (see dwork & Rote, 2014 Theorem 2.2), in what sense the method presented here different than these methods?\n2.\tAnother issue with the hospitals motivation is that the results show that when the number of parties is 10,000 the accuracy is close to the baseline. However, there are only 5534 registered hospitals in the US in 2018 according to the American Hospital Association (AHA): https://www.aha.org/statistics/fast-facts-us-hospitals. Therefore, are the sizes used in the experiments reasonable?\n3.\tIn the presentation of the methods, it is not clear what is novel and what was already done by Abadi et al., 2016\n4.\tThe theoretical analysis of the algorithm is only implied and not stated clearly\n5.\tIn reporting the experiment setup key pieces of information are missing which makes the experiment irreproducible. For example, what is the leaning algorithm used? If it is a neural network, what was its layout? What type of cross validation was used to tune parameters?\n6.\tIn describing the experiment it says that “For K\\in\\{1000,10000} data points are repeated.” This could mean that a single client holds the same point multiple times or that multiple clients hold the same data point. Which one of them is correct? What are the implications of that on the results of the experiment?\n7.\tSince grid search is used to tune parameters, more information is leaking which is not compensated for by, for example, composition bounds\n8.\tThe results of the experiments are not contrasted against prior art, for example the results of Abadi et al., 2016.\n\nAdditional comments\n9.\tThe introduction is confusing since it uses the term “federated learning” as a privacy technology. However federated learning discusses the scenario where the data is distributed between several parties. It is not necessarily the case that there are also privacy concerns associated, in many cases the need for federated learning is due to performance constraints.\n10.\tIn the abstract the term “differential attacks” is used – what does it mean?\n11.\t“An independent study McMahan et al. (2018), published at the same time”- since you refer to the work of McMahan et al before your paper was reviewed, it means that the work of McMahan et al came out earlier.\n12.\tIn the section “Choosing $\\sigma$ and $m$” it is stated that the higher \\sigma and the lower m, the higher the privacy loss. Isn’t the privacy loss reduced when \\sigma is larger? Moreover, since you divide the gradients by m_t then the sensitivity of each party is of the order of S/m and therefore it reduces as m gets larger, hence, the privacy loss is smaller when m is large. \n13.\tAt the bottom of page 4 and top of page 5 you introduce variance related terms that are never used in the algorithm or any analysis (they are presented in Figure 3). The variance between clients can be a function of how the data is split between them. If, for example, each client represents a different demography then the variance may be larger from the beginning.\n14.\tIn the experiments (Table 1), what does it mean for \\delta^\\prime to be e-3, e-5 or e-6? Is it 10^{-3}, 10^{-5} and 10^{-6}?\n15.\tThe methods presented here apply only for gradient descent learning algorithms, but this is not stated clearly. For example, would the methods presented here apply for learning tree based models?\n16.\tThe citations are used incorrectly, for example “sometimes referred to as collaborative Shokri & Shmatikov (2015)” should be “sometimes referred to as collaborative (Shokri & Shmatikov, 2015)”. This can be achieved by using \\citep in latex. This problem appears in many places in the paper, including, for example, “we make use of the moments accountant as proposed by Abadi et al. Abadi et al. (2016).” Which should be “we make use of the moments accountant as proposed by Abadi et al. (2016).” In which case you should use only \\cite and not quote the name in the .tex file.\n17.\t“We use the same deﬁnition for differential privacy in randomized mechanisms as Abadi et al. (2016):” – the definition of differential privacy is due to Dwork, McSherry, Nissim & Smith, 2006\n18.\tNotation is followed loosely which makes it harder to follow at parts. For example, you use “m_t” for the number of participants in time t but in some cases,  you use only m as in “Choosing $\\sigma$ and $m$”.\n19.\tIn algorithm 1 the function ClientUpdate receives two parameters however the first parameter is never used in this function. \n20.\tFigure 2: I think it would be easier to see the results if you use log-log plot\n21.\tDiscussion: “For K=10000, the differrntially private model almost reaches accuracies of the non-differential private one.” – it is true that the model used in this experiment achieves an accuracy of 0.97 without DP and the reported number for K=10000 is 0.96 which is very close. However, the baseline accuracy of 0.97 is very low for MNIST.\n22.\tIn the bibliography you have Brendan McMahan appearing both as Brendan McMahan and H. Brendan McMahan\n\n\nIt is possible that underneath that this work has some hidden jams, however, the presentation makes them hard to find. \n\n', '[Post-rebuttal update] No author response was provided to address the reviewer comments. In particular, the paper\'s contributions and novelty compared with previous work seem limited, and no author response was provided to address this concern. I\'ve left my overall score for the paper unchanged.\n\n[Summary] The authors propose a protocol for training a model over private user data in a federated setting. In contrast with previous approaches which tried to ensure that a model would not reveal too much about any individual data point, this paper aims to prevent leakage of information about any individual client. (There may be many data points associated with a single client.)\n\n[Key Comments] The submission generally seems polished and well-written. However, I have the impression that it\'s largely an incremental improvement over recent work by McMahan et al. (2018).\n* If the main improvement of this paper over previous work is the dynamic adaptation of weight updates discussed in Section 3, the experimental results in Table 1 should compare the performance of the protocol with vs. without these changes. Otherwise, I think it would be helpful for the authors to update the submission to clarify their contributions.\n* Updating Algorithm 1 / Line 9 (computation of the median weight update norm) to avoid leaking sensitive information to the clients would also strengthen the submission.\n* It would also be helpful if the authors could explicitly list their assumptions about which parties are trusted and which are not (see below).\n\n[Details]\n[Pro 1] The submission is generally well-written and polished. I found the beginning of Section 3 especially helpful, since it breaks down a complex algorithm into simple/understandable parts.\n\n[Pro 2] The proposed algorithm tackles the challenging/well-motivated problem of improving federated machine learning with strong theoretical privacy guarantees.\n\n[Pro 3] Section 6 has an interesting analysis of how the weight updates produced by clients change over the course of training. This section does a good job of setting up the intuition for the training setup used in the paper, where the number of clients used in each round is gradually increased over the course of training.\n \n[Con 1] I had trouble understanding the precise threat model used in the paper, and I think it would be helpful if the authors could update their submission to explicitly list their assumptions in one place. It seems like the server is trusted while the clients are not. However, I was unsure whether the goal was to protect against a single honest-but-curious client or to protect against multiple (possibly colluding) clients.\n\n[Con 2] During each round of communication, the protocol computes the median of a set of values, each one originating from a different client, and the output of this computation is used to perform weight updates which are sent back to the clients. The authors note that ""we do not use a randomized mechanism for computing the median, which, strictly speaking, is a violation of privacy. However, the information leakage through the median is small (future work will contain such privacy measures)."" I appreciate the authors\' honesty and thoroughness in pointing out this limitation. However, it does make the submission feel like a work in progress rather than a finished paper, and I think that the submission would be a bit stronger if this issue was addressed.\n\n[Con 3] Given the experimental results reported in Section 4, it\'s difficult for me to understand how much of an improvement the authors\' proposed dynamic weight updates provide in practice. This concern could be addressed with the inclusion of additional details and baselines:\n* Few details are provided about the model training setup, and the reported accuracy of the non-differentially private model is quite low (3% reported error rate on MNIST; it\'s straightforward to get 1% error or below with a modern convolutional neural network). The authors say they use a setup similar to previous work by McMahan et al. (2017), but it seems like that paper uses a model with a much lower error rate (less than 1% based on a cursory inspection), which makes direct comparisons difficult.\n* The introduction argues that ""dynamically adapting the dp-preserving mechanism during decentralized training"" is a significant difference from previous work. The claim could be strengthened if the authors extended Table 1 (experimental results for differentially private federated learning) in order to demonstrate the effect of dynamic adaptation on model quality.', 'The paper revisits the federated learning framework from McMahan in the context of differential privacy.  The general concern with the vanilla federated learning framework is that it is susceptible to differencing attacks. To that end, the paper proposes to make the each of the interaction in the server-side component of the gradient descent to be differentially private w.r.t. the client contributions. This is simply done by adding noise (appropriately scaled) to the gradient updates.\n\nMy main concern is that the paper just described differentially private SGD, in the language of federated learning. I could not find any novelty in the approach. Furthermore, just using the vanilla moment\'s accountant to track privacy depletion in the federated setting is not totally correct. The moment\'s accountant framework in Abadi et al. uses the ""secrecy of the sample"" property to boost the privacy guarantee in a particular iteration. However, in the federated setting, the boost via secrecy of the sample does not hold immediately. One requirement of the secrecy of the sample theorem is that the sampled client has to be hidden. However, in the federated setting, even if one does not know what information a client sends to the servery, one can always observe if the client is sending *any* information. For a detailed discussion on this issue see https://arxiv.org/abs/1808.06651 .']","[-60, -30, -50]","[20, 60, 20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper is 'hard to follow' and lists numerous issues, both technical and fundamental. They mention that 'Unfortunately, the presentation of this paper makes it hard to follow' and conclude with 'It is possible that underneath that this work has some hidden jams, however, the presentation makes them hard to find.' These statements indicate a significant negative sentiment. However, the reviewer does acknowledge the importance of the topic and the potential for 'hidden jams,' which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'Unfortunately' and 'Some of the issues... are easy to resolve,' which soften the criticism. The reviewer also provides detailed feedback and suggestions for improvement, which is a polite and helpful approach. However, the directness of some criticisms and the lack of overtly positive language keeps the politeness score from being higher."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (well-written, tackles a challenging problem), they express significant concerns about the paper's novelty, contributions, and some methodological issues. The lack of author response to address these concerns is also noted negatively. However, the criticism is not entirely harsh, hence a moderately negative score rather than strongly negative. The politeness score is 60 because the reviewer uses respectful and constructive language throughout, balancing criticism with praise and offering specific suggestions for improvement. They acknowledge the authors' honesty about limitations and use phrases like 'I appreciate' and 'it would be helpful if'. The tone remains professional and courteous even when expressing concerns."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and correctness. They state that they 'could not find any novelty in the approach' and point out that the use of the moment's accountant framework is 'not totally correct' in this context. These are major criticisms that suggest the reviewer is not favorable towards the paper. However, the score is not lower because the reviewer does acknowledge the paper's attempt to address a relevant problem (differencing attacks in federated learning). The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'My main concern is...' rather than more confrontational language. The reviewer also provides a detailed explanation of their concerns and even includes a reference for further reading, which is helpful and considerate. However, the score is not higher because the review lacks explicitly polite language or praise for any aspects of the paper.""]"
"['In this work the authors propose an end to end approach for model based reinforcement learning from images, where the main building blocks are locally-linear dynamical systems and variational auto-encoders (VAE). Specifically, it is assumed that the input features (i.e., the images) are generated from a low dimensional latent representation mapped through parametric random functions; the latter are modeled via neural networks. A recognition model based on convolutional neural networks operates on the reverse way and is responsible for projecting the input features to the latent space, in order to proceed with the reinforcement learning task. The variational framework is employed in order to jointly learn the VAE and the linear dynamics on the latent state. As a final step, once the model is fitted a linear quadratic system (LQS) is solved in order to learn the cost function and the optimal policy. \n\n* The paper is well motivated and tries to solve an interesting problem, that of data-efficient reinforcement learning. The experiments are well picked and demonstrate the advantages of the proposed approach towards solving the task, however, the method is only evaluated on few environments and compared against only a couple of other methods. I would expect a broader evaluation and/or comparison against more methods. Since the model is able to reach TRPO’s performance in much less steps it would be nice to see how it performs against PPO from [Schulman et al. 2017] (at least on the simulated environments). Also, would it make sense to compare against [Levine et al. 2016] that has been evaluated on similar tasks?\n\n[Schulman et al 2017] “Proximal Policy Optimization Algorithms”.\n[Levine et al. 2016] “End-to-End Training of Deep Visuomotor Policies”.\n\n* Methodologically, the paper is sound. The model part (as the authors point out) is based on [Johnson et al. 2016] and is well explained. On the other hand, the policy part, and in particular the policy update in Section 4.2 has some issues regarding readability. There is a strong interplay between Section 4.2, Section 2.1 and Appendix D and the authors did not manage to nicely explain what exactly is happening during the update phase. In the beginning the reader has the impression that we are finding the optimal policy via the closed-form LQS. Later on we switch to constrained optimisation for the cost by accounting for the KL divergence between the policy on two episodes. Finally, in the appendix we are back to the original quadratic cost. The authors need to clarify all the above. Also, they need to explicitly mention why they opt for stochastic optimisation (is it because of minibatching?)\n\n* To continue with the policy, in Section 4.2 the authors argue that although the optimal policy can be found in closed form this is not desirable because the policy will overfit the model and will not generalise well in the real environment. I disagree with this statement. If this happens it effectively means that the learned model or the assumption/learning of the linear dynamics is not right. The authors seem to also agree with this since they clearly state in the the experimental section that “... our method does not heavily rely on an accurate model...”. To my understanding, this means that we need to refine the modelling strategy and not learn a sub-optimal policy. I am really interested in the authors opinion on that.\n\n* The above argument is also directly related to the recognition model and learning of the policy in the latent state (I completely agree with that). The recognition network, which in this case is a convolutional neural network, is used as an inference mechanism to project the observations to the latent space. We learn the (variational) parameters of the recognition model by optimising the likelihood’s lower bound. This means that we are “allowed” to overfit the variational parameters as long as the bound gets tighter. This can possibly result in degraded performance during the policy update. Furthermore, the variational distribution of the latent state, i.e., q(z_t | s_t) is assumed to be mean field across time (independent z’s), while clearly this is not the case in the posterior. You somehow mitigate that by augmenting the observed state (feeding consecutive frames to the network), but still this is not ideal. Finally, is there a reason why we only use the mean of the recognition model to fit the cost on the projected latent states? Why are we throwing away the uncertainty? Especially since you do not use an exact solver and follow a stochastic gradient.\n\n* In the end of Section 2.1, the authors argue regarding the fact that the prior work assumes access to a compact low-dimensional representation which does not allow them to perform well on images. Reference is needed.\n\n* In the related work the authors mention modelling bias as a downside of prior work. Can you please elaborate on that? Where does the bias come from and, more importantly, how does your approach overcome this issue?\n\n* In the experiment and specifically in Figure 4 am I right in assuming that the distance to target is measured in actual pixels? Furthermore, why the relevant plot for the reacher task is depicting rewards instead of the distance to target. To me this suggests that the task is not solved. In general what I find very upsetting in the field are plots that only depict accumulated reward for a specific task. There are many situations where the agent learns a weird behaviour that happens to give good rewards (e.g., spinning around the cart-pole), and unfortunately such behaviours are not spotted on the reward plots.\n\nOverall, the paper is nicely presented and definitely an interesting work. However, given the fact that methodologically we have not learned anything new from this paper and in combination with the not satisfying experimental evaluation I warrant for rejection.', 'This paper proposes a model-based reinforcement learning approach, called SOLAR, \nwhich consists of mapping complex, high-dimensional observations to low-dimensional \nrepresentations where transition dynamics between consecutive states are approximately linear. \nIn this low-dimensional space, local models can easily be fit in closed form and then used to optimize a policy, using a similar method to Guided Policy Search (GPS). The method is evaluated in 4 different settings (3 simulated, 1 on a real robot). \n\n*Quality: the method seems to work well in the experiments. However, there are issues with the experimental evaluation (detailed below) which make it unclear whether the method is better than standard baselines.\n\n*Clarity: the paper is well-written and clear overall.  \n\n*Originality: the paper proposes an extension of GPS, which to my knowledge is novel. \n\n*Significance: the idea of learning representations where transitions are linear seems well-founded and potentially useful. However the merits of this method are not yet clear from the experiments. \n\n\nSpecific Comments:\n\n- Please include an illustration of the 2D navigation task in Figure 3a\n- I\'m confused by the poor performance of E2C in the 2D navigation task. \nThe previous works of [Watter et. al, 2015] and [Banijalami et. al, 2017] report close to 100% accuracy using similar methods. Is the task formulated differently here? \n- I would think a global action-conditional forward model (represented as convnet+deconvnet, and trained unrolled on its own predictions to reduce model errors) would perform quite well on the 2D navigation task, and possibly on the reacher task. Even though these are represented as images, they are very simple images with little distracting information, no changes in illumination/perspective, etc. It seems the model essentially just needs to learn a pixel translation for each action for the navigation task, and some rotations for the reacher. It already seems to work quite well for the non-holonomic car, which requires learning similar transformations. This baseline should be included for all the tasks. \n- Although it does seem that the method performs well on the stacking tasks for the real robot, there are no baselines included. However, there are many works which have explored representation learning and control for robotics using neural networks. A couple examples (+see references within):\n\n""Learning to poke by poking: Experiential learning of intuitive physics"" Pulkit Agrawal, Ashvin V Nair, Pieter Abbeel, Jitendra Malik, Sergey Levine. NIPS 2016\n""Deep Visual Foresight for Planning Robot Motion"" Chelsea Finn, Sergey Levine ICRA 2017\n\nAt the very least, the method should be compared to pixel-based global models and representations learned with some kind of autoencoder or forward model for the robot task. \n\nThe paper proposes what seems to be a good idea, but it is not yet demonstrated by the current experiments. ', 'Summary: \n\nThe paper proposes SOLAR a model based RL algorithm that learns a low dimensional embedding such that the dynamics within the latent space are linear. Within this latent space the linear dynamics  are learned using a Bayesian regression. In addition, a quadratic cost function is approximated. The learned dynamics and the cost function are used to update the policy, while simultaneously bounding the change in policy by a KL-bound.  In contrast to other model-based RL algorithms the learned dynamics are not used for planning or imaginary roll-outs and are only used to improve the policy.\n\nReview:\nThe introduction and experiment section is clearly written but the algorithm description lacks clarity and details, which hinder the understanding of the complete algorithm. One understands the motivation and the main approach but lacks a detailed understanding. For my personal taste the detailed description of learning the embedding is missing. I personally would prefer the statement of the cost-functions and the optimisation problem within the paper and not the appendix. The same holds true for the policy improvement. Therefore, I do not fully understand the approach without extensively studying the appendix or the references. Especially the contribution remains unclear. I am not aware how much the previous work had to be extended.\n\nThe experimental evaluation focuses on learning control signal to achieve certain trajectories, where the observations are high-dimensional images rather than low-dimensional representations. I personally think that these tasks are unnecessarily made more complex to incorporate high-dimensional images. Especially, the Sawyer experiment throws away all joint information even though the reward function is solely defined in joint/end-effector position. However, I am aware that this is general practice in the RL community. From the learning curves it seems that the approach is working and achieving good sample complexity compared to model free approaches. However, the improvement over the naive VAE approach remains unclear. I would like to see more comparisons to other model-based approaches. In addition, I am missing qualitative comparisons as the learning curves can be misleading. Especially, the videos on the homepage are really short and do not provide a good overview about the actual performance. Furthermore, you are not providing videos for all models in comparison. The 1s video of a single episode on the reacher task make me wonder what happens in the other episodes. Could you please add longer videos for all comparisons. Furthermore, it would be interesting how the trajectories evolve over time. Could you plot these trajectories? \n\nFurthermore, it would be really interesting to try your approach on breakout. And test if your approach is learning the actual game dynamics and does not overfit to the block configuration. \n\nFurther minor comments:\n- ""This shifts our problem setting to that of a partially observed MDP, as we do not observe the latent state""\nYou are mentioning that you are solving a POMDP. Could you elaborate how you exploit the POMDP formulation and relate your work to POMDP algorithms. In addition, how do you define partial observability? \n\n- You claim ""our method is also successful at handling the complex, contact-rich dynamics of block stacking, which poses a significant challenge compared to the other contactfree tasks."" I am quite doubt-full about the claim. Is the dynamics model really modelling contacts and is your policy really reacting to these contacts? Or is your policy just tying to follow a trajectory? From your current evaluation and the videos, I personally wouldn\'t conclude this. Could you elaborate how you come to this conclusion and provide additional evaluations to solidify your argument? \n\n- You are not describing the action space for the Sawyer experiment. Are you using torques, velocities or positions? Can you guarantee that the control sequence is smooth? If not how do you ensure that the policy does not harm the robot? \n \n- Could you please incorporate the exact  reward functions for each experiment within the appendix.\n\n- Figure 4. Thanks a lot for including the additional model free baselines and adding all learning curves. However, the learning curves raise multiple questions:\n\n(1) The Global Model Ablation, i.e. the MPC in latent space, works well in the the navigation and car experiment however fails \nto achieve a meaning-full policy within the reacher task. Even though the initial performance is significantly better than \nthe other policies. Do you have an explanation for this failure?\n\n(2) The LDS SVAE and VAE Solar version on the reacher task experiences jumps in performance even though the change between policies is bounded by a KL-Bound and the cost function is smooth. How do you explain these jumps? Furthermore, why are these jumps only occurring within the reacher tasks and not the other experiments. \n\n(3) You are still missing the PPO baselines for the reacher and car experiment. Could you further explain the qualitative difference between the model-free and model-based policies. The difference in learning curves can be misleading. \n\n(4) What is the unit of ""Average Distance to Final Goal""? Is this measured in pixel or a different unit? \n\n- Figure 5: You are plotting the distance to the goal as performance measure for the Sawyer experiment. The final policy has an approximate error of 2.5 cm. From just the learning curve I cannot conclude that the robot actually learns the task successfully. Is the block really stacked or can it also be wedged? Could you please provide image overlays of the last 10 episodes such that one can evaluate the qualitative performance? \n\n \n\n']","[-60, -20, -20]","[20, 60, 60]","[""The sentiment score is -60 because while the reviewer acknowledges some positive aspects ('well motivated', 'interesting problem', 'sound' methodology), they ultimately recommend rejection. The review contains several critical points and suggests that the paper does not contribute significant new knowledge. The politeness score is 20 because the reviewer uses generally respectful language and acknowledges positive aspects, but also directly states criticisms. They use phrases like 'I disagree with this statement' and 'I am really interested in the authors opinion on that', which maintain a professional tone while expressing disagreement. The reviewer balances critique with positive feedback, but the overall message is negative, hence the low sentiment score despite the relatively polite language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'the method seems to work well', 'the paper is well-written and clear overall'), they express significant concerns about the experimental evaluation and the lack of comparison to relevant baselines. The overall tone suggests that the paper's merits are not yet fully demonstrated. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as requests for clarification or additional information rather than outright criticism. They use phrases like 'Please include', 'I'm confused by', and 'I would think' which maintain a polite tone while expressing their points."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express several concerns and criticisms. The review points out lack of clarity in algorithm description, missing details, and requests for additional comparisons and evaluations. However, it's not overwhelmingly negative as the reviewer also notes some strengths and provides constructive feedback. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and expresses appreciation for certain aspects (e.g., 'Thanks a lot for including the additional model free baselines'). The reviewer maintains a professional tone, avoiding harsh or rude language, even when pointing out shortcomings.""]"
"['Review for CO-MANIFOLD LEARNING WITH MISSING DATA\nSummary:\nThis paper proposes a two-stage method to recovering the underlying structure of a data manifold using both the rows and columns of an incomplete data matrix. In the first stage they impute the missing values using their proposed co-clustering algorithm and in the second stage they propose a new metric for dimension reduction.\nThe overall motivation for how they construct the algorithm and the intuition behind how all the pieces of the algorithm work together are not great. The paper also has significant specific clarity issues (listed below). Currently these issues seem to imply the proposed algorithm has significant logic issues (mainly on the convex/concave confusions); however depending on how they are addressed, this may end up not being an issue. The experimental results for the two simulated datasets look very good. However for the lung dataset, the results are less promising and it is less clear of the advantage of the proposed algorithm to the two competing ones. \nNovelty/Significance:\nThe overall idea of the algorithm is sufficiently novel. It is very interesting to consider both rows and column correlations. Each piece of the algorithm seems to draw heavily on previous work; bi-clustering, diffusion maps, but overall the idea is novel enough. The algorithm is significant in that it addresses a relatively open problem that currently doesn’t have a well established solution.\nQuestions/Clarity:\nSmooth is not clearly defined and not an obvious measure for a matrix. Figure 1 shows smooth matrices at various levels, but still doesn’t define explicitly what smoothness is. Does smoothness imply all entries are closer to the same value? \n “Replacing Jr(U) and Jc(U) by quadratic row and column Laplacian penalties” – The sentence is kind of strange as Laplacian penalties is not a thing. Graph Laplacian can be used as an empirical estimate for the Laplace Beltrami operator which gives a measure of smoothness in terms of divergence of the gradient of a function on a manifold; however the penalty is one on a function’s complexity in the intrinsic geometry of a manifold. It is not clear how the proposed penalty is an estimator for the intrinsic geometry penalty. It seems like the equation that is listed is just the function map Omega(x) = x^2, which also is not a concave function (it is convex), so it does not fit the requirements of Assumption 2.2.\nProposition 1 is kind of strangely presented. At first glance, it is not clear where the proof is, and it takes some looking to figure out it is Appendix B because it is reference before, not after the proposition. Or it might be more helpful if it is clearly stated at the beginning of Appendix B that this is the proof for Proposition 1.\nThe authors write: “Missing values can sabotage efforts to learn the low dimensional manifold underlying the data. … As the number of missing entries grows, the distances between points are increasingly distorted, resulting in poor representation of the data in the low-dimensional space.” However, they use the observed values to build the knn graph used for the row/column penalties, which is counter-intuitive because this knn graph is essentially estimating a property of a manifold and the distances have the same distortion issue.\nWhy do the author’s want Omega to be concave functions as this makes the objective not convex. Additionally the penalty sqrt(|| ||_2) is approximately doing a square root twice because the l2-norm already is the square root of the sum of squares. Also what is the point of approximating the square root function instead of just using the square root function? It is overall not clear what the nature of the penalty term g2 is; Appendix A, implies it must be overall a convex function because of the upper bound.\nEquation 5 is not clear that it is the first order taylor approximation. Omega’ is the derivative of the Omega function? Do the other terms cancel out? Also what is the derivative with respect to; each Ui. for all Uj. ?\n “first-order Taylor approximation of a differentiable concave function provides a tight bound on the function” – Tight bound is not an appropriate term and requires being provable. Unless the function is close to linear, a first order Taylor approximation won’t be anything close to tight.\nThe authors state the objective in 1 is not convex. Do they mean it is not strictly convex? In which case, by stationary points, they are specifically referring to local minima? Otherwise, what benefits does the MM algorithm have on an indefinite objective i.e. couldn’t you end up converging to a saddle point or a local maxima instead of a local minima, as these are all fixed points. \nIt is not clear what the sub/super scripts l, k mean. Maybe with these defined, the proposed multi-scale metric would have obvious advantages, but currently it is not clear what the point of this metric is.\nFigure 4 appears before it is mentioned and is displayed as part of the previous section.\nFor the Lung data, it does not look like the proposed algorithm is better than the other two. None of the algorithms seem to do great at capturing any of the underlying structure, especially in the rows. It also is not super clear that the normal patients are significantly further from the cancer patients. Additionally are the linkage results from figure 3 from one trial? Without multiple trials it is hard to argue that this not just trial noise.\nHow big are N1 and N2 in the linkage simulations. The Lung dataset is not very large, and it seems like the proposed algorithm has large computation complexity (it is not clear). Will the algorithm work on even medium-large sized matrices (10^4 x 10^4)?\n', ""This paper presents a joint learning method for filling missing value and bi-clustering. The method extends (Chi et al. 2017), using a penalized matrix approximation. The proposed method is tested on three data sets, where two are synthetic and one small real-world data matrix. The presented method is claimed to be better than two classical approaches Nonlinear PCA and Diffusion Maps.\n\n1) Filling missing values is not new. Even co-clustering with missing values also exists. It is insufficient to defeat two methods which are older than ten years. More extensive comparison is needed but lacking here. Why not first use a dedicated method such as MICE or collaborative filtering, and then run embedding method on rows and columns?\n\n2) The purpose of the learning is unclear. The title does not give any hint about the learning goal. The objective function reads like filling missing values. The subsequent text claims that minimizing such a objective can achieve biclustering. However, in the experiment, the comparison is done via visualization and normal clustering (k-means).\n\n3) The empirical results are not convincing. Two data sets are synthetic. The only real-world data set is very small. Why k-means was used? How to choose k in k-means?\n\n4) The choice Omega function after Proposition 1 needs to be elaborated. A function curve plot could also help.\n\n5) What is Omega' in Eq. 2?"", ""The manuscript proposes a co-manifold learning approach for missing data.  The problem is important, but the method is lack of novelty. \nPros: important problem setting, Good experimental results.\nCons: the method is lack of novelty.\n\nIn detail, the method just simply combines a loss for competing missing values, which is not new,  and Laplacian losses for rows and columns, which are also not new. I don't see much novelty in the model.  \n""]","[-40, -50, -50]","[20, 0, 0]","[""The sentiment score is -40 because the review expresses several concerns and criticisms about the paper, particularly regarding clarity issues and potential logical problems. The reviewer states that 'the overall motivation for how they construct the algorithm and the intuition behind how all the pieces of the algorithm work together are not great.' However, the score is not extremely negative because the reviewer acknowledges some positive aspects, such as the novelty of the idea and good results for simulated datasets. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding harsh language or personal attacks. They provide constructive feedback and specific questions for improvement. The use of phrases like 'it is very interesting' and 'the overall idea of the algorithm is sufficiently novel' shows a degree of politeness and respect for the authors' work, even while pointing out areas for improvement."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings and areas for improvement. The reviewer acknowledges the proposed method but expresses concerns about its novelty, comparison with older methods, unclear learning goals, and unconvincing empirical results. However, it's not entirely negative as it does recognize the work done and suggests improvements.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite language or rude expressions. The critique is direct and to the point, listing concerns and suggestions in a matter-of-fact manner without personal attacks or overly courteous phrasing. The language is typical of academic peer reviews, focusing on the content rather than being particularly polite or impolite."", ""The sentiment score is -50 because the review is generally negative, highlighting a lack of novelty in the method, which is a significant criticism in academic research. However, it does acknowledge some positive aspects ('important problem setting, Good experimental results'), preventing it from being extremely negative. The politeness score is 0 (neutral) because the reviewer uses direct, matter-of-fact language without being overtly polite or rude. They state their opinions clearly but without using harsh or overly critical language, maintaining a professional tone throughout the review.""]"
"[""# Summary of the paper\n\nInspired by the success of deep filter banks, this paper presents a designed deep filter bank for graphs that is based on random walks.  More precisely, the technique uses lazy random walks, expressed in terms of the graph Laplacian, and re-frames this in terms of graph signal processing. Similarly to wavelets, graph node features are calculated at different scales and subsequently summed in order to remain invariant under permutations. Several experiments on graph data sets demonstrate the performance of the new technique.\n\n# Review\n\nThis paper is written very well and explains its method with high clarity. The principal issues I see are as follows:\n\n- The originality of the contributions is not clear\n- Missing theoretical discussion\n- The experimental setup is terse and slightly confusing\n\nConcerning the originality of the paper, the differences to Gama et al., 'Diffusion Scattering Transforms on Graphs' are not made clear. Cursory reading of this publication shows a large degree of similarity. Both of the papers make use of diffusion geometry, but Gama et al. _also_ define a multi-scale filter bank, similar to Eq. 4 and 5. The paper needs to position itself more clearly vis-à-vis this other publication. Is the present approach to be seen more as an application of the theory that was developed in the paper by Gama et al.? What are the key similarities and differences? In terms of space, this could be added to Section 3.2, which could be rephrased as a generic 'Differences to other methods' section and has to be slightly condensed in any case (see my suggestions below). Another publication by Zou & Lerman, 'Graph Convolutional Neural Networks via Scattering', is also cited as an inspiration, but here the differences are larger in my understanding and do not necessitate further justification. Last, the publication 'Graph Capsule Convolutional Neural Networks' by Verma & Zhang is also cited for the definition of 'scattering capsules'. Again, cursory reading of the publication shows that this approach is similar to the presented one; the only difference being which features are used for the definition of capsules. I recommend referring to the invariants as 'capsules' and link it back to Verma & Zhang so that the provenance of the terminology is clear.\n\nConcerning the theoretical part of the paper, I miss a discussion of the complexity of the approach. Such a discussion does not have to be long, but in particular since the paper mentions that the applicability of scattering transforms for transfer learning (and also remarks about the universality of them in Section 4), some space should be devoted to theoretical considerations (memory complexity, runtime complexity). This would strengthen the paper a lot, in particular in light of the complexity of other approaches! Furthermore, an additional experiment about the stability of scattering transforms appears warranted. While I applaud the experimental description in the paper (number of scales, how the maximum scale is chosen, ...), an additional proof or experiment in the appendix should deal with the stability. Let's assume that for extremely large graphs, I am content with 'almost-but-not-quite-as-good' classification performance. Is it possible to achieve this by limiting the number of scales? How much to the results depend on the 'right' choice here?\n\nConcerning the experimental setup, I think that the way (average) accuracies are reported at present is slightly misleading. The paper even remarks about this in footnote 2. While I understand the need of demonstrating the universality of these features, I think that the current setup is not optimal for this. I would recommend (in addition to reporting accuracies) a transfer learning setup rather in which the beneficial properties of the new method can be better explored. More precisely, the claim from Section 4, 4th paragraph ('Since the scattering transform...') needs to be further explored. This appears to be a unique feature of the new method. The current experimental setup does not exploit it. As a side-note, I realize that this might sound like a standard request for 'show more experiments', but I think the paper would be more impactful if it contained one scenario in which its benefits over other approaches are clear.\n\n# Suggestions for improvement\n\nThe paper flows extremely well and it is clear that care has been taken to ensure that everything can be understood. I liked the discussion of invariance properties in particular. There are only a few minor things that can be improved:\n\n- 'covariant' and 'equivariant', while common in (graph) signal processing, could be briefly explained to increase accessibility and impact\n- 'order' and 'layer' are not used consistently: in the caption of Figure 2a, the term 'order' is used, but for Eq. 4 and 5, for example, the term 'layer' is employed. Since 'layer' is more reminiscent of a DNN, I would suggest to use 'order' throughout the paper, because it meshes better with the way the scattering invariants are defined.\n- the notation $Sx$ is slightly overloaded; in Figure 2a, for example, it is not clear at first that the individual cascades are supposed to form a *set*; this is only explained at the end of Section 3.1; to make matters more consistent, the figure should be updated and the combination of individual cascades should be made clear\n- In Eq. 5, the bars of the absolute value are not set correctly; the absolute value should cover $\\psi_j x(v_i)$ and not $(v_i)$ itself.\n- minor 'gripe': $\\psi^{(J)}$ is defined as a set in Eq. 2, but it is treated as a matrix or an operator (and also referred to as such); this should be more consistent\n- The discussion of the aggregation of multiple statistics in Section 3.2 appears to be somewhat redundant in light of the discussion for Eq. 4 and Eq. 5 in the preceding section\n- in the appendix, more details about the training of the FCN should be added; all other parts of the experiments are described in sufficient detail, but the training process requires additional information about learning rates etc."", ""This paper generalizes scattering transform to graphs. It defines wavelets, scattering coefficients on graph signals. The experimental section describes their use in classification tasks with comparisons with recent methods. It seems scattering performs less well than SOTA methods, but has the advantages of not requiring any training so potentially good candidates for low data regimes application. Interesting and original paper and ideas being developed, but might be a tiny bit weak in term of results, both theoretical and experimental ?\n\nThere is not much theoretical results (mostly definition and hints that some of the results from euclidian case might generalize without formal investigation).\n\nRegarding the results, in particular table3, given that you use particular hyper parameters J and Q, for each dataset, this is arguably a bit of architectural overfitting ? Results would be more convincing IMO if obtained with a single set of hyper parameters. What was the procedure to come up with those parameters ?\n\nRegarding the methodology for training the classifier, I am not familiar with these datasets but using just a 1/10 of the data to train classifier seems a bit extreme ? \nHow about training each on 90% random subset of training set and averaging ? Or just the whole training subset ? That would still be fine in the sense that none of the classifier would have seen the test set ?\n\np2 '~it naturally extends to multiple signals by concatenating their scattering features~'\n\nP4 figure 1: Not very clear what those visualizations are. \\Psi_j is supposedly a n x n matrix so, is this \\Psi_j applied to a two different Dirac on the graph ? Would be good to clarify exactly what is being plotted in the legend.\n\nseems to be the biggest limitations of the proposed approach. By not early mixing of different features one might lose the high frequencies correlations between different signals defined on a single graph.\n\nP4. IMO capsule is not such a great name / already used in ML by Hinton's capsule etc... Why not simply 'moments' or 'statistics' ? \n\n'We can replace (3) with normalized moments of x ... how exactly do you normalize ? "", 'The authors propose an advance in geometric deep learning based on a geometric scattering transform using graph wavelets defined in terms of ran- dom walks on the graph. The paper is well written, easy to understand also for a not-so-tech audience but nevertheless precise in all the mathematical details.\nIntro and references are satisfactory, and also the experimental section is sufficiently convincing. However, there are two big issues undermining the overall structure of the manuscript: \na) the theoretical novelty w.r.t. (Zou & Lerman, 2018) and (Game, 2018) is partial and rather technical, so the originality of the present manuscript is limited\nb) the improvement w.r.t. to other published method is rather small, so the performance gain is only partially justified by the quite complex theoretical construction.']","[20, 20, -20]","[80, 60, 60]","[""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper is well-written and explains its method clearly, they also point out several significant issues such as unclear originality, missing theoretical discussion, and a confusing experimental setup. The overall tone is constructive but with substantial criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'I applaud the experimental description' and 'The paper flows extremely well' demonstrate a polite and considerate tone, even when providing critical feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'Interesting and original' with 'ideas being developed', but also notes that it might be 'a tiny bit weak in term of results'. The reviewer provides constructive criticism and suggestions for improvement, indicating a generally positive but cautious stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'Results would be more convincing IMO if...', 'How about...?'), and acknowledges the paper's strengths. The reviewer maintains a professional tone, avoiding harsh or dismissive language, and offers specific, actionable feedback for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (well-written, easy to understand, precise), they also point out two 'big issues' that undermine the manuscript. The criticism about limited originality and only partial improvement over existing methods outweighs the initial positive comments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'sufficiently convincing' and 'partially justified' which soften the critique. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out weaknesses.""]"
"[""This paper presents a way use using FSA-augmented MDPs to perform AND and OR of learned policies. This idea is motivated by the desirability of compositional policies. I find the idea compelling, but I am not sure the proposed method is a useful solution. Overall, the description of the method is difficult to follow. With more explanations (perhaps an algorithm box?), I would consider increasing my score.\n\nThe experiments demonstrate that this method can outperform SQL at skill composition. However, it is unclear how much prior knowledge is used to define the automaton. If prior knowledge is used to construct the FSA, then a missing comparison would be to first find the optimal path through the FSA and then optimize a controller to accomplish it. As the paper is not very clear, that might be the method in the paper. \n\nQuestions:\n- How do you obtain the number of automaton states? \n- In Figure 1, are the state transitions learned or handcoded? Are they part of the policy's action space?\n- In section 3.2, you state  s_{t:t+k} |= f(s)<c ⇔ f(s_t)<c    What does s without a timestep subscript refer to? Why does this statement hold?\n\nCan you specify more clearly what you assume known in the experiments? What is learned in the automata? In Figure 5, does SQL have access to the same information as Automata Guided Composition?"", 'This paper mainly focuses on combining RL tasks with linear temporal logic formulas and proposed a method that helps to construct policy from learned subtasks. This method provides a structured solution for reusing learned skills (with scTLTL formulas), and can also help when new skills need to be involved in original tasks. The topic of the composition of skills is interesting. However, the joining of LTL and RL has been developed previously. The main contribution of this work is limited to the application of the previous techniques.\n\nThe proposed approach also has some limitations. \nWill this method work on composing scTLTL formula with temporal operators other than disjunction and conjunction?\nCan this approach deal with continuous state space and actions? This paper describes a discretization way, which, however, can introduce inaccuracies. \nThe design of the skills is by hand, which restricts badly its usability.\nThe experiments results show that the composition method does better than soft Q-learning on composing learned policies, but how it performed compared to earlier hierarchical reinforcement learning algorithms? \n  ', 'This work proposed using temporal logic formulas to augment RL learning via the composition of previously learned skills. This work was very difficult to follow, so it is somewhat unclear what were the main contributions (since much of this seems to be covered by other works as referenced within the paper and as related to similar unreferenced works below). Moreover, regarding the experiments, many things were unclear (some of the issues are outlined below). While the overall idea of using logic in this way to help with skill composition is interesting and exciting, I believe several things must be addressed with this work. This includes: situating this work more clearly against existing similar works which use logic in this way, clearly defining the novel contributions of this work as compared to those and others, overall making the methodology more clear and specific (including experimental methodology), and comparing/contrasting against (or at least discussing differences with) methods with similar motivations (e.g., HRL multi-task learning, meta-learning) to emphasize the need/importance of this work — I am aware that at least 1 HRL work is mentioned, but this work is not really contrasted against it to help situate it.\n\nQuestions/Concerns about Experiments:\n\n+ Does Figure 5 show the averaged return over 5 runs, sum of discounted rewards averaged over 5 episodes per update step, or 5 episodes, each from a separate run averaged together? It is a bit unclear especially because the main text and the figure caption slightly differ. Also, average discounted return is somewhat different than average return,  suggest updating the label to be clear also with the discount factor used.\n+ What were the standard deviations for this across experiments? Even with averaging it seems that these runs are very high variance, would be good to understand what variance bounds to expect if using this method.\n+ Why were average discounted returns reported in Figure 5 and not in Table 1?\n+  What were the standard deviations on success rate and training time? Also what about sample complexity? \n+ To my understanding the benefit here is reusability of learned skills via the automata methods described here. It would have made sense to compare against other HRL or multi-task learning methods in addition to just SQL or learning from scratch. For example how would MAML compare to this?\n+ It is also unclear whether the presented results in Table 1 and Figure 5 are on the real robot or in simulation. The main text says, “All of our training is performed in simulation and the policy is able to transfer to the real robot without further fine-tuning.” So does this mean that Figure 5 is simulated results and Table 1 is on the real robot?\n\n\n\nCitations that should likely be made:\n\n+ Giuseppe, Luca Iocchi, Marco Favorito, and Fabio Patrizi. ""Reinforcement Learning for LTLf/LDLf Goals.""\xa0arXiv preprint arXiv:1807.06333\xa0(2018).\xa0\n+ Camacho, Alberto, Oscar Chen, Scott Sanner, and Sheila A. McIlraith. ""Decision-making with non-markovian rewards: From LTL to automata-based reward shaping.""\xa0 In\xa0Proceedings of the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), pp. 279-283. 2017. \n+ Camacho, Alberto, Oscar Chen, Scott Sanner, and Sheila A. McIlraith. ""Non-Markovian Rewards Expressed in LTL: Guiding Search Via Reward Shaping."" In Proceedings of the Tenth International Symposium on Combinatorial Search (SoCS), pp. 159-160. 2017.\xa0\n\n\nTypos/Suggested grammar edits:\n\n“Skills learned through (deep) reinforcement learning often generalizes poorly across tasks and re-training is necessary when presented with a new task.” —> Often generalize poorly\n\n“We present a framework that combines techniques in formal methods with reinforcement learning (RL) that allows for convenient specification of complex temporal dependent tasks with logical expressions and construction of new skills from existing ones with no additional exploration.” —> Sentence kind of difficult to parse and is a run-on\n\n“Policies learned using reinforcement learning aim to maximize the given reward function and is often difficult to transfer to other problem domains.” —> ..and are often..\n\n“by authors of (Todorov, 2009) and (Da Silva et al., 2009)” —> by Todorov (2009) and Da Silva et al. (2009) Also several other places where you can use \\citet instead of \\cite', 'The contribution of the paper is to set up an automaton from scTLTL formulas, then corresponding MDP that satisfies the formulas is obtained by augmenting the state space with the automaton state and zeroing out transitions that do not satisfy the formula. This approach seems really useful for establishing safety properties or ensuring that constraints are satisfied, and it is a really nice algorithmic framework. The RL algorithm for solving the problem is entropy-regularized MDPs. The approach “stitches” policies using AND and OR operators, obtaining the overall optimal policy over the aggregate. Proofs just follow definitions, so they are straightforward, but I think this is a quality. The approach is quite appealing because it provides composition automatically. The paper is very well written.  The main problem I see with the work is that composition can explode the number of states in the new automaton and hence the new MDP. It would be interesting in future work to do “soft” ruling out of transitions rather than the ""hard"" approach used in the paper. The manipulation task provided is quite appealing, as the robot arm is of high dimensionality but the FSAs obtainedare discrete. Overall, the paper provides a very good contribution.\n\nSmall comments:\nEquation equation in Def 3 also proof of Theorem 2\nIn section,  -> In this section\nare it has -> and it has']","[-20, -20, -40, 80]","[50, 50, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the idea 'compelling', they express significant doubts about the usefulness of the proposed method and the clarity of its description. They state that they 'are not sure the proposed method is a useful solution' and that the 'description of the method is difficult to follow'. However, they do offer the possibility of increasing their score with more explanations, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as personal opinions ('I find', 'I am not sure') and offering constructive suggestions for improvement. They also ask questions for clarification rather than making outright negative statements. The tone is professional and objective, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting topic and some positive aspects of the paper, they also point out several limitations and suggest that the main contribution is limited. The review starts positively but then shifts to a more critical tone. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases criticisms as questions or observations rather than direct attacks. They acknowledge the paper's strengths before discussing its weaknesses, which is a polite approach. The reviewer also uses phrases like 'interesting' and avoids harsh or dismissive language, maintaining a professional and respectful tone throughout the review."", ""The sentiment score is -40 because the review expresses significant concerns and criticisms about the paper, stating it was 'very difficult to follow' and that 'several things must be addressed'. However, it's not entirely negative as the reviewer acknowledges the idea is 'interesting and exciting'. The politeness score is 20 because while the reviewer is direct in their criticisms, they use polite language such as 'I believe' and 'suggest', and offer constructive feedback. The reviewer also provides detailed suggestions for improvement, which is helpful and courteous. The tone is professional and objective, avoiding harsh or rude language."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, using phrases like 'really useful', 'really nice algorithmic framework', 'quite appealing', 'very well written', and 'very good contribution'. The only criticism is minor and presented as a suggestion for future work. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths and offering constructive feedback. The tone is consistently positive and encouraging, with even the criticism framed politely as an interesting future direction. The use of phrases like 'The paper is very well written' and 'Overall, the paper provides a very good contribution' further contribute to the polite tone.""]"
"[""In this paper, an efficient re-training algorithm for neural networks is proposed. The essence is like Hinton's distillation, but in addition to use the output of the last layer, the outputs of intermediate layers are also used. The core idea is to add 1x1 convolutions to the end of each layer and train them by fixing other parameters. Since the number of parameters to train is small, it performs well with the small number of samples such as 500 samples. \n\nThe proposed method named FKSD is simple yet achieves good performance. Also, it performs well with a few samples, which is desirable in terms of time complexity. \n\nThe downside of this paper is that there is no clear explanation of why the FKSD method goes well. For me, adding 1x1 convolution after the original convolution and fitting the kernel of the 1x1 conv instead of the original kernel looks a kind of reparametrization trick. Of course, learning 1x1 conv is easier than learning original conv because of a few parameters. However, it also restricts the representation power so we cannot say which one is always better. Do you have any hypothesis of why 1x1 conv works so well?\n\n\n\nMinor:\n\nThe operator * in (1) is undefined.\n\nWhat does the boldface in tables of the experiments mean? I was confused because, in Table 1, the accuracy achieved by FKSD is in bold but is not the highest one.\n"", 'Model distillation can be tricky and in my own experience can take a lot of samples (albeit unlabeled, so cheaper and more readily available), as well as time to train. This simple trick seems to be doing quite well at training students quickly with few samples. However, it departs from most student-teacher training that find its primary purpose by actually outperforming students trained from scratch (on the full dataset without time constraints). This trick does not outperform this baseline, so its emphasis is entirely on quick and cheap. However, it\'s unclear to me how often that is actually necessary and I don\'t think the paper makes a compelling case in this regard. I am borderline on this work and could probably be swayed either way.\n\nStrengths:\n- It\'s a very simple and fast technique. As I will cover in a later bullet point (under weaknesses), the paper does not make it clear why this type of model distillation is that useful (since it doesn\'t improve the student model over full fine-tuning, unlike most student-teacher work). However, the reason why I do see some potential for this paper is because there might be a use case in quickly being able to adapt a pretrained network. It is very common to start from a pretrained model and then attach a new loss and fine-tune. Under this paradigm, it is harder to make architectural adjustments, since you are starting from a finite set of pretrained models made available by other folks (or accept the cost of re-training one yourself). However, it is unclear how careful one needs to treat the pretrained model if more fine-tuning is going to occur. If for instance you could just remove layers, drop some channels, glue it all together, and then that model would still be reasonable as a pretrained model since the fine-tuning stage could tidy everything up, then this method would not be useful in this situation.\n- The fact that least squares solvers can be used at each stage, without the need for a final end-to-end fine-tune is interesting.\n- It is good that the paper demonstrates improvements coupled with three separate compression techniques (Li et al., Liu et al., Guo et al.).\n- The paper is technically thorough.\n- It\'s good that the method is evaluated on different styles of networks (VGG, ResNet, DenseNet).\n\nWeaknesses:\n- Limited application because it only makes the distillation faster and cheaper. The primary goal of student-teacher training in literature is to outperform a student trained from scratch by the wisdom of the teacher. It ties into this notion that networks are grossly over-parameterized, but perhaps that is where the training magic comes from. Student-teacher training acknowledges this and tries to find a way to benefit from the over-parameterized training and still end up with a small model. I think the same motivation is used for work in  low-rank decomposition and many other network compression methods. However, in Table 1 the ""full fine-tune"" model is actually the clear winner and presented almost as an upper bound here, so the only benefit this paper presents is quick and cheap model distillation, not better models. Because of this, I think this paper needs to spend more time making a case for why this is so important.\n- Since this technique doesn\'t outperform full fine-tuning, the goal of this work is much more focused on pure model compression. This could put emphasis on reducing model size, RAM usage reduction, or FLOPS reduction. The paper focuses on the last one, which is an important one as it correlates fairly well with power (the biggest constraint in most on-device scenarios). However, it would be great if the paper gave a broader comparison with compression technique that may have slightly different focus, such as low-rank decomposition. Size and memory usage could be included as columns in tables like 1, along with a few of these methods. \n- Does it work for aggressive compression? The paper presents mostly modest reductions (30-50%). I thin even if accuracy takes a hit, it could still work to various degrees. From what I can see, the biggest reduction is in Table 4, but FSKD is used throughout this table, so there is no comparison for aggressive compression with other techniques. \n- The method requires appropriate blocks to line up. If you completely re-design a network, it is not as straightforward as regular student-teacher training. Even the zero-student method requires the same number of channels at certain block ends and it is unclear from the experiments how robust this is. Actually, a bit more analysis into the zero student would be great. For instance, it\'s very interesting how you randomly initialize (let\'s say 3x3) kernels, and then the final kernels are actually just linear combinations of these - so, will they look random or will they look fairly good? What if this was done at the initial layer where we can visualize the filters, will they look smooth or not?\n\nOther comments:\n- A comparison with ""Deep Mutual Learning"" might be relevant (Zhang et al.). I think there are also some papers on gradually adjusting neural network architectures (by adding/dropping layers/channels) that are not addressed but seem relevant. I didn\'t read this recently, but perhaps ""Gradual DropIn of Layers to Train Very Deep Neural Networks"" could be relevant. There is at least one more like this that I\'ve seen that I can\'t seem to find now.\n- It could be more clear in the tables exactly what cited method is. For instance, in Table 1, does ""Fine-tuning"" (without FitNet/FSKD) correspond to the work of Li et al. (2016)? I think this should be made more clear, for instance by including a citation in the table for the correct row. Right now, at a glance, it would seem that these results are only comparing against prior work when it compares to FitNet, but as I read further, I understood that\'s not the case.\n- The paper could use a visual aid for explaining pruning/slimming/decoupling.\n\nMinor comments:\n- page 4, ""due to that too much hyper-parameters""\n- page 4, ""each of the M term"" -> ""terms""\n- page 6, methods like FitNet provides"" -> ""provide""', 'This paper proposes a framework for few-sample knowledge distillation of convolution neural networks. The basic idea is to fit the output of the student network and that of the teacher network layer-wisely. Such a regression problem is parameterized by a 1x1 point-wise convolution per layer (i.e. minimizing the fitting objective over the parameters of 1x1 convolutions). The author claims such an approach, called FSKD, is much more sample-efficient than previous works on knowledge distillation. Besides, it is also fast to finish the alignment procedure as the number of parameters is smaller than that in previous works. The sample efficiency is confirmed in the experiments on CIFAR-10, CIFAR-100 and ImageNet with various pruning techniques. In particular, FSKD outperforms the FitNet and fine-tuning by non-trivial margins if only small amount of samples are provided (e.g. 100).\n\nHere are some comments:\n\n1. What exactly does “absorb” mean? Is it formally defined in the paper?\n\n2. “we do not optimize this loss all together using SGD due to that too much hyper-parameters need tuning in SGD”. I don’t understand (1) why does SGD require “too much” hyper-parameters tuning and (2) if not SGD, what algorithm do you use?  \n\n3. According to the illustration in 3.3, the algorithm looks like a coordinate decent that optimizing L over one Q_j at a time, with the rest fixed. However, the sentence “until we reach the last block in the student-net” means the algorithm only runs one iteration, which I suspect might not be sufficient to converge.\n\n4. It is also confusing to use the notation SGD+FSKD v.s. FitNet+FSKD, as it seems SGD and FitNet are referring to the same type of terminology. However, SGD is an algorithm, while FitNet is an approach for neural network distillation. \n\n5. While I understand the training of student network with FSKD should be faster because the 1x1 convolution has fewer parameters to optimize, why is it also sample-efficient? \n\n6. I assume the Top-1 accuracies of teacher networks in Figure 4 are the same as table 2 and 3, i.e. 93.38% and 72.08% for CIFAR-10 and CIFAR-100 respectively. Then the student networks have much worse performance (~85% for CIFAR-10 and ~48% for CIFAR-100) than the teachers. So does it mean FSKD is not good for redesigned student networks?\n\n7. While most of the experiments are on CIFAR10 and CIFAR100, the abstract and conclusion only mention the results of ImageNet. Why?']","[50, -20, 20]","[70, 60, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the proposed method's good performance and efficiency, especially with small sample sizes. However, they also point out a downside, which is the lack of clear explanation for why the method works well. This balanced view indicates a moderately positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, asks a thoughtful question about the method's effectiveness, and frames criticisms constructively. The use of phrases like 'For me' and 'Do you have any hypothesis' shows a collegial tone. The minor points are presented as neutral observations rather than harsh criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express significant reservations about its usefulness and impact. The reviewer states they are 'borderline on this work' and points out several weaknesses, including limited application and lack of outperformance compared to full fine-tuning. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They offer balanced feedback, acknowledging strengths before discussing weaknesses, and use polite language such as 'It's good that...' and 'It could be more clear...'. The reviewer also offers suggestions for improvement rather than just criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and the effectiveness of the proposed FSKD method, especially in sample-efficient scenarios. However, the reviewer also raises several questions and points of confusion, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'I don't understand' and 'It is also confusing' rather than making accusatory statements. The reviewer offers constructive feedback and asks for clarification on various points, which is a polite way to address concerns. The use of 'Here are some comments' also sets a neutral, professional tone for the critique.""]"
"['This paper introduces LIT, a network compression framework, which uses multiple intermediate representations from a teacher network to guide the training of a student network. Experiments are designed such that student networks are shallower than teacher networks, while maintaining their width. The method is validated on CIFAR-10 and 100 as well as on Amazon Reviews.\n\nThe paper is clearly written and easy to follow. The main novelty of the paper is essentially using the teacher intermediate representations as input to the student network to stabilize the training, and applying the strategy to recent networks and tasks.\n\nThe authors claim that they are only concerned with knowledge transfer between layers of the same width, that is teacher and student network been designed (by model construction) to have the same number of downsampling operations, while maintaining the same number of stages (referred to as sections in the paper). However, resnet-based architectures have been shown to perform iterative refinement of their features between downsampling operations (see e.g. https://arxiv.org/pdf/1612.07771.pdf and https://arxiv.org/pdf/1710.04773.pdf ). Moreover, these models were also shown to be good regularizers, since they can reduce their model capacity as needed (see https://arxiv.org/pdf/1804.11332.pdf).  Therefore, having experiments skipping stages would be interesting, and may allow to further compress the networks (by skipping layers or stages which do not incorporate much transformation). Following https://arxiv.org/pdf/1804.11332.pdf, for the sake of completeness, it might also be interesting to compare LIT results to the ones obtained by just removing layers in the teacher network which have small weight norms.\n\nIn method, the last sentence before ""knowledge distillation loss"" suggests the training of student networks might not be done end-to-end. Could the authors clarify this?\nIt seems there might be a typo in the KD loss of ""knowledge distillation loss"", equation (2). Shouldn\'t the second term of the equation be a function of p^T and q^T (with temperature)?\n\nI would suggest changing ""sections"" to stages, as previously introduced in https://arxiv.org/pdf/1612.07771.pdf .\n\nAs for the experiments, it would be more interesting to see this kind of analysis on ImageNet (pretained resnet models are readily available).\nFigure 3, why not add hint training as well?\nFigure 4, what\'s the dataset used here?\n\nIn Section 4.2, it seems that the choice of the IR layer in the analysis could have a significant impact. How was the layer chosen for the ablation study experiments?\n\nThere are a few overstatements in the paper:\n- page 5, paragraph 2: FitNets proposes a general framework to transfer knowledge from a teacher network to a student network through intermediate layers. Thus, the framework itself does not require the student networks to be deeper and thinner than the teacher network.\n- page 6, ""LIT can compress GANs"": authors claim to overcome limitations of KD when it comes to applying knowledge transfer to pixel-wise architecture that do not output distributions. It seems that changing the loss and using a l2 loss instead is a rather minor change, especially since performing knowledge transfer by means of l2 (although at intermediate layers) has already been explored in FitNets.\n\nPlease add references for inception and FID scores.\nPlease fix references format in page 10.', 'This paper proposes to compress the model by depth. It uses hint training and knowledge distillation techniques to compress a ""deep"" network block-wisely. It shows a better compression ratio than knowledge distillation or hint training while achieving comparable accuracy performance.\n\nPros: \n1. This paper considers block-wise compression. For each block, it uses the output of the teacher\'s last layer as input during training, which improves the learnability of the student models. \n2. The experiments include a large range of tasks, e.g., image classification, sentiment analysis and GAN. \n\nCons:\n1. Validation accuracy is used as the performance metric, which might be over-tuned. How is the performance on testing datasets?\n2. The writing and organization of the paper need some improvement, especially the experiments section.\n3. The compression ratio (3-5) is not very impressive compared with other compression techniques with pruning and quantization techniques, such as Han et al. 2015, Hubara et al. 2016.\n\nIn summary, I think this is an interesting approach to compress deep learning models. But I think the comparisons should be done in terms of testing accuracy. Otherwise, it is hard to judge the performance of this approach. \n\n=== after rebuttal ===\nThanks for the authors\' response. Some of my concerns have been clarified. I increased my rating from 5 to 6. \n', ""This paper proposes a new approach to compress neural networks by training the student's intermediate representation to match the teacher's.\n\nThe paper is easy to follow. The idea is simple. The motivation and contribution are clear. The experiments are comprehensive.\n\nOne advantage of the proposed approach that the authors did not mention is that LIT without KD can be optimized in parallel, though I'm not sure how useful this is.\n\nOne major weakness of the paper is how the hyperparameters, such as the number of layers, the alpha, beta, tau, and so on, are tuned. It is not clear from the paper that there is a separate development set for tuning these values. If the hyperparameters are tuned on the test set, then it is not surprising LIT works better.\n\nHere are some minor questions:\n\np.5\n\nLIT outperforms KD and hint training on all settings.\n--> what are the training errors (cross entropy) for LIT, KD and hint training? what about the KD objectives (on the training set) of the model trained with LIT and the one trained with KD? this might tell us why LIT is better than the two.\n\nLIT outperforms the recently proposed Born Again procedure ...\n--> what are the training errors (cross entropy) before and after the born again procedure? this might help us understand why LIT is better.\n\nKD degrades the accuracy of student models when the teacher model is the same architecture\n--> again, the training errors (cross entropy) might be able to help us understand what is going on.\n\np.7\n\nAs shown in Table 3, none of the three variants are as effective as LIT or KD.\n--> is this claim statistically significant? some of the differences are very small.\n\nWe additionally pruned ResNets trained from scratch.\n--> what pruning method is being used?\n\nAs shown in Figure 6., LIT models are pareto optimal in accuracy vs model size.\n--> this is a very strong claim. it's better to say we fail to prune the network with the approach, but we don't know whether there exists another approach that can reduce the network size while maintaining accuracy.\n\nAs shown, L2 and L1 do not significantly differ, but smoothed L1 degrades accuracy.\n--> is this claim statistically significant?""]","[50, 50, 60]","[75, 70, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being 'clearly written and easy to follow' and acknowledges the novelty of the approach. However, they also provide several critiques and suggestions for improvement, balancing out the overall sentiment. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'it would be more interesting to see...', 'I would suggest...'), and offers specific recommendations for improvement. The reviewer maintains a professional tone, avoiding harsh or dismissive language, even when pointing out potential issues or suggesting changes."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting approach and highlights some pros, but also points out several cons and areas for improvement. The overall tone is balanced, with a slight lean towards positive as evidenced by the increase in rating after the rebuttal. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the authors' response positively, and frames criticisms constructively. The reviewer uses phrases like 'I think' to soften opinions and thanks the authors for their response, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper being easy to follow, having a clear idea, motivation, and contribution, and comprehensive experiments. They also mention an advantage not noted by the authors. However, they do point out a 'major weakness' and have several questions, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions rather than direct attacks, and acknowledges the paper's strengths. They use phrases like 'One advantage...', 'Here are some minor questions:', and 'it's better to say...' which maintain a constructive tone. The reviewer also asks for clarification on several points rather than making assumptions, which is a polite approach to peer review.""]"
"['Summary of the paper:\nThis paper proposes to use structured gradient regularization to increase adversarial robustness of neural network. Here, the gradient regularization is to regularize some norm of the gradients on neural network input. ""structured"" means that instead of just minimizing the L2 norm of the gradients, a ""mahalanobis norm"" is minimized. The covariance matrix is updated continuously to track the ""structure"" of gradients/perturbations. Whitebox attack and blackbox attack \n\nThe paper is well written, both theory and experiments are well explained. The analysis of LRC attack on SGR trained models are interesting.\n\nHowever, I believe the paper has major flaws in several aspects.\n\nThe whitebox robustness evaluation is weak. Whitebox PGD with 10 iterations is not enough for discovering true robustness of a neural network, which makes the experiments unconvincing. PGD with 100 iterations and 50 random starts would make the evaluation much convincing wrt to whitebox attack. https://github.com/MadryLab/mnist_challenge\nI noticed that in Table 1, the authors reported averaged results across different epsilons. Although I see the motivation to give equal weights to small and large perturbations, it makes it hard to compare with previous papers. I think the authors should a least report commonly used eps in the literature, including MNIST eps=0.1, 0.2, 0.3 and CIFAR10 eps=8/255. Currently, for MNIST eps=32/255=0.125 is much below the standard eps for benchmarking MNIST.\n\nIn my opinion, when evaluating robust optimization / gradient regularization methods, robustness under the strongest whitebox should be the major benchmark. Because ""intrinsic"" robustness is their goal. In contrast, black-box results are less important. This is because 1) evaluating black-box robustness on a few attacks hardly give any conclusive statements; 2) if we\'re pursuing black-box robustness, there\'re many randomization methods that boosts black-box robustness under various settings. How does a gradient regularization method help on top of those should be at least evaluated.\nSo if the paper wants to claim black-box robustness, it needs at least include experiments like 2), so it provides useful benchmarks to practitioners.\n\nThere\'re also a few problems in the motivation / analysis. \n""""""A remedy to these problems is through the use of regularization. The basic idea is simple: instead of sampling virtual examples, one tries to calculate the corresponding integrals in closed form, at least under reasonable approximations.""""""\nThe adversarial robustness problem is not about integral over a neighborhood, it is about the maximum loss over a neighborhood. This is likely why previous attempts on gradient regularization and adversarial training on FGSM attack fails. And the success is of PGD training is largely due to that the loss minimize over the adversarial example that gives the maximum loss.\n\n""""""Thus, under the assumption that \\phi \\approx \\phi^* and of small perturbations (such that we can ignore higher order terms.""""""\nThe Bayes optimal assumption seems to be arbitrary to me. If \\phi is nearly Bayes-optimal, why would we worry about adversarial examples?\n\n\n\nOther relatively minor problems\n\nIn the caption of Figure 1, """"""Covariance matrices of PGD, FGSM and DeepFool perturbations as well as CIFAR10 training set (for comparison). The short-range structure of the perturbations is clearly visible. It is also apparent that the first two attack methods yield perturbations with almost identical covariance structure.""""""\nPGD and FGSM have very different attack power. If they are similar by any measure, wouldn\'t that mean the measure (covariance structure) is too coarse?\n\nIn Section 3.1, the paper talks about both centered and uncentered adversarial examples.\nI assumed that the authors mean that the distribution of perturbations are centered?\nFirst, I think this the authors should make this more explicit.\nSecond, I think this is not a realistic to assume the perturbations to be centered, because for image data, the epsilon-ball usually intersects with data domain boundary. So I\'m wondering in the experiments, which version was used? centered or uncentered?\n\nFigure 5 shows periodic patterns on covariance matrices. I didn\'t find explanation of the periodic patterns in the covariance matrices. It would nice if the authors can explain it or point me the relevant sections in the paper.\n\nI don\'t fully get the idea of LRC attack. Is it purely sampling? are there optimization involved?\n\nFigure 3, I suggest the authors show perturbations with different decay lengths on the same original images, which would make it easier to compare.', ""Short paper summary: This work proposes a novel method of gradient regularization (SGR) which utilizes the covariance structure of adversarial examples generated during training. The authors propose simple techniques to reduce the computational overhead of SGR. Empirically, the authors compare their method to standard adversarial training and gradient norm regularization.\n\nBrief review summary: There are some interesting ideas in this work but I feel that the some practical aspects lack formal justification and the comparison to existing work is inconclusive.\n\nDetailed comments:\n\nIn addition to some minor comments, I have two concerns. First, with the SGR algorithm itself. And second with the empirical analysis. While I suspect that the first concern may be clarified with discussion I think that the second is more serious and is the primary factor behind my review score.\n\n1) As the SGR algorithm is written I wonder whether the regularization term may be computed more efficiently using something like a Hutchinson trace estimation trick. I suspect that if the random vector used to estimate the trace was the xi from Algorithm 1 then the same Mahalanobis gradient norm would be recovered. This would hold only in the case beta=1, bringing me to my second point.\n\n2) What is the purpose of the running average of the covariance? A relatively small beta value is used in practice but I do not see any strong justification for this. Is there a good reason why we do not want the covariance matrix to be a close approximation for the local gradient landscape? This seems like an important part of the algorithm, especially as it may shed light on my next note.\n\n3) In practice, Algorithm 1 uses adversarial attack schemes to generate the perturbations. In simple cases like FGM, this would give the covariance of the input-output gradient which seems that it would have a direct interpretation as a form of classical gradient regularization. To this extent, I also wonder how the SGR algorithm could be related to interpretations of adversarial training as gradient smoothing (when using small perturbations).\n\nI recognize that the above points are (so far as I could tell) not directly addressed in the work, and some may be fairly considered out of scope. However, due to the direct comparison to adversarial training later and the need to tie SGR to adversarial attacks I feel that it would be important to distinguish these cases.\n\nOverall, I felt that the first three sections did well to introduce the motivation and techniques used and were was easy to follow. The derivation of the SGR algorithm was clear and concise but I believe that some of the practical details (covariance running average, computational efficiency [at first glance, it looks like the full Jacobian must be computed, but practically the sum over K reduces this to a single backprop call]) could have been elaborated on.\n\nFor the empirical evaluation the authors provided ample detail on the experimental set up and have performed a fairly thorough investigation in terms of existing defenses and attacks. I felt that the bulk of the study which is contained in Table 1 is fairly inconclusive or at the very least, difficult to interpret completely. Additional comments:\n\n4) I felt that Figure 1 and 2 are a little difficult to interpret at first. It would help to clearly define what is meant by short- and long-range signal corruptions. However, they do suggest some interesting findings. As these covariance matrices depend directly on the model itself, I think it is worth investigate (or commenting on) how this structure may change when introducing things like SGR (or GN). The authors claim that unregularized classifiers give too much weight to short range correlations but they should show that SGN (or other methods) correct this.\n\n5) My biggest concern with this work is with the results presented in Table 1. In terms of how they are presented: first I think that the fool column requires further explanation, or perhaps more simply the column could show accuracy instead of the average perturbation size. Second, I am not sure why the reported accuracies are averaged over attack strengths in a range. So far as I am aware, this is not standard and makes it difficult to interpret the performance of the models in this way. Figure 4 in the appendix does a better job of describing the behavior over a range of attack strengths.\n\n6) From the table, it is not obvious to me that SGR provides any improvements to robustness over existing techniques. Indeed, the authors write that SGR achieves white-box accuracies which are between those of the clean and adversarially trained models and claim that SGR improves on the clean accuracy for CIFAR-10. But in the table the gap between FGSM and GN/SGR clean accuracies seem fairly small with FGSM providing better robustness (for most source attacks). Even more concerning, is the fact that GN seems to outperform SGR. I do not find these results substantial enough to motivate SGR as a robustness defense compared with adversarial training (or even GN), especially as SGR has the same computational limitations involved with expensive adversarial perturbations.\n\n\nI felt that the study into the covariance structure of adversarial perturbations was interesting but as it stands was not complete enough to be informative in general. In the conclusion the authors write that they provide evidence that current adversarial attacks act by perturbing the short-range correlations of signals but this has only been confirmed for unregularized classifiers. Despite these issues, I thought that the paper was well written and hope that the empirical study can be improved and clarified.\n\n\nMinor comments:\n\n- Section 2.1, set of transformations only introduced briefly then forgotten. Leaving output invariant confused me, as this does not apply to adversarial examples.\n- Section 2.3, second paragraph l3: In Maaten et al. should be citet.\n- Section 3.1, should  make clear that derivative is with respect to the data.\n- Section 3.1, define delta as the Hessian clearly (it is used for the simplex in the previous section). Though this is easy to figure out.\n- Section 7.1, starts with (iii), is this intentional? Perhaps an introductory sentence could make this clearer.\n- Section 7.3, for label leaking, I'm not convinced by this argument alone. Assuming the covariance structure is still computed from a particular adversarial example, I see no compelling reason that this would not occur.\n\n\nClarity: The paper is very clearly written and is easy to follow."", 'The authors propose a new defense against adversarial examples that relies on a data-dependent regularization (instead of adversarial training). They then benchmark the performance of this new defense against popular white-box and transfer attacks, as well as propose a new long range correlated adversarial attack.\n\nComments:\nI find the premise of this paper interesting - developing regularization strategies to help with generalization to adversarial perturbations. For instance, it is well known that state-of-the-art defenses such as PGD have generalization gaps as large as 50% between robust train and test accuracies. It has also been previously hypothesized that this could be due to a data scarcity problem [Schmidt et al., 2018].  The authors here propose to tackle this problem using a new data-dependent regularization technique. \n\nMy primary issue with this paper is that the authors do not clearly illustrate what the advantage of their method over standard methods is\n- The problem this paper aims to solve is overfitting to a specific attack/virtual adversarial examples presented during adversarial training by using regularization instead. However, the authors do not actually illustrate that their technique reduces overfitting. For instance, the authors do not contrast the robust train-test accuracies using their method to other standard methods. Thus it is not clear that this paper met the objectives laid out in the introduction. \n- The claim in this paper is that SGR helps against attacks with long range dependencies. However, in their experiments (e.g., in Figure 3), the authors do not evaluate other standard defenses. It is thus unclear whether other standard methods are already robust to such attacks. In fact, based on the results of Table 1, it doesn’t seem like attacks from SGR  are able to reduce the robustness of PGD/FGSM trained models.\n\nBecause of these two points, along with the lower robustness to various attacks (in Table 1) as compared to approaches such as PGD, it is not really clear to me what the real merit of this new approach is. Ultimately, having a defense which is more robust to a particular attack is not very meaningful if there exists an alternative attack that reduces the robustness of the defense.\n\nI am also surprised that the authors chose to use this regularization as an alternative to adversarial training instead of complementary to it. I would be interested to see if such regularization could actually help to bridge the generalization gap observed while using adversarial training.\n\nThe paper is at times is poorly written and confusing. For instance, the description of CovFun is hard to parse. The authors should make this explanation more clear. The authors also do not state what their attack model is - Linf vs L2 perturbations. They also choose to evaluate attacks differently, using an average accuracy over different epsilons rather than reporting individual accuracies. This does make the results harder to compare to other work. The authors should include a full table of individual accuracies (at least in the appendix) to make the numbers easier to parse and compare.\n\nIn the derivation in Section 3.1, the authors use the assumption that the robust classifier is almost equal to the Bayes optimal classifier to justify dropping terms corresponding to the Hessian(\\phi_y). I am not sure how realistic this assumption is in the adversarial setting - one can construct simple distributions for which the Bayes optimal classifier is not the robust classifier.\n\nWith regards to Figure 3, the authors state -\n“As the decay length goes to zero, the synthetic covariance matrix converges to the identity matrix and SGR performance approaches GN performance” \nCould the authors clarify why this is obvious? After all these two models are trained very differently.\n\nThe plot in Figure 3 and the results in Table 1 seems to illustrate that SGR is no better than GN as you can find an attack where they perform as well/badly. The authors say that this is due to the short-range nature of current attacks. I do not understand this rationale though - the goal of the defenses should be to be more robust to all attacks, both short range and long range. Thus arguing that there may be an attack under which their model performs better is not sufficient. I do agree that finding long range attacks that can break current SOTA robust models would be interesting, however the authors do not seem to achieve that in this work.\n\nI find the observation on transfer attacks interesting - PGD attacks from SGR/GN models are better than PGD models. Do the authors have any insight as to why this is the case?\n\nIn general, my concern about gradient regularization based defenses is that they only give a very local picture of the landscape and thus can only protect against small eps attacks. This could probably explain why the SGR/GN models are less robust than PGD. As mentioned previously, it would be valuable to see accuracies against individual eps values (rather than averaged) to understand this better. If this is the case, this regularization would not provide any additional benefits when combined with adversarial training either.\n\nReferences:\nSchmidt, Ludwig, et al. ""Adversarially Robust Generalization Requires More Data."" arXiv preprint arXiv:1804.11285 (2018).']","[-50, -20, -40]","[20, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('The paper is well written, both theory and experiments are well explained'), they also state that 'the paper has major flaws in several aspects'. The review then goes on to list multiple criticisms and concerns, which outweigh the initial positive comments. The overall tone is more negative than positive, but not extremely negative.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I believe' and 'In my opinion' to soften criticisms, and provide constructive feedback with specific suggestions for improvement. However, the language is not overly polite or deferential, maintaining a neutral to slightly positive politeness level. The reviewer also directly states their concerns without excessive hedging, which keeps the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas, they express significant concerns about the practical aspects and empirical analysis of the work. The reviewer states that the comparison to existing work is 'inconclusive' and that the results are not 'substantial enough to motivate SGR as a robustness defense'. However, the score is not deeply negative as the reviewer also notes positive aspects like the paper being well-written and having interesting findings. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I feel that', 'I wonder whether', and 'I hope that' which soften the critique. The reviewer also provides detailed explanations for their concerns, showing engagement with the work, and ends on a positive note about the paper's writing quality."", ""The sentiment score is -40 because the reviewer expresses several significant concerns about the paper, including lack of clear advantages over standard methods, insufficient evidence to support claims, and unclear writing in parts. However, they do acknowledge some interesting aspects, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I find the premise of this paper interesting'), and offers suggestions for improvement. They maintain a professional tone without being overly formal or deferential.""]"
"['Summary: Given two sets of data, where one is unlabelled and the other is a reference data set with a particular factor of variation that is fixed, the approach disentangles this factor of variation from the others. The approach uses a VAE whose latents are split into e that represents the factor of variation and z that represents the remaining factors. A symmetric KL loss that is approximated using the density-ratio trick is optimised for the learning, and the method is applied to MNIST digit style disentangling and AffectNet facial expression disentangling.\n\nPros:\n- Clearly written\n- Results look promising, both quantitative and qualitative.\n\nCons:\n- Mathieu et al disentangle a specific factor from others without explicit labels but by drawing two images with the same value of the specified factor (i.e. drawing from the reference set) and also drawing a third image with a any value of the specified factor (i.e. drawing from the unlabelled set). Hence their approach is directly applicable to the problem at hand in the paper. Although Mathieu et al use digit/face identity as the shared factor, their method is directly applicable to the case where the shared factor is digit style/facial expression. Hence it appears to me that it should be compared against.\n- missing reference - Bouchacourt - explicit labels aren’t given and data is grouped where each group shares a factor of var. But here the data is assumed to be partitioned into groups, so there is no equivalent to the unlablled set, hence difficult to compare against for the outlined tasks.\n- Regarding comparison against unsupervised disentangling methods, there have been more recent approaches since betaVAE and DIP-VAE (e.g. FactorVAE (Kim et al) TCVAE (Chen et al)). It would be nice to compare against these methods, not only via predictive accuracy of target factors but also using disentangling metrics specified in these papers.\n\nOther Qs/comments\n- the KL terms in (5) are intractable due to the densities p^u(x) and p^r(x), hence two separate discriminators need to be used to approximate two separate density ratios, making the model rather large and complicated with many moving parts. What would happen if these KL terms in (5) are dropped and one simply uses SGVB to optimise the resulting loss without the need for discriminators? Usually discriminators tend to heavily underestimate density ratios (See e.g. Rosca et al), especially densities defined on high dimensions, so it might be best to avoid them whenever possible. The requirement of adding reconstruction terms to the loss in (10) is perhaps evidence of this, because these reconstruction terms are already present in the loss (3) & (5) that the discriminator should be approximating. So the necessity of extra regularisation of these reconstruction terms suggests that the discriminator is giving poor estimates of them. The reconstruction terms for z,e in (5) appear sufficient to force the model to use e (which is the motivation given in the paper for using the symmetric KL), akin to how InfoGAN forces the model to use the latents, so the necessity of the KL terms in (5) is questionable and appears to need further justification and/or ablation studies.\n- (minor) why not learn the likelihood variance lambda?\n\n************* Revision *************\nI am convinced by the rebuttal of the authors, hence have modified my score accordingly.', 'The paper proposes reference based VAEs, which considers learning semantically meaningful feature with weak supervision. The latent variable contains two parts, one related to the reference set and the other irrelevant. To prevent degenerate solutions, the paper proposed to use reverse KL resulting in a ALICE-style objective. The paper demonstrates interesting empirical results on feature prediction, conditional image generation and image synthesis.\n\nI don’t really see how Equation (5) in symmetric KL prevents learning redundant z (i.e. z contains all information of e). It seems one could have both KL terms near zero but also have p(x|z, e) = p(x|z)? One scenario would be the case where z contains all the information about e (which learns the reference latent features), so we have redundant information in z. In this case, the learned features e are informative but the decoder does not use e anyways. To ensure that z does not contain information about e, one could add an adversarial predictor that tries to predict e from z. Note that this cannot be detected by the feature learning metric because it ignores z for RbVAE during training.\n\nThe experiments on conditional image generation look interesting, but I wonder if the ground truth transformation for MNIST can be simply described as in some linear transformation on the original image. I wonder if the proposed method works on SVHN, where you can use label information as reference supervision. Moreover, I wonder if it is possible to use multiple types of reference images, but fewer images in each type, to reach comparable or even better performance.\n\nMinor points:\n- Why assume that the reference distribution is delta distribution whose support has measure zero, instead of a regular Gaussian?\n- (6), (8), (10) seems over complicated due to the semi-supervised nature of the objective. I wonder if having an additional figure would make things clearer. \n- Maybe it is helpful to cite the ALICE paper (Li et al) for Equation (10).\n- Table 1, maybe add the word “respectively” so it is clearer which metric you use for which dataset.\n- I wonder if it is fair enough to compare feature prediction with VAE and other models since they do not use any “weak supervision”; a fairer baseline could consider learning with the weak supervision labels (containing the information that some images have the same label). The improvement on AffectNet compared to regular VAE does not look amazing given the additional weak supervision.\n', 'The authors address the problem of representation learning in which data-generative factors of variation are separated, or disentangled, from each other. Pointing out that unsupervised disentangling is hard despite recent breakthroughs, and that supervised disentangling needs a large number of carefully labeled data, they propose a “weakly supervised” approach that does not require explicit factor labels, but instead divides the training data in to two subsets. One set, the “reference set” is known to the learning algorithm to leave a set of generative “target factors” fixed at one specific value per factor, while the other set is known to the learning algorithm to vary across all generative factors. The problem setup posed by the authors is to separate the corresponding two sets of factors into two non-overlapping sets of latents. \n\nPros:\n\nTo address this problem, the authors propose an architecture that includes a reverse KL-term in the loss, and they show convincingly that this approach is indeed successful in separating the two sets of generative factors from each other. This is demonstrated in two different ways. First, quantitatively on an a modified MNIST dataset, showing that the information about the target factors is indeed (mostly) in the set of latents that are meant to capture them. Second, qualitatively on the modified MNIST and on a further dataset, AffectNet, which has been carefully curated by the authors to improve the quality of the reference set. The qualitative results are impressive and show that this approach can be used to transfer the target factors from one image, onto another image.\n\nTechnically, this work combines and extends a set of interesting techniques into a novel framework, applied to a new way of disentangling two sets of factors of variation with a VAE approach. \n\nCons:\n\nThe problem that this work solves seems somewhat artificial, and the training data, while less burdensome than having explicit labels, is still difficult to obtain in practice. More importantly, though, both the title and the start of the both the abstract and the introduction are somewhat misleading. That’s because this work does not actually address disentangling in the sense of “Learning disentangled representations from visual data, where high-level generative factors correspond to independent dimensions of feature vectors…” What it really addresses is separating two sets of factors into different parts of the representation, within each of which the factors can be, are very likely are, entangled with each other.\n\nRelated to the point that this work is not really about disentangling, the quantitative comparisons with completely unsupervised baselines are not really that meaningful, at least not in terms of what this work sets out to do. All it shows is whether information about the target factors is easily (linearly) decodable from the latents, which, while related to disentangling, says little about the quality of it. On the positive side, this kind of quantitative comparison (where the authors approach has to show that the information exists in the correct part of the space) is not pitted unfairly against the unsupervised baselines.\n\n===\nUpdate: \nThe authors have made a good effort to address the concerns raised, and I believe the paper should be accepted in its current form. I have increased my rating from 6 to 7, accordingly. ']","[50, -20, 60]","[70, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons, with the pros being significant ('clearly written', 'results look promising'). The reviewer also mentions being 'convinced by the rebuttal', indicating a positive shift in opinion. However, there are several substantial criticisms and suggestions for improvement, balancing out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'it would be nice to compare'), and asks questions rather than making demands. The reviewer also shows flexibility by modifying their score after the rebuttal, which indicates respect for the authors' perspective."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they raise several significant concerns and questions about the methodology and results. The reviewer points out potential flaws in the approach and suggests improvements, indicating a somewhat critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges positive aspects of the work. They use phrases like 'I wonder if' and 'Maybe it is helpful to' which soften the critique. The review maintains a professional and constructive tone, even when pointing out potential issues."", ""The sentiment score is 60 (positive) because the reviewer acknowledges several pros of the paper, including the successful separation of generative factors, impressive qualitative results, and the novel framework. However, they also point out some cons, such as the somewhat artificial problem and misleading title/introduction. The overall tone is more positive than negative, especially with the final update recommending acceptance. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and achievements. They present criticisms constructively and end on a positive note, showing consideration for the authors' work in addressing previous concerns.""]"
"['The authors propose a method for learning vector representations for graphs. The problem is relevant to the ICLR community. \n\nThe paper has, however, three major problems:\n\nThe motivation of the paper is somewhat lacking. I agree that learning representations for graphs is a very important research theme. However, the authors miss to motivate their specific approach. They mention the importance of learning on smaller graphs and applying the learned models to larger graphs (i.e., extrapolating better). I would encourage the authors to elaborate on some use cases where this is important. I cannot think of any at the moment. I assume the authors had use cases in combinatorial optimization in mind? Perhaps it might make sense to motivate the use of GNNs to solve vertex cover etc. \n\nI’m not sure about the correctness of some of the theorems. For instance, Theorem 2 states \n“For any fixed k > 0, there exists a function f(·) and an input graph instance G such that no k-LOCAL-GATHER algorithm can compute f(G) exactly.”  I’m not claiming that this is a false statement. What I am suspecting at the moment is that the proof might not necessarily be correct. For instance, it is known that what you call 1-LOCAL-GATHER can compute the 1-Weisfeiler-Leman partition of the nodes (sometimes also referred to as the 1-WL node coloring). Now consider the chain graph 1 - 2 - 3 - 4 - 5. Here, the partition that puts together 1-WL indistinguishable nodes are {1, 5}, {2, 4} and {3}. Hence, the 1-WL coloring is able to distinguish say nodes 2 and 3 even their 1-neighborhood looks exactly the same. A similar argument might apply to your example pairs of graphs but I haven’t checked it yet in detail. What is for sure though: what you provide in the appendix is not a proper formal proof of Theorem 2. This has to be fixed. \n\nThe experiments are insufficient. The authors should compare to existing methods on common benchmark problems such as node or graph classification datasets. Comparing to baselines on a new set of task is not enough. Why not compare your method also on existing datasets?\nIf you motivate your method as one that performs well on combinatorial problems (e.g., vertex cover) you should compare to existing deterministic solvers. I assume that these are often much faster at least on smaller graphs. ', 'This paper proposes a new representation learning model for graph optimization, Graph2Seq. The novelty of Graph2Seq lies in utilizing intermediate vector representation of vertices in the final representation. Theoretically, the authors show that an infinite sequence of such intermediate representations is much more powerful than existing models, which do not maintain intermediate representations. Experimentally, Graph2Seq results in greedy heuristics that generalize very well from small training graphs (e.g. 15 nodes) to large testing graphs (e.g. 3200 nodes).\n\nOverall, the current version of the paper raises a number of crucial questions that I would like the authors to address before I make my decision.\n\nFirst, some strengths of the paper:\n- Theory: although I have not reviewed the proofs in details, the theorems are very interesting. If correct, the theorems provide a strong basis for Graph2Seq. In contrast, this aspect is missing from other work on ML for optimization.\n\n- Experiments: the experiments are generally thorough and well-presented. The performance of Graph2Seq is remarkable, especially in terms of generalization to significantly larger graphs.\n\n- Writing: the paper is very well-written and complex ideas are neatly articulated. I also liked the Appendix trying to interpret the trained model. Good job!\n\nThat being said, I have some serious concerns. Please clarify if I misunderstood anything and update the paper otherwise.\n\n- Graph2Seq at test time: in section Testing, you explain how multiple solutions are output by G2S-RNN at intermediate ""states"" of the model, and the best w.r.t. the objective value is returned. If I understand all this correctly, you take the output of the T-th LSTM unit, run it through the Q-network, then select the next node (e.g. in a vertex cover solution). Then, the complexity should be O((E+V)*T_max*V), since the Graph2Seq operations are linear in the size of the graph O(E+V), a single G2S-RNN(i) takes O(V) times if you want to construct a cover of size O(V), and you repeat that process exactly T_max times, for each i between 1 and T_max. What\'s wrong in my understanding of G2S-RNN here? Or is your complexity incorrect?\n\n- Local-Gather definition: in your definition of the Local-Gather model, do you assume that computations are performed for a single iteration, i.e. a single local step followed by a gather step? If so, then how is Graph2Seq infinity-local-gather? What does that even mean? I understand how some of the other GCNN-based models like Khalil et al.\'s is 4-local-gather (assuming 4 embedding iterations of structure2vec), but how is Graph2Seq infinity-local-gather?\n\n- Comparison to Structure2Vec: for fair comparison, why not apply Algorithm 2 to that method? Just run more embedding iterations up to T_max, and use the best among the solutions constructed between 1 and T_max.\n\nMinor:\n- Section 4: Vinyals et al. (2015) does not do any RL.\n', 'Graph representation techniques are important as various applications require learning over graph-structured data. The authors proposed a novel method to embedding a graph as a vector. Compared to Graph Convolutions Neural Networks (GCNN), the proposed are able to handle directed graphs while GCNN can not. Overall the paper is good, the derivation and theory are solid. The authors managed to prove the proposed representation is somehow lossless, which is very nice. The experiment is also convincing.\n\nMy only concern is as follows. The authors claim that Eq. (1) is able to handle features on vertices or edges. However, in the current formulation, the evolution only depends on vertex features, thus how can it handle edge features?']","[-60, 50, 80]","[20, 80, 70]","[""The sentiment score is -60 because the review is predominantly critical, highlighting 'three major problems' with the paper. The reviewer expresses doubts about the motivation, correctness of theorems, and sufficiency of experiments. However, it's not entirely negative as the reviewer acknowledges the relevance of the problem to the ICLR community. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'I would encourage the authors' and 'I'm not claiming that this is a false statement.' The reviewer also offers constructive suggestions for improvement, which contributes to the politeness. However, the overall tone remains professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several strengths of the paper including its theoretical contributions, experimental thoroughness, and writing quality. However, they also express 'serious concerns' and request clarifications on key points, indicating a mix of positive and negative sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths before raising concerns, and phrases criticisms as questions or requests for clarification rather than direct accusations. They also compliment the authors on aspects like 'Good job!' for the appendix. The tone remains professional and constructive throughout."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'good' with 'solid' theory and 'convincing' experiments. They also praise the authors for proving the representation is 'lossless'. The only negative aspect is a single concern raised at the end. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' achievements and framing their concern as a question rather than a criticism. The tone is professional and constructive, without any harsh or rude language.""]"
"[""This paper builds on the (Alemi et al 2018) ICML paper and presents a formal framework for representation learning. The authors use a graphical model for their representation learning task and use basic information theoretic inequalities to upper-bound their measure of performance which is a KL divergence. The authors then define the optimal frontier which corresponds to the lowest possible upper-bound and write it as an optimization problem. Written with Lagrange multipliers, they obtain several known cost functions for different particular choices of these parameters.\nThen the authors make a parallel with thermodynamics and this part is rather unclear to me. As it is written, this section is not very convincing:\n- section 4.1 after equation (27) which function is 'smooth and convex'? please explain why.\n- section 4.1 '...the actual content of the law is fairly vacuous...'\n- section 4.2 the explanation of equation (30) is completely unclear to me. Please explain better than 'As different as these scenarios appear (why?)...'\n- section 4.2 'Just as in thermodynamics, these susceptibilities may offer useful ways to characterize...'\n- section 4.2 'We expect...'\n- section 4.3 ends with some unexplained equations.\nAs illustrated by the examples above, the reader is left contemplating this formal analogy with thermodynamics and no hint is provided on how to proceed from here. \n\n"", 'This paper attempts to establish a notion of thermodynamics for machine learning. Let me give an attempt at summary. First, an objective function is established based on demanding that the multi-information of two graphical models be small. The first graphical model is supposed to represent the actual dependence of variables and parameters used to learn a latent description of the training data, and the model demands that the latents entirely explain the correlation of the data, with the parameters marginalized out. Then, a variational approximation is made to four subsets of terms in this objective function, defining four ""thermodynamic""  functionals. Minimizing the sum of these functionals puts a variational upper bound on the objective. Next, the sum is related to an unconstrained Lagrange multiplier problem making use of the facts (1) that such an objective will likely have many different realizations of the thermodynamic functionals for specific value of the bound and (2) that on the optimal surface the value of one of the functional can be parametrized in terms of the three others. If we pick the entropy functional to be parameterized in terms of the others, we find ourself precisely in the where the solution to the optimization is a Boltzmann distribution; the coefficients of the Lagrange multipliers will then take on thermodynamic interpretations in of temperature, generalized chemical potentials, etc. At this point, the machinery of thermodynamics can be brought to bear, including a first law, Maxwell relations (equality of mixed partial derivatives), etc.\n\nI think the line of thinking in this paper is very much worth pursuing, but I think this paper requires significant improvement and modifications before it can be published. Part of the problem is that the paper is both very formal and not very clear. It\'s hard to understand why the authors are establishing this analogy, where they are going with it, what\'s its use will be, etc. Thermodynamics was developed to explain the results of experiments and is often explained by working out examples analytically on model systems. This paper doesn\'t really have either such a motivation or such examples, and I think as a result I think it suffers.\n\nI also think the ""Tale of Two Worlds"" laid out in Section 2 requires more explanation. In particular, I think more can be said about why Q is the the ""world we want"" and why minimizing the difference between these worlds is the right way to create an objective. (I have no real problem with the objective once it is derived.) Since this paper is really about establishing this formal relationship, and the starting point is supposed to be the motivating factor, I think this needs to be made much clearer.\n\nThe I(Z_i, X_i, Theta) - I(X_i, Z_i) terms could have been combined into a conditional mutual information. (I see this is discussed in Appendix A.) This leads to a different set of variational bounds and a different thermodynamics. Why do we prefer one way over the other? At the level of the thermodynamics, what would be the relationship between these different ways of thinking? Since it\'s hard to see why I want to bother with doing this thermodynamics (a problem which could be assuaged with worked examples or more direct and clear experiments), it\'s hard to know how to think about this sort of freedom in the analogy. (I also don\'t understand why the world Q graphical model is different in Appendix A when we combined terms this way, since the world Q lead to the objective, which is independent of how we variationally bound it.) I think ultimately the problem can be traced to the individual terms in the objective (7) not being positive definitive, giving us the freedom to make different bounds by arranging the pieces to get different combinations of positive definite terms. How am I supposed to think about this freedom?\n\nIn conclusion, I would really like to see analogies like this worked out and be used to better understand machine learning methods. But for this program to be successful, I think a very compelling case needs to be made for it. Therefore, I think that this paper needs to be significantly rewritten before it can be published.', 'This paper introduces an information-theoretic framework that connects a wide range of machine learning objectives, and develops its formal analogy to thermodynamics. \nThe whole formulation attempts to align graphical models of two worlds P & Q and is expressed as computing the minimum possible relative information (using multi-informations)  between the two worlds. Interestingly, this computation consists of four terms of mutual information, each of which is variationally bounded by a meaningful functional: entropy, rate, classification error, distortion. Finding points on the optimal feasible surface leads to an objective function with the four functionals, and this objective is shown to cover many problems in the literature. The differentials of the objective bring this framework to establish formal analogies between ML and thermodynamics: the first law (the conservation of information), the Maxwell relations, and the second law (relative entropy decrease). \n\nThe main contribution of this paper would be to provide a novel and interesting interpretation of previous ML techniques using an objective function in an information theoretic viewpoint. Drawing the objective from the tale of two worlds and connecting them with existing techniques is impressive, and the analogies to thermodynamics are reasonable. I appreciate this new perspective of this paper and think this direction is worth exploring for sure. The terms and relations derived in the course of this work might be useful for understanding or analyzing ML models.  \n\nOn the other hand, this paper is not easy to follow. It’s written quite densely with technical details omitted, and in some parts lacking proper explanations, contexts, and implications. \nE.g., \n- In section 2, why the world Q is what we want?\n- Among the mutual information terms, it’s not clear why I(Z_i; X_i, Theta) need to be minimized. After the chain rule, while the part of I(Z_i;Theta | X_i) needs to be minimized, isn’t that I(Z_i; X_i) needs to be maximized? \n- The functionals and their roles (Section 2.1) need to be more clarified.\n- In the first paragraph of Section 3, why is that “any failure of the distributional families …. feature surface”?\nFor a broader audience, I recommend the authors to clarify with more explanations, possibly, with motivating examples.\n- Formal analogies to thermodynamics (Section 4) are interesting, but remains analogies only without any concrete case of usefulness. The implications of the first and second laws are not explained in detail, and thus I don’t see their significance.  In this sense, section 4 appears incomplete. I hope they are clarified. \n']","[-30, -50, 20]","[20, 50, 60]","[""The sentiment score is -30 because the review starts positively by acknowledging the paper's contribution, but then becomes increasingly critical, especially regarding the thermodynamics section. The reviewer expresses confusion and lack of clarity, which contributes to the negative sentiment. However, it's not entirely negative as there is recognition of the paper's foundation and theoretical work.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout. They use phrases like 'please explain' and 'this part is rather unclear to me', which are polite ways of requesting clarification. The criticism is presented as the reviewer's personal difficulty in understanding rather than attacking the authors directly. However, the politeness is not extremely high, as some statements like 'the actual content of the law is fairly vacuous' could be perceived as somewhat blunt."", ""The sentiment score is -50 because while the reviewer acknowledges the value of the research direction ('I think the line of thinking in this paper is very much worth pursuing'), they express significant concerns about the paper's clarity, motivation, and overall presentation. The reviewer states that the paper 'requires significant improvement and modifications before it can be published' and concludes that it 'needs to be significantly rewritten before it can be published', indicating a generally negative sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'I would really like to see' to soften criticism, and they provide constructive feedback with specific suggestions for improvement. The reviewer also acknowledges the potential value of the research, which adds to the overall politeness. However, the score is not higher because the criticism, while polite, is still quite direct and extensive."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's novel perspective and potential contributions, calling it 'impressive' and 'worth exploring'. However, they also express concerns about the paper's clarity and completeness, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They express appreciation for the work and frame their criticisms as recommendations rather than harsh judgments. The reviewer maintains a professional tone, balancing positive feedback with areas for improvement.""]"
"['This paper seems to be an exposition on the primary performance affecting aspects of generative adversarial networks (GANs).  This can possibly affect our understanding of GANs, helping practitioners get the most in their applications, and perhaps leading to innovations that positively affect GAN performance.\n\nNormally, expositions such as this I find difficult to recommend for publication. In these times, one can find ""best practices"" with a reasonable amount of rigor on data science blogs and such. An exposition that I would recommend for publication, would need to exhibit a high sense of depth and rigor for me to deem it publication worthy. This paper, for me, achieves this level of quality.\n\nThe authors start off by giving a precise, constrained list of hyperparameters and architectural components that they would explore. This is listed in the title and explained in detail in the beginning of the paper. The authors are right in explaining that they could not cover all hyperparameters and chose what I feel are quite salient ones. My one ask would have been a survey of how activations might affect performance. I sense that everyone has settled upon LeakyReLUs for internal layers, but a survey of that work and experimentation within the authors\' framework would have been nice.\n\nThe authors then explain the metrics for evaluation and datasets. The datasets offered a healthy variety for typical image recognition tasks. It would be interesting to see what these metrics would reveal when applied to other types of data (e.g. scientific images).\n\nThe  authors explain, with graphs, the results of the loss, normalization, and architectures. I feel the discussion on loss was rushed, and I gained no insight on what the authors thought was a prominent difference between the three losses studied. Perhaps the authors had no salient observations for loss, but explicitly stating such would be useful to the reader. The only observation I gained as far as this is that non-saturating loss would possibly be stable across various datasets.\n\nRegularization and normalization are discussed in much more detail, and I think the authors made helpful and interesting observations, such as the benefits of spectral normalization and the fact that batch normalization in the discriminator might be a harmful thing. These are good takeaways that could be useful to a vast number of GANs researchers.\n\nFor architectures to be a main pillar of the paper, I feel that this area could have been explored in greater detail. I feel that this discussion devolved into a discussion, again, about normalization rather than the architectural differences in performance. Unless I am misunderstanding something, it seems that the authors simply tested one more architecture, for the express purpose of testing whether their observations about normalization would hold.\n\nAs a bonus, the authors bring up some problems they had in making comparisons and reproducing results. I think this is an extremely important discussion to have, and I am glad that the authors detailed the obstacles in their journey. Hopefully this will inspire other researchers to avoid adding to the complications in this field.\n\nThe graphs were difficult to parse. I was able to make them out, but perhaps separating the top row (FID and diversity graphs) into separate figures, separate lines, or something would have reduced some confusion. In addition, different charts presenting only one loss function, with their spectral normalization and gradient penalty variants, would have made the effects of the normalization more obvious on the FID distribution graphs. If this can be changed before publication, I would strongly suggest it.\n\nI appreciate that the authors provided source code via GitHub. However, in the future, the authors should be careful to provide an anonymous repository for review purposes. I had to be careful not to allow myself to focus on the author names which are prominent in the repository readme, and one of whom has his/her name in the GitHub URL itself. I didn\'t immediately recognize the names and thus it was easy for me not to retain them or focus on them. However, if it had been otherwise, it might have risked biasing the review.\n\nIn all, I think this is a good and useful paper from which I have learned and to which I will refer in the future as I continue my research into GANs and VAEs. I would suggest changing the title to be more appropriate and accurate (the researchers are primarily focused on showing the positive and negative effects of normalization across various loss functions and architectures). But altogether, I believe this is a paper worth publishing at ICLR.', '(As a disclamer I want to point out I\'m not an expert in GANs and have only a basic understanding of the sub-field, but arguably this would make me target audience of this paper).\n\nThe authors presents a large scale study comparing a large number of GAN experiments, in this study they compare various choices of architechtures, losses and hyperparameters. The first part of the paper describes the various losses, architectures, regularization and normalization schemes; and the second part describes the results of the comparison experiments.\n\nWhile I wish there were more such studies -- as I believe reproducing past results experimentally is important, and so is providing practical advice for practitioners -- this work in many parts hard to follow, and it is hard to get lot of new insight from the results, or a better understanding of GANs. As far I can see the most important take home message of the paper can be summarized in ""one should consider non-saturating GAN loss and spectral normalization as default choices [...] Given additional computational budget, we suggest adding the\ngradient penalty [...] and train the model until convergence"".\n\nPros:\n- available source code\n- large number of experiments\n\nCons:\n- the exposition could be improved, in particular the description of the plots is not very clear, I\'m still not sure exactly what they show\n- not clear what the target audience of the first part (section 2) is, it is too technical for a survey intended for outsiders, and discusses subtle points that are not easy to understand without more knowledge, but at the same time seems unlikely to give additional insight to an insider\n- limited amount of new insight, which is limiting as new and better understanding of GANs and practical guidelines are arguably the main contribution of a work of this type\n\n\nSome suggestions that I think could make the paper stronger\n\n- I believe that in particular section 2 goes into too many mathematical details and subtleties that do not really add a lot. I think that either the reader already understand those concepts well (which I admit, I don\'t really, I\'m merely curious about GANs and have been following the action from a distance, hence my low confidence rating to this review), or if they does not, it will be very hard to get much out of it. I would leave out some of the details, shortening the whole sections, and focus more on making a few of the concepts more understandable, and potentially leaving more space for a clearer description of the results\n- it is not really clear to be what data the graphs show: the boxplots show 5% of what data? does it also include the models obtained by gaussian process regression? and what about the line plots, is it the best model so far as you train more and more models? if so, how are those models chosen and ordered? are they the results of single models or average of multiple ones?\n- ""the variance of models obtained by Guassian Process regression is handled implicitely so we tran each model once""? I do not understand what this means, and I work with hyper-parameter tuning using gaussian processes daily. It should probably be rephrased\n- at the start of section 3: what is an ""experiment""?\n- in 3.1 towards the end of the first paragraph, what is a ""study"", is that the same as experiment or something different?\n- (minor) stating that lower is better in the graphs might be useful\n- (minor) typo in page 5 ""We use a fixed the number""', ""\nThe paper studies several different techniques for training GANs: the architecture chosen, the loss function of the discriminator and generator, \nand training techniques: normalization methods, ratio between updates of discriminator and generator, and regularization. \nThe method is performing an empirical training study on three image datasets, modifying the training procedure (e.g. changing one of the parameters) and using different metrics to evaluate the performance of the trained network. \nSince the space of possible hyper-parameters , training algorithms, loss functions and network architecture is huge , the authors set a default training procedure, and in each numerical experiment freeze all techniques and parameters\nexcept for one or two which they modify and evaluate. \n\nThe results of the paper do not give major insights into what are the preferred techniques for training GANs, and certainly not why and under what circumstances they'll work. \nThe authors recommend using non-saturated GANs loss and spectral normalization when training on new datasets, because these techniques achieved good performance metrics in most experiments. \nBut there is no attempt to generalize the findings (e.g. new datasets not from original study, changing other parameters and then evaluating again if these techniques help etc.), not clear if the \nimprovement in performance is statistically significant, how robust it is to changes in other parameters etc. \nThe authors also rely mostly on the FID metric, but do not show if and how there is improvement upon visual inspection of the generated images (i.e. is resolution improved, is fraction of images that look clearly 'unnatural' reduced etc.) \n\nThe writing is understandable for the most part, but the paper seems to lack focus - there is no clear take home message. \nThe authors use numerous jargon words to describe the techniques studied (e.g. dragon penalty, gradient penalty, spectral normalization, Gaussian process regression in the bandit setting) but they do not explain them, \ngive mathematical formulations, or insights into their advantages/disadvantages, making it hard to the non-expert reader to understand what are these techniques and why are they introduced. \n\nWith lack of clear novel insights, or at least more systematic study on additional datasets of the 'winning' techniques and a sensitivity analysis, the paper does not give a valuable enough contribution to the field to merit publication. \n""]","[70, -30, -60]","[80, 50, 20]","[""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, stating it 'achieves this level of quality' and is 'worth publishing at ICLR'. They also mention learning from it and intending to refer to it in future research. However, it's not 100 as they do suggest some improvements and areas that could have been explored further. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive ones. They use phrases like 'I appreciate' and 'I would suggest' which are polite ways of giving feedback. The reviewer also acknowledges the authors' efforts and the paper's contributions to the field. The score isn't 100 as the review maintains a professional tone rather than being overly deferential."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), the overall tone is critical. They state the paper is 'hard to follow' and provides 'limited amount of new insight'. However, it's not extremely negative as they recognize the value of such studies. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging their own potential limitations ('I'm not an expert'), and framing criticisms as suggestions ('Some suggestions that I think could make the paper stronger'). They also balance negative points with positive ones. The language is professional and constructive, avoiding harsh or rude phrasing, but it's not overly formal or deferential either."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper lacks major insights, doesn't generalize findings, and doesn't provide clear novel contributions. They conclude that the paper doesn't merit publication. However, it's not entirely negative as they acknowledge some positive aspects like understandable writing and the study of various techniques.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding personal attacks or harsh language. They provide constructive criticism and explain their concerns in detail. However, the score is only slightly positive because while not impolite, the review doesn't go out of its way to be exceptionally courteous either. The reviewer directly states their negative opinions without much softening language.""]"
"['-> Summary\n\nThe authors propose to extend the analysis of Shwartz-Ziv & Tishby on the information bottleneck principle in artificial neural network training to realistic large-scale settings. They do so by replacing otherwise intractable quantities with tractable bounds in forms of classifiers for I(y;h) and Pixel CNNs for I(x;h). In conclusion, they observe two phases during training, one that maximizes mutual information between input and hidden representation and a second one that compresses the representation at the end of training, in line with the predictions from toy tasks of Shwartz-Ziv & Tishby.\n\n-> Quality\n\nThe paper is very well written, all concepts are well-motivated and explained.\n\n-> Significance\n\nThe main novelty is to replace intractable quantities in the analysis of the information bottleneck with tractable bounds in form of auxiliary models. The idea is neat and makes a lot of sense. On the other hand, some of the results and the bounds themselves are well-known and can thus not be considered novel. The main contribution is thus the empirical analysis itself and given some overly confident claims on qualitative results and missing ablation on the quantitative side, I am not convinced that the overall results are very conclusive.\n\n-> Main Concerns\n\nThe authors make a lot of claims about the qualitative diversity of samples from deeper layers h4 of the network as compared to h1 and h2. However, I do not agree with this. When I look at the samples I see a lot of variations early in training and also in layers h1 and h2. The difference to h4 seems marginal at best and not as clear cut as the authors present it. Thus, these claims should be softened.\n\nIn figure 1 I tend to say that samples at epoch 1 are more varied than at epoch 200. In figure 5 (b) seems pretty color invariant and not only (f) as claimed. In fact (f) seems pretty stable and consistent to me.\n\nThe bound in equation (2) might be quite loose, depending on the quality of the classifier or pixel CNN. Even though there is no way to test this, it should be discussed.\n\nWhat is the effect of weight decay here? I suspect that weight decay plays a crucial role in the final compression phase observed in e.g. figure 3 (c), but might not be a necessary condition to make the network generalize. An ablation experiment verifying or falsifying this statement would be important to conduct and without it I am not convinced that the shown curves are conclusive.\n\n-> Minor\n\n- You seem to use a weird math font, is this on purpose? It does not seem to be the ICLR standard.\n- The bound in equation (2) is a standard variational bound and has been used many times, the authors make it sound like it is their contribution. You should maybe cite basic work and recent work on variational information bottleneck here.', '## Summary\n\nThis paper is an empirical study which attempts to test some of the claims regarding the information bottleneck principle applied to deep learning. To estimate the mutual information (I(x; h) and I(y; h)) in neural networks, the authors define a lower bound on the MI. Then a PixelCNN++ model (for I(x; h)) and a partially frozen classifier (for I(y; h)) are used to compute the MI during classifier and autoencoder training. For both tasks, the authors report the mutual information between hidden layers and input training data first increase for a while and then decrease. The generated images conditioned on hidden layers by the PixelCNN++ were shown to demonstrate the fitting and compression of data in a visual and intuitive fashion.\n\nIn general, the paper is well-written and organized. The idea behind the paper is not novel. Shwartz-Ziv & Tishby (2017) and Nash et al. (2018) also attempt to test the information bottleneck principle by estimating the mutual information. The results of this paper are specious and hard to be explained. \n\n## Issues with the tightness of the lower bound\nThe tightness of the lower bound is dependent on the KL divergence between the true conditional distribution p(x|h) and the approximating distribution q(x|h). Does the adopted PixelCNN++ is good enough to approximate the true conditional distribution? There is not any discussion.\n\n## Issues with the results of autoencoder\nThe decrease of the mutual information in autoencoder training is very specious. Since the decoder part of autoencoder should generate better and better images during the training process, does it mean that the PixelCNN++ was worse? Does it imply that the optimization of the PixelCNN++ has some unknown problems?\n\n## Issues with the connection between this paper and Nash et al. (2018)\nThese two paper have used the same lower bound and the same PixelCNN++ for estimating the mutual information. The observations are also similar. Both of these papers found the mutual information between inputs and network layers decreases over the training. The differences of these two papers are the adopted neural networks and the dataset, which are kind of minor.  \n', '\n* Summary: \n\nThis work is an empirical study of the relevance of the Information Bottleneck principle as a way of understanding deep-learning. It is carried out in the setting of realistically sized networks trained on natural images dataset. This is, in spirit, a meaningful and sensible contribution to the ongoing debate. Being a largely empirical contribution, its value hinges on the exhaustivity and clarity of the experiments carried out. As it stands, I believe that these should be, and can be, improved. Details to support this opinion are given below. A summary of my expectations is given at the end.\n\n\n* Summary of the approach and significance:\n\nThe IB principle relies on estimating the mutual information between i) the input and an intermediate layer, I(x,h), and an intermediate layer and the output, I(h, y). Previous work has relied on binning strategies to estimate these quantities. This is not applicable in a real-sized problem such as classification of natural images with deep networks. This paper proposes to invert a first deep model using a second, generative, model which must reconstruct the input of the first given some intermediate layer. The information progressively discarded by the first network should be modelled as uncertainty by the second. This yields a lower bound on the mutual information, with a tightness that depends on the expressivity of the generative model.\n\nI believe the goal to be meaningful and a valuable contribution: going forward, testing this assumption in realistic setting is essential to the debate. The proposed approach to do this seems sensible to me. It is similar to cited work by Nash et al., however both works are concurrent and so far unpublished and should be considered as complementary point of views on the same problem.\n\nPartial conclusion: The goal is meaningful and sensible.\n\n* Quality of writing.\n\nIn sections 1, 2 and 3, the motivation is clear and contains relevant information. I feel it could be polished further. In particular, some redundant information could be condensed. The introduction to the IB principle, though understandable, could be improved. Here are some opinions:\n\n>> Paragraphs 3 and 4 of 1.0: A reference to M. Saxe et al. could already be made there: it is a major \'opponent\' in the debate to which you are empirically contributing.\n\n>> In paragraph 1.1: Points 1) and 2) are redundant. So are 3) and 4). Paragraph 1.1 as a whole is largely redundant with the previous paragraph, these could be collapsed. \n\n>> In section 2: I feel that the main intuitions of the encoder / decoder distributions (I(y,h) / I(x,h)), the information plane, and the optimal bottleneck representations (Sections 2.1 to 2.3 of Schwartz-Ziv & Tishby) could be better conveyed in 2, though I understand the need for brevity. \n\n>> Related works: Descriptions of related works could be condensed. On the other hands, the points of these papers that you contradict in you experiment section could be explicitly mentioned again there.\n\n>> End of section 3, section 4: The fact that estimation of the MI by traditional means is not applicable in your setting is repeated many times throughout the paper, in noticeably rapid succession in that region. Some mentions should be removed.\n\t\n### More minor points:\n\n>> Paragraphs 2 of 1.0:\n- \'the extraction of typical abstract properties...\' this statement is vague and thus debatable: the channel-wise mean in RGB space, for instance, is not an especially abstract property. \n- Reference is made to Zhang et al. to justify the need for more analysis of generalization in deep-learning. This paper can be considered controversial. Mention could be made of other works, for instance about the inaplicability of traditional generalization bounds and attempts to improve them.\n\n>> Pseudo code algorithm.\n- Could be summarized in the main body and pushed to the annex.\n\n>> The choice of pixCNN as a generative model could be discussed more. There are some good reasons to prefer this to L2 regression for instance. \n\nPartial conclusion: The description of the method contains relevant information and is functional, but the writing could be improved.\n\t\n\t\n* Experimental results.\n\n> The contribution and novelty of this paper is largely empirical. Therefore the experimental results should be held to a high standard of clarity and exhaustivity.\n\n\n*** The choice of dataset:\nThe experimental setup seems to be fair in terms of dataset / split chosen: the abundance of data for the three steps (encoding, decoding, evaluation) is a notable strength.\n\n*** The quality of the lower bound: Uncertainty when reconstructing the image may come from the fact that information has been discarded. Variance may also come from the pixCNN++, which is imperfect. You mention this (paragraph 4.1) but do not take experimental steps to measure it. Please consider reporting the performance of your generative model i) without conditioning, ii) conditioned on one-hot ground truth labels, and optionally iii) on grayscale/downsampled versions of the image without otherwise modifying the training setup. These values will give the reader an idea of the significance of variations in MI measured and give a \'scale\' to your figures, strengthening your claims.\n\n*** The evolution of compression *accross iterations* for a fixed layer\nI will focus on the classification setting for now.\n\nQualitatively: Figures 1, 4 and 5 do not convince me that a meaningful evolution in the type of information discarded *across training iterations* can be observed visually. In figures 1 and 4, the network seems to learn invariances to some coloring, and its preferred colours vary across iterations. Beyond that I cannot see much, except maybe for column (f) of figure 4, despite your claim in section 2, paragraph 2.\n\nQuantitatively: Curves in Figure 2 a) are more convincing, though a notion of scale is missing, as already discussed. The evolution of I(y; h) across iterations is very clear, in Figure 2 a) and especially 3 a). The evolution of I(x, h) much less so. h3 and h4 do not seem to show anything meaningful. In h2 the decrease in I(x, h) is supported by only 2 points in the curve (epoch 10 to epoch 100, and epoch 100 to epoch 200, figures 2a and 3c). Epochs displayed are also incoherent from one curve to the next (epoch 15 is missing for h2 in fig 3c) which raises suspicion. It appears important to i) display more points, to show that this is not just noise and ii) track more layers to confirm the trend, supported by a single layer so far (see next paragraph). I understand that each of these points require training of a generative model, but I feel it is necessary to make reliable conclusions.  \n\nMinor: In figure 2, epochs should be added as labels to the colours.  \n\n*** The evolution of compression *across layers* for a fixed iteration\n\t\t\nConversely, the evolution of the MI across layers is very convincingly demonstrated, and I feel this is perhaps the main strength of this paper. All curves display consistent trends across layers, and Figure 5 qualitatively displays much more invariance to pose, detail, etc than Figure 4. This is interesting, and could be made more central: i) by making a figure that compares samples across layers, for a fixed iteration, side by side. \n\nOn the downside, I believe it is important to track more layers, as it is to me the main interest of your results. The second paragraph of section 5 does not give a good idea of the spread of these layers to someone not familiar with the resnet architecture used. For example, the penultimate layer of the network could be used (the layer at which the most compression is to be expected).\n\n*** On the auto-encoder experiments.\n\n> Little detail is given about the way the auto-encoder is constructed. In particular, one expects the type of bottleneck used (necessary so that the network does not learn the identity function) to have large impact on the amount of information discarded in the encoding process. This dependency is not discussed. More crucially, experiments with different types / strength of bottleneck are not given, and would, in my opinion, be key to an analysis of this dependency through the IB principle. \n\n> Furthermore, no qualitative analysis is provided in this setting.\n\n> Without these additions, I find the Auto-encoding setting an unconvincing distraction from the main contribution of this paper. \t\n\n***  main avenues of improvement:\n\t\t\n> Two kinds of progression in compression are demonstrated in your paper: across layers, and across iterations. \nAs it stands, results evidence the former more convincingly than the latter, both qualitatively and quantitatively.\nI believe results could be presented in a way that clearly takes better advantage of this, as I will detail further.\nMore data points (across layer and epochs) would be beneficial. I feel that the auto-encoder setting, as it stands, is a distraction.\nI would find this paper more convincing if experiments focused more on showing how layers progressively discard information, and less on the \'training phases\' that are so far less clear.\n\n*** Additional comments\n\nThe following are a number of points that would be worthwhile to discuss in the paper\n\n> As it stands, it seems the line of reasoning and experimental setup seems to rely on the chain-structured nature of the considered neural net architecture. Can the same line of reasoning be applied to networks with more general computational graphs, such as dense-nets [a], mulit-scale denseness [b], fractal nets [c] etc.\n\n[a] Huang, G.; Liu, Z.; van der Maaten, L. & Weinberger, K. Densely connected convolutional networks CVPR, 2017\n[b] Huang, G.; Chen, D.; Li, T.; Wu, F.; van der Maaten, L. & Weinberger, K. Multi-Scale Dense Networks for Resource Efficient Image Classification ICLR, 2018\n[c] https://arxiv.org/abs/1605.07648\n\n> Why is it that earlier layers are estimated to have larger MI with the target y than later layers before convergence? Sure, later layers compress certain information about the input x, which could be informative on the response variable y. But since the MI estimate for early layers depends on the same network architecture as the one used to compute the later layers from the early ones, the result seems counter intuitive. See paragraph ""forward direction"" in section 4.1.\n\n> The orange curve in fig 3a estimating I(x;y) is not commented upon. How was it obtained, what is its relevance to the discussion?\n\n\n']","[-20, -30, -20]","[60, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is very well written'), they express significant concerns about the conclusiveness of the results and the validity of some claims. The reviewer states they are 'not convinced that the overall results are very conclusive' and disagrees with several of the authors' interpretations. However, the tone is not entirely negative, as the reviewer also notes some positive aspects and the potential of the approach. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I am not convinced' rather than more harsh language, and offer specific suggestions for improvement. The review maintains a professional and courteous tone while still clearly communicating concerns."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is well-written and organized, they express significant concerns about the novelty, results, and methodology. Phrases like 'The results of this paper are specious and hard to be explained' and 'The decrease of the mutual information in autoencoder training is very specious' indicate a negative sentiment. However, the criticism is not entirely harsh, hence the score is not extremely negative. The politeness score is 20 because the reviewer uses generally respectful language and starts with some positive comments. They raise concerns in a professional manner, using phrases like 'Issues with...' rather than direct attacks. However, the tone is not overly polite or deferential, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'meaningful and sensible', they express significant concerns about the clarity and exhaustiveness of the experiments, stating 'As it stands, I believe that these should be, and can be, improved.' The reviewer provides extensive critiques and suggestions for improvement throughout, indicating they are not fully satisfied with the current state of the work. However, the tone remains constructive rather than harshly critical. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, frequently employing phrases like 'I believe', 'Please consider', and 'I feel', which soften criticisms. They also acknowledge positive aspects of the work alongside areas for improvement. The review maintains a professional and courteous tone while providing detailed feedback.""]"
"['First off, the paper presents a relatively straight-forward extension to video from the work done in image compression. The work uses 3D volumes instead of 2D images, and exploits this structure by adding a secondary network to both the encoder/decoder.\n\nThe work is therefore *marginally* novel, but it is one of the first to propose neural methods for compressing video.\n\nMy biggest complaint about this paper, however, is about evaluation. I don\'t think it\'s possible to take this paper seriously as is, due to the fact that the metrics use in the evaluation are absolutely skipped.\n\nGiven that this is such a crucial detail, I don\'t think we can accept this paper as is. The metrics need to be described in detail, and they should follow some previously used protocols (see below). \n\nFor example, in libvpx and libaom (which is the current best performing method for video compression - AV1), there are two versions of PSNR: Global and Average PSNR respectively, and this is what gets reported in publications/standards meetings.\n\nGlobal PSNR: Compute MSE for the entire sequence combining Y, Cb, Cr components, and then compute PSNR based on the combined MSE.\nAverage PSNR: Compute MSE for each frame combining Y, Cb, Cr, components; then compute PSNR for the frame based on the combined MSE and cap it to a max of 100. Then average the PSNR over all the frames.\n\nMPEG uses something like computing Average PSNR for each component (similar to what I mentioned above, but for each component) and then combine the Y-, Cb- and Cr- PSNRs using a weighted average. For 420 that will be equivalent to [4*MSE(y) + MSE(Cb) + MSE(Cr)/6. For 422 that will be equivalent to [2*MSE(y) + MSE(Cb) + MSE(Cr)/4. For 444 that will be equivalent to [MSE(y) + MSE(Cb) + MSE(Cr)/3.  Additionally, when using YCbCr, the authors also need to refer to which version of the color standard is employed, since there are multiple ITU recommendations, all of which differ in how to compute the color space transforms.\n\nPlease note that video codecs DO NOT OPTIMIZE FOR RGB reconstruction (humans are much more sensitive to brightness details than they are to subtle color changes), so comparing against them in that color space puts them at a distinct disadvantage. In the video compression literature NOBODY reports RGB reconstruction metrics.\n\nPlease note that I computed the PSNR (RGB) for H.264, on the resized MCL-V dataset (640x360) as the authors proposed and I observed that the metric has been ***MISREPRESENTED*** by up to 5dB. This is absolutely not OK because it makes the results presented not be trustworthy at all.\n\nHere is the bpp/RGB PSNR that I obtained for H.264 (for completeness, this was computed as follows: used version 3.4.2 of ffmpeg, and the command line is ""ffmpeg -i /tmp/test.y4m -c:v h264 -crf 51 -preset veryslow"", tried many settings for crf  to be able to get roughly the same bpp per video, then compute RGB PSNR for each frame per video, aggregate over each video, then average cross videos):\n\nBPP, Average PSNR RGB (again, not a metric I would like to see used, but for comparison\'s sake, I computed nonetheless -- also, note that these numbers should not be too far off from computing the average across all frames, since the video length is more or less the same)):\n0.00719, 23.46\n0.01321, 26.38\n0.02033, 28.92\n0.03285, 31.14\n0.05455, 33.43\n\nSimilar comments go for MS-SSIM. \n\nLastly, it is unfair to compare against H263/4/5 unless the authors specify what profiles were used an what kind of bitrate targeting methods were used. ', 'This paper presents a spatiotemporal convolutional autoencoder trained for video compression. The basic model follows the logic of traditional autoencoders, with an intermediate quantizer:\n\ninput -> convolutional neural network with a skip connection as an encoder -> quantizer -> transposed convolutional neural network with a skip connection as a decoder.\n\nAs the quantizer is a non-differentiable operation, the paper proposes to follow (Toderici et al  2016, Balle et al, 2018) and cast quantization as adding uniform noise to the latent variables. The pre-quantized variables are modelled as Gaussians with variance that is predicted by a second ""hyperprior"" network dedicated to this task. The final model is trained to minimize three losses. The first loss minimizes the difference between the true frame pixel values and the predicted pixel values. The second loss minimizes the entropy of the latent codes. The third loss minimizes the difference between neighboring pixels in subsequent frames, ignoring those pixels that are not linked between frames. The model is trained on 10,000 videos from the Youtub-8M dataset and tested on 10 videos from the MCL-V database, with rather ok results.\n\nGenerally, parts of the proposed approach sound logical: an autoencoder like architecture makes sense for this problem. Also, the idea of using uniform noise to emulate quantization is interesting.  However, the paper has also weaknesses.\n\n- The added novelty is limited and unclear.  Conceptually, the paper is overclaiming. Quoting verbatim from the conclusion: ""Our work is, as far as we are aware, the first end-to-end learned video compression architecture using DL."", while already citing few works that also rely on deep networks (Wu et al., 2018, Chen et al., 2016). In the related work section it is noted that these works are computationally heavy. However, this doesn\'t mean they are not end-to-end. The claims appear to be contradicting.\n\n- The technical novelty is also limited. What is new is the combination of existing components for the task of video compression. However, each component in isolation is not novel, or it is not explained as such.\n\n- Parts of the model are unclear. How is the mask M computed in equation (7)? Is M literally the optical flow between frames? If yes, what is the percentage of pixels that is zeroed out? Furthermore, can one claim the model is fully end to end, since a non-differentiable optical flow algorithm is used?\n\n- The purpose of the hyperprior network is unclear. Why not use a VAE that also returns the variance per data point?\n\n- Most importantly, it is not clear whether the model is trained as a generative one, e.g., with using a variational framework to compute the approximate posterior. If the model is not generative, how can the model be used for generation? Isn\'t it then that the decoder simply works for reconstruction of already seen frames? Is there any guarantee that the model generalizes well to unknown inputs? The fact that the model is evaluated only on 10 video sequences does not help with convincing with the generalization.\n\n- The evaluation is rather weak. The method is tested on a single, extremely small dataset of just 10 videos. In this small dataset the proposed method seems to perform worse in the majority of compression ratios (bits per pixel). The method does seem to perform a bit better on the very low bits per pixel regime. However, given the small size of the dataset, it is not clear whether these results suffice.\n\n- Only two baselines are considered, both hand-crafted codecs: H.264/AVC and MPEG-4. However, in the related work section there are works that could also be applied to the task, e.g., the aforementioned ones. Why aren\'t these included in the comparison?\n\n- Although it is explained that the focus is on the very low bitrates, it is not clear what part of the model is designed with that focus in mind. Is this just a statement just so to focus on the part of the curve in the experiment where the proposed method is better than the reported baselines? Is there some intrinsic model hypothesis that makes the model suitable for low bit rates?\n\nIn general, the paper needs to clarify the model and especially explain if it is (or not a generative one) and why. Also, a more extensitve arrays of experiments need to be executed to give a better outline of the methods capabilities and limitations.\n', 'This paper proposes an extension of deep image compression model to video compression. The performance is compared with H.264 and MPEG-4. \n\nMy main concern is the limited technical novelty and evaluation:  \n - The main idea of the architecture is extending 2D convolutions in image compression networks to 3D convolutions, and use skip connections for multi-scale modeling. The 2D to 3D extension is relatively straightforward, and multi-scale modeling is similar to techniques used in, e.g., [Rippel and Bourdev ICML 2017].  \n\n - The reconstruction loss and the entropy loss are commonly used in existing work. One new component is the “temporal consistency loss”. However the impact of the loss is not analyzed in the Experiment section.\n\n - The evaluation isn’t very extensive. Comparing the proposed method with state-of-the-art codecs (e.g., H.265) or other deep video compression codec (e.g., Wu et al. in ECCV 2018) would be valuable. \n\n - Since the evaluation dataset is small, evaluation on multiple datasets would make the experiments more convincing. \n\n - The evaluation is conducted in rather low-bitrate region only (MS-SSIM < 0.9), which is not common point of operation. \n\n - Finally I agree with AnonReviewer2 on limited description of evaluation details. \n\nOverall I think this paper is not ready for publication yet.']","[-60, -50, -70]","[20, 20, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, particularly regarding the evaluation metrics. They state that the paper cannot be taken seriously as is and point out potential misrepresentation of data. The reviewer does acknowledge some positive aspects, like the novelty of applying neural methods to video compression, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'Please note' and provide detailed explanations for their concerns, which shows respect for the authors. However, the use of capitalized words for emphasis (e.g., 'MISREPRESENTED') and strong language ('absolutely not OK') prevents the score from being higher on the politeness scale."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several weaknesses in the paper. While the reviewer acknowledges some positive aspects ('parts of the proposed approach sound logical'), the majority of the review focuses on limitations and areas for improvement. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'the paper needs to clarify' and 'it is not clear' rather than harsh or dismissive language. However, the critique is direct and doesn't use many softening phrases, keeping the politeness score relatively low on the positive side."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses several major concerns about the paper's novelty, evaluation methods, and overall readiness for publication. The concluding statement 'Overall I think this paper is not ready for publication yet' clearly indicates a negative sentiment. However, it's not at the extreme negative end as the reviewer does acknowledge some aspects of the work and provides constructive feedback.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'My main concern is...' and 'I agree with...' which are polite ways to express criticism. The reviewer also provides specific, constructive feedback rather than dismissive or harsh comments. However, the score is only slightly positive as the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a mostly neutral, professional tone.""]"
"['The paper considers the problem of obtaining reliable predictive uncertainty estimates. The authors propose noise contrastive priors — the idea being to explicitly encourage high uncertainties for out of distribution (OOD) data through a loss in the data space.  OOD data is simulated by adding noise to existing data and the model is trained to maximize the likelihood wr.t. training data while being close in the KL sense to a (wide) conditional prior p(y | x) on the OOD responses (y).  The authors demonstrate that the procedure leads to improved uncertainty estimates on toy data and can better drive active learning on a large flight delay dataset.\n\nThe paper is well written and makes for a nice read. I like the idea of using “pseudo” OOD data for encouraging better behaved uncertainties away from the data. It is nice to see that even simple schemes for generating OOD data (adding iid noise) lead to improved uncertainty estimates. \n\nMy main concern about this work stems from not knowing how sensitive the recovered uncertainties are to the OOD data generating mechanism and the parameters thereof. The paper provides little evidence to conclude one way or the other.  The detailed comments below further elaborate on this concern.\n\nDetailed Comments: \na) I like the sensitivity analysis presented in Figure 4, and it does show for the 1D sine wave the method is reasonably robust to the choice of \\sigma_x. However, it is unclear how problem dependent the choice of sigma_x is. From the experiments, it seems that \\sigma_x needs to be carefully chosen for different problems, \\sigma^2_x < 0.3 seems to not work very well for BBB + NCP for the 1D sine data, but for the flight delay data \\sigma^2_x is set to 0.1 and seems to work well. How was \\sigma_x chosen for the different experiments?\n\nb) It is also interesting that noise with a shared scale is used for all 8 dimensions of the flight dataset. Is this choice mainly governed by convenience — easier to select one hyper-parameter rather than eight? \n\nc) Presumably, the predictive uncertainties are also strongly affected by both the weighting parameter \\gamma and the prior variance sigma^2_y . How sensitive are the uncertainties to these and how were these values chosen for the experiments presented in the paper? \n\nd) It would be really interesting to see how well the approach extends to data with more interesting correlations. For example, for image data would using standard data-augmentation techniques (affine transformations) for generating OOD data help over adding iid noise. In general, it would be good to have at least some empirical validation of the proposed approach on moderate-to-high dimensional data (such as images).\n\n==============\nOverall this is an interesting paper that could be significantly strengthened by addressing the comments above and a more careful discussion of how the procedure for generating OOD data affects the corresponding uncertainties.', ""The paper considers the problem of uncertainty estimation of neural networks and proposes to use Bayesian approach with noice contrastive prior.\n\nThe paper is nicely written, but there are several issues which require discussion:\n1. The authors propose to use so-called noise contrastive prior, but the actual implementation boils down to adding Gaussian noise to input points and respective outputs. This seems to be the simplest possible prior in data space (well known for example in Bayesian linear regression). That would be nice if authors can comment on the differences of proposed NCP with standard homoscedastic priors in regression.\n2. The paper title mentions 'RELIABLE UNCERTAINTY ESTIMATES', but in fact the paper doesn't discuss the realibility of obtained uncertainty estimates directly. Experiments only consider active learning, which allows to assess the quality of UE only indirectly. To verify the title one needs to directly compare uncertainty estimates with errors of prediction on preferably vast selection of datasets.\n3. The paper performs experiments basically on two datasets, which is not enough to obtain any reliable conclusions about the performance of the method. I recommend to consider much wider experimental evaluation, which is especially importan for active learning, which requires very accurate experimental evaluation\n4. It is not clear how to choose hyperparameters (noise variances) in practice. The paper performs some sensitivity analysis with resepct to variance selection, but the study is again on one dataset.\n\nFinally, I think that the paper targets important direction of uncertainty estimation for neural networks, but currently it is not mature in terms of results obtained."", 'This paper presents an approach to obtain uncertainty estimates for neural network predictions that has good performance when quantifying predictive uncertainty at points that are outside of the training distribution. The authors show how this is particularly useful in an active learning setting where new data points can be selected based on metrics that rely on accurate uncertainty estimates.\n\nInterestingly, the method works by perturbing all data inputs instead of only the ones at the boundary of the training distribution. Also, there is no need to sample outside of the input distribution in order to have accurate uncertainty estimates in that area.\n\nThe paper is clear and very well written with a good balance between the use of formulas and insights in the text. \n\nThe experimental section starts with a toy 1d active learning task that shows the advantage of good uncertainty estimates when selecting new data points. The authors also present a larger regression task (8 input dimensions and 700k data points in the training set) in which they obtain good performance compared to other models able to quantify epistemic uncertainty. In my opinion, the experiments do a good job at showing the capabilities of the algorithm. If anything, since the authors use the word ""deep"" in the title of the paper I would have expected some experiments on deep networks and a very large dataset.\n']","[50, -20, 80]","[80, 60, 90]","[""Sentiment score: The review starts with a positive tone, praising the paper as 'well written' and 'a nice read'. The reviewer likes the idea and acknowledges its merits. However, there are also concerns and suggestions for improvement, balancing out the overall sentiment. This mix of positive and constructive criticism suggests a moderately positive sentiment, hence the score of 50.\n\nPoliteness score: The language used throughout the review is consistently respectful and professional. The reviewer uses phrases like 'I like', 'it is nice to see', and 'it would be really interesting', which convey a polite and constructive tone. Even when expressing concerns, the reviewer maintains a courteous approach, using phrases like 'My main concern' rather than more critical language. The detailed comments are framed as questions or suggestions rather than demands, further contributing to the polite tone. This consistently polite and professional language warrants a high politeness score of 80."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'nicely written' and 'targets important direction', they also point out several significant issues and conclude that the paper is 'not mature in terms of results obtained'. This indicates a generally critical stance, albeit with some positive aspects. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'That would be nice if authors can comment on...' and 'I recommend to consider...', which maintain a polite and professional tone even while pointing out areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the paper as 'clear and very well written' and state that the experiments 'do a good job at showing the capabilities of the algorithm.' The only mild criticism is the suggestion for experiments on deep networks and larger datasets, but this is presented as a minor point. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'Interestingly' and 'In my opinion,' which show consideration for the authors' work. They also balance positive comments with suggestions for improvement in a tactful manner, maintaining a professional and courteous tone throughout the review.""]"
"[""Analysis of Spectral Bias of ReLU networks\n\nThe paper uses Fourier analysis to study ReLU network utilizing its continuous piecewise linear structure.\n\nMain finding is that these networks are biased towards learning low frequency which authors denote `spectral bias’.  This provides another theoretical perspective of neural networks preferring more smooth functions while being able to fit complicated function. Also shows that in terms of parameters networks representing lower frequency modes are more robust. \n\nPro: \n- Nice introduction to Fourier analysis providing non-trivial insights of ReLU networks.\n- Intuitive toy experiments to show spectral bias and its properties \n- Thorough theoretical analysis and empirical support\n\nCon: \n- The analysis is clearly for ReLU networks although the title may provide a false impression that it corresponds to general networks with other non-linearities. It is an interesting question whether the behaviour characterized by the authors are universal. \n- At least for me, Section 4 was not as clearly presented as other section. It takes more effort to parse what experiments were conducted and why such experiments are provided.\n- Although some experiments on real dataset are provided in the appendix, I personally could not read much intuition of theoretical findings to the networks used in practice. Does the spectral bias suggest better way of training or designing neural networks for example?\n\nComments/Questions:\n- In Figure 1, two experiments show different layerwise behaviour, i.e. equal amplitude experiment (a) shows spectral norm evolution for all the layers are almost identical whereas in increasing amplitude experiment (b) shows higher layer change spectral norm more than the lower layer. Do you understand why and does Fourier spectrum provide insights into layerwise behaviour?\n- Experiment 3 seems to perform binary classification using thresholding to the logits. But how do you find these results also hold for cross-entropy loss?\n“The results confirm the behaviour observed in Experiment 2, but in the case of classification tasks with categorical cross-entropy loss.”\n\n\nNit: p3 ReLu -> ReLU / p5 k \\in {50, 100, … 350, 400} (close bracket) / p5 in Experiment 2 and 3 descriptions the order of Figure appears flipped. Easier to read if the figure appears as the paper reads / p7 Equation 11 [0, 1]^m\n\n\n********* updated review *************\n\nBased on the issues raised from other reviewers and rebuttal from authors, I started to share some of the concerns on applicability of Thm 1 in obtaining information on low k Fourier coefficients. Although I empathize author's choice to mainly analyze synthetic data, I think it is critical to show the decays for moderately large k in realistic datasets. It will convince other reviewers of significance of main result of the paper.\n"", 'The paper considers the Fourier spectrum of functions represented by Deep ReLU networks, as well as the relationship to the training procedure by which the network weights can be learned. \n\nIt is well-known (and somewhat obvious) that deep neural networks with rectifier activations represent piecewise linear continuous function. Thus, the function can be written as a sum of the products of  indicators of various polytopes (which define the partition of R^d) and the linear function on that polytope. This allows the authors to compute the Fourier transform (cf. Thm. 1) and the magnitude of f(k) decays as k^{-i} where the i can depend on the polytope in some intricate fashion. Despite the remarks at the end of Thm 1, I found the result hard to interpret and relate to the rest of the paper. The appearance of N_f in the numerator (which can be exponentially large in the depth) may well make these bounds meaningless for any networks that are relevant in practice.\n\nThe main paper only has experiments on some synthetic data. \n\nSec 3: Does the MSE actually go to 0 in these experiments? Or are you observing that GD fits lower frequencies, because it has a hard time fitting things that oscillate frequently?\n\nSec 4: I would have liked to see a clearer explanation for example of why increasing L is better for regression, but not for classification. As it stands I can\'t read much from these experiments. \n\nOverall, I feel that there might be some interesting ideas in this paper, but the way it\'s currently written, I found it very hard to get a good ""picture"" of what the authors want to convey.\n\n', ""Synopsis:\nThis paper analyzes deep Relu neural networks based on the Fourier decomposition of their input-output map. They show theoretically that the decomposition is biased towards low frequencies and give some support that low frequency components of a function are learned earlier under gradient descent training. \n\nPros:\n--Fourier decomposition is an important and (to the best of my knowledge) mostly original angle from which the authors analyze the input-output map governing neural networks. There is some neat mathematical analysis contained here based off of the piecewise-linearity of deep Relu nets and Fourier decomposition of polytopes in input space.\n\n--The setup in the toy experiments of Sec. 4 seems novel & thoughtful; the authors consider a lower-dimensional manifold embedded in a higher dimensional input space, and the Fourier decomposition of the composition of two functions is related to the decomposition of constituents.\n\nCons:\n--While this paper does a fairly good job establishing that NNs are spectrally biased towards low frequencies, I’m skeptical of its impact on our understanding of deep neural nets. Specifically, at a qualitative level it doesn’t seem very surprising: intuitively (as the authors write in Sec. 5), capturing higher frequencies in a function requires more fine tuning of the parameters.  At initialization, we don’t have such fine tuning (e.g. weights/biases drawn i.i.d Normal), and upon training it takes a certain amount of optimization time before we obtain greater “fine tuning.” At a quantitative level, these results would be more useful if (i) some insight could be gleaned from their dependence on the architectural choices of the network (in particular, depth) or (ii) some insight could be gained from how the spectral bias compares between deep NNs and other models (as is discussed briefly in the appendix -- for instance, kernel machines and K-NN classifiers). The primary dependence in the spectral decay (Theorem 1) seems to be that it (i) decays in a way which depends on the input dimensionality in most directions and (ii) it is highly anisotropic and decays more slowly in specific directions. The depth dependence seems to arise from the constants in the bound in Theorem 1 (see my comment below on the bound). \n\n--Relying on the growth of the weight norm to justify the network's bias towards learning lower frequencies earlier in training seems a bit tenuous to me. (I think the stronger evidence for learning lower frequencies comes from the experiments.) In particular, I'm not sure I would use the bound in Theorem 1 to conclude what would happen to actual Fourier components during training, since the bound may be far from being met. For instance, (1) the number of linear regions N_f changes during training -- what effect would this have? Also, (2) what if one were to use orthogonal weight matrices for training? Presumably the network would still train and generalize but the conclusions might be different (e.g. the idea that growth of weight norms is the cause of learning low frequency components earlier). \n\nMiscellaneous:\n--Would appreciate a greater discussion on the role of the cost function (MSE vs cross-entropy) in the analysis or experiments. Are the empirical conclusions mostly identical?\n\n"", 'Summary.\n\nThis paper has theoretical and empirical contributions on topic of Fourier coefficients of neural networks.  First is upper bound on Fourier coefficients in terms of number of affine pieces and Lipschitz constant of network.  Second is collection of synthetic data and trained networks whereupon is argued that neural networks focus early effort upon low Fourier coefficients.\n\n\nBrief evaluation.\n\nPros:\n\n+ This paper attacks important and timely topic: identifying and analyzing implicit bias of neural networks paired with standard training methods.\n\nCons:\n\n- ""Implicit bias"" hypothesis has been put forth by many authors for many years, and this paper does not provide compelling argument that Fourier coefficients provide good characterization of this bias.\n\n- Regarding ""many authors for many years"", this paper fails to cite and utilize vast body of prior work, as detailed below.\n\n- Main theorem here is loose upper bound primarily derived from prior work, and no lower bounds are given.  Prior work does assess lower bounds.\n\n- Experiments are on synthetic data; prior work on implicit regularization does check real data.\n\n\nDetailed evaluation.\n\n* ""Implicit bias"" hypothesis appears in many places, for instance in work of Nati Srebro and colleagues (""The Implicit Bias of Gradient Descent on Separable Data"" (and follow-ups), ""Exploring generalization in deep learning"" (and follow-ups), and others); it can also be found in variety of recent generalization papers, for instance again the work of Srebro et al, but also Bartlett et al, Arora et al.  E.g., Arora et al do detailed analysis of favorable biases in order to obtain refined generalization bound.  Consequently I expect this paper to argue to me, with strong theorems and experiments, that Fourier coefficients are a good way to assess implicit bias.\n\n* Theorem 1 is proved via bounds and tools on the Fourier spectra of indicators of polytopes due to Diaz et al, and linearity of the Fourier transform.  It is only upper bound (indeed one that makes no effort to deal with cancellations and thus become tight).  By contrast, the original proofs of depth separation for neural networks (e.g., Eldan and Shamir, or Telgarsky, both 2015), provide lower bounds and metric space separation.  Indeed, the work of Eldan&Shamir extensively uses Fourier analysis, and the proof develops a refined understanding of why it is hard for a ReLU network to approximate a Fourier transform of even simple functions: it has to approximate exponentially many tubes in Fourier space, which it can only do with exponentially many pieces.  While the present paper aims to cover some material not in Eldan&Shamir --- e.g., the bias with training --- this latter contribution is argued via synthetic data, and overall I feel the present work does not meet the (high) bar set by Eldan&Shamir.\n\n*  I will also point out that prior work of Barron, his ""superposition"" paper from 1993, is not cited. That paper presents upper bounds on approximation with neural networks which depends on the Fourier transform.  There is also follow-up by Arora et al with ""Barron functions"".\n\n* For experiments, I would really like to see experiment showing Fourier coefficients at various stages of training of standard network on standard data and standard data but with randomized labels (or different complexity in some other way).  These Fourier coefficients could also be compared to other ""implicit bias"" quantities; e.g., various norms and complexity measures.  In this way, it would be demonstrated that (a) spectral bias happens in practice, (b) spectral bias is a good way of measuring implicit bias.  Admittedly, this is computationally expensive experiment. \n\n* Regarding my claim that Theorem 1 is ""loose upper bound"": the slope of each piece is being upper bounded by Lipschitz constant, which will be far off in most regions.  Meanwhile, Lemma 1, ""exact characterization"", does not give any sense of how the slopes relate to weights of network.  Improving either issue would need to deal with ""cancellations"" I mention, and this is where it is hard to get upper and lower bounds to match.\n\nI feel this paper could be made much stronger by carefully using the results of all this prior work; these are not merely citation omissions, but indeed there is good understanding and progress in these papers.\n']","[-20, -30, 20, -50]","[60, 20, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice introduction', 'intuitive toy experiments', 'thorough theoretical analysis'), they also raise several concerns and criticisms. The updated review at the end expresses more significant doubts about the paper's main results and applicability, which further lowers the overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balances positive and negative feedback, and phrases criticisms as suggestions or questions rather than harsh statements. They also use polite phrases like 'at least for me' and 'I personally' when expressing opinions. The review maintains a professional and constructive tone, even when expressing concerns in the updated section."", ""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper. They find parts of the paper hard to interpret, question the practical relevance of some results, and state that they found it 'very hard to get a good picture' of what the authors want to convey. However, they do acknowledge that there might be some interesting ideas, which prevents the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I would have liked to see' and 'I feel that' to express their opinions. They also acknowledge potential positives ('there might be some interesting ideas'). The language is not overly formal or polite, but it avoids rudeness or harsh criticism, maintaining a constructive tone."", ""The sentiment score is slightly positive (20) because the review begins with a balanced synopsis and lists both pros and cons. The pros highlight the originality and thoughtfulness of the paper's approach. However, the cons express skepticism about the impact and some methodological concerns, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. Phrases like 'fairly good job' and 'would appreciate' indicate a polite tone. The reviewer also uses hedging language ('I'm skeptical', 'seems a bit tenuous') when expressing concerns, which maintains a courteous approach to criticism."", ""The sentiment score is -50 because the review is predominantly critical. While the reviewer acknowledges some positive aspects ('Pros'), the majority of the review focuses on the paper's shortcomings ('Cons'). The reviewer points out several significant issues, including lack of compelling arguments, failure to cite prior work, loose upper bounds, and limited experiments. However, the score is not extremely negative as the reviewer does recognize the paper's importance and timeliness.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, such as 'This paper fails to cite and utilize vast body of prior work' rather than using harsh or accusatory language. The reviewer also provides constructive feedback and suggestions for improvement. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many polite phrases or softeners.""]"
"['This paper uses deep reinforcement learning (DRL) for malware detection. It can get better performance than LSTM or GRU based models.\n\nDeep reinforcement learning (DRL) has already used for classification or detection. I am not sure about the main contribution of this work. The new application of DRL can not convince me.\n\nAs the dataset is not a public dataset, it is difficult to evaluate the performance. As for the comparing models, i think some CNN based methods should be included. If the task is a detection, i think some attention methods should also be investigated and compared. LSTM combined with attention should already be well investigated in other classification/detection tasks.', ""The paper proposes an approach to use deep reinforcement learning to halt execution in detecting malware attacks. The approach seems interesting, there are some problems.\n\n1. There is no good justification of using DRL to the problem. Action space is only continue and halt. Besides there should be no effect to the result by the previous action. So I don't think DRL is a good selection.\n2. Experiments are weak. There is no detailed comparison to other existing works. Only one dataset is used."", 'This paper attempts to train a predictor of whether software is malware. Previous studies have emulated potential malware for a fixed number of executed instructions, which risks both false negatives (haven’t yet reached the dangerous payload) and false positives (malware signal may be lost amidst too many other operations). This paper proposes using deep reinforcement learning over a limited action space: continue executing a program or halt, combined with an “event classifier” which predicts whether individual parts of the program consist of malware. The inputs at each time step are one of 114 high level “events” which correspond to related API invocations (e.g. multiple functions for creating a file). One limitation seems to be that their dataset is limited only to events considered by a ""production malware engine"", so their evaluation is limited only to the benefit of early stopping (rather than continuing longer than the baseline malware engine). They evaluate a variety of recurrent neural networks for classifying malware and show that all significantly underperform the “production antimalware engine”. Integrating the event classifier within an adaptive execution control, trained by DQN, improves significantly over the RNN methods. \n\nIt might be my lack of familiarity with the domain but I found this paper very confusing. The labeling procedure (the ""production malware engine”) was left entirely unspecified, making it hard to understand whether it’s an appropriate ground-truth and also whether the DRL model’s performance is usable for real-world malware detection. \n\nAlso, the baseline models used an already fairly complicated architecture (Figure 3) and it would have been useful to see the performance of simple heuristics and simpler models. ']","[-50, -50, -20]","[0, 0, 50]","[""The sentiment score is -50 because the reviewer expresses skepticism about the paper's main contribution and the convincingness of the work. They state 'I am not sure about the main contribution of this work' and 'The new application of DRL can not convince me,' which indicates a negative sentiment. However, they do acknowledge that the proposed method can get better performance than some existing models, which prevents the score from being extremely negative. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They express their criticisms directly but without using harsh or offensive language. The reviewer uses phrases like 'I am not sure' and 'I think,' which soften the critique somewhat, but also doesn't use any particularly polite or deferential language either."", ""The sentiment score is -50 because while the reviewer acknowledges that the approach 'seems interesting', they immediately follow with 'there are some problems' and proceed to list significant issues with the paper. The criticism outweighs the initial positive comment, indicating a generally negative sentiment. The politeness score is 0 (neutral) because the reviewer's language is direct and matter-of-fact without being overtly polite or rude. They state their concerns plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or compliments beyond the initial 'seems interesting' comment."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to improve malware detection, they express confusion about the methodology and point out several limitations. The reviewer states that they found the paper 'very confusing' and criticizes the lack of specificity in the labeling procedure. They also suggest that simpler models and heuristics should have been included for comparison. However, the review is not entirely negative, as it does recognize some improvements made by the proposed method.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It might be my lack of familiarity with the domain' to soften criticism, showing consideration for their own potential limitations. The reviewer also provides constructive feedback and suggestions for improvement rather than harsh criticism. The language used is neutral and objective, focusing on the content of the paper rather than making personal comments about the authors.""]"
"['This paper empirically finds that the distribution of activations in quantized networks follow  Gaussian or Laplacian distribution, and proposes to determine the optimal clipping factor by minimizing the quantization error based on the distribution assumption.\n\nThe pros of the work are its simplicity, the proposed clipping and quantization does not need additional re-training. However, while the key of this paper is to determine a good clipping factor, the authors use uniform density function to represent the middle part of both Gaussian and Laplacian distributions where the majority of data points lie in, but exact computation for the tails of the distributions at both ends. Thus the computation of quantization error is not quite convincing. Moreover, the authors do not compare with the other recent works that also clip the activations, thus it is hard to validate the efficacy of the proposed method.\n\nFor the experiments, the authors mention that a look-up table can be pre-computed for fast retrieval of clipping factors given the mean and sigma of a distribution.  However, the mean and sigma are continuous numbers, how is the look-up table made?  Moreover, how is the mean and std estimated for each weight tensor and what is  the complexity?\n', 'This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value. This seems like too small a contribution to warrant a paper. I wasn\'t convinced that appropriate baselines were used in experiments. There were a number of statements that I believed to be technically slightly incorrect. There were also some small language problems (though these didn\'t hinder understanding).\n\nmore specific comments:\n\nabstract:\n""derive exact expressions"" -- these expressions aren\'t exact. they turn out to be based on a piecewise zeroth order Taylor approximation to the density.\n\nmain paper:\n""allow fit bigger networks into"" -> ""allow bigger network to fit into""\n""that we are need"" -> ""that need""\n""introduces an additional"" -> ""introduces additional""\nclippig -> clipping\n\nit\'s not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.\n\n""distributions of tensors"" -> ""distribution of tensor elements""\nthis comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor. note that a distribution over tensors is a joint distribution over all entries in a tensor. e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.\n\n""than they could have by working individually"" -> ""than could have been achieved by each individually""\n\nWhy the focus on small activation bit depth? I would imagine weight bit-depth was more important than activation bit depth. Especially since you\'re using ?32-bit? precision in the weight/activations multiplications, so activations are computed at a high bit depth anyways.\n\nTable 1: Give absolute accuracies too! Improvement relative to what baseline?\n\nsec 2:\nsufficeint -> sufficient\n\\citep often used when it should instead be \\citet.\n""As contrast"" -> ""In contrast""\n\nsection 3:\nuniformity -> uniformly\n\nI don\'t believe the notion of p-value is being used correctly here w.r.t. the Kolmogorov-Smirnov test.\n\nFigure 1: The mean square error should never go to 0. This suggests something is wrong. If it\'s just a scaling issue, consider a semilogy plot.\n\nFigure 2: I\'m unclear what baseline (no clipping) refers to in terms of clipping values. For uniform quantization there needs to be some min and max value.', 'The paper describes a clipping method to improve the performance of one particular type of quantization method that is naive clipping to closest ""bins"". The contribution of the paper is the (possibly incorrect) derivation of the clipping value that causes the least quantization error IF assumptions can be made about the distribution of the parameters (in a non-bayesian sense). Thus, the significance is low due to both reasons.\n\nOne conceptual issue is the assumed relationship between quantization error and classification accuracy. The literature has shown that high quantization error does not necessarily mean low classification accuracy when using non-uniform quantization. The proposed clipping does not account for classification accuracy (on training set), but I understand the motivation being that the training set is not available. \n\n1. There seems to be an error in derivation of Eq (3), the first term should be $(x-sgn(x).\\alpha) = x+\\alpha$ for $x$ negative. Please comment on this.\n\n2. When solving the integrals, the authors simply pull the solution ""out of the hat"" and show that the derivative is the integrand. This is a very opaque presentation that we cannot see how you solved the integral. What is C in $\\psi(x)$?\n\n3. The assumptions on the parameters are only valid for the particular model/dataset/precision. The assumption does not generalize arbitrarily. For example, models with quantized weights have bi-modal distributions. How would you clip the  activations after e.g. a ReLu? This is without going in to the weaknesses of the K-S test. \n\n4. Experiments do not show any comparison to the large body of prior work in this area. \n\n5. Page 4, para below (3), what is ""common additive orthogonal noise""? You should explain or give intuition instead of simply referring to a different paper.\n\n6. In the uniform case, one would think f(x)=1/<range of the interval>=2\\alpha. Why is it 1/\\Delta?\n\n6. Section 4, range should be [-\\alpha, \\alpha] instead of [\\alpha, -\\alpha]? Since \\alpha is positive.']","[-20, -60, -50]","[50, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the work (simplicity, no need for re-training), they express several concerns and criticisms. These include doubts about the computation of quantization error, lack of comparison with recent works, and questions about the implementation details. The overall tone suggests the reviewer is not fully convinced by the paper's approach and results.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They begin by acknowledging the positive aspects of the work before presenting their criticisms. The language used is neutral and objective, focusing on the content rather than making personal comments. The reviewer poses questions and expresses concerns in a constructive manner, without using harsh or dismissive language."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper's contribution seems too small to warrant publication, expresses doubt about the baselines used, and points out several technical inaccuracies. However, it's not entirely negative as the reviewer acknowledges that language issues didn't hinder understanding. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I wasn't convinced' and 'I believed to be' rather than making blunt accusations. The reviewer also provides specific, constructive feedback, which is a polite way to critique. However, some statements are quite direct, preventing a higher politeness score."", ""The sentiment score is -50 because the review starts with a critical tone, highlighting the low significance of the paper's contribution and pointing out conceptual issues. The reviewer uses phrases like 'possibly incorrect derivation' and 'significance is low', indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges the paper's motivation. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Please comment on this' and 'The authors should explain', which are polite ways of requesting clarification or improvement. The reviewer also provides specific, constructive feedback, which is a polite approach to criticism. However, the directness of some statements (e.g., 'There seems to be an error') prevents the score from being higher.""]"
"['The author proposed an extended version of MNIS where they introduced thickening/thinning/swelling/fracture. The operation is done using binary morphological operations.\n\n* Providing benchmark data for tasks such disentanglement is important but I am not sure generating data is sufficient contribution for a paper. \n* I am not sure what conclusion I should draw from Fig 5 and Fig 6 about the data.\n* Eventually this data can become a benchmark data when it is paired with a method. Then that method/data are a benchmark.\n\n ', ""Authors present a set of criteria to categorize MNISt digists (e.g. slant, stroke length, ..) and a set of interesting perturbations (swelling, fractures, ...) to modify MNIST dataset. They suggest analysing performance of generative models based on these tools. By extracting this kind of features, they effectively decrease the dimmension of  data. Therefore, statistically comparing the distribution of generated vs test data and binning the generated data is now possible. They perform a thorough study regarding MNIST. Their tools are a handy addition to the analytical surveys in several applications (e.g. how classification fails), but not convincingly for generation. \n\nSince their method is manually designed for MNIST, the manuscript would benefit from a justification or discussion on the  common pitfalls and the correlation between MNIST generation and more complex natural image generation tasks. Since the presented metrics do not show a significant difference between the VAE and Vanilla GAN model, the question remains whether evaluating on MNIST is a good proxy for the performance of the model on colored images with backgrounds or not. For example sharpness and attending to details is not typically a challenge in MNIST generation where in other datasets this is usually the first challenge to be addressed. I'm not convinced that ability of a model in disentangling thickness correlates to their ability in natural image generation."", 'This paper discusses the problem of evaluating and diagnosing the representations learnt using a generative model. This is a very important and necessary problem.\n\nHowever, this paper lacks in terms of experimental evaluation and has some technical flaws.\n1. Morphological properties deals with only the ""shape"" properties of the image object. However, when the entire image is subject to the generative model, it learns multiple properties from the image apart from shape too - such as texture and color. Additionally, there are lot of low level pixel relations that the model learns to fit the distribution of the given images. However, here the authors have assumed that the latent space of the generative models are influenced only by the morphological properties of the image - which is wrong. Latent space features could be affected by the color or texture of the image as well.\n\n2. Extracting morphological properties of the image is straight-foward for MNIST kind of objects. However, it becomes really difficult for other datasets such as CIFAR or some real world images. Studying the properties of a generative model on such datasets is very challenging and the authors have not added a discussion around that. \n\n3. Now assuming that my GAN model has learnt good representation in Morpho-MNIST dataset, is it guaranteed to learn good representations in other datasets as well? There is no guarantee on generalizability or extensibility of the work. ']","[-20, -20, -50]","[20, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the author's work on extending MNIS, they express doubts about the sufficiency of the contribution and the clarity of the presented data. The reviewer uses phrases like 'I am not sure' twice, indicating uncertainty about the paper's value. However, the criticism is not harsh, hence the score is only mildly negative. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They begin by acknowledging the author's work and use non-confrontational language like 'I am not sure' instead of direct criticism. The reviewer also provides constructive feedback by suggesting how the work could be improved (pairing the data with a method). The language is not overtly polite, but it avoids rudeness, resulting in a slightly positive politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work ('interesting perturbations', 'thorough study', 'handy addition'), they express significant doubts about the broader applicability and relevance of the method ('not convincingly for generation', 'question remains whether evaluating on MNIST is a good proxy'). The overall tone suggests more concerns than praise. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions without using harsh or dismissive language. They phrase their criticisms as suggestions ('would benefit from') and questions rather than direct attacks. The review maintains a professional and constructive tone, even while expressing reservations about the work's broader implications."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the problem, they express significant criticisms about the paper's experimental evaluation and technical flaws. The review starts positively but quickly shifts to a more critical tone, listing several major issues. The politeness score is 20 because the reviewer uses relatively neutral language and avoids harsh or personal criticisms. They present their concerns in a professional manner, using phrases like 'However, this paper lacks...' and 'the authors have not added a discussion around that' rather than more confrontational language. The reviewer also acknowledges the importance of the topic, which adds a polite tone to the critique.""]"
"['# Summary\n\nThis paper proposes to improve the sample efficiency of transfer learning for Deep RL by mapping a new visual domain (target) onto the training one (source) using GANs. First, a deep RL policy is trained on a source domain (e.g., level 1 of the Atari Road Fighter game). Second, a GAN (e.g. UNIT or CycleGAN) is trained for unsupervised domain adaptation from target images (e.g., level 2 of Road Fighter) to source ones. Third, the policy learned in the source domain is applied directly on the GAN-translated target domain. The experimental evaluation uses two Atari games: i) transfer from Breakout to Breakout with static visual distractors inpainted on the screen, ii) from one Road Fighter level to others. Results suggest that this transfer learning approach requires less images than retraining from scratch in the new domain, including when fine-tuning does not work.\n\n\n# Strengths\n\nControlled toy experiments of Deep RL generalization issues:\nThe experiments on Breakout quantify how badly A3C overfits in this case, as it shows catastrophic performance degradation even with trivial static visual input perturbations (which are not even adversarial attacks). The fine-tuning experiments also quantify well how brittle the initial policy is, motivating further the importance of the problem studied by the paper.\n\nInvestigating the impact of different GANs on the end task:\nThe experiments evaluate two different image translation algorithms: one based on UNIT, the other based on CycleGAN. The results suggest that this choice is key and depends on the target domain. This suggests that the adaptation is in fact task dependent, confirming the direction pursued by others in task-specific unsupervised domain adaptation (cf. below).\n\n\n# Weaknesses\n\nDiscrepancy between quantitative and qualitative results:\nThe good quantitative results (accumulated rewards) reported in the experiments are not reflected in the qualitative results. As can be seen from the videos, these results seem more to be representative of a bias in the data. For instance, in the Road Fighter videos, one can clearly see that the geometry of the road (width, curves) and dynamic obstacles are almost completely erased in the image translation process. The main reasons the quantitative results are good seem to be i) in the non-translated case the agent crashes immediately, ii) the ""translated"" image is a wide straight road identical to level 1 where the policy just keeps the car in the middle (thus crashing as soon as there is a turn or a collision with an obstacle). Even in the breakout case, there are catastrophic translation failures for some of the studied variations although the domain gap is static and small. The image translation results look underwhelming compared to state of the art GANs used for much more complex tasks and environments (e.g., the original CycleGAN paper and follow-up works, or the ICLR\'18 progressive growing of GANs paper). This might be due to a hyper-parameter tuning issue, but it is unclear why the adaptation results seem not on par with previous results although the paper is in a visually simpler domain (Atari games).\n\nDoes not address the RL generalization issues:\nAlthough it is the main goal of the paper, the method is fundamentally side-stepping the problem as it does not improve in any way the policy or the Deep RL algorithm (they are left untouched). It is mapping the target environment to the source one, without consideration for the end task besides tuning GAN hyper-parameters. If the initial policy is very brittle (as convincingly shown in section 2), then just mapping to the source domain does not improve the generalization capabilities of the Deep RL algorithm, or even improves transfer learning: it just enables the policy to be used in other contexts that can be reduced to the training one (which is independent of the learning algorithm, RL or otherwise). So it is unclear whether the main contribution is the one claimed. The contribution seems instead an experimental observation that it might be easier to reduce related domains to the training one instead of retraining a new (specialised and brittle) policy. Existing works have actually gone further, learning jointly the image translation and task network, including for very challenging problems, e.g. in unsupervised sim-to-real visual domain adaptation (e.g., Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks from Bousmalis et al at CVPR\'17, which is not cited here).\n\nExperimental protocol:\nThe experimental conclusions are not clear and lack generality, because the optimal methods (e.g., choice of GAN, number of iterations) vary significantly depending on the task (cf. Table 3 for instance). Furthermore, the best configurations seem selected on the test set for every experiment.\n\nData efficiency vs actual training efficiency:\nThe main claim is that it is better to do image translation instead of fine-tuning or full re-training. The basis of that argument is the experimentally observed need for less frames to do the image translation (Table 2). However, it is not clear that training GANs for unsupervised image translation is actually any easier / faster. What about training instability, mode collapse, hyper-parameter tuning, and actual training time comparisons on the same hardware?\n\n\n\n# First Recommendation\n\nUsing image translation via GANs for unsupervised domain adaptation is a popular idea, used in the context of RL for Atari games here. Although the experiments show that mapping a target visual domain to a source one can enable reusing a deep RL policy as is, the qualitative results suggest this is in fact due to a bias in the data used here and the experimental protocol does not yield general insights. Furthermore, this approach is not specific to RL and its observed generalization issues. It does not improve the learning of the policy or improve its transferability, thus having only limited new insights compared to existing approaches that jointly learn image translation and target task-specific networks in much more challenging conditions.\n\nI believe this submission is at the start of an interesting direction, and requires further work on more challenging tasks, bigger domain gaps, and towards more joint training or actual policy transfer to go beyond this first set of encouraging but preliminary results.\n\n\n# Post-rebuttal Recommendation\n\nThanks to the authors for their detailed reply. The clarifications around overfitting, UNIT-GAN in Section 4, and the paper claims are helpful. I  also agree that the quantitative experiments are serious. I have bumped my score by +1 as a result.\n\nNonetheless, the results still seem preliminary and limited in scope for the aforementioned reasons. The discussion in the comments about the learned policies and transfer are ad-hoc. A lot of the shortcomings mentioned in the review are outright dismissed (e.g., ""de facto standard in RL""), downplayed (esp. generalization, which is puzzling for a transfer learning paper), or left for future work.\n\nAs there is no strong technical contribution beyond the experimental observations in the current submission, I suggest the authors try to address the GAN shortcomings both mentioned in reviews and their reply, instead of  just observing  / reporting them. As this paper\'s main focus is to use image translation in the proposed RL setting (with standard GAN and RL methods), I do not think it is just someone else\'s problem to improve the image translation part. Proposing a technical contribution there would make the paper much stronger and appealing to a broader ICLR audience.  This might also require adding a third game to ensure more generalizable experimental insights.', 'The paper seeks to generalize the reinforcement learning agents to related tasks. The authors first show the failure of conventional transfer learning techniques, then use GANs to translate the images in the target task to those in the source task. It is an interesting attempt to use the style-transferred images for generalization of RL agents. The paper is well written and easy to follow.\nPros:\n1.\tIt is a novel attempt to use GANs to generate pictures that help RL agents transfer the policies to other related environments.\n2.\tIt is an interesting viewpoint to use the performance of RL agent to evaluate the quality of images generated by GANS.\nCons:\n1.\tThe pictures generated by GANs can be hardly controlled, and extra noise or unseen objects might be generated, and may fool the RL agent during training.\n\nOther feedback:\nIn Figure 2, it seems the fine-tuning methods also achieve comparable results (Full-FT and Partial-FT), such as Figure 2(b) and Figure 2(c). Besides, the plot is only averaged over 3 runs, whereas the areas of standard deviation still overlap with each other. It may not be convincing enough to claim the failure of fine-tuning methods.\n\nMinor typos:\n1.\tIn 2.1, second paragraph: 80x80 -> $80 \\times 80$\n2.\tIn 2.1, second paragraph: chose -> choose\n', 'This paper propose an intermediate stage before transfer learning on playing new games that is with slight visual change. The intermediate stage is basically a mapping function to translate the images in the new game to old game with certain correspondence. The paper claims that the adding of intermediate stage can be much more efficient than re-train the model instead. \nThen the paper compares different baselines without the mapping model. The baselines are either re-trained from scratch or (partially) initialized with trained model. The learning curves show that fine-tuning fails to transfer knowledge from the source domain to target domain. The mapping model is constructed based on unaligned GAN. And the experiments are setup and results are shown.\n\nPros:\n+ The paper makes a very good start from analogizing human being adjusting himself between similar tasks. \n+ The paper demonstrates strong motivation on improving the existing transfer learnings that are either fail or take too much time to train from scratch.\n+ The paper clearly illustrate the learning curve of multiple approaches for transferring knowledge across tasks.\n+ The paper proves detailed analysis why using unaligned GAN to learn the mapping model, and gives\n+ I also like the experiment section. It is well written, especially the discussions section answer all my questions. \n\nQuestions:\n1.\tWhy fine-tuning from a model that is trained from related task does not help, even decelerate the learning process? Could you explain it more?\n2.\tCould you please also include in figure 2 the proposed transfer learning curve with the mapping model G? I’m curious how much faster it will converge than the Full-FT. And I suppose the retrain from scratch can be extremely slow and will exceed the training epoch scope in the figure.\n3.\tIn dataset collection, you use untrained agent to collect source domain image. Will it improve the results if you use well trained agent, or even human agent, instead? \n4.\tI hope, if possible, you can share the source code in the near future.\n']","[-50, 70, 80]","[50, 80, 90]","[""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper, they express significant concerns about the methodology, results, and overall contribution. The review begins positively but quickly shifts to a critical tone, highlighting major weaknesses and limitations. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific recommendations and acknowledging the potential of the work despite their criticisms. They use polite language like 'I believe this submission is at the start of an interesting direction' and thank the authors for their detailed reply in the post-rebuttal section, even while maintaining their critical stance."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive overview, highlighting the paper's interesting approach and good writing. They list multiple pros and only one con, indicating a generally favorable view. The politeness score is 80 (polite) due to the reviewer's constructive tone throughout. They use phrases like 'interesting attempt' and 'well written', and provide feedback in a respectful manner. Even when pointing out potential issues, the language remains professional and courteous. The reviewer also offers helpful suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 80 (positive) because the review starts with a clear summary of the paper's content and then lists several pros, indicating a generally positive view of the work. The reviewer uses phrases like 'very good start', 'strong motivation', and 'well written', which all contribute to a positive sentiment. The presence of questions at the end doesn't detract significantly from the overall positive tone, as they appear to be constructive and aimed at improving the paper rather than criticizing it. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper and framing their questions in a courteous manner. The use of phrases like 'I like', 'Could you please', and 'I hope' contribute to a polite and constructive tone. The reviewer also expresses interest in future work and potential code sharing, which further reinforces the polite and encouraging nature of the review.""]"
"['In this paper the authors propose a method called “All learning rates at once” (Alrao) which aims to save the time needed to tune learning rate for DNN models testing. The method sets individual learning rate to each feature in each layer of a network using the values sampled from truncated log-uniform distribution. The only cost of the method is the creation of several branches of the classifier layer. Each of the branches is trained with a predefined learning rate value, and the final predictions are obtained by model averaging. In the presented experiments Alrao demonstrates performance comparable to SGD with optimal learning rate and more stable results compared to Adam. The authors indicate limitations of Alrao caused by the overhead in the final layer which complicates the application of the method for models with large classifier layer.\n\nOverall, the paper is written clearly and organized well. However, Equation (2) needs to be corrected. The denominator in the normalizing constant of log-uniform distribution should be \\log\\eta_{max} - \\log\\eta_{min}.\n\nMy main concern is related to the experimental evaluation of the method. I find the experimental evidence for the effectiveness of Alrao insufficient. As the authors propose to employ the method to quickly evaluate models and select best models to further training it would be beneficial to have more results in order to ensure that the method is reliable in this setting. Other demonstrations which would show possibly that the method enhances performance of architecture search methods may emphasize significance of the proposed method. Also, more experiments comparing Alrao against sampling learning rates per weight are needed. Given the current results, it is still unclear whether the proposed method performs better. Finally, I recommend to include comments explaining how much more time is needed in practice to train model with Alrao compared to SGD training.', ""POST REBUTTAL: I think the paper is decent, there are some significant downsides to the method but it could constitute a first step towards a more mature learning-rate-free method. However, in its current state the paper is left with some gaping holes in its experiment section. The authors tried to add experiments on Imagenet, but these experiments apparently didn't finish before the end of the rebuttal period. For that reason, the paper probably should not be accepted for publication (even if the authors manage to finish running these experiments, we would not have a chance to review these results). \n\n------\nOriginal review\n------\n\nIn this paper, the authors present a method for training deep networks with randomly sampled feature-wise learning rates, removing the need for fixed learning rates and their tuning. The method is shown to perform comparatively to SGD with a learning rate roughly optimized with regards to validation performance. The method applies to the most popular types of deep learning architectures, which includes fully connected layers, convolutional layers and recurrent cells. \n\nQuality: The paper is of a decent quality in general, I noticed no glaring omissions while reading the paper. However, I do worry that the method provides little gain for a lot of work. It is becoming more and more easy to tune the learning rate of deep learning models with strategies such as early stopping, and this method comes at a high cost for models with a big final layer. \n\nClarity: The paper is well written, but the reader is often (too often?) sent to the Appendix, which is itself ordered in a strange way (e.g., the first reference to the Appendix in the paper refers to Appendix F?). If some sections of the Appendix are not needed, I would remove them. \n\nOriginality: The work is original in the approach, i.e. randomization as a way to get rid of learning rates is a novel method. However, there was one work presented last year at NIPS which concerns itself with the same problem, which is getting rid of learning rates:\n\n“Training Deep Networks without Learning Rates Through Coin Betting” by Francesco Orabona and Tatiana Tommasi, NIPS, 2017.\n\nThey don’t compare on the same methods and the same datasets, but I think the authors should be aware of this work and perhaps compare themselves with it. The work takes a very different approach to solve the problem so I don’t think it’s an issue for this paper. \n\nSignificance: I think the work is important, in that it adds another tool to solve the learning rate problem. I would not say it is likely to have a very high impact, because it involves a lot of work, for little benefit. Furthermore, the cost of reproducing multiple times the last layer of the network will be prohibitive in many cases for NLP. \n\nThe method feels ad-hoc in many respects, and there are no guarantees that it would work any better than Adam does on pathological cases. Perhaps some mathematical analysis on simpler problems would help make the contributions stronger. \n\nThe authors state that the learning rate range has little impact on performance, yet it still has enough impact to justify tuning it for different models and datasets (on CIFAR it is 10^-5 to 10^1, on Pennbank it is 10^-3 to 10^2). I would tend to agree that the alrao method is more robust to the choice of learning rate than plain SGD, however the fact of the matter is that there are still parameters to tune. \n\nFigure 5. also seems to suggest that the range is important, although the models were not trained until the end, so it is not clear.\n\nSome additional comments:\n\nNitpicking: In Section 2, most sub-sections (or paragraphs titles?) have the name of the method in them. That’s redundant. Instead of “Alrao principle”, “Alrao update”, etc., just write “Principle.”, “Update.”.\n\nIs there a justification for using the same learning rate for all weights in an LSTM unit? \n\nI believe there is a mistake in Equation 2. The denominator should be log(\\eta_{max}) - log(\\eta_{min})\n\n[second paragraph on page 4.] Once again nitpicking for the sake of clarity: “For each classifier Cθ cl j, we set a learning rate log eta_j = …” this reads as if the learning rate would be set to log eta_j, but you probably mean you will set the learning rate to eta_j = exp(...).\n\nFigure 5b in the appendix does not specify which curve has which learning rate interval. \n"", '\nThis work proposes an optimization method called All Learning Rate\nAt Once (Alrao) for hyper-parameter tuning in neural networks.\nInstead of using a fixed learning rate, Alrao assigns the learning\nrate for each neuron by randomly sampling from a log-uniform\ndistribution while training neural networks. The neurons with\nproper learning rate will be well trained, which makes the whole\nnetwork eventually converge. The proposed method achieves\nperformance close to the SGD with well-tuned learning rate on the\nexperiments of image classification and text prediction.\n\n\n#Pros:\n\n-- The use of randomly sampled learning rate for deep learning\nmodels is novel and easy to implement. It can become a good\napproximation of using SGD with the optimal learning rate.\n\n-- The paper is well-written and easy to follow. The proposed\nmethod is illustrated in a clear way.\n\n-- The experiments are solid, and the performance on three\ndifferent architectures are shown for comparison. According to the\nexperiments, the proposed method is not sensitive to the\nhyper-parameter \\eta_{min} and \\eta_{max}.\n\n#Cons:\n\n-- The authors have not given any theoretical convergence analysis\non the proposed method.\n\n-- Out of all four experiments, the proposed method only\noutperforms Adam once, which does not look like strong support.\n\n-- Alrao achieves good performance with SGD, but not with Adam.\nAlso, there are no experimental results on Alrao with other\noptimization methods.\n\n#Detailed comments:\n\n(1) I understand that Alrao will be more efficient compared to\napplying SGD with different learning rate, but will it be more\nefficient compared to Adam? No clear clarification or experimental\nresults have been shown in the paper.\n\n(2) The units with proper learning rate could learn well and\nconstruct good subnetworks. I am wondering if the units with ""bad""\n(too small or too large) learning rate might give a bad influence\non the convergence or performance of the whole network.\n\n(3) The experimental setting is not clear, such as, how the input\nnormalized, how data augmentation is used in the training phase,\nand what are the depth, width and other settings for all three\narchitectures.\n\n(4) The explanation on the influence of using random learning rate\nin the final layer is not clear to me.\n\n(5) Several small comments regarding writing:\n    (a) Is the final classifier layer denoted as $C_{\\theta^c}$ or  $C_{\\theta^{cl}}$ in the third paragraph of ""Definitions and notations""?\n    (b) In algorithm 1, what is the stop criteria for the do while? The ""Convergence ?"" in the while condition is confusing.\n    (c) Is the learning curve in Figure 2 from one run or is it the average of all runs? Are the results consistent for each run? How about the learning curves for VGG19 and LSTM, do they have similar learning curves with the two architectures in Figure 2?\n    (d) For Figure 3, it will be easier to compare the performance on the training and test set, if the color bars for the two figures share the same range.\n']","[20, -20, 50]","[60, 50, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is 'written clearly and organized well' and finds the proposed method interesting. However, they express concerns about insufficient experimental evidence and suggest additional experiments, indicating a mixed but overall slightly positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I recommend' and 'it would be beneficial,' which maintain a polite and professional tone while providing feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merits of the paper ('decent quality', 'well written', 'original approach'), they express significant concerns about its readiness for publication. The reviewer points out 'gaping holes' in the experiment section and recommends against acceptance in its current state. They also question the method's practical benefits compared to its costs. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement, acknowledge the paper's strengths, and explain their concerns clearly without using harsh language. The reviewer balances critique with positive comments, demonstrating politeness in academic discourse."", ""The sentiment score is 50 (slightly positive) because the review acknowledges both pros and cons of the work. The reviewer praises the novelty and clarity of the method, as well as the solid experiments. However, they also point out limitations such as lack of theoretical analysis and mixed performance compared to other methods. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions or questions rather than harsh criticisms. They use phrases like 'I understand that...' and 'I am wondering if...' which maintain a polite tone. The reviewer also provides specific, detailed comments to help improve the paper, which is a courteous approach in academic peer review.""]"
"['Review: This paper proposed ""Dopamine"", a new framework for DeepRL.  While this framework seems to be useful and the paper seems like a useful guide for using the framework, I didn\'t think that the paper had enough scientific novelty to be an ICLR paper.  I think that papers on novel frameworks can be suitable, but they should demonstrate that they\'re able to do something or provide a novel capability which has not been demonstrated before.  \n\nStrengths: \n\n-Having a standardized tool for keeping replay buffers seems useful.  \n\n-The Dopamine framework is written in Python and has 12 files, which means that it should be reasonably easy for users to understand how it\'s functioning and change things or debug.  \n\n-The paper has a little bit of analysis of how different settings effect results (such as how to terminate episodes) but I\'m not sure that it does much to help us in understanding the framework.  I suppose it\'s useful to understand that the settings which are configurable in the framework affect results?  \n\n-The result on how sticky actions affect results is nice but I\'m not sure what it adds over the Machado (2018) discussion.  \n\nWeaknesses: \n\n-Given that the paper is about documenting a new framework, it would have been nice to see more comprehensive baselines documented for different methods and settings.  \n\n-I don\'t understand the point of 2.1, in that it seems somewhat trivial that research has been done on different architectures and algorithms.  \n\n-In section 4.2, I wonder if the impact of training mode vs. evaluation mode would be larger if the model used a stochastic regularizer.  I suspect that in general changing to evaluation mode could have a significant impact.  \n', 'Summary:\nThe authors present an open-source framework TensorFlow-based named Dopamine to facilitate the task of researchers in deep reinforcement learning (deep RL). It allows to build deep RL using existing components such as reinforcement learning agents, as well as handling memory, logs and providing checkpoints for them.\nEmphasis is given on providing a unified interface to these agents as well as keeping the framework generic and simple (2000 lines of code).\nThe framework was demonstrated on Atari games notably using Deep Q-network agents (DQN).\nThe authors provide numerous examples of parameter files that can be used with their framework.\nPerformance results are reported for some agents (DQN, C51, Rainbow, IQN).\n\nGiven the actual trends in deep learning works, unified frameworks such as that proposed is welcome.\nThe automatization of checkpointing for instance is particularly useful for long running experiments.\nAlso, trying to reduce the volume of code is beneficial for long-term maintenance and usability.\n\nMajor concerns:\n* This type of contribution may not match the scope of ICLR.\n* In the abstract and a large fraction of the text, the authors claim that their work is a generic reinforcement learning framework. However, the paper shows that the framework is very dependent on agents playing Atari games. Moreover, the word ""Atari"" comes out of nowhere on pages 2 and 5.\nThe authors should mention in the beginning (e.g. in the abstract) that they are handling only agents operating on Atari games.\n* The positioning of the paper relative to existing approaches is unclear: state of the art is mentioned but neither discussed nor compared to the proposal.\n* The format of the paper should be revised:\n                - Section 5 (Related Works) should come before presenting the author\'s work. When reading the preceding sections, we do not know what to expect from the proposed framework.\n                - All the code, especially in the appendices, seems not useful in such a paper, but rather to the online documentation of the author\'s framework.\n* What is the motivation of the author\'s experiments?\n                - Reproduce existing results (claimed on page 1)? Then, use the same settings as published works and show that the author\'s framework reaches the same level of performances.\n                - Show new results (such as the effect of stickiness)? Then the authors should explicitly say that one of the contributions of the paper is to show new results.\n* The authors say that they want to compare results in Figure 3. They explain why the same scale is not used. To my opinion, the authors should find a way to bring all comparisons to the same scale.\n\nFor all these reasons, I think the paper is not ready for publication at ICLR.', 'This paper introduces and details a new research framework for reinforcement learning called Dopamine. The authors give a brief description of the framework, built upon Tensorflow, and reproduce some recent results on the ALE framework. \n\nPros:\n1. Nice execution and they managed to successfully reproduce recent deep RL results, which can be challenging at times.\n\nCons:\n1. Given that this is a paper describing a new framework, I expected a lot more in terms of comparing it to existing frameworks like OpenAI Gym, RLLab, RLLib, etc. along different dimensions.  In short, why should I use this framework? Unfortunately, the current version of the paper does not provide me information to make this choice. Other than the framework, the paper does not present any new tasks/results/algorithms, so it is not clear what the contribution is.\n\n\nOther comments:\n1. The paragraphs in sections 2.1 and 2.2 (algorithmic research, architecture research, etc.) seem to say pretty much the same things. They could be combined, and the DQN can be used as a running example to make the points clear.\n2. The authors mention tests to ensure reliability and reproducibility. Can you provide more details? Do these tests account for semantic bugs common while implementing RL algorithms?']","[-30, -60, -20]","[50, 20, 60]","[""The sentiment score is -30 because the reviewer expresses a generally negative view of the paper's suitability for ICLR, citing lack of scientific novelty. However, they do acknowledge some strengths, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering both strengths and weaknesses in a balanced manner. They avoid harsh criticism and use phrases like 'I didn't think' and 'I wonder if' to soften their critiques. The reviewer also provides specific, constructive feedback, which contributes to the polite tone."", ""The sentiment score is -60 because the reviewer expresses several major concerns and concludes that the paper is not ready for publication at ICLR. The review starts with some positive comments about the framework's usefulness, but the majority of the review focuses on significant issues and criticisms. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'The authors should' and 'To my opinion' rather than harsh or rude language. The reviewer also acknowledges some positive aspects of the work before delving into the criticisms, which adds to the politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Nice execution'), they express significant concerns about the paper's contribution and lack of comparison to existing frameworks. The 'Cons' section outweighs the 'Pros', indicating overall dissatisfaction with the paper's content. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer balances critique with acknowledgment of the paper's strengths, maintaining a polite and professional tone.""]"
"['Quality (5/10): This paper proposes DppNet, which approximates determinantal point processes with deep networks by inhibitive attention mechanism. The authors provided a theoretical analysis under some condition that the DppNet is of log-submodularity.\n\nClarity (9/10): This paper is well written and provides a clear figure to demonstrate their network architecture.\n\nOriginality (6/10): This paper is mainly based on the work [Vaswani et al, Attention is all you need, 2017]. It computes the dissimilarities by subtracting attention in the original work from one, and then samples a subset by an unrolled recurrent neural network. \n\nSignificance (5/10): This paper uses negative log-likelihood as the measurement to compare DppNet with other methods. Without further application, it is difficult to measure the improvement of this method over other methods.\n\nPros: \n(1) This paper is well written and provides a figure to clearly demonstrate their network architecture.\n\n(2) This paper provides a deep learning way to sample a subset of data from the whole data set and reduce the computation complexity.\n\nThere are some comments.\n(1) Figure 4 shows the sampled digits from Uniform distribution, DppNet (with Mode) and Dpp. How about the sampled digits from k-Medoids? Providing the sampled digits from k-Medoids can make the experiments more complete.\n\n(2) The object of DppNet is to minimize the negative log-likelihood. The DPP and k-Medoids have other motivations, not directly optimizing the negative log-likelihood. This may be the reason why DppNet has a better performance on negative log-likelihood, even than DPP. Could the authors provide some other measures (like the visual comparison in figure 4) to compare these methods?\n\n(3) Does GenDpp Mode in Table 2 mean the greedy mode in Algorithm 1? A clear denotation can make it more clear.', 'This paper proposes a scaleable algorithm for sampling from DppNets, a proposed model which approximates the distribution of a DPP. The approach builds upon a proposed inhibitive attention mechanism and transformer networks.\n\nThe proposed approach and focus on sampling is original as far as I can tell. The problem is also important to parts of the community as DPPs (or similar distributions) are used more and more frequently. However, the applicability of the proposed approach is limited as it is unclear how to deal with varying ground set sizes — the authors briefly discuss this issue in their conclusion referring to circumvent this problem by subsampling (this can however be problematic either requiring to sample from a DPP or incurring high probability of missing „important“ items).\n\nFurthermore the used evaluation method is „biased“ in favor of DppNets as numerical results evaluate the likelihood of samples under the DPP which the DppNet is trained to approximate for. This makes it difficult to draw conclusions from the presented results. I understand that this evaluation is used as there is no standard way of measuring diversity of a subset of items, but it is also clear that „no“ baseline can be competitive. One possibility to overcome this bias would be to consider a downstream task and evaluate performance on that task. \n\nFurthermore, I suggest to make certain aspects of the paper more explicit and provide additional details. For instance, I would suggest to spell out a training algorithm, provide equations for the training criterion and the evaluation criterion. Please comment on the cost of training (constantly computing the marginal probabilities for training should be quite expensive) and the convergence of the training (maybe show a training curve; this would be interesting in the light of Theorem 1 and Corollary 1).\n\nCertain parts of the paper are unclear or details are missing:\n* Table 3: What is „DPP Gao“?\n* How are results for k-medoids computed (including the standard error)? Are these results obtained by computing multiple k-medoids solutions with differing initial conditions?\n* In the paper you say: „Furthermore, greedily sampling the mode from the DPPNET achieves a better NLL than DPP samples themselves.“ What are the implications of this? What is the NLL of an (approximate) mode of the original DPP? Is the statement that you want to make, that the greedy approximation works well?', 'Determinantal Point Processes provide an efficient and elegant way to sample a subset of diverse items from a ground set. This has found applications in summarization, matrix approximation, minibatch selection. However, the naive algorithm for DPP takes time O(N^3), where N is the size of the ground set. The authors provide an alternative model DPPNet for sampling diverse items that preserves the elegant mathematical properties (closure under conditioning, log-submodularity) of DPPs while having faster sampling algorithms.\n\nThe authors need to compare the performance of DPPNet against faster alternatives to sample from DPPs, e.g., https://arxiv.org/pdf/1509.01618.pdf, as well as compare on applications where there is a significant gap between uniform sampling and DPPs (because there are the applications where DPPs are crucial). The examples in Table 2 and Table 3 do not address this.']","[20, -20, 50]","[70, 60, 75]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges some strengths of the paper (well-written, clear figure, theoretical analysis), they also point out several limitations and areas for improvement. The overall tone is balanced but leans slightly positive due to the 'Pros' section and generally constructive feedback. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions rather than demands. They use phrases like 'Could the authors provide...' which is polite and non-confrontational. The review maintains a professional and courteous tone throughout, even when pointing out potential weaknesses in the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and importance of the work, they express several significant concerns about the paper's limitations and evaluation methods. The reviewer points out issues with the applicability of the approach, biased evaluation methods, and missing details. However, the tone is not entirely negative as they also offer constructive suggestions for improvement.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I suggest', 'Please comment', and 'I understand that' which indicate a polite and considerate approach to giving feedback. The reviewer also acknowledges the positive aspects of the work before presenting criticisms, which is a polite way to structure feedback. While direct in their critiques, the language remains constructive rather than harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the efficiency and elegance of Determinantal Point Processes and the potential of the authors' alternative model, DPPNet. However, they also point out the need for additional comparisons, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the work's merits before suggesting improvements. They use phrases like 'The authors need to' rather than more demanding language, maintaining a professional and courteous tone.""]"
"['The paper considers adaptive regularization, which has been popular in neural network learning.  Rather than adapting diagonal elements of the adaptivity matrix, the paper proposes to consider a low-rank approximation to the Gram/correlation matrix.\n\nWhen you say that full-matrix computation ""requires taking the inverse square root"", I assume you know that is not really correct?  As a matter of good implementation, one never takes the inverse of anything.  Instead, on solves a linear system, via other means.  Of course, approximate linear system solvers then permit a wide tradeoff space to speed things up.\n\nThere are several issues convolved here: one is ``full-matrix,\'\' another is that this is really a low-rank approximation to a matrix and so not full matrix, another is that this may or may not be implementable on GPUs.  The latter may be important in practice, but it is orthogonal to the full matrix theory.\n\nThere is a great deal of discussion about full-matrix preconditioning, but there is no full matrix here.  Instead, it is a low-rank approximation to the full matrix.  If there were theory to be had here, then I would guess that the low-rank approximation may work even when full matrix did not, e.g., since the full matrix case would involve too may parameters.\n\nThe discussion of convergence to first order critical points is straightforward.\n\nAdaptivity ratio is mentioned in the intro but not defined there.  Why mention it here, if it\'s not being defined.\n\nYou say that second order methods are outside the scope, but you say that your method is particularly relevant for ill-conditioned problems.  It would help to clarify the connection between the Gram/correlation matrix of gradients and the Hessian and what is being done to ill-conditioning, since second order methods are basically designed for ill-conditioned problems..\n\nIt is difficult to know what the theory says about the empirical results, given the tweaks discussed in Sec 2.2, and so it is difficult to know what is the benefit of the method versus the tweaks.\n\nThe results shown in Figure 4 are much more interesting than the usual training curves which are shown in the other figures.  If this method is to be useful, understanding how these spectral properties change during training for different types of networks is essential.  More papers should present this, and those that do should do it more systematically. \n\nYou say that you ""informally state the main theorem.""  The level of formality/informality makes it hard to know what is really being said.  You should remove it if it is not worth stating precisely, or state it precisely.  (It\'s fair to modularize the proof, but as it is it\'s hard to know what it\'s saying, except that your method comes with some guarantee that isn\'t stated.)', 'The authors seek to make it practical to use the full-matrix version of Adagrad’s adaptive preconditioner (usually one uses the diagonal version), by storing the r most recently-seen gradient vectors in a matrix G, and then showing that (GG^T)^(-½) can be calculated fairly efficiently (at the cost of one r*r matrix inversion, and two matrix multiplications by an r*d matrix).\n\nThis is a really nice trick. I’m glad to see that the authors considered adding momentum (to adapt ADAM to this setting), and their experiments show a convincing benefit in terms of performance *per iteration*. Interestingly, they also show that the models found by their method also don’t generalize poorly, which is noteworthy and slightly surprising.\n\nHowever, their algorithm--while much less computationally expensive than true full-matrix adaptive preconditioning---is still far more expensive than the usual diagonal version. In Appendix B.1, they report mixed results in terms of wall-clock time, and I strongly feel that these results should be in the main body of the paper. One would *expect* the proposed approach to work better than diagonal preconditioning on a per-iteration basis (at least in terms of training loss). A reader’s most natural question is whether there is a large enough improvement to offset the extra computational cost, so the fact that wall-clock times are relegated to the appendix is a significant weakness.\n\nFinally, the proposed approach seems to sort of straddle the line between traditional convex optimization algorithms, and the fast stochastic algorithms favored in machine learning. In particular, I think that the proposed algorithm has a more-than-superficial resemblance to stochastic LBFGS: the main difference is that LBFGS approximates the inverse Hessian, instead of (GG^T)^(-½). It would be interesting to see how these two algorithms stack up.\n\nOverall, I think that this is an elegant idea and I’m convinced that it’s a good algorithm, at least on a per-iteration basis. However, it trades-off computational cost for progress-per-iteration, so I think that an explicit analysis of this trade-off (beyond what’s in Appendix B.1) must be in the main body of the paper.\n', 'adaptive versions of sgd are commonly used in machine learning. adagrad, adadelta are both popular adaptive variations of sgd. These algorithms can be seen as preconditioned versions of gradient descent where the preconditioner applied is a matrix of second-order moments of the gradients. However, because this matrix turns out to be a pxp matrix where p is the number of parameters in the model, maintaining and performing linear algebra with this pxp matrix is computationally intensive. In this paper, the authors show how to maintain and update this pxp matrix by storing only smaller matrices of size pxr and rxr, and performing 1. an SVD of a small matrix of size rxr 2. matrix-vector multiplication between a pxr matrix and rx1 vector. Given that rxr is a small constant sized matrix and that matrix-vector multiplication can be efficiently computed on GPUs, this matrix adapted SGD can be made scalable. The authors also discuss how to adapt the proposed algorithm with Adam style updates that incorporate momentum. Experiments are shown on various architectures (CNN, RNN) and comparisons are made against SGD, ADAM. \n\nGeneral comments: THe appendix has some good discussion and it would be great if some of that discussion was moved to the main paper.\n\nPros:  Shows how to make full matrix preconditioning efficient, via the use of clever linear algebra, and GPU computations.\nShows improvements on LSTM tasks, and is comparable with SGD, matching accuracy with time.\n\nCons: While doing this leads to better convergence, each update is still very expensive compared to standard SGD, and for instance on vision tasks the algorithm needs to run for almost double the time to get similar accuracies as an SGD, adam solver.  This means that it is not apriori clear if using this solver instead of standard SGD, ADAM is any good. It might be possible that if one performs few steps of GGT optimizer in the initial stages and then switches to SGD/ADAM in the later stages, then some of the computational concerns that arise are eliminated. Have the authors tried out such techniques?']","[-20, 50, 50]","[20, 75, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they raise several critical points and issues that need to be addressed. The reviewer points out inaccuracies, lack of clarity, and areas where more explanation or precision is needed. However, it's not entirely negative as they also highlight interesting aspects of the work, particularly in Figure 4.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout. They use phrases like 'It would help to clarify' and 'You should' rather than more aggressive language. The critique is direct but not rude, and the reviewer offers constructive suggestions. However, the tone is not overly polite or deferential either, maintaining a neutral to slightly positive level of politeness typical in academic peer reviews."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the work as a 'really nice trick' and 'elegant idea', showing appreciation for the authors' contribution. They are 'convinced that it's a good algorithm' and note its benefits. However, they also point out significant weaknesses, particularly regarding the lack of wall-clock time analysis in the main body, which prevents a fully positive score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and using phrases like 'I'm glad to see' and 'Interestingly'. They provide constructive criticism without harsh language, suggesting improvements rather than simply criticizing. The reviewer maintains a professional and courteous tone, even when pointing out weaknesses in the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and improvements, especially for LSTM tasks, while also pointing out some limitations. The review begins with a neutral summary and then lists both pros and cons, indicating a balanced perspective. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as questions or suggestions rather than direct attacks. The reviewer also acknowledges the value of the appendix and suggests incorporating some of that content into the main paper, which is a polite way of recommending improvements.""]"
"['Summary\n------------------\n\nThe authors propose a new method to sparsify DNNs based on a dropout induced by a Beta-Bernoulli prior. They further propose a data-dependent dropout by linking the Beta-Bernoulli prevalence to the inputs, achieving a higher sparsification rate. In the experimental section they show that the proposed method achieves better compression rates than other methods in the literature. However, experiments against some recent methods are missing. Also, some additional experiments using data-dependent dropouts not based on the Beta-Bernoulli prior would help to better disentangle the effects of the two contributions of the paper. Overall, the paper is well-written but the mentioning of the IBP is confusing. The authors devote quite a bit of space to the IBP when it is actually not used at all.\n\n Detailed comments\n-------------------------\n\n1)\tIntroduction\n\nThe paper is well motivated and the introduction of the paper clearly states the two main contributions of the paper: a Beta-Bernoulli dropout prior and a dependent Beta Bernoulli dropout prior. \n\n2)\tBackground\n\nSection 3.1 is a nice summary of variational inference for BNNs. On the other hand, Section 3.2 is misleading. The authors use this section to introduce the IBP process (a generative sequential process to generate samples from a random measure called the Beta-Bernoulli process). However, this is not used in the paper at all. Then they introduce the Beta-Bernoulli prior as a finite Beta-Bernoulli process. I find this quite convoluted. I would suggest to introduce the Beta-Bernoulli distribution as a prior directly, and state that for alpha/K this is a sparse-inducing prior (where the average number of features is given by \\frac{\\alpha}{1 + \\frac{\\alpha}{K} ). No need to mention the IBP or the Beta Bernoulli process. \n\n3)\tMain Contribution\n\nI think the design of a link function that allows to implement a data-dependent Beta-Bernoulli dropout is one of the keys of the paper and I would suggest that the author clearly state this contribution at the beginning of the paper. I would also like to see the application of this link-function to other sparsity inducing priors different than the Beta-Bernoulli. This would allow to further understand the data-dependent contribution to the final performance and how transferable this is to other settings. Also, Have the authors try to train the data-dependent Beta-Bernoulli from scratch, i.e. without the two steps approach? I am assuming the performance is worse, but I would publish the results for completeness.\n\n4)\tExperiments\n\nThe main issues with the experimental section are:\na)\tI am missing some recent methods (some of them even cited in the related work section): e.g. Louizos et al. (2017). I would be interested in comparisons against the horshoe-prior and a data-dependent version of it. Also, a recent paper based on the variational information bottleneck have been recently published outperforming the state of the art in the field (http://proceedings.mlr.press/v80/dai18d.html).\nb)\tTable 1 should report the variance or other uncertainty measure: Given that they run the experiments 5 times, I do not understand why they only report the median. I would encourage the authors to publish the mean and the variance (at least).\nIn addition, one of my main question about the method is, once the network has been sparsified, how does this translate into a real performance improvement (in terms of memory and speed). In term of memory, you can always apply a standard compression algorithm. If the sparsity is about a certain threshold, you can resort to sparse-matrix implementations. However, regarding the speed only when you reach a certain sparsity level you would get a tangible improvement if your DL framework support sparse matrices. However, if you get an sparsity level below this threshold, e.g. 20%, you cannot resort to sparse matrices and therefore you would not get a speed improvement, unless you enforce structure sparsity or you optimize to low-level matrix multiplication routines. Are the Speedup/Memory results reported in Table 1 real or theoretical?\n\n', 'This work proposes Variational Beta-Bernoulli Dropout, a Bayesian way to sparsify neural networks by adopting Spike and Slab priors over the parameters of the network. Motivated by the Indian Buffet Process the authors further adopt Beta hyperpriors for the parameters of the Bernoulli distribution and also propose a way to set up the model such that it allows for input specific priors over the Bernoulli distributions. They then provide the necessary details for their variational approximations to the posterior distributions of both such models and experimentally validate their performance on the tasks of MNIST and CIFAR 10/100 classification.\n\nThis work is in general well written and conveys the main ideas in an clear manner. Furthermore, parametrising conditional group sparsity in a Bayesian way is also an interesting venue for research that can further facilitate for computational speedups for neural networks. The overall method seems simple to implement and doesn’t introduce too many extra learnable parameters.\n\nNevertheless, I believe that this paper needs more work in order to be published. More specifically:\n\n- I believe that the authors need to further elaborate and compare with “Generalized Dropout”; the prior imposed on the weights for the non-dependent case is essentially the same with only small differences in the approximate posterior. Both methods seem to optimise, rather than integrate over, the weights of the network and the main difference is in how to handle the approximate distributions over the gates. Why would one prefer one parametrisation rather than the other? Furthermore, the authors of this work argue that they employ asymptotically unbiased gradients for the binary random variables, which is incorrect as the continuous relaxation provides a biased gradient estimator for the underlying discrete model.\n\n- At section 3.2 the authors argue about the inherent sparsity inducing nature of the IBP model. In the finite K scenario this is not entirely the case as sparsity is only encouraged for alpha < K.\n\n- At Eq. 11 the index “n” doesn’t make sense as the Bernoulli probability for each point depends only on the global pi_k. Similarly for Eq. 12.\n\n- Since you tie q(z_nk|pi_k) = p(z_nk|pi_k) then it makes sense to phrase Eq.16 as just D_KL(q(pi) || p(pi)). Furthermore, I believe that you should properly motivate on why tying these two is a sensible thing to do.\n\n- Figure 1 is misleading; you start from a unimodal distribution and then you simply apply a scalar scale and shift to the elements of that distribution. The output of that will always be a unimodal distribution but somehow you end up with a multimodal distribution on the third part of the figure. As a result, I believe that in this case you will not have two clear modes (one at 0 and one at 1) when you apply the hard-sigmoid rectification.\n\n- The motivation for 21 seems a bit confusing to me; what do you mean with insignificant dimensions? What overflow does the epsilon prevent? If the input to the hard sigmoid is a N(0, 1) distribution then you will approximately have 1/3 of the activations having probability close to 1. Furthermore, it seems that you want beta to be small / negative to get sparse outcomes but the text implies that you want it to be large.\n\n- It would be better to rewrite eq. 22 to include also the fact that you have a separate z per layer as currently it seems that the there is only one z. Furthermore, you have written that the variational posterior distribution depends on x_n on the RHS but not on the LHS.\n\n- Above eq. 23 seems that it should be q(z_nk| pi_k, xn) = p(z_nk| pi_k, xn) rather than q(z_nk| pi_k) = p(z_nk| pi_k, xn)\n\n\nRegarding the experiments; the MNIST results are not particularly convincing as the numbers are, in general, similar to other methods. Furthermore, Figure 2 is a bit small and confusing to read. Should FLOPS be on the y-axis or something else? Almost zero flops for the original model doesn’t seem right. Finally, at the CIFAR 10/100 experiment it seems that both BB and DBB achieve the best performance. However, it seems that the accuracy /sparsity obtained for the baselines is inferior to the results obtained on each of the respective papers. For example, SBP managed to get a 2.71x speedup with the VGG on CIFAR 10 and an error of 7.5%, whereas here the error was 8.68% with just 1.34x speedup. The extra visualisations provided at Figure 3 do look interesting though as it shows what the sparsity patterns learn.', ""The authors propose a dropout method that uses the beta-Bernoulli process to learn the sparsity rate for each node. \n\nThe model itself make sense to me, though I don't have an understanding of why learning a node-specific sparsity rate should improve dropout -- i.e., what is there to learn? From what I understand about dropout, it's a stochastic method that has the same marginal as the original model, but because of the randomness induced it avoids bad local optimal solutions. Thus it's a learning trick, not a modeling technique. This treats dropout as something to directly model.\n\nMy confusion is mainly about inference. While there are many approximations introduced to make it work, if the sparsity z is something to be learned then why is it only being sampled from the beta prior in (15)? There is a likelihood term that incorporates z as well and it seems like this should be included as well to be strictly correct from a modeling standpoint. I didn't see any explanation in the discussion.""]","[20, -20, -20]","[60, 60, 50]","[""Sentiment score: The review starts with a generally positive tone, acknowledging the authors' contributions and the paper being well-written. However, it also points out several areas for improvement and missing experiments, which balances out the positive aspects. The overall sentiment leans slightly positive, hence a score of 20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would suggest' and 'I would encourage' when giving recommendations, which is polite. The critique is constructive and focuses on the work rather than the authors. There are no rude or harsh statements. However, the review is not overly effusive in its praise, maintaining a more neutral professional tone, so it doesn't reach the highest levels of politeness. Therefore, a score of 60 seems appropriate."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('well written', 'conveys the main ideas in a clear manner', 'interesting venue for research'), they ultimately state that 'this paper needs more work in order to be published' and provide a long list of criticisms and areas for improvement. This indicates an overall negative sentiment towards the current state of the paper. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms as suggestions or areas for clarification rather than direct attacks. They use phrases like 'I believe that...' and 'It would be better to...' which maintain a polite tone while still conveying critical feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the model 'makes sense', they express confusion about the reasoning behind the approach and have questions about the inference process. The reviewer seems skeptical about treating dropout as something to directly model. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing their concerns as personal confusion rather than direct criticism. They use phrases like 'My confusion is mainly about...' and 'I don't have an understanding of why...' which maintain a polite tone while expressing their doubts and questions.""]"
"['In this paper, the authors introduce a sampling strategy that aims to combine the benefits of with- and without-replacement SGD. With-replacement strategies add more randomness to the process, which the authors claim helps convergence, while the without-replacement strategies ensure equal usage of all datapoints. The authors present numerical results showing better convergence and improved final accuracy. While I found the idea appealing, I felt that the paper needs more work before it can be published. I detail some of my primary concerns below:\n\n- The entire motivation of the paper is predicated on the hypothesis that more randomness is better for training. This is not generally true. Past work has shown that specific kinds of random noise aid convergence through exploration/saddle point avoidance/escaping spurious minima while others either make no change, or hurt. Noise from sampling tends to be a structured noise that aids exploration/convergence over batch gradient descent, but it is not immediately clear to me why the choice between with- and without-replacement should imply exploration. \n\n- Maybe it\'s obvious but I\'m not grasping why, mathematically, the number of accessible configurations for SRS is the same as original replacement sampling (4th paragraph on page 3).\n\n- Given that the central motivation of the work was to enable with-replacement strategies while still ensuring equal usage, I recommend that the authors include a histogram of datapoint usage for three strategies (with, without, hybrid). This should help convince the reader that the SRS indeed improves upon the usage statistics of with replacement. \n\n- If one were to create a hybrid sampling strategy, one that is natural is doing 50-50 sampling with and without replacement. In other words, for a batch size of 64, say, 32 are sampled with replacement and 32 without. By changing the ratio, you can also control what end of the sampling spectrum you want to be on. Did you try such a strategy? \n\n- For the numerical experiments, as I see it, there are 3 differences between the SRS setup and the baseline: location of batch normalization, learning rate, and batch size. The authors show (at the bottom of Page 6) that the performance boost does not come from learning rate or mini-batch size, but what about the placement of the BN layer? Seems like that still remains as a confounding factor?\n\n- ""SRS leads to much more fluctuations, and hence significantly more covariate shift"". How do the authors define covariate shift? Can the authors substantiate this claim theoretically/empirically?\n\n- The authors claim that the method works better when the dataset size is low compared to number of classes. Again, can the authors substantiate this claim theoretically/empirically? Maybe you can try running a sub-sampled version of CIFAR-10/100 with the baselines?\n\n- The writing in the paper needs improving. A few sample phrases that need editing: ""smaller mini-batch means a larger approximation"", ""more accessible configurations of mini-batches"", ""hence more exploration-induction"", ""less optimal local minimum""\n\n- Minor comment: why is the queue filled with repeated samples? In Figure 1, why not have the system initialized with 1 2 3 in the pool and 4 5 in the queue? Seems like by repeating, there is an unnecessary bias towards those datapoints.  ', 'This paper constructs a very simple, new scheme for sampling mini-batches. It aims to (i) achieve the noise properties of sampling with replacement while (ii) reduce the probability of not touching a sample in a given epoch. The result is a biased sampling scheme called “sequenced-replacement sampling (SRS)”. Experimental results show that this scheme performs significantly better than a standard baseline on CIFAR-100 with minor improvements on CIFAR-10. \n\nThis is a highly empirical paper that presents a simple and sound method for mini-batch sampling with impressive results on CIFAR-100. It however needs more thorough analysis or experiments that validate the ideas as also experiments on harder, large-scale datasets.\n\nDetailed comments:\n\n1. The authors are motivated by the exploration properties of sampling with replacement which I find quite vague. For instance, https://arxiv.org/abs/1710.11029 , https://arxiv.org/abs/1705.07562 etc. show that sampling mini-batches with replacement has a large variance than sampling without replacement and consequently SGD has better regularization properties. Also, for mini-batches sampled with replacement, the probability of not sampling a given sample across an epoch is very small.\n\n2. I believe the sampling scheme is unnecessarily complicated. Why not draw samples with replacement with a probability p and draw samples without replacement with a probability 1-p? Do the experimental results remain consistent with this more natural sampling scheme which also aligns with the motivations of the authors?\n\n3. To validate the claim that SRS works well when there are fewer examples per class, can you do ablation experiments on CIFAR-10 or ImageNet/restricted subset of it?', ""The paper suggests a new way of sampling mini-batches for training deep neural nets. The idea is to first index the samples then select the batches during training in a sequential way. The proposed method is tested on the CIFAR dataset and some improvement on the classification accuracy is reported.\n\nI find the idea interesting but feel that much more is needed in order to have a better understanding of how the proposed method works, when it works and when it doesn't work. Some theoretical insight, or at least a more systematic experimental study, is needed to justify the proposed method.  ""]","[-50, 50, -20]","[50, 75, 50]","[""The sentiment score is -50 because while the reviewer found the idea 'appealing', they state that 'the paper needs more work before it can be published' and list several significant concerns and criticisms. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses polite language throughout, such as 'I found the idea appealing' and 'I recommend that the authors...', while also providing constructive criticism. They avoid harsh or rude language, instead framing their concerns as suggestions or questions. The reviewer maintains a professional and respectful tone while still clearly communicating their reservations about the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'impressive results' and describes it as 'simple and sound', but also points out areas for improvement and requests more thorough analysis. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or requests rather than demands. The reviewer also balances positive comments with areas for improvement, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea 'interesting', they express that 'much more is needed' and that 'theoretical insight' or 'a more systematic experimental study' is required. This suggests that the reviewer is not fully satisfied with the current state of the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work while providing constructive criticism. They use phrases like 'I find the idea interesting' and 'Some theoretical insight... is needed' which maintain a professional and courteous tone while expressing their concerns.""]"
"['The paper introduces a new approach to combine small RBMs that are pretrained in order to obtain a large RBM with good performance. This will bypass the need of training large RBMs and suggests to break them into smaller ones. The paper then provides experimental evidence by applying the method on ""invertible boolean logic"". MCMC is used to find the the solution to large RBM and compare it against the combined solutions of smaller RBMs.\n\n\nThe paper motivates the problem well, however, it is not well-written and at times it is hard to follow. The details of the approach is not entirely clear and no theoritcal results are provided to support the approach. For instance, in the introduced approach, only an example of combination is provided in Figure 1. It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model. From the experimental perspective, the experimental evidence on ""invertible boolean logic"" does not seem to be very convincing for validating the approach. Additionally, the details of the settings of the experiments are not fully discussed. For example, what are the atomic/smaller problems and associated RBMs? what is the larger problem and how is the corresponding RBM obtained? Overall, the paper seems to be a report consisting of a few interesting observations rather than introducing a solid and novel contribution with theoretical guarantees.\n\nRemark: \nThe term ""Combinatorial optimization"", which is used in the title and throughout the body of paper, sounds a bit confusing to the reviwer. This term is typically used in other contexts.\n\nTypos:\n** Page 2 -- Paragraph 2: ""Therefore, methods than can exploit...""\n** Page 3 -- 2nd line of math: Super-scripts are missing for some entries of the matrices W^A and W^{A+B}\n** Page 5 -- Last paragraph: ""...merged logical units is more likly to get get stuck in a ...""\n** Page 5 -- Last paragraph: ""...and combining their distributions using the mulistart heuristic...""\n', 'The paper proposes learning Restricted Boltzmann Machines for solving small computational tasks (e.g., 1-bit addition) and composing those RBMs to form a more complex computational module (e.g., 16-bit addition). The claim is that such an approach can be more data efficient than learning a single network to directly learn the more complex module. Results are shown for addition and factoring tasks.\n\n- The paper is somewhat easy to follow and the figures are helpful. But the overall organization and flow of ideas can be improved significantly.\n- The term ""combinatorial optimization"" is used in a confusing way -- addition would not usually be called a combinatorial optimization problem.\n- It would be good to understand what benefit does the stochasticity of RBMs provide. How do deterministic neural networks perform on the addition and factoring tasks? The choice of RBMs is not motivated well and without any comparisons to alternatives, it comes across as arbitrary.\n- That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.  After all, the former approach gets a lot more knowledge about the target function built into it. It\'s good that the paper empirically confirms the intuition, but doesn\'t feel like a significant contribution on its own.\n- The paper would be stronger if it includes more complex tasks, e.g., TSP, and show that the same ideas can be applied to improve the learning a solver for such tasks. The current tasks and problem sizes are not very convincing, and the accuracy results are not very compelling.', 'The paper proposes to combine several smaller, pretrained RBMs into a larger model as a way to solve combinatorial optimization problems. Results are presented on RBMs trained to implement binary addition, multiplication, and factorization, where the proposed approach is compared with the baseline of training a full model from scratch.\n\nI found the paper confusing at times. It is well-written from a syntactical and grammatical point of view, but some key concepts are stated without being explained, which gives the impression that the authors have a clear understanding of the material presented in the paper but communicate only part of the full picture to the reader.\n\nFor instance, there’s a brief exposition of the connection between Boltzmann machines and combinatorial optimization problems: the latter is mapped onto the former by expressing constraints as a fixed set of Boltzmann machine weights and biases, and low-energy states (i.e. more optimal solutions) are found by sampling from the model, which involves no training. What’s less clear to me is what kinds of combinatorial optimization problems can be mapped onto the RBM *training* problem. The paper states that the problem of training ""large modules"" is ""equivalent to solving the optimization problem"", but does not explain how.\n\nSimilarly, the paper mentions that the ""general approach to solving these combinatorial optimization problems is to recognize the atomic unit necessary to solve the problem"", but at that point the reader has no concrete example of what combinatorial optimization problem would be mapped onto training and inference in RBMS.\n\nA concrete example is provided in the Experiments section: the authors propose to implement invertible (reversible?) boolean logic circuits by combining smaller pre-trained RBMs which implement certain logical operations into larger circuits. I have two issues with the chosen example: 1) the connection with combinatorial optimization is not clear to me, and 2) it’s not very well explained. As far as I understand, these reversible boolean logic operations are expressed as sampling a subset of the RBM’s inputs conditioned on another subset of its inputs. An example is presented in Figure 3 but is not expanded upon in the main text. I’d like the authors to validate my understanding:\n\nAn RBM is trained to implement a complete binary adder circuit by having it model the joint distribution of the adder’s inputs and outputs [A, B, Cin, S, Cout] (A is the first input bit, B is the second input bit, Cin is the input carry bit, S is the output sum bit, and Cout is the output carry bit), where (I assume) the distribution over [A, B, Cin] is uniform, and where S and Cout follow deterministically from [A, B, Cin]. After training, the output of the circuit is computed from [A, B, Cin] by clamping [A, B, Cin] and sampling [S, Cout] given [A, B, Cin] using Gibbs sampling.\n\nThe alternative to this, which is examined in the paper, is to train individual XOR, AND, and OR gates in the same way and compose them into a complete binary adder circuit as prescribed by Section 3.\n\nI think the paper has the potential to be a lot more transparent to the reader in explaining these concepts, which would avoid them spending quite a bit of time inferring meaning from figures.\n\nI’m also confused by the presentation of the results. For instance, I don’t know what ""log"", ""FA1"", ""FA2"", etc. refer to in Figure 6. Also, Figure 6 is referenced in the text in the context of binary multiplication (""[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6""), but presents results for addition and factorization only.\n\nThe way I see it, implementing reversible boolean logic circuits using RBMs is an artificial problem, and the key idea of the paper -- which I find interesting -- is that in some cases it appears to be possible to combine RBMs trained for sub-problems into larger RBMs without needing to fine-tune the model. I think there are interesting large-scale applications of this, such as building an autoregressive RBM for image generation by training a smaller RBM on a more restricted inpainting task. The connection to combinatorial optimization, however, is much less clear to me.']","[-30, -40, -20]","[20, 20, 60]","[""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper such as it being 'not well-written', 'hard to follow', lacking theoretical results, and having unconvincing experimental evidence. However, it's not entirely negative as it acknowledges that the paper 'motivates the problem well' and contains 'interesting observations'. The politeness score is 20 because while the reviewer is critical, they use relatively polite language such as 'it is not clear' and 'does not seem to be very convincing' rather than harsh or rude phrasing. They also offer constructive feedback and point out typos, which is helpful. The reviewer maintains a professional tone throughout, even when expressing criticism."", ""The sentiment score is -40 because the review is generally critical, pointing out several weaknesses in the paper. The reviewer notes issues with organization, confusing terminology, lack of motivation for using RBMs, and the limited scope and impact of the work. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the paper being somewhat easy to follow and having helpful figures. The politeness score is 20 because the language used is professional and constructive, offering specific suggestions for improvement without being harsh. The reviewer uses phrases like 'It would be good to understand' and 'The paper would be stronger if' which are polite ways of pointing out areas for improvement. The tone is critical but not rude, maintaining a respectful approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper's core idea interesting, they express confusion and criticism about several aspects of the paper. They mention the paper is 'confusing at times', lacks clear explanations of key concepts, and has issues with the presentation of results. However, they also acknowledge the paper's potential and find the main idea interesting, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths (e.g., 'well-written from a syntactical and grammatical point of view'), and frames criticisms constructively (e.g., 'I think the paper has the potential to be a lot more transparent'). The reviewer also uses phrases like 'I'd like the authors to validate my understanding', which shows a collaborative approach rather than harsh criticism.""]"
"['The paper presents an intuitive architecture for learning cross-lingual sentence representations. I see weaknesses and strengths: \n\n(i) The approach is not very novel. Using parallel data and similarity training (siamese, adversarial, etc.) to facilitate transfer has been done before; see [0] and references therein. Sharing encoder parameters across very different tasks is also pretty standard by now, going back to [1] or so. \n(ii) The evaluation is strong, with a nice combination of standard benchmark evaluation, downstream evaluation, and analysis. \n(iii) While the paper is on cross-lingual transfer, the authors only experiment with a small set of high-resource languages, where transfer is relatively easy. \n(iv) I think the datasets used for evaluation are somewhat suboptimal, e.g.: \na) Cross-lingual retrieval and multi-lingual STS are very similar tasks. Other tasks using sentence representations and for which multilingual corpora are available, include discourse parsing, support identification for QA, extractive summarization, stance detection, etc. \nb) Instead of relying on Agic and Schluter (2017), why don’t the authors use the XNLI corpus [2]?\nc) Translating the English STS data using Google NMT to evaluate an architecture that looks a lot like Google NMT sounds a suspicious. \n(v) While I found the experiment with eigen-similarity a nice contribution, there is a lot of alternatives: seeing whether there is a linear transformation from one language to another (using Procrustes, for example), seeing whether the sentence graphs can be aligned using GANs based only on JSD divergence, looking at the geometry of these representations, etc. Did you think about doing the same analysis on the representations learned without the translation task, but using target language training data for the tasks instead? The question would be whether there exists a linear transformation from the sentence graph learned for English while doing NLI, to the sentence graph learned for German while doing NLI. \n\nMinor comments: \n- “Table 3” on page 5 should be Table 2. \n- Table 2 seems unnecessary. Since the results are not interesting on their own, but simply a premise in the motivating argument, I would present these results in-text. \n\n[0] http://aclweb.org/anthology/W18-3023', 'Summary\n----------\nIn this paper, authors explore learning of cross-lingual sentence representations with their proposed dual-encoder model. Evaluation conducted with learned cross-lingual representations on several tasks such as monolingual, cross-lingual, and zero-shot/few-shot learning show the effectiveness of the proposed approach. Also, they show provide a graph-based analysis of the learned representations.\n\nThree positive and negative points of the paper is presented as follows:\n\npros\n------\n\n1. cross-lingual representation learning by combinining ideas from learning sentence representations and cross-language retrieval.\n2. Multi-task setup of different tasks for improving cross-language and monolingual tasks.\n3. Lot of experimental results.\n\n\ncons\n-----\n1. Claim it works for monolignual tasks in target language such as zero-shot learning for sentiment classification and NLI. Also, for cross-lingual STS and eigen-similarity metric is hard to retrieve from the paper.\n\n2. Many terms, datasets are used without being referenced.\n\n3. Usage of existing approaches to build a single model for many tasks.\n\ncomments to authors\n-----------------------\n\n\n1. Dual-encoder architecture is inspired from Guo et al (2018) which uses encoding of source and target sentence with Deep neural network. However, it is here replaced into multi-task dual-encoder model.\n\n2. What are the tasks that are very specific to source language? \n\n3. Equation-1 is basically a logistic regression or softmax over \\phi. However \\phi is dot product of encodings as similar to Deep averaging networks (Iyyer et al. 2015) ?\n\n4. In Section-2, it is unclear what does symmetric tasks mean? They use parallel corpora?\n\n5. In Section-2.1, it is mentioned that Word embeddings are learned end-to-end. Does this mean they are not initialized with pretrained ones?\n\n6. In Section-2.1, it is mentioned that word and character embeddings are learned in a computationally efficient way, what does it represent? They use less parameters, parallelizable?\n\n7. Why only three layers of transformer, It is understood that 6-12 layers is required for effective encoding of sentences (Al-Rfou et al., 2018)\n\n8. In model configuration, how is convergence decided. Any stopping criterion?\n\n9. What are the splits for reddit, wikipedia datasets?\n\n10. In Table-1, what does MR,CR etc., refer to? They are never mentioned before. Does all tasks only use only English ?\n\n\n\nOverall it is an interesting paper which explores multi-task model for simultaneously improving both monolingual and cross-lingual tasks. However, due to missing information and lacking clarity in some details it is hard to accept at this point of time.\n\nMinor issues\n--------------\n\n1. Sentences are very long and not easily comprehensible.\n2. Target language and repsonse are used without referencing each other. Better to use one of them for better tracking.\n3. No common notation for the model. It is been referenced with different names (cross-lingual multi-task model, multi-task dual-encoder model).', 'This paper proposes a novel cross-lingual multi-tasking framework based on a dual-encoder model that can learn cross-lingual sentence representations which are useful in monolingual tasks and cross-lingual tasks for both languages involved in the training, as observed on the experiments for three language pairs. The main idea of the approach is to model all tasks as input-response ranking tasks and introduce cross-lingual representation tying through the translation ranking task, introduced by Guo et al. (2018). All components of the framework are quite standard and deja-vu, but I like the paper in general, and the results seem quite encouraging. I have several comments on how to further strengthen the paper and improve the presentation of the main findings.\n\nThe proposed framework does not offer any substantial modeling contribution (i.e., all major components are based on SOTA models), but the framework is still quite interesting as a mixture of these SOTA components. I believe that some additional experiments would make the main contributions clearer and would also provide additional insights into the main properties of the proposed framework: 1) cross-linguality and 2) multi-tasking. \n\n*Most of all, I am surprised not to see any ablation studies. For instance, what happens if we remove one of the two monolingual tasks in each language? How does that reduced model compare to the full model? Which monolingual task is more beneficial for the final performance in downstream tasks? Can we think of adding another monolingual task to boost performance further? I think that this sort of experiment would be more beneficial for the paper than a pretty long analysis from Section 5 (this analysis is still valid, but should be shortened substantially). Evaluating only multi-tasking without any cross-lingual training would also be very beneficial to recognise the extent of improvement achieved by adding cross-linguality to the model.\n\n*How much does the proposed architecture depend on the choice of the encoding model for the function g? Have the authors experimented with other (recent and (near-)SOTA) encoding models? I would like to see a comparative analysis of this \'hyper-parameter\'.\n\n*I would like to see more experiments on more distant language pairs. This would make the paper even more interesting imho. I am also curious whether there would be a drop in performance reported conditioned on the distance/proximity between two languages in a language pair.\n\n*I would like to see a more detailed description of the two best performing STS systems (ECNU and BIT). In what respect are these systems state-of-the-art feature engineered and mixed? I am not sure what this means without providing any additional context to the claim and description.\n\n*How does the monolingual English STS model trained with the cross-lingual multi-task framework compare to the work of Conneau et al. (EMNLP 2017) which also used SNLI as the task on which to learn universal sentence representations. This would be a good experiment imho as it would show how much we gain from cross-lingual training and multi-tasking.\n\nMinor:\n*Page 3: Could you add a short footnote discussing how hard-negatives for the translation ranking task are selected? How do you compute similarity here?\n*Do you expect performance to improve further by training MultiNLI instead of SNLI (or combining the two datasets)?\n*""All hyperparameters are tuned based on preliminary experiments on a development set."" -> What is used as the development set? More details needed.\n*""Finally, as an additional training heuristic, we multiply the gradients to the word and character embeddings by a factor of 100."" -> How is the value for the embedding gradient multiplier determined? Is there an automatic procedure to fine-tune this hyper-parameter or has this been done in a completely empirical way?\n*Table 1: please define the task abbreviations before showing them in the table. It is not clear what each task is by relying only on the abbreviation.\n*This dataset was not available at the time of the submission, but for the revision it would make sense to also evaluate on the new XNLI dataset of Conneau et al. (EMNLP 2018) for multilingual NLI experiments.\n\n(After the first revision) I have raised the score after the very detailed author response (thanks for that!), but this is also conditioned on the authors making the actual revisions promised in their response. I am still quite interested to check how well the method works in a setup with distant language pairs.']","[-20, -20, 60]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they point out several significant weaknesses and limitations. The reviewer notes issues with novelty, limited language scope, and suboptimal dataset choices. However, they do praise the strong evaluation and some interesting analyses. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I see weaknesses and strengths' and 'I think', which soften criticism. They also offer specific suggestions for improvement and alternative approaches, demonstrating engagement with the work rather than dismissive criticism. The language is not overly formal or deferential, but it remains respectful and focused on the content of the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting paper', 'lot of experimental results'), they also highlight several significant concerns and state it's 'hard to accept at this point of time'. The overall tone suggests more improvements are needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and frames negative points as suggestions for improvement rather than harsh criticisms. They use phrases like 'it is unclear' and 'better to use' instead of more confrontational language. The review maintains a professional tone while clearly communicating areas for improvement."", ""The sentiment score is 60 (moderately positive) because the reviewer states they 'like the paper in general' and finds the results 'quite encouraging', despite noting the lack of substantial modeling contribution. The overall tone is constructive and interested. The politeness score is 80 (quite polite) due to the reviewer's respectful language, use of phrases like 'I believe' and 'I would like to see', and offering specific suggestions for improvement rather than harsh criticism. The reviewer also acknowledges the authors' efforts in the revision, thanking them for their detailed response. The language throughout is professional and courteous, focusing on the work rather than personal judgments.""]"
"['\nSummary:\nThe authors present a video prediction model called SAVP that combines a Variational Auto-Encoder (VAE) model with a Generative Adversarial Network (GAN) to produce more realistic and diverse future samples.\n\nDeterministic models and certain loss functions such as Mean Squared Error (MSE) will produce \nblurry results when making uncertain predictions. GAN predictions on the other hand usually are more visually appealing but often lack diversity, producing just a few modes. The authors propose to combine a VAE model with a GAN objective to combine their strengths: good quality samples (GAN) that cover multiple possible futures (VAE).\n\nStrengths:\n[+] GANs are notoriously unstable to train, especially for video. The authors formulate a VAE-GAN model and successfully implement it.\n\nWeaknesses:\n[-] The combination of VAEs and GANs, while new for videos, had already been proposed for image generation as indicated in the Related Work section and its formulation for video prediction is relatively straightforward given existing VAE (Denton & Fergus 2018) and GAN models (Tulyakov et al. 2018).\n\n[-] The results indicate that SAVP offers a trade-off between the properties of GANs and VAEs, but does not go beyond its individual parts. For example, the experiment of Figure 5 does not show SAVP being significantly more diverse than GANs for KTH (as compared to VAEs). Furthermore, Figure 6 and Figure 7 in general show SAVP performing worse than SVG (Denton & Fergus 2018), a VAE model with a significantly less complex generator, including for the metric (VGG cosine similarity) that the authors introduce arguing that PSNR and SSIM do not necessarily indicate prediction quality.\n\nWhile the use of a GAN in general will make the results less blurry and visually appealing, it does not necessarily mean that the samples it generates are going to be plausible or better. Since a direct application of video prediction is model-based planning, it seems that plausibility might be as important as sample quality. This work proposes to combine VAEs and GANs in a single model to get the benefits of both models. However, the experiments conducted generally show that SAVP offers only a trade-off between the visual quality of GANs and the coverage of VAEs, and does not show a clear advantage over current VAE models (Denton & Fergus, 2018) that with simpler architectures obtain similar results. While the presentation is clear and the evaluation of the model is thorough, I am unsure of the significance of the proposed method.\n\nIn order to better assess this model and compare it to its individual parts and other VAE models, could the authors:\n\n1) Compare SAVP to the SVG-LP/FP model on a controlled synthetic dataset such as Stochastic Moving MNIST (Denton & Fergus, 2018)?\n2) Comment on the plausibility of the samples generated by SAVP? Do some samples show imagined objects – implausible interactions for the robotic arm dataset? If so, what would be the advantage over blurry but plausible generations of a VAE?', 'This paper proposes to extend VAE-GAN from the static image generation setting to the video generation setting. It’s a well-written, simple paper that capitalizes on the trade-off between model realism and diversity, and the fact that VAEs and GANs (at least empirically) tend to lie on different sides of this spectrum.\n\nThe idea to extend the use of VAE-GANs to the video prediction setting is a pretty natural one and not especially novel. However, the effort to implement it successfully is commendable and will, I think, serve as a good reference for future work on video prediction. \n\nThere are also several interesting design choices that I think are worth of further exposition. Why, for example, did the authors only perform variational inference with the current and previous frames? Did conditioning on additional frames offer limited further improvement? Can the blurriness instead be attributable to the weak inference model? Please provide a response to these questions. If the authors have any ablation studies to back up their design choices, that would also be much appreciated, and will make this a more valuable paper for readers.\n\nI think Figure 5 is the most interesting figure in the paper. I would imagine that playing with the hyperparameters would allow one to traverse the trade-off between realism and diversity. I think having such a curve will help sell the paper as giving the practitioner the freedom to select their own preferred trade-off. \n\nI don’t understand the claim that “GANs prioritize matching joint distributions of pixels over per-pixel reconstruction” and its implication that VAEs do not prioritize joint distribution matching. VAEs prioritize matching joint distributions of pixels and latent space: min KL(q(z, x) || p(z, x)) and is a variational approximation of the problem min KL(q(x) || p(x)), where q(x) is the data distribution. The explanation provided by the authors is thus not sufficiently precise and I recommend the retraction of this claim.\n\nPros:\n+ Well-written\n+ Natural extension of VAE-GANs to video prediction setting\n+ Establishes a good baseline for future video prediction work\nCons:\n- Limited novelty\n- Limited analysis of model/architecture design choices', 'The paper introduces a generative model for video prediction. The originality stems from a new training criterion which combines a VAE and a GAN criteria. At training time, the GAN and the VAE are trained simultaneously with a shared generator; at test time, prediction conditioned on initial frames is performed by sampling from a latent distribution and generating the next frames via an enhanced conv LST . Evaluations are performed on two movement video datasets classically used for benchmarking  this task - several quantitative evaluation criteria are considered.\n\nThe paper clearly states the objective and provides a nice general description of the method.  The proposed model extends previous work by adding an adversarial loss to a VAE video prediction model.  The evaluation compares different variants of this model to two recent VAE baselines. A special emphasis is put on the quantitative evaluation: several criteria are introduced for characterizing different properties of the models with a focus on diversity. w.r.t. the baselines, the model behaves well for the “realistic” and “diversity” measures. The results are more mitigated for measures of accuracy. As for the qualitative evaluation, the model corrects the blurring effect of the reference SV2P baseline, and produces quite realistic predictions on these datasets. The difference with the other reference model (SVG) is less clear.\n\nWhile the general description of the model is clear, details are lacking. It would probably help to position the VAE component more precisely w.r.t. one of the two baselines, by indicating the differences. This would also help to explain the difference of performance/ behavior  w.r.t. these models (Fig. 5).\n\nIt seems that the discriminator takes a whole sequence as input, but some precision on how this done could be added.  Similarly, you did not indicate what the deterministic version of your model is.\nThe generator model with its warping component makes a strong hypothesis on the nature of the videos: it seems especially well suited for translations or for other simple geometric transformations characteristics of the benchmarking videos .  Could you comment on the importance of this component? Did you test the model on other types of videos where this hypothesis is less relevant? It seems that the baseline SVG makes use of simpler ConLSTM for example.\n\nThe description of the generator in the appendix is difficult to follow. I missed the point in the following sentence: “For each one-step prediction, the network has the freedom to choose to copy pixels from the previous frame, used transformed versions of the previous frame, or to synthesize pixels from scratch” .\nAlso, it is not clear from the discussion on z, whether sampling is performed once for each video of for each frame.\n\nOverall, the paper proposes an extension of VAE based video prediction models and produces an extensive evaluation. While the model seems to perform well, the originality and the improvement w.r.t. baselines are somewhat limited.\n']","[-30, 50, -20]","[60, 75, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they express significant doubts about the novelty and effectiveness of the proposed method. The review points out several weaknesses and suggests that the model doesn't show clear advantages over existing methods. The overall tone is skeptical but not entirely negative.\n\nThe politeness score is 60 because the reviewer uses professional and respectful language throughout. They acknowledge the strengths of the paper and frame their criticisms constructively. The reviewer also asks questions at the end to give the authors an opportunity to address concerns, which is a polite way of suggesting improvements. While critical, the tone remains courteous and objective, avoiding harsh or personal criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'well-written' and 'commendable', and sees it as a good reference for future work. However, they also point out limited novelty and analysis, balancing the positive aspects. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as requests rather than demands. They acknowledge the paper's strengths before discussing areas for improvement, and use phrases like 'I think' to soften critiques. The reviewer maintains a professional and courteous tone while providing detailed feedback."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., \'The paper clearly states the objective\', \'the model behaves well for the ""realistic"" and ""diversity"" measures\'), they also point out several limitations and areas for improvement. The overall tone suggests that the paper\'s contribution is somewhat limited (\'the originality and the improvement w.r.t. baselines are somewhat limited\'). The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions rather than direct attacks. They use phrases like \'It would probably help to...\' and \'Could you comment on...\' which maintain a polite and professional tone.']"
"['======== Summary ============\n\nThe authors consider a setup where there is a set of trajectories (s_t, a_t, r_t) where r_t is a *vector* of rewards. They assume that each agent is trying to maximize \\sum_t \\gamma^t (\\phi . r_t) where \\phi is a preference vector that lives on the simplex. Their goal is to calculate \\phi (and maybe also an optimal policy under \\phi?). The \n\nThe authors first prove that this problem can be decomposed into finding Q functions for optimal policies for each component of r_t individually, and then solving for \\phi that rationalizes the trajectory of actions in terms of these Q functions. Given the entire collection of trajectories, they perform off-policy Q-learning on each component of r_t in order to learn the Q function for that component, and then use linear programming to solve for \\phi based on these Q function.\n\n========== Comments =============\n\nI think it\'s a worthwhile direction to combine IRL with modeling a diversity of preferences among agents. I can imagine several reasons you might want to do this, but the authors are not clear what their goal is besides ""to propose methods that can help to understand the intricacy and complexity of human motivations and their behaviors"". Is the goal to do better policy prediction? To do better policy prediction conditional on \\phi? To infer \\phi to understand people\'s preferences from a social science perspective? These all seems reasonable but not sufficiently teased out in the work. (For comparison, IRL is typically - although not always - interested in learning the reward function in order to construct robust policies that maximize it). The authors also don\'t seem to solve a particular task of importance on the WoW dataset.\n\nThe theoretical approach seems sound, and I liked the way their algorithm was motivated and the way the problem was decomposed into off-policy Q-learning and then solving for \\phi.\n\nHowever, I found myself quite confused in the experimental section (4.3). The authors evaluate their approach by action prediction. Given the trajectories, is \\phi computed for each player and then compute actions based on that value of \\phi? Is \\phi computed on the same trajectory data used for evaluation or a different subset? Or is action prediction performed in aggregate across the entire population? The experimental setup was never clarified for this (main) experiment.\n\nI was also confused about the motivation for Figure 2 and Appendix D. The authors are showing that their predictions about which reward is motivating the players is consistent with external factors. But wouldn\'t you see the same thing if you just plotted the observed *rewards* themselves? E.g. players in a guild will achieve more Relationship reward. \nThe proposed approach takes the vector of reward, learns which actions are consistent with achieving each reward, then infers from the actions which reward is trying to be achieved. What advantages does this have vs. just looking at the empirical trajectory of rewards for each player/group?\nI can certainly imagine that the IRL approach has certain advantages over looking at the empirical reward stream, but the authors have not talked about this nor compared against it experimentally.\n\nThe writing could also use some improvement for a future iteration, I\'ve listed a few points below:\n\npg.1, Neither Brown & Sandholm nor Moravcik et al use ""RL algorithms""\npg.1, Finn et al unmatched )\npg.1, ""a scalar reward despite observed or not"" -> ""a scalar reward whether observed or not""\npg.2, ""Either the range of"" -> ""Both the range of"" (and this sentence needs further cleanup)\npg.2, ""which records the pathing of players"" ??\nTheorem 3: ""each of the set e_i has an unique element..."" This isn\'t clear. I think you mean ""For each e_i there is a unique vector v^\\pi(s) for all \\pi \\in \\Pi_{e_i} . The equality holds if these vectors are distinct for each e_i"".\npg. 5 ""If otherwise all elements in \\phi are generative"" how can they be negative if they are on the simplex?\npg.5 ""we do not perform any scalarization on the reward...the model assumption is easier to be satisfied"" I think this is a strange comparison to IRL because in IRL you\'re trying to find a (possibly parametric) function (s,a) -> R, whereas here you\'re *given* the vector R and are trying to find \\phi. So while you have more degrees of freedom by adding \\phi, you lose the original degrees of freedom in the reward function.\n\n', 'This paper presents NMBM, a general inverse reinforcement learning (IRL) model that considers multifaceted human motivations. The authors have motivated and proposed the algorithm (Section 2 and 3), and demonstrated some experiment results based on a real-world dataset (WoWAH, Section 4).\n\n-- Originality and Quality --\n\nTo the best of my knowledge, the proposed NMBM algorithm is new. However, I feel that the derivation of this algorithm is relatively straightforward based on existing literature. Specifically, this algorithm is based on (1) Theorem 3 and (2) the linear program defined in equation 9. My understanding is that both Theorem 3 and the derivation of the linear program in equation 9 are relatively straightforward based on existing literature.\n\nOn the other hand, the experiment results in Section 4 are very strong and interesting. It is the main strength of this paper.\n\n-- Clarity --\n\nMy understanding is that the writing of Section 3 and 4 can be (and should be) further polished.\n\nSome key notations in the paper seem to be wrong:\n\n(1) In Theorem 3, how can the value function v^\\pi(s) be in the convex hull of policies? Also, e_i is not a set.\n\n(2) In equation 9, the linear program, \\eta should be another decision variable. \n\n-- Pros and Cons --\n\nPros:\n\n1) Strong experiments.\n\nCons:\n\n1) Insufficient novelty for algorithm design.\n\n2) No performance analysis for the proposed algorithm.\n\n3) Clarity needs to be further improved.', ""This paper studies inverse reinforcement learning with a vector-valued setting. A key motivation of the paper, as suggested by its title, is to incorporate and analyze the complex human motivations.\n\nThe proposed setting seems new to me, although vectored-valued rewards and Pareto optimality have been studied in the context of RL. The biggest issue of this paper, in my opinion, is it doesn't properly support its claim that it improves the understanding of the agents' motivations and the reward functions. Details comments / questions are listed below.\n\n- Pareto dominance is a rather weak relation. When the number of criteria increases, it is less likely one alternative dominates another. In this case, the binary comparisons defined in Sec. 2.1 becomes less discriminative. Is this a problem to the proposed method?\n\n- Pareto dominance and vector-valued rewards have been studied in preference-based reinforcement learning, such as Fürnkranz et al. 2012 @ MLJ and Cheng et al. 2011 @ ECML. \n\n- Please fix the citation style in the paper and use \\citep and \\citet properly. \n\n- The empirical study in this paper doesn't properly support the authors' claim. (1) It's questionable to assume the actions of a player in an online game are optimal or even rational. (2) The results presented in Figure 2 is hard to read and the differences look minor. (3) Maybe I miss it, but has Table 2 been referenced and explained in the paper?""]","[-20, -20, -30]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'worthwhile' and 'sound' in some aspects, they express significant confusion about the experimental section and raise several critical points about the motivation, clarity, and comparative advantages of the approach. The reviewer also lists multiple areas for improvement in writing and presentation.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think it's a worthwhile direction' and 'I liked the way their algorithm was motivated', which show appreciation for aspects of the work. Even when expressing criticism, the reviewer uses polite language such as 'I found myself quite confused' and 'The writing could also use some improvement', rather than using harsh or dismissive language. The reviewer also offers specific suggestions for improvement, which is a courteous approach in academic review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper (strong experiments), they also point out several significant weaknesses. The reviewer expresses concerns about insufficient novelty in algorithm design, lack of performance analysis, and clarity issues. The overall tone suggests that the paper needs substantial improvements.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'To the best of my knowledge' and 'My understanding is that,' which show consideration for the authors' perspective. The reviewer also balances criticism with positive feedback, acknowledging the paper's strengths alongside its weaknesses. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral, matter-of-fact tone in most of its critiques."", ""The sentiment score is -30 because while the reviewer acknowledges the novelty of the paper's approach ('The proposed setting seems new to me'), they express significant concerns about the paper's main claims and empirical study. The reviewer states 'The biggest issue of this paper, in my opinion, is it doesn't properly support its claim that it improves the understanding of the agents' motivations and the reward functions.' This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct attacks. For example, 'Is this a problem to the proposed method?' and 'Please fix the citation style' are polite ways of pointing out potential issues. The reviewer also acknowledges positive aspects before critiquing, which is a polite approach. However, the language is not overly formal or deferential, hence a score of 50 rather than higher.""]"
"['Main contribution: devising and evaluating a theoretically-sound algorithm for quantifying the semantic similarity between two pieces of text (e.g., two sentences), given pre-trained word embeddings (glove).\n\nClarity:\nThe paper is generally well-written, but I would have liked to see more details regarding the motivation for the work, description of the prior work and discussion of the results. As an example, I could not understand what were the differences between the online and offline settings, with only a reference to the (Arora et al. 2016) paper that does not contain neither ""online"" nor ""offline"". The mathematical derivations are detailed, which is nice.\n\nOriginality:\nThe work looks original. It proposes a method for quantifying semantic similarity that does not rely on cosine similarity.\n\nSignificance:\nI should start by saying I am not a great reviewer for this paper. I am not familiar with the STS dataset and don\'t have the mathematical background to fully understand the author\'s algorithm.\nI like to see theoretical work in a field that desperately needs some, but overall I feel the paper could do a much better job at explaining the motivation behind the work, which is limited to ""cosine similarity [...] is not backed by a solid theoretical foundation"".\nI am not convinced of the practicality of the algorithm either: the algorithm seems to improve slightly over the compared approaches (and it is unclear if the differences are significant), and only in some settings. The approach needs to remove stop-words, which is reminiscent of good old feature engineering. Finally, the paper claims better average time complexity than some other methods, but discussing whether the algorithm is faster for common ranges of d (the word embedding dimension) would also have been interesting.\n', ""The authors propose a probabilistic model for computing the sentence similarity between two sets of representations in an online fashion (that is, they do not need to see the entire dataset at once as SIF does when using PCA). They evaluate on the STS tasks and outperform competitive baselines like WMD, averaging embeddings, and SIF (without PCA), but they have worse performance that SIF + PCA.\n\nThe paper is clearly written and their model is carefully laid out along with their derivation. My concern with this paper however, is that I feel the paper lacks a motivation, was it derive an online similarity metric that outperforms SIF(without PCA)?\n\nA few experimental questions/comments:\n\nWhat happens to all methods when stop words are not removed? How far does performance fall? I think one reason it might fall (in addition to the reasons given in the paper) is that all vectors are set to have the same norm. For STS tasks, often the norms of these vectors are reduced during training which lessens their influence. What mechanism was used to identify the stop words and does removing these help the other methods (I know in the paper, stop words were removed in the baseline, did this unilaterally improve performance for these methods)?\n\nOverall I do like the paper, however I do find the results to be lackluster. There are many papers on combining word embeddings trained in various ways that have much stronger numbers on STS, but these methods won't be effective with this type of similarity (namely because embeddings must have unit norm in their model). Therefore, I think the paper needs some more motivation and experimental evidence of its superiority over related methods like SIF+PCA in order for it to be accepted.\n\nPROS\n- Probabilistic model with clear design assumptions from which a similarity metric can be derived.\n- Derived similarity metric doesn't require knowledge of the entire dataset (in comparison to SIF + PCA)\n\nCONS\n- Performance seems to be slightly better than SIF, WMD, and averaging word embeddings, but below that of SIF + PCA \n- Unclear motivation for the model, was it derive an online similarity metric that outperforms SIF(without PCA)?\n- Requires the removal of stop words, but doesn't state how these were defined. Minor point, but tuning this could be enough to cause the improvement over related methods."", ""The paper proposes a Bayesian model comparison based approach for quantifying the semantic similarity between two groups of embeddings (e.g., two sentences). In particular, it proposes to use the difference between the probability that the two groups are from the same model and the probability that they are from different models.\n\nWhile the approach looks interesting, I have a few concerns: \n-- Using the Bayesian model comparison framework seems to be an interesting idea. However, what are the advantages compared to widely used learned models (say, a learned CNN that takes as input two sentences and outputs the similarity score)? The latter can fit the ground-truth labels given by humans, while it's unclear the model comparison leads to good correlation with human judgments. Some discussion should be provided.\n-- The von Mises-Fisher Likelihood is a very simplified model of actual text data. Have you considered using other models? In particular, more sophisticated ones may lead to better performance. \n-- Different information criteria can be plugged in. Are there comparisons? \n-- The experiments are just too simple and incomplete to make reasonable conclusions. For example, it seems compared to SIF there is not much advantage even in the online setting. \n""]","[-20, -20, -20]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('generally well-written', 'mathematical derivations are detailed', 'work looks original'), they express several criticisms and doubts about the paper's motivation, clarity, and significance. The reviewer states they are 'not convinced of the practicality of the algorithm' and feels the paper 'could do a much better job at explaining the motivation behind the work'.\n\nThe politeness score is moderately positive (50) as the reviewer uses respectful language throughout and frames criticisms constructively. They acknowledge their own limitations as a reviewer ('I am not a great reviewer for this paper') and use phrases like 'I would have liked to see' and 'I feel' to soften their critiques. The tone is professional and objective, avoiding harsh or personal criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'carefully laid out'), they express concerns about the paper's motivation and results ('lackluster', 'needs some more motivation'). The reviewer also states that the paper's performance is below SIF + PCA, which is a significant drawback. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive feedback. They use phrases like 'I do like the paper' and offer specific suggestions for improvement, which contributes to a polite tone. The reviewer maintains a professional and balanced approach, even when expressing criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the approach as 'interesting', they express several concerns and criticisms about the paper. The reviewer points out limitations in the methodology, lack of comparisons, and insufficient experiments, which contribute to the overall negative sentiment. However, the criticism is not severe, hence the score is only slightly negative. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout. They start with a neutral summary and use phrases like 'looks interesting' and 'some discussion should be provided' instead of more direct criticisms. The reviewer also poses their concerns as questions or suggestions rather than outright criticisms, which maintains a respectful tone.""]"
"['The authors introduce Morph-Net, a single layer neural network where\nthe mapping is performed using morphological dilation and erosion.\nI was expecting something applied to convolutional networks as such operators\nare very popular in image processing, so the naming is a bit misleading.\n\nIt is shown that the proposed network can approximate any smooth function, \nassuming a sufficiently large number of hidden neurons, that is a nice result.\n\nClarity should be improved, for example it is mentioned that the structuring\nelement is learned but never clearly explained how and what difficulties it poses.\nIn the main text it is written that alpha is {-1, 1}, which would result in a\ncombinatorial search, but never explained how it is learned in practice.\nThis is shown only in the appendix but it is not clear to me that using a binarization\nwith the weights is not prone to degenerate solutions and/or to learn at all\nif proper initialization is not used.\nDid the authors experiment with smooth versions or other form of binarization with\nstraight-through estimator or sampling?\n\nIn the proof for theorem 1 it is not clear if the convergence of the proposed\nnetwork is faster or slower than that of a classic single layer network.\n\nThe main result of the paper is that the structuring element can be learned,\nbut there is no discussion on what it is learned. Also, there is no comparison\non related approaches that try to learn the structuring element in an end-to-end\nfashion such as [1].\n\nExperiments lack a more thorough comparison with state-of-the-art and at least\nan ablation study to show that the proposed approach is effective and has merit.\nFor example, what is the relative contribution of using dilation and erosion\njointly versus either one of them.\nWhat is the comparison with a winner-take-all unit over groups of neurons\nsuch as max-pooling?\n\nIt seems that extending the work to multiple layers should be trivial but it is\nnot reported and is left to future investigations. This hints at issues with\nthe optimization and should be discussed, is it related to the binarization\nmentioned above?\n\nOverall the idea is interesting but the way the structuring element is learned\nshould be discussed in more details and exemplified visually. Experiments need\nto be improved and overall applicability is uncertain at this stage.\n\n=======\n[1] Masci et al., A Learning Framework for Morphological Operators Using Counter--Harmonic Mean.\n', 'This paper proposes to replace the standard RELU/tanh units with a combination of dilation and erosion operations, arguing for the observation that the new operator creates more hyper-planes and therefore have more expressive power.\n\nThe paper is interesting and there are encouraging results which show a couple of percentage improvements over relu/tanh units.  This paper is also clearly written and easy to understand. However there are two issues:\n1. It is somewhat unclear from the paper what  is the main novelty here (compared to existing morpho neurons), is it the learning of the structuring element s? is it the combination of the dilation+erosion operations?\n2. The second issue is that presumably due to the fact that Conv layers are not used, the accuracy on cifar-10 and cifar-100 are significantly lower than state-of-the-art. It would make the paper extremely strong if the improvement translated to CNNs which are performing near the state-of-the-art. What happens if relu units in CNNs were swapped out for the proposed dilation/erosion operators?\n', ""* Update:\nThanks for you answer and clarification. While the Morph-net appears novel, the authors only report result for image classification task and don't achieve as good performance as standard convolutional baselines. Given the current empirical evaluation, I find hard to assess how significant is the contribution. I would encourage the authors to either compare on a task where dense networks achieve state-of-art performances or extend their approach to 2D inputs.\n\n\n* Review\n\nThis paper introduces Morph-Net, a new architecture that intertwine morphological operator such as dilation/erosion with linear layer. Authors first show than Morph-Net are universal approximator. Morph-Net can be expressed as a sum of multi-order hinge functions which can approximate any continuous function. They then validate empirically the Morph-Net on  MNIST, FashionMNIST,  CIFAR10 and CIFAR100 datasets. In particular, authors investigate a 3 layers  fully-connected Morph-Net and shows that it can outperform its Tanh/Relu/Maxout counterparts.\n\nThe paper is a nice read also some specific point could be clarify. For instance it is not clear how the structuring elements of the dilation/erosion are learned? Are the learned simply through backpropagation? Also, it is not clear to me how Morph-Net differs from the previously proposed morphological neurons? \n\nEmpirical evaluation of Morph-Net could be improved as well. In particular, authors focus on image classification task. While they show that Morph-Net can outperform other fully connected architecture, the results on CIFAR10/100 seems low compared to convolutional network. It raises the question of the advantages of Morph-Net over convolutional neural networks ?  Authors also limit their exploration to  3-layer networks. Why don’t you explore deeper network for both baseline and Morph-Net?  Finally, if I am not mistaken, authors use the same set of hyperparameters for the baselines/Morph-Net? It is not clear to me if the hyperparameters are optimal for all the approach? They might give an unfair advantage to one of the baseline or Morph-Net?\n\nOverall, this paper present a nice idea. Showing the Morph-Net is an universal approximator is a nice result. However, the empirical evaluation could be improved. It is not clear to me at this point if Morph-Net brings a benefit compare to convolutional net for image classification task.\n""]","[-20, 50, -20]","[50, 75, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice result', 'interesting idea'), they express several concerns and criticisms. The review points out issues with clarity, lack of thorough comparisons, and questions about the method's effectiveness and applicability. The overall tone suggests that significant improvements are needed.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It is shown that...', 'Did the authors experiment with...', and 'Overall the idea is interesting but...' which indicate a respectful approach to criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. However, the score is not higher because the language, while not rude, is also not overtly warm or encouraging."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'interesting' with 'encouraging results' and praises its clarity. However, they also point out two significant issues, balancing the positive aspects. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They phrase their concerns as 'issues' rather than flaws, and use phrases like 'It would make the paper extremely strong if...' which suggests constructive feedback rather than harsh criticism. The reviewer maintains a professional and courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice read', 'nice idea', 'nice result'), they express significant concerns about the empirical evaluation and the overall contribution. The reviewer questions the advantages of Morph-Net over convolutional networks and suggests that the evaluation could be improved. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as suggestions or questions rather than direct criticisms. They use phrases like 'could be clarify', 'could be improved', and 'I would encourage the authors to' which maintain a polite tone while providing feedback.""]"
"[""ML models are trained on a predefined dataset formed by a set of classes. Those classes use to be the same ones for training and testing. However, what happen when during testing time images with classes unseen during training are shown to the model? This article focus in this problem which is not currently taking much attention by the mainstream research community and is of great importance for the real world applications.\n\nThis article tries to detect areas of the image where those out-of-distribution situations appear in semantic segmentation applications. The approach used is by training a classifier that detects which pixels are out of distribution. For training two datasets are used: the dataset of interest and another different one. The classifier learns to detect if a pixel is from the dataset of interest or from another distribution.\n\nThe main problem I found with this article is that I couldn't fully understand it. Maybe because the text needs a bit more of review and improvement or maybe because Im not very familiar with the topic. Moreover the article is 10 pages while it is encouraged to be 8. I find that the method of the paper is quite simple and can be explained more straight forward and in less pages. The related work section overlaps a lot with the intro, I suggest to combine both. First two paragraphs of the method seam that should be in the intro. Model details from the experiments I consider that should be explained in the method. I miss a figure explaining the architecture of the model. Why using the semantic segmentation model proposed and no something standard? For instance Tiramisu (That is also based on dense layers). Note that the method used for semantic segmentation is 10 points lower than the SOTA in Cityscapes. Figure 1 is impossible to read as the captions are too small. The representations of figures 2-5 are difficult to interpret. There is no comparison to SOTA\n\n"", 'This paper aims to detect out-of-distribution pixels for semantic segmentation, which is a good direction for researchers in this field to explore. As the authors point out, recent semantic segmentation systems surpass 80% mIoU on Pascal VOC 2012  and  Cityscapes, which is a good achievement. Unfortunately, most existing semantic segmentation datasets assume closed-world evaluation which means that they require predictions over a predetermined set of visual classes. This work utilize data from other domain to detect undetermined classes, thus can model uncertainty better in an explicit way. I just have minor comments. \n\n1. When you perform training, do you train from scratch or from a pre-trained model? If using pre-trained model, then ILSVRC is not actually pure OOD pixels. \n\n2. How to interpret the results in Table 5? \n\n', 'Summary:\nThis paper addresses the problem of out-of-distribution detection for helping the segmentation process. Therefore, the detection is performed on a pixel basis. The application of the approach is to datasets used for autonomous driving, where semantic segmentation of the view of the road is a typical application. Since in a road view there will be pixels that are projections of objects that are likely not in the set of classes known by the semantic segmentation algorithm, it makes sense to flag them as being out of distribution (OOD), or not known, or to assign to them a low confidence level. The proposed approach is trivial: train a binary classifier that distinguishes image patches from a known set of classes from image patches coming from an unknown (background class). The classifier output applied at every pixel will give the confidence value. While there are different dataset options to represent the known classes, the background class is represented by images from ILSVRC. The results show that for the segmentation application the approach works better than using an adaptation of more elaborate out-of-distribution methods.\n\nQuality and clarity:\nThe paper is well organized and is described very clearly and provides an ok set of results, despite the simplicity of the approach.\n\nOriginality and significance:\nUnfortunately, I do not see any relevant technical novelty, and this is a major issue. Perhaps the only significant conclusion about this paper is that before designing a new OOD detector, if representing the set of “unknown” classes with ILVRC is reasonable, then it makes sense to simply train a binary classifier and see how it works.\n\nBesides the novelty, I disagree with the way the paper has been positioned and motivated. It brings into play epistemic and aleatoric uncertainty concepts to justify (the simplicity of) the approach, and it overlooks a large body of machine learning (novelty detection, one-class classification, …). This is also a major issue.\n\n\nAdditional comments:\n\nOne of the biggest motivations for this work is that other approaches do not distinguish between epistemic and aleatoric uncertainty and this is why they do not work. This is regarded as a distinctive advantage of the proposed approach. It is claimed that the proposed formulation is insensitive to any aleatoric uncertainty. On the other hand, the paper is written in a way that ignores a large body of literature that goes under the name of “novelty detection”, “anomaly detection”, “one-class classification”, and related names. So, I am wondering how the approaches just mentioned compare with the proposed method, when epistemic and aleatoric uncertainty become part of the discussion. Isn’t every novelty detector insensitive to aleatoric uncertainty as well? Could the Authors clarify what they claim with that statement, while considering a broader view? \n\nThe paper should relate to the literature mentioned above. In particular, I would point the Authors to a couple of recent works that seem to precisely contradict the premises of the proposed approach, which are given at the beginning of section 3:\n\n- Adversarially Learned One-Class Classifier for Novelty Detection, CVPR 2018\n- Generative Probabilistic Novelty Detection with Adversarial Autoencoders, arXiv, July 2018.\n\n\nAgain, related to novelty detection, it looks like the proposed approach still requires tuning one or more thresholds. Therefore, it would not be that different from tuning the threshold of a novelty detector, or a one-class classifier. It would have strengthened the paper if the approach was compared also to a novelty detector.\n\nIt is not clear if the fully convolutional OOD detector is working on a patch or on the entire image. If it is a patch, of what size?\n\nPage 4, define the “ID” acronym. \n']","[-30, 60, -50]","[20, 80, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the importance of the topic and the novelty of the approach, they express several concerns about the paper's clarity, length, and lack of comparisons to state-of-the-art methods. The reviewer states they 'couldn't fully understand' the article and suggests significant revisions, indicating a generally negative sentiment despite recognizing some positive aspects.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I suggest' and 'I miss' rather than making harsh demands. The criticism is presented as observations and suggestions rather than direct attacks. However, the politeness is not extremely high as the review is quite direct in pointing out flaws without much softening language."", ""The sentiment score is 60 (positive) because the reviewer starts by praising the paper's direction as 'good' and acknowledges the achievement in the field. They also mention that the work can 'model uncertainty better in an explicit way', which is positive. However, the score is not higher because the reviewer states they have 'minor comments', indicating some reservations. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They frame their comments as questions rather than criticisms, which is a polite approach. The use of phrases like 'Unfortunately' to introduce a critique and 'I just have minor comments' further softens the tone, making it very courteous."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('The paper is well organized and is described very clearly'), they express major concerns about the lack of technical novelty and disagreement with the paper's positioning. Phrases like 'Unfortunately, I do not see any relevant technical novelty, and this is a major issue' indicate a negative sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'Could the Authors clarify' and 'It would have strengthened the paper if'. They provide constructive criticism and suggestions without using harsh or rude language, but also don't go out of their way to be overly polite or complimentary.""]"
"['A Stackelberg competition is a nonzero-sum game where 1) each player has their own objective, which do not sum up to a constant, and 2) there is an order at which the players interact. The proposed formulation only assumes that parameters of one player (data generator) partition in I tuples \\gamma_i of parameters, where each tuple parameterizes a different data generator component (e.g., a separate neural network). Further, each of those components is assumed to contribute a term to the game\'s objective that only depends on the corresponding parameter tuple \\gamma_i, and the other player\'s parameters \\theta (e.g., weights of the discriminator). From a game theoretic perspective, this still yields a 2-player zero-sum game where the action space of the data generator is the product space of the I tuple spaces. Hence, I have doubts about the general finding that more data generating components decreases the duality gap.\n\nThe gap between the a maximin and minimax solution is determined by the shape of the objective \\phi(\\gamma,\\theta) and is zero, for example, if \\phi is (quasi) convex in \\gamma=[\\gamma_1, ..., \\gamma_I], and (quasi) concave in \\theta. The authors bound the violation of this property w.r.t. the data generator components\' parameters \\gamma_i, and argue that this degree of violation is the same for the whole data generator parametrized by \\gamma=[\\gamma_1, ..., \\gamma_I] if the data generator components are from the same family of mappings (e.g., having the same network architecture). While this conclusion is true under worst cast assumption, e.g., the globally maximal possible gap, this would also imply that all data generator components find the same global best solution, that is, yield the same mapping, in which case the gap would be identical to just using one of those components.\n\nIntuitively, the only reason to have multiple data generator components is to learn different mappings such that the joint data generator -- mixing the outputs of the different components -- is more expressiv than just a single mapping. If the different mappings only result from the inability of finding the global best solution, a worst case argument is not very insightful; in this case, one should study the duality gap in the neighborhood of the starting solutions. On the other hand, if we assume a different family of mappings for each component, the convexity violation of the joint data generator is higher than for each component; hence, the gap does not necessarily decrease with more components.\n\nSo why do multiple data generator components help in practice, and why does the proposed model outperform single-component GANs and the multi-branch GAN in the experiments? Solving a maximin/minimax problem for highly non-convex-concave functions is challenging; there is an infinity of saddle point solutions which yield different ""performances"". The multi-branch GAN can be seen as a model averaging approach giving more stable results, whereas the proposed GAN seems more of an ensemble approach to stabilize the result. Though, this is speculative and I would encourage the authors to study this in-depth; the reasoning in Remark 1 is not convincing to me.\n\nUPDATE:\n\nI read the revision and stick to my vote. In the discussion, I wasn\'t able to get my points across, e.g., that bounding the worst case duality gap is not enough to conclude that the observed duality gap does not grow for multiple local optimal GANs, where the duality gap is expected to be much smaller. A simple experiment could be to actually measure the duality gap (flip the order of the players and measure the difference of the objectives, when starting with the same initialization). If the authors were right, the maximum of those gap should stay constant when adding more data generators. To justify a Stackelberg setting, the authors may provide an example instantiation that cannot be cast into a standard zero-sum game with minimax solution. I can\'t see such an example but I\'m happy to be proven wrong.', ""This paper proposes a way of training multi-generator in the GAN setting.\nWhile a proposed approach is simply to put N generators and form a sum of GAN losses to train a model, the paper carefully presents a theoretical analysis on the duality gap, and shows as N goes infinity, the duality gap can shrink to zero.\nOne can think of this as a usual ensemble approach to increase model's capacity and performance, but the main difference to the usual ensemble approach is to form a sum of losses (ensemble losses) instead of a loss on output of ensemble.\nThe paper shows this can be more effective approach to train a multi-generator architecture and I believe that this can be an effective approach to capture multi-modal sample distributions.\nFinally, a paper is well-written and well-organized. "", 'This paper proposes the Stackelberg GAN framework of multiple generators in the GAN architecture. The architecture is similar with previous multiple-generator GANs (MAD-GAN and MGAN). In fact, it\'s even simpler in the sense that Stackelberg GAN has simpler loss function for the discriminator compared with the previous two. The authors prove that the minimax duality gap shrinks as the number of generators increases. And this proof has no assumption on the expressive power of generators and discriminator. With this proof, the authors argues that because the duality gap shrinks as the number of generators increases, the training of GANs gets more stable.\n\nFrom the algorithm part, I think the algorithm is very similar (and even simpler) than MAD-GAN and MGAN. The MAD-GAN and MGAN even proposed some specific loss for the discriminator so that it will encourage different generator to generate different modes in the target distribution. The Stackelberg GAN does not do this, but ""partially"" achieved the same goal. However, from Figure 9, we see that the simpler the generator is, the easier different generator will capture different modes. I think that this is due to the simplicity of discriminator loss. Therefore, on the algorithm part, the author may want to address the difference between Stackelberg GAN and MAD-GAN and MGAN. On the experiment part, we need to see more comparison between these three methods. In the current experiment, MGAN result is very similar to the proposed method, and MAD-GAN result is missing. Personally, I think that on cifar dataset (or larger datasets), these three methods should have very similar behavior. \n\nFrom the theoretical part, the authors derived a bound of the minimax duality gap for the Stackelberg GAN, without the assumption on the expressive power of generators and discriminator. Although the bound may not be practical, these are nice efforts. There are many typos in the paper (and appendix), which make me difficult to follow the proofs. For example, ""Let clf (bclf) be the convex(concave) closure of f, which is defined as the function whose epigraph (subgraph) is the convex\n(concave) closed hull of that of function f."" Do we have concave closed hull of subgraph of function f? What is the concave closed hull of a set? The usage of sub(sup)-script is also very confusing, like in the definition of h_i(u_i). The authors may want to correct typos and improve the presentation. In the conclusion, the authors conclude ""We show that the minimax gap shrinks to \\eps as the number of generators increases with rate e O(1/\\eps)."" This is an over-claim, because the authors only proved this under the assumption of concavity of the maximization w.r.t. discriminators. \n\nFinally, the authors may want to provide some simple results of the Stackelberg GAN from the perspective of density approximation, even assuming infinite capacity of the discriminator set, as other GANs does. Whether the distance defined by the maximization problem a distance or divergence. If we exactly minimizing that objective function, do we get the target distribution? \n']","[-50, 80, -20]","[20, 70, 50]","[""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's main findings and methodology. They use phrases like 'I have doubts about the general finding' and 'the reasoning in Remark 1 is not convincing to me', indicating a negative sentiment. However, the reviewer also acknowledges some positive aspects, such as the paper's performance in experiments, which prevents the score from being more negative. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I would encourage the authors to study this in-depth' and 'I'm happy to be proven wrong', which show respect and openness to dialogue. The language is not overly formal or polite, but it maintains a respectful tone throughout, hence a slightly positive politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, highlighting its theoretical analysis, potential effectiveness, and good organization. Phrases like 'carefully presents', 'can be an effective approach', and 'well-written and well-organized' indicate a positive sentiment. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, acknowledging the paper's contributions without harsh criticism. The tone is constructive and appreciative, using phrases like 'I believe' to soften personal opinions. The review focuses on the paper's strengths without using overly effusive language, maintaining a polite but professional distance."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'nice efforts' on the theoretical part), they raise several concerns and criticisms. These include similarities to existing methods, missing comparisons, typos in the proofs, and an over-claim in the conclusion. The overall tone suggests the paper needs significant improvements.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'the authors may want to' when suggesting improvements, which is a polite way of giving feedback. The reviewer also acknowledges positive aspects of the work before providing critiques. However, the score is not higher because the review is primarily focused on pointing out areas for improvement rather than praising the work.""]"
"['This paper develops a reinforcement learning approach for negotiating coalitions in cooperative game theory settings.  The authors evaluate their approach on two games against optimal solutions given by the Shapley value.\n\nThe work builds upon a substantial and growing literature on reinforcement learning for multiagent competitive and cooperative games. The most novel component of the work is a focus on the process of negotiation within cooperative coalition games. The two game environments studied examine a ""propose-accept"" negotiation process and a spatial negotiation process.\n\nThe main contribution of the work is the introduction of a reinforcement learning approach for negotiation that can be used in cases where unlimited training simulations are available.  This approach is a fairly straightforward application of RL to coalition games, but could be of interest to researchers studying negotiation or multiagent reinforcement learning, and the authors demonstrate the success of RL compared to a normative standard.\n\nMy primary concerns are:\n- The authors advertise the work as requiring no assumptions about the specific negotiation protocol, but the learning algorithms used are different in the two cases studied, so the approach does require fine-tuning to particular cases.\n- Maybe I missed it, but how many training games are required?\n- In what real applications do we expect this learning algorithm to be useful?  \n- The experiments where the RL agents are matched against bots include training against those specific bot types. How does the trained algorithm perform when matched against agents using rules outside its training set?  \n- Since the Shapley value is easily computable in both cases studied.  If the bots are all being trained together, why wouldn\'t the bots just use that to achieve the optimal solution?\n- Why are only 20 game boards used, with the same boards used for training and testing?  How do the algorithms perform on boards outside the training set?\n\nOverall, the paper is somewhat interesting and relatively technically sound, but the contribution seems marginal.\n', 'This is an emergency review, so apologies for the briefness.\n\nThe paper introduces an approach to learning negotiation strategies using reinforcement learning. The authors propose a new setup in which self-interested agents must cooperatively form teams to achieve a reward. They explore two ways of proposing agreements: one involving a random agent proposing an agreement symbolically, and another in which agents form teams by moving to the same location. Results show that RL-trained models outperform simple rule-based bots, and correlate with game-theoretic predictions. I think the paper is very well clearly presented, and tackles an interesting an important problem.\n\nOne issue I have is that as I understand it, the results are only reported for training games. Could the agents just be memorizing a good outcome for that specific environment, rather than actually learning to negotiate? Why not evaluate on held out games?\n\nThe experiments are pretty interesting, and I appreciated the last one showing that limitations are due to the difficulty of RL, rather than expressive power of the network. However, I think there are some other natural questions that could be explored, including: what kind of strategies are the models learning? Could we change the environment in such a way that the proposed approach is not sufficient? Is the choice of RL approach crucial, or does anything work? I think further experiments would strengthen the paper.', ""Note: This is an emergency review. I managed not to look at existing comments/ratings for this paper before writing my review.\n\nSummary\n---\n\nThis paper studies deep multi-agent RL in settings where all of the agents must cooperate to accomplish a task (e.g., search and rescue, multi-player video games). It uses simple cooperative weighted voting games 1) to study the efficacy of deep RL in theoretically hard environments and 2) to compare solutions found by deep RL to a fair solution concept known in the literature on cooperative game theory.\n\nIn a weighted voting game each agent is given a weight and the agents attempt to form teams. The first team whose total weights exceed a known threshold get the total reward, which is distributed amongst the team members. Given such a game, the __shapely value__ of an agent measures the importance of that agent. How much does it contribute to a team from this set of agents? How much payoff should it get? These have existed in the literature for over 60 years and appear to be widely known and used.\n\nAll of this is agnostic to how the agents communicate to form teams: i.e., the communication protocol or the actions available in the environment. The protocol matters because it can allow certain teams to form more or less easily than others, even though the same team would get the same reward regardless of protocol. This can make an agent more or less effective under different protocols. Here two protocols are considered - one where agents suggest proposed teams directly and another where they suggest teams by congregating on a 2d plane. Both protocols result in games whose Nash equilibria are computationally intractable.\n\nThe paper shows 4 results:\n1) It considers a hand-designed bot similar to models from the game theory literature. Relative to a group of RL agents, an additional RL bot will outputperform a hand-designed bot in terms of average reward it receives.\n\n2) The average reward of a bot is strongly correlated with that bots shapely value.\n\n3) In the negotiation by congregation environment, a bot's spatial position can affect its ability to negotiate.\n\n4) Shapely values can be predicted quite accurately from the weights and threshold that define a cooperative voting game, though these predictions have high variance.\n\nThe paper concludes that deep RL is effective at learning agents for cooperative games in multiple ways:\n1) Deep agents are better than a hand-designed agent.\n\n2) Deep agents easily extend across negotiation protocols (something hand-designed agents don't do).\n\n3) A popular result in cooperative game theory predicts how effective agents should be. Deep agents are just about that effective.\n\nStrengths\n---\n\n* The paper does a pretty good job of reviewing relevant work from game theory.\n\n* Some of the organization is nice (e.g., the list of reasons classic game theory doesn't extend to practice; one section per experiment).\n\nWeaknesses mentioned in individual sections...\n\nQuality\n---\nOverall, things were well thought through, but I would have liked more out of the experiment 4 section and I think a few minor details might have been missed.\n\nDetails:\n\nSection 4.5/Experiment 4: The Shapely value comparison is the most important part of the paper.  This section is important because it tries to explain those results, but it seems like there's more work to be done here. I'm not sure capacity is eliminated as a concern, and there might be other concerns not listed like optimization error.\n\n* I'm not sure what conclusion to take from experiment 4. Shapely values can be computed from the cooperative games directly, independent of protocol. We're interested in __policies__ that get exactly the shapley values as their average reward. Policies depend on the protocol. Does being able to predict shapley values mean that a model with similar capacity can learn a policy that will have the desired shapley value? Was that the desired conclusion?\n\nOther comments:\n\n* The current hand-designed baseline uses weights to form a probability distribution. There should be another baseline that uses Shapley values instead of weights.\n\n* It's not clear exactly what the spatial nature of the Team Patches environment adds. It is good to try another environment just to have an additional notion of generalization.\n\nClarity\n---\nOverall, the motivation could be clearer. Is the point to do work on cooperative games or to compare to Shapley values?\n\nPresentation details:\n\n* The paper does not get to specific examples of agents acting in environments until about page 4. Providing a simple, brief example which leaves out some details at the beginning would go a long way toward aiding intuitions about the abstract concepts discussed. Here are some clarity issues I had that might have been helped with an example:\n    * What exactly is it about a task which requires agents to form teams? How necessary are those teams?\n    * What exactly is a negotiation protocol?\n    * What does it mean to distribute/share a reward across agents?\n\n* When talking about shapely values, fairness seems to be emphasized somewhat often, but no concrete intuition about what fairness means in this setting is provided.\n\n* Intro para 4: What does the human data measure? And thus how might it be useful?\n\n* Intro para 7: People in the ICLR community will be more familiar with this work. What is the difference between communication and team forming?\n\n* The section on Shapley values should provide more intuition about what they're thought about as measuring. (An agent's importance or what payoff it should expect, according to wikipedia.)\n\n* Instead of measuring correlation to Shapley values, the paper measures whether average reward approximates Shapley values. It seems like the two are on a different scale. Average reward is unbounded and Shapley values are in [0, 1]. How are they comparable?\n\n* The paper mentions how results vary over different types of boards (ones with higher and lower variance in the sampled weights). It does not show results to support this discussion. A conditional analysis of performance would be interesting and relevant, perhaps conditional versions of Fig. 3.\n\nOriginality\n---\nI do not know much about game theory and I'm only somewhat familiar with multi-agent deep RL, so I am not in a great position to judge novelty. Nonetheless, Given existing work in multi-agent RL, it is unsurprising that deep RL agents learn reasonable policies in these environments.\n\nAs far as I know, the comparison of average reward to shapely values has not been done before. \n\n\nSignificance\n---\nMost work in multi-agent RL evaluates by 1) comparing to baselines or 2) measuring some environment/task-specific metric. The best thing about this work is that it evaluates by comparing actual performance to some external theory that suggests how well an agent should be able to do, falling into a 3rd category.  It's not alone in this category (e.g., paper compare to theoretically optimal baselines if they can), but it is interesting to see another example of this kind of evaluation.\n\nThe community might possibly start to focus more on cooperative games because of this paper. A more interesting result would occur if others are inspired to implement more comparisons to how agents __should__ perform in theory.\n\n\nJustification for Final Rating\n---\n\nI am unsure about novelty. As described above, the paper is lacking in clarity and quality (esp. section 4.5), but I don't think these concerns would invalidate the main result. I think the contribution is significant because of the kind of evaluation, but I'm not sure it will ultimately have a large impact. Thus I think some of the concerns above should be addressed before publication, but I would not be very disappointed if it were published as is.\n\n""]","[-20, 60, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('somewhat interesting and relatively technically sound'), they also express several concerns and state that 'the contribution seems marginal.' The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism or personal attacks. They present their concerns as questions or observations rather than direct criticisms, which maintains a polite tone. The reviewer also acknowledges the potential interest and success of the approach in certain areas, which contributes to the politeness of the review."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'very well clearly presented' and tackles 'an interesting and important problem'. However, they also raise some concerns and suggest improvements, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's apologetic tone for brevity, use of phrases like 'I think' and 'I appreciated', and constructive framing of criticisms. The reviewer maintains a respectful and professional tone throughout, offering suggestions rather than harsh criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and areas for improvement. The review highlights issues with clarity, quality (especially in section 4.5), and suggests that some concerns should be addressed before publication. However, it's not overwhelmingly negative as the reviewer states they 'would not be very disappointed if it were published as is'. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They provide constructive criticism and balance negative points with positive ones. The reviewer also acknowledges their own limitations in judging certain aspects of the paper. The tone is generally helpful and aimed at improving the paper rather than being harshly critical.""]"
"['The paper proposes Partial VAE to handle missing data and a variable-wise active learning method. The model combines Partial VAE with the acquisition function to design an intelligent information acquisition system. The paper nicely combines the missing value problem with an active learning strategy to in an acquisition pipeline and demonstrate the effectiveness on several datasets.\n\nI have following comments/questions:\n\n1.  Does p(x_i | z) include parameters? How do these parameters be trained?\n\n2. Does sample from p(x_i | x_o) follow by sampling z from q(z|x_o) then sample x_i from p(x_i | z)? How to sample from p(x_\\phi | x_i, x_o) in Eq (7)?\n\n3. In Eq (9), it uses q(z_i|x_o), q(z_i | x_i, x_o),  q(z_i | x_i, x_o, x_\\phi) while in Eq (4) it only shows how to learn q(z|x_o). Does it need to learn multiple partial inference networks for all combination of i and \\phi ?\n\n4. The comparison with similar algorithms seems to be weak in the experiment section. RAND is random feature selection, and SING is global feature selection by using the proposed method. These comparison methods cannot provide enough information on how well the proposed methods performs. There are plenty of works in the area of “active feature acquisition” and also many works in feature selection dated back to Lasso which should be considered as comparison targets.\n\n5. In the “personalized” implementation of EDDI on each data instances, is the model trained independently for each data point or share some parameters across different data? If so, what are the shared parameters?', 'The authors present an information discovery approach based on (partial) variational autoencoders and an information theoretic acquisition function that seeks to maximize the expected information gain over a set of unobserved variables. Results are presented on image inpainting, UCI datasets and health data, namely ICU and NHANES.\n\nIt is not clear why multiple recurrent steps improve perfromance. This is not conceptually justified and empirically (see Figure 8), it is also unclear whether PNP5 significantly outperforms PNP1. Further, results seem to support that PNP is always better than PN, so why introduce the methodology around PN or even present it at all. Note that the authors do not offer an explanation about the perfromance differences between PN and PNP.\n\nIn the inpainting regions section, the authors write about well-calibrated uncertainties without any context. What do they mean by calibration, well-calibrated and how can they support their claim about it?\n\nIn Figure 3 it is not clear that PNP+Ours outperforms PNP+SING. For Boston hosing seems to be marginally better but the error bars (which I assume are standard deviations, not stated) make difficult to ascertain whether the differences are significant. Although I understand the value of having ""personalized"" decisions, one wonders whether this personalization comes with any generalizable measurable gains given the results.\n\nThe results in Table 2 need to be clarified and further explained. 1) what are the error bars, considering multiple runs and datasets? 2) How can EDDI be so much better than SING when individual AUICs in Tables 6-11, the only significant difference (accounting for error bars) is on Boston data? 3) according to Tables 6-11, PNP is only the best in 1 of 5 datasets, so how come is the overall beast by a large margin? This being said, the results in Table 2 are at best misleading.\n\nIn Table 4, how can PNP-EDDI be so much better than PNP-SING, when in Figure 6 error bars overlap almost everywhere?\n\nI enjoyed reading the paper, the motivation is clear and the problem is important. The approach is modestly novel compared to existing approaches and in general well explained despite the fact that the need for multiple recurrent steps is not well justified and the differences between PN and PNP, advantages/disadvantages and when to use each are not described or explored in the experiments.', '----I acknowledge that the authors have made improvements to the paper and have increased my score to 6\n\nThis is still definitely not my area of expertise and so I am leaving my confidence score low. \n---\n\nThe paper presents an algorithm EDDI that uses a a partial VAE and does active feature selection. The authors show quite a bit of experiments that seem to indicate the approach gives positive results.  However, since this is not my main area of expertise I do not know if these tasks are standard evaluation for this task.\n\nFor instance in Section 4.3, 4.4 why don\'t the authors plot accuracy as a function of steps/number of variables observed. That would seem much more useful than log likelihood.\n\nIn general, I found the methodology in the paper to be difficult to understand and not enough background was given.\nI think the paper would be clearer if it was more self contained.\n\n-For instance, I found much of Section 3 to not have enough background. The authors use lots of terminology around VAEs but don\'t give enough rigorous background so the paper doesn\'t feel self contained. \n\n-The same is true regarding ""amortized inference"" which I also feel isn\'t rigorously defined anywhere but often discussed. \n\n-The task for Section 4.1 (image inpainting) is not quite defined.']","[50, -30, -20]","[70, 20, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with a positive overview of the paper, praising its combination of techniques and demonstration of effectiveness. However, the bulk of the review consists of questions and suggestions for improvement, indicating a balanced perspective. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'The paper nicely combines...' and the use of 'I have following comments/questions' instead of direct criticisms contribute to the polite tone. The reviewer also provides specific, constructive feedback without using harsh or dismissive language."", ""The sentiment score is -30 because while the reviewer acknowledges the importance of the problem and enjoys reading the paper, they express several significant concerns about the methodology, results, and their interpretation. The reviewer points out unclear justifications, potentially misleading results, and lack of explanations for performance differences. However, it's not entirely negative as they do recognize some positive aspects. The politeness score is 20 because the reviewer uses generally polite language, starting with positive comments and using phrases like 'I enjoyed reading the paper'. They present their criticisms as questions or observations rather than direct attacks. However, the tone is not overly polite, maintaining a professional and direct approach in pointing out issues."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges improvements ('have made improvements to the paper and have increased my score'), they still express several concerns and criticisms. The reviewer points out difficulties in understanding the methodology, lack of sufficient background, and suggests improvements ('I think the paper would be clearer if it was more self contained'). The politeness score is slightly positive (20) as the reviewer uses polite language throughout, acknowledges improvements, and frames criticisms as suggestions rather than harsh critiques. The reviewer also honestly admits their lack of expertise in the area, which comes across as humble and respectful.""]"
"[""The paper proposes to include within regular programs, learned parameters that are then tuned in an online manner whenever the program is invoked. Thus learning is continuous, integration with the ML backend seamless. The idea is very interesting however, it seems to me that while we can replace native variables with learned parameters, the hyperparameters involved in the learning become new native variables (e.g. the value of feedback). Perhaps with some effort we can replace the  hyperparameters with predicted variables too. Other concerns of mine stem from the programmer in me. I think of a program as something deterministic and predictable. With continuous, online, self-tuning, these properties are gone. How do the authors propose to assuage folks with my kind of mindset? Is debugging programs with predicted variables an issue? Consider a situation where the program showed some behavior with a certain setting of q which has since been tuned to another value and thus the same behavior doesn't show up. I find these to be very interesting questions but don't see much of a discussion in the current draft. Also, how does this work relate to probabilistic programming?"", 'This paper proposes the use of RL as a set of commands to be included as programming instructions in  common programming languages.  In this aspect, the authors propose to add simple instructions to employ the power of machine learning in general, and reinforcement learning in particular in common programming tasks.\n\nIn this aspect, the authors show with three different examples how the use of RL can speed up the performance of common tasks: binary search, sorting and caches.\n\nThe paper is easy to read and follow. \n\nIn my opinion, the main problem of the paper is that the contributions are not clear. The authors claim that the introduce a new hybrid approach of programming between common programming and ML, however, I do not see many differences between calling APIs and the current proposal. The paper seems to be a wrapper of API calls. Here, the authors should comment existing approaches based on ML and APIs.\n\nThe authors  introduce the examples to show the advantages of using predictive variables. Many of the advantages are based on increasing the performance of the algorithms using these predictive variables, however, the results do not include the computational costs of learning the models. \n\nTherefore, in my opinion the paper should be more focused on detailing the commands of use of predictive variables and emphasising the advantages with respect to existing methods. Currently, the paper gives too relevance to the performance of the experiments, where the novel contributions are not there.', 'This paper proposes using predicted variables(PVars) - variables that learn\ntheir values through reinforcement learning (using observed values and\nrewards provided explicitly by the programmer). PVars are meant to replace\nvariables that are computed using heuristics.\n\nPros:\n* Interesting/intriguing idea\n* Applicability discussed through 3 different examples\n\nCons:\n* Gaps in explanation\n* Exaggerated claims\n* Problems inherent to the proposed technique are not properly addressed, brushed off as if unimportant\n\nThe idea of PVars is potentially interesting and worth exploring; that\nbeing said, the paper in its current form is not ready for\npublication.\n\nSome criticism/suggestions for improvement:\n\nWhile the idea may be appealing and worth studying, the paper does not address several problems inherent to the technique, such as:\n\n- overheads (computational cost for inference, not only in\n  prediction/inference time but also all resources necessary to run\n  the RL algorithm; what is the memory footprint of running the RL?)\n\n- reproducibility\n\n- programming overhead: I personally do not buy that this technique -\n  at least as presented in this paper - is as easy as ""if statements""\n  (as stated in the paper) or will help ML become mainstream in\n  programming. I think the programmer needs to understand the\n  underpinnings of the PVars to be able to meaningfully provide\n  observations and rewards, in addition to the domain specific\n  knowledge. In fact, as the paper describes, there is a strong\n  interplay between the problem setting/domain and how the rewards should be\n  designed.\n\n- applicability: when and where such a technique makes sense\n\nThe interface for PVars is not entirely clear, in particular the\nmeaning of ""observations"" and ""rewards"" do not come natural to\nprogrammers unless they are exposed to a RL setting. Section 2 could\nprovide more details such that it would read as a tutorial on\nPVars. If regular programmers read that section, not sure they\nunderstand right away how to use PVars. The intent behind PVars\nbecomes clearer throughout the examples that follow.\n\nIt was not always clear when PVars use the ""initialization function""\nas a backup solution. In fact, not sure ""initialization"" is the right\nterm, it behaves almost like an ""alternative"" prediction/safety net.\n\nThe examples would benefit from showing the initialization of the PVars.\n\nThe paper would improve if the claims would be toned down, the\nlimitations properly addressed and discussed and the implications of\nthe technique honestly described. I also think discussing the\napplicability of the technique beyond the 3 examples presented needs\nto be conveyed, specially given the ""performance"" of the technique\n(several episodes are needed to achieve good performance).\n\nWhile not equivalent, I think papers from approximate computing (and\nperhaps even probabilistic programming) could be cited in the related\nwork. In fact, for an example of how ""non-mainstream"" ideas can be\nproposed for programming languages (and explained in a scientific\npublication), see the work of Adrian Sampson on approximate computing\nhttps://www.cs.cornell.edu/~asampson/research.html\nIn particular, the EnerJ paper (PLDI 2011) and Probabilistic Assertions (PLDI 2014).\n\nUpdate: I maintain my scores after the rebuttal discussion.']","[20, -20, -40]","[60, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer describes the idea as 'very interesting' and raises thought-provoking questions. However, they also express several concerns, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language, frames their concerns as questions rather than criticisms, and acknowledges the interesting nature of the work. They use phrases like 'Perhaps with some effort' and 'How do the authors propose' which maintain a constructive tone. The reviewer also personalizes their feedback ('concerns of mine stem from the programmer in me'), which adds a polite, conversational element to the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is easy to read and follow'), they express significant concerns about the paper's contributions and methodology. The reviewer states that 'the main problem of the paper is that the contributions are not clear' and suggests that the paper needs more focus on its novel aspects. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing criticisms as personal opinions ('In my opinion...') and offering constructive suggestions for improvement. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out weaknesses in the paper."", ""The sentiment score is -40 because while the reviewer acknowledges the idea as 'interesting/intriguing', they also state that the paper is 'not ready for publication' and list several significant criticisms. The overall tone is more negative than positive, with concerns about 'gaps in explanation', 'exaggerated claims', and unaddressed problems. However, it's not entirely negative as they see potential in the idea.\n\nThe politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They begin by acknowledging the pros before moving to cons, and use phrases like 'The paper would improve if...' and 'Some criticism/suggestions for improvement:' which are polite ways of offering criticism. They also provide specific recommendations and even suggest relevant literature, which is helpful. The language is not overly formal or deferential, but it's respectful and aimed at improving the paper.""]"
"[""I found the paper difficult to follow. The method proposed is not well motivated, and  the literature review explains well the novelty. Here are some questions/points for discussion:\n\n- the token-level MLE training is not what causes the exposure bias: one can train with MLE and still avoid it by generating appropriate sequences using the RNN, as in scheduled sampling. The problem with MLE (or cross entropy) is that the labels to be predicted might not be the correct ones. See the paper by Ranzato et al. (ICLR2016) for a good discussion of the issue: https://arxiv.org/pdf/1511.06732.pdf\n\n- The criticism against previous works for not comparing agains CRFs seems odd: CRFs are given the number of labels, words, etc. to predict, typically the same as the number of words to be tagged. If one  has this, as well as binary rewards for each decision, then there is little benefit for RL/IL based approaches to be used. The point for them is the use of non-decomposable loss functions such as BLEU, which are not common in tagging, but in tasks like MT, where CRFs can't be used. In fact, for the transliteration experiments in the paper, the CRF approach is padded to perform the task, which highlights that it is not the right comparison. \n\n- the approach proposed seems very similar to MIXER, which also learns a regressor to predict the reward for each action. A direct comparison both in terms of how the approaches operate and empirically is needed.\n\n- why is it a problem that previous works by Ranzato, Bahdanau and Paulus combine MLE and RL? You are using the same supervision, ie. the labeled corpus.\n\n- the adjusted training seems to essentially not reward correct predictions (top branch in the equation). Why is this a good idea?\n\n- In figure 1 it is not clear at all that the proposed approach works; depending on the epoch the ranking among the three variants differs\n\n\n- what does it mean for one method to surpass the other in flexibilty? If anything the requirement for immediate rewards after every action restricts flexibility, as one can't use non-decomposable loss functions such as BLEU which are prety common in NLP.\n\n- How is the training efficiency measured in the paper?\n\n- Why not compare against MIXER, as well as more recent work by Leblonde et al. (2018): https://arxiv.org/abs/1706.04499 ? I don't see why the Rennie et al. 2017 method is picked for comparison.\n\n- It is not true that in IL one needs a gold standard policy, one can learn with sub-optimal policies, see Sun et al. (2018): https://arxiv.org/pdf/1703.01030.pdf\n\n- It is odd to say that an approach proposed earlier (Dagger) reduces to a variant of a later proposed one (Scheduled sampling), the reduction should be the other way around\n\n- are the randomly initialized character embeddings for transliteration tuned during training?\n\n- How were the alignments for training the CRF obtained?\n"", 'The paper pretenses reinforcement learning algorithms for dealing with the ""exposure bias"" problem of RNNs in sequence labeling problems.  While I admire the thoroughness of  both the algorithmic work and experimental setup, I am afraid the paper suffers from two major problems:\n\n1. The paper suffers from serious clarity issues. Particularly, the main problem the paper deals with - exposure bias- is not well explained. I admit that while I am working with RNNs on a regular basis, I was not familiar with this problem. Unfortunately, I was also not able to understand it from the paper.  This may be a very basic concept, but a paper must be self-contained. Unfortunately, after reading the paper, front to cover, I cannot tell what is the problem the authors are trying to solve (except, of course, from providing a better training algorithm for RNNs).\n\n2. As the authors say already in the abstract, one of the best performing models on structured NLP tasks is LSTM-CRF, which combines the power of both the neural and the structured prediction frameworks. However, the authors do not compare their solution to LSTM-CRF, but only to LSTM and to CRF. This is a very important baseline, and without a proper comparison it is hard to evaluation the contribution of this paper.\n\n\n', 'The authors propose actor-critic method for sequence labeling and show that it performs better (is more stable than) other RL approaches and also outperforms other techniques for countering exposure bias like scheduled sampling.\n\nThe results show very small improvement in tagging tasks like NER and CCG supertagging compared to other approaches ; but they show good improvement in the transliteration task which is more of a transduction task than a tagging task. \n\nThis authors also discus the adjusted training procedure which accounts for bad performance of the critic model in the initial stages of training. The approach is not very novel because actor-critic for more general sequence-to-sequence models (arguably more complex than tagging) has already been explored in the literature (Bahdanau et al., cited by the authors). Major difference in the proposed approach is the use of stepwise hamming-loss based reward and it is unclear whether this is a major contribution which  sets it apart from the previous work on AC for sequence modeling. For example, a good comparison would be to do tagging in seq2seq style and use the approach proposed in the existing AC work to show the value of the approach proposed here.\n\nAlso, minor claims about thoroughness of comparison with CRF are ill-founded as previous published work on tagging has indeed compared CRFs, independent, LSTM/RNN based models.']","[-60, -50, -20]","[20, 20, 50]","[""The sentiment score is -60 because the review starts with a negative statement about the paper being difficult to follow and the method not being well motivated. The reviewer then lists numerous criticisms and questions, indicating significant issues with the paper. However, it's not entirely negative as the reviewer provides constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they phrase most points as questions or suggestions rather than harsh statements. The language is professional and academic throughout, avoiding personal attacks or overly harsh language. The reviewer also acknowledges some positive aspects, like explaining the novelty well in the literature review."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, particularly regarding clarity issues and lack of comparison to an important baseline. The reviewer uses phrases like 'I am afraid the paper suffers from two major problems' and 'it is hard to evaluation the contribution of this paper', indicating a negative sentiment. However, the reviewer does acknowledge some positive aspects ('I admire the thoroughness'), which prevents the score from being even lower. The politeness score is 20 because the reviewer uses polite language throughout, such as 'I admire' and 'I admit', and frames criticisms in a constructive manner. The reviewer also uses hedging language like 'may be' and 'Unfortunately', which softens the critique. However, the overall tone is professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work (e.g., 'performs better', 'good improvement in the transliteration task'), they also express several criticisms. They note that improvements in some tasks are 'very small', question the novelty of the approach, and suggest that some claims are 'ill-founded'. The overall tone suggests that the reviewer is not fully convinced of the paper's contributions.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present their criticisms in a constructive manner, using phrases like 'it is unclear' and 'a good comparison would be' rather than making blunt negative statements. The reviewer also acknowledges the positive aspects of the work before presenting criticisms, which is a polite approach. However, the score is not higher because the review doesn't include explicitly polite language or praise beyond what is necessary for a balanced review.""]"
"['Overall Score: 7/10.\nConfidence Score: 7/10.\n\nDetailed Comments: This paper introduces various Deep Recurrent Gaussian Process (DRGP) models based on the Sparse Spectrum Gaussian Process (SSGP) models and the Variational Sparse Spectrum Gaussian Process (VSSGP) models. This is a good paper and proposed models are very sound so I recommend for acceptance although as main weakness I can say that is very technical so it can be difficult to follow. Adding more intuitive ideas, motivation and maybe a figure for each step would be a solution. Apart from that it is a really good paper, congratulations.\n\nRelated to: RNN models and Sparse Nystrom approximation.\n\nStrengths: Models are very sound, solutions are solid, the proposed methodology is correct and the empirical results and experiments are valid and properly done.\n\nWeaknesses: It is too difficult to follow and it is written in an extreme technical way. More intuitions and a proper motivation both in the abstract and introduction may be put in order to make the paper easier to read and, hence, more used by researchers and data scientists.\n\nDoes this submission add value to the ICLR community? : Yes it does, the experiments show the efficiency of the proposed methods in some scenarios and are valid methodologies.\n\nQuality:\nIs this submission technically sound?: Yes it is.\nAre claims well supported by theoretical analysis or experimental results?: Experimental results prove empirically the methods and appendixes show the analysis performed in a clear and elegant way.\nIs this a complete piece of work or work in progress?: Complete piece of work.\nAre the authors careful and honest about evaluating both the strengths and weaknesses of their work?: Yes, and I would enfatize that I have liked that some experiments are won by other methods such as GP-LSTM, they are very honest.\n\nClarity:\nIs the submission clearly written?: Yes, but it is difficult for newcomers due to the reasons that I have stated before.\nIs it well organized?: Yes it is.\nDoes it adequately inform the reader?: Yes it is.\n\nOriginality:\nAre the tasks or methods new?: Yes, they are sound.\nIs the work a novel combination of well-known techniques?: Yes it is.\nIs it clear how this work differs from previous contributions?: Yes.\nIs related work adequately cited?: Yes, being a strength of the paper.\n\nSignificance:\nAre the results important?: I would argue that they are and are a clear alternative to consider in order to solve these problems.\nAre others likely to use the ideas or build on them?: If the paper is written in a more friendly way, yes.\nDoes the submission address a difficult task in a better way than previous work?: Yes I think.\nDoes it advance the state of the art in a demonstrable way?: Yes, empirically.\n\nArguments for acceptance: Models are very sound, solutions are solid, the proposed methodology is correct and the empirical results and experiments are valid and properly done\n\nArguments against acceptance: Clarity of the paper.\n\nMinor issues and typos:\n-> (V)SS not defined before being used.\n-> Abstract should be rewritten adding a motivation and focusing more on the problems being solved and less in the details of the solutions.\n-> Recurrent indexes that go backwards (i) of Eq. 1. should be explained why are going backwards before being used like that. Newcomers may be confused.\n-> Section 2 writing style lacks a bit of cohesion, relating the paragraphs may be a solution.\n-> Q is not defined in section 3.1 paragraph 1.\n-> A valid covariance function must produce a PSD matrix, put that in section 3.1. \n-> I do not see how U marginalizes in Eq. 7, kind of confused about that, I think that it should be p(y|X,U).\n-> Section 3.4 statistics should be explained.\n\nReading thread and authors response rebuttal decision:\n=================================================\n\nI consider that the authors have perfomed a good rebuttal and reading the other messages and the authors response I also consider that my issue with clarity is solved. Hence, I upgrade my score to 7 and recommend the paper for publication.', 'This paper proposes deep recurrent GP models based on the existing DRGP framework, two works on sparse spectrum approximation as well as that of inducing points. In these models, uncertainty is propagated by marginalizing out the hidden inputs at every layer.\n\nThe authors have combined a series of known ideas in the proposed work. There is a serious lack of discussion or technical insights from the authors for their technical formulations: in particular, what are the non-trivial technical challenges addressed in the proposed work? Furthermore, the authors are quite sloppy in referencing equations and inconsistent in the use of their defined notations and acronyms. I also find it hard to read and understand the main text due to awkward sentence structures.\n\nHave the authors revealed their identity on page 2 of the paper? I quote: ""We refer to the report Foll et al. (2017) for a detailed but preliminary formulation of our models and experiments."" and ""DRGP-(V)SS code available from http://github.com/RomanFoell/DRGP-VSS.""\n\n\n\nDetailed comments are provided below:\n\nFor the first contribution stated by the authors, what are the theoretical and practical implications of the different regularization terms/properties between the lower bounds in equations 10 vs. 8? These are not described in the paper.\n\nCan the authors provide a detailed derivation of DVI for equation 13 as well as for the predictive distributions in Sectio 6.3.5?\n\nCan the authors provide a time complexity analysis of all the tested deep recurrent GPs?\n\n\nWould the authors\' proposed approach be able to extend the framework of Hoang et al. (2017) (see below) that has generalized the SS approximation of Lazaro-Gredilla et al. (2010) and the improved VSS approximation of Gal & Turner (2015)?\n\nHoang, Q. M.; Hoang, T. N.; and Low, K. H. 2017. A generalized stochastic variational Bayesian hyperparameter learning framework for sparse spectrum Gaussian process regression. In Proc. AAAI, 2007–2014.\n\n\n\nMinor issues:\nJust below equation 6, equation 9, and throughout the entire paper, the authors need to decide whether to italicize their notations in bold or not.\n\nEquations are not properly referenced in a number of instances.\n\nThe authors have used their commas too sparingly, which makes some sentences very hard to parse.\n\nWhat is the difference between REVARB-(V)SS(-IP), DRGP-(V)SS(-IP), and DRGP-VSS-IP?\n\nEquation 7: LHS should be conditioned on U.\nPage 4:  (V)SSGP does not have the same...\nEquation 8: q_a and q_Z should be placed next to the expectation.\nPage 4: choosen?\nPage 5: will makes it possible?\nPage 5: DRGP-SSGP, -VSSGP, -SSGP-IP, -VSSG-IP?\nPage 5: to simplify notation, we write h^{L+1}_{Hx+1:} = y_{Hx+1:}? Such a notation does not look simplified.\n\nEquation after equation 12: On LHS, should U^(l) be a random variable?\n\nPage 17: Should the expressions begin with >=?\n', 'This paper addresses the problem of modeling sequential data based on one of the deep recurrent Gaussian process (DRGP) structures proposed by Mattos et al (2016). This structure acts like a recurrent neural net where every layer is defined as a GP. One of the main limitations of the original method proposed by Mattos et al (2016) is that it is limited to a small set of covariance functions, as the variational expectations over these have to be analytically tractable.\n\nThe main contributions of this paper are the use of previously proposed inference, namely (i) the sparse spectrum (SS) of Lazaro-Gredilla et al (2010); its variational improvement by Gal and Turnner (2015) (VSS);  and the inducing-point (IP) framework of Titsias and Lawrence (2010) into the recurrent setting of Mattos et al (2016). Most (if not all) of the technical developments in the paper are straightforward applications of the results in the papers above. Therefore, the technical contribution of the paper is largely incremental. Furthermore, while it is sensible to use random-feature approximation approaches (such as SS and VSS) in GP models, it is very unclear why combining the IP framework with SS approaches makes any sense at all. Indeed, the original IP framework was motivated as a way to deal with the scalability issue in GP models, and the corresponding variational formulation yielded a nice property of an additional regularization term in the variational bound. However, making the prior over a (Equation 9) conditioned on the inducing variables U is rather artificial and lacks any theoretical justification. To elaborate on this, in the IP framework both the latent functions (f in the original paper) and the inducing inputs come from the same GP prior, hence having a joint distribution over these comes naturally. However, in the approach proposed in this paper, a is a simple prior over the weights in a linear-in-the-parameters model, and from my perspective, having a prior conditioned on the inducing variables lacks any theoretical motivation. \n\nThe empirical results are a bit of a mixed bag, as the methods proposed beat (by a small margin) the corresponding benchmarks on 6 out of 10 problems. While one would not expect a proposed method to win on all possible problems (no free lunch), it will be good to have some insights into when the proposed methods are expected to be better than their competitors. \n\nWhile the proposed method is motivated from an uncertainty propagation perspective, only point-error metrics (RMSE) are reported. The paper needs to do a proper evaluation of the full predictive posterior distributions. What is the point of using GPs otherwise?\n\nOther comments:\nI recommend the authors use the notation p(v) = … and q(v) = … everywhere rather than v ~ … as the latter may lead to confusion on how the priors and the variational distributions are defined. \nIt is unnecessary to cite Bishop to explain how one obtains a marginal distribution\nWould it be possible to use the work of Cutajar et al (2017), who use random feature expansions for deep GPs,  in the sequential setting? If so, why aren’t the authors comparing to this?\nThe analysis of Figure 1 needs expanding \nWhat are the performance values obtained with a standard recurrent neural net / LSTM?\n']","[70, -60, -40]","[80, -20, 20]","[""The sentiment score is 70 out of 100 because the reviewer expresses a generally positive view of the paper, recommending it for acceptance and praising it as 'a really good paper' with 'very sound' models. However, they also point out some weaknesses, particularly regarding clarity, which prevents a higher score. The politeness score is 80 out of 100 because the reviewer uses respectful and constructive language throughout, offering congratulations and balancing criticisms with praise. They provide specific, helpful feedback without using harsh or dismissive language. The tone is professional and courteous, though not excessively formal or deferential, hence the score of 80 rather than higher."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, including 'serious lack of discussion or technical insights', 'sloppy' referencing, and 'awkward sentence structures'. The reviewer also asks for numerous clarifications and additional information, indicating dissatisfaction with the current state of the paper. However, it's not entirely negative as the reviewer does acknowledge the authors' work in combining known ideas.\n\nThe politeness score is -20 because while the reviewer isn't overtly rude, the language used is quite direct and critical. Phrases like 'serious lack', 'sloppy', and 'awkward' are somewhat harsh. The reviewer also questions whether the authors have revealed their identity, which could be seen as accusatory. However, the reviewer does provide detailed feedback and suggestions for improvement, which shows some level of engagement and respect for the authors' work, preventing the score from being lower."", ""The sentiment score is -40 because the review is generally critical of the paper's contributions, describing them as 'largely incremental' and questioning the theoretical justification of some approaches. The reviewer also points out mixed empirical results and suggests areas for improvement. However, it's not entirely negative as it acknowledges some positive aspects and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer suggestions for improvement. They use phrases like 'I recommend' and 'It will be good to have' which maintain a respectful tone. The reviewer also acknowledges potential merits of the work and provides detailed explanations for their concerns, which contributes to a relatively polite, albeit critical, review.""]"
"['The paper proposes node embedding methods for applications where nodes are sequentially related. An example application is the ""Wikispeedia"" dataset, in which nodes are connected in a graph, but a datapoint (a wikispeedia ""game"") consists of a sequence of nodes that are visited. Each node is further attributed with textual information.\n\nThe methods proposed are most closely related to skipgrams, whereby the sequence of nodes are treated like words in a sentence. Then, node attributes (i.e., text) and node representations must be capable of predicting neighboring nodes/words. (Fig.s 1/2 are a pretty concise overview of the proposed architecture).\n\nPositively, this is a quite sensible extension and modification of existing ideas in order to support a new (or different) problem setting.\n\nNegatively, I\'d say the applications for this technique are fairly niche, which may limit the paper\'s readership. The method is mostly fairly straightforward and not methodologically groundbreaking (probably borderline in terms of expected methodological contribution for ICLR). I also didn\'t understand whether the theoretical claims were significant.\n\nThe wikispedia/physics experiments feel a bit more like proofs-of-concept rather than demonstrating that the technique has compelling real-world uses. The experiments are quite well fleshed-out and detailed though.\n', 'This paper presents two approaches: one called SENSE-S for embedding nodes in attributed networks; the other one called SENSE for embedding a sequence of nodes. SENSE-S follows the structure of Skip-gram model. The main difference is that SENSE-S considers both node and words in node content as input and output for learning their embedding. For generating embedding vector for a sequence of nodes, SENSE takes summation of cyclically shifted unit-vectors constructed by SENSE-S on nodes in a sequence.    \n\nThe paper is well written with a clear definition of the studied problem and a clear introduction of the presented methods. Evaluation was conducted on two real-world data sets (Wikipedia and citation network). It is an interesting idea to represent a sequence by the summation of cyclically shifted unit-vectors of nodes in a sequence. However, there are several concerns about the work presented in this paper. \n1) the evaluation of SENSE-S is not sufficient. The baseline methods used in comparison are the simple ones that take concatenation of vectors induced from text and graph, or use one for initializing the learning of the other.  There existing several approaches that learn node embedding vectors from attributed graph (considering both the node content text and graph topology structure), such as TADW [1], HSCA [2], PLANE [3],GAE[4], AANE[5], ANRL [6]. SENSE-S should be compared with these methods for showing its effectiveness. \n2) the embedding vector of a node sequence is evaluated by showing the decoding accuracy. It would be more interesting to show how these vectors can be used for some real applications. And, to have high decoding accuracy, the embedding dimension for sequences of 10 nodes should be up to 1024, which is quite expensive for computing and for storage, making the presented method unpractical in real-world applications.   \n\n\n[1] C. Yang, Z. Liu, D. Zhao, M. Sun, E. Y. Chang, Network representation learning with rich text information. IJCAI, 2015\n[2] D. Zhang, J. Yin, X. Zhu, C. ZHang, Homophily, structure, and content augmented network representation learning.  ICDM 2016. \n[3] T. M. V. Le and H. W. Lauw. Probabilistic latent document network embedding.  ICDM, 2014.\n[4] Thomas N Kipf, Max Welling. Variational Graph Auto-Encoders. NIPS Workshop on Bayesian Deep Learning.  2016\n[5] Xiao Huang, Jundong Li, Xia Hu. Accelerated attributed network embedding. SDM 2017.\n[6] Zhen Zhang, Hongxia Yang, Jiajun Bu, Sheng Zhou, Pinggang Yu, Jianwei Zhang, Martin Ester, Can Wang. ANRL: Attributed Network Representation Learning via Deep Neural Networks. IJCAI, 2018\n', 'The authors introduce the problem of learning embeddings that consider both text information and graph structures, as well as the embedding of a sequence of nodes with embeddings.\n\nHowever, the proposed algorithm, SENSE-S, is incremental in the sense of aggregating two simple structures. In the evaluation, it is compared only with the heuristic combination of node2vec and paragraph2vec, not with any existing work about the graph embeddings that incorporate node features even though they are mentioned in the related work.\n\nFurthermore, the objective of node sequence embedding is not clear. What do we want to represent from the embedding of node sequences? It looks like we have to keep the node embeddings anyway, and then what is the problem of just storing node ordering instead of having representation? Or can we aggregate node embeddings in some way with storing the order of nodes? These kinds of questions can be raised, mainly because of uncertain objectives. The description of preserving both ordering and node properties is too vague.\n\nAlso, SENSE does not seem to have any connection with SENSE-S. Why is SENSE-S special to SENSE? Are they independent?\n\nFinally, the authors claim that SENSE is necessary to overcome the space issue that needs q*d dimension. However, from Figure 5, it seems that the proposed algorithm actually needs O(q*d) dimensions to represent the sequence correctly. It is somewhat related to the question about i.i.d. assumption in Theorem 2, where embedding does not guarantee the orthogonality across the dimensions. \n\n* Details\n- In the introduction, ""first"" is repeated in the last paragraph of Page 1.\n- N_G(v) and N_T(\\phi) are said to be independent, but it should be the assumption since they are not the fact.\n- Eq. (2) is not aligned with Eq (3) or (4). Either one needs to be fixed or the derivation needs to be described.\n- How SVM is used needs to be described. Usage of embedding might be different depending on the usage of RBF kernel or linear kernel.\n- Using the smaller number of random walks for Citation Network because it is a larger dataset needs some explanation.\n- The calculation on the improvement percentage is completely misleading. If the accuracy is improved from 95% to 96%, it is about 1% improvement, not 20% improvement based on the error rate calculation.\n- How the training/validation/test sets are split needs more description. Is it split by nodes or edges?\n']","[20, -20, -50]","[50, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as it being a 'sensible extension and modification of existing ideas' and having 'quite well fleshed-out and detailed' experiments. However, they also mention several negative points, including the niche applications, limited methodological contribution, and experiments feeling like 'proofs-of-concept'. This mix of positive and negative comments results in a slightly positive overall sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both positive and negative aspects in a professional manner without using harsh or overly critical language. They provide constructive feedback and balance their critique with positive observations, which contributes to a polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'clear definition', 'interesting idea'), they express significant concerns about the work. The reviewer points out insufficient evaluation and comparison with existing methods, and questions the practicality of the approach. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging strengths before presenting criticisms. They use phrases like 'It is an interesting idea' and 'It would be more interesting to' which maintain a constructive tone. The reviewer also provides specific suggestions and references, which is helpful and considerate. However, the score is not extremely high as the review is still direct in its criticisms without excessive softening language."", ""The sentiment score is -50 because the review is predominantly critical. While it acknowledges the introduction of the problem, it raises several concerns about the proposed algorithm, its evaluation, and the clarity of objectives. The reviewer points out limitations and questions the novelty and effectiveness of the approach. However, it's not entirely negative as it does recognize some aspects of the work.\n\nThe politeness score is 20 because the language used is generally professional and constructive. The reviewer uses phrases like 'However,' and 'Furthermore,' to introduce criticisms rather than using harsh or dismissive language. They also provide specific suggestions for improvement and point out details that need clarification. The tone is direct but not rude, maintaining a level of respect while delivering critique.""]"
"['The paper proposes a novel exploration strategy for self-supervised imitation learning. An inverse dynamics model is trained on the trajectories collected from a RL-trained policy. The policy is rewarded for generating trajectories on which the inverse dynamics model (IDM) currently works poorly, i.e. on which IDM predicts actions that are far (in terms of mean square error) from the actions performed by the policy. This adversarial training is performed in purely self-supervised way. The evaluation is performed by one-shot imitation of an expert trajectory using the IDM: the action is predicted from the current state of the environment and the next state in the expert’s trajectory. Experimental evaluation shows that the proposed method is superior to baseline exploration strategies for self-supervised imitation learning, including random and curiosity-based exploration. \n\nOverall, I find the idea quite appealing. I am not an expert in the domain and can not make comments on the novelty of the approach. I found the writing mostly clear, except for the following issues:\n- the introduction has not made it crystal clear that the considered paradigm is different from e.g. DAGGER and GAIL in that expert demonstrations are used at the inference time. A much wider audience is familiar with the former methods, and this distinction should have be explained more clearly.\n- Section 4.2.: “As opposed to discrete control domains, these tasks are especially challenging, as the sample complexity grows in continuous control domains.” - this sentence did not make sense to me. It basically says continuous control is challenging because it is challenging. \n- I did not understand the stabilization approach. How exactly Equation (7) forces the policy to produce “not too hard” training examples for IDM? Figure 4 shows that it is on the opposite examples with small L_I that are avoided by using \\delta > 0.\n- Table 1 - it is a bit counterintuitive that negative numbers are better than positive numbers here. Perhaps instead of policy’s deterioration you could report the relative change, negative when the performance goes down and positive otherwise?\n\nI do have concerns regarding the experimental evaluation:\n- the “Demos” baseline approach should be explained in the main text! In Appendix S.7 I see that 1000 human demonstrations were used for training. Why 1000, and not 100 and not 10000?  How would the results change? This needs to be discussed. Without discussing this it is really unclear how the proposed method can outperform “Demos”, which it does pretty often.\n- it is commendable that 20 repetitions of each experiment were performed, but I am not sure if it is ever explained in the paper what exactly the upper and lower boundaries in the figures mean. Is it the standard deviation? A confidence interval? Can you comment on the variance of the proposed approach, which seems to be very high, especially when I am looking at high-dimensional fetch-reach results?\n- the results of “HandReach” experiments, where the proposed method works much worse than “Demos” are not discussed in the text at all\n- overall, there is no example of the proposed method making a difference between a “working” and “non-working” system, compared to “Curiosity” and “Random”. I am wondering if improvements from 40% to 60% in such cases are really important. In 7 out of 9 plots the performance of the proposed method is less than 80% - not very impressive. ""Demos"" baseline doesn\'t perform much better, but what would happen with 10000 demonstrations?\n- there is no comparison to behavioral cloning, GAIL, IRL. Would these methods perform better than learning IDM like ""Demos"" does?\n\nI think that currently the paper is slightly below the threshold, due to evaluation issues discussed above and overall low performance of the proposed algorithm. I am willing to reconsider my decision if these issues are addressed.\n', ""The paper proposes an exploration strategy for deep reinforcement learning agent in continuous action spaces. The core of the method is to train an inverse local model (a model that predicts the action that was taken from a pair of states) and its errors as an exploration bonus for a policy gradient agent. The intuition is that its a good self-regulating strategy similar to curiosity that leads the agents towards states that are less known by the inverse model. Seeing these states improves the . There are experiments run on the OpenAI gym comparing to other models of curiosity. The paper is well written and clear for the most part.\n\npros:\n- the paper seems novel and results are promising\n- easy to implement\ncons:\n- seems unstable and not clear how it would scale in a large state space where most states are going to be very difficult to learn about in the beginning like a humanoid body.\n- only accounts for the immediately controllable aspects of the environment which doesn't seem to be the hard part. Understanding the rest of the environment and its relationship to the controllable part of the state seems beyond the scope of this model. Nonetheless I can imagine it helping with initial random motions. \n- from (6) the bonus seems to be unbounded and (7) doesn't seem to fix that. Is that not an issue in general ? Any intuition about that ?"", 'This paper presents a system for self-supervised imitation learning using a RL agent that is rewarded for finding actions that the system does not yet predict well given the current state.  More precisely, an imitation learner I is trained to predict an action A given a desired observation state transition xt->xt+1; the training samples for I are generated using a RL policy that yields an action A to train given xt (a physics engine evaluates xt+1 from xt and A).  The RL policy is rewarded using the loss incurred by I\'s prediction of A, so that moderately high loss values produce highest reward.  In this way, the RL agent learns to produce effective training samples that are not too easy or hard for the learner.  The method is evaluated on five block manipulation tasks, comparing to training samples generated by other recent self-supervised methods, as well as those found using a pretrained expert model for each task.\n\nOverall, this method exploration seems quite effective on the tasks evaluated.  I\'d be curious to know more about the limits and failures of the method, e.g. in other types of environments.\n\nAdditional questions:\n\n- p.2 mentions that the environments ""are intentionally selected by us for evaluating the performance of inverse dynamics model, as each of them allows only a very limited set of chained actions"".  What sort of environments would be less well fit?  Are there any failure cases of this method where other baselines perform better?\n\n- sec 4.3 notes that the self-supervised methods are pre-trained using 30k random samples before switching to the exploration policy, but in Fig 2, the success rates do not coincide between the systems and the random baseline, at either samples=0 or samples=30k --- should they?  if not, what differences caused this?\n\n- figs. 4, 5 and 6 all relate to the stabilizer value delta, and I have a couple questions here:  (i) for what delta does performance start to degrade?  At delta=inf, I think it should be the same as no stabilizer, while at delta=0 is the exact opposite reward (i.e. negative loss, easy samples).  (ii) delta=3 is evaluated, and performance looks decent for this in fig 6 --- but fig 4 shows that the peak PDF of ""no stabilizer"" is around 3 as well, yet ""no stabilizer"" performs poorly in Fig 5.  Why is this, if it tends to produce actions with loss around 3 in both cases?\n']","[-30, 50, 60]","[60, 75, 80]","[""The sentiment score is slightly negative (-30) because while the reviewer finds the idea 'quite appealing', they express several concerns about the experimental evaluation and state that the paper is 'slightly below the threshold'. They are willing to reconsider, but overall the tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects ('commendable that 20 repetitions were performed'), and offers constructive feedback rather than harsh criticism. They also express willingness to reconsider their decision, which is a polite gesture. The language is professional and objective, avoiding any rudeness or overly emotional phrasing."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, promising results, and clear writing. However, they also point out several cons and areas of concern, balancing the positive aspects. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, presents both pros and cons objectively, and phrases criticisms as questions or observations rather than direct attacks. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a polite approach in academic reviews."", ""The sentiment score is 60 (moderately positive) because the reviewer states that the method 'seems quite effective on the tasks evaluated' and shows interest in learning more about the method's limits. The overall tone is constructive and curious rather than critical. The politeness score is 80 (quite polite) due to the respectful and professional language used throughout. The reviewer asks questions in a courteous manner, using phrases like 'I'd be curious to know' and 'Additional questions:' which maintain a polite and collaborative tone. The review focuses on seeking clarification and understanding rather than pointing out flaws, which contributes to its politeness.""]"
"['Summary:\nEslami et al. (2018) proposed a deep neuronal framework for a scene representation and renderer (the Generative Query Networks: GQN), which generate an image from a scene representation and a query camera pose. In this work, the authors use the GQN to estimate the camera pose from a target image. Existing learning approaches are discriminative, meaning that they are trained to output the camera pose in an end-to-end fashion, while this paper proposes a generative method more in the line of hand-crafted methods which still largely outperform learning approaches. Using the GQN with the proposed attention mechanism, the method captures an implicit mapping of the environment at a more abstract level. This implicit representation is then used to optimize the likelihood of the target pose in a probabilistic graphical model framing. They compare their solution to a discriminative baseline, based on a reversed GQN.\n\nPros:\n- As shown in Figure 7, the generative approach seems to capture better the implicit representation associated to the mapping from the scene geometry and the image. \n- The proposed generative solution seems to be more accurate than the discriminative baseline. \n- As shown in Table 1, the proposed attention mechanism allows to focus on relevant parts of the context images, giving flexibility for more complex scenes.\n- Unlike classical discriminative methods, the proposed solution can be easily used in new scenes (different from the one used for the learning) thanks to the representation network. \n\nCons:\n- The contribution seems incremental with respect to Eslami et al. (2018). \n- Lack of comparisons to state of the art, in particular a comparison with PoseNet is necessary.\n- The results are shown only on simple datasets of small images (32x32 pixels). \n- Tradeoff between precision and time computing is necessary to handle large environments because of space discretization. Then, the method seems to be far to be exploited in a real life SLAM application (e.g. autonomous vehicle). \n', '**Summary of the paper**\n\nThis paper studies the problem of visual re-localization, where we are interested in estimating the camera pose of a new image from a set of source images and their camera poses. Instead of explicitly designing the structure of a map of 3D scenes (e.g. occupancy grids or point clouds), the paper proposes implicitly learning an abstract map representation. Specifically, the paper proposes a generative method based on Generative Query Networks (GQNs) augmented with an attention mechanism. The authors apply this model to the visual re-localization problem. To train and test the proposed model, the authors introduce the Minecraft random walk dataset, which consists of images and their camera poses extracted from randomly generated trajectories in the Minecraft environment. The proposed model is compared against a discriminative counterpart, which is trained to directly predict the target camera pose and achieves better MSE.\n\n**Clarity**\n\nAbove average\n\n**Significance**\n\nBelow Average\n\n**Detailed comments**\n\n_Paper Strengths_\n\n- The idea of leveraging generative models\' knowledge of ""maps"" to perform visual localization is interesting. This gives learning frameworks the flexibility of building a latent representaiton of maps which may yield better performance instead of being restricted to a pre-defined representations.  \n- The paper is very well-written and easy to follow. \n- The authors did a good job presenting the proposed methods. The descriptions and formulations are clear. Both Figure 2 and Figure 3 are helpful for understanding the GQNs and the proposed attention mechanism.\n- The patch dictionary for the attention mechanism seems effective especially when dealing with a set of context images capturing the same scene.\n- The authors are honest about the limitations of the proposed framework compared to classic approaches.\n- The visualization of results are clear. Particularly, Figure 5 and Figure 7 give easily interpretable representations of the results.\n\n_Paper Weaknesses_\n\n- Implicitly learning a map of the scene is mentioned as a strength in the paper, but this comes at the high cost of interpretability. Without an explicit map representation, it is difficult to understand the failure cases - does the model not understand the 3D scene well or does the model have a hard time accurately predicting camera poses?\n- Minecraft is an interesting environment for proof of concept, but lacks much of the subtlety of the real world.\n- Building a framework that is able to perform the localization task from real-world scenes is more interesting. Learning generative models of real-world scenes is known to be difficult, which makes this framework impractical. There are google streetview and indoor datasets authors can try to utilize.\n- The aforementioned point is supported by the fact that the localization performance of the proposed model on real-world scenes is missing.  \n- The reviewer does not find enough novelty from the proposed model, which is an iterative improvement on GQNs.\n- The paper only compares the proposed model against its discriminative couterpart, which is not sufficient. While the authors strongly argue that exploiting the proposed implicitly representations of scenes is more beneficial than utilizing the pre-defined explicit representations, the only baseline is using the same implicit representations. Although the reviewer is aware of that this model does not use complete video sequences, benchmarking against a visual monocular SLAM algorithm, like LSD-SLAM [1], would contextualize the claim.\n- Why quantize the discriminative model\'s output? This de-correlates nearby pose values. The paper could benefit from an explanation of not using a straightforward regression over pose variables.\n- Overall, the reviewer does not find enough novelty from any aspects except the idea of utilizing a generative model for visual localization with implocitly learned maps, which is not fully demonstrated in the experiment section (i.e. not compare to baselines using explicit maps). \n- A differentiating factor for this paper could be tackling one of the open problems remaining in SLAM as identified in [2], like lifelong learning or semantic mapping.\n\n\n_Reproducibility_\n\n- Given the clear description in the main paper and the details provided in the appendix, the reviewer believes reproducing the results is possible. \n\n_Conclusion_\n\n- Overall, the reviewer believes this paper is well presented and reproducible. However, the paper does not propose to solve a novel problem, nor does it present a very novel method. Although the idea of using existing generative networks for localization is interesting, the paper misses important baselines relying on explicit map representation and is not sufficiently convincing. Moreover, requiring a generative model significantly limits the possibility of utilizing the proposed model for real-world applications. While the paper does present a new dataset built in Minecraft which is suitable for demonstrating the strengths of the proposed method, the reviewer does not find this significant. Therefore, the reviewer recommends a rejection.\n\n_Reference_\n\n[1] Engel, Jakob, Thomas Schöps, and Daniel Cremers. ""LSD-SLAM: Large-scale direct monocular SLAM."" European Conference on Computer Vision. Springer, Cham, 2014.\n[2] Cadena, Cesar, et al. ""Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age."" IEEE Transactions on Robotics 32.6 (2016): 1309-1332.\n', 'This paper proposes generative approaches to localization without explicit high definition geometric maps. A generative baseline (GQN) and an extension to that with attention is introduced in the context of localization. \n\nThe paper is clearly written, and the relevant previous work is discussed to satisfying degree. \n\nFigures 2 and 3 help understanding the GQN and the proposed attention version a lot. \n\nI am intrigued with the result presented in table 1. especially with the fact that attention is helping the generative method quite a bit, but not so much for the discriminative method. This is not discussed in detail in the paper, I suggest the authors expand their discussion a bit in this direction. \n\nThe second suggestion is in terms of the data. I understand the motivations behind using the minecraft world. however, real data is still quite different than this data, think about various differences in the real world at time of training and test even at the same location texture of sky and lighting will change. On top of this, there is quite a bit of variance in levels of detail compared to the monotonic minecraft world. I suggest using a real dataset for another set of experiments. This can be added as an appendix. \n\nIn general, very good motivation, and intriguing work for the community -- localization with high definition geometric works is tough to scale, and implicit world representations are an important piece in relaxing this dependency. I believe this paper will motive more future work. ']","[20, -60, 80]","[50, 50, 90]","['The sentiment score is slightly positive (20) because the review begins by highlighting several pros of the paper, such as the generative approach capturing better implicit representation, being more accurate than the discriminative baseline, and the attention mechanism allowing focus on relevant parts. However, it also lists significant cons, which temper the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout, presenting both pros and cons in a balanced manner without using harsh or overly critical language. The reviewer acknowledges the strengths of the paper while also pointing out areas for improvement in a constructive way.', ""The sentiment score is -60 because the overall tone of the review is negative, with the reviewer recommending rejection and highlighting several weaknesses of the paper. The reviewer states that the paper lacks novelty, has insufficient comparisons to baselines, and is limited in its real-world applicability. However, the score is not at the extreme negative end because the reviewer does acknowledge some strengths, such as the interesting idea and good presentation.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, even while criticizing the paper. They use phrases like 'The reviewer believes' and 'The paper could benefit from' rather than making blunt or harsh statements. The reviewer also takes care to highlight the paper's strengths before delving into weaknesses, which is a polite approach. However, the score is not extremely high because the review is still direct in its criticisms and does not use overly deferential language."", ""The sentiment score is 80 (positive) because the reviewer expresses clear appreciation for the paper, describing it as 'clearly written' and 'intriguing work'. They state that the paper will motivate future work, which is a strong positive sentiment. The score is not 100 as there are some suggestions for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands ('I suggest'), and balancing critiques with positive feedback. They acknowledge the authors' efforts and the paper's potential impact. The reviewer's tone is consistently professional and constructive, without any harsh or rude language.""]"
"['This paper introduces a data dependent strategy to mask parts of the partial derivatives in the chain rule computation. \n\nTypically with papers proposing modifications of the training regime of the neural network one would expect one of three outcomes:\n - a well justified, mathematically sound method, well tested in simple cases and with some proof of concept results on proper tasks\n - a more heuristic, empirical driven research, where strong results on proper tasks\n - method, however justified, allows us to do something previously impossible, removing some limitations/constraints (like biologically plausible learning etc.)\n\nIn its current form paper seems to lack any of these characteristics. On one hand method lacks any guarantees and on the other paper does not present significant improvements under any approved metrics, nor it introduces new which can be properly quantified. In fact, authors explicitly claim that empirical section ""Note that in these experiments, the purpose is not to achieve state of the art performance, but to exemplify how backdrop can be used and what measure of performance gains one can expect."".  \n\nWith methods like this it is almost obvious that resulting update is not an unbiased gradient estimator of any function. Consequently convergence/learning guarantees that we have for GD or SGD no longer apply. Do authors have any thoughts on how bad can it get? As noted in the text, other methods of ""dropping"" data (such as dropout) don\'t have this issue as they still estimate proper gradients. Here, since dropping is done inside the network only on backwards pass, resulting estimates could, in principle, lead to oscilations, divergence and other issues. If these are not encountered in practice it might be interesting to understand why. \n\nIf authors prefer to go through more empirical path, one would expect at least to see some baselines for tasks proposed, rather than comparing Backdrop to SGD. There are many methods that could be applied in scenarios like this, including dozens forms of dropout (which, as authors note, is not aimed at the same goals, but this does not mean that it will not shine under the metrics introduced, as they are non-standard and so - noone tested them in this exact regime).\n\nI am happy to revisit my rating given authors restructure paper towards one of these paths (or other one which is not listed here).', 'The authors propose to apply Dropout only in the backward pass, by applying a mask sampled from a Bernoulli distribution. They claim that this method can help in situations like optimizing non-decomposable losses where minibatch SGD is not viable. \n\nFirst and foremost, the paper has an acknowledgement paragraph that gives information violating, in my sense, the anonymity requirement. \n\nThis being said, I have other concerns with the paper, and this possible violation didn\'t effect much my rating. \n\nFirst, the authors claim that the proposed method ""is a flexible strategy for introducing data-dependent stochasticity into the gradient"". However, it doesn\'t seem to me that the sampled dropped nodes are data-dependent. \n\nIt is also not clear to me why the proposed method is better suited to non-decomposable losses and hierarchically structured data than the classical Dropout.\n\nMoreover, while the method is clearly related to Dropout, the paper lacks of comparison to this regularizer. \n\nThis being said, the idea is sound, and can have a good impact in for example combining the good aspects of batch-normalization and dropout. However, the authors structured the paper on a completely different argument that doesn\'t convince me for the reasons cited above.     ', 'This paper proposes a stochastic based method, namely Backdrop, for updating the network structures via backpropagation type methods.  Backdrop inserts masking layers along the network; it acts as the identity in the forward pass, but as randomly masks parts of the backward gradient propagation. The paper claims this approach can significantly improves the overall generalization performance. \n\nAlthough some difference to Dropout is summarized in Section 2, I still feel these two methods have almost the same idea, with just different implementation. Actually this Backdrop seems to have one more limitation in the parameter complexity, as it introduces several mask layers but keep the dense structures from other intermediate layers. \n\nThe proposed Backdrop uses Bernoulli distribution to select active variables. This is the very fundamental way in the conventional Dropout method. On the other hand, the authors do not  provide convincing justification how this can guarantee the improvement in subsequent generalization. ']","[-70, -50, -50]","[20, 20, 0]","[""The sentiment score is -70 because the reviewer expresses significant criticism of the paper. They state that the paper lacks any of the expected characteristics of a good research paper in this field, pointing out deficiencies in both theoretical justification and empirical results. The reviewer also mentions that the paper doesn't present significant improvements or introduce new quantifiable metrics. However, it's not entirely negative as the reviewer expresses willingness to revisit their rating if the authors restructure the paper.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone throughout. They use phrases like 'I am happy to revisit my rating' and frame their criticisms as expectations or questions rather than direct attacks. The reviewer also acknowledges the authors' explicit claims about the purpose of their experiments. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the reviewer expresses several concerns and criticisms about the paper, including potential anonymity violation, unclear claims, and lack of comparison to related methods. However, they do acknowledge that the idea is 'sound' and could have a good impact, which prevents the score from being more negative. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively neutral language and phrases like 'in my sense' and 'This being said,' which soften the tone. They also acknowledge potential positive aspects of the work, showing a degree of politeness in balancing criticism with recognition of potential value."", ""The sentiment score is -50 because the reviewer expresses skepticism about the novelty and effectiveness of the proposed method. They suggest that it's very similar to existing methods (Dropout) and point out potential limitations. The lack of positive comments and the questioning of the method's justification indicate a negative sentiment, though not extremely harsh.\n\nThe politeness score is 0 because the language used is neutral and professional. The reviewer doesn't use overly polite language, but also doesn't use any rude or disrespectful phrases. They present their criticisms in a straightforward, matter-of-fact manner without personal attacks or overly harsh language.""]"
"['The paper provides a dynamic sparse reparameterization method allowing small networks to be trained at a comparable accuracy as pruned network with (initially) large parameter spaces. Improper initialization along with a fewer number of parameters requires a large parameter model, to begin with (Frankle and Carbin, 2018).  The proposed method which is basically a global pooling followed by a tensorwise growth allocates free parameters using an efficient weight re-distribution scheme, uses an approximate thresholding method and provides automatic parameter re-allocation to achieve its goals efficiently. The authors empirically demonstrate their results on MNIST, CIFAR-10, and Imagenet and show that dynamic sparse provides higher accuracy than compressed sparse (and other) networks.\n\nThe paper is addressing an important problem where instead of training and pruning, directly training smaller networks is considered. In that respect, the paper does provide some useful tricks to reparameterize and pick the top filters to prune. I especially enjoyed reading the discussion section.\n\nHowever, the hyperbole in claims such as ""first dynamic reparameterization method for training convolutional network"" makes it hard to judge the paper favorably given previous methods that have already proposed dynamic reparameterization and explored. This language is consistent throughout the paper and the paper needs a revision that positions this paper appropriately before it is accepted.\n\nThe proposed technique provides limited but useful contributions over existing work as in SET and DeepR. However, an empirical comparison against them in your evaluation section can make the paper stronger especially if you claim your methods are superior.\n\nHow does your training times compare with the other methods? Re-training times are a big drawback of pruning methods and showing those numbers will be useful.', 'This paper presents a method for training neural networks where an efficient sparse/compressed representation is enforced throughout the training process, as opposed to starting with are large model and pruning down to a smaller size.  For this purpose a dynamic sparse reparameterization heuristic is proposed and validated using data from MNIST, CIFAR-10, and ImageNet.\n\nMy concerns with this work in its present form are two-fold.  First, from a novelty standpoint, the proposed pipeline can largely be viewed as introducing a couple heuristic modifications to the SET procedure from reference (Mocanu, et al., 2018), e.g., substituting an approximate threshold instead of sorting for removing weights, changing how new weights are redistributed, etc.  The considerable similarity was pointed out by anonymous commenters and I believe somewhat understated by the submission.  Regardless, even if practically effective, these changes seem more like reasonable engineering decisions to improve the speed/performance rather than research contributions that provide any real insights.  Moreover, there is no attendant analysis regarding convergence and/or stability of what is otherwise a sequence of iterates untethered to a specific energy function being minimized.\n\nOf course all of this could potentially be overcome with a compelling series of experiments demonstrating the unequivocal utility of the proposed modifications.  But it is here that unfortunately the paper falls well short.  Despite its close kinship with SET, there are surprisingly no comparisons presented whatsoever.  Likewise only a single footnote mentions comparative results with DeepR (Bellec et al., 2017), which represents another related dynamic reparameterization method.  In a follow up response to anonymous public comments, some new tests using CIFAR-10 data are presented, but to me, proper evaluation requires full experimental details/settings and another round of review.\n\nMoreover, the improvement over SET in these new results, e.g., from a 93.42 to 93.68 accuracy rate at 0.9 sparsity level, seems quite modest.  Note that the proposed pipeline has a wide range of tuning hyperparameters (occupying a nearly page-sized Table 3 in the Appendix), and depending on these settings relative to SET, one could easily envision this sort of minor difference evaporating completely.  But again, this is why I strongly believe that another round of review with detailed comparisons to SET and DeepR is needed.\n\nBeyond this, the paper repeatedly mentions significant improvement over ""start-of-the-art sparse compression methods."" But this claim is completely unsupported, because all the tables and figures only report results from a single existing compression baseline, namely, the pruning method from (Zhu and Gupta, 2017) which is ultimately based on (Han et al., 2015).  But just in the last year alone there have been countless compression papers published in the top ML and CV conferences, and it is by no means established that the pruning heuristic from (Zhu and Gupta, 2017) is state-of-the-art.\n\nNote also that reported results can be quite deceiving on the surface, because unless the network structure, data augmentation, and other experimental design details are exactly the same, specific numbers cannot be directly transferred across papers.  Additionally, numerous published results involve pruning at the activation level rather than specific weights.  This definitively sacrifices the overall compression rate/model size to achieve structured pruning that is more naturally advantageous to implementation in practical hardware (e.g., reducing FLOPs, run-time memory, etc.).  One quick example is Luo et al., ""ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression,"" ICCV 2017, but there are many many others.\n\nAnd as a final critique of the empirical section, why not report the full computational cost of training the proposed model relative to others?  For an engineered algorithmic proposal emphasizing training efficiency, this seems like an essential component.\n\n\nIn aggregate then, my feeling is that while the proposed pipeline may eventually prove to be practically useful, presently this paper does not contain a sufficient aggregation of novel research contribution and empirical validation.\n\nOther comments:\n\n- In Table 2, what is the baseline accuracy with no pruning?\n\n- Can this method be easily extended to prune entire filters/activations?', 'Weaknesses:\n\n1-The authors claim that: ""Compared to other dynamic reparameterization methods that reallocate non-zero parameters during training, our approach broke free from a few key limitations and achieved much better performance at lower computational cost."" => However, there is no quantitative experiments related to other dynamic reparameterization methods. There should be at least sparsity-accuracy comparison to claim achieving better performance. I expect authors compare their work at-least with with DEEP R, and NeST even if it is clear for them that they produce better results. \n2-The second and fourth contributions are inconsistent: In the second one, authors claimed that they are the first who designed the dynamic reparameterization method. In the fourth contribution, they claimed they outperformed existing dynamic sparse reparameterization.  Moreover, it seems DEEP R also is a  dynamic reparameterization method because DEEP R authors claimed: ""DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded.""\n3- The authors claimed their proposed method has much lower computational costs, however, there is no running time or scalability comparison. \n\n\nSuggestions:\n1-Authors need to motivate the applications of their work. For instance, are they able to run their proposed method on mobile devices?\n2-For Figure 2 (c,d) you need to specify what each color is.\n3-In general, if you claim that your method is more accurate or more scalable you need to provide quantitative experiments. Claiming is not enough.\n4-It is better to define all parameters definition before you jump into the proposed section. Otherwise, it makes paper hard to follow.  For instance, you didn\'t define the R_l directly (It is just in the Algorithm 1).\n']","[20, -60, -60]","[60, 20, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's importance and contributions, especially praising the discussion section. However, they also express concerns about hyperbole and suggest revisions, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They balance positive feedback with areas for enhancement, maintaining a professional and courteous tone. The reviewer avoids harsh language, instead using phrases like 'I especially enjoyed reading' and offering specific recommendations for strengthening the paper."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty and empirical validation. They state that the paper 'falls well short' in experiments, lacks comparisons to related methods, and makes unsupported claims about improvements over state-of-the-art methods. The reviewer also questions the practical utility and significance of the proposed modifications. However, the score is not at the extreme negative end because the reviewer acknowledges that the method 'may eventually prove to be practically useful.'\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'My concerns are...', 'I believe...', and 'my feeling is that...' which soften the criticism. The reviewer also offers constructive suggestions for improvement, such as including comparisons to related methods and reporting full computational costs. However, the score is not higher because the criticism is direct and the reviewer does not use many overtly polite phrases or compliments."", ""The sentiment score is -60 because the review primarily focuses on weaknesses and suggestions for improvement, indicating a generally negative sentiment. The reviewer points out several significant issues, such as lack of quantitative comparisons, inconsistencies in claims, and missing information. However, it's not entirely negative as the reviewer provides constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer specific suggestions for improvement. The tone is not rude, but rather constructive and aimed at improving the paper. The use of phrases like 'I expect authors to...' and 'It is better to...' shows a polite way of giving recommendations.""]"
"['i have change my rating from 5 to 6 after reading the numerous and thorough rebuttals from the authors. I hope they will incorporate these clarifications and additional experiments into the final version of the paper if accepted.\n\nThe purpose of this paper is presumably to approximate the margin of a sample as accurately as possible. This is clearly an intractable problem. Thus all attacks make some kind of approximation, including this paper. I am still a bit confused about the difference between ""zero-confidence attacks"" and those that don\'t fall into that category such as PGD. Since all of these are approximations, and we cannot know how far we are from the true margin, I don\'t see why these categories help. The authors spend two paragraphs in the introduction trying to draw a distinction but I am still not convinced. \n\nThe proofs provided by the authors assume that convexity and many assumptions, which makes it not very useful for the real world case. What would have been helpful is to show the accuracy of their margin for simple binary toy 2D problems, where the true margin and their approximation can be visualized. This was not done. This reduces the paper to an empirical exercise rather than a true understanding of their method\'s advantages and limitations.\n\nFinally, the experimental results do not show any significant advantage over PGD, either in running time (they are slower) or norm perturbation. Thus their novelty rests on the definition of zero confidence attack, and of the importance of such a attack. So clarifying the above question will help to judge the paper\'s novelty.\n\n', 'The authors propose a new method for constructing adversarial examples called MarginAttack. The method is inspired by Rosen\'s algorithm, a classical algorithm in constrained optimization. At its core, Rosen\'s algorithm (instantiated for adversarial examples) alternates between moving towards the set of misclassified points and moving towards the original data point (while ensuring that we do not move too far away from the set of misclassified points). The authors provide theoretical guarantees (local convergence) and a broad set of experiments. The experiments show that MarginAttack finds adversarial examples with small distortion (as good as the baselines or slightly better), and that the algorithm runs faster than the Carlini-Wagner (CW) baseline (but slower than other methods).\n\nThe authors make a distinction between ""fixed perturbation"" attacks and ""zero confidence"" attacks. The former finds the strongest attack within a given constrained set, while the latter finds the smallest perturbation that leads to a misclassification. Method such as projected gradient descent fall into the ""fixed perturbation"" category, while MarginAttack and CW belong to the ""zero confidence"" category. The authors claim that zero confidence attacks pose a harder problem and hence mainly compare their experimental results to the CW attack. Indeed, their results show that MarginAttack is 3x - 5x faster than CW and sometimes achieves smaller perturbations.\n\nFirst of all, I would like to emphasize that the authors conducted a thorough experimental study on multiple datasets using multiple baseline algorithms. Unfortunately, the comparison to CW and PGD still leaves some questions in my opinion:\n\n- The authors state that CW does an internal binary search over the Lagrangian multiplier, and that this search goes for up to 10 steps. As a result, it is not clear whether the running time benchmarks are a fair comparison since MarginAttack does not automatically tune its parameters. To the best of my knowledge, the CW implementation in Cleverhans is specifically set up so that the user does not need to tune a large number of hyperparameters (the implementation accepts a running time overhead to achieve this). Since MarginAttack also contains multiple hyperparameters (see Table 4), it would be interesting to see how the running time of MarginAttack compares to that of a tuned CW implementation without the binary search.\n\n- The authors explicitly state that the step sizes for CW were tuned for best performance, but do not mention this for PGD. For a fair comparison, the step sizes used for PGD should also be (approximately) tuned. Moreover, it is not clear why PGD is only used for an l_inf comparison and not a l_2 comparison.\n\n- In the introduction, the authors emphasize the distinction between fixed perturbation attacks and zero confidence attacks. However, from an optimization point of view, these two notions are clearly related and a fixed perturbation attack can be converted to a small perturbation / zero confidence attack via a binary search over the perturbation size. While one would indeed expect an overhead due to the binary search, it is not clear a priori how large this overhead needs to be to achieve a competitive zero confidence attack with PGD (especially with a tuned step size for PGD, see above).\n\nI would be grateful if the authors could provide their view on these points. Until then, I will assign a rating of 5 since tuning the parameters of optimization algorithms is crucial for a fair comparison.\n\n\nAdditional comments:\n\n- In the introduction, the authors equate white-box attacks with access to gradient information. But generally a white-box attack is understood as an attack that has arbitrary access to the target network. It may be helpful for the reader to clarify this.\n\n- In the second paragraph of the introduction, the authors claim that fixed perturbation attacks and zero confidence attacks differ significantly. But as pointed out above, it is possible to convert a fixed perturbation attack to a zero confidence attack via a binary search. So it is not clear that there is a large gap in difficulty. Moreover, the authors state that fixed perturbation attacks often come with theoretical guarantees. But to the best of my knowledge, there is no comprehensive theory that describes when a fixed perturbation attack should be expected to succeed in attacking a commonly used neural network.\n\n- On top of Page 2, the authors claim that zero-confidence attacks are a more realistic attack setting. Why is that?\n\n- The authors state that JSMA (Papernot et al., 2016) is one of the earliest works that use gradient information for constructing adversarial examples. However, L-BFGS as employed by Szegedy et al., 2013 also uses gradient information. Moreover, the authors may want to cite the work of Biggio et al. from 2013 (see the survey https://arxiv.org/abs/1712.03141).\n\n- Since all distances referred to by d(x, y) seem to be norms (and the paper relies on the existence of dual norms), it may be more clear for the reader to use the norm notation || . || from the beginning.', ""This paper proposes an efficient zero-confidence attack algorithm, MARGINATTACK, which uses the modified Rosen's algorithm to optimize the same objective as CW attack. Under a set of conditions, the authors proved convergence of the proposed attack algorithm. My main concern about this paper is why this algorithm has a better performance than CW attack? I would suggest comparing with CW attack under different sets of hyper-parameters.\n\nMinor comment:\nThe theoretical proof depends on the convexity assumption, I would also suggest comparing the proposed attack with CW and other benchmarks on some simple models that satisfy the assumptions.""]","[-20, -20, -20]","[50, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer has increased their rating, they still express confusion and skepticism about key aspects of the paper. They point out several limitations and areas where they feel the paper falls short, such as the lack of visualization for simple cases and the absence of significant advantages over existing methods. However, the tone is not entirely negative as they acknowledge the authors' thorough rebuttals and express hope for improvements in the final version. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism and instead framing their concerns as areas for clarification or improvement. They acknowledge the authors' efforts in responding to previous feedback and use phrases like 'I hope' and 'what would have been helpful' rather than making demands, which contributes to a polite tone overall."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the thorough experimental study and some positive aspects of the work, they express several concerns and questions about the methodology and comparisons. The reviewer assigns a rating of 5 (out of 10), indicating a somewhat negative overall assessment. The politeness score is positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and phrases criticisms as questions or requests for clarification. The reviewer uses phrases like 'I would be grateful if the authors could provide their view' and 'it may be helpful for the reader to clarify', which contribute to a polite tone. However, the score is not extremely high as the review maintains a professional, rather than overly deferential, tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express a 'main concern' about the algorithm's performance compared to CW attack. This indicates some skepticism about the work's effectiveness. The reviewer also suggests additional comparisons and experiments, implying that the current work may be incomplete. However, the tone is not overwhelmingly negative, hence the moderate negative score. The politeness score is positive (60) because the reviewer uses respectful language throughout. They frame their concerns as suggestions ('I would suggest...') rather than demands, and use polite phrases like 'My main concern' instead of more critical language. The review also offers constructive feedback for improvement, which is a polite way to address shortcomings. The language is professional and courteous, though not excessively formal or deferential, leading to a moderately high politeness score.""]"
"['The paper proposes a compositional generative model for GANs. Basically, assuming existence of K objects in the image, the paper creates a latent representation for each object as well as a latent representation for the background. To model the relation between objects, the paper utilizes the multi-head dot-product attention (MHDPA) due to Vaswani et a. 2017. Applying MHDPA to the K latent representations results in K new latent representations. The K new representations are then fed into a generator to synthesize an image containing one object. The K images together with the synthesized background image are then combined together to form the final image. The paper compares to the proposed approach to the standard GAN approach. The reported superior performance suggest the inductive bias of compositionality of scene leads to improved performance.\n\nThe method presented in the paper is a sensible approach and is overall interesting. The experiment results clearly shows the advantage of the proposed method. However, the paper does have several weak points. Firs of all, it misses an investigation of alternative network design for achieving the same compositionality. For example, what would be the performance difference if one replace the MHDPA with LSTM. Another weak point is that it is unclear if the proposed method can be generalize to handle more complicated scene such as COCO images as the experiments are all conducted using very toy-like image datasets. ', 'This paper explores compositional image generation. Specifically, from a set of latent noises, the relationship between the objects is modelled using an attention mechanism to generate a new set of latent representations encoding the relationship. A generator then creates objects separately from each of these (including alpha channels). A separate generator creates the background. The objects and background are finally combined in a final image using alpha composition. An independent setting is also explored, where the objects are directly sampled from a set of random latent noises.\n\nMy main concern is that the ideas, while interesting, are not novel, the method not clearly motivated, and the paper fails to convince. \n\nIt is interesting to see that the model was able to somewhat disentangle the objects from the background. However, overall, the experimental setting is not fully convincing. The generators seem to generate more than one object, or backgrounds that do contain objects. The datasets, in particular, seem overly simplistic, with background easily distinguishable from the objects. A positive point is that all experimented are ran with 5 different seeds. The expensive human evaluation used does not provide full understanding and do not seem to establish the superiority of the proposed method.\n\nThe very related work by Azadi et al on compositional GAN, while mentioned, is not sufficiently critiqued or adequately compared to within the context of this work.\n\nThe choice of an attention mechanism to model relationship seems arbitrary and perhaps overly complicated for simply creating a set of latent noises. What happens if a simple MLP is used? Is there any prior imposed on the scene created? Or on the way the objects should interact?\nOn the implementation side, what MLP is used, how are its parameters validated?\n\nWhat is the observed distribution of the final latent vectors? How does this affect the generation process? Does the generator use all the latent variables or only those with highest magnitude? \nThe attention mechanism has a gate, effectively adding in the original noise to the output — is this a weighted sum? If so, how are the coefficient determined, if not, have the authors tried?\n\nThe paper goes over the recommended length (still within the limit) but still fails to include some important details —mainly about the implementation— while some of the content could be shortened or moved to the appendix. Vague, unsubstantiated claims, such as that structure of deep generative models of images is determined by the inductive bias of the neural network are not really explained and do not bring much to the paper.', ""[Overview]\n\nIn this paper, the authors proposed a compositional image generation methods that combines multiple objects and background into the final images. Unlike the counterpart which compose the images sequentially, the proposed method infer the relationships between multiple objects through a relational network before sending the hidden vectors to the generators. This way, the method can model the object-object interactions during the image generation. From the experimental results, the authors demonstrated that the proposed k-GAN can generate the images with comparable or slightly better FID compared with baseline GAN, and achieve plausible performance under the human study.\n\n[Strengthes]\n\n1. This paper proposed an interesting method for compositional image generation. Unlike the counterparts like LR-GAN, which generate foreground objects recurrently, this method proposed to derive the relationships between objects in parallel simultaneously. This kind of relational modeling has been seen in many other domains. It would be nice to see it can be applied to the compositional image generation domain.\n\n2. The authors tried multiple synthesized datasets, including multi-MNIST and its variants, CLEVR. From the visualization, it is found that the proposed k-GAN can learn to disentangle different objects and the objects from the background. This indicates that the proposed model indeed capture the hidden structure of the images through relational modeling. The human study on these generated images further indicate that the generated images based on k-GAN is better than those generated by baseline GAN.\n\n[Weaknesses]\n\n1. The main contribution of this paper fall to the proposed method for modeling the relational structure for multiple objects in the images. In the appendix, the authors presented the results for the ablated version which does not consider the relationships. As the authors pointed out, these results are a bit counterintuitive and concluded that FID is not a good metrics for evaluating compositional generation. However, as far as I know, the compositional generation can achieve much better Inception scores on CIFAR-10 in LR-GAN paper (Yang et al). Combining the results on MNIST in LR-GAN paper, I would suspect that the datasets used in this paper are fairly simple and all methods can achieve good results without much efforts. It would be good to show some results on more complicated datasets, such as face images with background, or cifar-10. Also, the authors did not present the qualitative results for independent version of k-GAN. Meanwhile, they missed an ablated human study when the relational modeling is muted. I would like to see how the generated images without modeling relationships look like to humans.\n\n2. Following the above comment, I think the datasets used in this paper is relatively simpler. In MM and CLEVR, the foreground objects are digits or simple cubes, spheres or cylinders. Also, the background is also simpler for these two datasets. Though CIFAR10+MM has a more complicated background, it is trivial for the model to distinguish the foregrounds from the backgrounds. Again, the authors should try more complicated datasets.\n\n3. Though the proposed method can model the relationship between objects simultaneously, I doubt its ability to  really being able to disentangle the foregrounds from the backgrounds. Since the background and foregrounds are both whole images, which are then combined with an alpha blending, the model cannot discover the conceptually different properties for foreground and background that foregrounds are usually small than background and scattered at various locations. Actually, this has been partially demonstrated by Figure 4. In the last row, we can find one sphere is in the background image. I tend to think the proposed model performs similar to Kwak & Zhang's paper without a strong proof for the authors that the relational modeling plays an important role in the model.\n\n4. It would be nice to perform more analysis on the trained k-GAN. Given the training set, like MM or CLEVR, I am wondering whether k-GAN can learn some reasonable relationship from the datasets. That is, whether it is smart enough to infer the right location for each objet by considering the others. This analysis can be performed, how much occlusions the generated images have compared with the real images. For example, on CLEVR, I noticed from the appendix that the generated CLEVR images base on k-GAN actually have some severe occlusions/overlaps.\n\n[Summary]\n\nIn this paper, the authors proposed an interesting method for image generation compositionally. Instead of modeling the generation process recurrently, the authors proposed to model the relationships simultaneously in the hidden vector space. This way, the model can generate multiple foreground objects and backgrounds more flexibly. However, as pointed above, the paper missed some experiment, ablation study and analysis to demonstrate the relational modeling in the image generation. The author need to either try more complicated images or add deeper analysis on the recent experimental results.""]","[50, -50, 20]","[75, 20, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting approach and clear experimental results showing advantages. However, they also point out weak points, creating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'sensible approach' and 'overall interesting' before discussing limitations, maintaining a professional and courteous tone throughout."", ""The sentiment score is -50 because the review expresses significant concerns about the paper's novelty, motivation, and convincingness. The reviewer states that 'the ideas, while interesting, are not novel, the method not clearly motivated, and the paper fails to convince.' However, it's not entirely negative as the reviewer acknowledges some positive aspects, such as the model's ability to disentangle objects from the background and the use of multiple seeds in experiments. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'My main concern is...' and 'It is interesting to see...'. The reviewer also balances criticism with positive observations. However, the language is not overly polite or deferential, maintaining a neutral, objective tone typical of academic reviews."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the paper's strengths and interesting approach, but also points out several weaknesses and areas for improvement. The overall tone is constructive rather than overtly negative or positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands, and acknowledges the positive aspects of the work. Phrases like 'It would be nice to see' and 'I would like to see' indicate a polite approach to criticism. The reviewer also uses neutral language when pointing out weaknesses, avoiding harsh or judgmental terms.""]"
"['The paper studies the benefit of an anisotropic gradient covariance matrix in SGD optimization for training deep network in terms of escaping sharp minima (which has been discussed to correlate with poor generalization in recent literature). \n\nIn order to do so, SGD is studied as a discrete approximation of stochastic differential equation (SDE). To analyze the benefits of anisotropic nature and remove the confounding effect from scale of noise, the scale of noise in the SDE is considered fixed during the analysis. The authors identify the expected loss around a minimum as the efficient of escaping the minimum and show its relation with the hessian and gradient covariance at the minimum. It is then shown that when all the positive eigenvalues of the covariance matrix concentrate along the top eigenvector and this eigenvector is aligned with the top eigenvector of the Hessian of the loss w.r.t. the parameters, SGD is most efficient at escaping sharp minima. These characteristics are analytically shown to hold true for a 1 hidden layer network and experiments are conducted on toy and real datasets to verify the theoretical predictions.\n\nComments:\n\nI find the main claim of the paper intuitive-- at any particular minimum, if noise in SGD is more aligned with the direction along which loss surface has a large curvature (thus the minimum is sharp along this direction), SGD will escape this minimum more efficiently. On the other hand, isotropic noise will be wasteful because a sample from isotropic noise distribution may point along flat directions of the loss even though there may exist other directions along which the loss curvature is large. However, I have several concerns which I find difficult to point out because *many equations are not numbered*. \n\n1. In proposition 2, it is assumed under the argument of no loss of generality that both the loss at the minimum L_0=0 and the corresponding theta_0 =0. Can the authors clarify how both can be simultaneously true without any loss of generality?\n2. A number of steps in proposition 2 are missing which makes it difficult to verify. When applying Ito\'s lemma and taking the integral from 0 to t, it is not mentioned that both sides are also multiplied with the inverse of exp(Ht).\n3. In proposition 2, when computing E[L(theta_t)] on page 12, the equalities after line 3 are not clear how they are derived. Please clarify or update the proof with sufficient details.\n4. It is mentioned below proposition 2 that the maximum of Tr(H. Sigma) under constraint (6) is achieved when Sigma* = Tr(Sigma). lambda_1 u1.u1^T, where lambda_1 is the top eigenvalue of H. How is lambda_1 a factor in Sigma*? I think Sigma* should be Tr(Sigma). u1.u1^T because this way the sum of eigenvalues of Sigma remains unchanged which is what constraint (6) states.\n5. The proof of proposition 5 is highly unclear.Where did the inequality ||g_0(theta)||^2 <= delta.u^TFu + o(|delta|) come from? Also, the inequality right below it involves the assumption that u^Tg_0 g_0u <= ||g_0||^2 and no justification has been provided behind this assumption.\n\n\nRegarding experiments, the toy experiment in section 5.1 is interesting, but it is not mentioned what network architecture is used in this experiment. I found the experiments in section 5.3 and specifically Fig 4 and Fig 7 insightful. I do have a concern regarding this experiment though. In the experiment on FashionMNIST in Fig 4, it can be seen that both SGD and GLD 1st eigvec escapes sharp minimum, and this is coherrent with the theory. However, for the experiment on CIFAR-10 in Fig 7, experiment with GLD 1st eigvec is missing. Can the authors show the result for GLD 1st eigvec on CIFAR-10? I think it is an important verification of the theory and CIFAR-10 is a more realistic dataset compared with FashionMNIST.\n\nA few minor points:\n\n1. In the last paragraph of page 3, it is mentioned that the probability of escaping can be controlled by the expected loss around minimum due to Markov\'s inequality. This statement is inaccurate. A large expected loss upper bounds the escaping probability, it does not control it.\n2. Section 4 is titled ""The anisotropic noise of SGD in deep networks"", but the sections analyses a 1 hidden layes network. This seems inappropriate.\n3. In the conclusion section, it is mentioned that the theory in the paper unifies various existing optimization mentods. Please clarify.\n\nOverall, I found the argument of the paper somewhat interesting but I am not fully convinced because of the concerns mentioned above.', 'The authors studied the effect of the anisotropic noise of SGD on the algorithm’s ability to escape from local optima. To this end, the authors depart from the established approximation of SGD in the vicinity of an optimum as a continuous-time Ornstein-Uhlenbeck process. Furthermore, the authors argue that in certain deep learning models, the anisotropic noise indeed leads to a good escaping from local optima.\n\nProposition 3 (2) seems to assume that the eigenvectors of the noise-covariance of SGD are aligned with the eigenvectors of the Hessian. Did I understand this correctly and is this sufficient? Maybe this is actually not even necessary, since the stationary distribution for the multivariate Ornstein-Uhlenbeck process can always be calculated (Gardiner; Mandt, Hoffman, and Blei 2015–2017)\n\nI think this is a decent contribution.\n\n', 'This paper studies the effort of anisotropic noise in stochastic optimization algorithms. The goal is to show that SGD escapes from sharp minima due to such noise. The paper provides preliminary empirical results using different kinds of noise to suggest that anisotropic noise is effective for generalization of deep networks.\n\nDetailed comments:\n\n1. I have concerns about the novelty of the paper: It builds heavily upon previous work on modeling SGD as a stochastic differential equation to understand its noise characteristics. The theoretical development of this manuscript is straightforward until simplistic assumptions such as the Ornstein-Uhlenbeck process (which amounts to a local analysis of SGD near a critical point) and a neural network with one hidden layer. Similar results have also been in the the literature before in a number of places, e.g., https://arxiv.org/abs/1704.04289 and references therein.\n\n2. Proposition 4 looks incorrect. If the neural network is non-convex, how can the positive semi-definite Fisher information matrix F sandwich the Hessian which may have strictly negative eigenvalues at places?\n\n3. Section 5 contains toy experiments on a 2D problem, a one layer neural network and a 1000-image subset of the FashionMNIST dataset. It is hard to validate the claims of the paper using these experiments, they need to be more thorough. The Appendix contains highly preliminary experiments on CIFAR-10 using VGG-11.\n\n4. A rigorous theoretical understanding of SGD with isotropic noise or convergence properties of Lagevin dynamics has been developed in the literature previously, it’d be beneficial to analyze SGD with anisotropic noise in a similar vein.']","[-20, 50, -50]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer finds some aspects of the paper interesting, they express several concerns and are 'not fully convinced' by the arguments. The review begins with a neutral tone, acknowledging the intuitive nature of the main claim, but then lists multiple technical concerns and requests for clarification. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as requests for clarification or additional information, and acknowledges positive aspects of the work. They use phrases like 'Can the authors clarify' and 'Please clarify or update' which maintain a polite tone while pointing out issues. The reviewer also notes aspects they found 'interesting' and 'insightful', balancing criticism with positive feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the work as a 'decent contribution' and shows interest in the topic, asking clarifying questions. However, they don't express strong enthusiasm. The politeness score is 20 (slightly polite) as the reviewer uses neutral language without any rudeness, and phrases their question politely ('Did I understand this correctly?'). The tone is professional and respectful, but not overtly warm or effusive."", ""The sentiment score is -50 because the review expresses several concerns and criticisms about the paper, including lack of novelty, potential errors, and insufficient experimental validation. However, it's not entirely negative as it acknowledges the paper's goals and suggests improvements. The politeness score is 20 because the reviewer uses professional and neutral language, avoiding harsh criticism. They offer constructive feedback and suggestions for improvement, which is polite. However, the tone is not overly warm or complimentary, maintaining a professional distance.""]"
"['This paper proposes to use 8/4-bit approximation of activations to save the memory cost during gradient computation.  The proposed technique is simple and straightforward. On the other hand, the proposed method only saves up to a constant cost of the storage. With the constant factor (4x, 8x) depending on whether fp16 or fp32 is used during computation. Notably, there is a small but noticeable accuracy drop in the final trained model using this mechanism.\n\nThe alternative method, gradient checkpointing, can bring sublinear memory improvement, with at most 25%  compute overhead, with no loss of accuracy drop.\n\nAs a result, the proposed method has a limited use case. The author did mention, during the response that the method could be combined further with the sublinear checkpointing. However, since sublinear checkpointing already brings in significant savings, it is unclear whether low bit compression is necessary.\n\nGiven the limited technical novelty(can be described as oneliner ""store forward pass in 4/8 bit fixed point""),  limited applicable scenarios, and limited improvement it can buy(4x memory saving with accuracy drop), I think this is a boarder-line paper\n\nOn the positive side, the empirical result could still be interesting to some readers in the ICLR community, the paper could be further improved by comparing more numerical representations, such as fp16 and other floating point formats such as unum.\n', ""The authors detail a procedure to reduce the memory footprint of deep networks by quantization of the activations only on back propagation. While this scheme does not benefit from computational speedups of activation quantization on both passes (and indeed has a slight computational overhead), the authors demonstrate that for common convolutional architectures it nicely preserves the accuracy of computation by computing the forward pass at full accuracy and limiting propagation of errors in the backward pass. This is possible because the majority of errors are introduced in gradient calculation of the weights and not the inputs each layer. The authors also wisely perform quantization after batch normalization and use the known mean and variance of the activations to scale the quantization and reduce errors. They demonstrate very slight drops in performance accuracy for ResNets on Cifar10, Cifar100, and ImageNet with memory compression factors up to 8. They also point to natural future directions such as using vector quantization to better leverage the activation statistics. The paper is also very clearly written with appropriate references to the relevant literature. \n\nAn area of improvement I could see for the paper would be to demonstrate the utility of the reduced memory footprint. Their motivation clearly outlines that reducing memory can allow for larger batch sizes and larger networks that can improve the performance of training, but the authors do not demonstrate an example of this principle. They do mention that they are able to train with a larger batch size on ImageNet without combining batches, but more quantitative evidence of improvements in wall clock time (for different batch sizes) or improvement in performance (for larger networks) would help support the arguments of the paper. Given that the authors are focusing on single device training, they don't have to necessarily improve the state of the art, but a relative comparison would be illustrative. Also, specific measurements of the change in memory footprint for real networks would be helpful. "", 'In this paper the authors describe a quantization approach for activations of the neural network computation to improve the memory efficiency of neural network training and thus training efficiency of a single worker.\n\nPrior work\n-----------------\nThey compare the proposed method with other approaches involving the quantization of gradients or recomputation of activations in a sub-graph during back-propagation. However the literature survey lacks survey of more relevant quantization techniques e.g. [1]. \n[1] : Hubara, Itay, et al. ""Quantized neural networks: Training neural networks with low precision weights and activations."" The Journal of Machine Learning Research 18.1 (2017): 6869-6898.\n\nexperimental setup\n-----------------------------\nA more formal description of experimental setup assuming a general reader not familiar with the specific toolkits is advised. Any toolkit specific details like how the layer-wise forward & backward propagation is done via separate sess.run calls can be delegated to an appendix or footnote. Further given that the authors have chosen not to utilize the auto-diff functionality or other computation graph optimization features provided by Tensorflow; and given that they are even manually managing the memory allocation it is not clear why they are relying on this toolkit.  Irrespective of this choice, this section could be re-written to make the implementation description more accessible to a general reader and toolkit specific details could specified separately.\n\nReg. manual memory management - The authors specify how common buffers are being used for storing activations and gradients across layers. Given that typical neural network models need not be composed of homogenous layer types which can actually share the buffers it would be useful to add a detail on how much efficiency is achieved by reducing the memory allocation calls for the architectures being used in this paper.\n\n\nresults\n-----------\nComparisons with prior work using other quantization methods to achieve memory efficiency is lacking.']","[-30, 80, -30]","[50, 70, 20]","[""The sentiment score is -30 because the reviewer expresses several concerns about the paper's limited novelty, applicability, and improvement, calling it a 'border-line paper'. However, they do mention some positive aspects, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement without being harsh or dismissive. They balance negative points with positive ones and use phrases like 'could be further improved' which maintain a polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the work as 'clearly written' and praise the authors for their 'wise' choices in methodology. The reviewer acknowledges the paper's contributions and potential future directions. The only criticism is framed as an 'area of improvement,' suggesting overall approval with minor suggestions. The politeness score is 70 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'wisely perform' and 'appropriate references,' showing respect for the authors' work. Even when suggesting improvements, the language remains courteous, using phrases like 'An area of improvement I could see' rather than direct criticism. The reviewer balances praise with constructive feedback, maintaining a professional and polite tone throughout the review."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the authors' work, they point out several areas for improvement. The review highlights lacking literature survey, suggests a more formal description of the experimental setup, and notes missing comparisons with prior work. These criticisms outweigh the neutral opening statement. The politeness score is slightly positive (20) as the reviewer uses professional language throughout, offering constructive feedback without harsh criticism. They use phrases like 'is advised' and 'it would be useful to add' which maintain a respectful tone while suggesting improvements.""]"
"[""Revision:\n\nThe authors have took in the feedback from myself and the other reviewers wholeheartedly, and have clearly worked hard to improve the results, and the paper during the revision process. In addition, their code release encourages easy reproducibility of their model, which imo is needed for this work given the non-conventional nature of the model (that being said, the paper itself is well written and the authors have done sufficiently well in explaining their approach, and also the motivation behind it, as per my original review). The code is relatively clear and self-contained demonstrating their experiments on MNIST, CelebA demonstrating the use of the visual sketch model.\n\nI believe the improvements, especially given the compute resources available to the authors, warrant a strong accept of this work, so I revised my score to 9. I also believe this work will be of value to the ICLR community as it offers alternate, less explored approaches compared to methods that are typically used in this domain. I'm excited to see more in the community explore biologically inspired approaches to generative models, and I think this work along with the code base will be an important base for other researchers to use as a reference point for future work.\n\nOriginal Review below:\n\nSummary: They propose a biologically motivated short term attentive working memory (STAWM) generative model for images. The architecture is based on Hebbian Learning (i.e. associative memories are represented in the weight matrices that are dynamically updated during inference by a modified version of Hebbian learning rule). These memories are sampled from glimpses on an input image (using attention on contextual states, similar to [1]), in addition to a latent, query state. This model learns a representation of images that can be used for sequential reconstruction (via a sequence of updates, like a sketchpad, like DRAW [1], trained in an unsupervised manner). These memories produced by drawing can also be used for semi-supervised classification (achieves very respectable and competitive results for MNIST and CIFAR-10).\n\nThis paper is beautifully written, and the biological inspiration, motivation behind this work, and links to neuroscience literature as well as relation to existing ML work (even recent papers) is well stated. The main strength of this paper is that the author went from a biologically inspired idea to a complete realization of the idea in algorithmic form. The semi-supervised classification results are competitive to SOTA, and although the CIFAR-10 reconstruction results are not great (especially compared to generative adversarial models or recent variation models [2]), I think the approach is coming from a very different angle that is different enough compared to the literature to warrant some attention, or at least a glimpse, so to speak, from the broader community. The method may offer new ways to interpret ML models that is current models lack, which in itself is an important contribution. That being said, the fact that most adversarial generative models achieved a far better performance raises concern on the generalization ability of these memory-inspired learned representations, and I look forward to seeing future work investigate this area in more detail.\n\nThe authors also took great care in writing details for important parts of the experiments in the Appendix section, and open sourced the implementation to reproduce all their experiments. Given the complex nature of this model, they did a great job in writing a clear explanation, and provided enough details for the community to build biologically inspired models for deep networks. Even without the code, I felt I might have been able to implement most of the model given the detail and clarity of the writing, so having both available is a great contribution.\n\nI highly recommend this paper for acceptance, with a score of 8 (edit: revised to 9 after rebuttal period). The paper might warrant a score of 9 if they had also achieved higher quality results for image generation, on Celeb-A or demonstrated results on ImageNet, and provided more detailed analysis about drawbacks of their approach vs conventional generative models.\n\n[1] https://arxiv.org/abs/1502.04623\n[2] https://arxiv.org/abs/1807.03039\n\n"", 'The paper proposes a novel Hebb-Rosenblatt working memory model to augment the recurrent attention model and achieves competitive results on the MNIST dataset. Some results on CIFAR and Celeb-A datasets are also shown. The code is released anonymously which substantiated the reproducibility of the results; however, I haven’t physically run the code to verify it.\n\nMotivation: First, as much as I appreciate the research direction of combining recurrent attention models and working memory, the use of recurrent attention models is not well motivated throughout the article. It it of course biologically inspired, but the engineering benefit is not obvious. It has the benefit of model compression, using less parameters to process the attended region, yet pooling mechanisms can also achieve similar effect. It also has the benefit of model interpretability, but for vanilla feed-forward counterparts, it is also possible to visualize salient regions that impact the decisions. While feed-forward CNNs process all regions in parallel, sequential models will be much slower. The core question is the following, if the final task is just image classification, why is sequential processing necessary? The author should spend some text explaining why studying recurrent attention model + working memory is important. Ideally, if the author could consider tasks other than image classification, which could potentially highlight the need for sequential processing and working memory.\n\nNotation clarity: The clarity of model notation could be significantly improved. I am confused what is `e`, and my guess it is the layer I input. Figure 1 does not help my understanding. Notations such as \\mu, \\nu, M are left unexplained.\n\nUnderstanding of the model: Although Hebbian learning rule is a well established mechanism, the article doesn’t provide much insight into why the rule is applied here but rather just stipulates them in Section 3.1 as the overall formulation of the memory network. What would be the objective function for such an update rule (e.g. the delta decay term corresponds to a L2 weight decay term)? For the applications studied in the paper, i.e. image classification, why does the model need to ever forget?\n\nCIFAR/Celeb-A experiments: There is no tabulated results for these experiments. I only see CIFAR gets 93.05% accuracy, without mention of any baselines. Since attention mechanisms are used here, it would be a much stronger argument to report results on higher resolution images than CIFAR (which is 32x32).\n\nModel interpretability: Model interpretability is often one of the biggest selling point of attention-based models. However, by examining the glimpse locations on CIFAR datasets, the model learns to look at the whole image for all glimpses, which hurts the argument of using a recurrent attention model. Also for MNIST experiments, the best number is achieved by using S_g=28, which has the glimpse size of the whole image. The author claims that it can learn a good representation despite the not so good looking glimpse visualization, but so can regular feed-forward CNNs.\n\nComparison to VAEs: Since VAE formulations are used, it would be good if the authors can compare the model with vanilla VAE and convolutional VAEs, both in terms of classification accuracy and reconstructed sample quality.\n\nComparison to DRAW: It is also recommended to show more visualization comparison to DRAW, and pinpoint the differences of using a canvas based memory vs. the proposed Hebb-Rosenblatt working memory.\n\nIn conclusion, I think the paper opens a promising direction of combining recurrent attention models and working memory networks. I believe it is a huge amount of engineering effort to make this model to work, as we can see in the Appendix and the released code base. However, there are several issues as I pointed above, most notably the motivation, and understanding of the models. The experiments on CIFAR and Celeb-A could been done more thoroughly, and I also believe that it would make more impact if the authors can show experiments other than image classification that highlight the need for a recurrent attention model equipped with working memory. Based on the above reasons, I think the paper could be better polished for future publication.', 'Summary: this paper introduces a new  network architecture inspired by visual attentive working memory. The network consists of a recurrent components that generates glimpses of features from a CNN applied to the input (inspired by the DRAW network), and a working memory component that iterative stores memories using Hebbian mechanisms. The authors apply this network to classification tasks (MNIST) as well as using it as a generative model.\n\nThe ideas in the paper are somewhat  interesting, but I have major concerns with the motivation (it is unclear) and the experiments (not convincing):\n\nMotivation: The authors motivate their inclusion of a Hebbian working memory from the perspective of trying to mimic the human visual system. The main problem here is that it is unclear what problem the authors are trying to solve by including this Hebbian mechanism. In the fast-weights paper (Ba et al), they had a clear example of a task that standard recurrent networks could not easily solve, which motivated the inclusion of a working memory mechanism. A similar motivation here is lacking, with the main justification seeming to be to ""move towards a biologically motivated model of vision"". Are the authors interested in more biologically motivated models because they think they will be useful for some task? Or are the authors interested in models of biological vision itself? If the former, it is unclear what new tasks would be solved by their model (all the results focus on tasks that can be solved without these mechanisms). If the latter, there should be some clear goals for what they hope their model to achieve. ""Moving towards biological vision"" is too vague and broad of a justification in order for us to judge progress. Section 2 discusses, at a high level, broad concepts from the visual neuroscience literature, but this also does not clearly motivate why the authors are interested in this particular instantiation of these ideas, indeed, their model is only weakly related to many of the neuroscience ideas discussed.\n\nResults: The authors evaluate their network on two tasks: classification and image generation.\n- For classification, I have a hard time understanding what these results tell us. Very simple models can achieve low test error on MNIST, so it is unclear what the attention or working memory buys you. One simple improvement would be if the authors ablated different parts of their network to show how critical they are to performance. Increasing the window size to 28 helps the model, suggesting that the network is hindered by the glimpses, so I do not feel like I have learned much from these results. In addition, the authors only mention Cifar10 results in a couple of lines, so it is hard to take anything away from those statements.\n- For image generation, similarly, the authors do not compare their model to other standard generative models. Does their model perform better than simple baselines?\nFinally, for all of these results, what is the working memory doing? Why is it necessary? Does it learn something interesting? It is hard to understand the significance of the work without answers to these questions.']","[90, -30, -60]","[80, 50, 20]","[""The sentiment score is 90 because the reviewer expresses very positive views about the paper, recommending it for acceptance with a high score of 9 out of 10. They praise the authors' efforts in improving the paper, the clarity of writing, and the value of the work to the community. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout, acknowledging the authors' hard work and the potential impact of their research. They offer constructive feedback and express excitement about future work in this area. The review maintains a professional and courteous tone while providing detailed and thoughtful commentary."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (novel approach, competitive results, code release), they express several significant concerns and criticisms. The overall tone suggests that the paper needs substantial improvements before publication. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I appreciate' and 'I believe', which soften the critique. However, they don't use overly polite language, maintaining a neutral to slightly positive tone in their expressions."", ""The sentiment score is -60 because the reviewer expresses 'major concerns' with the paper's motivation and experiments, describing them as 'unclear' and 'not convincing'. The reviewer also points out several weaknesses in the results and methodology. However, the score is not lower because the reviewer does acknowledge that the ideas are 'somewhat interesting'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I have a hard time understanding' and 'it is unclear' rather than more aggressive language. The reviewer also offers constructive suggestions for improvement, such as ablation studies. However, the score is not higher because the criticism is quite direct and there are few positive comments or softening phrases used.""]"
"['\nThe authors provide new generalization bounds for recurrent neural networks.\nTheir main result is a new bound for vanilla RNNs, but they also have\nbounds for gated RNNs.\n\nThey claim that their vanilla bound improves on an earlier\nbound for RNNs in Section 6 of an ICML\'18 paper by Zhang, et al.\nThe main result of the submission is incomparable in strength with the earlier result,\nbecause this submission assumes that the activation functions in the hidden\nlayers are bounded, where the earlier paper did not.  Part of the difference in the results\n(roughly speaking, the ""min"" in the bound) can be traced to this difference in the assumptions. \n (This paper uses this assumption in the second-to-last line of the proof of Lemma 6.)\n\nI think that the root cause of the remaining difference is that this paper,\nat its core, adapts the more traditional analysis, used in Haussler\'s\n1992 InfComp paper.  New analyses, like from the Bartlett, et al\nNIPS\'17 paper, strove for a weak dependence in the number of parameters,\nbut this proof technique appears to lead to a worse dependence on the\ndepth.  I think that, if you unwind the network, to view the function\nfrom the first t positions of the input to output number t as a\ndepth t network, and apply Haussler\'s bound, you will get a qualitatively\nsimilar result (in particular with bounds that scale polynomially with\nd and t).  I think that Haussler\'s proof technique can be adapted to\ntake advantage of the weight sharing between layers in the unrolled\nnetwork.  \n\nIt is somewhat interesting to note that the traditional bounds have\na better dependence on depth, with correspondingly better dependence\non the length of the output sequence of the RNN.\n\nI also do not see that substantial new insight is gained through the\nanalysis that incorporates gating.\n\nI do not see much technical novelty in this paper.\n\n\n\n', 'The paper focuses on the generalization performance of RNNs and its variant in a theoretical perspective. Compared to the previous result (Zhang et al., 2018) for RNNs, this paper refines the generalization bounds for vanilla RNNs in all cases and fills the blank for RNN variants like MGU and LSTM. Specifically, in the work of Zhang et al. (2018), the complexity term quadratically depends on the layer (or say, current sequence length, denoted by t in original paper), making it less instructive. This paper improves it to at most linear dependence and can achieve at logarithmic dependence in some cases, which should be accredited. \n\nThe key step in the proof is Lemma 2. In Lemma 2, the spectral norms of weight matrices and the number of weight parameters are decoupled. With Lemma 2, it is natural to construct a epsilon-net for RNNs and then upper bound the empirical Rademacher complexity by Dudley’s entropy integral, since such methodology is not so novel. Bartlett, et al. (2017) developed this technique to analyze the generalization bound for neural networks in a margin-based multiclass classification. However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification. I wonder the motivation of analyzing generalization of RNNs by the techniques established by Bartlett. \n\n', 'This paper studies the generalization properties of Recurrent Neural Networks (RNN) and its variants for the sequence to sequence multiclass prediction problem. The problem is important to understand in the theoretical machine learning community. The paper is written well overall, clearly explaining the results obtained. I would like to raise several important points:\n\n1. Missing comparison with parameter counting bounds: there has been a long line of research on generalization bounds for RNNs by obtaining bounds on the VC dimension of the function class [1, 2] which provide generalization bounds for various non-linearities. The bounds obtained are polynomial in the sequence length T (often sublinear or linear) and should be compared with the existing bounds for a thorough comparison.\n\n2. Vacuous bounds in the regime \\beta >1: Most recurrent architectures with no restrictions on the transition matrices work in the regime where they are more expressive and \\beta >1. A quick glance at Table 1 suggests that the bounds obtained through Theorem 3 are exponential in t and are mostly vacuous. They can indeed be subsumed by generalization bounds based on VC theory. The bound obtained in Theorem 2 comes rather easily from the bounded assumption on the non-linearity and is this not very interesting. \n\n3. Technical contribution: While the authors propose the first bounds for LSTMs and MGUs, most of the analysis seems to be a marginal contribution over the work of Bartlett et al. [3] \n\n4. Missing experiments to validate nature of bounds: Bartlett et al. [3] performed extensive experiments to exhibit the correct scaling of the generalization bounds with the ""model complexity"" introduced upto numerical constants. It would be good to have some experiments in the sequence to sequence setting to understand if the obtained complexities are in fact what one would expect in practice. \n\n\n[1] Koiran, Pascal, and Eduardo D. Sontag. ""Vapnik-Chervonenkis Dimension of Recurrent Neural Networks."" Discrete Applied Mathematics 86.1 (1998): 63-79.\n[2] Dasgupta, Bhaskar, and Eduardo D. Sontag. ""Sample complexity for learning recurrent perceptron mappings."" Advances in Neural Information Processing Systems. 1996.\n[3] Bartlett, Peter L., Dylan J. Foster, and Matus J. Telgarsky. ""Spectrally-normalized margin bounds for neural networks."" Advances in Neural Information Processing Systems. 2017.\n']","[-50, 60, -20]","[20, 50, 60]","[""The sentiment score is -50 because the review is generally critical of the paper's contributions. The reviewer states that they 'do not see much technical novelty in this paper' and that the main result is 'incomparable in strength with the earlier result'. They also mention that they don't see 'substantial new insight' gained from the analysis. However, it's not entirely negative as they do acknowledge some interesting aspects, hence not a lower score. The politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone throughout. They use phrases like 'I think' and 'It is somewhat interesting to note' which soften the criticism. The language is not overtly polite, but it's respectful and avoids harsh or rude phrasing, resulting in a slightly positive politeness score."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions, such as refining generalization bounds and improving upon previous work. They use phrases like 'should be accredited' and note that the paper 'fills the blank' in certain areas. However, it's not extremely positive as the reviewer also raises some questions about the methodology. The politeness score is 50 (slightly polite) because the language is professional and respectful throughout. The reviewer acknowledges the paper's merits and frames their concerns as questions rather than criticisms. They use phrases like 'I wonder' instead of more direct critiques, maintaining a courteous tone. The review doesn't contain overly effusive praise or particularly formal language, hence the moderate positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'written well overall' and 'clearly explaining the results obtained', they raise several critical points and suggest the work may be a 'marginal contribution'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, such as 'I would like to raise' and 'It would be good to have', while providing constructive criticism. They also begin with a positive comment before moving to their concerns, which is a polite approach. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out potential shortcomings of the paper.""]"
"['The paper presents a novel hierarchical clustering method over an embedding space. In the presented approach, both the embedding space and the hierarchical clustering are simultaneously learnt. The hierarchical clustering algorithm aims to recover complex clustering hierarchies which cannot be captured by previously proposed methods. \n\nThe paper address a relevant problem, which is of great interest for extracting knowledge from data. In general, the quality of the paper is high. The presented approach is based on a sound formalization of hierarchical clustering and deep generative models. The paper is easy to follow in spite of the technical difficulty. The experimental evaluation is really extensive. It compares against many state-of-the-art methods. And the results are promising from both a quantitative and qualitative point view. \n\nThe only issue with this paper is its degree of novelty, which is narrow. The proposed method adapt a previously presented hierarchical clustering method in the ""standard space"" (Griffiths et al., 2004) to an embedding space defined by a variational autoencoder model. The inference algorithm builds on standard techniques of deep generative models and, also, on previously proposed methods (Wand and Blei, 2003) for dealing with the complex hierarchical priors involved in this kind of models.', ""The paper proposes using the nested CRP as a clustering model rather than a topic model. The clustering is on the latent vector input into a neural network for generating the observation. A variational approach is derived.\n\nThe proposed model seems like a straightforward extension of the nCRP with a deep model hanging off the end of it. A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time. From the generative model it seems every data point has its own Dirichlet vector on levels. For topic models this makes sense since that vector is then drawn from multiple times (once per word) from a Discrete, so there's a distribution to actually learn. My understanding is that this isn't being done here."", 'This paper proposes using a variant of the nested CRP as a prior on the latent space of a variational autoencoder. The authors demonstrate that this approach is able to simultaneously learn a meaningful latent representation of high-dimensional data (text and images) and do hierarchical clustering in that space.\n\nPros:\n* The high-level idea is compelling.\n* The empirical results are compelling, and the evaluation is thorough.\n\nCons:\n* The prose is pretty rough. The paper is full of sentences like ""VAE-nCRP trade-off is the direct dependency modeling among clusters against the mean-field variational approach"" that don\'t convey their intended meaning (at least to me).\n* The random variable η seems completely superfluous. It only affects the likelihood through the level indicator l, but the marginal distribution p(l) = ∫_η p(η, l)dη \\propto α is tractable, since only one level is drawn per observation. (This is not the case for the traditional nCRP as used in topic modeling, since there a different level is chosen for each word.)\n* The novelty over the nCRP-VAE approach of Goyal et al. (2017) is pretty minor. The main difference seems to be that the model can select clusters at different levels, but I didn\'t quite get the intuition for why this should be desirable. In topic modeling, higher-level clusters tend to contain less-specialized words, and each document is a mix of specialized and general topics. But in this model, only one level is used to explain an entire image or document, and the idea that an entire image or document is much ""more specialized"" than another doesn\'t seem very intuitive to me.']","[80, -20, 20]","[70, 50, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'high quality', 'easy to follow', and having 'promising' results. The only criticism is about the degree of novelty, which is described as 'narrow'. This minor criticism prevents a perfect score. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths and express the criticism in a constructive manner. The reviewer doesn't use overly effusive language or personal compliments, which keeps the tone professional rather than extremely polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal and approach, they express 'significant concern/confusion' about a key aspect of the model. The reviewer questions the meaningfulness of certain model components, which indicates some skepticism about the paper's methodology. However, the criticism is not harsh, hence only a mild negative score. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present their concerns as personal confusion rather than outright criticism ('A significant concern/confusion for me is...'), which is a polite way to express doubts. The reviewer also uses phrases like 'seems like' and 'My understanding is', which softens their critique and shows respect for the authors' work."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as the 'compelling' high-level idea and empirical results. However, they also list significant cons, including issues with prose clarity and questions about novelty, which temper the positive aspects. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language to describe both strengths and weaknesses. They avoid harsh criticism and instead offer constructive feedback, such as pointing out specific areas for improvement in the writing and questioning certain aspects of the model. The reviewer also uses phrases like 'at least to me' when expressing confusion, which shows a degree of politeness by acknowledging the possibility of personal misunderstanding rather than outright criticism.""]"
"['Authors provide a variant of WGAN, called PC-GAN, to generate 3D point clouds. The drawback of a vanilla GAN with a DeepSet classifier is analyzed. The rationality that decoupling the point generator with the object generator is also discussed. \nA sandwiching objective function is proposed to achieve a better estimation of Wasserstein distance. \nCompared with AAE and the simplified variants of the proposed PC-GAN, the proposed PC-GAN achieves incremental results on point cloud generation.\n\nComments:\n1. Authors calculate W_U in a primal form via solving an assignment programming problem. Have authors ever tried Sinkhorn iteration? To my knowledge, sinkhorn iteration is a very popular method to solve OT problem effectively. It would be nice if authors can provide some reasons and comparisons for their choice on the optimizer of W_U. \n\n2. Authors proved that the sandwiching object W_s is closer to the real Wasserstein distance, but it increases the variance of the loss function. Specifically, the dynamics of W_U, and W_L, according to lemma1, is (epsilon2-epsilon1)*w(P, G) while the dynamics of W_s is 2*epsilon1 * w(P, G), and 2epsilon1 > epsilon2 - epsilon1 (according to the assumption in lemma 1). Does it mean that the W_s is not as stable as W_L or W_U during training?  Additionally, authors combined W_U with W_L with a mixture 20:1, i.e., the s in Eqs(6, 13, 14) is smaller than 0.05. In such a situation, both the value and the dynamics of W_s will be very close to that of W_U. Does it mean that W_L is not so important as W_U? Authors should analyze the stability of their method in details.\n\nEssentially, the proposed method is a variant of WGAN, which estimates Wasserstein distance with lower bias but may suffer from worse stability. In the experiments, both the setting and the experimental results show that the proposed W_s will be very close to W_U. As a result, the improvement caused by the proposed method is incremental compared with its variants. \n\nTypos:\n- The end of the 2nd line of lemma 1: P, G should be \\mathbb{P}, \\mathbb{G}\n- The 3rd line of lemma 1: epsilon1 -> epsilon_1\n- Page 14, Eq(14), \\lambda should be s\n- Page 14, Eqs(13, 14), w(\\mathbb{P}, \\mathbb{G}) should appear on the right.\n', 'Summary:\nThis paper proposes a generative point cloud model based on adversarial learning and definitti’s representation theorem of exchangeable variables.\nThe main focus in experiments and the exposition is on 3D point clouds representing object shapes (seems the surface, but could also be the interior of objects, please clarify). \nThe main idea is to represent a point cloud using a global latent variable that captures the overall shape, and a collection of local latent variables that code for the position of a point on the shape.\nThe model consists of thee components:\n(i) an “encoder” that takes a point cloud as input and maps it to a (point estimate of) the global latent variable of the shape represented by the input cloud, a point-net architecture is used here\n(ii) a “decoder” that takes the estimated global latent variable, and a local latent variable, and maps it to an “output” point in the cloud to be produced by the model. \n(iii) a “discriminator” network that aims to distinguish points from a *given* shape, and the points produced by pipe-lining the encoder and decoder. Critically different from conventional GANs, the discriminator is optimized *per shape*, ie each point cloud is considered as a *distribution* over R^3 specific to that shape. \n(iv) a “shape prior” that, once the encoder-decoder model from above is trained, is used to model the distribution over the global latent variables. This model is trained, presumably, in a conventional GAN style using the global latent variable representations inferred across the different training point clouds.\n\nAs compared to prior work by Achiloptas et al (2017), the proposed approach has the advantage to allow for sampling an arbitrary number of points from the target shape, rather than a fixed pre-defined number. \n\nIn addition, the authors propose to minimize a weighted average of a lower bound and upper bound on the Wasserstein distance between the distributions of points corresponding to given shapes. \nThis approach translates to improved quantitative evaluation measures, \n\nExperiments are conducted on a simple toy data set, as  a proof of concept, and on data from ModelNet10 and ModelNet40. \nTwo performance metrics are introduced to assess the auto-encoding ability of the model: to what extent does the encoder-decoder pipeline result in point clouds similar to the shape from which the input point-cloud is generated. \n\nOverall I find the idea of the paper interesting and worth publishing, but the exposition of the paper is less than ideal and needs further work. \nThe experimental validation of the proposed approach can also be further improved, see more specific comments below. \n\nSpecific comments:\n\n- The counter example at the bottom of page 2 is limited, in the sense that the oracle assumption seems highly non-realistic, casting doubt on the relevance of the argument.\n\n- The notation in section 3 (before 3.1) is rather sloppy. \nFor example, \n- please define P and G, the elements of the divergence D(P||G) that appears in the first paragraph of section 3.\n- it is not defined in which space theta lives, it is not clear what the authors intend with the notation G_theta(u) \\sim p(theta). \n- what prior distributions p(z) and p(u) are used? What is the choice based on?\n\n- abbreviation IPM is referred several times in the paper, but remains undefined in the paper until end of page 4, please define earlier. \n\n- The model G_theta does not appear in the training objective function (4), how is this module trained precisely?\n\n- Lack of clarity in the following passage: “In our setting, each point xi in the point cloud can be considered to correspond to single images when we train GANs over images”\n\n- The notion of divergence D(P|G) is not made concrete in section 3 and 3.1, which makes the notation of rather little use.\n\n- The following paper merits a discussion in the related work section: \n“TOWARDS A NEURAL STATISTICIAN”, ICLR’17, https://openreview.net/pdf?id=HJDBUF5le\n\n- The manuscript contains many typos. For example\n “vedio” op page 4, “circile” on page 5, “condct” on page 8, etc.\nPlease proof read your paper and fix these.\nThe refenence to  Bengio 2018 is incomplete: what do you refer to precisely?\n\n- There seems to be no mention of the dimension of the “local” latent variables z_i. \nPlease comment on the choice, and its impact on the behavior of the model.\n\n- The quantitative evaluation in table 1 is interesting and useful. \nIt is limited, however, in the sense that it (only) measures auto-encoding capabilities: to what extent can the shape be reproduced given a sample point cloud from the given shape. \nQuantitative evaluation of generative modeling performance is unfortunately missing from this paper, as it is in much of the GAN literature. \nCould you please comment on how this can/will be fixed?\n\n- The toy data set experiments could be dropped  to make room for experiments suggested below.\n\n- An experimental study of the effect of the mixing parameter “s” would be useful to include. \nFor example, by taking s on a grid from 0 to 1, one could plot the coverage and distance-to-face measures.\n\n- Experimental evaluation of auto-encoding using a variable number of input points is interesting to add: ie how do the two evaluation measures evolve as a function of the number of points in the input point cloud?\n\n- Similar, it is interesting to evaluate how auto encoding performs when non-uniform decimation of the input cloud is performed, eg what happens if we “chop off” part of the input point cloud (eg the legs of the chair), does the model recover and add the removed parts? This is potentially useful to practitioners which have to deal with incomplete point clouds acquired by range scanners. \n\n- Analysis of shapes with different genus and dimensions would be interesting. \nDoes the model manage to capture that some shapes have holes, or consists of a closed 2D surface (ball) vs an open surface (disk),  despite a simple prior on the local latent variables z?\n\n', 'Summary:\nThis paper introduces a generative model for 3D point clouds. Authors aim at theoretically showing the difficulties of using existing generative models to learn distributions of point clouds, and propose a variant that supposedly solves the issues.\n\nPros:\n+ The problem of designing generative models for 3D data is important.\n\nCons: \n- Paper is often hard to follow, and contains a significant number of typos. \n- Authors claim to identify a fundamental problem with the existing generative models for point clouds, yet Section 2 tries to show that a _specific version_ that uses DeepSet does not satisfy theoretical guarantees. What if we use e.g. a recurrent network instead? As is, the counter example proof itself is quite confusing: it would really help if the proof was more formal.\n- Jointly learning an inference network (Q) has certainly been done before, and I am not sure authors provide an elaborate enough explanation of what is the difference with adversarially learned inference /  adversarial feature learning.\n- It is not clear why authors did not follow the evaluation protocol of [Achlioptas’17] or [Wu’16] more closely. In particular, evaluation for the classification task should be compatible with the proposed model, which would give a much better picture of the learned representations.\n']","[20, 20, -50]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the incremental improvements of the proposed PC-GAN method and provides a balanced assessment of its strengths and limitations. The review starts with a neutral summary of the work and then offers constructive criticism and suggestions for improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Have authors ever tried...', 'It would be nice if...'), and provides specific, actionable feedback. The reviewer also points out typos in a helpful manner. However, the score is not maximally positive due to the direct nature of some critiques and the lack of overtly positive language or praise."", ""The sentiment score is slightly positive (20) because the reviewer states that the idea is 'interesting and worth publishing', indicating overall approval. However, they also mention that 'the exposition of the paper is less than ideal and needs further work', which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'please clarify', 'could you please comment', and 'it is interesting to evaluate', which maintain a polite and collaborative tone. The reviewer also balances criticism with positive remarks, such as praising the 'interesting and useful' quantitative evaluation. The presence of detailed, specific recommendations also contributes to the politeness, as it shows the reviewer has carefully considered the work."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the problem, they list several significant criticisms that outweigh the single positive point. The review highlights issues with clarity, theoretical foundations, and evaluation methodology. The politeness score is 20 because the reviewer uses neutral language and frames criticisms as areas for improvement rather than harsh judgments. They begin with a brief positive note and use phrases like 'it would really help if' to suggest improvements. However, the overall tone remains professional rather than overtly polite, hence the moderate positive score.""]"
"[""This paper focuses on the alignment of different Knowledge Graphs (KGs) obtained from multiple sources and languages - this task is similar to the Link Prediction setting, but the objective is learning a mapping from the entities (or triples) in one Knowledge Graph to another. In particular, the paper focuses on the setting where the number of available training alignments is small.\n\nThe model and training processes are slightly convoluted:\n- Given a triple in the KG A, the model samples a candidate aligned triple from a KG B, from a (learned) alignment distribution.\n- The objective is a GAN loss where the discriminator needs to distinguish between real and generated alignments.\nThe objective is non-differentiable (due to the sampling step), and it's thus trained via policy gradients.\n\nQuestion: to me it looks like the whole process could be significantly simpler, and end-to-end differentiable. For instance, the loss may be the discrepancy between the alignment distribution and the training alignments. As a consequence, the whole procedure would be significantly more stable; there would be no need of sampling; or tricks for reducing the variance of the gradient estimates. What would happen with such a model? Would it be on par with the proposed one?\n\nThe final model seems to be better than the considered baselines.\n"", '<Summary>\nAuthors propose a new approach for aligning partially heterogeneous knowledge graphs, which allows for unsupervised / semi-supervised alignment via GANs that serve as: (1) triplet discriminator and (2) entity distribution matching.\n\nThe paper reports big improvement over their baseline approaches especially for unsupervised and weakly-supervised settings. The experiment is performed for various combinations of several small KG datasets (both simulated - artificial division of a KB - and real multi-lingual KG triple datasets). The authors also report ablation studies over multiple optimization algorithms as well as reward functions,\n\n<Comments>\n- As far as I know, the idea of applying GAN for triplet discrimination has not been tried before, and it is a novel contribution of the authors. The prior literature has focused primarily on distribution matching / regularization only, often via MMR, autoencoders, GAN training, etc.\n\n- While the idea of applying adversarial approaches is new in the context of KG alignment, the technical novelty of each component is limited, and borrowed directly from existing literature with minor modifications.\n\n- It would be interesting to report results at varying controlled conditions (e.g. as a function of % of label overlaps, etc.) to better study the empirical effects of each training component, etc.\n\n- Experiments are only conducted on smaller 15K subsets of FB KG datasets. It would be interesting to run experiments on larger subsets and see if the proposed approaches can scale.\n\n- The alignment is applied only on a simple TransE algorithm.  While the author’s formulation is flexible and shouldn’t restrict application of other state-of-the-art graph embedding methods, it is not clear if one will see the same improvement.\n', 'The authors propose KAGAN, a novel method for knowledge graph (KG) alignments using GANs. In contrast to most other methods, KAGAN does not rely on a supervised setting where a set of already aligned triples is used as seed. In addition, the authors propose modifications such that their method can also integrate information about aligned triples.\n\nIn my opinion the biggest strength of the paper is the novelty of the proposed method. The standard framework of GANs is adjusted elegantly to the KG alignment setting. Further, the basic approach as well as the proposed modification to deal with practical issues such as mode collapse are well motivated and comprehensible. The ability to perform well in the unsupervised/weakly supervised setting is another plus. Up to my knowledge, this paper constitutes the first approach using GANs for the KG alignment task. However, there are several methods that use GANs directly to produce KG embeddings (e.g. KBGAN). These methods are related to KAGAN since they employ TransE as an underlying embedding method. Therefore, I strongly believe the authors should include [1] and [2] in their references and discuss these methods briefly. \n\nThe authors conduct experiments on benchmark datasets for the KG alignment tasks. Thereby, they aim to show that their KAGAN outperforms other state of the art methods. However, I have one major concern: In the subsection \'Parameter Settings\' the authors state without further explanation that they set the embedding size to 512 for all compared methods. I do not understand the rationale behind this decision. In particular, since the embedding sizes in the original publications (e.g., in Chen et al. (2017a)) are very different. For KG embedding methods the dimensionality of the embeddings is probably the most important hyperparameter. In my opinion, picking a global value for all methods instead of tuning it for each method individually does not guarantee a fair comparison. \n\nOn a side note, the authors might also consider the mean rank as performance measure which is frequently employed in the KG alignment setting.   \n\nOverall, the paper is well written and organized. A minor point: I would get rid of the formulas in the introduction; in particular, since the notation is not introduced at this point.\n\nWhile the novelty and good structure of the paper are reasons to accept it, I have doubts concerning the soundness of the results due to the experimental setup. \n\nReasons to accept the paper\n- novelty\n- works in an unsupervised setting\n- well written/structured\n\nReasons to reject\n-  Doubts concerning the experimental setting\n- (Minor) related work is not complete\n- (Minor) not all common performance measures are reported\n\n\n----------------------------\n\n[1] Wang, Peifeng, Shuangyin Li, and Rong Pan. ""Incorporating GAN for Negative Sampling in Knowledge Representation Learning."" (2018).\n[2] Cai, Liwei, and William Yang Wang. ""KBGAN: Adversarial Learning for Knowledge Graph Embeddings."" Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Vol. 1. 2018.\n']","[20, 50, 50]","[60, 75, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's focus and notes that the final model performs better than the baselines. However, they also express concerns about the complexity of the model and suggest a simpler approach. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, poses their critique as a question, and offers constructive feedback. They avoid harsh criticism and instead suggest alternatives in a professional manner."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the approach and its improvements over baselines, but also points out limitations and areas for improvement. The review begins with positive aspects before moving to constructive criticism. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames criticisms as suggestions or areas of interest rather than direct attacks. The reviewer uses phrases like 'it would be interesting' and 'it is not clear if' rather than more confrontational language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths such as novelty, good structure, and ability to work in an unsupervised setting. However, they also express significant concerns about the experimental setup and completeness of related work, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive observations. They use phrases like 'In my opinion' and 'The authors might also consider' which maintain a polite tone even when critiquing.""]"
"['The paper proposes the inclusive neural random field model. Compared the existing work, the model is different because of the use of the inclusive-divergence minimization for the generative model and the use of stochastic gradient Langevin dynamics (SGLD) and stochastic gradient Hamiltonian Monte Carlo  (SGHMC) for sampling. Experimental results are reported for unsupervised, semi-supervised, and supervised learning problems on both synthetic and real-world datasets. Specific comments follow:\n\n1. A major concern of the reviewer is that, given the related work mentioned in Section 3, whether the proposed method exerts substantial enough contribution to be published at ICLR. The proposed method seems like an incremental extension of existing works.\n\n2. A major claim by the authors is that the proposed techniques can help explore various modes in the distribution. However, this claim can only seem easily substantiated by experiments on synthetic data. It is unclear whether this claim is true in principle or in reality.\n\nOther points:\n3. the experimental results of the proposed method seems marginally better or comparable to existing methods, which call in question the necessity of the proposed method.\n\n4. more introduction to the formulation of the inclusive-divergence minimization problem could be helpful. The presentation should be self-contained.\n\n5. what makes some of the statistics in the tables unobtainable or unreported?\n\n\n============= After Reading Response from Authors ====================\n\nThe reviewer would like to thank the authors for their response. However, the reviewer is not convinced by the authors’ argument. \n\n“The target NRF model, the generator and the sampler are all different.”\nIt is understandable that modeling continuous data can be substantially different from modeling discrete data. Therefore, it is non-surprising that the problem formulations are different.\n\nAs for SGLD/SGHMC and the corresponding asymptotic theoretical guarantees, this reviewer agrees with reviewer 2’s perspective that it is a contribution made by this paper. But this reviewer is not sure whether such a contribution is substantial enough to motivate acceptance.\n\nThe explanation for better mode exploration of the proposed method given by the authors are the sentences from the original paper. The reviewer is aware of this part of the paper but unconvinced.\n\nIn terms of experiments, sample generation quality seems to be marginally better. Performances in multiple learning settings are comparable to existing methods.\n\nA general advice on future revision of this paper is to be more focus, concrete, and elaborative about the major contribution of the paper. The current paper aims at claiming many contributions under many settings. But the reviewer did not find any of them substantial enough.\n\n', 'This paper describes a method of training NRFs with auxiliary generator networks, using an error that minimizes KL(NRF || generator).  This formulation enables the use of iterative gradient-based stochastic sampling of image samples from the model distribution using SGLD/SGHMC.  Applications to both unsupervised sample generation and semi-supervised classification are evaluated.\n\nI\'m not very familiar with these types of NRFs or random sampling techniques, but the approach appears sound and is evaluated rather well.  I would have liked some more background and explicit description and contrast compared to the explicit NRF.  While this is described already, I think the contrasts could potentially be spelled out even more explicitly, particularly in the descriptions of the sampling algorithms.\n\nThe toy example with mixture of gaussians is convincing showing the contrast in results between the exclusive NRF, inclusive, and sampling gradient revision steps.\n\nExperimental evaluations on MNIST, SVHN and CIFAR show that the system obtains performance similar to SOA generative systems, in both semi-supervised classification and sample generation.\n\n\nQuestions and comments:\n\n- While the paper claims the results show classification and generation performance are complementary, Table 3 appears to validate the opposite claim, that these are to a large degree a trade-off.  The fact that this system performs well at both is good, but to me it looks like it may be on the ""shoulder"" of a frontier curve if one were to plot the classification vs generation performance of the different current systems.\n\n- Table 4 and sec 4.4:  I think these could be clearer.  The first observation states that revision improves IS.  But using more iterations (increasing L) does not appear to increase IS.  There does appear to be a consistent increase from the first column (generation) to second (revision), though -- is this what this observation refers to?  In addition, I\'m not entirely clear what the ""Generation IS"" vs ""Revision IS"" column refers to --- I believe ""generation"" is the initial sampling of x=g(h) (i.e. h followed by q(x | h)), and ""revision"" is the application of gradient revision.  But then how does the generation IS results change from row to row (which only modify the revision step)?\n\n', 'This paper addresses an important problem of learning the random field using neural networks by using a inclusive auxiliary generator. Comparing to existing state-of-the-art methods for learning neural random fields, this paper used a the inclusive-divergence (KL divergence of the density approximate and the auxiliary generator) which avoids the intractable entropy term. SGLD/SGHMC are used to revise samples drawn from the auxiliary generator and these two sampling methods are examined theoretically.  \n\nIn generally, the paper is well motivated and well written. Experiments are sufficient and convincing, especially the synthetic data experiments with GMM distributions. \n\nHowever, I am a little bit concerned that the theoretical contribution seems weak. As discussed in the related work, the idea of using neural network to learn the random field is not new. Using inclusive-divergence is also not new, e.g. Xie et al (2016) and Wang & Ou (2017) already proposed to use the inclusive-divergence. If I understand it correctly, the only contribution here is to apply the SGLD/SGHMC to revise the samples and authors provided some theoretical analysis of SGLD/SGHMC.\n\nThe overall technical quality of the paper is sound but I am not 100% sure about the equations, e.g. the second line in Eq. 4. \n\nIn summary, this paper is well written and authors have done a good job. But I will appreciate if authors can elaborate\nmore on the novelty and innovation of the paper. ']","[-60, 50, 50]","[20, 70, 75]","[""The sentiment score is -60 because the reviewer expresses major concerns about the paper's contribution and is not convinced by the authors' responses. They question the novelty and necessity of the proposed method, and find the experimental results only marginally better or comparable to existing methods. The politeness score is 20 because while the reviewer maintains a professional tone and thanks the authors for their response, they are direct in their criticisms. The language is not rude, but it's also not overly polite, striking a balance between courtesy and frank academic critique. The reviewer offers constructive feedback and suggestions for improvement, which adds to the politeness, but the overall tone remains critical."", ""Sentiment score: The review starts with a positive tone, describing the paper as 'sound' and 'evaluated rather well'. The reviewer also mentions that the experimental evaluations show performance 'similar to SOA generative systems'. However, there are some critiques and questions raised, which temper the overall positivity. This mix of positive and constructive feedback suggests a moderately positive sentiment, hence the score of 50.\n\nPoliteness score: The language used throughout the review is professional and respectful. The reviewer uses phrases like 'I would have liked' and 'I think' to soften criticisms, and frames suggestions as questions or comments rather than demands. The tone is consistently constructive rather than dismissive. However, it doesn't go out of its way to be overly polite or complimentary, maintaining a professional neutrality. This balance of respect and professionalism warrants a politeness score of 70."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's importance, good motivation, and convincing experiments. However, they express concerns about the theoretical contribution and novelty, which prevents a higher score. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language, acknowledging the authors' good work, and framing criticisms constructively. They use phrases like 'I am a little bit concerned' and 'I will appreciate if' rather than harsh criticism. The reviewer also balances positive feedback with areas for improvement, maintaining a professional and courteous tone throughout.""]"
"['This paper poses and addresses the problem of language drift in multi-agent communication paradigms. When two pretrained natural-language agents are jointly optimized to communicate and solve some external non-linguistic objective, their internal communication often diverges to a code-like, unnatural communication system. This paper solves this “language drift” problem by requiring that the messages between agents be usable as inputs to an image caption retrieval system. They demonstrate that the jointly optimized agents perform best when regularized in this manner to prevent language drift.\n\n1. Framing: I’m uncertain about the framing of this paper. The authors pose the problem of “language drift,” which is indeed a frequent problem in multi-agent communication tasks where the principle supervision involves non-linguistic inputs and outputs. They then design a three-language MT task as a test case, where the inputs and outputs are both linguistic. Why attack this particular task and grounding solution? I can imagine some potential goals of the paper, but also see more direct ways to address each of the potential goals than what the authors have chosen:\n1a. Study how to counter language drift in general — why not choose a more intuitive two-agent communication task, e.g. navigation, game playing, etc.?\n1b. Study how to counter language drift in the MT task — aren’t there simpler solutions to prevent language drift in this particular task? e.g. require “cycle-consistency” – that it be possible to reconstruct the French input using the French output? Why pick multimodal grounding, given that it imposes substantial additional data requirements?\n1c. Build a better/more data-efficient machine translation system — this could be an interesting goal and suitable for the paper, but this doesn’t seem to be the framing that the authors intend.\n\n2. Interpretation of first results:\n2a. Thanks for including standard deviation estimates! I think it’s also important that you do some sort of significance testing on the comparison between PG+LM+G and PG+LM performance for Fr->En->De — these numbers look pretty close to me. You could run e.g. a simple sign test on examples within each corpus between the two conditions.\n2b. It would also be good to know how robust your results are to hyperparameter settings (especially the entropy regularization hyperparameter).\n\n3. Token frequency results: These are intriguing but quite confusing to me!\n3a. How sensitive are these results to your entropy regularization setup? How does PG behave without entropy regularization?\n3b. Table 6 shows that the PG model has very different drift for different POS categories. Does this explain away the change in the token frequency distribution? What do the token frequency effects look like for PG within the open-class / content word categories (i.e., controlling for the huge difference in closed-class behavior)?\n\n4. Minor comments:\n4a. There’s a related problem in unsupervised representation learning for language. Work on VAEs for language, for example, has shown that the encoder often collapses meaning differences in the latent representation, and leans on an overly powerful decoder in order to pick up all of the lost information. It would be good to reference this work in your framing (see e.g. Bowman et al. (2015)).\n4b. In sec. 3.1 you overload notation for R. Can you subscript these so that it’s especially clear in your results which systems are following which reward function?\n4c. Great to show some qualitative examples in Table 7 — can you explicitly state where these are from (dev set vs. test set?) and whether they are randomly sampled?\n\nReferences:\nBowman et al. (2015). Generating sentences from a continuous space. https://arxiv.org/abs/1511.06349\n', 'The paper presents an approach to refining a translation system with grounding (in addition to LM scores) in the loop to manage linguistic drift.  The intuition is straightforward and results are clearly presented, but the gains are unfortunately much weaker than I would have hoped for.  \n\nThe results for both Fr-En and Fr-En-De only show very small gains for adding grounding, often with PG+LM results being within 1 std-dev of the PG+LM+G results.  Otherwise, the results are quite nice with interesting increases in linguistic diversity.  This leads me to wonder if this approach would show more gains with a human evaluation rather than BLEU score. \n\nWhat is the performance of PG+G without the +LM?  \n\nMinor -- In Fig 2, should the green line (PG+LM) have continued climbing to >21 BLEU?', 'Summary:\nThis paper tries to verify a hypothesis that language grounding DO help to overcome language drift when two agents creating their own protocol in order to communicate with each other. There are several constraints to enforce: 1) naturalness, say ""Englishness"", 2) grounded in visual semantics. The experiments prove that both constraints help the most (say, BLUE score). 1) w/o 2) restricts the vocabulary into a small set with the most frequent words, while 1) with 2) can resemble the original distribution. \n\nStrength:\n- How to make the protocol automatically created by two agents much explainable/meaningful is a very interesting topic. This paper explores plausible constraints to reach this goal. \n\nWeakness:\n- Visual grounding task brings more data there. To fairly compare, I hope to add one more baseline PG+LM+G_text, where G_text simply means to use text data (captions) alone, i.e., without visual signals.\n']","[20, -20, 50]","[80, 50, 70]","[""Sentiment Score (20): The review begins with a positive summary of the paper's contribution, acknowledging its novel approach to solving the language drift problem. However, the reviewer then raises several questions and concerns about the framing, methodology, and interpretation of results. While these critiques are constructive, they do indicate some reservations about the paper, leading to a slightly positive but not overwhelmingly enthusiastic sentiment.\n\nPoliteness Score (80): The reviewer maintains a consistently professional and respectful tone throughout. They use phrases like 'Thanks for including...', 'It would be good to...', and 'Great to show...', which demonstrate appreciation and constructive feedback. The critiques are framed as questions or suggestions rather than direct criticisms. The reviewer also acknowledges positive aspects of the work, such as the inclusion of standard deviation estimates and qualitative examples. The high politeness score reflects this considerate approach, although it's not at 100 as there's still a clear critical element to the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('intuition is straightforward', 'results are clearly presented'), they express disappointment with the gains ('unfortunately much weaker than I would have hoped for', 'only show very small gains'). The overall tone suggests the reviewer is not fully satisfied with the paper's results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms politely ('I would have hoped for', 'leads me to wonder'). They also highlight positive aspects before mentioning limitations. The reviewer maintains a professional tone without using overly formal or informal language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting topic and the strength of exploring plausible constraints. However, they also point out a weakness, suggesting an additional baseline for comparison. This balanced view indicates a moderately positive sentiment. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, presenting both strengths and weaknesses objectively without harsh criticism. They use phrases like 'I hope to add' when suggesting improvements, which is a polite way of offering feedback. The overall tone is professional and constructive, maintaining a courteous approach to the review process.""]"
"['This paper proposed a progressive weight pruning approach to compress the learned weights in DNN. My major concerns about the paper are as follows:\n\n1. Novelty: The proposed approach heavily relies on the one in (Zhang et. al. 2018b) as shown in Sec. 2.2 for 1 page, making the paper as being an incremental work, like finding better initialization for (Zhang et. al. 2018b).\n\n2. Faster convergence: First of all, from Fig. 3 I do not believe that both methods converged, as both performances vary a lot with significant gaps. In terms of being faster, I do not think that it makes sense by comparing numbers of epochs in training with only one approach. There is no theoretical or empirical evidence (e.g. running time) to support this claim.\n\n3. I do not understand how the proposed approach is motivated by DP. To me it is more like a greedy search algorithm, while DP has the ability to locate global maximum. Does the proposed approach guarantee to find the maximum accuracy? Also, in Fig. 2 why was the best partial model replaced with the new one, rather than the worse one? There is no explanation to this at all. Besides, I do think this approach is very heuristic, same as some other approaches in the related work.\n\n4. Experiments: Since the performance varies a lot as shown in Fig. 3, how are the numbers calculated? Average? Best one? With/without cross-validation to tune parameters? How much gain in terms of running time in testing can you get with more compact models in practice? A training/testing behavior analysis is highly appreciated.\n', ""This paper focus on weight pruning for neural network compression. The proposed method is based on ADMM optimization method for neural network loss with constraint on the l_0 norm of weights, proposed in Zhang et al. 2018b. Two improvements, masked retraining and progressive pruning, are introduced. Masked retraining set the weights to zero at early stages and stop updating those weights. Progressing pruning keeps a buffer of partial pruning results and select the best performed model for further pruning. The proposed method achieves 30x compression rate for AlexNet and VGG for ImageNet.\n\nI have the following concerns about the proposed method. \n- It is unclear to me what is the benefit of ADMM for solving the sparse regularized NN optimization problem. Why is it better than projected gradient descent or proximal gradient method used in previous network pruning? I understand the proposed method is based on Zhang et al. 2018b, but a strong argument will support the draft.\n- I fail to understand the claim ``at convergence, the pruned DNN model will not be exactly sparse’’ in section 2.3. Z will always be sparse after the projection step in (5). At convergence, the linear constraint should be satisfied, which makes W = Z to be sparse. \n- Please describe the the proposed method in detail. The current description is very vague and I do not think it can be reimplemented based on the current draft. In each outer loop of ADMM, (4)(5) and dual update is applied (I consider solving (4) is the inner loop). How is the mask generated and fit into these equations? For progressive pruning, it looks to me there is an outer loop outside the outer loop of ADMM. Please provide details on how many iterations, and how the compression rate is decided for each iteration.\n- The hyper-parameters of the proposed method is unclear. It is a bit strange the optimization parameter \\rho could control the pruning rate (section 3.1). As described before, I guess the proposed method has three loops. How is the iterations counted, like for Figure 3. Please clarify the experiments are fair comparison, the better results are not because of more weight updates from the three loops. \n- It is unclear what is the benefit of masked retraining. It looks to me this kind of greedy approach will harm the performance (I have to guess if a weight is masked to be zero, it will never be updated or recovered). What happens if there are a lot of weights (Z in (5)) are zero at the early stage?\n- The progressive pruning looks heuristic and I am not convinced the buffer is necessary. There is always a progressive pruning trace that can directly lead to the results without selecting from candidates. For example, in Figure 2, we can just train model from 15x to 24x to 30x.  \n- The following works are related. \nLi et al. Pruning Filters for Efficient ConvNets. ICLR 2017\nAlvarez et al. Learning the number of neurons in deep networks. NIPS 2016\n\n=============== after rebuttal ===================\nI appreciate the authors' feedback and slightly raise the score. \n\nThough the compression results look good, I still have some concerns about the method. The motivation of the proposed method is not strong. The proposed mask is greedy and sounds ad-hoc. The proposed progressive pruning looks expensive. \n\nThe proposed method looks time consuming. For the experiments, I would love to see the training time comparing with baselines in table 1, not only the ADMM method in table 2. A fair comparison could be wall-clock time, or number of gradient updates for neural networks. \n"", 'The authors argue that ADMM-based approach achieves higher accuracy than projected gradient descent. However, experimental evidence is lacking. The authors should compare to a trivial variant of Adam that a projection step is followed by the gradient update.\n\nExperimental results are weak. It seems that the proposed method only works on small networks such as AlexNet and LeNet. On larger networks such as VGG-16 and ResNet, the proposed method achieves higher compression rates at the expense of lower accuracies compared to the related works. Thus, the authors should compare with other methods with the same compression rates.\n\nAs ADMM is sensitive to the penalty parameter, the authors should also conduct more experiments to show robustness of the choice of the penalty parameter across different experiments.']","[-60, -50, -50]","[20, 20, 0]","[""The sentiment score is -60 because the reviewer expresses several major concerns about the paper, questioning its novelty, claims of faster convergence, theoretical foundations, and experimental rigor. The tone is predominantly critical, though not entirely negative. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and frame their points as 'concerns' rather than outright dismissals. They also offer constructive suggestions like requesting a 'training/testing behavior analysis'. The reviewer maintains a respectful tone throughout, even when pointing out significant issues, which keeps the review from being impolite despite its critical nature."", ""The sentiment score is -50 because the review expresses several concerns and criticisms about the paper, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects and raises the score slightly after the rebuttal. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude expressions. They phrase their concerns as questions or suggestions rather than direct criticisms. The slight positive score in politeness is due to the use of phrases like 'I appreciate the authors' feedback' and the constructive nature of the comments. However, it doesn't reach a high positive score as it maintains a neutral, professional tone rather than being overtly polite or friendly."", ""The sentiment score is -50 because the review is generally critical and points out several weaknesses in the paper. The reviewer argues that experimental evidence is lacking, results are weak, and more experiments are needed. However, it's not entirely negative as it provides constructive feedback for improvement. The politeness score is 0 (neutral) because the language is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly but doesn't use harsh language or personal attacks. The tone is matter-of-fact and focused on the content of the paper rather than on pleasantries or rudeness.""]"
"['This paper proposed a query-synthesis-based active learning algorithm that uses GAN to generate high entropy sample; instead of annotating the synthesized sample, the paper proposed to find the most similar unlabeled data from the pool via nearest neighbor search, with the latter is the main contribution of the paper.\n\nPros: \n(1)\tthe paper is well written and easy to follow;\n(2)\tevaluations look reasonable and fair\n\nCons:\n(1)\tThe idea of using GAN for active query synthesis isn’t new. As the authors pointed out, this idea is mainly from GAAL (Zhu & Bento 2017). The main difference is sample matching that searches the nearest neighbor from pool and add the real unlabeled data for AL. So the novelty of the paper isn’t significant.\n(2)\tIn terms of accuracy comparison, on Cifar-10-ten classes experiments, all ASAL variants have similar accuracies as random sampling, while traditional pool-based max-entropy clearly works much better. Although the former is much faster (O(1) vs. O(N)), this benefit is mainly due to GAAL (Zhu & Bento 2017).\n\nThe paper provides additional evidence showing that GAN-based active learning might be an interesting research direction for active query synthesis. However, given the reasons above, particularly novelty, I think the authors might need to additional work to improve the method.\n', 'The paper presents a pool-based active learning method that achieves sub-linear \nruntime complexity while generating high-entropy samples, as opposed to linear \ncomplexity of more traditional uncertainty sampling (i.e., max-entropy) methods. \nThis is achieved by using a generative adversarial network (GAN) to generate \nhigh-entropy samples that are then used by a nearest neighbor method to pick \nsamples from a pool, that are closest to the generated samples. The sub-linear \ncomplexity is achieved through the use of a k-d tree, combined with the fact \nthat similarity is computed on the feature space and samples can thus be indexed \nonce (as the feature space does not change while training).\n\nThe proposed idea builds on top of previously published work on Generative \nAdversarial Active Learning (GAAL). The main difference is the added nearest \nneighbor component, as GAAL is directly using the generated examples, thus \nachieving constant runtime complexity, rather than sub-linear.\n\nI like the overall direction and the idea of being able to perform uncertainty \nsampling in sub-linear time. The approach is interesting. However, the results \npresented in the paper are not strong and I do not see whether or not I should \nbe using this method over uncertainty sampling. Most importantly, the results \nare strongest only for the MNIST experiments, which are over a small dataset. \nGiven that the method is motivated by the scalability argument, I would like to \nsee at least one large scale experiment where it performs well, and more \nspecifically, outperform random sampling. Also, I would really like to see a \nmore principled and thorough experimental investigation with justifications for \nthe configurations used and with more comparisons to alternative approaches, \nsuch as GAAL, which has constant complexity.\n\nI believe that it would be better for your paper if you work a bit more on the \nexperimental evaluation and submit a revised version at a later deadline.\n\n== Background and Method ==\n\nThe background and method sections are clear and easy to follow. One improvement \nI can see is making figure 1 more clear, by maybe explicitly stating in the \nfigure what ""G"" and ""F"" are. One more point of interest is that the way you \nperform sample matching makes some smoothness assumption about the feature \nspace as related to the classifier uncertainty. I perceive this as a smoothness \nassumption on the decision boundary of the classifier and I do not know how true \nis may be for deep neural networks, but I can see how it may be true for \nlogistic regression models and support vector machines (SVMs), depending on the \nkernel used. I believe that this point and main assumption may be worth further \ndiscussion, given that it is also about the main difference your method has with \nrespect to GAAL.\n\nI do not have any other major comments for these sections as my main concerns \nare about the experiments section.\n\n== Experiments ==\n\nIn the experiments, it would be very useful to have plots against execution \ntime, given that the main motivation for this method is scalability. For \nexample, the method outperforms random sampling for small datasets, based on \nnumber of samples, but what happens when you look at execution time? Given that \nrandom sampling is very cheap, I imagine that it probably does better. Also, as \nmentioned earlier, I would like to see at least one experiment using a big \ndataset, where the method outperforms random sampling, as I am not currently \nconvinced of its usefulness.\n\nAlso, you present a lot of results and list observations but I felt there was \nnot much discussion as to why you observe/obtain some of the results. Given that \nyour method is not working very well for CIFAR, I would like to see a more \nthorough investigation as to why that may be the case. This investigation could \nconclude with some ""tips"" on when it may be a good idea to use your method over \nGAAL, or uncertainty sampling, for example.\n\nRegarding the experimental setup, I find lots of configuration choices very \narbitrary and have difficulty understanding how they were chosen. For example:\n\n  - For the two-class MNIST you use classes ""5"" and ""7"" and for the two-class \n    CIFAR you use classes ""automobile"" and ""horse"". Why is that? How did you \n    pick the two classes to use in each case? Do the results match for other \n    class pairs?\n  - ""learning rate of 0.01 that we decay by a factor of 10 at the 130th and \n    140th epochs"" -- end of page 6\n  - ""In contrast to the previous experiments we use a residual Wasserstein GAN \n    with gradient penalty and soft consistency term"" -- page 7 -- why do you \n    make that change?\n\nQuestions:\n  - Why do you think using Wasserstein GANs perform better than using DCGANs? -- section 5.3.1\n  - Why not compare to GAAL in all of figures 3 and 4?\n  - How/why were the number of samples you start with and sample in each round, \n    chosen? Do you observe any difference if you increase/decrease the number of \n    samples sampled in each round or if you start with fewer samples?\n  - How/why were these model architectures chosen?', 'This paper proposes adversarial sampling for pool-based active learning, which is a sublinear-time algorithm based on 1) generating “uncertain” synthetic examples and 2) using the generated example to find “uncertain” real examples from the pool. I liked the whole idea of developing a faster algorithm for active learning based on the nearest neighborhood method. However, my only & major concern is that one has to train GANs before the active learning process, which might cost more than the whole active learning process.  \n\nPros: \n- This paper tackles the important problem of reducing the time complexity needed for active learning with respect to the pool size. I think this is a very important problem that is necessary to be addressed for the application of active learning.\n-The paper is well written and easy to understand.\n-I think the overall idea is novel and useful even though it is very simple. I think this work has a very promising potential to be a building block for future works of fast active learning.\n\nCons:\n-There is no theoretical guarantee on the ""uncertainty"" of obtained real examples. \n-The main contribution of this algorithm is computational complexity, but I am not very persuaded by the idea of using the GAN in order to produce a sublinear (faster) time algorithm for active learning, since training the GAN may sometimes take more time that the whole active learning process. Explicitly describing situations where the proposed method is useful seems necessary. I would expect the proposed algorithm to be beneficial when there is a lot of queries asked and answered, but this seems unlikely to happen in real situations.  \n-Empirical evaluation is weak, since the algorithm only outperforms the random sampling of queries. Especially, given that sublinear nature of the algorithm is the main strength of the paper, it would have been meaningful to evaluate the actual time spent for the whole learning process including the training of GANs. Especially, one could also speed-up max entropy criterion by first sampling subset of data-points from the pool and evaluating upon them. \n']","[-20, -20, 20]","[60, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'evaluations look reasonable'), they express significant concerns about the novelty and effectiveness of the proposed method. The reviewer concludes that 'additional work' is needed, indicating an overall negative sentiment towards the current state of the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging both pros and cons, and provides constructive feedback. They avoid harsh criticism and use phrases like 'might need to' instead of more forceful language, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer likes the overall direction and idea, they express significant concerns about the experimental results and their convincingness. The reviewer suggests that more work is needed and recommends submitting a revised version later, indicating dissatisfaction with the current state of the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as suggestions rather than harsh criticisms. They use phrases like 'I like the overall direction,' 'I believe that it would be better,' and 'I would like to see,' which maintain a polite and professional tone even while expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer expresses appreciation for the paper's idea and its potential, noting it as 'novel and useful' with 'promising potential'. However, this positivity is tempered by significant concerns, particularly about the practicality of using GANs in the process. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I liked the whole idea' and 'The paper is well written', which contribute to a polite tone. Even when presenting concerns, the language remains professional and constructive, avoiding harsh or dismissive statements.""]"
"[""In this paper, the authors present how to integrate replay buffer and on-policy trust region policy optimization (TRPO) by generalizing Q/V/advantage function and then empirically show the proposed method outperforms TRPO/DDPG.\n\nThe generalization of advantage function is quite interesting and is well written. One minor issue is that d^{\\pi_n} (s) is confusing since it appears after ds. \n\nThe theory in Section 3.1 makes sense. However, due to the limitation in Theorem 1 that $\\theta$ is the joint parameters, applying Theorem 1 can be difficult. In Eq (25), what is the $\\theta$ here? And what does $\\nabla_\\theta \\pi_n$ mean? Does $\\pi_n$ uses $\\theta$ for computation? One of the problems of using replay buffers in on-policy algorithms is that the stationary distribution of states changes as policy changes, and at least the writing doesn't make it clear on how to solve distribution mismatching issue. Further explanation on Eq (25) might help. If the distributions of states are assumed to match, then the joint distribution of states and actions may mismatch so additional importance sampling might help, as suggested in [1] Eq (3). \n\nAnother problem is on the barrier function. In Eq (26), if we only evaluate $\\rho_b(\\theta)$ (or its gradient w.r.t. $\\theta$) at the point $\\theta_old$, it doesn't differ with or without the barrier function. So in order to show the barrier function helps, we must evaluate $\\rho_b(\\theta)$ (or its gradient) at a point $\\theta \\neq \\theta_old$. As far as I know, the underlying optimizer, K-FAC, just evaluates the objective's (i.e., $\\rho_b$) gradients at $\\theta_old$. Both Conjugate Gradient (CG), which TRPO uses, and K-FAC are trying to solve $F^{-1} g$ where $g$ is the gradient of the objective at the current point. \n\nThe experiments show significant improvement over TRPO/DDPG. However, some experiments are also expected.\n1. How is the proposed algorithm compared to PPO or Trust PCL? \n2. How does the barrier function help? More importantly, what's the comparison of the barrier function to [1] Eq (5)? \n\nThe proposed algorithm seems more like a variant of ACKTR instead of TRPO since line search is missing in the proposed algorithm and the underlying optimizer is K-FAC instead of CG.\n\nRef:\n[1]: Proximal Policy Optimization Algorithms, by John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov. \n"", 'The authors introduce a off-policy method for TRPO by suggesting to use replay buffers to store trajectories and sample from them during training. To do this they extend the definition of the Q function to multiple policies where the Q_pi bar is then the expectation over the several policies. They propose the same for the value function and consequently the advantage function. \nIn my opinion this is some interesting work, but there are some details that are not clear to me, so i have several questions.\n\n1. Why is it necessary to define these generalized notions of the Q, Value and Advantage functions? You motivate this by the fact the samples stored in the replay buffer will be generated by different policies, i.e. by differently parametrized policies at a certain time step. But this also holds almost all algorithms using replay buffers. Could you plese explain this part further?\n\n2. In eq. (26) you introduce the parameter alpha as a sort of Lagrange multiplier to turn the unconstrained optimization problem defined by TRPO into a constrained one. This is was also proposed early by Schulman et al. in Proximal Policy Optimization. Yet, it is not cited or referenced. In the discussion of the experimental results go further into this. Please explain this part in more detail.\n\n3. Another point of your work is the learnable diagonal covariance matrix. How can you be sure that the improvements you show are due to the replay buffers and not due to learning these? Or learning covariance in combination with the penalty term alpha?\n\n4. Can you provide comparative results for PPO? PPO outperforms DDP and TRPO on most tasks so it would be interessting to see\n\n5. How many trajectory samples do you store in the replay buffers? Can you provide results where you use your method but without any replay buffers, i.e. by using the last batch of data points?\n\nMinor Suggestions:\n- The references for the figures in the Experiments part are off. In fig. 1 you cite Todorov et al. for Mujoco but not TRPO and ACKTR, the same in fig. 2. Then in fig. 3 you cite DDPG also with Todorov et al.\n- Some parts of the text is a bit unorganized. In section 2.1 you introduce AC algorithms and on the next page you give the definitions for all components but you don\'t say anything about how the interact. Also, the definition of the expected return was not ""invented"" by Schulman et al, and neither were Advantages, Q-, and Value functions. Maybe add a second or third reference.  \n', 'The paper tries to bring together the replay buffer and on-policy method. However, the reviewer found major flaws in such a method.\n\n- Such replay buffers are used for storing simulations from several policies at the same time, which are then utilised in the method, built upon generalised value and advantage functions, accommodating data from these policies.\n\nIf the experience the policy is learning from is not generated by the same policy, that is off-policy learning. \n\nIn the experiment part, the replay buffer size is often very tiny, e.g., 3 or 5. The reviewer believes there may be something wrong in the experiment setting. Or if the reviewer understood it incorrectly, please clarify the reason behind such a tiny replay buffer.']","[20, 20, -60]","[60, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting aspects of the paper and its well-written parts. However, they also point out several issues and limitations, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and suggests improvements without being harsh. They use phrases like 'quite interesting,' 'well written,' and 'further explanation might help,' which contribute to a polite tone. The reviewer also provides specific recommendations and references, showing engagement with the work. The overall tone is professional and aimed at improving the paper rather than dismissing it."", ""The sentiment score is slightly positive (20) because the reviewer describes the work as 'interesting' and provides constructive feedback. However, they also express several questions and concerns, which tempers the positivity. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, phrases their critiques as questions or suggestions, and uses polite expressions like 'please explain' and 'Can you provide'. The reviewer also acknowledges the authors' work positively before offering critiques. The tone is professional and constructive, avoiding harsh criticism while still pointing out areas for improvement."", ""The sentiment score is -60 because the reviewer states they found 'major flaws' in the method, which indicates a significantly negative view of the paper. They also express skepticism about the experiment settings, suggesting potential errors or misunderstandings. The politeness score is 20 because while the reviewer is critical, they use relatively neutral language and offer the authors a chance to clarify ('please clarify the reason'). The reviewer also uses phrases like 'the reviewer believes' and 'if the reviewer understood it incorrectly,' which softens the criticism. However, the overall tone is still more critical than overtly polite, hence the modest positive score.""]"
"['Summary: The authors study building models for edits in source code. The application is obvious: a system to accurately predict what the next edit should be would be very valuable for developers. Here, edits are modeled by two types of sequences: one that tracks the state of all edits at each time step (and is thus very long), and one that contains the initial step and a changelist that contains the minimal information required to derive the state at any time. The authors train models on top of both of these representations, with the idea being to match the performance of the explicit (heavy) model with the implicit model. This is shown to be challenging, but a clever model is introduced that achieves this, and is thus the best of both worlds. There are synthetic and real-world code (text) edit experiments.\n\nStrengths: The problem is well-posed and well-motivated. There\'s a nice application of powerful existing models, combined and tailored to the current work. The writing is generally quite clear. The number of experiments is quite solid. \n\nWeaknesses: The main flaw is that nothing here is really specifically for souce code; the authors are really just modeling edits in text sequences. There\'s not an obvious way to integrate the kinds of constraints that source code typically satisfies either. There\'s some confusion (for me) about the implicit/explicit representations. More questions below.\n\nVerdict: This is a pretty solid paper. It doesn\'t quite match up to its title, but it sets out a clearly defined problem, achieves its aims, and introduces some nice tricks. Although it doesn\'t produce anything genuinely groundbreaking, it seems like a nice step forward.\n\nComments and Questions:\n\n- The problem is written in the context of source code, but it\'s really setup just for text sequences, which is a broader problem. Is there a way the authors take can advantage of the structural requirements for source code? I don\'t see an obvious way, but I\'m curious what the authors think.\n\n- What\'s the benefit of using the implicit representation for the positions? The explicit/implicit  position forms are basically just using the permutation or the inverse permutation form, which are equivalent. I don\'t see directly what\'s saved here, the alphabet size and the number of integers to store is the same.\n\n- Similar question. The implicit likelihood is s^0, e^(1),...,e^(t-1), with the e^(i)\'s being based on the implicit representations of the positions. Seems like you could do this with the *explicit* positions just fine, they carry enough information to derive s^(i) from s^(i-1). That is, the explicit/implicit problems are not really related to the explicit/implicit position representations.\n\n- Just wanted to point out that this type of approach to sequences and edits has been studied pretty often in the information/coding theory communities, especially in the area of synchronization. There, the idea is to create the minimal ""changelist"" of insertions/deletions from two versions of a file. This could come in handy when building the datasets. See, for example, Sala et al ""Synchronizing files from a large number of insertions and deletions"".\n\n- The problem statement should be stated a bit more rigorously. We\'d like to say that the initial state is drawn from some distribution and that the state at each time forms a stochastic process with some transition law. As it stands the problem isn\'t well-defined, since with no probability distribution, there\'s nothing to predict and no likelihood.\n\n- The ""analogical decoder"" idea is really nice.\n\n- For the synthetic dataset, why are you selecting a random initial string, rather than using some existing generative text or source code model, which would get you synthetic data that more closely resembles code?\n\n- I really liked the idea of using an oracle that gives the position as upper bound. Would it make sense to also have the opposite oracle that gives the edit symbol, but doesn\'t tell the location? I\'m really curious which is the ""harder"" task, predicting the next symbol or the next location. In the information-theory setting, these two are actually equally hard, but the real-world setting might be pretty different. It would also be interesting to train models on top of the POMP. That would produce genuine upper bounds to the model performances. \n\n- The explicit baseline model performs very well on all the edit types in Table 1. Are there cases where even this explicit case works poorly? Is the improved implicit model *always* upper bounded by the explicit model (to me it seems like the answer should always be yes, but it would be interesting to check it out for cases where explicit is not very high accuracy). ', 'The paper provides good baselines for predicting edits in a text (evaluated on source code) learned from a history of changes. This is an interesting problem that has not beed systematically studied in literature, with the exception of several sporadic works from the software engineering community. Fully predicting the code text writing process as opposed to the code itself is an interesting task with possible big impact, IF the accuracy of this edit model manages to significantly outperform simple left-to-right code text prediction techniques.\n\nOne of closest related works to this A somewhat similar system with language models for predicting APIs based on sequences is [1], it would help to compare to it at least on a conceptual level. is [2] that predicts if a ""change"" is complete i.e if it misses to complete a change. However it does not predict the entire edit process, but only the last missing piece of a change (usually a bug if it is missed).\n\nPro:\n - First fine grained text (code) evolution evaluation and formulation of the challenge to provide labels for predicting the process of code writing.\n - Discussion about effectiveness of the introduced explicit vs implicit tasks and good trade-offs discussion.\n - Techniques are applicable and interesting beyond code.\n - Well-written and easy to follow text\n\nAgainst:\n - The introduced models are based on simple sequence representations of code tokens. Once more semantic representation (let\'s say ASTs) are taken, the implicit attention techniques may need to also be updated.\n - It would help to elaborate more on the process defined in 5 for the real dataset that given a pair of code snapshots, assumes that one is obtained by simply inserting/removing the tokens in sequence. In particular, it could be that a candidate model predicts a different sequence with the same results in the snapshots. Then the training loss function should not penalize such solutions, but it will if the sequence is not strictly left-to-right. Did you need to tweak something here especially for larger changes?\n\n[1] Anh Nguyen, Michael Hilton, Mihai Codoban, Hoan Nguyen, Lily Mast, Eli Rademacher, Tien Nguyen, Danny Dig. API Code Recommendation using Statistical Learning from Fine-Grained Changes\n[2] Thomas Zimmermann, Andreas Zeller, Peter Weissgerber, Stephan Diehl. Mining version\nhistories to guide software changes.', ""Although the subject of the task is not quite close to my area and the topic of programming language edit is relatively new to me, it is a comfortable reviewing for me thank to the well-written paper. This paper formalize a new but very interesting problem that how to learn from and predict edit sequence on programming language. \n\nPros:\n+ This paper proposed two different data representation for the tokens in text, implicit and explicit. The paper starts with a very interesting problem of programming language editing, in that the intend of source code developer's intent is predicted. \n+ The two different representations are well described, and dis/advantages are well elaborated.\n+ The writing is very technical and looks solid.\n+ Both synthetic dataset and real source code dataset are exploit to evaluate the performance of all models proposed. \n\nQuestions:\n1.\tThe content of text supposed to be programming language, but neither the model design nor synthetic dataset generation specify the type of text. \n2.\tFurther, if the text type is specified to be source code, I suppose each token will has its own logical meaning, and a line of source code will have complex logic structures that is not necessarily a flat sequence, such an “if…else…”, “try…catch…”, “switch…case…” etc. How do you address this issue with sequence models such as LSTM?\n3.\tIn generating synthetic dataset, where is the vocabulary from?\n\nMinor issues:\n1.\tThe first sentence in Abstract doesn’t look right: “Programming languages are emerging as a challenging and interesting domain for machine learning”. I suppose you meant: “Programming language generation/edit….”\n"", 'The paper presents a very interesting new task of modeling edits to a piece of source code. The task also has immediate practical applications in the field of Software Engineering to help with code reviews, code refactoring etc. \n\nPros:\n1. The paper is well-written and easy to follow.\n2. The task is novel (to my knowledge) and has various practical applications.\n3. Many obvious questions that would arise have been answered in the paper for eg., the contrast between explicit and implicit data representations.\n4. The use of synthetic data to learn about the types of edits that the models can learn is a very good idea and its inclusion is much appreciated.\n5. Evaluation on a very large real dataset demonstrates the usefulness of the model for real world tasks.  \n\nCons:\n\nIn general, I really like the task and a lot of the models and experiments, but the description of the real world experiments is severely lacking in information and results. Also, there are many unanswered questions about the synthetic experiments.\n\n1. Firstly, where is the data obtained from? Who are the programmers? What was the setting under which the data was collected in ?\n2. The paper doesn\'t provide examples from this real world dataset nor are there examples of model predictions on this dataset.\n3. What are the kinds of edits on the real world dataset? What happens if someone adds a 100 lines to a file and saves it? How is this edit added to the dataset?\n4. Some Error analysis on the real world data? It\'s hard to understand how the model is doing by just reporting the accuracy as 61.1%. Lots of the accuracy points maybe obtained for obvious commonplace edits like keywords, punctuation etc.. ? \n5. Some more dataset stats related to the real world data. For eg., how many tokens are in each snapshot?\n6. ""We evaluate models on their ability to predict a sequence of subtokens up to the next token boundary"" <-- Require more details about this. This section needs more clarity, its hard to interpret the results here.\n7. Are you going to release this real world dataset?\n8. If the real world dataset is large, why don\'t you report running time stats on that? Why use the synthetic dataset for testing scalability? If you have 8 million edits, that seems like a big enough dataset. How long did your models take on these?\n\nRe: the synthetic dataset\n\n1. It\'s nice that you\'ve tested out different single synthetic edit patterns, but what happens in a dataset with multiple edit patterns? Because this will be the scenario in a real world dataset.\n2. What happens when the order of edits is different in the prediction but the outcome is the same? Suppose we have edit A followed by B and the model predicts B followed by A, but the end result is the same? The accuracy metric will fail here? How can this be addressed?']","[60, 60, 60, 60]","[80, 80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'a pretty solid paper' and 'a nice step forward'. They highlight several strengths and praise aspects like the problem being well-posed and well-motivated, clear writing, and solid experiments. However, it's not a perfect score as they also point out some weaknesses and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance criticism with praise, use phrases like 'I'm curious what the authors think' and 'I really liked the idea', and frame their criticisms as questions or suggestions rather than harsh statements. The tone is professional and collaborative, aiming to improve the paper rather than tear it down."", ""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper, describing it as 'good', 'interesting', and having 'possible big impact'. They list several pros before mentioning any cons, and the cons are presented as suggestions for improvement rather than severe criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms as constructive feedback. They use phrases like 'it would help to' and 'Did you need to' when suggesting improvements, which maintains a collegial tone. The reviewer also compliments the paper as 'Well-written and easy to follow', further indicating a polite and professional approach to the review."", ""The sentiment score is 60 (positive) because the reviewer starts with a positive tone, mentioning that the paper is 'well-written' and describes the topic as 'very interesting'. They list several pros of the paper, indicating a generally positive view. However, they also raise some questions and minor issues, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging their own limitations ('not quite close to my area'), and framing criticisms as questions rather than direct negative statements. They also balance their critique with positive feedback. The use of phrases like 'thank to the well-written paper' and the constructive nature of the feedback contribute to the high politeness score."", ""The sentiment score is 60 (positive) because the reviewer starts by calling the paper 'very interesting' and lists several pros, indicating a generally positive view. However, they also mention some cons and areas for improvement, which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as questions or suggestions for improvement rather than harsh critiques. The reviewer also uses phrases like 'I really like the task' and 'its inclusion is much appreciated,' which contribute to a polite tone. The score isn't 100 because the review does directly point out shortcomings, albeit in a constructive manner.""]"
"['Summary:\nThe authors present a straightforward method to improve generative quality of GANs that can allow for fewer parameters by separating the task into a basic-generation followed by a chain of multiple edits to the base generation with different editor networks. The fact that separating the task allows for smaller networks is key to the reduction in parameters.  Each editor is trained separately in alternance, with its associated critic. Authors test their approach mostly on CIFAR10, as well as CelebA and MNIST.\n\nPros:\n- The proposed method is simple and makes intuitive sense. Having editor generators acting like highly-conditioned GANs should make their job easier to produce better samples.\n\n- Empirical results show that when removing editors for evaluation, some well-known architecture (DCGAN - WGAN+GP) can be outperformed with less parameters when comparing IS scores.\n\n- Interesting leads and negative results are discussed in Section 5.\n\nCons : \n- Comparisons with end-to-end training seems inadequate. The authors invalidate the end-to-end approach with two arguments; (1) that it doesn’t allow for the removal of superfluous editors once the training is done (Section 3.3), and (2) that IS scores are significantly lower (Section 4.2, Table1). It seems that both these statements are true simply because end-to-end learning is performed with a single score outputted by a single critic at the end of the chain, while it would be entirely possible and simple to keep all discriminators and associated losses and train end-to-end. This would still push all editors to produce good samples, thus allowing removal of editors at test-time, and would probably yield better results than those reported in Table 1. It could also invalidate the results shown in Figure 4 (left). For me this is an important missing comparison, as it might even yield better results than the proposed approach and invalidates one of the proposed advantage of the method.\n\n- I think this idea of sequential generation has been explored before, (e.g. StackGAN [1, 2] or LAPGAN [3] and others?), in which unconditional image generation is performed on relatively complicated datasets with a somewhat more principled way of actually simplifying the task of the base generator. Therefore, I think important citations and valid comparisons are missing.\n\n- The only reported metric is the Inception Score (IS), while most of the recent literature agrees that the Fréchet Inception Distance is a better metric. I think FID should be presented as well to be better aligned with recent literature, even in cases where comparison with previously reported performance is impossible (if previous works only presented IS). If you want to be compared to in future work, I think this is necessary.\n\n- It would be a good addition to have FID/IS scores for each editor output, as we could see the quantitative increase in performance at each editing step.\n\n- In Section 4.2, you specify that all experiments are done using the WGAN-GP training formulation. Looking at Table 1 this is unclear, as you specify this training scheme only for model 6 and model 9. If all models use the same training scheme, this information should be absent from the Table.\n\n- CelebA results. Experiments are reported in the main text, without any results, which are only in the Appendix. These results don’t show any quantitative metrics and are visually disappointing. It is hard to see if the editors actually improve the generation.\n\n- Some of the main results or discussions are based on Section 7, which is not the main article even though it is used as another Section instead of an Appendix. I think Section 7 should be separated into Appendices A, B, etc. Maybe some important aspects of the research presented could fit into the main text, given some removal of repetitions, and some compression of the intro to GANs, which should be vastly known by the ICLR community by now.\n\n- Wrong citation format at the end of Section 2.1.\n\n- Section 3.3 : “train the critic more than the generator in each iteration”. This could be clarified by stating exactly what you do (training the critic for k steps for each generator steps).\n\n- It’s not always clear what the boldface represents throughout tables.\n\n- The discussion in Section 5 about promising techniques explored is somewhat disappointing as efforts to investigate why training failed are not apparent.\n\n- Every result shown from the proposed method is performed with ‘small’ or ‘tiny’ versions of existing architectures. This method could have additional value if it could boost performance on the same architecture, even if there are added editors and trainable parameters. The fact that such results are absent makes me suspicious of such a behavior.\n\nOverall I think this paper presents a relevant and interesting idea. However I think this idea has been explored before with more convincing results and with a more principled approach. There are some important flaws in the comparisons made to assess the advantages of the method, and the overall results fail to convince of any important benefit. Based on the pros/cons stated above, I think this paper does not reach the required quality for acceptance in ICLR.\n\n[1] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al. 2017)\n[2] StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al. 2017)\n[3] Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks (Denton et al. 2015)\n', ""The authors propose `ChainGAN, a GAN architecture where the generator is supplemented with a series of editors that iteratively improve image quality. In practice, the algorithm also uses multiple critics (discriminators), although this is not explained until the Experiments section. \n\nThe paper contains the germ of a powerful idea. However, it feels as if the authors haven't yet come to grip with their own idea and architecture. Currently, the role of the editors feels underspecified: it is unclear (and unexplored?) what architectures make for good editors; exactly how editors should interact with the various losses; and what the role of the critics (ideas are proposed in related work) should be. In the experiments, the editors sharpen image quality, but the tradeoffs are not explored. Are more editors always better? When does it saturate? Why? Adding a few editors and critics makes the architecture more parameter-efficient, but increases the number of losses. What happens to wall-clock training time? Moreover, the paper is conflicted about the role of the critic(s). Is the core idea to have multiple generators, discriminators, or both? What is moving the needle? \n\n\n"", 'The paper proposes a GAN variant, called ChainGAN, which expresses the generator as a ""base generator"" -- which maps the noise vector to a rough model sample -- followed by a sequence of ""editors"" -- which progressively refine the sample. Each component of the generator is trained independently to fool its own separate discriminator, without backpropagating through the entire chain of editors. The proposed ChainGAN model is trained on MNIST, CIFAR10, and CelebA. The paper presents model samples for all three datasets, as well as Inception scores for CIFAR10.\n\nI find the proposed idea simple and elegant but the evaluation lacking, and as such I’m a bit hesitant to outright recommend accepting the paper:\n\n- Evaluation is not very extensive or detailed. Inception scores are shown only for CIFAR10 and using two base generator architectures. The Inception score has known limitations, and I would have expected the authors to also provide FID scores. The main takeaway is also not articulated very clearly. As far as I can tell it appears to be that ChainGAN allows to achieve similar performance with less tunable parameters, but Table 1 shows mixed results, where ChainGAN outperforms the baseline DCGAN architecture using fewer parameters but underperforms the baseline ResNet architecture.\n- The way the experimental section is organized made it difficult for me to find my way around. For example, subsection titles are hard to locate due to the fact that figures and tables were placed immediately underneath them. Overall when the flow of the text is interrupted by a figure, it’s hard to locate where to resume reading.\n- There is a connection to be made with other sequential generation approaches (not to be confused with sequence generation) such as LAPGAN, DRAW, and Unrolled GANs. Discussing the relationship to those approaches would in my opinion add more depth to the paper.']","[-50, -20, -20]","[60, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('pros') of the paper, the overall tone is critical and the review concludes with a recommendation against acceptance. The reviewer points out several significant flaws and missing comparisons, which outweigh the positive aspects. The politeness score is 60 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I think' and 'It would be a good addition' when offering criticisms. The reviewer also balances negative points with positive ones and provides detailed explanations for their concerns, which is a polite way to give feedback. However, the score is not higher as the review is still quite critical and direct in its assessment."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the 'germ of a powerful idea', they express several concerns and criticisms about the paper's execution and clarity. The reviewer points out underspecified aspects, unexplored tradeoffs, and conflicting ideas, indicating that the paper needs significant improvement. However, the score is not deeply negative as the reviewer sees potential in the core concept.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They begin by acknowledging the potential of the idea and use phrases like 'it feels as if' and 'it is unclear' rather than making blunt criticisms. The reviewer asks questions to prompt further exploration rather than making accusatory statements. The language is direct but not rude, focusing on the work rather than the authors personally."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the proposed idea 'simple and elegant', they express hesitation about recommending acceptance due to lacking evaluation. They point out several shortcomings in the paper, such as limited evaluation, unclear organization, and missing comparisons to related work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects ('simple and elegant') before presenting criticisms. They frame their concerns as suggestions for improvement rather than harsh criticisms. The reviewer maintains a professional tone, avoiding personal attacks or overly negative language, which contributes to the polite impression.""]"
"['The authors propose to include phrases (contiguous n-grams of wordpieces) in both the self-attention and encoder-decoder attention modules of the Transformer model (Vaswani et al., 2017). In standard multi-head attention, the logits of the attention distribution of each head is computed as the dot-product between query and key representations, which are position-specific. In the phrase-based attention proposed here, a convolution is first computed over the query, key, value sequences before logits are computed as before (a few variants of this scheme are explored). Results show an improvement of up to 1.3 BLEU points compared to the baseline Transformer model. However, the lack of a controlled experiment sheds substantial doubt on the efficiacy of the model (see below).\n\nContributions\n-------------------\nProposes a simple way to incorporate n-grams in the Transformer model. The implementation is straightforward and should be fully replicable in an afternoon.\n\nHaving an inductive bias towards modeling of longer phrases seems intuitively useful, in particular when using subword representations, where subword units are often ambiguous. This is also motivated by the fact that prior work has shown that subword regularization, where sampling different subword segmentations during training can be useful.\n\nImprovements in BLEU scores are quite strong.\n\nIssues\n---------\nThe experiments do not control for parameter count. The phrasal attention model adds significant number of parameters (e.g., ""interleaved attention"" corresponds to 3x the number of 1D convolution parameters in the attention layer). It is well established that more parameters correspond to increased BLEU scores (e.g., the 2x parameter count in the ""big"" Transformer setting from Vaswani et al. (2017) results in over 1 BLEU point improvement). This needs to be fixed!\n\nThe model is a very modest extension of the original Transformer model and so its value to the community beyond improved numbers is somewhat questionable.\n\nWhile an explicit inductive bias for phrases seem plausible, it may be that this can already be fully captured by multi-head attention. With positional encodings, two heads can easily attend to adjacent positions which gives the model the same capacity as the convolutional phrase model. The result in the paper that trigrams do not add anything on top of bigrams signals to me that the model is already implicitly capturing phrase-level aspects in the multi-head attention. I would urge the authors to verify this by looking at gradient information (https://arxiv.org/abs/1312.6034).\n\nThere are several unsubstantiated claims: ""Without specific attention to phrases, a particular attention function has to depend entirely on the token-level softmax scores of a phrase for phrasal alignment, which is not robust and reliable, thus making it more difficult to learn the mappings."" - The attention is positional, but not necessarily token-based. The model has capacity to represent phrases in subsequent layers. WIth h heads , a position in the k-th layer can in principle represent h^k grams (each slot in layer 2 can represent a h-gram and so on).\n\nThe differences in training setup compared to Vaswani et al. (2017) needs to be explicit (""most of the training settings"" is too handwavy). Please list any differences.\n\nThe notation is somewhat cumbersome and could use some polishing. For example, the input and output symbols both range over indices in [1,n]. The multi-head attention formulas also do not match the ones from Vaswani et al. (2017) fully. Please ensure consistency and readability of symbols and formulas.\n\nThe model inspection would be much improved by variance analysis. For example, the numbers in table 3 would be more useful if accompanied by variance across training runs. The particular allocation could well be an effect of random initialization. I could also see other reasons for this particular allocation than phrases being more useful in intermediate layers (e.g., positional encodings in the first layer is a strong bias towards token-to-token attention, it could be that the magnitude of convolved vectors is larger than the batch-normalized unigram encodings, so that logits are larger.\n\nQuestions\n--------------\nIn ""query-as-kernel convolution"", it is unclear whether you map Q[t, :] into n x d_q x d_k convolution kernel parameters, or if each element of the window around Q[t] of width n is mapped to a convolution kernel parameter. Also what is the exact form of the transformation. Do you transform the d_q dimensional vectors in Q to a d_q x d_k matrix? Is this done by mapping to a d_q * d_k dimensional vector which is then rearranged into the convolution kernel matrix?\n\nDoes the model tend to choose one particular n-gram type for a particular position, or will it select different n-gram types for the same position?\n\n""The selection of which n-gram to assign to how many heads is arbitrary"" - How is this arbitrary? This seems a rather strong inductive bias?\n\n""However, the homogeneity restriction may limit the model to learn interactions between different n-gram types"" - How is the case? It seems rather that the limitation is that the model cannot dynamically allocate heads to the most relevant n-gram type?\n\nI do not understand equation 14. Do you mean I_dec = I_cross = (...)?\n\n""Phrase-to-phrase mapping helps model local agreement, e.g., between an adjective and a noun (in terms of gender, number and case) or between subject and verb (in terms of person and number)."" Is this actually verified with experiments / model inspection?\n\n""This is especially necessary when the target language is morphologically rich, like German, whose words are usually compounded with sub-words expressing different meanings and grammatical structures"" This claim should be verified, e.g. by comparing to English-French as well as model inspection.\n', 'Phrase-Based Attention\n\nPaper Summary:\n\nNeural translation attention computes latent alignments which pairs input/target positions. Phrase-based systems used to align pairs of spans (n-grams) rather than individual positions, this work explores neural architectures to align spans. It does so by compositing attention and convolution operations. It reports empirical results that compares n-gram to uni-gram attention.\n\nReview:\n\nThis paper reads well. It provides appropriate context. The equations are correct. It lacks a few references I mentioned below. The main weaknesses of the work lies in its motivation and in the \nempirical results.\n\nThis work motivation ignores an important aspect of neural MT: the vectors that attention compares (“queries” and “keys”) do not summarizes a single token/unigram. These vectors aggregate information across nearby positions (convolutional tokens, Ghering et al 2017), all previous tokens (recurrent models, Suskever et al 2014) or the whole source sentence (transformer, Vaswani et al 2017). Moreover multiple layers of attention are composed in modern decoders, comparing vectors which integrates information from both source and target. These vectors cannot be considered as the representation of a single unigram from the source or from the target.\n\nThe key-value convolution method 3.1.1 is not different from (Ghering et al 2017) which alternates computing convolution and attention multiple times. The query as kernel is a contribution of this work, it is highly related to the concurrent submission to ICLR on dynamic convolution “Pay Less Attention with Lightweight and Dynamic Convolutions”. This other work however reports better empirical results over the same benchmark.\n\nOn empirical results, it seems that the table does not include recent results from work on weighted transformer (Ahmed et al 2017) or relative attention (Shaw et al 2018). Also a 0.1 BLEU improvement over Vaswani et al seems brittle, is your result averaged over multiple runs, could the base transformer be better with as many parameters/updates as your model?\n\nReview Summary:\n\nThis work starts from the premise that current models attends to unigram representation, which is wrong (keys and values already depends on multiple source/target positions). The empirical results are missing recent improvements. The reported empirical advantage compared to baseline is thin. The most interesting contribution is the query as kernel approach: however the concurrent submission “Pay Less Attention with Lightweight and Dynamic Convolutions” obtains better empirical results with a similar idea.\n\nMissing references:\n\nKarim Ahmed, Nitish Shirish Keskar, and Richard Socher. 2017. Weighted transformer network for machine translation. arxiv, 1711.02132.\n\nPeter Shaw, Jakob Uszkoreit, and Ashish Vaswani. 2018. Self-attention with relative position representations. In Proc. of NAACL.\n', 'This paper presents an attention mechanism that computes a weighted sum over not only single tokens but ngrams (phrases). Experiments on WMT14 show a slight advantage over token-based attention.\n\nThe model is elegant and presented very clearly. I really liked the motivation too. \n\nHaving said that, I am not sold on the claim that phrasal attention actually helps, for two reasons:\n\n1) The comparison to previous results is weak. There are more datasets, models, and hyperparameter settings that need to be tested.\n\n2) Phrasal attention essentially adds an additional convolution layer, i.e. it adds parameters and complexity to the proposed model over the baseline. This needs to be controlled by, for example, adding another transformer block to the baseline model. The question that such an experiment would answer is ""does phrasal attention help more than an extra transformer layer?"" In my view, it is a more interesting question than ""does phrasal attention help more than nothing?""\n\nAlso related to concern (2), I think that the authors should check whether the relative improvement from phrasal attention grows/shrinks as a function of the encoder\'s depth. It could be that deep enough encoders (e.g. 10 layers) already contain some latent representation of phrases, and that this approach mainly benefits shallower architectures (e.g. 2 layers).\n\n===  MINOR POINTS ===\nIf I understand the math behind 3.1.2 correctly, you\'re first applying a 1x1 conv to K, and then an nx1 conv. Since there\'s no non-linearity in the middle, isn\'t this equivalent to the first method? The only difference seems to be that you\'re assuming the low-rank decomposition fo the bilinear term at a different point (and thus get a different number of parameters, unless d_k = d_q).\n\nHave you tried dividing by sqrt(d_k * n) in 3.1.1 too?\n\nWhile the overall model is well explained, I found 3.3 harder to parse.']","[-20, -30, 20]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Improvements in BLEU scores are quite strong'), they raise several significant concerns and issues. The reviewer points out lack of controlled experiments, questions the value of the model beyond improved numbers, and highlights unsubstantiated claims. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'I would urge the authors to verify' and 'Please ensure consistency', and frame their criticisms as suggestions for improvement rather than harsh judgments. The reviewer also acknowledges the potential contributions of the paper before delving into the issues, which contributes to the polite tone."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('This paper reads well', 'provides appropriate context', 'equations are correct'), they express significant criticisms about the paper's motivation, empirical results, and overall contribution. The reviewer points out 'main weaknesses' and suggests the reported improvements are 'thin' and potentially 'brittle'. However, the tone is not entirely negative, hence a score above the minimum. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or personal criticisms. They offer constructive feedback and suggestions for improvement, such as missing references. The tone is academic and objective, maintaining politeness while still conveying critical points."", ""The sentiment score is slightly positive (20) because the reviewer starts with praise for the paper's clarity and motivation, but then expresses significant concerns about the claims and methodology. The overall tone is constructive but skeptical. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms, and phrases concerns as suggestions rather than direct criticisms (e.g., 'I am not sold on the claim' rather than 'The claim is wrong'). The reviewer also uses polite phrases like 'I really liked' and frames recommendations as questions to be explored rather than demands.""]"
"['The paper proposes a new representation of Wasserstein AutoEncoder and provides the formal analysis of learning autoencoders with optimal transport theory. The proposed model, SAE, employs the constraints on the equality of prior and posterior latent spaces with a Sinkhorn distance. Moreover, the proposed model is also backed up with some theoretical guarantees.\n\nThe paper is well-written and easy to follow. The experimental results with different priors have demonstrated the effectiveness of the newly formulated model. However, it is not convinced that what is the advantages of the proposed model with WAE. Can the authors provide more insight and comparison with its counterpart, WAE?\n\nIn term of time-complexity, computing Sinkhorn distance in Alg 1 introduces computation overhead, especially with small \\epsilon. In compared with WAE, what is the computation overhead of the proposed model? Can the authors provide some theoretical analysis of time-complexity and experimental results?\n\nIn Table 2, there are only FID values for WAE with MMD cost. Can the authors show the numbers with WAE-GAN on these datasets?\n\nConclusion: The theoretical and experimental contributions are significant to publish at the venue.', 'Summary\n\nThis paper builds upon the recent Wasserstein Auto-Encoders; the main innovation is the use of the Sinkhorn distance between the prior and the aggregate posterior. This distance, is used as a differentiable and more tractable surrogate for the wasserstein distance, which is proposed as an alternative to heuristics (e.g. MMD) in Wasserstein-auto encoders.\n\nAlso, the authors provide some theoretical results complementing the Wasserstein Auto-Encoders papers and illustrate their results showing better or equal performance than with alternatives, particularly VAE and WAE.\n\nEvaluation.\nIt is certainly a good paper, and well written (but notice several typos). The experimental part is thorough which certainly plays in favor at evaluation time. Theoretical results are a significant contribution, but not quite deep.\n\n But what troubles me is that when I read the paper it was hard for me to understand what the contribution is. My guess on this is what I wrote in the Summary. And if that is the case, I think it is a rather marginal contribution: it would be desired to have a theory for why using the wassertein penalization is better than the ones proposed in the WAE paper (Recall, there, penalizations are introduced to get rid of a constraint that appears in the minimization paper). The authors argue that Sinkhorn does as good as wasserstein and I can believe that (but it would be good if authors could refer to recent results [1] regarding the quality of this approximation, which essentially say that sinkhorn does no do miracles) but the most fundamental question is why a wasserstein penalization is better than the ones proposed in WAE. If no such theory is available, it is hard for me to judge the paper as non-marginal.\n\nTheorem 3.1 is an attempt for such an explanation, but it was not clear at all for me why theorem 3.1 implies that wasserstein distance is the penalization to use. Theorem 3.1 only gives an upper bound. The authors may elaborate on this\n\n\nI hope my criticism is helpful for improving the current version of the manuscript.\n\n\n[1] http://proceedings.mlr.press/v75/weed18a/weed18a.pdf\n\n\n=== after rebuttal ===\n\nThe authors have addressed my concerns and I have updated my score accordingly.', 'I tried to understand the paper it seems to me that the paper proposed a new objective function for learning an autoencoder based on Sinkhorn algorithm. Following the idea of Sinkhorn algorithm, the Sinkhorn autoencoder minimizes the W-distance between aggregated posterior and the data prior via integrating the objective of (original) autoencoder and Sinkhorn distance. This looks new, but I did not look insight to the detailed derivations. One thing that I do not like is that Sinkhorn distance needs to be optimized before optimizing the autoencoder distance, if I understand correctly.', ""The paper introduces a new cost function for training Wasserstein Autoencoders that combines reconstruction error with Sinkhorn distance on the latent space. Authors provide nice theoretical motivation, yet empirical results seem incremental and do not fully support the effectiveness of this approach.\n\nPros:\n- Theorem 3.1 (although trivial) provides motivation for optimizing Wasserstein distance in the latent space in WAEs.\n- Theorem 3.2 shows sufficiency of optimization over deterministic encoders in WAEs.\n- The proposed SAE virtually does not favor any prior and can preserve some aspects of geometry of the original space. \n\nCons:\n- It is unclear why Sinkhorn algorithm would provide better estimate of Wasserstein distance than e.g. adversarial WGANGP (which would be a variant of GAN-WAE). Sinkhorn convergence is discussed only in terms of sample size and  smoothing regularizer, not in the context of batch training. \n- Quantitative results are on par or marginally better than other methods, they also lack some comparisons (see details below).\n- There is no comparison to relevant models outside VAE scope, e.g. ALI [4]. \n\nThe novelty of this paper is combining WAEs with Sinkhorn algorithm. Overall, it has potential, but the proposed method would probably require clearer evaluation. \n\nDetailed issues:\n- Notation for posterior seems somewhat inconsistent and misleading, namely push-forward G#P_Z = P_G, while Q#P_X = Q_Z.\n- It is unclear why MMD or GAN losses on WAS's latent space are referred to as heuristics, each of these constitutes a divergence in the same way as the proposed Sinkhorn distance.\n- FID scores for MNIST are incomparable due to the use of own network; using LeNet has been proposed [3].\n- It is unclear what ‘Empirical lower bounds’ for MMD mentioned in Table 1. caption mean, as unbiased MMD estimator (e.g. [2]) is available. On the other hand, FID is known to be biased [3], so test-set FID should be provided for comparison.\n- Table 2. lacks comparison of SAE with normal prior even though a) authors note that MMDs are incomparable with different priors, b) SAEs is claimed to be prior-agnostic, c) in such setting MMD-WAE might be advantageous [1]. Again, no test-set FID scores.\n- Samples in Figure 2 too small.\n- MMD lacks citation (e.g. [2]).\n\nTypos:\np.6 line 3 construcetion -> construction\np.6 line 30 Hypersherical -> Hyperspherical \nP.8 line 1 this a sign -> this is a sign\n\n[1] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schölkopf. Wasserstein Auto-Encoders. ICLR 2018.\n[2] Arthur Gretton, Karsten M. Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alex J. Smola. A kernel two-sample test. The Journal of Machine Learning Research, 13, 2012a.\n[3] Mikołaj Bińkowski, Dougal J. Sutherland, Michael Arbel, Arthur Gretton. Demystifying MMD GANs. ICLR 2018.\n[4] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky and Aaron Courville. Adversarially Learned Inference. ICLR 2017\n""]","[70, 20, 20, -20]","[80, 60, 0, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses that the paper is well-written, easy to follow, and has demonstrated effectiveness. They also state that the theoretical and experimental contributions are significant enough for publication. However, it's not a perfect score as they do raise some questions and request additional information. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and concludes with a positive recommendation. They maintain a professional and constructive tone, offering specific areas for improvement without being harsh or dismissive."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges it as 'certainly a good paper' with thorough experiments and some theoretical contributions. However, they express concerns about the significance of the contribution and desire for more theoretical justification, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement. Phrases like 'I hope my criticism is helpful' and 'The authors have addressed my concerns' indicate a polite and collegial tone. The reviewer maintains a professional and considerate demeanor while still providing honest feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the proposed approach ('This looks new') and provides a brief summary of the paper's content without major criticisms. However, the reviewer also expresses a concern ('One thing that I do not like...'), which prevents the score from being higher. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer maintains a professional tone throughout, stating their understanding and opinion without using overly formal or informal language. The phrase 'I tried to understand' and 'if I understand correctly' indicate a level of humility, but not enough to push the score into the positive range."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice theoretical motivation', 'provides motivation', 'shows sufficiency'), they also express significant concerns ('empirical results seem incremental', 'do not fully support the effectiveness', 'unclear why', 'lack some comparisons'). The overall tone suggests the paper has potential but requires substantial improvements. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present both pros and cons objectively, use phrases like 'it is unclear' rather than direct criticisms, and offer constructive suggestions for improvement. The reviewer also acknowledges the paper's potential and provides detailed feedback, which is a polite and helpful approach.""]"
"['This paper uses a mixed strategy perspective for GANs. With this formulation the non-convex game formulation of GANs can be transformed into a infinite dimensional problem analog to a finite dimensional bilinear problem.  \n\nI really like this approach, that tries to find methods that converge globally to (mixed) Nash equilibriums. However I have some concerns. \n\n- I\'m concerned about the definition of a $O(T^{-1})-NE$. Actually, this merit function is not standard for game. It can be 0 even if $x_t,y_t$ is far from the equilibrium (for instance for the problem $\\min_{x \\in \\Delta_d}\\max_{y \\in \\Delta_d} x^\\top y$ with $x_t = (1,0,\\ldots,0)$ and $y_t= (F(x_{NE},y_{NE}),1-F(x_{NE},y_{NE}),0,\\ldots,0)$ we have $F(x_t,y_t) = F(x_{NE},y_{NE})$ but $x_{NE} = y_{NE} =(1/d,\\ldots,1/d)$). One merit function that could be considered is $\\max_{y} F(x,y_t) - \\min_{y} F(x_t,y)$. \n\n- There is a gap between the theory and the practical method that could be bridged. Actually Theorem 2 assume that the stochastic derivatives are unbiased but since your Langevin dynamics gives you an *approximate* of the next distribution an analysis taking into account this bias would provide much stronger results. More precisely, it would be interesting to have a result similar as Theorem 2 with conditions on $\\epsilon_t$ and $K_t$. For instance, if the theoretical $K_t$ is too large it would reduce the interest of your algorithm. I think this analysis is key since it allows to claim that you can properly approximate the distributions of interest.\n\nIf you are able to ease these concerns I\'m eager to increase my grade.\n\n\n- ""(5) is exactly the infinite-dimensional analogue of (1):"" Actually it is not exactly the analogue since $<.,.>$ is not a scalar product anymore (particularly, $<g,\\mu>$ is not defined) but the canonical pairing between a space and its dual (we are loosing something going to infinite dimension).\nI think it should be clarified somewhere. \n\nMinor comments: \n- on the updates rules of $\\theta$ and $\\omega$ (Page 6) the Gaussian noises are missing. \n- On algorithm 3,4,5 and 6 the Gaussian noise is too wide and causes an Overfull.\n\n=== After Authors response ===\nThe authors fixed some major issues. That is why I improved my grade. \nHowever I\'m still concerned about the scalability of this algorithm\n', 'This paper extends the mirror-descent and mirror-prox algorithms to infinite dimensional Banach spaces so that they can be applied to solve the mixed Nash equilibrium of the popular generative adversarial networks. The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces. A sample-based practical algorithm is proposed so that the infinite dimensional algorithms can still be computed. Experiments are a bit disappointing as the authors only used visual appeal as an evaluation criterion. (I understand why the authors chose to do so but as an algorithmic paper, resorting to an evaluation based on visual appeal is almost always unsatisfactory.)\n\nQuality: The quality of this work is moderate. Quite strangely, the authors made a fundamental mistake at the very beginning: their definition of approximate mixed equilibrium  (page 2, Notation) is bizarre and different from those in previous work (such as Nemirovski\'s MP paper). Fortunately, this is perhaps only an oversight on the definition; the algorithms and theorems are for the correct definition anyways. Example: consider min_{-1<= x <= 1} max_{-1<=y<=1} xy. Should we call (x, 0) an (approximate) NE for any x??\n\nAnother major issue with this work is its relaxation into mixed NE. The ""bilinarization"" trick in Eq (5) goes back to Kantorovich (who perhaps deserves to be mentioned), and is a relaxation in general: we now have to use a mixture of generators. Since MD/MP is not sparse, in the end we must use a large number of mixtures of generators. This certainly will create some computational issues, and make comparison to pure NE methods unfair.\n\nClarity: The writing of this work is mostly easily to follow. However, the presentation of the technical results suffers from a real dilemma: On one hand, the authors completely ignored the technical difference between infinite dimensional Banach spaces and finite dimensional spaces. In fact, the authors never even formally defined the underlying Banach spaces. Another example, is the mapping G on page 3 continuous? wrt what topology? without such discussion what do you mean by Frechet derivative on page 4? when is the entropy function well-defined? when is the integral of exponential well-defined? Part of me totally understand that these technicalities are daunting and perhaps should not appear in the main text. On the other hand, aren\'t these technicalities the only ""interesting and nontrivial"" part of the extension to infinite dimensional spaces? If we do not care about such technicalities and can safely ""assume they can be taken care of,"" then why is this work nontrivial? I do not see a way to resolve this dilemma here but suggest the authors consider maybe a different venue for such type of results.\n\nOriginality: The novelty of this work is limited. The extension of MD/MP to infinite dimensional spaces is mostly formal but straightforward. In fact I believe previous authors such as Nemirovski deliberately restrict to finite dimensional spaces not because of technical incapability but to avoid uninspiring technicalities. Some very related previous works were not mentioned at all:\n-- Mirror Descent Learning in Continuous Games\n-- Convex Games in Banach Spaces\n-- On the Universality of Online Mirror Descent\n\nThe sample based algorithms are more interesting because they make the infinite dimensional extensions implementable. However, one can not say much about their convergence behavior at the moment.\n\nSignificance: The main results, although not difficult to obtain, can potentially be very useful in broadening our arsenal of tools for training GANs. The claim ""resolving the longstanding problem that no provably convergent algorithm exists for general GAN"" in the Abstract is disturbing, because the authors changed the definition of GAN and because the technical contributions of this work do not live up to that strong claim. \n', 'This paper proposes to consider the mixed equilibrium objective function for GANS. The authors generalize the mirror descent/mirror prox to handle continuous games. The technical challenge is to write those algorithms in infinite dimensional spaces. This reviewer finds this however to be a mere technicality, and there seems to be no conceptual obstruction. In fact other paper have already written this, see for example ``Mirror Descent Learning in Continuous Games"" by Zhou et al. at CDC 2017 (I\'m sure there are other references too).\nWhile the theory part is not particularly exciting, the paper could be saved by the experiments. However as far I can tell the authors are only able to reproduce the results obtained with more classical approaches.\n']","[-20, -30, -50]","[60, 20, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer expresses liking the approach, they raise significant concerns about the methodology and gaps between theory and practice. The reviewer indicates willingness to increase their grade if concerns are addressed, suggesting the current evaluation is not very positive. The politeness score is moderately positive (60) as the reviewer uses respectful language, acknowledges positives, and frames criticisms constructively as 'concerns' rather than flaws. They also express eagerness to potentially improve their evaluation. The tone is professional and collegial throughout, even when pointing out issues."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper. The reviewer describes the quality as 'moderate', mentions 'disappointing' experiments, and highlights 'major issues'. However, it's not entirely negative as the reviewer acknowledges some potential usefulness and interesting aspects. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They offer constructive criticism and suggestions, and use phrases like 'I understand why' and 'Part of me totally understand' which show empathy. The reviewer also balances negative points with positive ones, maintaining a polite tone even when pointing out flaws."", ""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper. They describe the technical contribution as 'a mere technicality' and 'not particularly exciting'. They also state that the paper could only 'reproduce the results obtained with more classical approaches', suggesting a lack of novelty. However, it's not entirely negative as they acknowledge the potential for the paper to be 'saved by the experiments'. The politeness score is 0 (neutral) because the reviewer's language is neither overtly polite nor rude. They express their criticisms directly but professionally, without using inflammatory language or personal attacks. The reviewer maintains a formal, academic tone throughout the review.""]"
"['Brief Summary:\nThe authors present a novel adversarial attack on node embedding method based on random walks. They focus on perturbing the structure of the network. Because the bi-level optimization problem can be highly challenging, they refer to factorize a random walk matrix which is proved equivalent to DeepWalk. The experimental results show that their approach can effectively mislead the node embedding from multi-classification. \n\nQuality:\nThis paper is well-written except for some minor spelling mistakes\n\nClarity:\nThis paper is quite clear and easy to follow.\n\nOriginality:\nThis work follow the proposal Qiu et al.(WSDM\'18)\'s proof and present a novel approach to calculate the loss when the network changes by A\'.\n\nPros:\n1. Detailed proofs presented in appendix\n2. They present 6 questions and answer them with effective experiments.\n3. They present a new way to attack node embedding by factorizing a equivalent matrix.\n\nCons:\n1. I have noticed that Zügner et al.(KDD\'18) present an adversarial attack method on GCN for graph data. I think it is reachable by the day the authors submitted this paper. This is opposite to the first sentence ""Since this is the first work considering adversarial attacks on node embeddings there are no known\nbaselines"" said in Section 4.\n2. The author present the time analysis of their approach but the efficiency result of their approach is not presented.\n3. To enforce misclassification of the target node t, the author set the candidate flip edges as edges around t. Does this mean only the node\'s local edges can mislead the target node from downstream tasks? I think the authors should consider more candidate edges but this may lead to larger time complexity.\n4. Figure. 4 tells that low-degree nodes are easier to mis-classify. If the baseline method B_{rnd} randomly select edges to flip among the local area of node t, I think the result should be similar to the proposed approach on low-degree nodes because the flipped edges should be the same. \n\n== I have read the rebuttal. Thanks for the response.', ""This paper is a timely work on poisoning random walk based graph embedding methods. In particular, it shows how to derive a surrogate loss function for DeepWalk. Even though the analysis method and the algorithm proposed is somewhat loose, I think this paper do a good contribution towards the adversarial attack problem for important models.\n\nThere are still some room to improve in this paper. One problem is that since the paper proposes a surrogate loss L_{DW3}, it would be natural to analysis its gap from L_{DW1}. In this paper I can only see some empirical results on this issue. Another issue is that the algorithm the paper used is another approximation towards L_{DW3} by an additional sampling method. And the overall strategy can be far away from the true optimal solution for maximizing L_{DW3}. Still there's no analysis on that issue. A potential drawback for the method proposed is that its complexity is O(NE), which can be quite expensive when the graph is big, and # edges is \\Omega(NlogN).\n\nThe experiments in this paper is convincing. It seems that the method proposed is way better than its competitors when removing edges. Is there any further intuition on that? Why the method is not so good when we add edges? Moreover, the black-box attack scenario requires more justification. What is the relative performance gain for A_{DW3} against other attacks in the black-box setting?\n\nOverall, this paper targets on an important issue in machine learning. My main concern is that it leaves too many questions behind their algorithms. Still some effort is required to improve the paper."", 'The topic of this paper is interesting; however, the significance of the work can be improved.  I recommend that the authors test the vulnerability of node embeddings on various random graph models.  Examples of random graph models include Erdos-Renyi, Stochastic Kronecker Graph, Configuration Model with power-law degree distribution, Barabasi-Albert, Watts-Strogatz, Hyperbolic Graphs, Block Two-level Erdos-Renyi, etc.  That way we can learn what types of networks are more susceptible to attacks on random-walk based node embeddings and perhaps look into why some are more vulnerable than others.']","[60, 20, -20]","[70, 50, 50]","[""The sentiment score is 60 (moderately positive) because the reviewer highlights several pros of the paper, including its clarity, detailed proofs, and novel approach. They describe it as 'well-written' and 'quite clear and easy to follow'. However, they also list some cons, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They phrase criticisms constructively as suggestions or questions rather than harsh judgments. The reviewer also thanks the authors for their rebuttal at the end, showing courtesy. The tone remains professional and objective throughout, without any rude or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'timely' and making a 'good contribution', but also points out several areas for improvement. The overall tone is constructive but with reservations. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. Phrases like 'There are still some room to improve' and 'My main concern is' indicate a polite approach to giving feedback. The reviewer also asks questions to prompt further thought rather than making blunt criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the topic is interesting, they state that 'the significance of the work can be improved.' This suggests that the paper has potential but falls short in its current form. The politeness score is moderately positive (50) as the reviewer uses polite language such as 'I recommend' and provides constructive suggestions without harsh criticism. The tone is professional and helpful, offering specific examples to improve the work, which contributes to the politeness. The reviewer balances critique with guidance, maintaining a respectful tone throughout.""]"
"['The main idea behind the paper is to use random projections as the initial word representations, rather than the vocab-size 1-hot representations, as is usually done in language modeling. The benefit is that the matrix which projects words into embedding space can then be much smaller, since the space of random projections can be much smaller than the vocab size. The idea is an interesting one, but this work is at too much of a preliminary stage for a top-tier conference such as ICLR. In its present state it would make for a potentially interesting paper at a targeted workshop.\n\nMore specific comments\n--\n\nThe initial description of the language modeling problem assumes a particular decomposition of the joint probability, according to a particular application of the chain rule, but of course this is a modeling choice and not the only option (albeit the standard one).\n\nThe main problem with the paper is the use of simple baseline setups as the only experimental configuration:\n\no feedforward rather than recurrent network;\no use of the Penn Treebank dataset only;\no use of a small n for the n-grams.\n\nAll or at least some of these decisions would need to be relaxed to make a convincing paper.\n\nThe reasons for the use of the energy-based formulation are not clear to me. Is the energy-based model particularly well-suited to the random-projection setup, or are there other reasons for using it, independent of the use of random projections?\n\nJust before equation 6 it says that the resulting vector representation is the *sum* of all the non-zero entries. But there are some minus ones in the random projection? \n\nThe PPL expression at the bottom of p.5 doesn\'t look right. The index over which the sum happens is n, but n is fixed? So this looks like a sum with just one component in it, namely the first n-gram.\n\nIt looks like all the results are given on the test set. Did you not do any tuning on the validation data?\n\nThe plots in figure 4 are too small. It would be useful to have a table, like the one on the last page, which clearly shows the baseline vs. the random-projection model, with some description of the results in the main body of the text.\n\nThe overall presentation could be better, and I would encourage the authors to tidy the paper up in any subsequent submission. For example, there are lots of typos such as ""instead of trying to probability of a target word"".\n', 'This paper studied a random projection of word embeddings in neural language modeling. Instead of having |V| x m embeddings, the author(s) represented a word with a random, sparse, linear combination {1, 0, -1} of k vector of size m. The experiment on PTB dataset showed that k had to be somewhat close to |V| in order to achieve the comparable perplexity to a feed-forward NLM.\n\nOverall, I am not sure what we could gain from this research direction. The advantage of this random encoding was to reduce the number of parameters for an embedding layer, but the results showed we gained much PPL from a 25% reduction in embedding size (Table 1). In addition, the fact that the random projections preserved the inner product (centered at zero) was probably not desirable. It might be more fruitful if these linear combinations were learned or sub-senses of words (e.g. [1]).\n\nThe experiments were quite extensive on the hyper-parameters and showed how the models performed under different settings. However, these were done using 1 dataset and also a simple feed-forward network (rather than LSTM). I can understand the point that training NNLM accelerates the experiments, but the author(s) should consider trying a simply LSTM model after the best settings had been discovered (e.g. Table 1). PTB also has a very unnatural vocabulary distribution as pointed out in [2]. Thus, it might be helpful to test the result on another dataset (e.g. WikiText).\n\n\nOther comments\n1. I do not get the point of bringing up NCE. Did you actually use NCE loss? Did you only refer to NCE as a weight tying which can be used in a standard XENT loss [3]? The first paragraph of 3.3 did not help clarify this point either.\n\n2. In Figure 3, the baseline got different perplexity between 3(a) and 3(b). \n\n3. Shouldn\'t random indexing produce non-uniform numbers of non-zero entries depending on alpha? Why did you have an exact number of non-zero entries, s, in the experiments?\n\n3. Some typos\n- ""... is that instead of trying to probability ..."" => ""... tying ...""\n- ""... All models sare trained ..."" => ""... are ...""\n- ""... Tho get the feature ..."" => ?\n\nReferences\n[1] S. Arora et al., 2016. Linear Algebraic Structure of Word Senses, with Applications to Polysemy\n[2] S. Merity et al., 2016. Pointer Sentinel Mixture Models\n[3] Y. Gal et al., 2015. A Theoretically Grounded Application of Dropout in Recurrent Neural Networks', 'This paper presents some experiments using random projections instead of embeddings from a 1-of-V encoding.  Experiments on the Penn TreeBank benchmark data set show that in a feed-forward language modeling architecture similar to that of (Bengio, 2003), the random projections substantially reduce the number of parameters of the model while not harming perplexity too much.\n\nThe paper would need to be improved substantially in order to appear at a conference like ICLR.  First, the novelty of the approach is limited -- the approach amounts to using a sparse integer layer instead of a floating-point layer within a feed-forward architecture.\n\nSecond, and more importantly, the experiments need to be re-done to better measure the practical impact of the techniques.  First, larger data sets such as Wikitext-2 and Wikitext-103, and/or the billion-word benchmark, are needed to understand how well the approach works in practical LM settings.  Second, the paper needs to use more state-of-the-art architectures.  Language modeling is a fast-moving field, so the very latest and greatest techniques are not strictly necessary for this paper, but at least midsize LSTM models that get scores in the ~80 ppl range for Penn Treebank are important, otherwise it becomes very questionable whether the results will provide any practical impact in today\'s best models.  Finally, the paper needs to compare its parameter-reduction approaches against other compression and hyperparameter optimization techniques.  Changing the number/sizes of the network layers or using sparse weight matrices (perhaps with sparsity-inducing regularization) would be natural ways to reduce the parameter space.\n\nIn my opinion, due to how many researchers are and have been looking into improvements of language modeling, the authors may find it hard to break new ground in this direction.\n\nMinor\nIn the start of Section 3, it is not clear why having the projection be sparse is desired.  Later, space (and time) efficiency is revealed as the motivation for the sparsity, but it would be helpful if the paper said this earlier.\nEquation 6 seems to have an error, the probability should be P(w_t | w_t-1...) instead of P(w_t , w_t-1...) if this is to represent the standard LM objective (the probability of the corpus).\nSec 3.3: ""all models sare""']","[-30, -30, -50]","[50, 50, 20]","[""The sentiment score is -30 because while the reviewer acknowledges the interesting idea, they state that the work is too preliminary for a top-tier conference and would be more suitable for a workshop. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They avoid harsh or dismissive language, instead providing specific areas for enhancement. The reviewer also acknowledges the potential of the idea, which adds to the politeness. However, it's not extremely polite, as it maintains a professional, matter-of-fact tone rather than being overly complimentary."", ""The sentiment score is -30 because the reviewer expresses significant doubts about the value and generalizability of the research, stating 'I am not sure what we could gain from this research direction' and pointing out limitations. However, they do acknowledge some positive aspects like the extensive experiments. The politeness score is 50 because the reviewer uses respectful language throughout, offers constructive feedback and suggestions for improvement, and frames criticisms as questions or gentle recommendations rather than harsh statements. They also acknowledge the work done by the authors. The tone is professional and courteous overall, even while expressing concerns about the research."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and experimental approach, stating it 'would need to be improved substantially' to be conference-worthy. However, it's not entirely negative as they acknowledge some positive aspects like the reduction in parameters without harming perplexity too much. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They offer constructive feedback and suggestions for improvement rather than harsh dismissals. The use of phrases like 'in my opinion' and providing specific recommendations shows a level of respect for the authors' work while still pointing out areas for improvement.""]"
"['This paper introduces an interesting unifying perspective on several sequence generation training algorithms, exposing both MLE, RAML and SPG as special cases of this unified framework. This enables insightful new interpretations of standard issues in MLE training in terms of exploration for instance.\nBased on this new perspective, a new algorithm is introduced. Its performance is analysed on a machine translation and a text summarisation task.\n\n==> Quality and clarity\nThe paper is overall well-written, although it can be improved upon (see details below). The bibliography for instance does not reference the conference/journals where the articles were published and lists many (>10) published papers as arXiv preprints.\n\nThe ideas are clearly presented, which is crucial in a paper trying to unify different approaches, and the new perspective on exploration is well motivated.\n\n==> Originality and significance\nThe unifying framework is interesting, and helps shed new light on some standard issues in sequence generation.\nOn the other hand, the new algorithm and its analysis seem like a slightly rushed attempt at leveraging the unifying framework. \nThe experiments, in particular, present several issues.\n- For instance, it\'s clear from Figure 3 that both MLE and RAML are overfitting and would benefit from more dropout (in the literature, 0.3 is commonly used for this type of encoder-decoder architecture). Having access to these experimental results is important, since it would enable the reader to understand whether the benefits of the new approach are subsumed by regularisation or not.\n- Further, the performance of the competing methods seems a bit low. MLE reports 26.44 BLEU, which is a bit surprising considering that: \n   - with beam-search (beam of size 10, not 5, admittedly), Bahdanau et al (2016) get 27.56 BLEU, and this is without dropout.   \n   - with dropout 0.3 (but without beam search), Leblond et al (2018) get 27.4 BLEU.\nMaking a strong case for the benefits of the new algorithm requires more thorough experiments.\n\nOverall, the first half of the paper is interesting and insightful, while the second would benefit from more time. \n\nPros\n- clarity of the ideas that are presented\n- interesting unifying perspective on sequence generation algorithms\n- insightful new interpretations of existing algorithms in terms of exploration\n\nCons\n- the example new algorithm is not very original\n- the associated experiments are incomplete\n\n==> Details\n1. page 2, ""Dayan & Hinton (1997); Levine (2018); Abdolmaleki et al. (2018) study in a probabilistic inference perspective."" is an incomplete sentence.\n2. at the beginning of section 3.1, policy optimisation is a family of algorithmS\n3. page 7 in the setup of the experiments, ""We use the Adam optimizer for SGD training"" is incorrect since SGD is not a family but a specific algorithm, which is different from Adam.', ""The authors provide a common mathematical perspective on several learning algorithms for sequence models. They also introduce a new algorithm that combines several of the existing ones and achieves significant (but small) improvements on a machine translation and a text summarization task.\n\nThe paper is clearly written, giving a good exposition of the unifying formulation.\n\nI believe the paper is quite insightful, and contributes to the community's understanding of the learning algorithms. However, the improvements in their experiments are rather small, and could probably be improved with more experimental work. They do showcase the usefulness of their new formulation, but not very strongly. Thus my recommendation to accept the paper is mostly based on the theoretical content that opens an interesting new perspective."", ""The authors propose a more unified view of disparate methods for training sequence models. Specifically, a multi-term objective L(q,theta) consisting of:\n1) The standard reward maximization objective of policy gradient, E_{p_\\theta}[R], \n2) A weighted (weight alpha) reverse KL divergence of the parametric policy and a non-parameteric policy q, \n3) A weighted (weight beta) entropy term on q, \nIs proposed for sequence training (see equation (1). L can be iteratively optimized by solving for q given p_\\theta, and the \\theta given q (see eq. 2).\n\nThis framework mathematically generalizes softmax-policy gradient (SPG, alpha=1, beta=0), and reward-augmented maximum likelihood (alpha=0, beta=temperature), and also standard entropy regularized policy gradient (alpha=0), among other algorithms.\n\nThe paper is well written, and the approach sensible. However, combining SPG and RAML by introducing their respective regularization terms is a rather straightforward exercise, and so seems quite incremental.\n\nOther major concerns are:\n1) the true utility of the model, and \n2) the integrity of the experiments. \n\nWrt: \n1), While RAML was a significant contribution at the time, it is now well established that RAML generally doesn't perform well at all in practice due to exposure bias (not conditioning on it's own previous predictions during training). Moreover SPG, as the authors point out, was supposed to address the need for ML pre-training, but required much engineering to work. The fact is that REINFORCE-based policy gradient methods are still more effective than these methods, provided they have a good baseline to reduce varince. Which brings me to point \n2) Was MIXER run with a learned baseline and judiciously optimized? Table 1 suggests that MIXER can outpeform ML by only 0.1 Bleu points, and outpeformed by RAML? Something is wrong with your implementation then. Moreover, there are techniques like self-critical sequence training (SCST), which far outpeform MIXER, and we haven't even discussed Actor-Critic baselines...\n\nIn summary, the contribution over RAML and SPG in combining them is quite incremental, and the practical importance of combining them is questionable, as is the integrity of the presented experiments, given how poorly MIXER is reported perform, and the omission of stronger baselines like SCST and AC methods. Also, a paper on essentially the same approach was submitted and rejected from ICLR 2018(https://openreview.net/pdf?id=H1Nyf7W0Z), although this paper is better written, and puts the method more fully in context with existing work, I think that several of the concerns with that paper apply here as well. \n\nLook forward to the authors' feedback, and additional/corrected results - will certainly update my score if these concerns are addressed. In particular, if this generalization can significantly outpeform existing methods it generalizes with non-degenerate settings, this would overcome the more incremental contribution of combining SPG and RAML.\n\nCurrent Ratings:\n\nEvaluation      2/5: Results are not consistent with previous results (e.g. MIXER results). Stronger baselines such as SCST and AC are not considered.\nClarity         5/5: Clear paper, well written.\nSignificance    3/5: RAML and SPG have not been established as important methods in practice, so combining them is less interesting.\nOriginality     2/5: RAML and SPG are fairly straightforward to combine for experts interested in these methods.\n\nRating          4/10 Okay but not good enough, reject.    \nConfidence      5/5\n\nPros: \n- Generalizes RAML and SPG (and also standard entropy-regularized policy gradient).\n- Well written paper, clean generalization.\nCons:\n- RAML and SPG have not been established as important methods in practice.\n- generalization of RAML and SPG is straightforward,  incremental.\n- Existing baselines in the paper (i.e. MIXER) do not perform as expected (i.e barely better than ML, worse than RAML)\n- Stronger REINFORCE-based algorthms like SCST, as well as Actor-critic algorithms, have not been compared.\n\nUpdate after author responses:\n--------------------------------------------\n\nAuthors, thank you for your feedback.\n\nWhile it is true that generalizing RAML and SPG into a common framework is not trivial, the presented framework simply augments the dual form of SPG (i.e. REPS [16] in the SPG paper) with a RAML term. Furthermore, the MLE interpretation discussed is contained within the RAML paper, and the reductions to RAML and SPG are straightforward by design, and so do not really provide much new insight. Considering this, I feel that the importance of the paper largely rests on investigating and establishing the utility of the approach experimentally.\n\nWrt the experiments, I appreciate that the authors took the time to investigate the poor performance of MIXER. However, the unusally poor performance of MIXER remains unexplained, and falls short even of scheduled sampling (SS), which suggests a lingering major issue. REINFORCE techniques rely on 1) strong baselines, verified by the authors, 2) larger batch sizes to reduce variance, and 3) pre-training to reduce variance and facilitate efficient exploration. If the MLE is undertrained or overtrained (the latter the more likely issue given the plots), then MIXER will perform poorly. Actually, it is now standard practice to pre-train with MLE+SS before RL training, and this is really the (also dynamically weighted objective) baseline that should be compared against. The current REINFORCE results (MIXER or otherwise) really need to be updated (or at the least removed, as they are not captured by the framework, but the comparison to PG methods is important!).\n\nMore generally, I feel that the experiments are not yet comprehensive enough. While the authors have shown that they can outperform SPG and RAML with a scheduled objective, it is not currently clear how sensitive/robust the results are to the term weight scheduling, or even what most appropriate general weights/scheduling approach actually is.\n\nOverall I feel that the paper is still in need of substantial maturation before publication, although I have revised my score slightly upward.\n""]","[20, 60, -60]","[60, 80, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting perspective and clarity of ideas, but also points out significant issues with the experiments and the second half of the paper. The positive aspects ('pros') are balanced against the 'cons', resulting in a mildly positive overall sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They offer constructive criticism and specific suggestions for improvement, maintaining a professional tone without being overly harsh or dismissive."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'clearly written', 'quite insightful', and contributing to the community's understanding. However, it's not extremely positive due to the mention of small improvements and the suggestion that experimental work could be improved. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism without harsh words. The reviewer also frames their recommendation positively, focusing on the theoretical content's value rather than dwelling on the experimental limitations."", ""The sentiment score is -60 because the review is largely critical, pointing out major concerns with the paper's contribution and experimental integrity. The reviewer states the work seems 'quite incremental', questions its practical importance, and recommends rejection. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the paper being well-written. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language throughout and express openness to updating their score if concerns are addressed. Phrases like 'Look forward to the authors' feedback' and 'thank you for your feedback' indicate a respectful tone, even while delivering criticism.""]"
"['This paper introduces a new convolutional layer named the Temporal Gaussian Mixture (TGM) layer, and present how it can be used for activity recognition. The kernels of the new layer are controlled by a set of (temporal) Gaussian distribution parameters, which significantly reduce learnable parameters. The results are complete on four benchmarks and show consistent improvement. I just have minor comments. \n\n1. I am curious what the learned feature look like. As the author mentioned, ""The motivation is to make each temporal Gaussian distribution specify (temporally) ‘where to look’ with respect to the activity center, and represent the activity as a collection/mixture of such temporal Gaussians convolved with video features."" So does the paper achieve this goal? \n\nAnother thing is, can the authors extract the features after TGM layer, and maybe perform action recognition on UCF101 to see if the feature really works? I just want to see some results or visualizations to have an idea of what TGM is learning. \n\n2. How long can the method actually handle? like hundreds of frames? Since the goal of the paper is to capture long term temporal information. \n\n3. It would be interesting to see an application to streaming video. For example, surveillance monitoring of human activities. \n\n\n\n', 'Summary:\nThis paper proposes a temporal convolution layer called Temporal Gaussian Mixture (TGM) for video classification tasks. Usually, video classification models can be decomposed into a feature extraction step, in which frames are processed separately or in local groups, and a classification step where labels are assigned considering the full video features/longer range dependencies. Typical choices for the classification step are Recurrent Neural Networks (RNNs) and variations, pooling layers and 1D temporal convolutions. TGMs are 1D temporal convolutions with weights defined by taking samples from a mixture of Gaussians. This allows to define large convolutional kernels with a reduced number of parameters -the mean and std of the gaussians- at the cost of having reduced expressiveness. The authors experiment replacing 1D temporal convolutions with TGMs in standard video classifications models and datasets and report state-of-the-art results.\n\nStrengths:\n[+] The idea of defining weights as samples from a Mixture of Gaussians is interesting. It allows to define convolutional kernels that scale with the number of channels (equivalent to the number of Gaussians) instead of the number of channels and receptive field.\n\nWeaknesses:\n[-] The explanation of the TGM layers is very confusing in its current state. \n\nCertain aspects of TGMs that would help understand them are not clearly stated in the text. For example, it is not clear that 1) TGMs are actually restricted 1D convolutions as the kernel is expressed through a mixture of gaussians, 2) In a TGM the number of mixtures corresponds to the number of output channels in a standard 1D convolution and 3) despite TGMs are 1D convolutions, they are applied differently by keeping the number of frame features (output channels of a CNN) constant through them. Section 3 does not explain any of these points clearly and induces confusion.\n\n[-] The comparisons in the experimental section are unfair for the baselines and do not justify the advantages of TGMs. \n\nTGMs are 1D convolutions but they are applied to a different axis - 1D convolutions take as input channels the frame features. Instead, TGMs add a dummy axis, keep the number of frame features constant through them, and finally use a 1x1 convolution to map the resulting tensor to the desired number of classes. There is no reason why TGMs can’t be used as standard 1D convolutions taking as the first input channels the frame features - in other words, consider as many input mixture components as frame features for the first TGM. This is a crucial difference because the number of parameters of TGMs and the baselines is greatly affected by it.\n\nThe implicit argument in the paper is that TGMs perform better than standard 1D convolutions because they have less parameters. However, in the experiments they compare to 1D convolutions that have smaller temporal ranges – TGMs have a temporal kernel of 30 timesteps or 10 per layer (in a stack of 3 TGMs), whereas the 1D convolutions either have 5 or 10 timestep kernels according to section 4. Thus, it is impossible to know whether TGMs work better because 1) in these experiments they have longer temporal range – we would need a comparison to 1D convolutions applied in the same way and with the same temporal range to clarify it, 2) because they are applied differently – we would need a comparison when TGMs are used the same way as 1D convolutions, 3) because the reduced number of parameters leads to less overfitting – we would need to see training metrics and see the generalization gap when compared to equivalent 1D convolutions or 4) because the reduced number of parameters eases the optimization process. To sum up, it\'s true that TGMs would have a reduced number of parameters compared to the equivalent 1D convolutions with the same temporal range, but how does that translate to better results and, in this case, why is the comparison made with non-equivalent 1D convolutions? What would happen if the authors compared to 1D convolutions used in the same way as TGMs?\n\n[-] To claim SOTA, there are comparisons missing to recently published methods.\nIn particular, [1] and [2] are well-known models that report metrics for the Charades dataset also used in this paper.\n\nRating:\nAt this moment I believe the TGM layer, while a good idea with potential, is not sufficiently well explained in the paper and is not properly compared to other baselines. Thus, I encourage the authors to perform the following changes:\n\n-Rewrite section 3, better comparing to 1D convolutions and justifying why TGMs are not used in the same manner but instead using a dummy axis and a linear/1x1 conv layer at the end and what are the repercussions of it.\n-Show a fair comparison to 1D convolutions as explained above.\n-If claiming SOTA results, compare to [1] or [2] which use different methods to the one proposed in these paper but outperform the baselines used in the experiments.\n\n[1] Wang, Xiaolong, et al. ""Non-local neural networks."" CVPR 2018\n[2] Zhou, Bolei et al. ""Temporal Relational Reasoning in Videos"" ECCV 2018\n\n\n----------------------\nUpdate: In light of the authors\' rebuttal I have updated my rating from 5 to 6.', 'This paper presents Temporal Gaussian Mixture (TGM) layer, efficiently capturing longer-term temporal dependencies with smaller number of parameters. The authors apply this layer to the activity recognition problem, claiming state-of-the-art performance compared against several baselines.\n\nStrong points of this paper:\n - The authors clearly described the proposed layer and model step by step, first explaining TGM layer, followed by single layer model, then generalizing it to multi-layer model.\n - The authors achieved state-of-the-art performance on multiTHUMOS dataset. The results look great in two aspects: the highest MAP scores shown in Table 1, and significantly smaller number of parameters shown in Table 2 to achieve the MAP scores.\n\nQuestions:\n - Basically, the idea in this paper is proposing to parameterize conv layers with Gaussian mixtures, with multiple pairs of mean and variance. Although Gaussian mixtures are powerful to model many cases, it might not be always to perfectly model some datasets. If a dataset is highly multi-modal, Gaussian mixture model also needs to have large M (number of mixture components). It is not clear how the authors decided hyper-paramter M, so it will be nicer for authors to comment the effect of different M, on various dataset/task if possible.\n - Same for the hyper-parameter L, the temporal duration. It will be nicer to have some experiments with varied L, and to discuss how much this model is sensitive to the hyper-parameter.']","[80, -40, 70]","[90, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer starts by highlighting the paper's novel contribution (the TGM layer) and mentions 'consistent improvement' in results. The overall tone is supportive, with only 'minor comments' mentioned. The politeness score is 90 (very polite) due to the constructive and respectful nature of the comments. The reviewer uses phrases like 'I am curious' and 'It would be interesting,' which are polite ways to suggest improvements. The comments are framed as questions or suggestions rather than criticisms, maintaining a courteous tone throughout the review."", 'The sentiment score is -40 because while the reviewer acknowledges some strengths of the paper, they primarily focus on weaknesses and areas for improvement. The review lists several major concerns about the explanation of the method, experimental comparisons, and missing comparisons to state-of-the-art methods. The overall tone suggests the paper needs significant revisions before being acceptable. However, the score is not extremely negative as the reviewer sees potential in the idea and provides constructive feedback for improvement. The politeness score is 60 because the reviewer uses professional and respectful language throughout, acknowledging strengths alongside weaknesses. They provide detailed explanations for their critiques and offer specific suggestions for improvement, which is considerate. The tone remains objective and constructive rather than harsh or dismissive, even when pointing out flaws.', ""The sentiment score is 70 (positive) because the reviewer begins by highlighting the paper's strong points, praising the clear description of the proposed layer and model, and acknowledging the state-of-the-art performance achieved. The reviewer uses phrases like 'Strong points' and 'The results look great,' indicating a generally positive view. However, it's not a perfect 100 as the reviewer also raises some questions and suggestions for improvement. The politeness score is 80 (polite) because the reviewer maintains a respectful and constructive tone throughout. They use phrases like 'It will be nicer' when suggesting improvements, and frame their critiques as questions rather than direct criticisms. The language is professional and courteous, avoiding any harsh or dismissive statements.""]"
"['This paper proposed a 3D scene parsing that takes both objects and their relations into account, extending the Factor3D model proposed by Tulsiani et al 18. Results are demonstrated on both synthetic and real datasets.\n\nThe paper is in general well written and clear. The approach is new, the results are good, the experiments are complete. However, I am still lukewarm about the paper and cannot champion it. I feel the paper interesting but not exciting, and it’s unclear what we can really learn from it. \n\nApproach-wise, the idea of using pair-wise relationship as an inductive bias is getting popular. This paper demonstrated that it can be used for scene parsing, too, within a neural net. This is good to know, but not surprising given what have been demonstrated in the extensive literature in the computer graphics and vision community. In particular, the authors should discuss many related papers from Pat Hanrahan’s group and Song-Chun Zhu’s group (see some examples below). Apart from that, this paper doesn’t have an obvious technical innovation that can inspire future work. This is different from Factor3D, which is the first voxel-based semantic scene parsing model from a single color image, with modern neural architecture.\n\nThe results are good, but are on either synthetic data, or using ground truth bounding boxes. Requiring ground truth boxes greatly restricts the usage of these models. Would that be possible to include results under the detection setting on NYU-D or Matterport 3D? The authors claimed that the gain of 6 points is significant; however, a simple interaction net achieves a gain of 5 points, so the technical contribution of the proposed model is not too impressive.\n\nIn general, I’m on the border but leaning slightly toward rejection, because this paper is very similar to Tulsiani et al, and the proposed innovation has been explored in various forms in other papers.\n\nA minor issue:\n-\tIn fig 5. The object colors are not matched for GT and Factor3D and ours.\n\nRelated work\nHolistic 3D Scene Parsing and Reconstruction from a Single RGB Image. ECCV’18.\nConfigurable 3D Scene Synthesis and 2D Image Rendering with Per-pixel Ground Truth Using Stochastic Grammars. IJCV’18.\nCharacterizing Structural Relationships in Scenes Using Graph Kernels. SIGGRAPH’11.\nExample-based Synthesis of 3D Object Arrangements. SIGGRAPH Asia’12.\n', '<Summary>: This paper presented a method for incorporating binary relationship between objects (relative location, rotation and scale) into single object 3d prediction. It is built on top of previously published work of [a] and used same network architecture and loss as of [a] and only added the binary relations between objects for object 3d estimation. The results are shown on SUNCG synthetic dataset and only *4 image* instances of NYUv2 dataset which is very small for a computer vision task.\n\n[a] Shubham Tulsiani, Saurabh Gupta, David Fouhey, Alexei A Efros, and Jitendra Malik. Factoring shape, pose, and layout from the 2d image of a 3d scene. In CVPR, 2018.\n\n<Pros>: The paper tackles a problem of obvious interest to computer vision research community. It shows better results compared to previous similar work of [a] without considering binary relation between objects.\n\n<Cons>:\n\n*Technical details are missing:\n\nThe set of known and unknown variables are not clear throughout the paper:\n-The extrinsic camera parameters are known or estimated by the method?\n-The intrinsic camera parameters are known or estimated by the method?\n-What are the properties of ground truth bounding boxes in 2D camera frame and 3D space?\n-What is the coordinate of translation? is it in camera coordinate or world coordinate?\n-What are the variations of camera poses in training and testing for synthetic dataset and how are the samples generated? Are the train/test images generated or are rendered images from previously published work of [b] used?\n\n[b] Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, and Thomas Funkhouser. Physically-based rendering for indoor scene understanding using convolutional neural networks. In CVPR, 2017.\n\n*The proposed method is trained on synthetic dataset of SUNCG and their object relations have biases from scene creators. While using binary relation between objects increase the recall in prediction it can also make the predictions bias to the most dominant relations and decrease the precision of detection in rare cases in synthetic dataset. Also, such bias can decrease prediction precision in images of real scenes.\n \n*One of the main issues in this paper is that the result of fully automated pipeline versus having ground-truth annotation at test time are mixed up. For example, in the teaser figure (Figure 1-b), does the proposed method use ground truth bounding boxes or not? It is mentioned in figure caption: “(b) Output: An example result of our method that takes as input the 2D image and generates the 3D layout.”. Is the input only 2D image or 2D image + ground truth object bounding boxes?\nIn order to make sure that reader understands each qualitative result, there should be a column showing the “Input” to the pipeline (Not “Image”). For example, in Figure 3 and Figure 4, the image overlaid with input ground-truth bounding boxes should be shown as input to the algorithm. \n\n\n*The experiments and results does not convey the effectiveness of the proposed approach. There are major issues with the quality of the experiments and results. Here are several examples:\n\n- Missing baseline: Comparison with the CRF-based baseline is missing. This statement is not convincing in the introduction: “One classical approach is to use graphical models such as CRFs. However, these classical approaches have usually provided little improvements over object-based approaches.” For a fair comparison with prior works, reporting results on a CRF-based baseline using similar unary predictions is necessary. \n\n-The experimental results are heavily based on ground truth boxes for the objects, but it is not clear how/where the ground truth boxes are given at the test time and which part is actually predicted.\n\n-If the ground truth boxes are given at the test time, it means that the ground truth binary relations between objects are given and it makes the problem trivial.\n\n-It is not clear what is the ground truth box in experimental setup. Is it amodal object box or the ground truth box contains only the visible part of the object? \n\n-The qualitative results shown in Figure 4 have full objects in voxel space with predicted rotation, scale and translation. In the qualitative result of Figure 3 and Figure 5 the voxel prediction is shown as final output. Why the result of full object in voxel space with predicted (rotation, scale and translation) is not shown in Figure 3 and Figure 5 and why it is shown in Figure 4?\n\n\n*Very limited results on real images:\n\n-Quantitative result on a dataset of real images is missing. The results on synthetic datasets is not a good proxy for the actual performance of the algorithm in real use cases and applications.\n\n- The paper only shows few results of NYUv2 on known ground truth boxes. The errors in object detection can be propagated to the 3D estimation therefore these qualitative results are not representative of the actual qualitative performance of the proposed algorithm. Several randomly selected qualitative results on a dataset of real images “without ground-truth boxes” are needed for evaluating the performance of the proposed method on real images. \n\n-Reporting variation in all parameters of scale, rotation and translation is necessary in order to find the difficulty of the problem. For example, what is the distribution of object scale in different object categories. What is the error of scale prediction of we use mean object scale for each object category for all object instance at test set?\n\n\n*Unclear statements and presentation:\n\n- It is mentioned in the paper: “While the incorporation of unary and relative predictions can be expressed via linear constraints in the case of translation and scale, a similar closed form update does not apply for rotation because of the framing as a classification task and non-linearity of the manifold.”\n\n-Is it necessary for the relative rotation to be formulated to classification task? \n\n-If not the comparison of modeling relative rotation via linear constraints is missing.\n\n- In some of the tables and figures the “know ground-truth boxes/detection setting” are in bold face and in some cases are not. This should be consistent throughout the paper.\n', ""The paper is well-written with a few figures to illustrate the ideas and components of the proposed method. However, one of the main components in the proposed method is based on Tulsiani et al. CVPR'18. The remaining components of the proposed method are not very new. Hence, I am not very sure whether the novelty of the paper is significant. Nevertheless, the performance of the proposed method is fairly good outperforming all baseline methods. \nI also have a few questions:\n1. How did you get the instance boxes, union boxes, and binary masks in testing?\n2. What are the training and inference time? ""]","[-20, -60, 20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'approach is new', 'results are good'), they express being 'lukewarm' about the paper and 'leaning slightly toward rejection'. The reviewer finds the paper 'interesting but not exciting' and questions its contribution to learning. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging strengths before presenting criticisms, and frames concerns as personal opinions ('I feel', 'I'm on the border'). The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is -60 because the review is predominantly critical. While it acknowledges the paper's relevance and some improvements over previous work, the majority of the review focuses on significant shortcomings, including missing technical details, potential biases, unclear experimental setup, limited results on real images, and presentation issues. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express concerns. They acknowledge the paper's merits before diving into criticisms, and frame issues as areas for improvement rather than outright failures. The reviewer also provides specific examples and suggestions, which is constructive. However, the extensive list of criticisms prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper is well-written and performs well, they express doubts about its novelty. The reviewer states the paper is 'well-written' and has 'fairly good' performance, but also says 'I am not very sure whether the novelty of the paper is significant.' This mix of positive and negative comments results in a slightly positive overall sentiment. The politeness score is moderately positive (50) because the reviewer uses polite language throughout, such as 'I also have a few questions' instead of demanding answers. They also phrase criticisms gently, like 'I am not very sure' rather than making blunt negative statements. However, the review doesn't go out of its way to be exceptionally polite either, maintaining a professional tone.""]"
"['This paper presents a new quasi-Newton method for stochastic optimization that solves a regularized least-squares problem to approximate curvature information that relaxes both the symmetry and secant conditions typically ensured in quasi-Newton methods. In addition to this, the authors propose a stochastic Armijo backtracking line search to determine the steplength that utilizes an initial steplength of 1 but switches to a diminishing steplength in later iterations. In order to make this approach computationally tractable, the authors propose updating and maintaining a Cholesky decomposition of a crucial matrix in the Hessian approximation. Although it is a good attempt at developing a new method, the paper ultimately lacks a convincing explanation (both theoretical and empirical) supporting their ideas, as I will critique below.\n\n1. Stochastic Line Search\n\nDetermining a steplength in the stochastic setting is a difficult problem, and I appreciate the authors’ attempt to attack this problem by looking at stochastic line searches. However, the paper lacks much detail and rigorous reasoning in the description and proof for the stochastic line search.\n\nFirst, the theory gives conditions that the Armijo condition holds in expectation. Proving anything about stochastic line searches is particularly difficult, so I’m on board with proving a result in expectation and doing something different in practice. However, much of the detail on how this is implemented in practice is lacking. \n\nHow are the samples chosen for the line search? If we go along with the proposed theory, then when the function is reevaluated in the line search, a new sample is used. If this is the case, can one guarantee that the practical Armijo condition will hold? How often does the line search fail? How does the choice of the samples affect the cost of evaluating the line search?\n\nThe theory also suggests that the particular choice of c is dependent on each iteration, particularly the inner product between the true search direction and the true gradient at iteration k. Does this allow for a fixed c to be used? How is c chosen? Is it fixed or adaptive? What happens as the true gradient approaches 0?\n\nThe algorithm also places a limit on the number of backtracks permitted that decreases as the iteration count increases. What does the algorithm do when the line search fails? Does one simply take the step although the Armijo condition does not hold?\n\nIn deterministic optimization, BFGS typically needs a smaller steplength in the beginning as the algorithm learns the scale of the problem, then eventually accepts the unit steplength to obtain fast local convergence. The line search proposed here uses an initial steplength of $\\min(1, \\xi/k)$ so that in early iterations, a steplength of 1 is used and in later iterations the algorithm uses a $\\xi/k$ steplength. When this is combined with the diminishing maximum number of backtracking iterations, this will eventually yield an algorithm with a steplength of $\\xi/k$. Why is this preferred? Are the other algorithms in the numerical experiments tuned similarly?\n\nThe theory also asks for a descent direction to be ensured in expectation. However, it is not the case that $E[\\hat{p}_k^T \\hat{g}_k] = E[\\hat{p}_k]^T g_k$, so it is not correct to claim that a descent direction is ensured in expectation. Rather, the condition is requiring the angle between the negative stochastic gradient direction and search direction to be acute in expectation.\n\nAll the proofs also depend on a linear Taylor approximation that is not well-explained, and I’m wary of proofs that utilize approximations in this way. Indeed, the precise statement is that $\\hat{f}_{z’} (x + \\alpha \\hat{p}_z) = \\hat{f}_{z’} + \\alpha \\hat{p}_z’ \\hat{g}_z(x + \\bar{\\alpha} \\hat{p}_z)$, where $\\bar{\\alpha} \\in [0, \\alpha]$. How does this affect the proof?\n\nLastly, I would propose for the authors to change the name of their condition to the “Armijo condition” rather than using the term “1st Wolfe condition” since the Wolfe condition is typically associated with the curvature condition (p_k’ g_new >= c_2 p_k’ g_k), hence referring to a very different line search. \n\n2. Design of the Quasi-Newton Matrix\n\nThe authors develop an approach for designing the quasi-Newton matrix that does not strictly impose symmetry or the secant condition. The authors claim that this done because “it is not obvious that enforced symmetry necessarily produces a better search direction” and “treating the [secant] condition less strictly might be helpful when [the Hessian] approximation is poor”. This explanation seems insufficient to me to explain why relaxing these conditions via a regularized least-squares approach would yield a better algorithm, particularly in the noisy or stochastic setting. The lack of symmetry seems particularly strange; one would expect the true Hessian in the stochastic setting to still be symmetric, and one would still expect the secant condition to hold if the “true” gradients were accessible. It is also unclear how this approach takes advantage of the stochastic structure that exists within the problem.\n\nAdditionally, the quasi-Newton matrix is defined based on the solution of a regularized least squares problem with a regularization parameter lambda. It seems to me that the key to the approximation is the balance between the two terms in the objective. How is lambda chosen? What is the effect of lambda as a tuned parameter, and how does it affect the quality of the Hessian approximation? It is unclear to me how this could be chosen in a more systematic way.\n\nThe matrix also does not ensure positive definiteness, hence requiring a multiple of the gradient direction to be added to the search direction. In this case, the key parameter beta must be chosen carefully. What is a typical value of beta that is used for each of these problems? One would hope that beta is small, but if it is large, it may suggest that the search direction is primarily dominated by the stochastic gradient direction and hence the quasi-Newton matrix is not useful. The interplay of these different parameters needs to be investigated carefully.\n\nLastly, since (L-)BFGS use a weighted Frobenius norm, I am curious why the authors decided to use a non-weighted Frobenius norm to define the matrix. How does changing the norm affect the Hessian approximation?\n\nAll of these questions place the onus on the numerical experiments to see if these relaxations will ultimately yield a better algorithm.\n\n3. Numerical Experiments\n\nAs written, although the range of problems is broad and the numerical experiments show much promise, I do not believe that I could replicate the experiments conducted in the paper. In particular, how is SVRG and L-BFGS tuned? How is the steplength chosen? What (initial) batch sizes are used? Is the progressive batching mechanism used? (If the progressive batching mechanism is not used, then the authors should refer to the original multi-batch paper by Berahas, et al. [1] which do not increase the batch size and use a constant steplength.)\n\nIn addition, a more fair comparison would include the stochastic quasi-Newton method in [2] that also utilize diminishing steplengths, which use Hessian-vector products in place of gradient differences. Multi-batch L-BFGS will only converge if the batch size is increased or the steplength diminished, and it’s not clear if either of these are done in the paper.\n\nTypos/Grammatical Errors:\n- Pg. 1: Commas are needed in some sentences, i.e. “Firstly, for large scale problems, it is…”; “…compute the cost function and its gradients, the result is…”\n- Pg. 2: “Interestingly, most SG algorithms…”\n- Pg 3: Remove “at least a” in second line\n- Pg. 3: suboptimal, not sup-optimal\n- Pg. 3: “Such a solution”, not “Such at solution”\n- Pg. 3: Capitalize Lemma\n- Pg. 4: fulfillment, not fulfilment\n- Pg. 7: Capitalize Lemma\n- Pg. 11: Before (42), Cov \\hat{g} = \\sigma_g^2 I\n- Pg. 11: Capitalize Lemma\n\nSummary:\n\nIn summary, although the ideas appear to provide better numerical performance, it is difficult to evaluate if the ideas proposed in this paper actually yield a better algorithm. Many algorithmic details are left unanswered, and the paper lacks mathematical or empirical evidence to support their claims. More experimental and theoretical work is needed before the manuscript can be considered for publication.\n\nReferences:\n[1] Berahas, Albert S., Jorge Nocedal, and Martin Takác. ""A multi-batch l-bfgs method for machine learning.""\xa0Advances in Neural Information Processing Systems. 2016.\n[2] Byrd, Richard H., et al. ""A stochastic quasi-Newton method for large-scale optimization.""\xa0SIAM Journal on Optimization\xa026.2 (2016): 1008-1031.\n[3] Schraudolph, Nicol N., Jin Yu, and Simon Günter. ""A stochastic quasi-Newton method for online convex optimization.""\xa0Artificial Intelligence and Statistics. 2007.', 'This paper presents a new quasi-Newton type method for stochastic optimization problems. The primary contributions of the paper include a new stochastic linesearch method as well as a novel way to incorporate second order information which is different from existing approaches such as BFGS or L-BFGS. \n\nIn terms of the clarity, I think this is a very well-written paper with nice organization. The paper does have some typos, though. \n\nIn terms of significance, how to incorporate second-order information in stochastic optimization has long been an important research topic. Most existing stochastic quasi-Newton methods use L-BFGS method to incorporate second order information and choose a fixed, small stepsize, with the only differences being how to compute the curvature pair (s_k, y_k). Therefore, this paper is addressing a very important question and has made respectable attempt to use mechanisms other than L-BFGS method and to incorporate a linesearch scheme. \n\nSpecifically, the paper relaxes the secant equation, which is natural for the stochastic settings because the difference in gradients y_k is computed from stochastic gradients, and the true Hessian only satisfies the secant equation in expectation. I believe replacing the secant equation is an important and promising direction.\n\nHowever, there are concerns about the new approach proposed in this paper:\n\n1.\tThe resulting Hessian inverse approximation in (14) is no longer symmetric, or guaranteed to be positive definite. While the underling true Hessian might not be positive definite because of the nonconvexity, it is always symmetric. Is it possible to impose symmetricity as a constraint in (12)?\n\n2.\tWhat is the correct way to choose regularization parameter λ in (14)?\n\nThe paper also proposes a stochastic linesearch algorithm. For this part, there are several concerns as well:\n\n1.\tThe assumption that the covariance of gradient estimator is a constant multiple of identity is a strong and unrealistic assumption, which is never satisfied in machine learning. \n\n2.\tThe algorithm performs a backtracking linesearch, with the initial trial stepsize decreaing as O(1/k), which means that the stepsize used is always decreasing at least as fast as O(1/k). This is in general in stark contrast with the intuition that a O(1) stepsize should be used for a quasi-Newton method. \n\n3.\tSatisfying the Armijo condition in expectation does not lead to any useful convergence guarantee. \n\nThe paper also presented some numerical experiments. While the numerical results look promising, I would appreciate some clarification about what method they are really comparing against. For example, for LBFGS the authors cite R. Bollapragada et al. “A progressive batching L-BFGS method for machine learning”. Is the paper comparing against progressive batching L-BFGS? The results of LBFGS here seem to be very different from the paper cited. \n\nFinally, the paper could certainly benefit by making some mathematical statement more rigorous. For example, Lemma 1 and 2 are stated in expectation; however, since the algorithm is a stochastic algorithm, the whole sequence {x_k} generated is a stochastic process, and the expectation in the lemmas are conditional expectations. It is important to clarify w.r.t. what the conditional expectation is taken.\n\nIn summary, I believe that this paper has made a novel contribution. However, the author should address the concerns above.', 'The authors present an interesting variation of the standard QN methods. Their main point of departure from LBFGS/SR1 is in constructing a simpler Hessian inverse approximation. Recall that SR1 and LBFGS updates all satisfy the secant equation for each of the `m` previous gradient differences stored in memory. The authors choose to get ""close"" to satisfying the equations by solving an l_2 penalization of the secant equations. \n\nThe resulting algorithm is interesting, but it is not clear from the paper what the claimed advantage of doing this is. The LBFGS and SR1 unrolled update rules for H (Hessian inverse approximation) is O(m^2 d) (Sec 7.2 NW 2006),  and this seems to be the same for the authors\' method, where the main matrix R_k that forms H has the same order. (BTW, did you mean \'d\' in place of \'n\'  the computational order discussion preceding Sec  4.2?)\n\nThe experiments show that this method\'s performance is impressive compared to an LBFGS implementation provided by Bollapragada 2018 , but as I recall that paper presented a variable/increasing batch method, while the authors\' method uses fixed batches (as far as I can tell) so it is not clear that comparison on time alone is sufficient. The advantage over LBFGS and SGD seen in MNIST seems to go away by the CIFAR example, so it is unclear what might happen in larger problems like ImageNet. \n\nI am also not able to see the difference between the \'stochastic\' line search presented here and the standard backtracking method as applied to mini-batch evaluated estimates. What is different, and new that brings in consideration for the noise? I recall that bollapragada 2018 had an additional variance based rule to check. Some more conservative values are chosen for the step length, but I do not see the justification presented in the appendix, esp Eq 47 : p is not independent from g here, being calucated as p=Hg,  so E[p^t g] is not equal to the product of  the individual expectations.\n\nSome key points were left out in the discussion of the experiments. This is a common slip up when writing conf papers these days, but please do consider discussing the settings of parameters like mini-batches sizes , value of \\lambda in the H derivation, how one calculates the \\sigma^2_g within the algorithm presented in the Appendix. The last must include\nan extra computational cost, or are you using Adam style online variance estimator?\n\nThe MSE error alone seems insufficient in the results. Please publish the test mis-classification results too. Also, why is the MSE loss used with the softmax in CIFAR? Shouldn\'t cross-entropy, better justified theoretically, be better justified?\n']","[-60, 20, -20]","[50, 60, 60]","[""The sentiment score is -60 because the review is predominantly critical. The reviewer points out numerous issues with the paper, including lack of convincing explanations, insufficient details, and unanswered questions about the proposed method. The overall tone suggests the paper needs significant improvements before it can be considered for publication. However, it's not entirely negative as the reviewer acknowledges some positive aspects ('good attempt', 'appreciate the authors' attempt', 'show much promise'). The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciate', 'I'm on board with', and offer constructive criticism. The reviewer also provides detailed feedback and suggestions for improvement, which is helpful and courteous. However, the score is not higher because the review is direct in its criticism without excessive softening language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's novel contributions and well-written organization, but also raises several concerns and areas for improvement. The overall tone suggests the paper has merit but needs significant revisions. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. The reviewer uses phrases like 'I believe,' 'I would appreciate,' and 'The paper could certainly benefit,' which maintain a polite and professional tone while providing critical feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting', they express several concerns and uncertainties about the method's advantages, comparisons, and justifications. The reviewer points out multiple areas where clarification or additional information is needed, suggesting that the paper has significant room for improvement. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'interesting variation' and 'impressive performance' to acknowledge positive aspects, while politely expressing concerns using language like 'it is not clear' and 'please consider discussing'. The reviewer also offers specific suggestions for improvement, which is a courteous approach in academic review.""]"
"['The paper proposes a second order method to represent images. More exactly, multiple (low-dimensional) projections of Kronecker products of low-dimensional representations are used to represent a limited set of dimensions of second-order representations. It is an extension of HPBP (Kim et al., ICLR 2017) but with codebook assigment. \n\nThe main advantage of the method is that, if the number of projection dimensions is small enough, the number of learned parameters is small and the learning process is fast. The method can be easily used as last layers of a neural network. Although the derivations of the method are straightforward, I think the paper is of interest for the computer vision community. \n\nNonetheless, I think that the experimental evaluation is weak. Indeed, the article only considers the specific problem of transfer learning and considers only one evaluation metric (recall@k). However, recent papers that evaluate their method for that task also use the Normalized Mutual Information (NMI) (e.g. [A,B]) or the F1-score [B] as evaluation metrics. \nThe paper does not compare the same task and datasets as (Kim et al., ICLR 2017) either.\nIt is then difficult to evaluate whether the proposed representation is useful only for the considered task. Other tasks and evaluation metrics should be considered.\nMoreover, only the case where D=32 and R=8 are evaluated. It would be useful to observe the behavior of the approaches for different values of R. \nIn Section 3.2, it is mentioned that feature maps become rapidly intractable if the dimension of z is above 10. Other Factorizations are then proposed. How do these factorizations affect the second order nature of the representation of z? Is the proposed projection in Eq. (10) still a good approximation of the second order information induced by the features x?\n\n\nThe paper says that the method is efficient but does not mention training times. How does the method compare in terms of clockwork times compared to other approaches (on machines with similar architecture)?\n\nIn conclusion, the experimental evaluation of the method is currently too weak.\n\n\n[A] Hyun Oh Song, Stefanie Jegelka, Vivek Rathod, Kevin Murphy: Deep Metric Learning via Facility Location. CVPR 2017\n[B] Wang et al., Deep Metric Learning with Angular Loss, ICCV 2017\n\nafter rebuttal:\nThe authors still did not address my concern about testing on only one task with only one evaluation metric.', 'Summary:\nThis paper proposes a novel bilinear representation based on a codebook model.\nThe proposed method is build upon the form of Hadamard Product for efficient representation of a bilinear model.\nThrough introducing the framework of codebook, it is naturally extended into a multiple-rank representation while the efficient pooling scheme is also derived from the (sparse) codeword assignment.\nIn addition, the authors also present an efficient formulation in which the codebook-based projections are factorized via a shared projection to further reduce the parameter size.\nThe experimental results on image retrieval tasks show that the proposed method produces better classification accuracy with a limited amount of parameters.\n\nComments:\nPros:\n+ It is interesting that one-rank bilinear pooling is naturally extended to multiple-rank one via introducing codebooks.\n+ Good performance in the image retrieval tasks.\n\nCons:\n- This paper lacks important comparison for fairly evaluating the effectiveness of the proposed formulation.\n- It also lacks detailed description and discussion for the methods.\n\nDue to the above-mentioned weak points, the reviewer cannot fully understand whether the performance improvement really comes from the proposed formulation or not. Thus, this manuscript is currently judged as border. The detailed comments are shown in the followings.\n\n- Comparison\nEventually, the proposed method is closely related to the multiple-rank representation of a bilinear model;\n\nz_i = x^T W_i x (Eq.5) ~ x^T u_i v_i^T x (one-rank, Eq.6) ~ x^T U_i V_i^T x (multiple-rank), ... Eq.(A)\n\nwhich is a straightforward extension from the one-rank model. From this viewpoint, the proposed form in Eq.10 is regarded as an extension of (A) by introducing non-linearity as\n\nz_i = x^T U_i {h(x)h(x)^T} V_i^T x.  ... Eq.(10)\n\nThus, the main technical contribution is found in the weighting by {h(x)h(x)^T}, but its impact on the performance is not evaluated in the experiments. Furthermore, it is also possible to simply introduce such a non-linearity into the model (A) according to [Kim et al.,2017];\n\nz_i = \\sigma(x^T U_i) \\sigma(V_i^T x) = 1^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(B)\n\nwhere "".*"" indicates Hadamard Product, and we can more directly apply the method of [Kim et al., 2017] to the multiple-rank model by\n\nz_i = p^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(C)\n\nwhere p is a R-dimensional vector. On the other hand, it is also necessary to compare the proposed method with [Kim et al.,2017] which is formulated by\n\nz = P^T {\\sigma(U^T x) .* \\sigma(V^T x)}, ... Eq.(D)\n\nwhere U and V are matrices of d x K and P is K x D. The parameter K (shared rank) should be determined so that the total parameter size of (2dK + KD) is compatible to that of the proposed method, 2NdD.\n\nIn summary, for demonstrating the effectiveness of the proposed method in Eq.(10), it is inevitable to compare it with the models (A, B, D) and hopefully (C).\n\n- Presentation\nIn Section 4.2, the performance results of the factorization model in Eq.(13) are merely shown without deep discussion nor analysis on them. In particular, it is unclear why the JCF of N=32 and R=32 outperforms the CHPBP of N=32. Those two methods are different only in the form of U and V:\n(CHPBP) U_i -> U\'_i A (JCF),\nwhere U_i and U\'_i have the same dimensionality of d x 32, and thus we can say that JCF overly parameterizes the projection by redundantly introducing A of 32 x 32. Thus, the projection capacity of JCF is completely the same as that of CHPBP. Therefore, it needs detailed discussion for the performance improvement shown in Figure 1.\n\nMinor comments are:\n* There are lots of notations, and thus it would be better to show a summary of the notations.\n* In Section 4.1, there is no clear description about the methods of BP and HPBP. Actually, the method of HPBP is different from the one presented in [Kim et al., 2017].\n', 'Summary: This paper presents a way to combine existing factorized second order representations with a codebook style hard assignment. The number of parameters required to produce this encoded representation is shown to be very low. Like other factorized representations, the number of computations as well as the size of any intermediate representations is low. The overall embedding is trained for retrieval using a triplet loss. Results are shown on Stanford online, CUB and Cars-196 datasets.\n\nComments:\n\nReview of relevant works seems adequate. The results seem reproducible. \n\nThe only contribution of this paper is combining the factorized second order representations  of (Kim et. al. 2017) with a codebook style assignment (sec. 3.2). Seems marginal.\n\nThe scheme described in Sec. 3.2 needs clarification. The assignment is applied to x as h(x) \\kron x in (7). Then the entire N^2 D^2 dimensional second order descriptor h(x) \\kron x \\kron h(x) \\kron x is projected on a N^2 D^2 dim w_i. The latter is factorized into p_i, q_i \\in \\mathbb{R}^{Nd}, which are further factorized into codebook specific projections u_{i,j}, v_{i,j} \\in \\mathbb{R}^{d}. Is this different from classical assignment, where x is hard assigned to one of the N codewords as h(x), then projected using \\mathbb{R}^d dimensional p_i, q_i specific to that codeword ?\n\nIn section 4.1 and Table 2, is the HPBP with codebook the same as the proposed CHPBP ? The wording in ""Then we re-implement ... naively to a codebook strategy""  seems confusing.\n\nThe method denoted ""Margin"" in Table 4 seems to be better than the proposed approach on CUB. How does it compare in terms of efficiency, memory/computation ?\n\nIs it possible to see any classification results? Most of the relevant second order embeddings have been evaluated in that setting.\n\n\n===============After rebuttal ===============================\n\nAfter reading all reviews, considering author rebuttal and AC inputs, I believe my initial rating is a bit generous. I would like to downgrade it to 4. It has been pointed out that many recent works that are of a similar flavor, published in CVPR 2018 and ECCV 2018, have slightly better results on the same dataset. Further, the only novelty of this work is the proposed factorization and not the encoding scheme. This alone is not sufficient to merit acceptance. ']","[-50, -20, -60]","[50, 50, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('of interest for the computer vision community'), they express significant concerns about the experimental evaluation being 'weak' and 'too weak'. The reviewer lists several limitations and suggests additional work needed, indicating an overall negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge positive aspects before presenting concerns, and use phrases like 'I think' to soften critiques. However, the tone remains neutral and objective rather than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting', 'good performance'), they express significant concerns ('lacks important comparison', 'lacks detailed description') and ultimately judge the manuscript as 'border'. The review is more critical than positive overall. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present criticisms constructively, use phrases like 'it would be better' and 'it needs detailed discussion' rather than harsh directives, and acknowledge both pros and cons. The tone is firm but not rude, maintaining a collegial academic discourse."", ""The sentiment score is -60 because the reviewer expresses several criticisms and ultimately downgrades their rating, stating the work's novelty is insufficient for acceptance. They describe the contribution as 'marginal' and point out that similar recent works have better results. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They ask clarifying questions and provide specific feedback rather than using harsh or dismissive phrasing. The tone is constructive overall, even while expressing concerns about the paper's contribution.""]"
"['This paper makes two different contributions in the field of adversarial training and robustness.\nFirst the authors introduce a new type of attack that exploits second-order information while traditional attacks typically rely on first-order information.\nAnother contribution is a theorem that using the Renyi divergence certifies robustness of a classifier by adding Gaussian noise to pixels.\n\nOverall, I find that the paper lacks clarity and does not properly contrast their work to existing results. They are also some issues with the evaluation results. I provide detailed feedback below.\n\n1) Prior work\na) Connection between adversarial defense and robustness to random noise\nThis connection is established in Fawzi, A., Moosavi-Dezfooli, S. M., & Frossard, P. (2016). Robustness of classifiers: from adversarial to random noise. In Advances in Neural Information Processing Systems (pp. 1632-1640).\nb) Connection between minimal perturbation required to confuse classifier and its confidence was discussed for the binary classification in Section 4 of\nFawzi, Alhussein, Omar Fawzi, and Pascal Frossard. ""Analysis of classifiers’ robustness to adversarial perturbations."" Machine Learning 107.3 (2018): 481-508.\nc) The idea to compute the distribution of classifier outputs when the input is convolved with Gaussian noise was already “anticipated” in Section V of the following paper which relates the minimum perturbation needed to fool a model to it’s misclassification rate under Gaussian convolved input:\nLyu, Chunchuan, Kaizhu Huang, and Hai-Ning Liang. ""A unified gradient regularization family for adversarial examples."" Data Mining (ICDM), 2015 IEEE International Conference on. IEEE, 2015.\n\nThese papers should be discussed in the paper, please elaborate how you see your contribution regarding the results derived there.\n\n2) Second-order attack introduced in the paper\nI think they are a number of important details that are ignored in the presentation.\na) Regarding the assumption that the gradient vanishes in the difference of the loss, I think the authors should elaborate as to why this is a reasonable assumption to make. If we assume that the classifier has been trained to optimality then expanding the function at this (near-)optimum would perhaps indeed yield to a gradient term of small magnitude (assuming the function is smooth). However, nothing guarantees that the magnitude of the gradient term is negligible compared to the second-order information. The boundary of the classifier could very well be in a region of low-curvature.\nb) The approximation of the second-order information is rather crude. However, the update derived is very similar to PGD with additional noise. In optimization, the use of noise is known to extract curvature, see e.g. (Xu & Yang, 2017) who showed that noisy gradient updates act as a noisy Power method that extracts negative curvature direction.\nXu, Y., & Yang, T. (2017). First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time. arXiv preprint arXiv:1711.01944.\n\n3) Issue of ""degenerate global minimum"": The authors argue that multistep attacks also suffer from this issue. However, the PGD attack of Madry is also initialized at a random point within the uncertainty ball around x, i.e. PGD attack first adds random noise to x before iteratively ascending the loss function. This PGD update + noise at first iteration seem rather similar to the update derived by the authors that uses random noise at every iteration. It could therefore be that the crude approximation of second-order information is not so different from previous work. This should be further investigated either theoretically or empirically.\n\n4) Lack of details regarding some important aspects in the paper\na) “Note the evaluation requires adjustment and computing confidence intervals for p(1) and p(2), but we omit the details as it is a standard statistical procedure”\nThe authors seem to sweep this under the carpet but this estimation procedure gives only an estimate of the required quantities p(1) and p(2), which I think would require adjusting the result in the theorem to be a high probability bound (or an expectation bound) instead of a deterministic result.\n\nb) “the noise is not necessarily added directly to the inputs but also to the first layer of a DNN. Given the Lipschitz constant of the first layer, one can still calculate an upper bound using our analysis. We omit the details here for simplicity”\nWhat exactly changes here? How do you estimate the Lipschitz constant in practice?\n\n\n5) Main theorem needs to be contrasted to previous results\nThe main Theorem uses the Renyi divergence certifies robustness of a classifier by adding Gaussian noise to pixels. There are already many results in the field of robust optimization that already derive similar results, see e.g.\nNamkoong, H., & Duchi, J. C. (2017). Variance-based regularization with convex objectives. In Advances in Neural Information Processing Systems (pp. 2971-2980).\nGao, R., & Kleywegt, A. J. (2016). Distributionally robust stochastic optimization with Wasserstein distance. arXiv preprint arXiv:1604.02199.\nCan you elaborate on the difference between your bounds and these ones? You do mention some of them require strong assumptions such as smoothness but this actually seems like a mild assumption (although some activation functions used in neural nets are indeed not smooth).\n\n6) Adversarial Training Overfit to the Choice of norms\nThe main theorem derived in the paper uses the l_2 norm. What can be said regarding other norms?\n\n7) Experiments:\na) the authors only report accuracies for attacks whose l2-norm is smaller than a fixed constant 0.8. However, this makes the results difficult to interpret and the authors should instead state the signal to noise ratio, i.e. dividing the l2-norm of the perturbation by the l2-norm of the image. Otherwise, it is not clear how strong or weak such perturbations are. (In particular, the norm depends on the dimension of the image, so l2-norms of perturbations for MNIST and CIFAR10 are not comparable).\nb) In Section 6.2, the authors state that an l_infty trained model is vulnerable against l_2 perturbations. Why not training the model under both l_infty and l_2 perturbations?\nc) Figure 1\nBased on the results predicted in Theorem 2, it seems it would be more interesting to evaluate the largest L for which the classifier predictions are the same. Why did you report a different results?\n\n8) Other comments\nsection 2.1: “Note this distribution is different from the one generated from softmax”. Why/How is this different?\nconnection to EOT attack’: authors claim: E_{d∼N(0,σ2I)} [∇_x L(θ, x, y)|x+d] = ∇_x E_{d∼N(0,σ2I)} [∇_x L(θ, x, y)|x+d]. There is a typo on the RHS where ∇_x is repeated twice. This is also the common reparametrization trick so could cite \nKingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.\n', ""This paper consists of two parts: a 2nd-order attack method and a certification for robustness. The paper is well written and easy to follow. However, addressing of similarity and comparison with some previous methods could be improved.\n\nFirst of all, the motivation of 2nd order attack is clear and reasonable: for adversarially trained model at minimax, the gradient is close to vanishing, so 2nd order information helps a lot to find actual adversarial examples in this case. However,\n\n1. A lot of defenses have tried to modify the networks to make even computing the gradient difficult if not impossible. In this case, how effective is the 2nd order attack? I would like to see some discussion of this.\n\n2. While the starting point seems like a powerful attack method. The 2nd order information is only approximately computed via finite differences. A powerful method with weak approximation will sounds more powerful than a weak method to start with, but the actual effectiveness will need more systematic comparison. I think adding some studies of the accuracy or variances of the 2nd order information with the proposed approximation method (under natural setting and maybe also under the setting where the networks are modified to make even 1st order information hard to compute) would definitely help.\n\n3. Also after the approximation, as mentioned in the paper, the algorithm becomes equivalent to EOT attacks with Gaussian noises. The EOT attacks are also more general to allow different types of noises. While it might not make lots of sense to compare with EOT attacks in the experiments as the two algorithms seem to be exactly the same, it would help of more discussions could be devoted to justify how the proposed algorithm is novel given the previously existed EOT attack.\n\n4. In the experiments on adversarially trained models, the adversarial trained models are trained against l_inf attack, while the actual attack is l2. This seems unfair. Since the author mentioned that it is easy to extend their method to l_inf attack. It would be more justifiable if the results with matching attack types are shown instead of the current ones.\n\nThe certified robustness is an interesting take, too. However, the bounds might be too strong: as far as I understand, it does not rely much on the properties of the underlying neural networks f. So in order to be applicable to all kinds of weird non-robust neural networks uniformly, the bounds cannot be too tight. To get useful certificate level, a too heavy noise level sigma might be needed and potentially destroys the classification accuracy of the original model f. This is acknowledged in the 'gap between theory and empirical' section. And it makes the importance of such kind of bounds a bit weak.\n\n5. Also, the 'stability training' procedures derived based on this bounds is quite similar to some previous methods. For example, the objective function is very similar to 'logit pairing', which add an extra term to bound the similarity between two logits from an adversarial or noisy version. The empirical results will be much stronger if more closely related methods are included in the comparison. For example, logit pairing, as well as simple training with Gaussian perturbation on inputs.\n\nIn summary, this paper provide some interesting perspectives to adversarial attacks and certifications. However, the main algorithms are very similar to some existing methods, more discussion could be used to compare with the existing literature and clarify the novelty of the current paper. The empirical results could also be made more stronger by including more relevant baseline methods and more systematic study of the effectiveness of some approximation methods adopted"", 'The paper makes three rather independent contributions: a) a method for constructing adversarial examples (AE) utilizing second-order information, b) a method for certifying classifier robustness, c) a method to improve classifier robustness. I will discuss these three contributions separately.\n\na) Second order attack: Miyato et al. (2017) propose a method for constructing AE for the case where the gradient of the loss is vanishing. In this case, at given a point, the direction of steepest loss ascent can be approximated by the gradient at a randomly sampled nearby point. Miyato et al. (2017) show how this can be derived as a very crude approximation of the power method. The authors of the current paper apply this attack to the adversarial trained networks of Madry et al. (2017). They find that the *L_infinity* trained networks of that work are not as *L_2* robust as originally claimed. I find this result interesting, highlighting a failure case of first-order methods (PGD) for evaluating adversarial robustness. However, it is important to note that these were models that were *not* trained against an L2 attack and thus should not be expected to be very robust to one. Therefore, this result does not identify a failure of adversarial training as the authors seem to suggest but rather a failure of the original evaluation of Madry et al. (2017). It is also worth noting that this finding is specific to MNIST given the results currently presented. This might be explained by the fact that robust MNIST models tend to learn thresholding filters (Madry et al., 2017) which might cause gradient obfuscation.\n\nb) Adversarial robustness certification: The authors proposed a method for certifying the robustness of a model based on the Renyi divergence. The core idea is to define a stochastic classifier that randomly perturbs the input before classifying it. Given such a classifier, one can construct the probability distribution over classes. The authors prove that given the gap between the first and second most likely classes, one can construct a bound on the L2 norm of perturbations required to fool the classifier. This method is able to certify the adversarial accuracy of some classifier to relatively small epsilon values. While I think the theoretical arguments are elegant, I find the overall contribution incremental given the work of Mathias et al. (2018). Both methods seem to certify robustness of roughly the same scale. One component of the experimental evaluation missing is how does the certifiable accuracy differ between robust and non-robust models. Currently there are only results for a single model (Figure 1) and it is not clear from the text which one it is. Given that there exists a section titled ""improved certifiable robustness"" I would at least expect a result where a model with higher certifiable accuracy is constructed. \n\nc) Improved robustness via stability training: The authors propose a method to make a classifier more robust to input noise. They add a regulatization term to the training loss that penalizes a change in the probabilities predicted by the network when the input is randomly perturbed. In particular, they use the cross-entropy loss between the probability distributions predicted at the original and the perturbed point. The goal is to train a model that is more robust to random perturbation which will then hopefully translate to robustness to adversarial perturbation. This method is evaluated against the proposed attack (a) and is found to be more robust to that attack than previous adversarially trained models. Overall, I find the idea of stability training interesting. However I find the current evaluation severely lacking. First of all, these models should be evaluated against a standard PGD adversary (missing from Table 1). Even if that method is unreliable when applying random noise to the input at each step it is still an important sanity check. Additionally, in order to deal with the stochasticity of the model one should experiment with a PGD attack that estimates the gradient using multiple independent noise samples (see https://arxiv.org/abs/1802.00420). Finally, other attacks such as black-box attacks and finite-differences attacks should potentially be considered. Given how other defenses based purely on data augmentation during training or testing were bypassed it is important to apply a certain amount of care when evaluating the robustness of a model.\n\nOverall, while I think the paper contains interesting ideas, I find the current evaluation lacking. I recommend rejection for now but I would be willing to update by score based on author responses. \n\nMinor comments to the authors:\n-- Last paragraph of first page: ""Though successful in adversarial defensing, the underlying mechanism is still unclear."", adversarial training has a fairly principled and established underlying mechanism, robust optimization. \n-- Figure 2 left: is the natural line PGD or SO?\n-- The standard deviation of the noise used is very large relative to the pixel range. You might want to comment on that in the main text.\n-- Figure 3: How was the Madry model trained? L_inf or L_2?']","[-50, -20, -30]","[50, 50, 50]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper, including lack of clarity, insufficient contrast with existing work, and problems with evaluation results. However, it's not entirely negative as it acknowledges the paper's contributions. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and detailed feedback. They use phrases like 'I find that' and 'please elaborate' which maintain a polite tone. The reviewer also provides specific recommendations and references to help improve the paper, which is a courteous approach in academic peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written and easy to follow'), they express several concerns and suggest multiple improvements. The overall tone indicates that the paper has potential but needs significant work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I would like to see' and 'it would help if' which are polite ways to suggest improvements. The reviewer also acknowledges the paper's strengths before diving into critiques, which is a courteous approach."", ""The sentiment score is -30 because while the reviewer acknowledges some interesting ideas in the paper, they ultimately recommend rejection due to lacking evaluation. The review points out several shortcomings and areas for improvement, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer expresses willingness to update their score based on author responses. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'I find this result interesting' and 'I think the paper contains interesting ideas', which soften the criticism. The reviewer also provides detailed explanations for their concerns, which is a polite way of giving feedback. However, the score is not higher as the language, while polite, is not overly warm or encouraging.""]"
"['The authors proposed a novel probabilistic framework to model adversarial attacks on deep networks with discrete inputs such as text. The proposed framework assumes a two step construction of an adversarial perturbation: 1) finding relevant features (or dimensions) to perturb (Eq. 3); 2) finding values to replace the features that are selected in step 1 (Eq. 4). The authors approximate some terms in these two equations to make the optimization easier. For example, it is *implicitly* assumed that given the i-th feature is removed from consideration, the probability of attack success does not change *on average* under probabilistic *adversarial* attack on other features (Eq. 5). It is not clear why that should hold and under what conditions that assumption would be reasonable (given that the attacks on other features are adversarial, although being probabilistic). \nThe proposed framework allows one to solve the computation vs. success rate trade-off by either estimating the best attack from the network (called greedy attack Eq. 6) or using a parametric estimation that does not require model evaluation (called Gumbel attack). Experimental results suggest that Gumbel attack has better or competitive attack rate on models developed for text classification while having the most computationally efficiency among other methods. It is also noticeable that the greedy attack achieves the best success rate with a large margin among all the tested methods. ', 'In this work the authors introduce two new state-of-the-art adversarial attacks on discrete data based on a two-stage probabilistic process: the first step identifies key features which are then replaced in the second step through choices from a dictionary.\n\nOverall the manuscript is very well written and easy to follow. The evaluation is extensive and contains all previous attacks I am aware of. The greedy attack outperforms all prior work by a large margin while the Gumbel attack works on par with the previous state-of-the-art while being significantly faster. \n\nI only have a few questions and remarks:\n\n* What’s the “random attack” baseline in these tasks? In computer vision it’s often sufficient to add a little bit of salt-and-pepper noise or Gaussian noise to change the model decision.\n\n* Another thing I am wondering is what the human evaluation scores would be on adversarials from other adversarial attacks? Adversarial attacks in general (e.g. in computer vision) can work in two ways: one being actually changing the semantic content (thus also “fooling humans) while the other changes background features / add noise to which humans are pretty insensitive (unless you add too much of it). The greedy attack does seem to change some semantics as can be seen in the increased error rate of humans (which is pretty rare for computer vision adversarials). It might be that other attacks are rather changing words or characters which are not as semantically meaningful, as would be revealed by the accompanying human scores.\n\n* Are you planning to release the code? Will it be part of CleverHans or Foolbox?\n\nOverall, I find this work to be a really exciting advance on discrete adversarial attacks.', 'This paper addresses the problem of generating adversarial examples for discrete domains like text. They propose two simple techniques:\n1) Greedy: two stage process- first stage involves finding the k words in the sentence/paragraph to perturb and second step changes the word in the positions identified in step 1.\n2) Gumbel: first approach amortized over datasets where first and second steps are parametrized and learned over the dataset with the loss being the probability of flipping the decision.\nSpecifically, for the Gumbel approach, the authors use the non-differentiable top-k-argmax output to train the module in the second step which is not ideal and it would be better to train both first and second steps jointly in an end-to-end differentiable manner.\n\nThe results show that Greedy approach is able to significantly affect the accuracy of the systems compared to other adversarial baselines. Mturk evaluation shows that for tasks like sentiment analysis, humans weren\'t as confused as the systems were when the selected words were changed which is encouraging. However, the Gumbel method performs poorly compared to other baselines.\nMoreover, a thorough analysis of why Greedy is doing better than some gradient based adversarial attacks is needed in the paper because it is unclear what is causing their greedy approach to perform well; is it the two-stage nature of the process?\n\nMy major gripe with the paper is that it is egregiously difficult to read in parts and is poorly written. There are dangling conditional bars in many equations (5, 7, Greedy attack etc.), unclear ""expectation (E)"" signs and many other confusing notational choices which make the math difficult to parse. I am not even sure if those equations are correctly conveying the idea they are meant to convey. I found  the algorithms to be more clearly written and realize that the text in the models and equations is unnecessarily complicated. The argument about approximation to the objective by considering the i positions independently is not convincing and their is nothing in the paper to show if the assumption is reasonable.', 'This paper introduces two new methods for generating adversarial examples for text classification models. The paper is well written, the introduced algorithms and experiments are easy to understand. \n\nHowever, I do not believe that these two methods are sufficiently significant. First of all, I am not convinced that the attacks can be classified as “adversarial examples”, especially the ones on the word-based models. The community originally got interested in adversarial examples because while they can easily be classified correctly by humans, they seemed to fool machine learning models with high efficiency. For example, the PGD attack by Madry et al. can reduce the accuracy of a CIFAR-10 model to 0% by using distortions that are not at all noticeable to humans. In the case of the word-based task studied here, human accuracy drops by 8-11%. \n\nWhile the question of whether adversarial examples are actually a security threat is under debate, the attacks on the word-based models here do not even classify as adversarial examples. Of course, it is interesting that the ML models are much less robust to these distortions than humans are, however, this is a well known problem. This paper did not perform comprehensive experiments to investigate this phenomenon. For example, they could have evaluated a wide range of distortions (including random distortions), and then check if training with all of these distortions makes the network more robust … etc (for example, see [1]).  \n\nThe attacks on character-based models are closer to adversarial examples from this perspective. However, the performance of the Gumbel Attack is significantly worse on character-based models than an attack as simple as the Delete-1 attack. The Greedy attack is more successful than the Delete-1 attack, however it is a straight-forward application of greedy optimization on discrete data and is not very novel or interesting. \n\n[1] Generalisation in humans and deep neural networks, arXiv:1808.08750 ']","[50, 90, -20, -50]","[75, 80, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the proposed framework and its competitive performance, particularly noting the greedy attack's success rate. However, they also raise questions about some assumptions, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, presenting their concerns as observations rather than criticisms. They use phrases like 'It is not clear' instead of more confrontational language, and they highlight positive aspects of the work alongside areas for improvement."", ""The sentiment score is 90 (very positive) because the reviewer expresses strong approval of the work, calling it a 'really exciting advance' and praising the manuscript as 'very well written and easy to follow'. They note that the proposed methods outperform previous work and provide extensive evaluation. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, framing their questions and remarks as constructive suggestions rather than criticisms. They use phrases like 'I am wondering' and 'Overall, I find this work to be...', which maintain a courteous tone. The reviewer also acknowledges the authors' efforts and achievements positively."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Greedy approach is able to significantly affect the accuracy of the systems'), they also express significant criticisms. The reviewer mentions that the Gumbel method performs poorly, calls for more thorough analysis, and describes the paper as 'egregiously difficult to read in parts and poorly written'. These criticisms outweigh the positive elements, resulting in a slightly negative overall sentiment. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using phrases like 'My major gripe' instead of more harsh language. They also provide constructive feedback and suggestions for improvement. However, the use of strong language like 'egregiously difficult to read' and 'poorly written' prevents the score from being higher, as these phrases, while not impolite, are quite direct criticisms."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well written', 'easy to understand'), they express significant doubts about the paper's contribution ('I do not believe that these two methods are sufficiently significant'). They critique the methods and results, suggesting the work doesn't meet the standard for adversarial examples. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives before critiques, and frames concerns as personal opinions ('I am not convinced') rather than harsh statements. They also provide constructive suggestions for improvement and reference related work, which is helpful and polite. The language is professional and avoids any rudeness, but also doesn't go out of its way to be overly polite or complimentary.""]"
"[""The paper introduces hierarchical attention, where they propose to weighted combine all the intermediate layers of multi-level attention. The idea is simple and seems to be promising, however originality seems incremental.\n\nIn order to fully demonstrate the significance of the proposed algorithm, the authors should conduct more comparisons, for example, to multi-level attention. Just comparing with one-level attention seems unfair given the significant increase of computation. Another aspect of comparison may be to consider computation and performance improvements together and discuss the best trade-off. The authors should also include some standard benchmark datasets for comparisons. The current ones are good but it is not so clear what is the best state-of-the-arts results on them when compared with all other methods.\n\nThe analysis on the network's representation and convergence is nice but it does not bring much insights. The argument for decreasing global minimal of the loss function in terms of increasing parameter size can be made for nearly all models but it is of little practical use since there is no guarantee one can reach the global optimal of these models.\n\nI recommend the authors to analyze/demonstrate how effective this weighted combination is. For example, the paper can benefit from some clear examples that show the learned weights across the layers and which ones are more important.\n\nThe presentation of the paper needs some polishing. For example, there are numerous typos, grammatical errors everywhere."", 'The paper proposes to enhance existing multi-level attention (self-attention) mechanism by obtaining query and key vectors (= value vectors) from all levels after weighted-averaging them. The paper claims that this is also theoretically beneficial because the loss function will converge to zero as the number of layers increase. It claims that the proposed architecture outperforms existing attention-based models in English MRC test (SQuAD), Chinese MRC test, and Chinese poem generation task.\n\nI find three major issues in the paper.\n\n1.  I think the proposed hypothesis lacks the novelty that ICLR audience seeks for. Through many existing architectures (ResNet, ELMo), we already know that skip connection between CNN layers or weighted average of multiple LSTM layers could improve model significantly. Perhaps this could be an application paper that brings existing methods to a slightly different (attention) domain, but not only such paper is less suitable for ICLR, but also it would require strong experimental results. But as I will detail in the second point, I also have some worries about the experiments. \n\n2. The experimental results have problems. For English MRC experiment (SQuAD), the reproduced match-LSTM score is ~10% below the reported number in its original paper. Furthermore, it is not clear whether the improvement comes from having multiple attention layers (which is not novel) or weighted-averaging the attention layers (the proposed method). BiDAF and match-LSTM have single attention layers, so it is not fair to compare them with multi-layer attention. \n\n3. Lastly, I am not sure I understood the theoretical section correctly, but it is not much interesting that having multiple layers allow one to approach closer to zero loss. In fact, any sufficiently large model can obtain close-to-zero loss on the training data. This is not a sufficient condition for a good model. We cannot guarantee if the model has generalized well; it might have just overfit to the training data.\n\nA few minor issues and typos  on the paper:\n- First para second sentence: In -> in\n- First para second sentence: sequence to sequence -> sequence-to-sequence\n- Second last para of intro: sentence fragment\n- Figure 3: would be good to have English translation. \n', 'Overall, this is an incremental paper.\nThe authors propose a hierarchical attention layer, which computes an aggregation of self attention layer outputs in the multi level attention model. This seems like a small improvement.\n\nThere are results using this hierarchical attention layer instead of the vanilla attention layers on Machine Reading Comprehension and Chinese Poem Generation. The authors should have also included results on more tasks to show the clear improvement of the proposed method.\n\nThe issues with this paper are:\n- Aggregating weights of different layers has been an idea explored before (Elmo, Cove, etc.). So the model improvement itself seems small.\n- Lack of strong experimental evidence. In my regard, the experiments are somewhat incomplete. In both the tasks, the authors compare only the vanilla model (BIDAF, MatchLSTM, R-NET) and the model with HAM layers. It is not clear where the improvement is coming from. It would have made sense to compare the number of parameters and also, using the same number of vanilla attention layers  which outputs the last layer and compare it to the one proposed by the authors.\n- Since the argument is towards using weighted average rather than the last layer, there should have been a more detailed analysis on what was the weight distribution and on how important were representations from different layers.\n\n']","[-20, -70, -50]","[50, 20, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the idea is 'simple and seems to be promising', they also point out several limitations and areas for improvement. The reviewer suggests that the originality is 'incremental', calls for more comparisons, and states that some of the analysis 'does not bring much insights'. However, the tone is not entirely negative, as the reviewer also offers constructive feedback and suggestions for improvement. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering recommendations rather than harsh criticisms. They use phrases like 'I recommend' and 'The paper can benefit from', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects of the paper, such as calling the analysis 'nice'. However, the score is not extremely high as the review is primarily focused on areas for improvement rather than praise."", ""The sentiment score is -70 because the reviewer identifies 'three major issues' with the paper and expresses significant concerns about the novelty, experimental results, and theoretical claims. The language used suggests the paper falls short in multiple important areas, indicating a largely negative sentiment. However, it's not entirely negative as the reviewer acknowledges some potential value, hence not scoring at the extreme end. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I find', 'I think', and 'I am not sure I understood' which soften the critique. The reviewer also provides constructive feedback and suggestions for improvement, including minor typo corrections, which adds to the politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the review is generally critical, describing the paper as 'incremental' and pointing out several issues. However, it's not entirely negative as it acknowledges some results and improvements. The politeness score is 0 (neutral) because the language is professional and objective, without being particularly polite or rude. The reviewer states criticisms directly but without harsh language, maintaining a neutral tone throughout. The reasoning for these scores is based on the overall critical nature of the review, the use of phrases like 'incremental paper', 'small improvement', and 'lack of strong experimental evidence', balanced against the neutral, professional tone of the language used.""]"
"['The paper proposes PDDPG, a combination of prioritized experience replay, parameter noise exploration, and DDPG. Different combinations are then evaluated on MuJoCo domains, and the results are mixed. \n\nThe novelty of the work is limited, and the results are hard to interpret: sometimes PDDPG performs better, sometimes worse, and the training curves are only obtained with a single random seed. Also presented results are substantially worse than current state of the art (e.g., TD3, SAC).\n', 'This paper combines elements of two existing reinforcement learning approaches, namely, Deep Q-learning Networks (DQN) with Prioritised Experience Replay (PER) and Deep Deterministic Policy Gradient (DDPG) to propose the Prioritized Deep Deterministic Policy Gradient (PDDPG) algorithm. The problem is interesting and there is a nice review of relevant work. The algorithm has a limited novelty with a simple modification of the DDPG algorithm to add the PER component. Experiment results show improvements in certain simulation environments. However, the paper lacks insight on how and why results are improved on some settings while performing worse than the others. Detailed comments are as follows:\n\n1. Algorithm 1 is not self-contained. Yes, I understand that it is a slight modification to DDPG with changes being Line 11 and 16. But p_i^alpha is not defined anywhere in Algorithm 1. How the transition probabilties are updated on Line 16 is also not clear to me.\n\n2. It would be better if multiple simulation runs on the same experiment can be performed to have a more reliable display of performance.\n\n3. Section 6 is on Parameter Space Noise for Exploration. This is not the authors\' proposed work so it is strange to have a separate section here. In the end of Section 1, the authors wrote that ""We then use the concept of parameter space noise for exploration and show that this further improves the rewards achieved."" This seems to be a bold claim from the varying performance displayed in Figure 2-4. Similar to Comment 2, more simulation runs and statistical tests need to be conducted to support this claim.', ""The paper proposes an augmentation of the DDPG algorithm with prioritized experience replay plus parameter noise. Empirical evaluations of the proposed algorithm are conducted on Mujoco benchmarks while the results are mixed.\n\nAs far as I can see, the paper contains almost no novelty as it crudely puts together three existing algorithms without presenting enough motivation. This can be clearly seen even from the structuring of the paper, since before the experimental section, only a short two-paragraph subsection (4.1) and an algorithm chart are devoted to the description of the main ideas. Furthermore, the algorithm itself is a just simple addition of well-known techniques (DDPG + prioritized experience replay + parameter noise) none of which is proposed in the current paper. Finally, as shown in the experimental sections, I don't see a evidence that the proposed algorithm consistently outperform the baseline.\n\nTo sum up, I believe the submission is below the novelty threshold for a publication at ICLR.""]","[-50, -20, -80]","[0, 50, -20]","[""The sentiment score is -50 because the review is generally negative, pointing out limited novelty, mixed results, and performance worse than state of the art. However, it's not entirely dismissive, acknowledging some positive aspects like the proposed combination of techniques. The politeness score is 0 (neutral) because the language is direct and factual without being overtly polite or rude. The reviewer states observations and criticisms in a professional manner without using inflammatory language or personal attacks, but also without adding polite phrases or softening the critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting problem and nice review of relevant work, they also point out limited novelty and lack of insight into the results. The reviewer mentions improvements in certain environments but also notes worse performance in others. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'it would be better if' and 'this seems to be a bold claim' rather than more confrontational language. The reviewer also provides specific, detailed comments to help improve the paper, which is a polite and professional approach."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, stating it 'contains almost no novelty' and is 'below the novelty threshold for publication'. The reviewer criticizes the paper's structure, lack of motivation, and inconsistent results. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'crudely puts together' and 'I don't see evidence' come across as somewhat impolite in academic discourse. The reviewer doesn't use any softening language or acknowledge potential positives, which contributes to the slightly negative politeness score.""]"
"['The paper studies the standard denoising problem under the assumption that the unknown n-dimensional signal can be written as the output of a known d-layer neural network G mapping k dimensions to n dimensions. The paper specifies an algorithm to perform this denoising and the algorithm is based on a variant of the usual gradient method. Then, under additional assumptions on the neural network G, the paper proves that their algorithm produces a denoised signal that achieves a mean squared accuracy of k/n. Because the input signal has ""effective"" dimensionality k (as it can be written as G(x) for some k-dimensional x), it is nice that it can be recovered at the accuracy k/n by Gradient Descent despite the complicated nature of G. In this respect, the result is quite interesting. However, the underlying assumptions are too strong in my opinion as described below: \n\n1. It is assumed that the Weights of the neural network G are all Gaussian (and also specific Gaussians with mean zero and variances determined by the layer dimensions). This of course is highly impractical. In practice, these network weights are pre-learned (say based on similar datasets) and there is hardly any reason to believe that they will satisfy the Gaussian assumption. \n2. It is assumed that the network is expansive in some sense with an expansivity constant \\epsilon. This \\epsilon then gets into the accuracy bound which basically means that \\epsilon has to be set very small. Unfortunately, this leads to the expansivity condition being quite stringent which will further lead to k being very small (especially if d is large). It is unrealistic to believe that real-world signals will come from a neural network with small k. \n\nGiven that there do not seem to be other such results for the accuracy of neural network denoising, the paper might still be considered interesting despite the above shortcomings. However, I believe that the theoretical result has near-zero relevance to a practical neural network denoiser.\n\nAnother concern is that the paper seems to borrow quite a lot of ideas from the paper ""Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk"" by Hand and Voroninski. It will be good if the authors can explain the essential differences between the present paper and this earlier paper. ', 'This paper studies the signal denoting problem. The theoretical results are nice, and supported by numerical experiments. I have the following two major concerns:\n\n(1) Using deep neural network as a prior in signal denoising is definitely an important and also challenging problem, only when the neural network is learnt from data. However, this paper assumes that the weight matrices of the neural network prior are i.i.d. Gaussian ensemble and independent on the signal. This assumption is oversimplified, and makes the theoretical results become quite expected and delicate. One can hardly get any insights of the practical signal denoising.\n\n(2) The paper has a significant overlap with HV:COLT18:""Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk"". HV:COLT18 consider a RIP-type linear operator, and this paper considers the identity operator, which is actually easier. Dealing with the additive noise is new, but somehow incremental.\n\n~~~~~After Rebuttal~~~~~~\n\nThe rebuttal still cannot justified such a random deep prior well. I keep my rating unchanged.', 'The paper analyzes the recovery accuracy of a ""tweaked"" gradient descent algorithm for imaging denoising and compressive sensing under deep generative priors. In particular, when assuming Gaussian randomness of the network weights and extremely stringent conditions of network sizes, they demonstrate a specific denoising rate of O(k/n), with k and n being the input and output dimension of the generative network. This is seemingly optimal in terms of the dependence on the latent code dimensionality and the signal dimensionality and is the first result of this kind. \n\nTwo papers are closely related, but are not sufficiently discussed in the introduction. [Bora et al., 2017] does not require Gaussian randomness of the network weights, but achieves only O(1) error bound assuming the empirical risk minimization problem can be solved to optimality.  [Hand & Voroninski, 2018] showed that under same assumptions as in this paper, the nonconvex empirical risk minimization problem exhibits a nice geometric landscape - no spurious stationary points. This implies that virtually anything reasonable would converge to global optimum. Combing both facts, it is not surprising to arrive at the results in this paper.\n\nWhile the paper makes some novel theoretical contributions, two concerns stand out. First, there is a lack of intuition or justification of the tweak in gradient descent - flipping the sign of the iterate at times.  The author argued that around approximately -x*, the loss function is larger than around the optimum x* . So simple gradient descent is likely to get stuck in this region, so the negation check is needed. I am not so convinced by the argument. There could be other critical points that are not necessarily in the negative regime of true optimal, right?  So why would this be sufficient or necessary for global convergence? Second, even ignoring the unrealistic Gaussian assumption on the network weights, the theorem requires very narrow regimes for the expansivity condition and the noise variance bound. It\'s hard to verify whether these conditions can be satisfied at all. \n\nThe experiment on denoising with learned prior from MNIST data is interesting, as it suggests that the theoretical assumptions are not necessary in practice to observe the optimal recovery rate. It would be more convincing if more experiments are provided, especially for the compressive sensing application. \n']","[-30, -60, -20]","[50, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they express significant concerns about the underlying assumptions and practical relevance. The review starts positively but then shifts to a more critical tone, highlighting major shortcomings. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's contributions before presenting criticisms. They use phrases like 'it is nice that' and 'the result is quite interesting' before presenting their concerns. The criticisms are presented as professional opinions rather than harsh judgments, maintaining a polite tone even when expressing doubts about the paper's relevance."", ""The sentiment score is -60 because the reviewer expresses two major concerns and states that the paper's assumptions are 'oversimplified' and the results are 'quite expected and delicate.' The reviewer also mentions significant overlap with another paper and maintains a negative rating even after the authors' rebuttal. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as 'nice' theoretical results supported by experiments. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and avoid personal attacks. They present their concerns in a structured manner and provide specific reasons for their assessment. The use of phrases like 'I have the following two major concerns' and 'One can hardly get any insights' maintains a professional tone while clearly expressing disagreement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some novel theoretical contributions, they express significant concerns about the paper. The reviewer points out issues with the lack of intuition for the 'tweaked' gradient descent algorithm, questions the necessity and sufficiency of the proposed approach, and criticizes the unrealistic assumptions and narrow regimes required by the theorem. However, the reviewer does recognize some positive aspects, such as the interesting experiment on denoising.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'I am not so convinced' rather than more confrontational phrases. The reviewer also acknowledges the paper's contributions and suggests improvements rather than outright dismissing the work. The language is constructive and aimed at improving the paper rather than criticizing the authors personally.""]"
"['This paper offers the argument that dropout works not due to preventing coadaptation, but because it gives more gradient, especially in the saturated region. However, previous works have already characterized how dropout modifies the activation function, and also the gradient in a more precise way than what is proposed in this paper. \n\n## Co-adaptation\nco-adaptation does not seem to mean correlation among the unit activations. It is not too surprising units need more redundancy with dropout, since a highly useful feature might not always be present, but thus need to be replicated elsewhere.\n\nSection 8 of this paper gives a definition of co-adaptation,\nbased on if the loss is reduced or increased based on a simultaneous change in units.\nhttps://arxiv.org/abs/1412.4736\nAnd this work, https://arxiv.org/abs/1602.04484, reached a conclusion similar to yours\nthat for some notion of coadaptation, dropout might increase it.\n\n## Gradient acceleration\nIt does not seem reasonable to measure ""gradient information flow"" simply as the norm of the gradient, which is sensitive to scales, and it is not clear if the authors accounted for scaling factor of dropout in Table 2.\n\nThe proposed resolution, to add this discontinuous step function in (7) with floor is a very interesting idea backed by good experimental results. However, I think the main effect is in adding noise, since the gradient with respect to this function is not meaningful. The main effect is optimizing with respect to the base function, but adding noise when computing the outputs. Previous work have also looked at how dropout noise modifies the effective activation function (and thus its gradient). This work, http://proceedings.mlr.press/v28/wang13a.html, give a more precise characterization instead of treating the effect as adding a function with constant gradient multiplied by an envelop. In fact, the actual gradient with dropout does involve the envelope by chain rule, but the rest is not actually constant as in GAAF. \n', 'The authors attempt to propose an alternative explanation for the effect of dropout in a neural network and then present a technique to improve existing activation functions.\n\nSection 3.1 presents a experimental proof of higher co-adaptation in presence of dropout, in my opinion this is an incorrect experiment and request authors to double check. In my experience, using dropout results in sparse representations in the hidden layers which is the effect decreased co-adaptions. Also, a single experiment with MNIST data-set cannot be a proof to reject a theory.\n\nSection 3.2 Table 2 presents a comparison between average gradient flow through layers during training where flow with dropout is higher. This is not very surprising, in my opinion, given the variance of the activation of a neuron in presence of dropout the network tries to optimize the classification cost while trying to reduce the variance. The experimental details are almost nil.\n\nThe experiments section 5 presents very weak results. Very little or no improvement and authors randomly introduce BatchNorm into one of the experiment.', 'This paper gives further analysis on dropout and explains why it works although Hinton et al. already showed some analysis. This paper also introduced a new gradient acceleration in activation function (GAAF).\n\nOn Table 4, the GAAF is a bit worse than dropout although GAAF converges fast. But i am not sure whether GAAF is really useful on large datasets, not on a small dataset, e.g., MINIST here. On table 5, i am not sure whether you compared with dropout or not. Is your base model already including dropout?\n\nIf you want to demonstrate that GAAF is really helpful, i think more experiments and comparisons, especially on larger datsets should be conducted.\n\n\n\n']","[-50, -60, -20]","[20, -20, 20]","[""The sentiment score is -50 because the review is generally critical of the paper's main arguments and contributions. The reviewer points out that previous works have already characterized dropout effects more precisely, and questions the novelty and accuracy of the paper's claims. However, it's not entirely negative as the reviewer acknowledges some interesting ideas and experimental results.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'It does not seem reasonable' and 'I think' rather than making blunt or harsh statements. The reviewer also acknowledges positive aspects, such as 'a very interesting idea backed by good experimental results'. The language is not overtly polite, but it avoids rudeness and maintains a constructive tone."", ""The sentiment score is -60 because the reviewer expresses significant criticism and skepticism throughout the review. They describe the experiments as 'incorrect', 'weak', and lacking details. They also suggest the authors' conclusions are not well-supported. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. Phrases like 'this is an incorrect experiment' and 'very weak results' come across as somewhat harsh. The reviewer does use some polite phrases like 'in my opinion' which prevents the score from being lower, but the overall tone leans towards the critical and direct side rather than being particularly courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express doubts about the usefulness of GAAF on larger datasets and suggest that more experiments are needed. The overall tone indicates that the reviewer is not fully convinced by the paper's findings. The politeness score is slightly positive (20) as the reviewer uses neutral language and offers constructive feedback without being harsh. They use phrases like 'I am not sure' and 'I think' which soften their criticisms. The reviewer also acknowledges the paper's contributions at the beginning, which is a polite way to start a review.""]"
"[""This paper studies the implicit bias of minimizers of a regularized cross entropy loss of a two-layer network with ReLU activations. By combining several results, the authors obtain a generalization upper bound which does not increase with the network size. Furthermore, they show that the maximum normalized margin is, up to a scaling factor, the l1 svm margin over the lifted feature space of an infinite-size network. Finally, in a setting of infinite-sized networks, it is proved that perturbed Wasserstein gradient flow finds a global minimum in polynomial time.\n\nI think that the results are interesting and relevant to current efforts of understanding neural networks. The techniques and ideas seem promising and may be applied in more general settings. The paper is mostly clearly written, but there are some issues which I outline below.\n1.\tIt is not clear what is the novelty in sections 2 and 3.1 except the combination of all the results to get a generalization bound which does not increase with network size (which on its own is non-trivial). Specifically, \na.\tWhat is the technical contribution in Theorem 2.1 beyond the results of the two papers of Rosset et al. (journal paper and the NIPS paper which was mentioned in the comment on missing prior work)?\nb.\tHow does Theorem 3.1 compare with previous Rademacher bounds for neural networks which are based on the margin? In Neyshabur et al. (2018), it is shown that margin-based generalization bounds empirically increase with network size. Does this hold for the bound in Theorem 3.1?\n\n2.\tIn the work of Soudry et al. (2018) section 4.3, they consider deep networks with an unregularized loss and show that gradient descent converges to an l2 max margin solution under various assumptions. What is the connection between this result and the l1 max margin result in section 3.3?\n\n3.\tWhat are the main proof ideas of Theorem 4.3? Why is the perturbation needed?\n\n4.\tWhat is the size of the network that was trained in Section 5 in the experiments of Figure 3? Only the size of the ground truth network is mentioned.\n\n\n---------Revision------------\n\nI have read the author's response and other reviews. I am not changing the current review.\nI have one technical question. In the new generalization bound (Proposition 3.1), the authors claim that the product of Frobenius norms is replaced with a sum. However, I don't see any sum in the proof. Could the authors please clarify this?"", 'UPDATE: after revisions and discussion. There seems to be some interesting results presented in this paper which I think would be good to have discussed at the conference. This is conditional on further revisions of the work by the authors.\n\n\nThis paper studies margin theory for neural nets.\n\n1. First it is shown that margin of the solution to regularized problem approaches max margin solution.\n2. Then a bound is given for using approximate solution to above optimization problem instead of exact one. Note that the bound depends on size of the network via parameter a.\n3. Then 2-layer relu networks are studied. It shown that max margin is monotonically increasing in size of the network. Note however, it is hard to relate this results to inexact solutions since the bound in that case as was pointed out also depends on the size of the network.\n4. Paper also provides comparison with kernel methods, simulations and shows that perturbed wasserstein flows find global optimiziers in poly time.\n\nThe paper argues that over-parameterization is good for generalization since margin grows with the number of parameters. However, it should be also noted the radius of data may also grow (and in case of the bounds it seems to be the radius of data in lifted space which increases with the size of the network). I hope authors can clarify this and points 2 and 3 above in their response. In the current form the paper is below the acceptance threshold for me. ', 'Overall I found that the paper does not clearly compare the results to existing work. There are some new results, but some of the results stated as theorems are immediate consequence of existing work and a more detailed discussion and comparison is warranted. I will first give detailed comments on the establishing the relationship to existing work and then summarize my evaluation. \n\n————\nDetailed comments on contributions and relationships to existing work.\n\nA. Theorem 2.1 establishes the limit of the regularized solutions as the maximum margin separator. \nThis result is a generalization the analogous results for linear models Theorem 3 in Rosset et al. (2004) “Boosting as a regularized path to maximum margin separator” and Thm 2.1 in Rosset Zhu Hastie “margin maximizing loss functions”  (the later paper missing from references, and that paper generalizes the earlier result for multi-class cross entropy loss). \nMain difference from earlier work:\n1. extends the results for linear models to any homogeneous function \n2. (minor) the previous results by Rosset et al. were stated only for lp norms, but this is a minor generalization since the earlier work didn’t at any point use the lp-ness of the norm and immediately extends for any norms. \n\nSecondly, Theorem 2.2 also gives a bound on deviation of margin when the regularization is not driven all the way to 0. I do think this theorem would be differently stated by making the explicitly showing dependence of suboptimal margin \\gamma’ on lambda and the sub optimality constant of loss. This way, one can derive 2.1 as a special case and also reason about what level of sub-optimality of loss can be tolerated. \n\nB. Theorem 3.1 derives generalization bounds of learned parameters in terms of l2 margin. \n—this and many similar results connecting generalization to margins have already been studied in the literature (Neyshabur et al. 2015b for example covers a larger family of norms than just l2 norm). Specially an analogous bound for l1 margin can also be found in these work which can be used in the discussions that follow. \n\nC. Theorem 3.2: This result to my knowledge is new, but also pretty immediate from definition of margin. The proof essentially follows by showing that having more hidden units can only increase the margin since the margin is maximized over a larger set of parameters. \n\nD. Comparison to kernel machines: Theorem 3.3 seems to be the paraphrasing of corollary 1 in Neyshabur et al (2014). But the authors claim that the Theorem 3.3 also holds when “the regularizer is small”. I do not understand what the authors are referring to here or how the result is different form existing work. Please clarify\n\n-----------\nIn summary, The 2.1-2.2 on extension of the connection between regularized solution and maximum margin solution to general homogeneous models and to non-asymptotic regimes \n-- this is in my opinion key contribution of the paper and an important result. But there is not much new technique in terms of proof here\n', 'The authors claim to prove three things: (1) Under logistic loss (with a vanishing regularization), the normalized margin (of the solution) converges to the max normalized margin, for positive homogenous functions. This is an asymptotic result: the amount of regularization vanishes. (2) For one hidden layer NN, the max margin under l_2 norm constraint on weights in the limit, is equivalent to the l_1 constraint (total variation) on the sign measure (specified by infinite neurons) for the one hidden layer NN. (3) Show some convergence rate for the mean-field view of one hidden layer NN, i.e., the Wasserstein gradient flow on the measure (of the neurons). The author show some positive result for a perturbed version.\n\nThe problem is certainly interesting. However, my main concerns are: (1) the novelty of the main theorems given the literature, and (2) the carefulness of stating what is known in the literature review.\n\nIn summary:\n1. Theorem 2.1, Theorem 3.1, and Theorem 3.3 are anticipated, or not as critical, given the literature (detailed reasons in major comments).\n\n2. The construction in Theorem 3.5 is nice, but, it is only able to say an upper bound of the generalization of kernel is not good (comparing upper bounds is not enough). In addition, For Theorem 4.3. [Mei Montanari and Nguyen 2018] also considers similar perturbed Wasserstein gradient flow, with many convergence results. One needs to be more careful in stating what is new.\n\n\nMajor comments:\n1. Theorem 3.3 (and Theorem 3.2) seems to be the most interesting/innovative one.\nHowever, I would like to argue that it might be natural in one line proof, with the following alternative view:\n\n--\nl_2 norm constraint normalized margin, one hidden layer NN, with infinite neurons\n\ngamma^star, infty :=\n\\max \\min_i y_i int_{neuron} w || u || ReLU( x_i \\bar{u}) dS^{d-1} -- integral over normalized neurons over sphere\n\nunder the constraint\nint_{neuron} (w^2 + ||u||^2) dS^{d-1} \\leq 1\n\nThis is equivalent to the l_1 constraint margin (variation norm), one hidden layer NN,\ngamma_l_1 :=\n\\max \\min_i y_i int_{neuron} rho(u) ReLU( x_i \\bar{u}) dS^{d-1} -- integral over normalized neurons over sphere\n\nunder the constraint\nint_{neuron} |rho(u)| dS^{d-1} \\leq 1/2\n\nhere rho(u) is the sign measure represented by neurons. Simply because at the optimum\nw || u || = 1/2 ( w^2 + || u ||^2) := rho(u)\ntherefore\ngamma^star, infty =  gamma_l_1\n\nSo one see the factor 1/2 exactly.\n--\n\nIn addition, [Bach 18, JMLR:v18:14-546] discuss more in depth the l_1 type constraint\n(TV of sign measure) rather then l_2 type constraint (RKHS) for one hidden layer NN with infinite neurons. The authors should cite this work.\n\nIt is clear that l_1(neuron) < l_2(neuron) therefore\nl_2 constraint margin is always smaller than l_1 constraint margin.\n\n2. Theorem 2.1. I think the proof is almost a standard exercise given [Rosset, Zhu, and Hastie 04].\nThe observation for it generalizes to positive homogenous function beyond linear is a nice addition, but not crucial enough to stand out as an innovation.\n\nMuch of the difficulty in related paper lies in achieving non asymptotic convergence rate to max margin solution, for logistic loss [Soudry, Hoffer and Srebro 18], or what happens when data is not perfectly separable [Ji and Telgarsky 18].\n\n3. Generalization result Theorem 3.1. Maybe it is better to state as a corollary, given the known results in the literature, in my opinion. This generalization is standard result from margin-based bounds available\n[Koltchinskii and Panchenko 02, Bartlett and Mendelson 02].\n\nIn addition, the authors remark that the limit for (3.3) may not exist. You can change to limsup, your footnote[4]\nis essentially the limsup definition.\n\n4. Theorem 3.5. This construction of the data distribution is the part I like. However, you should remind the reader that\nhaving a small margin for the kernel only implies the the upper bound for generalization is bad.\nComparing the upper bound doesn\'t mean kernel method is performing bad for the instance.\n\nFrom a logic view, it is unclear the benefit of Theorem 3.5.\nI do agree one can try to see in simulation if kernel/RKHS approach (l_2) is performing worse for generalization, for one hidden layer NN. But this is separate from the theory.\n\n5. Theorem 4.3. This result should be put in the context of the literature. Specifically\n[Mei Montanari and Nguyen 2018], Eqn 11-12. The perturbed wasserstein flow the authors considered\nlooks very close to [Mei Montanari and Nguyen 2018], Eqn 11-12, admittedly with the logistic loss instead of the square loss.\n\nRight now, as stated in the current paper, it is very hard for the general audience to understand the contribution. A better job in comparing the literature will help.\n\nFor the technical crowd, maybe emphasize on why the ""simga"" can help you achieve a positive result.\n\nMinor Comments:\n\n6. One additional suggestion: seems to me Section 4 is a bit away from the central topic of the current paper.\n\nI can understand that the optimization/convergence result will help complete the whole picture. However, to contribute to the ""margin theme"", it would be better to state with the ""small vanishing regularization"", how it affects the convergence of Theorem 4.3.\nEven with this, it is unclear as one don\'t know how to connect different part of the paper: with what choice of vanishing regularization will generate a solution with a good margin, using the Wasserstein gradient flow.\n']","[50, -20, -30, -30]","[75, 50, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer states the results are 'interesting and relevant' and the techniques 'seem promising', indicating a generally positive view. However, they also raise several questions and issues, tempering the positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits before raising concerns. They phrase their critiques as questions or suggestions rather than direct criticisms. The use of phrases like 'I think' and 'It is not clear' maintains a polite tone while expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting results and potential for discussion at the conference, they also express concerns and state that 'in the current form the paper is below the acceptance threshold'. This indicates a generally critical stance, albeit with some positive aspects. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive feedback and expressing hope for clarification rather than using harsh criticism. They also acknowledge the potential value of the work if revisions are made. The tone is academic and objective, avoiding personal attacks or overly negative language."", 'The sentiment score is -30 because the reviewer expresses several criticisms, noting that some results are not novel and the paper lacks clear comparison to existing work. However, they do acknowledge some new and important contributions, preventing a more negative score. The politeness score is 20 because the reviewer uses professional and respectful language throughout, offering constructive feedback and detailed explanations for their critiques. They avoid harsh or dismissive phrasing, instead providing specific suggestions for improvement. The slightly positive politeness score reflects this professional tone, though it stops short of being overtly warm or complimentary.', ""The sentiment score is -30 because while the reviewer acknowledges the problem as interesting, they express significant concerns about the novelty of the main theorems and the accuracy of the literature review. The reviewer points out several issues with the theorems, suggesting they are either anticipated or not as critical as presented. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I would like to argue' and 'One needs to be more careful' rather than harsh criticism. They also offer constructive suggestions and acknowledge positive aspects, such as 'This construction of the data distribution is the part I like.' The language is consistently polite and academic, avoiding personal attacks or overly negative language.""]"
"['This paper presents an empirical evaluation of continual learning approaches for generative modelling. Noting that much of previous work focuses on supervised tasks, the paper evaluates various combinations of continual learning strategies (EWC, rehearsal/replay-based, or generative replay) and generative models (GANs or likelihood-based).\nThe experiments evaluate all combinations on MNIST and Fashion MNIST, and the resulting best-performing combination on CIFAR.\nThe paper is well-written and structured, and although there are no new proposed algorithms or measures, I think this has the potential to be a useful empirical study on the relatively unstudied topic of continual learning with generative models.\n\nHowever, my main concern is in the detail of analysis and discussion: for an empirical study, it would be much more beneficial to empirically investigate *why* certain combinations are more effective than others. For example:\n- Is the reason GANs are better than likelihood models with generative replay purely because of sample quality? Or is it sufficient for the generator to learn some key characteristics for a class that lead to sufficient discriminability?\n- Why is rehearsal better for likelihood models? (And how does this relate to the hypothesis of overfitting to a few real examples?)\n\nThe CIFAR-10 results also require more work - it is unclear why the existing approaches could not be made to work, and whether this is a fundamental deficiency in the existing approaches or other factors (hyperparameters, architecture choices, lack of time, etc). Presuming the sample quality is as good as in the WGAN-GP work (given the original implementation is used for experiments), why is this insufficient for generative replay? More detailed analysis / discussion, or another combinatorial study, would help for CIFAR too.\n\nSome comments:\n- The poor performance of EWC across the board is concerning. Was this implemented by computing the Fisher of the ELBO with respect to parameters? Was the empirical or true Fisher used? Why does the performance appear so poor compared to Seff et al (2017)? This suggests that either more thought is required on how to best protect parameters of generative models, or the baseline has not been properly implemented/tuned.\n- Given this is an entirely empirical study, I would strongly encourage the authors to release code sooner than the acceptance deadline - this can be achieved using an anonymous repository.\n- Figure 2 and 3 plots are a little difficult to parse without axis labels.', 'This paper performs an empirical comparison of models and CL methods in a generative setting. The main motivation of the paper is to make statements about which model/method combinations are best to use for generative tasks in the CL setting. In short, the paper provides an empirical analysis and evaluation of the combination of CL methods and generative models.\n\nThe datasets used for comparison are MNIST, Fashion MNIST, and CIFAR10. For each dataset, sequential (class by class) generative tasks are introduced, aligning with the CL setting. The models investigated are VAEs, GANs, and WGANs, along with their (class) conditional counter-parts. The CL methods investigated are (i) fine-tuning (a simple baseline), (ii) rehearsal methods, (iii) elastic weight consolidation (EWC), and (iv) generative replay (GR). The authors propose to use two evaluation metrics: Fréchet Inception Distance (FID) measures the quality of the generated images, and fitting capacity (FC) measures the usefulness of the images to train classifiers.\n\nPros:\n- The authors are correct in pointing out that most of the work on CL has been restricted to the discriminative case, and that there is value in exploring generative tasks in the CL setting.\n- Empirical and experimental evaluation of this sort are useful, and help the community better understand the relationship between model, CL method, and task. Such an evaluation and in-depth analysis is welcomed in CL, especially in the generative setting.\n- The authors draw a number of useful conclusions e.g., regarding the usefulness and dangers of employing the different CL methods.\n\nCons:\n- My main concern with this paper regards the evaluation metrics used. The authors propose quality metrics for the generative model, both of which (directly or indirectly) measure the quality of the generated images. In this setting, it is unsurprising that GANs outperform VAEs, as they are known to generate higher-quality images. This however, does not necessarily mean that they are better at the continual learning task (i.e., avoiding catastrophic forgetting). It seems to me that one source from which to draw would be [1], which conducted a very rigorous and useful empirical evaluation of generative models, and the methodology followed there (i.e., evaluating marginal log-likelihoods via annealed importance sampling) would be more convincing evidence for empirical comparison of models, as it would somewhat detach the quality of the generated images from the ability of the model to avoid catastrophic forgetting.\n\nUsing their proposed image-quality metrics, the authors make statements such as: ""Our results do not give a clear distinction between conditional and unconditional models. However, adversarial methods perform significantly better than variational methods. GANs variants are able to produce better, sharper quality and variety of samples, as observed in Fig. 13 and 14 in Appendix G. Hence, adversarial methods seem more viable for CL."" My impression is that this statement on the viability of VAEs vs GANs for CL, which is a major point of the paper, does not follow from the empirical results on the quality of the generated images. It seems quite predictable that the GAN-based models would produce higher quality images, regardless of catastrophic forgetting.\n\nAdditional (minor) comments:\n- Sec. 2 could consist of a more thorough review of the literature, with a more in-depth comparison of the different CL methods proposed and evaluated in the paper.\n- Sec. 2 contains a number of statements of the form: ""restricted to VAEs only"". For many of the cases it is not immediately clear why this is true, and in my opinion the authors should either drop those comments, or make them rigorous.\n- VCL ""use specific weights for each task, which only works for the setting where the number of tasks is known in advance"". Unclear what exactly this means or why this is true.\n- ""while the teacher retains knowledge"" - how does it ""retain knowledge"", how is this then transferred to the student, and why is this restricted to VAEs?\n\nExperimental protocol:\n- Core-sets for the rehearsal as proposed by [1] could be an interesting extension. It is unclear how the samples were selected for rehearsal, and core-sets represent a principled way to do so, that would also be interesting to compare in this setting to a random baseline.\n- For VAEs, a potentially better metric of their ability (other than the log-likelihood as suggested by [2]) would be fitting capacity (or other metric) over learned latent space rather than the reconstructed image-space.\n\nOverall, my impression is that while an empirical analysis of CL methods in the generative setting is a useful concept, the submission in its current form requires some improvement. In particular, I am worried that the choice of evaluation metrics may lead to incorrect (or partially correct) conclusions, which could of course have a negative impact on the research into CL. It also seems that the paper could use some further polishing in both writing and presentation. As such, I encourage the authors to continue the work on this empirical analysis, and perhaps submit in again to future conferences.\n\n[1] - Nguyen et al. Variational Continual Learning, ICLR 2018\n[2] - Wu et al. On the Quantitative Analysis of Decoder-Based Generative Models, ICLR 2017', 'This paper evaluates and compares various methods for learning GANs in a Continual Learning setting, i.e., only some of the classes are available during training. It evaluates different continual learning methods including rehearsal, EWC and generative replay applied to training several deep generative models, like GAN, CGAN, WGAN, WGAN-GP, VAE and CVAE on MNIST, Fashion MNIST and CIFAR. The authors conclude with these experimental results that generative replay is the most effective method for such a setting, and found it is difficult to generate CIFAR10 images that can be classified successfully by an image classifier.\n\nI appreciate the authors for providing so much detailed experimental results to the community, but this paper lacks novelty in general. All the CL methods the authors evaluate come from other papers that are already using these methods for generative models: rehearsal has been used in VCL Nguyen et al. (2017), EWC comes directly from Seff et al. (2017), and generative replay has been used by Wu et al. (2018a). The authors also fail to provide any valuable insight with these experimental results, e.g., analyzing why generative replay fails to improve VAEs. \n\nI expect to see more exciting results coming from the authors, but the paper is not mature enough for acceptance this time.\n']","[20, -30, -50]","[70, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's potential as a useful empirical study and praises its structure, but expresses concerns about the depth of analysis and discussion. The politeness score is fairly high (70) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive comments with areas for improvement. The reviewer uses phrases like 'well-written and structured' and 'potential to be a useful empirical study', while also providing specific suggestions for improvement in a professional manner."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('Pros'), they express significant concerns about the paper's methodology and conclusions ('Cons'). The reviewer states that the paper 'requires some improvement' and encourages the authors to continue working on it, suggesting it's not ready in its current form. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the value of the work, and offers constructive criticism. They use phrases like 'I encourage the authors to continue the work' and 'Such an evaluation and in-depth analysis is welcomed', which maintain a polite and supportive tone even while expressing concerns."", ""The sentiment score is -50 because while the reviewer appreciates the detailed experimental results, they express significant criticism about the paper's lack of novelty and insufficient insights. The overall tone suggests the paper is not ready for acceptance. The politeness score is 20 because the reviewer uses polite language like 'I appreciate' and provides constructive feedback, but also directly states the paper's shortcomings without much softening of the criticism. The reviewer maintains a professional tone throughout, avoiding rudeness while being frank about the paper's limitations.""]"
"['This paper identifies bias of commercial Face detection API (Microsoft, Google, Face++, IBM) by sending face images generated from AirSim, in which different face attributes (e.g., skin color, age, face orientation, lighting conditions, etc) can be controlled and explored. The paper shows that for darker skin color and old age, the classifier tends to have a higher false negative rate (miss the face more). This is in particular more apparent if Bayesian Optimization is used to explore the parameter space based on the previous detection results to find the failure cases. \n\nThere are several concerns:\n\n1. Bayesian Optimization might itself create a bias in the input data distribution, since it selectively pick some parameter configuration over the others.   \n\n2.  Using simulator might create additional biases. Maybe the faces generated by the simulator using the parameters of skin color of the minority / old age are less realistic than other faces, which lead to higher misclassification rate. In the paper there is no analysis in that aspect. \n\nOverall I feel this is an interesting paper and it may identify important problems in the existing commercial AI system. However,  I am not an expert in this field so I am less confident about the thoroughness of experiments, as well as the fairness of approaches. \n\nMinor issue:\n\nFig. 4 “Age”, skin detection => age. \n', '\nSummary:\n=========\nThe paper uses a proof-of-concept Bayesian parameter search-based simulation in virtual environment to probe biases of an already trained model towards specific categories that may have been sparsely represented in the training set. Understanding bias in trained models, especially in models involving end-to-end deep neural networks learners, is of high importance in machine learning. More specifically, probing the source of unintentional bias introduced as a result of skewed distribution in the training set and dissecting the biased performance is important for many applications such as surveillance, criminal profiling, medical diagnosis and predicting creditworthiness of a person. \n\nThe authors used four commercial face recognition APIs (by Microsoft, Google, IBM, and Face++) as test bed for this investigation.\n\nStrength:\n========\n- The paper reads well and is easy to follow.\n\n- The application of face detection and recognition is a good choice as it is precursor to detailed analysis in surveillance and criminal profiling.\n\n- The choice of the controlled Bayesian parameter search enables one to control the amount of variation with respect to the expected uncertainty in performance of the classifier on the generated input from the simulator.\n\n- The use of standardized measures such as Fitzpatrick’s skin tone and FACS intensity help in replication and consistency in the evaluation.\n\nWeakness:\n=========\n\n- Although evaluating commercial APIs is good enough in demonstrating the existence of the bias, access to the trained model with possibility to retrain the model in such a way to mitigate a bias in particular parameter could have helped to further tie the drop in performance to the parameter variation.\n\n- This work is preliminary and only involves a single person face manipulated in the parameter space. It lacks diversity of in samples and as such limits the analysis to draw strong conclusions. As such a generative network (such as a GAN trained to generate diverse samples while controlling for the parameters under investigation could have helped to draw more generalized conclusion.\n\n- The age parameter variation is not convincingly different across the values considered. It would have been interesting to use models trained for age progression such as [1] for a more diverse variation in the age parameter space.\n\nMinor comments:\n===============\n- Figures 4 and 5 could have used better captions describing the ranges for instance for age 1 is older and for skin tone 1 is darker (although indicated in Fig. 3). Captions should be self contained. Fig. 5 caption should describe the chance performance in each case.\n\n- The manuscript should be revised to make in text citation formats consistent (some places it uses authors (year) and other places it uses (authors, year)). Also, minor punctuation and syntactic errors should be fixed.\n\n[1] Yang, H., Huang, D., Wang, Y. and Jain, A.K., 2017. Learning face age progression: A pyramid architecture of gans. arXiv preprint arXiv:1711.10352.', ""Quality and Clarity:  The paper is clear and has comprehensive references to the recent literature and past literature on face detection, bias in computer vision data and systems.  \nOriginality:   Since the main claim of the paper is about the use of graphics simulation for performance characterization, we recommend that the authors review past work on use of simulations for systems performance characterization.  The idea of using simulations to perform performance assessment of vision goes back to the 90's (see for instance: haralick et al (haralick.org, performance characterization papers). The idea of using computer graphics simulations for transfer learning and performance assessment has been revisited recently (see for instance: veerasavarappu et al, 2015-17, arxiv papers, cvpr 2017, wacv 2017). \n\nSignificance:  While the paper demonstrates the utility of the main idea, the results are not comprehensive and can be strengthened.  For instance, the authors state that simulations can be used to combat bias via training with augmented data.   My opinion is that the paper may be more well suited in a applied workshop/conference such as WACV. ""]","[20, 50, -20]","[60, 80, 50]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and acknowledges that it 'may identify important problems'. However, they also express several concerns and uncertainties, which temper the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'There are several concerns'), and acknowledges their own potential limitations ('I am not an expert in this field'). The reviewer also offers a minor correction in a neutral tone. The overall tone is professional and courteous, without being overly deferential."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary, highlighting both strengths and weaknesses of the paper. The reviewer acknowledges the importance of the topic and praises aspects like readability and methodology choices. However, they also point out significant limitations, suggesting the work is preliminary and could be improved. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'could have helped' and 'it would have been interesting' when suggesting improvements, maintaining a professional and courteous tone. The reviewer also acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clear', 'comprehensive references'), they also point out significant limitations ('results are not comprehensive', 'can be strengthened') and suggest the paper might be better suited for a different venue. This indicates the reviewer is not fully convinced of the paper's suitability or significance in its current form. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement without using harsh or dismissive language. They maintain a professional tone, using phrases like 'we recommend' and 'my opinion is', which contribute to the polite nature of the review.""]"
"['Main idea:\nThis paper studies a problem of the importance weighted autoencoder (IWAE) pointed out by  Rainforth 18, that is, tighter lower bounds arising from increasing the number of particles improve the learning of the generative model, but worsen the learning of the inference network. The authors show that the reweighted wake-sleep algorithm (RWS) doesn\'t suffer from this issue. Moreover, as an alternative to control variate scheme and reparameterization trick, RWS doesn\'t suffer from high variance gradients, thus it is particularly useful for discrete latent variable models.   \nTo support the claim, they conduct three experiments: 1) on ATTEND, INFER, REPEAT, a generative model with both discrete and continuous latent variables; 2) on MNIST with a continuous latent variable model; 3) on a synthetic GMM.\n\nClarity issues:\n1. ""branching"" has been used many times, but AFAIK, this seems not a standard terminology. What do ""branching on the samples"", ""conditional branching"", ""branching paths"" mean?\n2. zero-forcing failure mode and delta-WW: I find this part difficult to follow. For example, the following sentence \n""the inference network q(z|x) becomes the posterior for this model which, in this model, also has support at most {0, . . . , 9} for all x"". \nHowever, this failure mode seems an interesting finding, and since delta-WW outperforms other methods, it deserves a better introduction. \n\nQuestions:\n1. In Fig 1 (right), how do you estimate KL(q(z|x) || p(z|x))?\n2. In Sec 4.2, why do you say IWAE learns a better model only up to a point (K = 128) and suffers from diminishing returns afterwards?  \n3. In Fig 4, why WS doesn\'t achieve a better performance when K increasing?\n\nExperiments:\n1. Since the motivating story is about discrete latent variable models, better baselines should be compared, e.g. RBM, DVAE, DVAE++, VQ-VAE etc. \n2. All experiments were on either on MNIST or synthetic data, at least one large scale experiment on discrete data should be made to verify the performance of RWS. \n', 'This manuscript investigates the performance of Reweighted Wake-Sleep (RWS) framework for learning deep generative models with discrete latent variables. It gives a clear introduction to variational autoencoder based models for scenarios with discrete latent variables, including IWAE and also models based on continuous relaxations of discrete variables. The paper performs several experiments, which suggest that RWS is more appropriate for discrete latent variables than other methods such as IWAE. Especially, increasing the number of particles, unlike IWAE, always enhances the performance of RWS.\n\nWhile this paper investigates an important problem, and also offers interesting observations, it lacks a rigorous analysis of why the RWS performance is consistently better than IWAE. More precisely, the propositions should be stated in more formal language and they should be accompanied with a minimal rigorous justification.', 'This paper conducts an extensive set of experiments on RWS and compares it against a set of benchmarks such as GMM and IWAE. The main contribution of the paper is the fact revealed by these experiments, that RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to continuous latent variable models as well. The performance of RWS will increase significantly if we increase the number of particles. \n\nThe experimental part is written in an inspiring way, and I enjoyed reading it. However, there should be stronger baselines incorporated. for example, https://arxiv.org/abs/1805.07445. Also, I think the authors could try to emphasize more on the shortcomings of RWS discovered by the GMM experiments, and how defensive importance sampling fixes it. There are several other parts in the paper that indicates interesting facts, diving deeper into it could possibly lead to more interesting findings.\n\nIn all, I would consider these comparison results important to be somewhere in the literature, but because its lack of rigorous analysis and explanation for the observations, I personally think these observations alone are not novel enough to be an ICLR paper. \n']","[20, 50, -20]","[60, 75, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and interesting findings, particularly regarding the reweighted wake-sleep algorithm (RWS). However, they also point out several clarity issues and questions, suggesting room for improvement. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They use phrases like 'better baselines should be compared' and 'deserves a better introduction,' which are polite ways of suggesting improvements. The reviewer also asks questions for clarification rather than making accusatory statements, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the problem and the interesting observations made in the paper. They use phrases like 'clear introduction' and 'interesting observations', which indicate a positive view. However, they also point out that the paper 'lacks a rigorous analysis', suggesting room for improvement. This balance of positive comments and constructive criticism results in a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout. They acknowledge the paper's strengths before offering suggestions for improvement. The criticism is presented constructively, using phrases like 'should be' rather than more demanding language. The overall tone is professional and courteous, maintaining a balance between praise and critique without being overly harsh or dismissive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('extensive set of experiments', 'inspiring', 'enjoyed reading it'), they ultimately conclude that the paper lacks novelty and rigorous analysis for an ICLR paper. The reviewer suggests improvements and points out shortcomings, indicating a generally critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and provides constructive feedback. They use phrases like 'I enjoyed reading it' and offer specific suggestions for improvement, which contributes to a polite tone. However, the criticism is still direct, preventing a higher politeness score.""]"
"['summary--\nThe paper focuses on improving object localization, though the title highlights ""interpreting deep neural network"" which is another area. It analyzes the classifier weights for image classification, and compute the derivative of the feature maps from the network for a sensitivity map of the image. Then it learns a simple linear mapping over the sensitivity map for bounding box regression. Experiments report competitive performance.\n\nHowever, there are several major concerns.\n\n1) The paper appears misleading from multiple claims. For example, [abstract] ""common approaches to this problem involve the use of a sliding window,... time consuming"". However, current state-of-the-art methods accomplish detection in a fully convolutional manner using CNN, and real-time performance is achieved. the paper claims that ""computer vision can be characterized as presenting three main tasks... (1) image classification, (2) image localization and (3) image detection"". This appears quite misleading. There are way more topics, from low-level vision to mid-level to high-level, e.g., stereo, boundary detection, optical flow, tracking, grouping, etc. Moreover, just in ""localization"", this could be object localization, or camera localization. Such misleading claims do not help readers learn from the paper w.r.t related work in the community.\n\n\n2) The approach ""is rooted in the assertion that any deep CNN for image classification must contain, implicit in its connection weights, knowledge about the location of recognized object"". This assertion does not appear obvious -- an reference should be cited if it is from other work. Otherwise, recent work shows that deep CNN can overfit random training data, in which case it is hard to imagine why the object location can be implicitly captured by the CNN [R1]. Similarly, the paper claims that ""once weights are found, the gradient... with regard to X would provide information about the sensitivity of the bounding box loss function with regard to the pixels in the images"". This is not obvoius either as recent work show that, rather than the whole object, a part of it may be more discriminative and captured by the network. So at this point, why the gradient can be used for object location without worrying that the model merely captures a part? \n\n[R1] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals, Understanding deep learning requires rethinking generalization, ICLR 2017.\n[R2] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba, Learning deep features for discriminative localization, CVPR 2016.\n\n3) The paper admits in Section 2.2 that ""we have not yet done a formal comparison of these two approaches to constructing the sensitivity map"". As the two approaches are suggested by the authors, why not comparing in this paper. It makes the paper less self-contained and not ready to publish. A formal comparison in the rebuttal may improve the rating of the paper.\n\n4) In Equation 3, how to represent the bounding box coordinate? Are they any transforms? What does it mean by ""bias weights""? Are they different from Cartesian coordinates, or the one used in Equation (2)?\n\n\n5) The experiments are not convincing by merely reporting the metric of IoU>0.5 without any in-depth analysis. Perhaps some visualization and ablation study improve the quality of experiments.\n\n6) In Section 3.2, why using two different aggregation methods for producing the final sensitivity map -- max-pool along the channel for PACAL VOC 2017 dataset and avg-pool for ImageNet dataset, respectively? Are there some considerations?\n\n7) In Table 1, it shows the proposed method outperforms the other methods significantly, achieving 41% better than the second best method. However, there is no in-depth analysis explaining why the proposed method performs so well for this task. Moreover, from Figure 1 and Figure 3, it is straightforward to ask how a saliency detection model performs in object detection given that the images have clean background and objects are mostly centered in the image.\n\n8) What does it mean by ""CorLoc (mAP)"" in Table 2? As defined in Equation 4, CorLoc acounts the portion of detection whose IoU greater than 0.5 compared to the ground-truth. But mAP accumulates over a range of IoU threshold and precision across classes.\n\n9) As the proposed method is closely related to the CAM method, how does CAM perform on these datasets? This misses an important comparison in the paper.\n\n\n10) The readability of the paper should be improve. There are many typos, for example --\n1. What does ""..."" mean above and below Equation (2)?\n2. inconsistent notation, like $w_{ki}$ and ${\\bf w}_{ki}$ in Equation (2).\n3. conflicted notation, w used in Equation 2 and Equation 3.', ' \n===================\nSUMMARY\n===================\n\nThe paper proposes a method to extend the output of a network trained for visual object recognition (i.e. image classification) with bounding box coordinates that can serve to localize the recognized object. \nThis process is referred to as ""object localization"", and it resembles to some extent the object detection task.\nObject localization is achieved by analyzing the absolute values of the gradients in the last convolutional layer (referred to as ""attention map"" in the paper) with regard to the pixel locations of the input image.\nThen, a linear model is trained in order to predict the bounding box coordinates that serve to localize the recognized object instance. This is different from traditional object detection methods, which learn how to predict bounding boxes directly from image pixels. The paper claims that by learning how to predict bounding boxes from sensitivity maps the amount of needed training data is reduced.\n\nExperiments on the PASCAL VOC\'07 and a subset of the ImageNet\'12 dataset show the performance of the proposed method.\n\n===================\nREVIEW\n===================\n\nThe content of the paper is clear, has a good flow. Moreover, the proposed method is sound and relatively easy to follow. The reported experiments show good performance of the proposed method. In addition, there seems to be hints that the proposed method has a computation speed that makes it suitable for on-the-fly computations.\n\nMy main concerns with the manuscript are the following:\n\nThe manuscript proposes to analyze the internal spatial activations/gradients of a network trained for object recognition with the goal of exploiting internally encoded cues that can serve for object localization. At the high level, as recognized in the manuscript, this is very similar to the work from Zhou et al.,CVPR\'16 with some differences regarding how the attention maps are defined, and if additional components are added to the network.\nIn addition, the way in which the proposed object localization problem is formulated bears resemblance to work on weakly-supervised object detection where object detectors are trained by using only image-level annotations (no bounding box annotations are used). \nKeeping these two groups of work in mind, I find the contribution of the proposed method limited. \nPerhaps a explicit positioning with respect to this work is required.\n\nSection 2.3 states that there two possibilities, i.e. max or average. to aggregate the sensitivity maps obtained for each of the RGB channels from images. However, in Section 3.2, it is stated that the max operation is used for the Pascal VOC\'07 dataset while the average operation was used for ImageNet data. This inconsistency in the way these maps are aggregated makes it hard to observe if there is a difference or trend across these two operations. Is there a reason why different operations were applied to different datasets? I recommend applying both operations on both datasets and discuss observations from the results.\n\nWhile the proposed method have been evaluated on two datasets, and compared with respect to standard classic baselines, a deeper evaluation analyzing the inner workings of the method is not conducted.\nIn this regard, in addition to evaluating the effect of the method to aggregate sensitivity maps accross color channels (previously mentioned), I suggest reporting results by changing the threshold used in intersection over union (IoU) measure used to verify matching (Section 3,1). In addition, I am curious about the performance of the method in the two following scenarios: i) when multiple instances of the recognized object are present in the image, and ii) when instances of other distractor classes are present in the image.\n\nIn several parts of the manuscript, e.g. Sec. 1, 3.4, and 4, claims regarding the speed of the proposed method are made. However, there is no evaluation focusing on this aspect that could be used to support this claims. In this regard, either a evaluation focusing on the computation speed of the proposed method should be conducted or claims regarding to computation speed should be toned down.\n  \nFinally, the first title of the manuscript, i.e. ""Interpreting Deep Neural Networks"", suggests that the manuscript will cover topics regarding model interpretation of DNNs. However, model interpretation as such is never touched wich makes this title somewhat misleading. In fact the main theme of the manuscript is about object localization/detection, hence the second part of its title: ""Fast Object Localization via Sensitivity Analysis"". \nIf this manuscript is to be accepted, the first part of the title should be removed.\n\nI would appreciate if my main concerns are addressed in the rebuttal.', 'Summary\nThe paper presents a method to perform object localization by computing sensitivity of the network activations with respect to each pixel. The key idea is that the representation for classification implicitly contains object localization information since the object classification is done by detecting features of an object in an image. The localization information is extracted as a form of sensitivity map which indicates each pixel’s contribution to the final classification decision, and is subsequently used for regressing the bounding box. The proposed method outperforms other baseline methods and achieves reasonable performance when compared with slower state-of-the-art deep learning techniques for object localization.\n\nStrengths\n-\tFor object localization, this technique can provide faster results.\n-\tThe paper proposes a simple sensitivity measure which works well in identifying the pixels which are important for object classification, and provides relevant information for localization.\n-\tThe paper suggests a simple linear mapping from sensitivity maps to object bounding box coordinates, which can be learnt from a fairly small ground truth localization data.\n\nWeaknesses\n-\tThe idea of utilizing back-propagated sensitivity map is not novel for weakly-supervised object localization [1,2], as the proposed method just uses a simpler sensitivity function with linear regression.\n-\tThe paper mentions the approach being ‘very fast’, but they do not show any quantitative comparisons in fair and similar settings with other techniques. The reviewer strongly suggests to provide testing time measures.\n-\tIn ImageNet experiment, test data split in the paper is not held out as they use a pre-trained VGG network which is trained on the full ImageNet dataset.\n-\tThe title claims to interpret deep neural networks, but the proposed approach just uses sensitivity map for object localization task, without any analysis for interpretation. Such interpretations have already been extensively studied in [1,2].\n-\tThe idea of utilizing classification network for localizing an object is new, but the ideas of weakly-supervised object localization is already explored in [1,2,3,4,5,6]. The reviewer recommends to cite and provide valid comparison with [3,4,5,6].\n-\tMore detailed experimental results, i.e. accuracy across different categories are required. The reviewer also recommends ablation studies to compare with bounding box heuristics and sensitivity measures as used in [1, 2].\n-\tNo details about reproduction of results are provided in the paper.\n\nPossible Questions\n-\tWhen computing a sensitivity map from a CNN output vector or an attention map, is the sensitivity calculated with respect to each activation in the output vector? How is a single sensitivity map computed from the attention map, which contains a number of activations?\n\nMinor Comments\n-\tIn the description of g’(\\eta_i), g’(\\eta i) should be g’(\\eta_i).\n-\t“…” around equations should be replaced by “: equation,”.\n\nReferences\n[1] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In CVPR, 2016. \n[2] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-CAM: Visual explanations from deep networks via gradient-based localization. See https://arxiv.org/abs/1610.02391 v3, 7(8), 2016. \n[3]  Cho et al., Unsupervised Object Discovery and Localization in the Wild: Part-based Matching with Bottom-up Region Proposals, CVPR 2015\n[4] Yi et al., Soft Proposal Networks for Weakly Supervised Object Localization, ICCV 2017\n[5] Oquab et al., Is object localization for free? – Weakly-supervised learning with convolutional neural networks, CVPR 2015\n[6] Li et al., Weakly Supervised Object Localization with Progressive Domain Adaptation, CVPR 2016\n']","[-70, -20, -20]","[20, 60, 60]","[""The sentiment score is -70 because the review expresses several major concerns and criticisms about the paper, including misleading claims, lack of in-depth analysis, and unconvincing experiments. The reviewer points out multiple issues without many positive comments, indicating a largely negative sentiment. However, it's not at the extreme negative end as the reviewer does acknowledge some aspects of the work and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'However, there are several major concerns' and 'The readability of the paper should be improved' rather than using harsh or rude language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. However, the score is only slightly positive as the review is quite direct and doesn't use many overtly polite phrases or soften the criticisms significantly."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The content of the paper is clear, has a good flow. Moreover, the proposed method is sound and relatively easy to follow.'), they express several significant concerns and limitations about the paper's contribution, methodology, and claims. The reviewer requests multiple revisions and additional analyses, indicating overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms constructively ('I suggest...', 'I recommend...'), and expresses willingness to reconsider ('I would appreciate if my main concerns are addressed in the rebuttal.'). The tone remains professional and courteous even when pointing out flaws or inconsistencies in the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and areas for improvement. The review begins with a neutral summary and lists some strengths, but the weaknesses section is more extensive and critical. The reviewer suggests that the paper's main idea is not novel and lacks proper comparisons and experimental details.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The reviewer strongly suggests' and 'The reviewer recommends' instead of making blunt demands. The critique is presented constructively, with specific suggestions for improvement and additional references. The language is formal and avoids personal attacks or harsh criticism. However, it's not extremely polite as it doesn't include many overtly courteous phrases or compliments beyond acknowledging the paper's strengths.""]"
"['The paper tries to provide an explanation for a memorization phenomenon observed in convolutional autoencoders. In the case of memorization, the autoencoder always outputs the same fixed image for any input image, even when the input image is random noise. The authors provide an empirical analysis that connects such a phenomenon to strides in convolutional layers of the autoencoder. Then, a possible theoretical explanation is given in the form of conjecture with some empirical evidence.\n\nThe paper presents very interesting idea, however presentation and theoretical foundation can be significantly improved.\n\n- Please elaborate on how different initializations influence memorization effect. Currently the paper only mentions initialization approaches for which memorization can or cannot occur without going into deeper analysis.\n- Having linear operator extraction described in the paper somehow breaks the flow, please consider moving it to Appendix.\n- The comment after the Proposition section is not very clear. What does it mean that the Proposition does not imply that A_X must obtain rank which is given in the Conjecture? Please explain how is Proposition providing any theoretical support for Conjecture then.\n\n- Minor comments\n1. “2000 iteration” -> “2000 iterations”\n2. The text says “Network ND trained on frog image” while the following next sentence says that “the network reconstructed the digit 3”. Please clarify.\n3. “Network ND reconstructed the digit 3 with a training loss of 10^-4 and Network ND with loss 10^-2”. It seems that one of these should be “Network D”.\n4. “(with downsamling)” ->  “(with downsampling)”', 'Summary:-\nThe authors investigates downsampling as one method by which autoencoding CNNs may memorize data. The theoretical motivation provided concentrates on linear CNNs. They show that downsampling linear CNNs tent to learn a point-map of the training data, even though (under certain initializations) they are capable of learning identity maps. However, non-downsampling linear CNNs learn identity maps. Given enough data however, the authors claim that the downsampling CNN will learn the identity map.\n\nStrengths:-\n+ Authors present a good exploration of how linear CNNs memorize data when they do downsampling. \n+ A theoretical prediction of the amount of training data needed to counteract data memorization for downsampling linear CNNs is provided, ""Our conjecture also implies that when training a linear downsampling CNN on images of size 3 · 224 · 224, which corresponds to the input image size for VGG and ResNet (He et al. (2016), Simonyan & Zisserman (2015)), the number of linearly independent training examples needs to be at least 3 · 224 · 224 = 153, 228 before the network can learn the identity function."" \n\nWeaknesses:-\n+ Not enough theoretical proof is provided to support the hypothesis. Which would be fine but some key experiments are missing to make the paper empirically rigorous.\n++ Would be good to see experiments that illustrate the predication that a certain amount of data would allow for learning identity maps, both for linear and non-linear CNNs.\n++ In the non-linear CNN setting, I\'d like to see the same early-stopping experiment done for linear CNNs whose results are in Fig. 3. I don\'t see any obvious theoretical reason why that result form Fig. 3 must extend to the non-linear setting. \n+ Initializations are pointed to as effecting the type of function the network learns. The authors give an example of a hand-designed initialization that allows a downsampling linear CNN to learn the identity map but they don\'t explain how they arrived at this initialization, or its properties that make it a good initialization. In general however, I think it\'s alright to assign exploration of effect of initialization to future work, since it seems like a non-trivial task.\n+ It is mentioned that ""the results are not observed for linear networks when using Kaiming initialization,"" which I read to mean the downsampling linear CNNs with Kaiming initialization learn the identity map, not point-map. If this is true, it seems like a vital point and should be included in discussions of future work.\n\nRecommendation:  I think this could be a better short paper. There are some interesting contributions, but maybe not enough for a full length paper. For a full length paper, some further exploration of _why_ downsampling leads to (if indeed there is a causality) data memorization is needed.\n\nMinor stuff:-\nCitation ""Gunasekar et al."" is missing year (conclusions section)', ""The authors conjecture that convolutional downsampling is an underlying mechanism behind sample memorization in over-parameterized convolutional autoencoders. They claim that this effect leads the system to converge to a low-rank solution in contrast to the theoretically possible identity mapping. They support their claim with numerical experiments on linear and non-linear convolution autoencoders.\n\nStrengths:\n- The authors develop their idea in close connection to commonly used architectures.\n\nWeaknesses:\n- The main statements concern the architecture; however, the experiments do not account for the many confounding factors such as initialization or the chosen optimizer. The paper itself states on page 4 that the results depend on the initialization and cite Gunasekar et al. in the conclusion for an analogy, which, however, explores the implicit regularization effect of a gradient descent optimizer.\n- There is no clear and proved statement despite the suggestive mathematical nature of the writing (Conjecture, Proposition). The claimed 'proof' of the Proposition is conducted via experiment. In light of the above mentioned confounding factors, the current phrasing of the Proposition will not allow a formal proof as it is unclear what the system 'linear Network DS' even is.\n- The boundary between conjectured and inferred statements is very vague. For example, the meaning of  'prefers to learn a point map' is unclear.\n\nOverall, the exposition is insufficient in supporting the conjectured effect. The methodology could be strengthened in two directions:\n1) experimentally: designing numerical experiments that exclude confounding factors and surface the conjectured effect\n2) theoretically: abstracting the idea into a clear mathematical statement that can be proved\n\nI encourage the authors to extend their work for submission to a future venue.""]","[50, -20, -50]","[75, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as presenting a 'very interesting idea', which is a positive comment. However, they also mention that the presentation and theoretical foundation 'can be significantly improved', indicating room for improvement. This mix of positive and constructive criticism suggests a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. They use phrases like 'Please elaborate' and 'Please consider', which are polite ways of requesting changes. The reviewer also provides specific, constructive feedback and even points out minor issues, which is helpful and considerate. The overall tone is professional and courteous, maintaining a respectful dialogue with the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they point out several significant weaknesses and suggest it might be better as a short paper rather than a full-length one. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'Would be good to see' and 'I'd like to see' when suggesting additional experiments, which maintains a polite tone while still conveying the need for more work."", ""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses and insufficient support for the authors' claims. However, it's not entirely negative as it acknowledges some strengths and encourages further work. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They encourage the authors to extend their work, which is a polite way of suggesting improvements. The reviewer avoids harsh language, but also doesn't use overtly polite phrases, maintaining a mostly neutral, professional tone.""]"
"['The authors introduce the problem of Model Completion (MC) to the machine learning community.  They provide a thorough review or related works, and convincingly argue that existing solutions to this sort of task (i.e., homomorphic encryption and multi-party computation) are not fully satisfactory in the domain of neural network learning.\n\nThe authors also provide extensive numerical experiments attempting to quantify their proposed measure of hardness-of-model-completion, MC-hardness_T(\\alpha) on a diverse set of Supervised and RL-related tasks, and they provide extensive analysis of those results.\n\nI find the paper to raise more questions than it answers (in a good way!).  The authors note that their measure depends strongly on the peculiarities of the particular (re)training scheme used.  Do the authors worry that such a measure could end up being too loose--essentially always a function of whatever the fastest optimization scheme happens to be for any particular architecture?  \n\nMore broadly, there\'s an additional axis to the optimization problem which is ""How much does the training scheme know about the particulars of the problem?"", ranging from ""Literally has oracle access to the weights of the trained model (i.e., trivial, MC-hardness = 0 always)"" to ""knows what the architecture of the held-out-layer is and has been designed to optimize that particular network (see, e.g., learned optimizers)"" to ""knows a little bit about the problem structure, and uses hyperparameter tuned ADAM"" to ""knows nothing about the problem and picks a random* architecture to use for the held out weights, training it with SGD"".\n\nModel completion seems, morally (or at least from a security stand-point) slightly under-specified without being more careful about what information each player in this game has access to.  As it stands, it\'s an excellent *empirical* measure, and captures a very interesting problem, but I\'d like to know how to make it even more theoretically grounded.\n\nAn excellent contribution, and I\'m excited to see follow-up work.\n\n\n\n* We of course have tremendous inductive bias in how we go about designing architectures for neural networks, but hopefully you understand my point.', 'This paper proposes the interesting idea of analyzing how difficult\nit is to re-initialize and re-train layers in neural networks.\nThey study these techniques in the context of ImageNet classification\nand reinforcement learning in the Atari and DeepMind lab domains.\nWhile these are interesting ideas and domains to study, I have\nconcerns with the positioning and execution of the paper.\n\n[Positioning, execution and motivation]\nOn the positioning of the paper, a significant part of the introduction\nand related work section is spent arguing that this approach can be used\nfor shared model governance in contexts where homomorphic encryption\nor secure multi-party computation would instead be used.\nComparing the approaches studied in this paper to these\nsophisticated cryptographically-motivated techniques seems\nlike too much of a stretch, as the methods serve very different\npurposes and in most cases cannot even be directly compared.\n\nThe first and second paragraph discuss the vision of distributing\nthe training of models between multiple parties.\nI agree that this is a useful area to study and direction\nfor the community to go, but as the introduction of this paper\nstates, this is the most interesting when the parties have\ncontrol over logically separate components of the modeling pipeline\nand also when joint training of the components is being done,\npotentially on disjoint and private datasets.\nThe empirical results of this paper do none of this,\nas they only look at the case when a single layer is being\nreplaced.\n\nFurthermore the motivation and positioning of the paper is\nnot carried through in the empirical setup, where they\ninvestigate approaches that do training over all\nof the parameters of the model, breaking the assumption\nthat the parties should be independent and should\nnot share information.\n\n[Metrics for measuring model completeness]\nSection 3.1 defines the metric of completion hardness that is\nused throughout the rest of the paper. The metric looks at the\nnumber of iterations that re-training the model takes to\nreach the same performance as the original model.\nIt\'s not clear why this is an important metric and I am\nnot convinced it is the right one to use as it:\n1) does not give a notion of how nicely the missing portion\nwas recovered, just that the accuracy reached the\nsame accuracy as the original network, and\n2) methods with a very long per-iteration runtime such as\nsecond-order and sampling-based methods could be used to\nreach a good performance in a small number of iterations,\nmaking these methods appear to be very ""good"" at\ncompleting models. I don\'t think it is nice that this\nmetric relies on the same optimizer being used for the\noriginal model and the completed model.\n\nI think it\'s more interesting to study *how much* data is\nrequired to recover missing portions of the model instead\nof how many iterations are needed to recover the same performance.\nThe supervised learning experiments appear to be done\nusing the entire dataset while the RL experiments do\npresent a setting where the data is not the same.\n\n[Empirical results]\nI am also surprised by the empirical finding in Section 5.1\nthat T1 outperforms T2, since it seems like only optimizing\nthe parameters of the missing layer would be the best\napproach. I think that if a similarity metric was used\ninstead, T2 would be significantly better at finding the\nlayer that is the most similar to the layer that was removed.\n\nSome smaller comments:\n\n1. In Section 3.1, the definition of C_T does not use T explicitly\n   inside of it.\n2. In the last paragraph of Section 3.1 and first paragraph of\n   Section 3.2, N should be defined as an iteration that\n   reaches the best loss.\n3. The description of T3 does not say what method is used to\n   optimize the over-parameterized layer, is it T1 or T2?\n4. Why does T4 use T1 instead of T2?\n5. In the experimental setup, why is T2 applied with a different\n   learning rate schedule than the original training procedure?\n6. Why is T2 not shown in the AlexNet results for Figure 2?\n7. The dissimilar axes between the plots in Figure 2 and\n   Figure 3 make them difficult to compare and interpret.\n8. It\'s surprising that in Figure 3, the hardness of \\alpha=1.0\n   for T2 is 1.0 for everything.', 'This paper proposes and studies the “model completion” problem: given a trained network (and the data on which is was trained), if a subset of the network is reinitialized from scratch, how many retraining iterations are needed to achieve the original network accuracy (or some percentage of it)? For a variety of networks and problems in both supervised and reinforcement learning, model-completion (MC) hardness is quantified for individual network layers/sections. The experiments are the core of the paper and are generally well documented and seem reproducible.\n\nHowever, there are two issues that cloud the paper:\n\t1. The problem motivation (bounding the security of model splitting) is a bit odd. Has model splitting been proposed in the literature as a potential solution to shared model governance? Otherwise it feels like the problem setting was invented to justify the analysis in this paper: “the tail wagging the dog” as the saying goes…\n\t2. Model completion yet still be an interesting analytical tool for deep networks, but this requires a different evaluation. For instance, model completion provides a way to study how complicated different network layers are to learn or maybe to quantify how much of the inference task may be contained in each. (Though these concepts would need precise language and experimental evidence.) But how do these observations compare to other ways of obtaining similar observations? For instance, from the pruning literature, (Molchanov, 2017, ICLR, https://openreview.net/pdf?id=SJGCiw5gl) includes several figures detailing the statistics of individual network layers and how “prunable"" are the filters in each.\n\nThis is largely an analytical paper, and I’ll readily acknowledge that it is difficult to pull a clear and insightful study out of a jumble of experimental observations (and hard to review such a paper too). But the limitations of the problem motivation (point #1) and (in my opinion) the misaligned focus of the analysis (point #2), hurt the clarity and significance of this paper. For it to really be a useful tool in understanding deep learning, some additional work seems to be needed.\n\nOther notes:\n\t3. Pruning literature would be a reasonable comparison in the related work. For instance, (Han, ICLR, 2017, https://arxiv.org/abs/1607.04381) describes a dense-sparse-dense method where a (dense) model is pruned (sparse), after which the pruned connections are reinitialized and retrained (dense) leading to improved accuracy relative to the original dense model.\n\t4. Consider replacing the uncommonly used “ca.” with “~”, e.g. “~1000x” instead of “ca. 1000x”.\n\t5. The specifics about ImageNet in the intro to Section 3 should be moved to Section 4.\n\t6. In Section 3.2 paragraph 2, clarify if “loss” refers to test loss as stated in the intro to Section 3.\n\t7. In Figure 2 (alpha=0.9) and Figure 3 (alpha=1.0, bottom), why are the values constant?\n']","[80, -50, -20]","[90, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses enthusiasm for the paper, calling it an 'excellent contribution' and stating they are 'excited to see follow-up work.' They also praise the thorough review, convincing arguments, and extensive experiments. The reviewer raises questions, but frames this positively as 'raising more questions than it answers (in a good way!)'. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I find,' 'Do the authors worry,' and 'I'd like to know,' which are polite ways of offering critique. They also compliment the work multiple times, showing respect for the authors' efforts."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's 'interesting idea' in the opening, the majority of the review focuses on concerns and criticisms. The reviewer expresses doubts about the positioning, execution, motivation, and metrics used in the paper. However, it's not entirely negative as the reviewer does recognize some value in the research direction.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have concerns' and 'I am surprised' rather than harsh or dismissive language. The reviewer also provides detailed explanations for their concerns and offers constructive suggestions, which is a polite approach to criticism. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral to slightly positive tone in terms of politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'experiments are the core of the paper and are generally well documented and seem reproducible'), they also highlight significant issues that 'cloud the paper'. The reviewer expresses concerns about the problem motivation and the focus of the analysis, suggesting that 'additional work seems to be needed'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They acknowledge the difficulty of the task ('I'll readily acknowledge that it is difficult to pull a clear and insightful study out of a jumble of experimental observations') and offer constructive feedback. The reviewer also uses phrases like 'Consider replacing' and 'clarify if' when making suggestions, which is polite. However, the score is not extremely high as the criticism, while professionally delivered, is still direct and substantial.""]"
"['Authors argue that the main issue with stability in GANs is due to the discriminator becoming too powerful too quickly. To address this issue they propose to make the task progressively more difficult: Instead of providing only the samples to the discriminator, an additional (processed) bitstring is provided. The idea is that the bitstring in combination with the sample determines whether the sample should be considered true or fake. This in turn requires the decision boundary of the discriminator to become more complicated for increasing lengths of the bitstring. In a limited set of experiments the authors show that the proposed approach can improve the FID scores.\n\nPro:\n- A simple idea to make the problem progressively more difficult.\n- The writing is relatively easy to follow.\n- Standardized experimental setup.\n\nCon:\n- Ablation study of the training tricks is missing: (1) How does the proposed approach perform when no progressive scheduling is used? (2) How does it perform without the linear model for increasing p? (3) How does the learning rate of G impact the quality? Does one need all of these tricks? Arguably, if one includes the FID/KID to modify the learning rates in the competing approaches, one could find a good setup which yields improved results. This is my major issue with this approach.\n- Clarity can be improved: several pages of theory can really be summarized into “learning the joint distribution implies that the marginals are also correctly learned’ (similar to ALI/BIGAN). This would leave much more space to perform necessary ablation studies. \n- Comparison to [1] is missing: In that model, it seems that the same effect can be achieved and strongly improves the FID. Namely, they introduce a model in which observed samples pass through a ""lens"" before being revealed to the discriminator thus balancing the generator and discriminator by gradually revealing more detailed features.\n- Can you provide more convincing arguments that the strength of the discriminator is a major factor we should be fixing? In some approaches such as Wasserstein GAN, we should train the discriminator to optimality in each round. Why is the proposed approach more practical then approaches such as [2]?\n\n[1] http://proceedings.mlr.press/v80/sajjadi18a.html\n[2] https://arxiv.org/abs/1706.08500', 'This paper proposes a new trick to improve the stability of GANs. In particular the authors try to tackle the vanishing gradient problem in GANs, when the discriminator becomes to strong and is able to perfectly separate the distribution early in training, resulting in almost zero gradient for the generator. The authors propose to increase the difficulty of the task during training to avoid the discriminator to become too strong.\n\nThe paper is quite well written and clear. However there is several unsupported claims (see below).\n\nA lot of work has been proposed to regularize the discriminator, it\'s not clear how different this approach is to adding noise to the input or adding dropout to the discriminator.\n\nPros:\n- The experimental section is quite thorough and the results seem overall good.\n- The paper is quite clear.\n\nCons:\n- There is a major mistake in the derivation of the proposed method. In eq. (6) & (7), (c) is not an equivalence, minimizing the KL divergence is not the same as minimizing the Jensen-Shannon divergence. The only thing we have is that: KL(p||q) = 0 <=> JSD(p||q) = 0 <=> p=q . The same kind of mistake is made for (d). Note that the KL-divergence can also be approximated with a GAN see [1]. Since the equivalence between (6) and (7) doesn\'t hold, the equation (11) doesn\'t hold either.\n\n- The authors say that the discriminator can detect the class of a sample by using checksum, the checksum is quite easy for a neural networks to learn so I don\'t really see how the method proposed actually increase the difficulty of the task for the discriminator. Especially if the last layer of the discriminator learns to perform a checksum, and the discriminator architecture has residual connections, then it should be straight-forward for the discriminator to solve the new task given it can already solve the previous task. So I\'m not sure the method would still works if we use ResNet architecture for the discriminator.\n\n- I believe the approach is really similar to adding noise to the input. I think the method should be compared to this kind of baseline. Indeed the method seems almost equivalent to resetting some of the weights of the first layer of the discriminator when the discriminator becomes too strong, so I think it should also be compared to other regularization such as dropout noise on the discriminator.\n\n- The authors claim that their method doesn\'t ""just memorize the true data distribution"". It\'s not clear to me why this should be the case and this is neither shown theoretically or empirically. I encourage the author to think about some way to support this claim. \n\n- The authors states that ""adding high-dimensional noise introduces significant variance in the parameter estimation, which slows down training"", can the author give some references to support that statement ?\n\n- According to the author: ""Regularizing the discriminator with the gradient penalty depends on the model distribution, which changes during training and thus results in increased runtime"". While I agree that computing the gradient penalty slightly increase the runtime because we need to compute some second order derivatives, I don\'t see how these increase of runtime is due to change in the model distribution. The authors should clarify what they mean.\n\nOthers:\n- It would be very interesting to study when does the level number increase and what happens when it increase ? Also what is the final number of level at the end of training ?\n\nConclusion:\nThe idea has some major flaws that need to be fixed. I believe the idea has similar effect to adding dropout on the first layer of the discriminator. I don\'t think the paper should be accepted unless those major concerns are resolved.\n\nReferences:\n[1] Nowozin, S., Cseke, B., & Tomioka, R. (2016). f-gan: Training generative neural samplers using variational divergence minimization. NIPS', ""This paper modifies the GAN objective by defining the TRUE and FAKE labels in terms of both the training sample, and a newly introduced random variable s. The intuition is that by progressively changing the definition of s, and its effect on the label, we can prevent the discriminator network from immediately learning to separate the two classes. \n\nThe paper doesn't give any strong theoretical support for this intuition. And it I found it a bit surprising that the discriminator doesn't immediately learn the one extra bit of information introduced by every new level of augmentation. However, the results do seem to show that this augmentation has a beneficial effect on two different architectures in different data scenarios, although the increase is not uniform over all settings.\n\nThe approach presented in this paper is motivated primarily as a method of increasing stability of training but this is not directly investigated. Figure 3 and Table 2 both suggest that the augmentation does nothing to reduce variance between runs. There is also no direct comparison to other methods of weakening the discriminator, although these are mentioned in the related work. I think the paper would be much improved by a thorough investigation of the method's effect on training stability, to go along with the current set of evaluations.""]","[-20, -60, -20]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pro' section), they raise several significant concerns in the 'Con' section. The reviewer points out missing ablation studies, lack of clarity in some parts, absence of comparison to relevant work, and questions the fundamental premise of the approach. These criticisms outweigh the positive points, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use neutral language to express criticisms (e.g., 'Clarity can be improved', 'Comparison... is missing') and provide specific suggestions for improvement. The reviewer also acknowledges positive aspects of the work before presenting criticisms, which is a polite approach in academic reviews."", ""The sentiment score is -60 because the review is overall negative. While the reviewer acknowledges some positives ('The experimental section is quite thorough', 'The paper is quite clear'), they list several major concerns and conclude that 'The idea has some major flaws that need to be fixed' and 'I don't think the paper should be accepted unless those major concerns are resolved.' This indicates a predominantly negative sentiment. The politeness score is 20 because the reviewer uses generally polite language ('I encourage the author', 'It would be very interesting'), acknowledges positives, and provides constructive feedback. However, they also use some direct language when pointing out flaws ('There is a major mistake', 'I don't really see how'), which prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (beneficial effects shown in results), they express several criticisms and doubts. The reviewer points out the lack of strong theoretical support, surprising aspects, and suggests significant improvements needed. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms constructively. They use phrases like 'I found it a bit surprising' and 'I think the paper would be much improved by' rather than harsh or dismissive language. The reviewer also acknowledges the paper's strengths alongside its weaknesses, maintaining a balanced and professional tone throughout.""]"
"[""\nThe authors proposed a new model Adaptive Neural Trees(ANTs) by combining the representation learning and gradient optimization of neural networks with architecture learning of decision trees. The key advantage of the new model ANTs  over the existing methods(Random forest, Linear classifier, Neural decision forest, et al) is: it may achieve high accuracy(above $90\\%$) with relatively much smaller number of parameters, as shown by the experiments on the datasets MNIST and CIFAR-10. Besides, the authors proposed single-path inference based on the greedily-selected leaf node to approximate the multi-path inferences with the full predictive distribution. The experiments show the single-path inference doesn't lose much accuracy but it saves memory and time. This paper is acceptable after minor modification.\n\n\nQuestions:\nIn the second line below equation (1), $n$ in $t_{e_{n(j)}}^{\\psi}$ is not defined. Also, should $t_{e_{1}}^{\\psi}$ be $t_{e_{n(1)}}^{\\psi}$? "", 'The paper is written rather well, however I find the experiments incomplete and have some reservations about the\nmethod. My main points of critique are:\n\n1.  Combining DT & NN \nI have doubts that the way you combine DT &NN  you get the ""Best of both world"". In some ways your architecture also \nshares disadvantages of both:\n\n1.1 Interpretability\nBecause each node in the tree can a neural network (with arbritrary complexity), this approach looses one central advantage of DT, that is the interpretability of the result.    Each node in the tree can perform arbritrary complex (and hierarchical) \ncomputations. The authors only show one particular example (Fig. 2a), where the model has learned is a reasonable \nstructure.\n\n1.2 Complexity:\nThe whole architecture is much more complex than either a neural network or a decision tree. I expect that therefore training these is not easy, and expert knowledge in either DT  or NN may not be enough to use this model.\n\n\n2. Limited experiments\n\n2.1 The authors only consider 2 experiments from vision (MNIST & CIFAR 10) while proposing a universal method.  To show universality the authors should use data sets from different domains (e.g UCI data sets)\n\n2.2 The authors argue that a  strength of the method   is  that it uses a low number of parameters on average for a forward path (compared to the total parameter size).  I don\'t find this argument to be convincing. In the limit this would imply a high memorization of the  data.  Also, a similar case can be made for standard CNN, when a particular filter is mostly inactive for some data points.\n\n2.3 The interpretability of DT compared to NN I mentioned earlier.  To make the argument that their method learns the\nhierarchical structure of the data , the authors should have added experiments to support this, where  such a hierarchical structure is clearly present and can be evaluated empirically.\n\n\n--\n\nIn light of the extended experiments w.r.t. to 2.1 I increased my score from 5 to 6.  Overall, I still have doubts about the interpretability and complexity of the proposed method.  \n\nComplexity:  ""but all the intuitions needed would come solely from training NN"".    I disagree with this response.   The architecture is a mix between a tree (hard, decision-tree like error surface,  non-local) and neural network (smooth, mostly convex error surface). This also implies that the training process and its behavior will possess patterns and challenges of both approaches. \n\nInterpretability:  I think the method misses ""priors"" that enforce credit assignment.  Partitioning the problem in subp-roblems should be done via the tree components, whereas processing (such as image filtering) should be done in the network nodes. However,  the method does not enforce, or encourage this behavior, for instance\nvia constraints:   also nodes can do partitioning (because neural networks can approximate decision trees)  and edges can do processing (e.g. decisions-trees can be used for mnist).\n\nSo I still believe this to be a borderline paper, however, the experiments support a more general applicability.\n', 'The presented method is a generalization of a number of existing methods, which can be regarded as special cases. Overall the method seems to be novel. Meanwhile, I have two major questions:\nTo account for the bias issue, instead of a single DT, ensemble methods such as random forests are the popular choices. How ANT could benefit from relying on a single DT instead of a random forest type?\nThe datasets of MNIST and CIFAR-10 are used for many years and the performance is already saturated. As presented in Table.3, the performance of the proposed method is also not the best on either of the tested datasets. Please clearly elaborate on why and how to address this issue. It would be more interesting and meaningful to work with a more recent large datasets, such as ImageNet or MS COCO. \n\nThe response does not fully address my concerns. ']","[70, -30, -50]","[80, 50, 0]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its advantages and innovative aspects. The reviewer states that the paper is 'acceptable after minor modification,' which indicates a positive overall assessment. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They objectively describe the paper's contributions and provide constructive feedback. The reviewer's tone is courteous, especially when pointing out minor issues in the 'Questions' section. The use of phrases like 'The authors proposed' and 'The experiments show' demonstrates a respectful approach to discussing the work."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The paper is written rather well'), they express significant reservations about the method and experiments. The reviewer lists several critiques and doubts, indicating an overall negative sentiment. However, it's not extremely negative as they increased their score from 5 to 6 after extended experiments. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They present their critiques in a constructive manner, using phrases like 'I have doubts' and 'I don't find this argument to be convincing' rather than more aggressive language. The reviewer also acknowledges improvements ('In light of the extended experiments... I increased my score'), showing a fair and balanced approach."", ""The sentiment score is -50 because the review expresses some concerns and dissatisfaction with the response to previous questions. The reviewer states that their concerns were not fully addressed, indicating a negative sentiment. However, it's not extremely negative as the reviewer acknowledges the method's novelty and generalization of existing methods. The politeness score is 0 (neutral) because the language used is professional and straightforward, without being particularly polite or rude. The reviewer raises questions and points out issues in a matter-of-fact manner without using overly courteous language or harsh criticism.""]"
"['The paper proposes an RNN architecture inspired from deterministic pushdown automata. An RNN is extended to use soft attention at every time step to choose from several learnable centroids.\n\nIn general, the paper is well written and the proposed model is theoretically grounded. Unfortunately, the proposed approach shines only on specifically designed benchmarks. It is not a surprise that a CF can be learned by an architecture very similar to DPDA (with addition of learnable parameters). There is a number of specifically designed tasks to test long-term memorization, such as copy/addition, etc. Furthermore, RNNs are mostly used for natural language processing tasks. This paper only conducts experiments on IMDB sentiment analysis ignoring better benchmarked tasks, such as language modelling.\n\nIt is not absolutely clear why authors claim that cell is playing the role of memory. It is always possible to rewrite LSTM formulas with h\' which is concatenation of hidden state h and cell c. Results on ""peephole connection""-inspired SR-LSTM-p should be benchmarked against an LSTM with peephole connections.\n\nThe claim repeated several times that RNNs operate like DFAs, not DPDAs. This is an important point in the paper and should be verbalized more. Does it mean that it is easier to learn regular languages with RNNs?\n\nWhile intuitive, theorems 3.1-3.2 are very vague to be theorems. Otherwise, they should be proven or provided a sketch of proof. For example, how do you formalize ""state dynamics""?\n\nThe quality of writing of the related work section is worse that the rest of the paper. Authors should explore more other hidden state regularization methods. And, perhaps, give less attention to stochastic RNNs since the final version of the proposed model is not stochastic.\n\nTo summarize, this paper provides an interesting direction but lacks in terms of experimentation and global coherence of what is claimed and what is shown.\n\nMinor points:\n- Citation of Theano is missing\n- Give a sentence explaining what is hidden state ""drifting""\n- a-priori -> a priori', '\nSummary:\n\nThis paper is based on the observation that LSTMs use the hidden state to memorize information and the cell state (memory) is not fully utilized. To encourage the LSTM to utilize the cell state, authors constraint the hidden state to a set of centroid states and learn to transition between these centroids in a soft way. Authors demonstrate their model in learning simple regular and context-free languages and also in a couple of non-synthetic tasks. The proposed model also has some interpretability of internal state transitions.\n\nMajor comments:\n\n1.\tThe main claim of the paper is that SR-LSTM can extrapolate to longer sequences, unlike LSTM. However, the sequence lengths considered are too small. It would be interesting to train both models with specific sequence length and then keep testing them with longer sequence length and compare the performance. If SR-LSTM behaves like a DPDA, then with larger cell state, the performance should not drop as you increase the sequence length till the capacity of the cell state.\n\n2.\tTheorem 3.1 and 3.2 have no proofs. Please make them as notes rather than theorems.\n\n3.\tWhat do different colors in Figure 6 stands for?\n\n4.\tIn the MNIST task authors claim that they have significant improvement when compared to LSTM. I am not sure if that is accurate. Also, why do you compare SR-LSTM-p only with LSTM? What is the performance of LSTM-p? Please report that as well.\n\n5.\tEven in table 3, can you please report the performance of LSTM-p?\n\nEven though the paper does not show strong empirical performance in real-world tasks, I would still recommend for accepting this paper for its contributions in understanding RNNs better, provided authors answer to question 1, 4, and 5.\n\n\nMinor comments:\n\n1.\tFig 6 is not referred anywhere.\n\n', 'This paper proposes a novel architecture and regularization technique for RNN, where the hidden state of an RNN is one of (or a soft weighted average of) a finite number of learnable clusters. This has two claimed benefits: (1) extracting finite state automata from an RNN is much simpler, and (2) forces RNN to operate like an automata and less like finite state machines. The authors make (1) immediately clear, and show (2) with empirical results.\n\nMajor comments:\n\n(1) No experiments on widely used benchmarks for RNNs (e.g. language modeling, arithmetic tasks (for instance see Zaremba and Sutskever, 2015) ). Have you tried this by any chance?\n\n(2) Theorems 3.1 and 3.2 are presented without proof. Will be good to at least include it in the appendix.\n\n(3) IMDB experiments: you claim that SR-LSTM and SR-LSTM-p have ""superior"" extrapolation capabilities than vanilla LSTMs. However, as SR-LSTM and SR-LSTM-p give far lower train error rate, it\'s not strictly fair to claim that they extrapolate better to longer sequences than encountered during training time. \n\nIs the number of parameters held constant across 3 models? I\'m struggling to understand why the training performance of the proposed models is significantly better than pure LSTM. For SR-LSTM-P I can see this being the case (the peephole connections effectively increase the hidden state size), but why does SR-LSTM (whose hidden states should be more constrained than pure LSTMS) perform better than LSTM during training? This makes me wonder whether SR-LSTM and SR-LSTM-P have higher capacity than LSTM somehow.\n\n(4) MNIST experiments : please include results for SR-LSTM\n\nMinor comments:\n\n(1) page 8 : MNIST imagse -> images']","[-30, 50, 50]","[50, 75, 80]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('well written', 'theoretically grounded'), they express significant concerns about the paper's limitations and lack of comprehensive experimentation. The reviewer states the approach only works well on 'specifically designed benchmarks' and lacks testing on 'better benchmarked tasks'. The conclusion that the paper 'lacks in terms of experimentation and global coherence' further reinforces the overall negative sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. Phrases like 'It is not absolutely clear' and 'Authors should explore more' maintain a polite tone while conveying areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses a generally favorable view of the paper, recommending it for acceptance despite some limitations. They acknowledge the paper's contributions to understanding RNNs better. However, they also point out several areas for improvement and request additional information, which prevents a higher positive score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively, and offers specific suggestions for improvement. They use phrases like 'Please make' and 'can you please' when requesting changes, which adds to the politeness. The review maintains a professional and courteous tone without any harsh or rude comments."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novel aspects and potential benefits of the proposed architecture, while also providing constructive criticism and suggestions for improvement. The review is not overwhelmingly positive, but it shows interest in the work and its potential. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the authors' claims and efforts. The use of phrases like 'Will be good to' and 'please include' contribute to the polite tone. The reviewer also offers specific, constructive feedback without using harsh or dismissive language.""]"
"[""This paper presents an extension of Capsule Networks, Siamese Capsule Networks (SCNs), that can be applied to the problem of face verification. Results are reported on the small AT&T dataset and the LFW dataset. \n\nI like the direction that this paper is taking. The original Capsules work has been looking at fairly simple and small scale datasets, and the natural next step for this approach is to start addressing harder datasets, LFW being one of them. Also face verification is a natural problem to look at with Capsules.\n\nHowever, I think this paper currently falls short of what I would expect from an ICLR paper. First, the results are not particularly impressive. Indeed, SCN doesn't outperform AlexNet on LFW (the most interesting dataset in the experiments). Also, I'm personally not particularly compelled by the use of the contrastive loss as the measure of performance, as it is sensitive to the scaling of the particular representation f(x) used to compute distances. Looking at accuracy (as in other face verification papers, such as DeepFace) for instance would have been more appropriate, in my opinion. I'm also worried about how hyper-parameters were selected. There are A LOT of hyper-parameters involved (loss function hyper-parameters, architecture hyper-parameters, optimizer hyper-parameters) and not much is said about how these were chosen. It is mentioned that cross validation was used to select some margin hyper-parameters, but results in Table 1 are also cross-validation results, which makes me wonder whether hyper-parameters were tuned on the performance reported in Table 1 (which of course would be biased).\n\nThe paper is also pretty hard to read. I recognize that there is a lot of complicated literature to cover (e.g. prior work on Capsule Networks has introduced variations on various aspects which are each complicated to describe). But as it currently reads, I can honestly say that I'm not 100% sure what exactly was implemented, i.e. which components of previous Capsule Networks were actually used in the experiments and which weren't. For example, I wasn't able to figure out which routing mechanism was used in this paper. The paper would strongly benefit from more explicitly laying out the exact definition of SCN, perhaps at the expense of enumerating all the other variants of capsules and losses that previous work has used.\n\nFinally, regardless of the clarify of the paper, the novelty in extending Capsule Networks to a siamese architecture is arguably pretty incremental. This wouldn't be too much of a problem if the experimental results were strong, but unfortunately it isn't the case.\n\nIn summary:\n\nPros\n- New extension of Capsule Networks, tackling a more challenging problem than previous work\n\nCons\n- Novelty is incremental\n- Paper lacks clarity and is hard to read\n- Results are underwhelming\n\nFor these reasons, I'm afraid I can't recommend this paper be accepted.\n\nFinally, I've noted the following typos:\n- hinton1985shape => use proper reference\n- within in => within\n- that represent => that represents\n- a Iterated => an Iterated\n- is got => is obtained\n- followed two => followed by two\n- enocded => encoded\n- a a pair => a pair\n- such that to => such as to\n- there 1680 subjects => there are 1680 subjects\n- of varied amount => of the varied amount\n- are used many => are used in many\n- across the paper: lots of in-text references should be in parenthesis\n\n"", 'In this paper, the author extends Capsule Network on the task of face verification to solve the problem of learning from only few examples and speeding the convergence. They propose a Siamese Capsule Network, which extends Capsule Networks to the pairwise learning setting with a feature l2-normalized contrastive loss that maximizes inter-class variance and minimizes intra-class variance. Here is a list of suggestions that will help the authors to improve this paper.\n1.\tThe pairwise learning setting allow learning relationships between whole entity encodings \n2.\tThe ability to learn from little data that can perform few-shot learning where instances from new classes arise during testing\n3.\tWhen a contrastive loss is used that takes face embeddings in the form of encoded capsule pose vectors, speed of converging is lifted.\n4.\tThe description of experiment is too brief to show specific details.\n5.\tThe figure of Siamese Capsule Network Architecture (figure 1) cannot show kernel of author(s)’s method, and lack explanation in the paper.\n', ""Authors present an adaptation of Capsule Networks for pairwise learning tasks. The pose vectors of final capsule layers for each tower is concatenated and passed through a fully connected layer to calculate the embedding for each tower's input. Then a contrastive loss based on a distance metric is optimized for the embeddings. An interesting regularizer (?) is used which is a dropout based on Capsule activation for connecting last layer capsules to the fully connected layer. \n\nPros:\n\nThe literature review is rich and complete. In general authors explain details of the previous techniques as they use them too which is a good writing technique and improves the readability.\n\nBy utilizing Capsules authors avoid a rigorous preprocessing as it is common with the community. As I understand they do not even use face landmarks to align images.\n\nMeasured by the optimized loss, the proposed method achieves significant improvement upon baseline in the small At&t dataset.\n\nCons:\n\nThe contribution of this work is not on par with ICLR standard for conference papers. Specially since SDropCapsNet (the added dropout) is seems to be auxiliary (gives a slight boost only in LFW without double margin).\n\nThe method used for reporting results is unjustified and not compareable to prior work. For face verification, identification one should report at least an ROC curve based on a threshold on the distance or nearest neighbor identification results which are standards in the literature. Where as they only report the contrastive loss of their model and their own implementation of baselines and Figure 3 which does not clearly show any advantage for CapsNet Siamese networks.\n\n\nQuestion:\nThe architecture description for last layer is vague. In text 512 is mentioned as the input dimmension, 512 is 16*32, Figure 1 shows 9 features per capsule or 3x3 kernels over capsules where it has to be fully connected? Also it says last layer is 128 dimmension where the text implies it should be 20. Could you please explain the role of 20?\n\nIs table 1 the final contrastive loss achievable for each model?\n\nHave you tried just gating the pose parameters of last layer by their activation (multiply to the tanh) rather than using a stochastic dropout?""]","[-60, 20, -20]","[50, 60, 60]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's quality, clarity, and results. While they initially mention liking the direction, the majority of the review focuses on shortcomings, including underwhelming results, lack of clarity, and incremental novelty. The reviewer ultimately recommends against acceptance, indicating a negative overall sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, acknowledging positive aspects and providing constructive feedback. They use phrases like 'I like the direction' and 'I think this paper currently falls short' rather than harsh criticism. The reviewer also offers specific suggestions for improvement and notes typos helpfully, demonstrating a polite approach to critique."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the author's work in extending Capsule Networks and proposes improvements, indicating a constructive approach. However, the review is not overwhelmingly positive, as it mainly focuses on suggestions for improvement. The politeness score is moderately high (60) due to the use of neutral language and the framing of criticisms as suggestions ('Here is a list of suggestions that will help the authors to improve this paper'). The reviewer avoids harsh or negative language, maintaining a professional and respectful tone throughout. The review provides specific points for improvement without being overly critical, which contributes to its politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros (rich literature review, avoiding rigorous preprocessing), they also highlight significant cons. The main criticisms are that the contribution is not up to ICLR conference standards and the reporting method is unjustified and not comparable to prior work. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and phrases criticisms constructively. They use phrases like 'Could you please explain' and offer suggestions, which contributes to a polite tone. The reviewer also balances positive and negative feedback, further enhancing the politeness of the review.""]"
"['This paper analyzes the relationship between ""adversarial vulnerability"" with input dimensionality of neural network. The paper proves that, under certain assumptions, as the input dimensionality increases, neural networks exhibit increasingly large gradients thus are more adversarially vulnerable. Experiments were done on neural networks trained by penalizing input gradients and FGSM-adversarial training. Similar trends on vulnerability vs dimensionality are found.\n\nThe paper is clearly written and easy to follow. I appreciate that the authors also clearly stated the limitation of the theoretical analysis.\n\nThe theoretical analyses on vulnerability and dimensionality is novel and provide some insights. But it is unlikely such analysis is significant There are a few reasons:\n- This analysis only seems to work for ""well-behaved"" models. For models with gradient masking, obfuscated gradients or even non-differentiable models, it is not clear that how this will apply. (and I appreciate that the authors also acknowledge this in the paper.) It is unclear how this specific gradient based analysis can help the understanding of the adversarial perturbation phenomena. After all, the first order Taylor expansion argument on top of randomly initialized weights is oversimplifying the complicated problem.\n- One very important special case of the point above: the analysis probably cannot cover the  adversarially PGD trained models [MMS+17] and the certifiably robust ones. Such models may have small gradients inside the box constraint, but can have large gradients between different classes.\n\n\nOn the empirical results, the authors made a few interesting observations, for example the close correspondence between ""Adv Train"" and ""Grad Regu"" models. \nMy concern is that the experiments were done on a narrow range of models, which only have ""weak"" adversarial training / defenses.\nAdversarial robustness is hard to achieve. What matters the most is ""why the strongest model is still not robust?"" not ""why some weak models are not robust?"" \nIt is especially worrisome to me that the paper does not cover the adversarially-augmented training based iterative attacks, e.g. PGD TRAINED models [MMS+17] which is the SOTA on MNIST/CIFAR10 L_\\infty robustness benchmark.\nWithout comprehensive analyses on SOTA robust models, it is hard to justify the validity of the theoretical analysis in this paper, and the conclusions made by the paper.\nFor example, re: the last sentence in the conclusion: ""They hence suggest to tackle adversarial vulnerability by designing new architectures (or new architectural building blocks) rather than by new regularization techniques."" The reasoning is not obvious to me given the current evidence shown in the paper.\n\n[MMS+17] Madry A, Makelov A, Schmidt L, Tsipras D, Vladu A. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083', 'The authors provide a compelling theoretical explanation for a large class of adversarial examples.  While this explanation (rooted in the norm of gradients of neural networks being the culprit for the existence of adversarial examples) is not new, they unify several old perspectives, and convincingly argue for genuinely new scaling relationships (i.e. \\sqrt(d) versus linear in d scaling of sensitivity to adversarial perturbations versus input size). They prove a number of theorems relating these scaling relationships to a broad swathe of relevant model architectures, and provide thorough empirical evidence of their work.\n\nI can honestly find very little to complain about in this work--the prose is clear, and the proofs are correct as far as I can tell (though I found Figure 4 in the appendix (left panel) to not be hugely compelling.  More data here would be great!)\n\nAs much of the analysis hinges on the particularities of the weight distribution at initialization, could the authors comment on possible defenses to adversarial attack by altering this weight distribution? (By, for example, imposing that the average value must grow like 1/d)?', 'This paper argues that adversarial vulnerability of neural networks increases with input dimension. Theoretical and empirical evidence are given which connect the l_p norm of the gradient of the training objective with the existence of small-worst case l_q perturbations. This connection is made by assuming that the learned function is well approximated by a linear function local to the sampled input x. By making assumptions on the initialization scheme for some simple architectures, the authors show that the l_p norm of the gradient for randomly initialized network will be large, and provide empirical evidence that these assumptions hold after training. These assumptions imply bounds on the typical magnitude of the gradient of the loss with respect to a single input coordinate, this then implies that the overall gradient norm will depend on the input dimension.\n\nI found this paper well written. The mathematical assumptions are presented in a clear, easy to understand manner. Also high level intuition is given around their main theorems which help the reader understand the main ideas. However, I have a  number of concerns about this work.\n\nThe first is, I do not buy the motivation for studying the ""phenomenon"" of small worst-case l_p perturbations. I realize this statement applies to a large body of literature, but since the publication of  [1] we are still lacking concrete motivating scenarios for the l_p action space. I would encourage the authors instead to ask the closely related but more general question of how we can improve model generalization outside the natural distribution of images, such as generalization in the presence of commonly occurring image corruptions [2]. It\'s possible that the analysis in this work could better our understanding model generalization in the presence of different image corruptions, indeed by making similar linearity assumptions as considered in this work, test error in additive Gaussian noise can be linked with distance to the decision boundary [3,4]. However, this particular question was not explored in this work.\n\nSecond, the work is one of many to relate the norm of the gradient with adversarial robustness (for example, this has been proposed as a defense mechanism in [5,6]). I also suspect that the main theorem relating gradient norm to initialization should easily follow for more general settings using the mean field theory developed by [7,8] (this would be particularly useful for removing assumption H1, which assumes the ReLU activation is a random variable independent of the weights). Overall, I don\'t see how gradient norms explain why statistical classifiers make mistakes, particularly for more realistic attacker action spaces [9]. Even for ""small"" l_p adversarial examples there seem to be limitations as to how much gradient norms can explain the phenomenon --- for example even max margin classifiers such as SVM\'s have ""adversarial examples"". Furthermore, adversarial training has been shown to reach a point where the model is ""robust"" locally to training points but this robustness does not generalize to the points in the test set [10]. In fact, for the synthetic data distributions considered in [10], it\'s proven that no learning algorithm can achieve robustness given insufficient training data.\n\nFinally, the main conclusion of this work ""adversarial vulnerability of neural networks increases with input dimension"" is an overly general statement which needs a much more nuanced view. While experiments shown in [11] support this conclusion for naturally trained networks, it is shown that when adversarial training is applied the model is more robust when the input dimension is higher (see Figure 4 a. and b.). Perhaps the assumptions for Theorem 4 are violated for these adversarially trained models. \n\n1. https://arxiv.org/abs/1807.06732\n2. https://arxiv.org/abs/1807.01697\n3. https://arxiv.org/abs/1608.08967\n4. https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57.\n5. https://arxiv.org/abs/1704.08847\n6. https://arxiv.org/abs/1608.07690\n7. https://arxiv.org/abs/1611.01232\n8. https://arxiv.org/abs/1806.05393\n9. https://arxiv.org/abs/1712.09665\n10. https://arxiv.org/abs/1804.11285\n11. https://arxiv.org/pdf/1809.02104.pdf', 'The paper studies how the vulnerability of a neural network model depends on its input dimension. The authors prove that for an *untrained* model, randomly initialized with Xavier initialization, the gradient of the loss wrt the input is essentially independent of the architecture and task. This implies that the major factor affecting the norm of that gradient is the input dimension. They then support their argument by experiments measuring the relation between adversarial vulnerability and gradient norm using various *trained* models (including adversarially regularized ones).\n\nI find the main theoretical result interesting. While this is a known fact for the simple case of linear classifiers, extending it to arbitrarily deep networks is a valuable contribution. The proof crucially relies on properties of the specific initialization scheme to show that the gradient does not change too much during backproparagation through the layers. The most significant limitation of the result (which the authors kindly acknowledge) is that this result only holds at initialization. Hence it cannot distinguish between different training methods or between how different architectures evolve during training. Since the situation in adversarial robustness is much more nuanced, I am skeptical about the significance of such statements.\n\nOn the experimental side, the finding that gradient regularization improves adversarial robustness to small epsilon values has been made multiple times in the past (as the authors cite in the related work section). It is worth noting that the epsilon considered is 0.005 in L_inf (1.275/255) which is pretty small. This value corresponds to the ""small-epsilon regime"" where the behavior of the model is fairly linear around the original inputs and thus defenses such as FGSM-training and gradient regularization are effective.\n\nThe authors also perform an interesting experiment where they train models on downsampled ImageNet datasets and find that indeed larger input dimension leads to more vulnerable models.\n\nWhile I find the results interesting, I do not see clear implications. The fact that the vulnerability of a classifier depends on the L1 norm of the input gradient is already known for any locally linear classifier (i.e. deep models too), and it is fairly clear that the L1 norm will have a dimension dependence. The fact that it does not depend on architecture or task at initialization is interesting but of limited significance in my opinion. Given that the experimental results are also not particularly novel, I recommend rejection.\n\n[UPDATE]: Given the overall discussion and paper updates, I consider the current version of the paper (marginally) crossing the ICLR bar. I update my score from a 5 to a 6.\n\nMinor comments to the authors:\n-- I think || x ||_* is more clear than |||x||| for the dual norm.\n-- Consider using lambda for the regularization, epsilon is confusing since it is overloaded.']","[-30, 90, -30, -20]","[60, 80, 60, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('clearly written', 'novel', 'provide some insights'), they express significant concerns about the paper's limitations and applicability. The reviewer questions the significance of the analysis and its relevance to state-of-the-art models, which outweighs the positive comments. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging the authors' efforts and clearly stating their appreciation for certain aspects of the paper. They phrase their criticisms constructively, using phrases like 'My concern is...' and 'It is unclear...' rather than making blunt negative statements. However, the score is not higher as the review maintains a professional tone rather than being overtly polite."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the work, using phrases like 'compelling theoretical explanation', 'convincingly argue', and 'I can honestly find very little to complain about'. The only minor criticism is about Figure 4 in the appendix, but this is presented as a suggestion rather than a significant flaw. The politeness score is 80 because the language is consistently respectful and constructive. The reviewer uses polite phrases like 'could the authors comment on' when making suggestions, and the overall tone is professional and courteous. The reviewer also acknowledges the strengths of the work before offering any suggestions for improvement, which is a polite approach to peer review."", ""The sentiment score is -30 because while the reviewer initially praises the paper as 'well written' with clear mathematical assumptions and high-level intuition, they then express several significant concerns about the work. These concerns include questioning the motivation, suggesting the work may not be novel, and critiquing the main conclusion as overly general. This mix of positive and negative comments, with the negatives outweighing the positives, results in a slightly negative overall sentiment. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and phrases concerns as suggestions (e.g., 'I would encourage the authors...'). The reviewer also uses hedging language like 'I suspect' and 'Perhaps', which softens the critique. However, some direct statements of disagreement (e.g., 'I do not buy the motivation') prevent the score from being higher."", ""For the sentiment score, I assigned -20 because while the reviewer finds some aspects of the paper interesting, they ultimately recommend rejection. The review starts positively but becomes more critical, especially regarding the significance and novelty of the findings. However, it's not entirely negative as they do acknowledge some valuable contributions. For the politeness score, I assigned 60 because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and provides constructive feedback. They use phrases like 'I find the main theoretical result interesting' and 'The authors kindly acknowledge', which indicate politeness. Even when criticizing, they do so in a professional manner. The minor comments at the end are also presented constructively.""]"
"['I have to say that this paper is not well organized. It describes the advantage function and CMA-ES, but it does not describe PPO and PPO-CMA very well. I goes through the paper twice, but I couldn\'t really get how the policy variance is adapted. Though the title of section 4 is ""PPO-CMA"", only the first paragraph is devoted to describe it and the others parts are brief introduction to CMA.\n\nThe problem of variance adaptation is not only for PPO. E.g., (Sehnke et al., Neural Networks 2009) is motivated to address this issue. They end up using directly updating the policy parameter by an algorithm like evolution strategy. In this line, algorithm of (Miyamae et al. NIPS 2010)  is similar to CMA-ES. The authors might want to compare PPO-CMA with these algorithms as baselines.', 'This is in my view a strong contribution to the field of policy gradient methods for RL in the context of continuous control. The method the authors proposed is dedicated to solving the premature convergence issue in PPO through the learning of variance control policy. The authors employ CMA-ES which is usually employed for adaptive Gaussian exploration. The method is simple and yet provides good results on a several benchmarks when compared to PPO.\n\nOne key insight developed in the paper consists in employing the advantage function as a means of filtering out samples that are associated with poorer rewards. Namely, negative advantage values imply that the corresponding samples are filtered out. Although with standard PPO such a filtering of samples leads to a premature shrinkage of the variance of the policy, CMA-ES increases the variance to enable exploration.\n\nA key technical point is concerned with the learning of the policy variance which is cleverly done, BEFORE updating the policy mean, by exploiting a window of historical rewards over H iterations. This enables an elegant and computationally cheap means of changing the variance for a specific state.\n\nSeveral experiments confirm that this method may be effective on different task when compared to PPO. Before concluding the authors carefully relate their work to prior research and delineate some limitations.\n\nStrengths:\n   o) The paper is well written.\n   o) The method introduced in the paper to learn how to explore is elegant, simple and seems robust.\n   o) The paper combines educational analysis through a trivial example with more realistic examples which helps the reader understand the phenomenon helping the learning as well as its practical impact.\n\nWeaknesses:\n   o) The experiments focus a lot on MuJuCo-1M. Although this task is compelling and difficult, more variety in experiments could help single out other applications where PPO-CMA helps find better control policies.\n\n', 'This paper proposes an improvement of the PPO algorithm inspired by some components of the CMA-ES black-box optimization method. The authors evaluate the proposed method on a few Mujoco domains and compare it with PPO method using simpler exploration strategies. The results show that PPO-CMA less likely to getting stuck in local optima especially in Humanoid and Swimmer environments. \n\nMajor comments:\n\nThe reason that CMAES discards the worst batch of the solutions is that it cannot utilize the quality of the solutions, i.e., it treats every solution equally. But PPO/TRPO can surely be aware of the value of the advantage, and thus can learn to move away from the bad area. The motivation of remove the bad samples is thus not sound, as the model cannot be aware of the areas of the bad samples and can try to repetitively explore the bad area. \n\nPlease be aware that CMAES can get stuck in local optima as well. There is no general convergence guarantee of CMAES.\n\n\n\nDetailed comments:\n\n- In page 4, it is claimed that ""actions with a negative $A^\\pi$ may cause instability, especially when one considers training for several epochs at each iteration using the same data"" and demonstrate this with Figure 2. This is not rigorous. If you just reduce all the negative advantage value to zero and calculate its gradient, the method is similar to just use half of step-size in policy gradient. I speculate that if you halve the step-size in ""Policy Gradient"" setting, the results will be similar to the ""Policy Gradient(only positive advantages)"" setting. Furthermore, different from importance sampling technique, pruning all the negative advantage will lose much **useful** information to improve policy. So I think this is maybe not a perfect way to avoid instability although it works in experiments.\n\n\n- There have been a variety of techniques proposed to improve exploration based on derivative-free optimization method. But in my opinion, the way you combine with CMA-ES to improve exploration ability is not so reasonable. Except for the advantage function is change when policy is updated (which has mentioned in ""D LIMITATIONS""), I consider that you do not make good use of the exploration feature in CMA-ES. The main reason that CMA-ES can explore better come from the randomness of parameter generation (line 2 in Algorithm 2). So it can generate more diverse policy than derivative-based approach. However, in PPO-CMA, you just replace it with the sampling of policy actions, which is not significant benefit to exploration. It more suitable to say that you ""design a novel way to optimize Gaussian policy with separate network for it mean and variance inspired by the CMA-ES method rather than ""provides a new link between RL and ES approaches to policy optimization"" (in page 10).\n\n- In experiments, there are still something not so clear:\n\n1. In Figure 5, I notice that the PPO algorithm you implemented improved and then drop down quickly in Humanoid-v2 and InvertedDoublePendulum-v2, which like due to too large step-size. Have you tried to reduce it? Or there are some other reasons leading to this phenomenon.\n\n2. What\'s the purpose of larger budget? You choose a bigger iteration budget than origin PPO implementation.\n\n3. What the experiments have observed may not due to the clipping of negative reward, but could due to the scaling down of the reward. Please try reward normalization.']","[-60, 80, -20]","[20, 70, 50]","[""The sentiment score is -60 because the review starts with a negative statement ('this paper is not well organized') and continues to point out several shortcomings of the paper, such as inadequate descriptions of PPO and PPO-CMA, and difficulty understanding the policy variance adaptation. The reviewer also suggests additional comparisons, indicating that the current work is incomplete. However, it's not entirely negative, as the reviewer acknowledges making an effort to understand the paper, which prevents the score from being lower.\n\nThe politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language. Phrases like 'I have to say' and 'The authors might want to' soften the critique. The reviewer also admits to reading the paper twice, showing a level of engagement and effort. However, the overall tone is still quite critical, which prevents the politeness score from being higher."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as a 'strong contribution' and highlights several strengths, including that the method is 'elegant, simple and seems robust'. The overall tone is very positive, with only minor weaknesses mentioned. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They provide constructive feedback and use phrases like 'in my view' to soften their statements. The reviewer also balances praise with a suggestion for improvement, which is presented politely as a way to potentially enhance the work rather than as a criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The results show that PPO-CMA less likely to getting stuck in local optima'), they raise several major concerns and criticisms about the methodology and conclusions. The reviewer questions the motivation behind certain choices, points out potential flaws in the reasoning, and suggests that some claims are not rigorous.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Please be aware' and 'I consider that' which soften their criticisms. The reviewer also offers constructive feedback and suggestions for improvement, rather than just pointing out flaws. However, the review is not overly effusive or deferential, maintaining a balanced and objective tone.""]"
"['This paper focuses on the extraction of high-quality model-agnostic saliency maps. The authors argue that when an extracted saliency map is directly dependent on a model, then it might not be useful for a different classifier and thus not general enough. To overcome this problem, they consider all the possible classifiers weighted by their posterior probabilities. This problem cannot be solved explicitly, and the authors suggest a scheme to approximate the solution using two networks. That is, pretrain an initial classifier and then, following an adversarial training procedure, one network is trying to confuse the classifier and the other one to maximize its accuracy. Using this formulation, the authors report state-of-the-art results for salience map extraction.\n\nSUMMARY/OVERALL COMMENTS\nThe authors present a simple and effective way to produce classifier-agnostic saliency maps. The argument for the approach is well justified and the results seem convincing on a first read. However, the novelty of the method is a concern given the previous work of Fan et al. (2017), and the manuscript is not upfront about the differences between the two works. The experiments are another cause for concern: Fan et al. should have been tested as a baseline with similar implementation (controlling for architecture and \\lambda), and implementation differences in prior works of Table 1 make it difficult to draw conclusions. \n\n\nRELATED WORKS\n* In the introduction, the authors mention related works but fail to mention the work of Fan et al. (2017) which is clearly the most relevant. The first mention of Fan et al is on page 4 in a very specific discussion the regularization coefficient. The problem formulation in Section 2 and the approach is Section 3 is largely borrowed from Fan et al but not acknowledged until the last page. This introduces bias and confusion to the reader in regards to the novelty of the approach. Please, mention the work of Fan et al. (2017) in the introduction and clearly delineate the differences in the works earlier in the text. (--)\n\n* Du et al. (2018), “Towards Explanation of DNN-based Prediction with Guided Feature Inversion”, use the VGG models for saliency map extraction and achieve a LE of 38.2. Note that Du et al. (2018), suggest that this modification could lead to SOTA results. I would like to see a comparison with this method. (-)\n\n* The work of Kindermans, et al. (2017), “Learning how to explain neural networks: PatternNet and Pattern Attribution”, although they do not aim for weakly supervised localization and thus, they do not present the LE, they produce saliency maps. I would like to see a LE comparison with that method. (minor -)\n\n* In the introduction, p1 (last paragraph) other methods are briefly mentioned (Extracted saliency maps show all the evidence….superpixels), etc.) without references. Please add references when needed. (-)\n\n* The framework presented in this paper was first proposed by Fan et al. (2017). The authors claim four main differences in their approach. In my eyes, not all of them are major or novel - probably the most impactful is removing superpixels as it simplifies the problem and implementation. (+)\n\n\nAPPROACH\n* The authors aim for simplicity (strong +)\n\n* The authors justify their approach and present their arguments clearly (strong ++)\n\n* In the algorithm section, the authors first mention the sampling procedure and then their motivation. Please alter the ordering of these to be conceptually easier to understand your approach\n\n* In the first sentence after the equation 6 I guess that “(cf. Alg. 1)” is a typo and should be modified to (Alg. 1)”\n\n* After Equation 6 it is argued that the method resembles the training procedure of GANs (Godfellow et al., 2014) but not the work of Fan et al., 2017. (--)\n\n\nEXPERIMENTS\n* The authors define as their baseline the F thinning strategy (i.e. use only the first classifier) which is a model dependent salience map. While this is a useful comparison against the classifier dependent methods, given the similarity to the work of Fan et al. (2017), experiments comparing the proposed model to Fan et al. are necessary. It is important to control for network architecture (ResNet-50) and choice of \\lambda to properly determine if the four changes outlined in Section 6 result in any real improvement over Fan et al. (strong --)\n\n* The authors use the Table 1 (borrowed from Fong and Vedaldi (2017)) to compare their results against other methods. This comparison is problematic as different approaches are using different models as classifiers which may lead to increase or decrease of the LE. (--)\n\n* In Table 2 the authors do not report how many times they run the same experiments to get these values. They also run less experiments with non-shared weights and they report only the LE. In my eyes it looks that the authors are trying to force their argument that the sharing weights helps (probably because it is one of their novelties). Please report the statistics of your experiments and fill the empty entries in the table. (--)\n\n* In Table 3, what does the last row represent?\n\n* Table 1 errors: (1) You write “Localization evaluation using OM, LE and F1 scores”. Please remove the F1 score as you do not report it. Also, correct the first sentence of the “Localization” subsection which states that you use three different metrics to “two different metrics”. (2) The LE from Fong and Vedaldi (2017) should be 43.2 and not 43.1.\n\n* Regarding the unseen classes (section 5): (1) Please report in the appendix the classes that you are using in each subset. Are there classes correlated? (-)  (2) I see that there is a strong correlation between the LE on subset A and E. It looks like you are training on E and you generalize on A.\n\n\nNOVELTY/IMPACT\n* Novelty is a strong concern, given the work of Fan et al. (2017) (strong --). Nevertheless, the authors propose some changes that can be seen as more general, but the effectiveness of the changes is clearly established.\n\n* This paper’s strongest point is the simplicity (conceptually and implementation-wise) of the method, an advantage over previous works (+)\n\n\nOTHER COMMENTS\n* Fan et al. (2017), use an adaptive λ that pushes the mask to 10% of the image whereas you are using a fixed one that pushes the mask to approximately 50% of the image. How can you make sure that this is not the reason that you are getting better results?\n\nIf the authors can clearly and fairly demonstrate that the changes they propose over Fan et al (2017) result in improved performance, and the manuscript is adjusted to be more upfront about this prior work, I would consider increasing my rating.\n', 'This paper introduces a new saliency map extractor that seems to improve state-of-the-art results. Saliency maps are tools that can be useful to understand the decision-making of deep networks for object recognition; advances in this research topic may lead to a better understanding of the functioning of deep networks.\n\nThe paper is based on the approach of Fan et al. (2017). The improvements over Fan et al. seem to be mainly technical: the objective function and the optimization procedure. This makes the novelty of the paper quite thin, as the main underlying idea of the paper was previously introduced. \n\nThe algorithm is introduced without motivating well the different choices. What are the intuitions and evidence that guided the design of the algorithm? How are the technical choices made? Answers to these questions may help to understand how this paper builds on Fan et al. and other previous works.\n\nThe experiments compare a comprehensive set of algorithms and show an improvement over previous works. Yet, the OM metric is only compared for a few of these algorithms and it is unclear why is so. Also, the qualitative examples do not clarify how the proposed method improves over state-of-the-art (it would be useful to compare with qualitative examples of previous work). It remains unclear how much of an improvement over state-of-the-art there is.\n\nIn summary, I think the paper could be valuable as the proposed algorithm may improve state-of-the-art results. Yet, these results and the novelty of the paper are not entirely clear.', 'This paper proposes a classifier-agnostic method for saliency map extraction. In order to address the dependence of saliency map extraction on the classifier, the authors propose to learn a saliency mapping by considering all possible classifiers (i.e., a certain classifier structure w.r.t. the space of all its parameters). The goal is to find the relevant features in the data that work with all possible classifiers. The proposed framework is formulated as a min-max game between two players: a mask m corresponding to the saliency mapping, and a function f sampled from a set of classifiers with the same structure but different parameters. The mapping m is optimized to maximize the masked-out classification error (such that m captures all relevant features whose removal can maximally confuse the classifier), while f is optimized to minimize the mask-out classification error.\n\nThe idea of how to formulate the classifier set and how to sample from the set is interesting. However, I have some concerns regarding the overall model:\n\n1) It seems not quite convincing to me why the model should involve an adversarial game. In particular, why f should be optimized to minimize the masked-out classification error? I understand that by doing this, f has an opposite goal with m so as to force m to capture as many relevant features as possible. However, I do not think f has a natural motivation to minimize the maxed-out error. In my opinion, it seems more convincing if f is optimized to minimize the masked-in classification error, but not necessarily the masked-out one. I think this also explains why the model works better by adding the classification loss over original images in Eq. (8). Would it be more natural if we optimize both f and m to minimize the masked-in classification error? And it would easier to train compared with the min-max model. Maybe some more explanation on the motivation of such an adversarial game can be helpful.\n\n2) I was curious whether the alternating optimization of m and f would cause the cumulation of errors? I mean, if in some iteration m just captures irrelevant features, f will still be optimized to accomodate to such a bad mapping. Would such kind of error accumulate during training?\n\n3) In Algorithm 1, after \\theta_m is learned, how is m is determined?']","[-60, -20, -20]","[20, 50, 60]","[""The sentiment score is -60 because the review expresses significant concerns about the paper's novelty and experimental methodology. The reviewer points out multiple issues, including lack of proper acknowledgment of prior work, problematic comparisons in experiments, and insufficient justification for claimed improvements. However, some positive aspects like simplicity and clear argumentation are noted, preventing an extremely negative score. The politeness score is 20 because while the reviewer maintains a professional tone throughout, using phrases like 'Please' and acknowledging positive aspects, there are also direct criticisms and strong negative comments indicated by multiple uses of '(-)' and '(--)'. The language is generally constructive but firm in pointing out flaws, striking a balance between politeness and critical feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges potential value in the paper ('may improve state-of-the-art results'), they express several concerns about the novelty, clarity, and significance of the improvements. Phrases like 'novelty of the paper quite thin', 'introduced without motivating well', and 'remains unclear how much of an improvement' indicate a generally critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges potential merits, and frames criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'seems to improve', 'may help to understand', and 'I think the paper could be valuable' demonstrate a considerate tone while still conveying concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper ('The idea of how to formulate the classifier set and how to sample from the set is interesting'), they express several concerns and questions about the model. The reviewer uses phrases like 'It seems not quite convincing to me' and 'I was curious whether', indicating skepticism about certain aspects of the work. However, the tone is not overwhelmingly negative, as the reviewer offers constructive feedback and suggestions for improvement.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use polite language such as 'I understand that' and 'Maybe some more explanation... can be helpful', showing consideration for the authors' perspective. The reviewer also frames their concerns as questions or suggestions rather than harsh criticisms, which contributes to the overall politeness of the review.""]"
"['This paper explores the idea of utilizing a secret random permutation in the Fourier phase domain to defense against adversarial examples. The idea is drawn from cryptography, where the random permutation is treated as a secret key that the adversarial does not have access to. This setting has practical limitations, but is plausible in theory.\n\nWhile the defense technique is certainly novel and inspired, its use case seems limited to simple datasets such as MNIST. The permuted phase component does not admit weight sharing and invariances exploited by convolutional networks, which results in severely hindered clean accuracy -- only 96% on MNIST and 45% on CIFAR-10 for a single model. While the security of a model against adversarial attacks is important, a defense should not sacrifice clean accuracy to such an extent. For this weakness, I recommend rejection but encourage the authors to continue exploring in this direction for a more suitable scheme that does not compromise clean accuracy.\n\nPros:\n- Novel defense technique against very challenging white-box attacks.\n- Sound threat model drawn from traditional security.\n- Clearly written.\n\nCons:\n- Poor clean accuracy makes the technique very impractical.\n- Insufficient baselines. While the permutation is kept as a secret, it is plausible that the adversary may attempt to learn the transformation when given enough input-output pairs. Also, the adversary may attack an ensemble of PPD models for different random permutations (i.e. expectation over random permutations). The authors should introduce an appropriate threat model and evaluate this defense against plausible attacks under that threat model.', 'This paper proposes Permutation Phase Defense (PPD), a novel image hiding method to resist adversarial attacks. PPD relies on safekeeping of the key, specifically the seed used for permuting the image pixels. The paper demonstrated the method on MNIST and CIFAR10, and evaluates it against a number of adversarial attacks. The method appears to be robust across attacks and distortion levels.\n\nThe idea is clearly presented and evaluated. \n\n*Details to Improve*\nIt would be interesting to see how performance degrades if the opponent trains with an ensemble of random keys.\n\nIt would be great to see this extended to convolutional networks.\n', 'The Paper is written rather well and addresses relevant research questions.\nIn summary the authors propose a  simple and intuitive method to improve the defense on adversarial attacks by combining random permutations and using a 2d DFT. The experiments with regards to robustness to adversarial attacks I find convincing, however the overall performance is not very good (such as the accuracy on Cifar10). \n\nMy main points of critique are:\n\n1. The test accuracy on Cifar10 seems to be quite low,  due to the permutation of the inputs. This \nmakes me question  how favorable the trade-off between robustness vs performance is. \n\n2. The authors state ""We believe that better results on clean images automatically translate to better results on adversarial examples""\n\nI am not sure if this is true.   One counter argument is  that better results on clean images can be obtained by memorizing more structure of the data (see [1]). But if more memorizing (as opposed to generalization) happens, the classifier is more easily fooled (the decision boundary is more complicated and exploitable).\n\n\n\n[1] Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2016). Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530.']","[-50, 70, 20]","[60, 60, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('novel defense technique', 'sound threat model', 'clearly written'), they ultimately recommend rejection due to significant limitations, particularly poor clean accuracy. The overall tone is more negative than positive, but not entirely negative. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and encourages further research despite the rejection recommendation. They provide constructive feedback and explain their reasoning clearly, which is polite and helpful to the authors."", ""The sentiment score is 70 (positive) because the reviewer states that the paper's idea is 'clearly presented and evaluated' and describes the method as 'robust across attacks and distortion levels'. These are strong positive statements about the paper's quality and contributions. The score is not higher because the review also includes suggestions for improvement, indicating that there's room for enhancement. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, offering constructive feedback without harsh criticism. The suggestions for improvement are framed as interesting possibilities ('It would be interesting to see...', 'It would be great to see...') rather than demands, which contributes to the polite tone. The score is not higher because the language, while polite, doesn't include overtly courteous phrases or compliments beyond the factual positive statements."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying the paper is 'written rather well and addresses relevant research questions.' They also find the experiments 'convincing.' However, they express concerns about the overall performance and have 'main points of critique,' which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'I find' and 'I am not sure,' showing consideration for the authors' perspective. They also frame their criticisms as questions or observations rather than harsh judgments. The reviewer maintains a professional tone, balancing praise with constructive criticism, which contributes to the polite impression.""]"
"[""This paper proposed a retrieval model based on the residual network and evaluated the use of ELMo word embedding with/without IDF weight. The results showed that there are significant gain when adding the residual network on top of the word embedding. \n\nPros:\n* This work set a strong baseline for the retrieving target paragraph for question answering on the SQuAD dataset.\n* The experiments were sounds and leverage interesting points -- the use of word embedding itself as the feature representation didn't have as much impact to retrieval performance as the distance function.\n* The studied problem -- retrieval for answering question rather than getting the most relevant document worth more attention.\n\nCons:\n* The motivation of using the word embedding and contextual word embedding over the TF-IDF feature wasn't clear. Results on using simple feature like TF-IDF maybe useful to give readers better judgement of the use of word embedding.\n* The choice of dataset, SQuAD over more retrieval based QA like TrivialQA also wasn't strongly motivated. Also, it would be nice to see how the QA result would be improve with better retrieval model. \n* Another use of TF-IDF/IDF and embedding is to use TF-IDF/IDF to identify the related document and then use word embedding to resolve semantic ambiguity. Do you have theoretical/empirical reason why this shouldn’t be considered?\n\nComment on writing:\n    - In Section 3.1: the dimension of the tensor should reflect the meaning (vocab size, embedding size or the number of documents) rather than numbers.\n    - In Section 3.1: since the weighting for each document is not shared, it would be clearer to just use M and W for each document instead of M’, W'\n    - In Section 3.1: Evaluation metrics, e.g., recall@k, ROC, AUC; technical details, for example, tensor dimension, optimizer hyperparameters should be moved to the experiment section"", 'This paper tries to study retrieval methods for multi-paragraph / multi-document reading comprehension.  The basic approach is to embed the question and the paragraph and train a system to put the correct paragraph close to the question.  I had a very hard time following the details of the proposed approach for this, however, and I still don\'t really understand what the authors are proposing.\n\nThis paper is not ready for publication.  The exposition is not at all clear and needs substantial rewriting.  Additionally, the evaluation done in the paper is not well-justified.  I do not know what ""paragraph-side"" means, but I assume that means you are trying to retrieve the question given the paragraph.  Why?  There were no standard baselines compared against, like a simple IR system (Lucene).  And I expected to see actual impact of the retrieved results on downstream QA performance of a system like Chen et al.\'s, or Clark and Gardner 2018.  Even if you have a slightly better ranking of the retrieved paragraphs, it\'s not clear to me that this will improve performance, if the downstream method is properly calibrated to handle multiple paragraphs (see Clark and Gardner 2018).\n\nA few writing suggestions for the authors, for next time:\n\nThis paper does not follow the typical flow of an academic paper.  It reads too much like a logbook of what you did, presented chronologically, instead of presenting the ideas in a coherent sequence.  Part of this is just simple wording fixes (e.g., avoid things like ""it was time to compute ELMo representations"" - this isn\'t a logbook).  Also, all of the shape comments and numerical details at the top of page 4 are out of place.  Describe your method first in general terms, then give experimental details (like corpus size, etc.) later.  I suggest reading the award-winning papers at various conferences to get a sense of how these papers are typically structured and phrased.\n\nSection 2: A full page dedicated to the history of word embeddings is entirely unnecessary for this paper.  This is not a survey on word embeddings.  It\'s much more useful to the reader to give pointers to multiple connection points between your work and the rest of the literature.  You could have given a paragraph to the most relevant embedding techniques, a paragraph to the most relevant retrieval / multi-paragraph techniques (e.g., Clark and Gardner 2018, which is very relevant, along with Chen et al., TriviaQA, others), and a paragraph to distance metric learning.                                                                                                                                            \n       ', 'Summary: \nThis paper proposes to reformulate the QA task in SQUAD as a retrieval task, i.e., using question as query and paragraphs as candidate results to be ranked.  Authors makes some modifications to elmo model to create better word embedding for the ranking task. Authors have mentioned and are aware of open domain QA methodologies (e.g., DrQA).\n\nPros:\n- The general idea is interesting, to reformulate any QA task as a ranking task\n\nCons:\n- The methodology and task are not clear. Authors have reformulated QA in SQUAD as as ranking and never compared the results of the proposed model with other QA systems. If authors want to solve a pure ranking problem why they do not compare their methods with other ranking methods/datasets.\n- The novelty: The novelty is not significant. Although modifications to ELMO are interesting. \n- Results: Why authors have not compared their work with DrQA? ']","[50, -70, -20]","[80, -20, 50]","[""The sentiment score is 50 (slightly positive) because the review begins by acknowledging the paper's contributions and lists several pros, indicating a generally positive view. However, it also includes a list of cons and suggestions for improvement, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively as suggestions or questions, and acknowledges the strengths of the paper before discussing areas for improvement. The use of phrases like 'it would be nice to see' and framing criticisms as questions (e.g., 'Do you have theoretical/empirical reason...?') contribute to the polite tone."", ""The sentiment score is -70 because the reviewer expresses significant criticism, stating the paper is 'not ready for publication' and needs 'substantial rewriting'. They also mention having 'a very hard time following the details' and that the evaluation is 'not well-justified'. The politeness score is -20 because while the reviewer provides constructive feedback and suggestions, the tone is quite direct and critical. Phrases like 'This paper is not ready for publication' and 'I had a very hard time following the details' come across as somewhat blunt. However, the reviewer does offer specific suggestions for improvement, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer notes the idea is 'interesting', they list more cons than pros and point out significant issues with methodology, novelty, and lack of comparisons. The politeness score is moderately positive (50) as the reviewer uses neutral language, acknowledges some positives, and frames criticisms as questions or suggestions rather than harsh statements. They avoid overtly rude language while still clearly communicating the paper's shortcomings.""]"
"['This work introduces a framework for learning implicit models that is robust to mode collapse. It consists in learning an explicit model of the implicit model through maximum likelihood while the later is used to teach the explicit model to better match the data distribution. The resulting bi-level optimization is carried out with truncated unrolled stochastic gradient descent.\n\n# Quality\n\nThe method combines an interesting set of ideas. It is validated on some reasonable experiments. \n\nHowever after reading the paper, I remain with too many unanswered questions:\n- Why should the method avoid mode collapse? Experiments clearly show that it indeed is resilient to mode collapse, but I have would have been curious in seeing some more discussion regarding this point. What is the exact mechanism that solves the issue?\n- What is the effect of K? Is mode collapse solved only because of the unrolled gradients?\n- What is the effect of M? How does the method behave for M=1, as usually done in GANs?\n- What if the explicit model has not enough capacity?\n- The original Unrolled GAN paper presents better results for the ring problem. Why are results worse in the experiments?\n\nMore fundamentally what is the main benefit of this approach with respect to models that can be trained straight with maximum likelihood? (e.g., flow-based neural generative models; and as required for the explicit model) Is it only to produce generative models that are fast (because they are implicit)? Why not training only the explicit model directly on the data?\n\n# Clarity\n\nThe paper is in general well-written, although some elements could be removed to actually help with the presentation.\n- The development around influence functions could be removed, as the method ends up instead making use of truncated unrolled gradients.\n- The theoretical analysis is straightforward and could be compressed in a single paragraph to motivate the method.\n\n# Originality\n\nThe method makes use of several ideas that have been floating around and proposed in different papers. As far as I know, the combination proposed in this work is original.\n\n# Significance\n\nResults show clear resistance to mode collapse, which is an improvement for implicit models. However, other types of generative models generally do not suffer from this issue. Significance is therefore limited.\n', 'This paper presents an learning by teaching (LBT) framework to train implicit generative models. Instead of using discriminator as in GANs, LBT adopts an explicit likelihood estimator as the student, which is formulated as a bilevel optimization problem: \n1) maximize the log-likelihood of the generated samples; \n2) maximize the log-likelihood evaluated on the training data. \nThe authors argue that LBT avoids the mode collapse problem intrinsically as the missing modes will be penalized by the second objective. I have some concerns on this.  Why teaching an explicit likelihood can help learn an implicit one? \n\nSuppose the explicit likelihood estimator is a single Gaussian, but the real distribution has multiple modes, fitting such the generated data and the training data on this likelihood will not help to avoid missing modes. \n\nFrom the empirical results, it is clear that LBT-GAN is better than LBT. From the objective in (8), it seems the true reason is  the P_E and D together representing a mixture model, which may fit the training data better. \n\nIn Figure 2.(b), the Intra-mode KL divergence of LBT-GAN seems to be unstable during the training, is this caused by the joint training of discriminator with the estimator. Can you discuss this?\n\nIn Table 1, the authors just copied the results of VEEGAN. Indeed, in our implementation, DCGAN and VEEGAN can be much better than the reported one. The authors have not tried the effort to tune the results of baselines. \n\nRecently, the Least square GAN has been purposed to address the mode collapse as well. I suggested the authors should empirically compare with it as well.\n\nGenerally, the paper is well-written. The idea is interesting, however, the motivation, analysis and empirical results are not convincing enough to fully support their claim. \n\n', 'The authors present a novel architecture of  an implicit unsupervised learning architectures using\na teacher student approach.  In particular the main advantage to me seems to be the mode-collapse property,  an important drawback in standard\nGAN approaches.\n\nThe paper is written very well and is easy to follow. The methodology is presented in a clear way and the experiments make sense given the research question.  I particular like that the authors define clear metrics to evaluate success, which is often the weak point in unsupervised learning problems. \n\nI believe the work is interesting, but the results still preliminary and  possibly limited by  scalability.  As the authors put it \n\n""The main bottleneck of LBT is how to efficiently solve the bi-level optimization problem. On one\nhand, each update of LBT could be slower than that of the existing methods because the computational\ncost of the unrolling technique grows linearly with respect to the unrolling steps.""\n\nOn the other hand, I appreciate the honesty in discussing possible scalability constraints.\n\nI was a bit surprised that the method the authors propose seems to work well in the  ""Intra-mode KL divergence"".  My expectation was  that the main advantage of your method is capturing the global, holistic shape of the distribution\nof the data, whereas classical methods would, because of mode collapse, only capture specific  sub-spaces.  Therefore, i would expect these classical methods to perform better in intra-mode KL divergence,  which is a metric to measure local\n, not global, approximation quality.\n\nTypos: \n-  In practise (Introduction) -> in practice\n- 3.1 accent -> ascend\n- Conclusion: on one hand / other hand is used for two opposite ways of thinking']","[20, -30, 60]","[60, 20, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the originality and potential of the work, noting that it 'combines an interesting set of ideas' and shows 'clear resistance to mode collapse.' However, the reviewer also raises several unanswered questions and concerns, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'I would have been curious' and 'Results show clear resistance to mode collapse, which is an improvement.' The reviewer also provides constructive feedback and suggestions for improvement without using harsh or dismissive language."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is well-written and the idea is interesting, they express several concerns and criticisms about the methodology, analysis, and empirical results. The reviewer states that the motivation and results are 'not convincing enough to fully support their claim,' which indicates a generally negative sentiment. However, it's not extremely negative as they do recognize some positive aspects.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have some concerns' and 'I suggested' rather than making harsh or rude statements. The reviewer also acknowledges positive aspects of the paper, such as it being well-written. However, the score is not higher because the review is quite direct in its criticisms without much softening language."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the work, praises the clear writing and methodology, and appreciates the authors' honesty. However, they also mention that the results are preliminary and there are potential scalability issues, which prevents a higher score. The politeness score is 80 (very polite) due to the reviewer's constructive tone, use of phrases like 'I appreciate' and 'I particularly like,' and the way they frame their concerns as observations rather than criticisms. The reviewer also provides helpful feedback on typos, which is done in a neutral, matter-of-fact manner.""]"
"['The paper proposes an alternative to commonly used ReLU activated networks. The ""gating"" and ""amount"" effects of the weights are decoupled. The authors claim that such architectures are easier to theoretically understand. That might be the case indeed, but I fail to see much value in obtaining such understanding of very contrived objects that are not being used in practice. Unless such architectures can be proven to be interesting from a practical standpoint I do not think there is much of a point in studying them. The argument provided by the authors that they can - in a simple situation - have as much expressive power as a standard ReLU activated architecture is insucfficient, in my opinion, to justify researching them. Also, if a strong, deep theorem was proven using GaLU networks was proven, I would be inclined to recommend the paper to be accepted. As is - I do not find the paper to be a contribution significant enough for ICLR.', 'The authors propose a modified ReLU, the GaLU, where the nonlinearity gating role is decoupled from the linear weights. Similar ideas have been previously proposed. For example Tsai et al: http://papers.nips.cc/paper/6516-tensor-switching-networks: ""The TS network decouples a hidden unit’s decision to activate (as encoded by the activation weights) from the analysis performed on the input when the unit is active (as encoded by the analysis weights)"" and Veness et al: Online learning with gated linear networks, https://arxiv.org/abs/1712.01897. \n\nIn short, the paper proposes a tweak to the nonlinearity in neural nets. Since many tweaks have been previously investigated, for such a paper to be worthy of publication, in 2018, the experimental results need to be extremely impressive. The results in this paper, on MNIST and fashion-MNIST are nowhere near sufficient.\n', ""The paper introduces a GaLU activation function, which is the product of a random gate function and a learnable linear function. The authors argue that empirically, neural networks with the GaLU activation is as effective as that with the ReLU activation, but theoretically, the GaLU activation is easier to understand because of the separation of the non-linearity and the learnable parameters. The the paper analyzes neural networks with one GaLU layer. Essentially, the network is a random transformation followed by a linear projection. This property enables analysis that are well known for the linear models.\n\nAlthough the definition of GaLU is new, the idea of combining a non-linear projection with a linear transformation is an old one. [1] shows that many kernel SVM models can be written in this form. [2] [3] show that neural networks with various of activation functions can be relaxed to this form. However, these methods have never achieved performance that is as good as the state-of-the-art CNN models in challenging datasets (ImageNet or even CIFAR-10).\n\nIn section 3, the accuracies on MNIST (98%) and MNIST-fashion (88%) are quite low. They are not even as good as a classical kernel SVM, though the non-linear projection version of the kernel SVM has been well-studied in theory.\n\nIn section 4, the analyses are mostly standard for linear models and convex optimization. To the best of our knowledge, it doesn't introduce new insight on the understanding of non-convex optimization.\n\nOverall, I think the paper and its theoretical analysis is built on an unsolid claim that the GaLU activation is a good replacement for traditional non-linear activation functions. The empirical study doesn't seem to support this claim. I cannot recommend accepting the paper.\n\n[1] Random Features for Large-Scale Kernel Machines \n[2] Learning Kernel-Based Halfspaces with the Zero-One Loss\n[3] Convexified Convolutional Neural Networks""]","[-60, -60, -70]","[20, 0, 20]","[""The sentiment score is -60 because the reviewer expresses significant skepticism about the value and practical relevance of the paper's contribution. They state that they 'fail to see much value' in the work and don't find it to be a 'significant enough' contribution for ICLR. However, it's not entirely negative as they acknowledge some potential theoretical interest. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and relatively respectful manner. They use phrases like 'I fail to see' and 'in my opinion' rather than making blunt dismissals. The language is direct but not rude, maintaining a neutral to slightly polite tone throughout."", ""The sentiment score is -60 because the reviewer expresses significant skepticism about the novelty and impact of the proposed method. They point out that similar ideas have been proposed before and state that the experimental results are 'nowhere near sufficient' for publication. This indicates a clearly negative sentiment, though not extremely harsh. The politeness score is 0 (neutral) because the language is direct and matter-of-fact without being overtly polite or rude. The reviewer states their criticisms plainly but professionally, without using inflammatory language or personal attacks."", ""The sentiment score is -70 because the reviewer expresses significant doubts about the paper's claims and contributions, ultimately recommending against acceptance. The reviewer points out several weaknesses, including low accuracy results and lack of new insights. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout, using phrases like 'I think' and 'To the best of our knowledge' to soften their criticisms. They also acknowledge the paper's efforts and provide specific reasons for their assessment, which contributes to a respectful tone despite the negative evaluation.""]"
"[""The authors propose a multi-objective neural architecture search based on an evolutionary algorithm. The contradicting objective functions are optimized by ranking the candidates by Pareto-dominance, replace the bottom 50% with new candidates generated by the top 50% candidates through random mutations. The multi-objective function considers classification accuracy and an approximation of the inference speed. The method is compared to MobileNet and Mobile NASNet on ImageNet indicating an improvement with respect to search time.\n\nThe authors admit that their work is incremental and a combination of existing work. Furthermore, they admit that Dong et al. (2018) is the closest related work, however, they do not compare to them in the experimental section. The method by Dong et al. requires only 8 GPU days (Dvolver requires 50) yielding very similar results. Why this has been ignored remains unclear.\n\nThe paper is not self-contained, important methodological aspects of the method are insufficiently described. I recommend at least to formally define the crowding distance. It would be also reasonable to define your objective functions already in Section 3 instead of mentioning them in the caption of Figure 3 and its axis labels.\n\nI think it's fair to call your approach evolutionary but you might want to discuss its relationship to beam search and in this scope discuss [A].\n\nThe comparison in Table 2 is not fair. You use the swift activation function and do not report the corresponding numbers for MobileNet or Mobile NASNet. Ramachandran et al. (2017) report these (75% and 74.2% for NASNet and MobileNet).\nComparing the Dvolver architecture with ReLU activations to MobileNet does not indicate any improvements.\n\nYou mention that most previous approaches are only keeping track of the best solution while you evolve over a population. Maybe this sentence is not well written and something else is meant but now this statement is wrong.\n\n[A] Thomas Elsken, Jan Hendrik Metzen, Frank Hutter: Simple And Efficient Architecture Search for Convolutional Neural Networks. CoRR abs/1711.04528 (2017)"", 'The paper is easy to read. The authors did a job in describing the problem, concepts, and the proposed multi-objective optimization method. The computational results are on par with NASNet-A mobile. \n\nIt is good to know that we can use standard multi-objective method for neural architecture search. The implementation seems to be straightforward. The paper mainly uses existing ideas, but with some incremental improvements. It lacks novelty.  \n\nThe time reduction of this method on ImageNet comes from transfer learning by training on CIFAR-10 first. As the paper admits this is not going to generalizing well. How good the method is if just using a single dateset? For CIFAR-10, is this method comparable with ENAS(https://arxiv.org/pdf/1802.03268.pdf)?\n\n', 'The paper proposes a multi-objective search algorithm that designs resource-efficient convolutional architectures. The key idea is to maintain a population of networks and to iteratively approach the Pareto front through evolution. The normal & reduction cells are searched on CIFAR-10 and then transferred to ImageNet. The resulting architectures empirically lead to better trade-offs than other baselines.\n\nPros:\nThe paper is well-written and easy to comprehend.\nResults are competitive against strong baselines such as NASNet.\nResource budgets are handled in a principled manner with multi-objective optimization. \n\nCons:\n\nMy main concerns are on the technical novelty and experimental comparison.\n\nTechnical novelty:\n\nThe proposed algorithm seems highly similar to the existing multi-objective NAS algorithms, especially the ones based on Pareto optimality [1,2,3]. In Sect 2, the authors state that the main difference from prior works such as [2] and [3] is the usage of a different and larger search space and large-scale experiments. However, both aspects are of limited technical novelty.\n\nExperimental comparison:\n\nIn sect 3.3, the authors say “we noticed that the original NASNet search space can greatly benefit from extra connections from any given block”. If the proposed algorithm was investigated in an enhanced version of the NASNet space, it would be unclear whether we should attribute the reported performance to the proposed multi-objective evolution or this additional search space engineering. It would be better to report the results using the original space as well for fair comparison. \n\nThe main claimed contribution is a multi-objective evolutionary algorithm. To demonstrate its effectiveness, it would be necessary to compare against existent multi-objective NAS strategies in the literature. Most of those strategies (e.g., scalarization, weighted product method) should be straightforward to implement on top of the current search space. The current results are less convincing since the authors only compared their method against single-objective baselines (e.g. NASNet, PNAS, AmoebaNet) which are completely unaware of additional dimensions of the desired objectives. \n\nThe networks are searched on CIFAR-10 and then transferred to ImageNet. Unlike most prior works (including the ones focusing on resource-constrained NAS), the authors did not the final performance of their architecture on CIFAR-10. It would be informative to report the CIFAR-10 results as well.\n\nOther suggestions & questions:\nThe authors did not report their training setup for ImageNet. It would be good to include those details to ensure the readers are informed should there are any additional augmentations.\n\n“uniform mutation and a crossover probability of 0.1” (sect 4.1)\nIt would be better to included more details on these evolution forces for reproducibility. These are also important component of the proposed algorithm.\n\n“We manually select 3 architectures that we will be fully train on ImageNet in Section 4.2” (sect 4.1)\nI believe this part needs more clarifications since there can be a large number of architectures on the Pareto front. What’s the criteria for manual selection?\n\n[1] Elsken, Thomas, Jan Hendrik Metzen, and Frank Hutter. ""Multi-objective architecture search for cnns."" arXiv preprint arXiv:1804.09081 (2018).\n[2] Kim Ye-Hoon, Reddy Bhargava, Yun Sojung, and Seo Chanwon. NEMO: Neuro-Evolution with Multiobjective Optimization of Deep Neural Network for Speed and Accuracy. ICML’17 AutoML Workshop, 2017.\n[3] Dong, Jin-Dong, et al. ""DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures."" arXiv preprint arXiv:1806.08198 (2018).']","[-50, -20, -20]","[20, 50, 60]","[""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings of the paper. The reviewer notes that the authors admit their work is incremental, questions why they didn't compare to closely related work, and points out issues with the methodology description and fairness of comparisons. However, it's not entirely negative as it acknowledges some positive aspects like improvements in search time. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I recommend' and 'I think it's fair' which soften the criticism. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('easy to read', 'did a job in describing', 'computational results are on par'), they also point out significant limitations ('lacks novelty', 'mainly uses existing ideas', questions about generalizability). The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, acknowledging positives before presenting criticisms, and phrasing concerns as questions rather than direct criticisms. The reviewer maintains a professional and respectful tone, even when pointing out limitations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros ('well-written', 'competitive results'), they express significant concerns about the technical novelty and experimental comparison. The reviewer lists more cons than pros and suggests several improvements, indicating overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They phrase criticisms constructively (e.g., 'It would be better to...', 'It would be good to include...') and acknowledge positive aspects before presenting concerns. The reviewer also offers specific suggestions for improvement, which is a polite and helpful approach in academic review.""]"
"['This paper proposes a way to speed up initial training a model.  The key idea\nis to:\n\n1. Train an autoencoder on the full dataset and select a subset of training \nexamples.  The subset is the union of examples that maximally activate each of\nthe dimensions of the autoencoder\'s low-dimensional embedding.\n\n2. Then a target classifier is trained on the subset,\n\n3. followed by final fine-tuning on the full dataset.\n\nThe paper is understandably written, although some crucial experimental details\nneed a bit of guesswork.\n\nTheir proposal is evaluated on only one dataset, CIFAR10, using an autoencoder  \nand classifier of roughly similar design from the initial convolutional layers. \n\nThey mention a baseline [classifier training, I presume] classifier training \nover ~200 epochs in 736 s (~12 min) to get 83% accuracy.  This skips steps 1. \nand 2.  Since this is already fast, CIFAR10 is perhaps too small a dataset\nto spur readers to use their proposed method (which does require them to\nadditionally train an autoencoder) when tackling more ambitious problems.\n\nThey do not report the time taken to train their autoencoder for 800 epochs\n(step 1.).  For larger networks and images, it might also be important to\ninvestigate whether an autoencoder considerably simpler than the classifier\nmodel can suffice for subset selection; for example, if I want to train a\nResnet-152 classifier can I use a poorer quality autoencoder?  Since\nusing a randomly selected subset 20% of the original size works about\nas well as step 1 for CIFAR10, I cannot judge whether the time taken to\nset up and train an autoencoder makes it worthwhile to further reduce\nthe training subset from 20% to ~8% of the original size.\n\nThey do not consider alternative subset selection (1.) methods.  For example,\none might use a pretrained network to select examplar images by a clustering\nmethod (ex. [2]), possibly providing representative images per class.  Other \nselection criteria are also possible -- for example, [1] evaluates subset \nselection based on ""representativeness"" vs ""diversity"" criteria.\n\nThey do not compare with many existing approaches to training set compression.\nInstead, they dismiss (Sec. 3 ""Related Work"") most previous work on selecting a \nsmall subset of training examples.  However, googling will quickly find many\npapers on subset selection (exactly what they do) as well as related dataset\noptimization techniques (such loss-based revisiting of training examplars, or\ntraining example weighting etc.).  For example, review-type article [3] \nprovides a good introduction to existing subset selection techniques, as well\nas references to earlier papers.\n\nIt is unclear whether the autoencoder training time is included in their\nexperiments that fix the total training time to 7 minutes and compare results\nwith different numbers of fast epochs (step 2.).\n\nNo guidelines are given for how to select the dimensionality of the autoencoder\nembedding, and how the selection procedure should be done in cases with large\nnumbers of classes, although they mention the possibility of using combinations\nof activations for subset selection.  I do not understand how in problems with\nlarger numbers of classes I can guarantee that the training subset will contain\nat least one representative from each class.  Some alternative subset selection\nmethods can provide such guarantees, which might be important for training\ndatasets with class imbalance.\n\nGiven that they do not use a very large dataset, where their technique would\nreally be needed, and that they provide no comparison with other possibly\nfaster and better ways to select a subset of training examples, I cannot argue\nfor acceptance of this paper.\n\n\n[1] ""Learning From Less Data: Diversified Subset Selection and\nActive Learning in Image Classification Tasks"", Kaushal et al.\nhttps://arxiv.org/abs/1805.11191\n\n[2] Li, D., & Simske, S. (2011). Training set compression by incremental\nclustering. Journal of pattern recognition research, 1, 56-64.\n\n[3] Borovicka, T., Jirina Jr, M., Kordik, P., & Jirina, M. (2012). Selecting\nrepresentative data sets. In Advances in data mining knowledge discovery and\napplications. InTech.\n', 'This paper presents the idea of splitting the training process into two phases: fast training on a subset of the original dataset and finetining on the full dataset. To find a good subset of the training dataset it is proposed to train an autoencoder and use its embeddings to choose examples that have large values of the embedding features. The experiments show that on CIFAR-10 dataset this may speed up the convergence.\n\nIn general, I like the idea of being smart about which data and in which order to feed to the learner.\n\nNonetheless, I disagree with several premises of this paper. The paper claims that by making the dataset smaller one can speed up the training by the means of fitting the dataset into the accelerator memory and thus avoiding slow memory copies from CPU to accelerator memory. However, modern deep learning data pipelines are built in a way that has virtually zero overhead, since the data is loaded from disk and preprocessed on CPU and then copied on the accelerator asynchronously (i.e. the GPU doesn’t have to wait for the data, it can process the current batch and at the same time load the next one). Moreover, moving the data to GPU will introduce additional overheads in the case of random data augmentation, since this additional work would have to be done by GPU (while current deep learning frameworks asynchronously do this work on CPU). And finally, the authors claim that most modern datasets can fit to the accelerator memory if reduced 10x, but in my experience the network and it’s activations (which are stored during training) occupies most of the GPU memory even on high end accelerators, not leaving enough space to store a large dataset even after data reduction.\nThe paper cites Dunner  et al. (2017) as related work that focus on the similar problem: how to find a subset of the dataset to fit it into the GPU memory. However, I would argue that their setup is very different because they are using linear models (such as SVM): their learning steps are very fast compared to CNNs (which makes the memory bandwidth much slower in comparison), they don’t have to store activations of the layers (which allows them to fit much more training samples into GPU memory), and they don’t use data augmentation.\n\nAlso, I don’t think that the experimental comparison provides a strong enough evidence supporting the benefits of the proposed scheme. First, the experiments are only done on a small scale dataset (CIFAR-10), which is OK in general, but questionable when the proposed method explicitly targets big data regime and making the training faster. Second, the only baseline considered is choosing subset of data randomly. Third, the optimization method is plain SGD with momentum, while when presenting techniques for faster convergence it would make sense to compare on at least several standard optimization algorithms (e.g. Adam). Finally, the presented results are weak: in Fig 4 any improvements over random baseline are noticeable only after degrading the performance of the network by a large margin (to less than 67% accuracy on CIFAR-10);\nFig 5 looks like it has an error: training on the full dataset performs on the level of random guess after some training, which contradicts the fact that the same network converged to something reasonable in Fig. 6. Also, I believe that the training on the full dataset is strictly better than training on a random subset of data for a few epochs and then finetuning on the full dataset (with the same time budget). The latter sees the same number of updates but with less data, which should only decrease the test performance. If it’s correct, the results in Fig 5 for the full training should look similar (or better) than the results in Fig 4 for the random subset baseline, but it’s very far from being the case.\nIn Fig 6 I’m not sure what is being compared. Is a train or test loss? If it’s train, then it’s not a fair comparisons, since the two network are optimizing different train losses. I’m also very surprised not to see the moment of training mode transition on the plot (i.e. the moment when the model switched from restricted dataset to the full one), the lack of it can indicate an implementation error.\n\nAnd finally, I would like to see the text being improved. Right now the language is confusing, for example: “this technique is shown to be effective” (what does it mean “effective” and compared to what?), “Unfortunately, while these techniques may be viable for smaller networks or datasets, large datasets have shown that they do not scale well.” (who have shown that the techniques doesn’t work on large dataset?), “the testing network is initialized using a weighted average of the final weights learned during training” (what does it mean?), “Qualitatively, the trained autoencoder succeeded in learning an adequate embedding.” (what does it mean?), etc.\nAlso, there is a typo in formulas 1, 2, and 3: it probably should sum up to n-1.\nAnd I didn’t get what formula 4 means, what is “union of (for all i in n)”?\nThis bit I also didn’t get: “This simple loss function, in essence, forces the network to learn to extract the key features from the input, so that it can reproduce it using said features only. If desired, one could elect to use a more sophisticated loss, such as the Wasserstein distance metric (Gulrajani et al., 2017; Arjovsky et al., 2017), that takes more into account than raw pixel values.”. How can you substitute L2 loss in an autoencoder with Wasserstein metric (which is a metric between probability distributions, not images)?\nThere is also some missing related work, e.g. the idea mentioned in conclusion on augmenting the dataset in the latent space is presented in DeVries et al. “Dataset augmentation in feature space”.\n\nIt would be interesting to connect this work with importance sampling off-policy RL (see e.g. “Prioritized Experience Replay”) and look into sampling dataset points proportional to some importance probability with importance sampling correction.\n\nOn the positive side, I really enjoyed the look of the figures and diagrams.\n', 'Summary: \nThe manuscript introduces a dataset filtering technique for the purpose of speeding up training of machine learning models.\nThe technique filters the training set, yielding a subset of examples that are as diverse as possible, according to an autoencoder embedding of the input space. First, one trains a deep autoencoder, whose code layer is used as embedding of the input space. Then, for each element of the embedding the top k training samples are selected which activate that element. This reduced training set is then used for rapid training of the model in the first optimization stage, followed by slower fine-tuning on the complete data set. The experimental section presents a comparison of accuracies after training a simple CNN on CIFAR10 with and without the proposed data filtering under several constraints.\n\nStrengths: The proposed technique addresses the important problem of long training times. The description is very clear and detailed.\n\nWeakness:\nMy main criticism of this manuscript is that the experimentation is not nearly sufficient to support the central claim that dataset filtering via embeddings, as described in this manuscript, is a “general technique” that “any tasks [...] could in principle benefit from [...]”.\nThe evidence from the presented experiment is rather weak, as only one architecture and one dataset is selected. Furthermore, there are quite a few confounding factors that I don’t think are compensated by averaging the performances of four training runs. A few recommendations on how to improve the experimental section:\n- How are hyperparameters selected? For a fair comparison, separate hyperparameter searches should be performed for training with the full training set and with the filtered set. Simple hyperparameters can influence the performance strongly for a given dataset.\n- It requires extensive experimentation to “show the technique’s merits as a generally applicable technique that is not bound to certain types of architectures”, for instance trying different types of architectures and datasets. Of course the technique can be applied to most architectures and datasets. However, the question is whether it often helps, not whether it is technically possible. Does it for example improve convergence speed or performance in a state-of-the-art network trained on ImageNet? \n- The heavy use of data augmentation is a confounding factor which adds randomness that is not likely to be compensated by averaging a few training runs. Maybe you could present performances without augmentation.\n- You mention momentum is used. For reproducibility, it would be good to state the coefficient used.\n- Testing is performed on checkpoints with some form of weighted averaging of final weights. Could you describe the steps in detail for better reproducibility?\n- Is the result stable over multiple autoencoder trainings?\n- It would be interesting to see the performance before the finetuning stage!\n\nI feel the discussion section could benefit from a few thoughts on the limitations of this approach. For instance, the method might not be the best choice for highly imbalanced classification datasets. Literature on dataset resampling for such scenarios might be worth mentioning in the related work section. Also, the autoencoder’s embeddings are trained to reconstruct the whole image, an objective that gives more importance to patterns that occupy a larger portion of the image. If the downstream task needs attention to detail (e.g. counting of small objects, segmentation in remote sensing or medical imaging, street-number or road-sign detection), the filtering method might also not be much better than random subsampling.\n\nThe related work section could also be improved. I see only one work on data set optimization. I’ve seen work using a reducedMNIST dataset, which is probably created by random subsampling, but still more relevant than many of the aspects of embeddings cited in this section (the paragraph about arithmetic operations for instance). Katharopoulos and Fleuret (2018) seems like highly relevant recent work, which should be cited and contrasted against. The evaluation in that work seems very thorough in comparison.\n\nA general recommendation on writing: Try to limit the content to relevant details. For example, a description of hardware specifics (support for NVLink, which is not used) or stating the well-established speed-up when using GPUs for CNNs are not relevant.\n\nFigure 6 could be improved by marking on the time axis, when the fine-tuning sets in.\n\nTo summarize my feedback, I like most of the presentation and it is good to see effort towards reducing training times by selecting good training samples, but I think the manuscript requires significant effort to justify acceptance.']","[-60, -60, -50]","[20, 20, 50]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's methodology, limited dataset, lack of comparisons with existing approaches, and unclear experimental details. The reviewer concludes by stating they 'cannot argue for acceptance of this paper,' indicating a negative overall sentiment. However, the score is not at the extreme negative end as the reviewer does acknowledge some positive aspects, such as the paper being 'understandably written.' The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding harsh language or personal attacks. They provide constructive criticism and suggestions for improvement, which is polite. However, the score is not higher as the review doesn't include many explicitly polite phrases or compliments, maintaining a mostly neutral, academic tone."", ""The sentiment score is -60 because the reviewer expresses significant disagreement with several premises of the paper, points out multiple weaknesses in the experimental design and results, and highlights several areas of confusion in the text. However, there are a few positive comments (e.g., liking the general idea and enjoying the figures), which prevent the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout, using phrases like 'I disagree' and 'I would argue' rather than more confrontational language. They also offer some constructive suggestions and acknowledge positive aspects. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper (clear description, addressing an important problem), they express significant criticisms and state that the manuscript requires 'significant effort to justify acceptance'. The overall tone is more negative than positive, but not entirely negative. The politeness score is 50 because the reviewer uses polite and professional language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I feel', 'Could you describe', and 'It would be interesting to see', which maintain a respectful tone. However, the review is not overly effusive or excessively polite, maintaining a professional, neutral-to-positive tone in terms of politeness.""]"
"['Paper summary: The paper presents a 2-step approach to generate strong adversarial examples at a far lesser cost as compared to recent iterative multi-step adversarial attacks. The authors show the improvements of this technique against different attacks and show that the robustness of their 2-step approach is comparable to the iterative multi-step methods. \n\nThe paper presents an interesting technique, is nicely written and easy to read. The fact that their low-cost 2-step method achieves is robust enough to iterative multi-step methods that are expensive is significant.  \n\nPros: \n1) The technique is low-cost as compared to other expensive techniques like PGD and IFGSM \n2) The technique tries to use the categorical distribution of the generated example in the first step to generate an example in the second step, such that the generated image is most different from the first. This is important and different from the most common technique of iteratively maximizing the loss between the generated samples. \n3) The authors show the effetiveness  and improvement of the approach to various attack methods as compared to existing defense techniques\n4) The authors evaluate their technique on MNIST and SVHN datasets\n\n\nCons or shortcomings/things that need more explanation :\n1) It would have been really good to the kind of adversarial examples generated by this technique look like as compared to the examples generated by the other strategies. \n2) In table 2, for the substitute models of FGSM trained on H and S labels (rows 2 and 5), it is unclear why the accuracies are so low when attacked on FGSM (hard) and FGSM(soft) models. \n ', 'The paper introduces a two-step adversarial defense method, to generate two adversarial examples per clean sample and include them in the actual training loop to achieve robustness. The main claim is that the proposed two-step scheme can outperform more expensive iterative methods such as IFGSM; hence achieving robustness with lower computation. The first example is generated in a standard way (FGSM) method, while the second example is chosen to maximally increase the cross entropy between output distribution of the first and second adversarial example.\n\nThe idea seems simple and practical and the empirical results are encouraging. However, other than experiments, there is no justification why the proposed loss should do better that IFGSM. Ideally, I wanted to see the authors to start from some ideal defense definition (e.,g. Eq 4) and then show that some kind of approximation to that leads to the proposed scheme. In the absence of that, the faith about the proposed method solely must be based on the reported empirical evaluation, which is not ideal due to issues like hyper parameter tuning for each of the methods. I hope at least the authors publish the code so it could tried by others.', 'Summary. The authors propose a novel adversarial training method, e2SAD, that relies on a two-step process for generating sets of two training adversarial samples for each clean training sample. The first step is a classical FGSM that yields the first adversarial sample. The second adversarial sample is calculated with a FGSM that is based on the cross-entropy between the probabilities generated by the first adversarial sample and the probabilities generated by the second adversarial sample. The method is computationally efficient (two forward/backward passes per clean sample) w.r.t. powerful iterative attacks such as IFGSM or PGD requiring 40+ steps and the authors claim it gives comparable results to adversarial training with multi-step attacks methods in white and black-box settings.\n\nClarity. Part 1 and 2 of the paper are well written and summarize the existing attacks/defense mechanisms, their pros and cons as well as the contributions clearly. The next sections could be made shorter (see comments below) to match ICLR’s recommended soft limit of 8 pages instead of the 10 pages hard limit. This would also help the reader grasp the key ideas faster and have a standard formatting (no negative spaces for instance).\n\nNovelty. The idea of simulating the effect of iterative attacks using two distinct steps is novel and appealing to me. The first step increases the loss while the second step shifts the probability distributions apart.\n\nPros and cons.\n(+) The paper is clear and easy to follow, although a bit long.\n(+) The idea is interesting and clearly motivated in terms of computational efficiency and in terms of desired properties (Figure 2 illustrates this point well).\n\n(-) Only one aspect of the idea is exploited in the article. It would be interesting to compare this method as an attacker (both in terms of performance and in terms of generated samples, see comment below). Powerful adversarial training should indeed rely on powerful generated adversarial samples.\n(-) The results seem somewhat mitigated in terms of significance and conclusions drawn by the authors. Also, the experimental setup is quite light, notably the used CNN architectures are quite small and other datasets could have been used (also linked to the significance of the results).\n\nComments.\n- Shorter paper. Here are suggested modifications for the paper that could help strengthen the impact of your paper. Section 3.1 could be almost entirely discarded as it brings no new ideas w.r.t sections 1 and 2. Figure 1 summarizes the method well, thus the description in Section 3.2 could be made shorter, especially when displaying Equation (8) right after Figure 1. This would then help reduce the size of Sections 3.2.1 and 3.2.2 (because Equation (8) and Figure 1 would prevent you from repeating claims made earlier in the paper). Algorithm 1 is straightforward and could be placed in Appendix. Conclusion and Result sections could be shortened a little as well (not as much as Section 3 though).\n\n- Significance of the results. The significance of some results is unclear to me. Could the authors provide the standard deviation over 3 or 5 runs? For example, in rows 1, 3, 4, 5, 6 of Table 2, it is not clear it e2SAD performs better than FGSM adversarial training, thus raising the question of the necessity of Step 2 of the attack (which is the core contribution of the paper).\n\n- Experimental setup. The last two rows of Table 1 are encouraging for e2SAD. However, the authors could introduce another dataset, e.g. CIFAR10 or 100 or even ImageNet restricted to 20 or 100 random classes/with fewer samples per class and use deeper modern CNN architectures like ResNets (even a ResNet18). Those models are widely adopted both in the research community and by the industry, thus defense mechanisms that provably work for such models can have a huge impact.\n\n- Defense setup. Is the order of Steps 1 and 2 relevant? What if the authors use only iterations of Step 2?\n\n- Attack setup. Here are a few suggestions for assessing your method in an attack setting: what is the precision of the network, without any defense, given an average dissimilarity L2 budget in the training/test samples, in a white/black box setting? How does it compare to standard techniques (e.g. FGSM, IFGSM, DeepFool, Carlini)? What happens if the authors use their method both for both defense and attack? Could the authors display adversarial samples generated by their method?\n\nConclusion. The idea presented in the paper is interesting, but (1) the experimental results are not entirely satisfactory for the moment and (2) only one aspect of the idea is exploited in the paper, which can be made more interesting and impactful while studying both attack and defense setups. I strongly encourage the authors to continue their research in this area due to the high potential impact and benefits for the whole community.']","[80, 20, 20]","[70, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting', 'nicely written', and 'easy to read'. They also highlight the significance of the technique and list several pros. The few cons mentioned are framed as suggestions for improvement rather than criticisms. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their suggestions constructively. They use phrases like 'It would have been really good' and 'it is unclear why', which are polite ways to point out potential improvements without being harsh or demanding."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the idea as 'simple and practical' and the results as 'encouraging'. However, they express concerns about the lack of theoretical justification, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I wanted to see' and 'I hope' which maintain a polite tone while expressing their suggestions. The reviewer also balances critique with positive observations, showing consideration for the authors' work."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the novelty and clarity of the paper, they also point out several areas for improvement and express some reservations about the significance of the results. The overall tone is constructive and encouraging, but not overwhelmingly positive. The politeness score is high (80) as the reviewer uses respectful language throughout, offers constructive criticism, and encourages the authors to continue their research. They balance their critique with positive comments and use phrases like 'I strongly encourage the authors' which demonstrates a supportive attitude. The reviewer also provides detailed suggestions for improvement, which is a polite way of offering criticism.""]"
"['In the manuscript entitled ""Likelihood-based Permutation Invariant Loss Function for Probability Distributions"" the authors propose a loss function for training against instances in which ordering within the data vector is unimportant.  I do not find the proposed loss function to be well motivated, find a number of confusing points (errors?) in the manuscript, and do not easily follow what was done in the examples.\n\nFirst, it should be noted that this is a very restricted consideration of what it means to compare two sets since only sets of equal size are under consideration; this is fundamentally different to the ambitions of e.g. the Hausdorff measure as used in analysis.  The logsumexp formulation of the proposed measure is unsatisfactory to me as it directly averages over each of the independent probabilities that a given element is a member of the target set, rather than integrating over the combinatorial set of probabilities for each set of complete possible matches.  Moreover, the loss function H() is not necessarily representative of a generative distribution.\n\nThe definition of the Hausdorff distance given is directional and is therefore not a metric, contrary to what is stated on page 2.\n\nI find the description of the problem domain confusing on page 3: the space [0,1]^NxF is described as binary, but then values of log y_i and log (1-y_i) are computed with y in [0,1] so we must imagine these are in fact elements in the open set of reals: (0,1).\n\nClarity of the examples could be greatly improved, in particular by explaining precisely what is the objective of each task and what are the \'ingredients\' we begin with.', 'The paper is understandable and the question addressed is interesting. The use of log likelihoods to metrize distances between sets, although not new, is used quite effectively to address the issue of label switching in sets. Although the run time is O(N^2), the metric can be computed in a parallelized manner. The question of comparing sets of different sample sizes would be a valuable extension to the work. Although I think the proposed loss function addresses some important issues, would like to defer the question of acceptance/rejection to other reviewers due to lack of expertise in related areas.', 'This paper proposes an objective function for sets autoencoders such that the loss is permutation invariant with respect to the order of reconstructed inputs. I think that the problem of autoencoding sets is important and designing custom loss functions is a good way to approach it. Thus, I quite like the idea of SCE  from that point of view. However, I find the experiments not convincing for me to accept the paper. \n\nWhile reading Section 3, I found it hard to keep in mind that x and y are discrete probability distributions and the notation like P(x=y) is not making things easier. Actually, I’ve never seen cross entropy written with P(x=y). Though is my personal opinion and I don’t have a suggestion on how to improve the explanations in Eq. 1-8. However, I’m glad there is an example at the end of Section 3.\n\nI have some comments on the Experiments section. \n\n* Puzzles:\n(1) Figure 1 could have been prettier. \n(2) The phrase “The purpose of this experiment is to reproduce the results from (Zaheer et al., 2017)” makes little sense to me.  In Deep Sets, there are many experiments and it’s not clear which experiment is meant here.\n(3) Table 1 gives test error statistics for 10 runs. What is changed in every run? Does the test set stay the same in every run or is a kind of a cross-validation? Or is it just a different random seed for the initial weights? I could not find an explanation in the text, so there is no way I can interpret the results.\n\n* Blocksworld: the reconstructions are nice, but the numbers in Table 2 are difficult to interpret. \nFor example, I cannot estimate how important the difference of 10 points in SH scores is.\n\n* Rule learning ILP tasks: I don’t know enough about learning logic rules tasks to comment on those experiments, but Table 3 seems overwhelming and the concept of 10 runs is still unclear.\n\n--- General comment on the experiments ---\n\nI think an important goal of any autoencoder is to learn a representation that can be useful in other tasks. There is even an example in the paper: “set representation of the environment is crucial in the robotic systems”. Thus, the experiments I would like to see are about evaluating the quality of a representation from an SCE-trained autoencoder compared to other training methods.  Without those experiments, I cannot estimate how valuable the SCE loss function is.  ']","[-70, 50, -20]","[-20, 75, 50]","[""The sentiment score is -70 because the reviewer expresses significant criticism and dissatisfaction with the manuscript. They state that they 'do not find the proposed loss function to be well motivated,' find 'confusing points (errors?),' and 'do not easily follow what was done in the examples.' These are strong negative statements indicating major issues with the paper. The reviewer also points out specific problems with definitions and clarity. However, it's not entirely negative as they do engage with the content, suggesting it's not a complete rejection.\n\nThe politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the criticism. Phrases like 'I do not find,' 'unsatisfactory to me,' and 'Clarity of the examples could be greatly improved' are blunt and could be perceived as somewhat impolite in academic discourse. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or overly harsh language, which is why the score isn't lower."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's understandability, interesting question, and effective use of methods. However, they also mention limitations and defer final judgment, indicating a balanced view. The politeness score is 75 (quite polite) due to the use of respectful language, acknowledging the paper's strengths, and diplomatically expressing limitations. The reviewer also humbly admits their lack of expertise in some areas, which adds to the polite tone. The language is constructive and avoids harsh criticism, maintaining a professional and courteous approach throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and likes the idea, they find the experiments 'not convincing' and have several criticisms. The overall tone suggests skepticism about the paper's contribution without outright rejection. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I think,' 'I found it hard,' and 'I'm glad,' showing respect for the authors' work. They also provide constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer maintains a professional and courteous tone even when expressing concerns or disagreements.""]"
"[""This paper proposed the use of uncertainty measure evaluated by the prior network framework in (Malinin and Gales 2018) to detect adversarial inputs. Empirically, the best detector against three L_infinity based attacks (FGSM, BIM and MIM), is a prior network that is adversarially trained with FGSM, in both white-box and black-box settings. The results also showed superior performance over a detector based on Monte Carlo Dropout methods (MCDP). Although the idea is interesting and the presented results seem promising, there are some key experiments lacking that may prevent this work from making its claims on robustness and detectability. The detailed comments are as follows.\n\n1. Detection performance against high-confidence adversarial examples is lacking : In many of Carlini-Wagner papers, they showed that some detection methods become weak by simply increasing the confidence parameter (kappa) in the CW attack. The three attacks considered in this work, FGSM, BIM, and MIM are all L_infinity attacks, which are known to introduce unnecessary noises due to the definition of L_infinitiy norm. On the other hand, CW attack is a strong L2 attack and it also offers a way of tuning confidence of the adversarial example. In addition, a variant of CW L2 attack, called Elastic-Net attack https://arxiv.org/abs/1709.04114, is able to generate L1-norm based adversarial examples that can bypass many detection methods. Without the results of attack performance vs different confidence levels against strong L1 and L2 attacks, the detection performance is less convincing. \n\n2. Lack of comparison to existing works - there are several detection works that already used uncertainty in detection. A representative paper is MagNet https://arxiv.org/abs/1705.09064 . MagNet paper showed that detection against FGSM/BIM is easy (even without adversarial training), and shows some level of robustness against CW L2 attack when the attacker is unaware of the detection. Later on, MagNet has been bypassed if the detection is known to the adversary https://arxiv.org/abs/1711.08478. Since MagNet and this paper have similar detection methodology using uncertainty, and the detection performance seems similar, the authors are suggested to include MagNet for comparison.\n\n3. The objective of adaptive adversarial attack is unclear - inspecting how MagNet's detection performance is degraded when the attacker knows the detection mechanism https://arxiv.org/abs/1711.08478, the authors should do an adaptive attack that directly includes eqn (8) as one of the attack loss term, rather than using the KL term. In addition, if there is randomness in calculating the MI term for adaptive attacks, then averaged gradients over randomness should be used in adaptive attacks. Lastly, CW L2/EAD L1 attacks with an additional loss term using (8) should be compared.\n\n4. The white-box attacks in Fig. 2 (b) to (c) seem to be quite weak - not be able to reach 100% success rate (saturates around 90%) when using BIM and MIM on the undefended model (DNN) with large attack strength. This might suggest some potential programming errors or incorrect attack implementation. \n\n5. What black-box attack is implemented in this work? It's not clear what kind of black-box attack is implemented in this paper: is it transfer attack? score-based black-box attack? or decision-based black-box attack? Can the proposed method be robust to these three different settings?\n\n6. This paper heavily relies on the work in  (Malinin and Gales 2018), and basically treats adversarial input detection as an out-of-distribution detection problem. Please emphasize the major differences and differentiate the contributions between these two works.\n\n7. In Fig. 2, it seems that adversarial training with FGSM is actually the key factor that makes the detection work (by comparing PN vs PN-ADV in (b) and (c)). To justify the utility of the proposed metric in detection adversarial inputs, the authors are suggested to run MCDP on FGSM-trained model and compare the performance with PN-ADV."", 'Summary:\nThe authors propose a new method to detect adversarial attacks (examples). This approach relies on prior networks to estimate uncertainty in model predictions. Prior-networks are then trained to identify out-of-distribution inputs, and thereby used to detect adversarial examples. The authors evaluate their methodology on CIFAR-10 in different white-box and blackbox settings.\n\nThis work addresses an important question - detecting adversarial examples. Since it may not always be possible to build models that are completely robust in their predictions, detecting adversarial examples and/or identifying points where the model is uncertain is important. However, I am not convinced by the specific methodology as well as the proposed evaluation. \n\nDetailed comments:\n\n- This work is largely based on the recent work by Malinin and Gales, 2018, where prior networks are developed as a scheme to identify out-of-distribution inputs. As a result, the authors rely fundamentally on the assumption that adversarial examples lie off-the data manifold. There has been no convincing evidence for this hypothesis in the literature thus far. Adversarial examples are also likely to be on the data manifold, but form a small enough set that it doesn’t affect standard generalization. But because of the high-dimensional input space, a member of this small set is still close to every “natural” data point. \n\n- I do not find the specific choice of attacks the authors consider convincing. (These being the attacks studied in Smith & Gal, 2018 does not seem to be a sufficient explanation). Specifically, the authors should evaluate on stronger Linf attacks such as PGD [Madry et al., 2017]. Further, it seems that the authors consider Linf eps around 80. These values seem extremely large given that eps=32 (possibly even > 16) causes perceptible changes in the images. Did the authors look at the adversarial examples created for these large eps values?\n\n- The authors should include evaluation on a robust DNN (for example PGD trained VGG network) in the comparison. I believe that the joint success rate for this robust model will already be comparable to the proposed approach. \n\n- I am not convinced by the attack that the authors provide for the setting where the detection scheme is known. This attack seems similar to the approach studied in Carlini and Wagner, 2017 (Perfect-Knowledge Attack Evaluation) which was insufficient to break the randomization defense. Why did the authors not try something along the lines of the attack in Carlini and Wagner, 2017 (Looking deeper) that actually broke the aforementioned defense? Specifically, trying to find adversarial examples that have low uncertainty as predicted by the prior networks. The uncertainty loss -- minimizing KL between p_in(\\pi|x_adv) and p(\\pi|x_adv, \\theta) -- could be added to cross entropy loss.\n\n- In Section 4.2, how do the authors generate black box attacks? If they are white box attacks on models trained with a different seed (as in Section 4.1) the results in 4.2 are surprising. Carlini and Wagner, 2017 found white-box attacks for randomization schemes transferrable and as per my understanding, this should be reflected in Fig 3, at least for prior work.\n\n- I am confused by the authors comment - “Figure 3c shows that in almost 100% of cases the attack yields the target class.” The joint success rate being lower than the success rate should convey that adversarial examples couldn’t be found in many of these cases. What was the value of the epsilon that was used in these plots?\n\nQuality, Novelty and Significance:\n\nThe paper is written well, but clarity about the evaluation procedures is lacking in the main manuscript. I am also not convinced by the rigor of the evaluation of their detection methodology. Specifically: (1) they do not consider state-of-the-art attack models such as PGD and (2) the scheme they propose for a perfect knowledge attack seems insufficient. While the paper asks an important question, I do not find the results sufficiently novel or convincing. More broadly, I find the idea of using a secondary network to detect adversarial examples somewhat tenuous as it should be fairly easy for an adversary to break this other network as well. \n', 'This paper proposes a new detection method for adversarial examples, based on a prior network, which gives an uncertainty estimate for the network\'s predictions.\n\nThe idea is interesting and the writing is clear. However, I have several major concerns. A major one of these is that the paper considers ""detection of adversarial attacks"" to mean detecting adaptive and non-adaptive attacks, while the latter are (a) unrealistic and (b) a heavily explored problem, with solutions ranging from clustering activations, to denoising the image via projection (in particular, once can use any of the circumvented ICLR 2018 defenses which all work in the non-adaptive sense, and check the prediction of the denoised image vs the original). Thus, the paper should focus on the regime of adaptive attacks. Within this regime:\n\nMotivation:\n- This work seems to suggest that dropout-based detection mechanisms are particularly successful. While Carlini & Wagner finds that the required distortion (using a specific attack) increases with randomization, the detection methods which used dropout were still completely circumvented in this paper.\n\n- The claim that adversarial examples are ""points off of the data manifold"" is relatively unmotivated, and is not really justified. Justification for this point is needed, as it forms the entire justification for using Prior Networks.\n\n- Detecting adversarial examples is not the same problem to detecting out-of-distribution samples, and the writing of the paper should be changed to reflect this more.\n\nEvaluation:\n- 100 iterations is not nearly enough for a randomization-based or gradient masking defense, so the attacks should be run for much longer. In particular, some of the success rate lines appear to be growing at iteration 100.\n\n- There is no comparison to any other method (in particular, just doing robust prediction via Madry et al or something similar); this should be added to contextualize the work.\n\n- The term ""black-box"" attacks can take on many meanings/threat models. The threat models in the paper need to be more well-defined, and in particular ""black-box attacks"" should be more accurately defined. If black-box attack refers to query-based attacks, the success rate should be equal to those of white-box attacks (or very close to it), as then the attack can just estimate the gradient through the classifier via queries.\n\n- The fact that the attacks do not reach 100% on the unprotected classifier is concerning, and illustrates the need for stronger attacks.\n\nSmaller comments:\nPage 1: Abstract: Line 4: missing , at the end of the line\nPage 1: Abstract: Line 5: “However, system can“ missing a before system\nPage 1: Abstract: Line 10: “have been shown” should be “has” instead of “have”\nPage 1: Abstract: Line 13: “In this work” missing a , after\nPage 1: Last paragraph: Line 2: “investigate” missing an s and should be “investigates’\nPage 2: Section 2: Line 5: “in other words” missing a , after\nPage 2: Section 2: Line 8: “In order to capture distributional uncertainty”  missing a , after\nPage 2: Last paragraph: Line 2: “Typically” missing a , after\nPage 3: Paragraph 2: Line 1: “In practice, however, for deep,” no need for the last ,\nPage 3: Section 2.2: paragraph 1: Line 2: “a Prior Network p(π|x∗; θˆ), “ no need for the last ,\nPage 3: Section 2.2: paragraph 1: Line 3: “In this work“ missing a  , after\nPage 3: second last paragraph: Line 1: refers to figure as fig and figure (not consistent)\nPage 3: second last paragraph: Line 3: “uncertainty due severe class“ missing “to” before “severe”\nPage 4: Paragraph 1: Line 2: “to chose” should be “to choose”\nPage 4: Paragraph 2: Line 1: “Given a trained Prior Network“ missing a , after\nPage 4: Paragraph 2: two extra ,\nPage 6: paragraph 1: Last line: 5 needs to be written in words and same for 10 in the next paragraph\nPage 7: section 4.2: paragraph 3: “For prior networks” need a , after\nPage 8: Paragraph 1: Line 6: “and and”\nPage 8: Conclusion: Line 4: “In section 4.2” needs a , after\nPage 8: Conclusion: Line 7: “it difficult” missing “is”\nPage 8: Conclusion: Line 9: “is appropriate” should be “if” instead of “is”']","[-20, -50, -50]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and promising results, they express significant concerns about lacking key experiments and comparisons. The review lists several major issues and suggests substantial additional work, indicating that the paper falls short of fully supporting its claims. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and phrases suggestions constructively (e.g., 'the authors are suggested to...'). The tone is professional and objective, avoiding harsh or personal criticism while providing detailed, actionable feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic, they express significant doubts about the methodology and results. Phrases like 'I am not convinced' and 'I do not find the results sufficiently novel or convincing' indicate a negative sentiment. However, the reviewer does mention some positives, such as the paper being well-written, which prevents the score from being lower. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I am confused by' rather than more aggressive language. They also acknowledge the importance of the research question. However, the critique is direct and doesn't use overly polite language, keeping the score from being higher."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's interesting idea and clear writing, they express 'several major concerns' and point out multiple issues with the methodology, evaluation, and motivation. This indicates a predominantly negative sentiment, though not entirely dismissive. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They begin with positive comments and use phrases like 'should be added' or 'needs to be more well-defined' rather than harsh criticisms. However, the tone is mostly neutral and matter-of-fact rather than overtly polite, hence the moderate positive score. The reviewer also provides detailed feedback on grammar and formatting, which is helpful but not necessarily indicative of extreme politeness.""]"
"[""In this paper, authors proposed an ensemble approach for query reformulation (QR).  The basic idea is that 1) train a bunch of models/sub-agents on subsets, e.g., randomly partitioned, of the training data; 2) and then train an additional meta model/meta-agent to aggregate the results from the step 1).  They conduct experiments on document retrieval and question answering tasks to show the effectiveness of the proposed model.\n\nThis paper is well written and easy to follow.  \nHowever there are several my concerns. \n\n1. It is counter intuitive, e.g., why sub-agents trained on full training dataset obtain worse results than on its subset. Regarding diversity, one may use different random seeds or different dropout rates instead of sample a subset of training data. \n\n2. The baseline is much lower than the current SOTA systems. Such as the best result on SearchQA in this paper is 50.5 in terms of F1 score. However R3 and Re-Ranker obtains 55.3 and 60.6 respectively. Could the proposed approach be adapted on those models? Note that those SOTA systems are released.\n\n3. The proposed system is quite similar to Nogueira& Cho 2017 and Buck et al. 2018. I'm not very sure the contribution of this work and its novelty.  \n\nQuestions:\n1. Why the authors didn't use beam search during the sub-agent training? \n2. It seems that the proposed framework is a pipeline model: firstly it trains a bunch of sub-agents; and then trains meta-agent. Is it possible to fine-tune the model jointly?\n3. What is Extra Budget in Table 1?    "", 'Summary:\nThe authors propose to train multiple distinct agents, each over a different subset of the training set. A meta-agent, known as the aggregator, groups and scores answers from the sub-agents for any given input. \n\nEach agent produces a unique reformulation that is applied to the environment, producing an answer for the reformulated query. The aggregator receives the original query and the answers provided by the environment and produces a relevance score for each answer with respect to the original query that is a function of both components.\n\nThe final answer is select using this relevance score, as well as an aggregate ranking score for over the space of reformulations for each answer.\n\nThe aggregator is trained to minimize the cross-entropy of the relevance score. Each reformulation agent is trained using Recall@40 as a reward for retrieving the correct answer from the environment given their reformulation. \n\nThe authors argue that learning multiple specialized sub-agents is easier than learning a generalist agent responsible for being able to model the entire training data. Authors shows that this strategy is even more generalizable than training an ensemble for the same number of agents over the entire training set. Authors apply the approach to query reformulation for document retrieval and QA.\n\nReview:\n\nPros:\n-The paper provides convincing empirical evidence that training multiple distinct agents on different partitions of a dataset to learn to reformulate queries for environment feedback is a more efficient and accurate approach than training single or ensemble model on the whole dataset. Empirical result show that both the addition of the aggregator and the exclusivity of the agents contributes to this effect. Baselines are considerable and in-depth (though it seems like the Hui et al., 2017 model that is SOTA on TREC-CAR could be shown in Table 1 as well)\n-The paper is well written and easy to understand in the approach.\n\nCons:\n-The authors could do a better job explaining a couple of unclear points. First, how did the authors come up with equation 2 for computing the relevance score? While the empirical investigation in Table 8 indicates it does better than other simpler formulations, it’s not clear why the authors were motivated to try this one.\n-I don’t come away with an idea of WHY the author’s proposed approach works better. While the empirical investigation is a contribution in it of itself, the results seem slightly counterintuitive. It’s not clear why a random partition should be better than a semantically-motivated partition. It’s also not clear why training the reformulating agents individually on these partitions would do better than an ensemble. I find the paper interesting, but the analysis of these results is missing.\n\nQuestions:\nWhy does the function for z_j in equation 2 need to be so complicated? Why are the CNN features of the query concatenated twice in the first part. What does the dot operator in the second part of the equation correspond to?', 'The authors proposed a variant of ensemble method in reinforcement learning for query reformulation. They train multiple specialized sub-agents on disjoint partitions of the training data, and use a meta-agent, which can see all the training data, to decide the final answer. This can speed up the training thanks to parallelization. They observed that this can improve the diversity of learnt reformulations and the overall performance in some cases. \n\n\nStrengths\n1. The paper is clear and easy to follow.\n2. Multiple evaluation metrics and baseline models are considered\n\nWeaknesses\n1. The proposed method is simple and lacks novelty.\n2. The performance improvement is marginal and some empirical results are not carefully analyzed. \n\n\nSignificance\nExploring a diverse set of strategies is beneficial in reinforcement learning. This paper focuses on two aspects of this problem. One is how to learn diverse agents and the other one is how to efficiently learn these agents efficiently, which are important concerns in practice. \n\n\nOriginality\nThe model learning approach they proposed is merely a simple variant of ensemble learning. The main difference is they train sub-agents on disjoint partitions of the training data, which seems a trivial modification although this shows to improve the overall model performance.\n\n\nTechnical Quality\nOverall, the experiments are well-thought, but the following questions need to be explained:\n1.\tIn the Introduction, the authors claim three contributions they made in this paper. My question is, if the third one is really an important contribution, why didn’t the authors demonstrate it in detail in the main text? Attaching it to the appendix could make the reader confused about its significance.\n2.\tIn Table-1, the authors claim that their proposed architectures can outperform the baseline RL-10-Ensemble with only 1/10 time. The sub-agents are trained on a partition of the training set. My question is, are these sub-agents trained in parallel on different machine? If so, why cannot the RL-10-Ensemble be trained in parallel through some multithread or distributed computation? The implementation of the proposed model and the baseline seems not that fair.\n3.\tThe main architecture is described in section 3.3 and 3.4, including the Sub-agents and the Aggregator. However, in Appendix C.1, the authors claim that the gains the proposed method comes mostly from the pool of diverse reformulators, and not from the simple use of a re-ranking function (Aggregator). This is confusing because if it is true, the proposed method is really reduced to an ensemble of the baseline model.\n4.\tIn Table-2, some of the results are worse than the baseline methods like Re-Ranker. Although the authors claim the re-ranking is a post-processing, Re-Ranker performs significantly better than the proposed model. If the authors want to better demonstrate the advantages of the proposed model, a comparison between the proposed model with re-ranking and the Re-Ranker is required.\n5.\tIn Table 10, why the proposed method fails to produce the right answer whereas the other methods perform well?\n']","[-20, 50, -20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and easy to follow, they express several concerns about the methodology, results, and novelty of the work. The reviewer points out counter-intuitive aspects, lower baseline results compared to state-of-the-art systems, and similarities to existing work, which contribute to the overall negative sentiment. However, the criticism is not severe, hence the score is only slightly negative.\n\nThe politeness score is positive (60) as the reviewer maintains a professional and respectful tone throughout. They begin with a positive comment about the paper being well-written, and frame their concerns as 'my concerns' rather than stating them as absolute flaws. The reviewer also asks questions at the end, which is a constructive approach to peer review. The language used is not overly formal or excessively polite, but it is consistently respectful and appropriate for academic discourse."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced assessment, listing both pros and cons. The reviewer acknowledges the paper's strengths, such as providing convincing empirical evidence and being well-written, while also pointing out areas for improvement. The overall tone is constructive rather than overly critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'The authors could do a better job explaining' instead of more confrontational language. The review also acknowledges the paper's contributions before discussing its limitations, which is a polite approach to academic critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths (clear writing, multiple evaluation metrics), they also point out significant weaknesses (lack of novelty, marginal performance improvement) and raise several critical questions about the methodology and results. The overall tone suggests more concerns than praise. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout, using neutral language to express criticisms and asking questions rather than making accusatory statements. They acknowledge the paper's strengths before discussing weaknesses, which is a polite approach. The reviewer also uses phrases like 'need to be explained' rather than more confrontational language, contributing to the polite tone.""]"
"['TITLE\nA VARIATIONAL AUTOENCODER FOR PROBABILISTIC NON-NEGATIVE MATRIX FACTORISATION\n\nREVIEW SUMMARY\n\nWell written, interesting new idea, modest technical contribution, limited demonstration.\n\nPAPER SUMMARY\n\nThe paper presents an approach to NMF within a variational autoencoder framework. It uses a Weibull distribution in the latent space. \n\nQUALITY\n\nThe work appears technically sound except for minor typos. \n\nCLARITY\n\nOverall the paper is a pleasure to read. Only the presentation of the standard vae could be more clear.\n\nORIGINALITY\n\nThe method is (to my knowledge) novel. \n\nSIGNIFICANCE\n\nI think this paper is a significant contribution. I feel I have learned something from reading it, and am motivated to try out this approach. I believe there should be a wide general interest. The technical contribution is perhaps somewhat modest, as the paper fairly straightforwardly includes non-negativity in a vae setting, but I think this is a good idea. The demonstration of the algorithm is also quite limited - I would have enjoyed seeing this applied to some more reaslistic, practical problems, where perhaps the quantification of uncertaincy (which is one of the main benefits of a vae-based nmf) would come more directly into play. \n\nFURTHER COMMENTS\n\npage 3\n\nThe presentation of the VAE objective is a bit oblique. The statement ""they require a different objectiv function"" is not wrong, but also not very precise. The equality in eq. (2) is incorrect (I assume this is meant to be a stochastic approximation, i.e. the expectation over q approximated by sampling?)\n\n""with \\hat v  the reconstructed vector"" Not clear. I assume \\hat v is reconstructed from a sample from q given v ?\n\nThere is a typo in eq. 3. The first factor in the second to last term should be (lambda_1/\\lambda_2)^(k_2)\n\n', 'This paper replaces the Gaussian latent variables in standard VAE with the Weibull distribution and therefore presents a VAE solution to nonnegative matrix factorization, under squared Euclidean distance loss function. The literature review summarizes four related work very well. The adopted Weibull distribution provides a tractable inverse CDF function and analytical form of the KL divergence, facilitating VAE inference. In particular, the effects of the entropy term are discussed in detail.  Experiments illustrate the generated data from the model,  the learned part-based dictionaries, and the distributions of latent variables from similar data points.  \n\nQuestions: \n\n1. What is the updating rule for W_f? Is it multiplicative?  In Sec 2.4, The value of W_f is kept to be nonnegative by ""setting negative terms to zero"". Does it mean once one entry is set to zero, it would never be positive in the sequential gradient steps? \n\n2. Although the proposed model is claimed to be probabilistic, the L2 loss function in equation (2) implies that the data generated from the model could be negative. How would the proposed approach handle other loss function of NMF such as KL (e.g., under Poisson assumption)?  \n\n3. The nonnegative variant sounds interesting, but the experimental results are quite limited. It is unclear how the proposed approach would compare to other probabilistic NMF models and algorithms, or the standard VAE as a generative model. It seems the proposed method can do as good as NMF or VAE in some aspects. This begs the question of when would the proposed approach be superior to others and in what aspect? \n\nMinor: \nIn some places where the parameter are constrained to be nonnegative, it would be more clear to use notations such as R_+ instead of R.  ', 'The paper is generally well-written (lacking details in some sections though). My main criticism is about the lack of motivation for nonnegative VAE and lack of comparison with NMF.\n\nComments:\n- the motivation of the proposed methodology is not clear to me. What is the interest of the proposed auto-encoding strategy w.r.t NMF ? There is no experimental comparison either. Besides the probabilistic embedding (which exists in NMF as well), is there something PAE-NMF can do better than NMF ? There is probably something, but the paper does not bring a convincing answer.\n- the paper missed important references to nonnegative auto-encoders, in particular:\nhttps://paris.cs.illinois.edu/pubs/paris-icassp2017.pdf\n- the review of probabilistic NMF works is limited, see e.g.,\nhttps://paris.cs.illinois.edu/pubs/smaragdis-spm2014.pdf\n- more details are needed about inference in Section 2.4\n\nMinor comments:\n- the notations z and h are sometimes confusing, what about using h every where ?\n- it’s not clear to me how the first term in (1) is equal to the second term in (2']","[60, 50, -30]","[80, 80, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'well written' and 'interesting', and stating that it's 'a significant contribution' that they learned from. However, they also note some limitations, such as 'modest technical contribution' and 'limited demonstration', which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They praise aspects of the paper ('a pleasure to read', 'significant contribution') and offer criticism in a gentle manner ('could be more clear', 'somewhat modest'). The reviewer also expresses personal engagement ('I feel I have learned something', 'I would have enjoyed seeing'), which adds a polite, collegial tone. The only slight reduction in politeness comes from the direct pointing out of typos and errors, though this is done matter-of-factly rather than rudely."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and provides a balanced overview, noting both strengths and areas for improvement. The review begins with positive comments about the paper's approach and literature review, but also raises several questions and points out limitations in the experimental results. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. The reviewer also acknowledges the paper's strengths before raising concerns. The use of phrases like 'sounds interesting' and the constructive nature of the feedback contribute to the polite tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper is 'generally well-written', they express 'main criticism' about lack of motivation and comparisons. They also point out several areas needing improvement or clarification. The politeness score is slightly positive (20) as the reviewer uses professional language and offers constructive criticism. They use phrases like 'My main criticism is...' and 'more details are needed' rather than harsh or rude language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback.""]"
"['The authors present two methods for learning a similarity score between pairs of graphs. They first is to use a shared GNN for each graph to produce independent graph embeddings on which a similarity score is computed. The authors improve this model using pairs of graphs as input and utilizing a cross-graph attention-mechanism in combination with graph convolution. The proposed approach is evaluated on synthetic and real world tasks. It is clearly shown that the proposed approach of cross-graph attention is useful for the given task (at the cost of extra computation).\n\nA main contribution of the article is that ideas from graph matching are introduced to graph neural networks and it is clearly shown that this is beneficial. However, in my opinion the intuition, effect and limitations of the cross-graph attention mechanism should be described in more detail. I like the visualizations of the cross-graph attention, which gives the impression that the process converges to a bijection between the nodes. However, this is not the case for graphs with symmetries (automorphisms); consider, e.g., two star graphs. A discussion of such examples would be helpful and would make the concept of cross-graph attention clearer.\n\nThe experimental comparison is largely convincing. However, the proposed approach is motivated by graph matching and a connection to the graph edit distance is implied. However, in the experimental comparison graph kernels are used as baseline. I would like to suggest to also use a simple heuristics for the graph edit distance as a baseline (Riesen, Bunke. Approximate graph edit distance computation by means of bipartite graph matching. Image and Vision Computing, 27(7), 2009).\n\n\nThere are several other questions that have not been sufficiently addressed in the article.\n\n* In Eq. 3, self-attention is used to compute graph level representations to ""only focus on important nodes in the graph"". How can this be reconciled with the idea of measuring similarities across the whole graph? Can you give more insights in how the attention coefficients vary for positive as well as negative examples? How much does the self-attention affects the performance of the model in contrast to mean or sum aggregation?\n* Why do you chose the cross-graph similarity to be non-trainable? Might there be any benefits in doing so?\n* The note on page 5 is misleading because two isomorphic graphs will lead to identical representations even if communication is not reduced to zero vectors (this happens neither theoretically nor in practice).\n* Although theoretical complexity of the proposed approach is mentioned, how much slower is the proposed approach in practice? As similarity is computed for every pair of nodes across two graphs, the proposed approach, as you said, will not scale. In practice, how would one solve this problem given two very large graphs which do not fit into GPU memory? To what extent can sampling strategies be used (e.g., from GraphSAGE)? Some discussion on this would be very fruitful.\n\n\nIn summary, I think that this is an interesting article, which can be accepted for ICLR provided that the cross-graph attention mechanism is discussed in more detail.\n\n\nMinor remarks:\n\n* p3: The references provided for the graph edit distance in fact consider the (more specific) maximum common subgraph problem.', 'The authors introduce a Graph Matching Network for retrieval and matching of graph structured objects. The proposed methods demonstrates improvements compared to baseline methods. However, I have have three main concerns: \n1) Unconvining experiments.\n\ta) Experiments in Sec4.1. The experiments seem not convincing. Firstly, no details of dataset split is given. Secondly, I am suspicious the proposed model is overfitted, although proposed GSL models seem to bring some improvements on the WL kernel method. As shown in Tab.3, performance of GSL models dramatically decreases when adapting to graphs with more nodes or edges. Besides, performance of the proposed GSLs also drops when adapting to different combines of k_p and k_n as pointed in Sec.B.1. However, the baseline WL kernel method demonstrates favourable generalization ability.\n\n\tb）Experiments in Sec4.2. Only holding out 10% data into the testing set is not a good experiment setting and easily results in overfitting. The authors are suggested to hold more data out for testing. Besides, I wonder the generalization ability of the proposed model. The authors are suggested to test on the small unrar dataset mentioned in Sec.B.2 with the proposed model trained on the ffmpeg dataset in Sec4.2.\n\n2) Generalization ability. The proposed model seems sensitive to the size and edge density of the graphs. The authors is suggested to add experiments mentioned in (1).\n\n3) Inference time and model size. Although the proposed model seems to achieve increasing improvements with the increasing propagation layers. I wonder the cost of inference time and model size compared to baselines methods. ', 'Graph matching is a classic and import problem in computer vision, data mining, and other sub-areas of machine learning. Previously, the graph matching problems are often modeled as combinatorial optimization problems, e.g. Quadratic Assignment Problems. While these optimization problems are often NP-hard, researchers often focus on improving the efficiency of the solvers. The authors attack the problem in another way. They proposed an extension of graph embedding networks, which can embed a pair of graphs to a pair of vector representations, then the similarity between two graphs can be computed via computing the similarities of the pair of vector representations. The proposed model is able to match graphs in graph level as it can predict the similarities of the two graphs.\n\nCompare to Graph Embedding Networks (GNN), the authors proposed a new model, in which a new matching module accepts the hidden vector of nodes from two graphs and maps them to a hidden matching variable, then the hidden matching variable serves as messages as in Graph Embedding Networks. This is the main contribution of the paper compared to GNN.\n\nThe main problem of the paper is that it is not clear where the performance improvement comes from. The authors proposed a cross-graph attention-based matching module. However, it is not clear whether the performance improvement comes from the cross-graph interaction, or the attention module is also important. It would be nice if the author can do some ablation study on the structure of the new matching module.\n\nIn graph matching, we not only care about the overall similarity of two graphs but also are interested in finding the correspondence between the nodes of two graphs, which requires the similarities between vertexes of two graphs. Compared to another [1] deep learning based graph matching model, the author did not show that the proposed are able to give the matching constraints. For example, while the authors show that it is possible to use GMN to learn graph edit distances, is it possible to use the GMN to help to the exact editing?\n\n\n\n[1] Zanfir, Andrei, and Cristian Sminchisescu. ""Deep Learning of Graph Matching."" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.']","[50, -50, 20]","[75, 20, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper and suggests it can be accepted with revisions, while also providing constructive criticism. The review begins positively, noting the clear contributions and useful visualizations. However, it also points out several areas needing improvement or clarification. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands, and acknowledges the paper's strengths. Phrases like 'I like', 'I would like to suggest', and 'In summary, I think that this is an interesting article' contribute to the polite tone. The reviewer also provides detailed feedback to help improve the paper, which is a courteous approach in academic reviewing."", ""The sentiment score is -50 because while the reviewer acknowledges some improvements of the proposed method, they express three main concerns about the experiments, generalization ability, and lack of information on inference time and model size. These concerns outweigh the positive aspects, resulting in a moderately negative sentiment. The politeness score is 20 because the reviewer uses professional and constructive language, offering specific suggestions for improvement. They avoid harsh criticism and use phrases like 'the authors are suggested to,' which maintains a respectful tone. However, the review is not overly polite or effusive, maintaining a primarily neutral, professional tone with slight positive politeness."", ""Sentiment Score (20): The review begins with a positive tone, acknowledging the importance of graph matching and praising the authors' novel approach. However, it also points out some significant issues, particularly the lack of clarity on the source of performance improvements and the absence of certain comparisons. This mix of positive and critical elements suggests a mildly positive sentiment.\n\nPoliteness Score (60): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would be nice if' and frame criticisms as suggestions for improvement rather than direct attacks. The language is consistently courteous, avoiding harsh or dismissive statements. However, it doesn't go out of its way to be overly polite or complimentary, maintaining a balanced, academic tone.""]"
"[""The paper proposes deep learning extension of the classic paradigm of 'conformal prediction'. Conformal prediction is similar to multi-label classification, but with a statistical sound way of thresholding each (class-specific) classifier: if our confidence in the assignment of an x to a class y is smaller than \\alpha, then we say 'do not know / cannot classify'). This is interesting when we expect out of distribution samples (e.g., adversarial ones).\n\nI think this paper, which is very well written, would make for nice discussions at ICLR, because it is (to my knowledge) the first that presents a deep implementation of the conformal prediction paradigm.  However, there are a couple of issues, which is why I think it is definitely not a must have at ICLR. The concrete, deep implementation of the approach is rather straightforward and substandard for ICLR: Features are taken from an existing, trained SOTA DNN, then input KDE, based on which for each class the quantiles are computed (using a validation set). Thus, feature and hypothesis learning are not coupled, and the approach requires quite a lot of samples per class (however, oftentimes in multi-label prediction we observe a Zipf law, ie many classes have fewer than five examples). Furthermore, there is no coupling between the classes; each class is learned separately; very unlikely this will work better than a properly trained multi-class or (e.g., one-vs.-rest) multi-label classifier in practice. Since a validation set is used to compute the quantiles, substantial 'power' is lost (data not used very efficiently; although that could be improved at the expense of expensive CV procedures).\n"", ""This paper applies Conformal Methods to multi-class classification. I am unfamiliar with the field, but the authors seem to be the first to attempt multiclass classification with Conformal Methods by estimating p(x|y) instead of the usual p(y|x). In doing so, they effectively build an independent classifier for each class that estimates whether an example comes from that class within a certain confidence which is set before training time.\nIn this way, they create meaning NULL predictions for an unidentified example, instead of the usual low-probability of an erroneous class.\nThe paper is well written, although it is difficult for me to work out which parts are the author's contributions, and which parts are tutorial/introduction to known Conformal Methods techniques, again this might be because this is not my subject area.\nThe ImageNet results look OK, not great, I would prefer to see a table in section 6.\nThe transfer of features from CelebA to IMDB-wiki is good, but it is hard to tell how good. I feel there should be more comparisons to other methods, even, perhaps an ROC curve for a set of 1 vs all mlp binary/SVM classifiers along with the conformal results (mlp using different cutoff thresholds, conformal method being trained with different confidence levels).\nI feel like this paper may be important, but it is a little difficult for me (myself) to judge without clear empirical evidence of a strong method vs other methods.\n"", 'The paper proposes an approach to construct conformal prediction sets. The idea is to estimate p(x|y) and then construct a conformal set based on the p(x|y) instead of p(y|x). The paper claims that such a method produces cautious classifiers that can produce ""I don\'t know"" answers in the face of uncertainty.\n\nHowever,\nA] Although the paper is titled is ""Cautious Deep Learning"", the method is broadly applicable to any classifier, there is nothing in the method that restricts it to the domain of deep learning. A broad spectrum evaluation could have been done on standard multi-class classifiers.\nB] The paper provides multiple qualitative evaluation results. While it gets the point across, I still would have liked to see a quantitative evaluation, for e.g., there have been several papers that proposed generating adversarial examples for deep learning. The author could have taken any of those methods, generated adversarial examples for deep learning and compared the original classifier with the conformal prediction set. Also, such comparison would have made the paper more connected with deep learning.\nC] The paper uses Xception network as a feature extractor and then compares its result with Inception-v4. Honestly, I would have preferred if the comparison was between 1] Xception Feature Extractor + Conformal Set Prediction, 2] Xception network prediction, and 3] Inception-v4. The reason being that it is very difficult to understand how much of the cautious-ness is because of the proposed approach and how much is due to the Xception network being good. For example, in Figure 3b, does Xception network generate high probability values for the top classes or does it generate low probability values? Unless we can understand this difference, it is very difficult to appreciate what this approach is giving us.\nD] Another analysis that could have been done is to apply this approach and use several different pre-trained networks as feature extractor and check whether there is a decrease in false positives across all the networks, that would suggest that the method can truly make deep learning cautious across a wide variety of networks.\nE] Another analysis that could have been done is understand the impact of the quality of feature extractor. For example, take a deep network (of sufficient depth) and use the proposed approach but instead of using just the penultimate layer for feature extraction, one can keep on removing layers from the end and use the remaining as the feature extractor. Then analyze the quality of conformal predictions as each layer gets removed. One can understand the robustness of this method.\n\nEven though doing all these evaluations may be a tad too much, but definitely, quite a few of those could have been done to make the approach look convincing and enticing. I think bulking this paper with such analysis could make for a very good submission. However, as it stands, it still quite lacks.']","[20, 20, -50]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is 'very well written' and would make for 'nice discussions at ICLR'. They also mention it's the first to present a deep implementation of conformal prediction. However, the reviewer also points out several issues, which balances out the positive aspects. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and uses phrases like 'I think' to soften their opinions. The reviewer provides constructive feedback without using harsh or dismissive language, maintaining a professional tone throughout the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's potential importance and novelty, stating 'I feel like this paper may be important' and 'the authors seem to be the first to attempt multiclass classification with Conformal Methods.' However, the reviewer also expresses some reservations and suggests improvements, which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise ('I am unfamiliar with the field'), and frames criticisms as suggestions rather than demands ('I would prefer to see', 'I feel there should be'). The reviewer also balances critique with praise, noting the paper is 'well written' and that some results are 'good'. The language is consistently professional and constructive, avoiding any harsh or rude phrasing."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's proposal and its potential, they express significant concerns and criticisms. The review starts with a neutral tone but quickly shifts to highlighting multiple shortcomings (points A through E), suggesting that the paper 'quite lacks' in its current state. This indicates a generally negative sentiment, though not entirely dismissive. The politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would have preferred' and 'Another analysis that could have been done,' which are polite ways of suggesting improvements. The reviewer also acknowledges that doing all suggested analyses might be 'a tad too much,' showing consideration for the authors' workload. However, the politeness is not overly effusive, maintaining a neutral to slightly positive tone in terms of courtesy.""]"
"['===========================\nSince the authors did not provide a proper response to my questions, I have lowered my score from 7 to 6. I think this paper will have a good chance to be a good paper if evaluated more comprehensively, as suggested by reviewers. \n===========================\n\nContributions:\n\nThe main contribution of this paper is the study of the currently adopted evaluation metrics for textual GAN models. It was shown that BLEU and Self-BLEU scores used by previous work are insufficient to evaluate textual GAN models, and the authors propose that Frechet Distance and reverse Language Model scores can be a good complement to the above BLEU score evaluations. \n\nDetailed Comments:\n\n(1) Novelty: It seems to me that this paper is timely, as developing GAN models for text generation gains more and more attention in the research community, and it is indeed much needed to provide good evaluation methods. The proposed new metrics seem proper, and the observation that most GAN models do not yield obviously better results than conventional LM is also insightful. \n\n(2) Presentation: This paper is generally well-written and easy to follow. However, when discussing related work in section 3.1, I think one literature [*] is missed. It uses annealed softmax to approximate argmax for textual GAN. \n\n[*] Adversarial Feature Matching for Text Generation, ICML 2017\n\n(3) Evaluation: The experiments are generally well-executed, with some questions listed below.\n\nQuestions:\n\n(1) I have some concerns in terms of human evaluation. Though human evaluation is the golden metric, it seems that presenting individual sentences to human raters does not account diversity into consideration. Therefore, systems that generate high quality samples but with less diversity will get a high score in terms of human evalution. Can the authors provide some discussion on this? And if this is the case, how will this change the conclusions in this paper?\n\n(2) I understand why the authors use simplified GAN models for evaluation. However, if the models are not simplified, what the performance will be for LeakGAN and MaskGAN, for example? This seems to be relatively easy to evaluate since the code is open sourced. \n\nMinor issues:\n\n(1) I think the citation format needs to be changed. For example, in many places, it is more natural to use ""(Hassan et al., 2018)"" than ""Hassan et al. (2018)"" for example. ', 'The paper sets out to improve the evaluation of GAN models as e.g. the previously used BLEU score is not sensitive to semantic deterioration of generated texts. The paper claims to “propose alternative metrics that better\ncapture the quality and diversity of the generated samples”.\n\n\nStrengths:\n-\tThe paper has a valuable goal\n-\tSome of the evaluations are interesting.\n\n\nWeaknesses:\n1.\tThe claim of the paper to “propose alternative metrics that better capture the quality and diversity of the generated samples” is not met in multiple ways:\na.\tThe paper seems not to propose any new metrics but evaluate existing ones.\nb.\tThe metrics are not extensively compared to human judgments, e.g. by computing correlation. In fact, Figure 5 suggests that they are not very well correlated.\nc.\tThe diversity is not explicitly studied on generated text samples.\n2.\tThe paper concludes that the human eval “assigns better scores to the Language Model”, which is incorrect as Seq gan scores 3.49 vs. 3.37 for language model (even if the seq gan has higher variance).\n3.\tThe metrics are not very well defined, e.g. with formulas, although this is one of the central points of the paper. e.g. what are the reference the blue score is computed against?\n\n', 'This paper tackles the problem of evaluation of language generation models and particularly focuses on the comparison between GAN-based language models (GAN-LM) vs likelihood-based language models (MLE-LM). Studying the behaviour of current evaluation metrics for language generation as well as finding new ones is an important research topic. I believe that this paper makes a step in the right direction but the magnitude of that step may be insufficient for publication. I appreciate the efforts but I find most of the findings about BLEU not being a good metric and characteristic of reverse PPL rather unsurprising. The majority of the paper is dedicated to describing models / metrics which are well-known instead of performing more solid experimental evaluation (Results start at page 6). Instead, the authors could have focused more on the study of FD for language generation.\n\n-- Details\n\n-""Our main finding is that, when compared carefully, a conventional neural Language Model performs at least as well as any of the tested GAN models"", however the authors don\'t compare with the recent MaskGAN model, which, according to (https://arxiv.org/abs/1801.07736) outperforms MLE variants.\n\n- ""We demonstrate that previously used n-gram matching, such as BLEU scores, is an insufficient metric"": the fact that BLEU is not ideal for evaluation natural language generation has been pointed out in multiple related papers (e.g. https://arxiv.org/abs/1603.08023) and thus is not surprising.\n\n- ""We find that reporting results from the best single run or not performing sufficient tuning introduces significant bias in the reported results"": as the authors point out in related works, the variance in GAN results which hinders meaningfulness of the reported results is a also a well-known problem (e.g. https://arxiv.org/pdf/1711.10337.pdf), therefore cannot be considered as a contribution.\n\n- The observed behaviour (sensitivity to mode collapse, word swap, word removal) of the ""reverse PPL"" metric is pretty much expected, but I agree some experimental results are still interesting.\n\n- On the contrary, I liked the study on the FD metric but I would have loved the paper to focus more on the study of the behaviour of that metric: for example, by examining the robustness under different base models, while the authors only test with the model by Conneau et. al, 2017.\n\n- It would have been good to train a state-of-the-art language model architecture, e.g. AWD-LSTM, and to control regularization. I cannot see if the MLE-LM model is overfitting or not.\n\n-- Style remarks:\n\n- Moving the figures closer to the paragraph where they are described avoids the reader the burden of going back and forth through the paper.']","[-20, -50, -30]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because the reviewer lowered their score from 7 to 6, indicating some disappointment with the authors' response to previous questions. However, they still believe the paper has potential to be good if evaluated more comprehensively. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering detailed comments and suggestions without using harsh language. They acknowledge the paper's contributions and potential while also pointing out areas for improvement in a respectful manner. The use of phrases like 'I think,' 'Can the authors provide,' and 'I understand' contribute to the polite tone."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths ('valuable goal', 'interesting evaluations'), the majority of the review focuses on weaknesses and criticisms. The reviewer points out multiple ways in which the paper fails to meet its claims and highlights incorrect conclusions. However, it's not entirely negative, hence not a lower score. The politeness score is 20 because the reviewer uses neutral, professional language without personal attacks. They present criticisms as 'weaknesses' and use phrases like 'The paper seems not to' rather than more accusatory language. However, the directness of the criticisms prevents a higher politeness score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('makes a step in the right direction', 'I appreciate the efforts'), they express significant criticisms and state that the paper's contributions may be 'insufficient for publication'. The overall tone suggests disappointment with the paper's novelty and depth. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the authors' efforts and using phrases like 'I believe' and 'I would have loved' to soften criticisms. However, they do not go out of their way to be overly polite or encouraging, maintaining a professional tone focused on the paper's content rather than on interpersonal niceties.""]"
"['The paper intends to utilize natural gradient induced by Wasserstein-2 distance to train the generator in GAN. Starting from the dynamical formulation of optimal transport, the authors propose the Wasserstein proximal operator as a regularization, which is simple in form and fast to compute. The proximal operator is added to training the generator, unlike most other regularizations that focus on the discriminator. This is an interesting direction. \n\nThe motivation is clear but by so many steps of approximation and relaxation, the authors didn’t address what is the final regularization actually corresponding to? Personally I am not convinced that theoretically the proposed training method is better than the standard SGD. The illustration example in the paper is not very helpful as it didn’t show how the proposed proximal operator works. The proximal operator serves as a regularization and it introduces some error, I would like to know how does this carry over to the whole training procedure. \n\nIn GAN, the optimal discriminator depends on the current generator. Many approaches to GAN training (i.e. WGAN-GP) advocates to update the generator once in every “outer-iteration”. I am not sure how the proposed approach fit in those training schemes.\n\nIn the simulation, the difference is not very significant, especially in FID vs iteration number. This could be due to parameter tuning in standard WGAN-GP. I encourage more simulation studies and take more GAN structures into consideration. \n\nLastly, the stability mentioned in the paper lacks a formal definition. Is it the variance of the curves? Is it how robust the model is against outer iterations?', '\n[summary]\nThis paper considers natural gradient learning in GAN learning, where the Riemannian structure induced by the Wasserstein-2 distance is employed. More concretely, the constrained Wasserstein-2 metric $d_W$, the geodesic distance on the parameter space induced by the Wasserstein-2 distance in the ambient space, is introduced (Theorem 1). The natural gradient on the parameter space with respect to the constrained Wasserstein-2 metric is then derived (Theorem 2). Since direct evaluation of $G^{-1}$ poses difficulty, the authors go on to considering a backward scheme using the proximal operator (3), yielding:\n(i) The Semi-Backward Euler method is proposed via a second-order Taylor approximation of the proximal operator $d_W^2$ (Proposition 3).\n(ii) From an alternative formulation for $d_W$ (Proposition 4), the authors propose dropping the gradient constraint to define a relaxed Wasserstein metric $d$, yielding a simple proximal operator given by the expected squared Euclidean distance in the sample space used as a regularizer (equation (4)). The resulting algorithm is termed the Relaxed Wasserstein Proximal (RWP) algorithm.\n\n[pros]\nThe proposal provides an easy-to-implement drop-in regularizer framework, so that it can straightforwardly be combined with various generator update schemes.\n\n[cons]\nDespite all the theoretical arguments given to justify the proposal, the resulting proposal may simply be viewed as a naive application of the proximal operator.\n\n[Quality]\nSee [Detailed comments] section below.\n\n[Clarity]\nThis paper is basically clearly written.\n\n[Originality]\nProviding justification to the proximal operator approach in GAN learning via natural gradient with respect to the Riemannian structure seems original.\n\n[Significance]\nSee [Detailed comments] section below.\n\n[Detailed comments]\nTo the parameter space $\\Theta\\subset\\mathbb{R}^d$, one can consider introducing several different Riemannian structures, including the conventional Euclidean structure and that induced by the Wasserstein-2 metric. Which Riemannian structure among all these possibilities would be natural and efficient in GAN training would not be evident, and this paper discusses this issue only in the very special single instance in Section 2.3. A more thorough argument supporting superiority of the Riemannian structure induced by the Wasserstein-2 metric would thus be needed in order to justify the proposed approach.\n\nIn relation to this, the result of comparison between WGAN-GP with and without SBE shown in Figure 5 is embarrassing to me, since it might suggest that the proposed framework aiming at performing Wasserstein natural gradient is not so efficient if combined with WGAN-GP. The natural gradient is expected to be efficient when the underlying coordinate system is non-orthonormal (Amari, 1998). Starting with the gradient descent iteration derived from the backward Euler method in (3), which is computationally hard, the argument in this paper goes on to propose two methods: the Semi-Backward Euler method via a second-order Taylor approximation to the backward Euler scheme (Proposition 3), and RWP in (4) via approximation (dropping of the gradient constraint and finite-difference approximation in the integral with respect to $t$) of an alternative simpler formulation for the Wasserstein metric (Proposition 4). These two methods involve different approximations to the Semi-Backward Euler, and one would like to know why the approximations in the latter method is better in performance than those in the former. Discussion on this point is however missing in this paper.\n\nIn Section 3, it would have been better if the performance be compared not only in terms of FID but also the loss considered (i.e., Wasserstein-1), since the latter is exactly what the algorithms are trying to optimize.\n\nMinor points:\n\nPage 4: The line just after equation (4) should be moved to the position following the equation giving $d(\\theta_0,\\theta_1)^2$.\n\nIn the reference list, the NIPS paper by Gulrajani et al. appears twice.', 'The authors propose a new GAN procedure. It\'s maybe easier to reverse-engineer it from the simplest of all places, that is p.16 in the appendix which makes explicit the difference between this GAN and the original one: the update in the generator is carried out l times and takes into account points generated in the previous iteration. \n\nTo get there, the authors take the following road: they exploit the celebrated Benamou-Brenier formulation of the W2 distance between probability measures, which involves integrating over a vector field parameterized in time. The W2 distance which is studied here is not exactly that corresponding to the measures associated with these two parameters, but instead an adaptation of BB to parameterized measures (""constrained""). This metric defines a Riemannian metric between two parameters, by considering the resulting vector field that solve this equation (I guess evaluated at time 0). The authors propose to use the natural gradient associated with that Riemannian metric (Theorem 2). Using exactly that natural gradient would involve solving an optimal transport problem (compute the optimal displacement field) and inverting the corresponding operator. The authors mention that, equivalently, a JKO type step could also be considered to obtain an update for \\theta. The authors propose two distinct approximations, a ""semi-backward Euler formulation"", and, next, a simplification of the d_W, which, exploiting the fact that one of the parameterized measures is the push foward of a Gaussian, simplifies to a simpler problem (Prop. 4). That problem introduces a new type of constraint (Gradient constraint) which is yet again simplified.\n\nIn the end, the metric considered on the parameter space is fairly trivial and boils down to the r.h.s. of equation 4. It\'s essentially an expected squared distance between the new and the old parameter under a Gaussian prior for the encoder.  This yields back the simplification laid out in p.16.\n\nI think the paper is head over heels. It can be caricatured as extreme obfuscation for a very simple modification of the basic GAN algorithm. Although I am *not* claiming this is the intention of the authors, and can very well believe that they found it interesting that so many successive simplifications would yield such a simple modification, I believe that a large pool of readers at ICLR will be extremely disappointed and frustrated to see all of this relatively arduous technical presentation produce such a simple result which, in essence, has absolutely nothing to do with the Wasserstein distance, nor with a ""Wasserstein natural gradient"".\n\nother comments::\n\n*** ""Wasserstein-2 distance on the full density set"": what do you mean exactly? that d_W(\\theta_0,\\theta_1) \\ne W(p_{\\theta_0},p_{\\theta_1})? Could you elaborate where this analogy breaks down? \n\n*** It is not clear to me why the dependency of \\Phi in t has disappeared in Theorem 2. It is not clear either in your statement whether \\Phi is optimal at all for the problem in Theorem 1.\n\n*** the ""semi-backward Euler method"" is introduced without any context. The fact that it is presented as a proposition using qualitative qualifiers such as ""sufficient regularity"" is suspicious. ']","[-20, -20, -70]","[50, 60, -20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting direction and clear motivation, they express several concerns and are not fully convinced by the proposed method. The reviewer points out theoretical uncertainties, lack of clarity in illustrations, and insignificant differences in simulation results. However, the tone is not entirely negative, as they also offer constructive feedback and encouragement for further studies. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'I would like to know' and 'I encourage more simulation studies', which maintain a polite and constructive tone. The reviewer also acknowledges positive aspects of the paper before presenting their concerns, which is a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects like originality and clarity, they express significant concerns about the paper's justification, efficiency, and comparative results. The reviewer uses phrases like 'embarrassing to me' and notes missing discussions, indicating disappointment with certain aspects. However, they also highlight pros and recognize the paper as 'basically clearly written'. The politeness score is moderately positive (60) as the reviewer maintains a professional tone throughout, using respectful language like 'would have been better' and 'one would like to know'. They provide constructive criticism and specific suggestions for improvement, which is considerate. The reviewer also acknowledges positive aspects before diving into critiques, which is a polite approach in academic reviews."", ""The sentiment score is -70 because the reviewer expresses significant disappointment and frustration with the paper, describing it as 'head over heels' and criticizing it for 'extreme obfuscation' of a simple modification. They suggest that readers will be 'extremely disappointed and frustrated' by the paper's approach. The politeness score is -20 because while the reviewer maintains some professional language, there are several instances of blunt criticism and dismissive phrasing, such as 'caricatured as extreme obfuscation' and 'absolutely nothing to do with the Wasserstein distance'. The reviewer does attempt to soften some criticisms ('I am *not* claiming this is the intention of the authors'), but the overall tone remains quite critical and somewhat impolite.""]"
"[""The paper proposes a technique (well, two) to prune convolutional layers to reduce the required amount of computation when  the convolutions are done using the winograd algorithm. Winograd convolutions first transform the image and the filter, apply a multiplication in the transformed space, and then retransform the image back to the intended image space. The transformation of the filter, however, means that sparsity in the regular domain does not translate to sparsity in the winograd domain.\n\nThis paper presents two techniques to achieve sparsity in the winograd domain: approximating winograd sparsity based on sparsity in the regular domain (thereby pruning with a non uniform cost model) and pruning in winograd space directly. The actual implementation alternates the first pruning technique and retraining the network with fixed sparsity followed by alternating winograd-space pruning and retraining. The tricky part is retraining in winograd space, which seems to require fine tuned per coordinate learning rates.\n\nMy main concern is that the method feels fairly fragile and hyperparameter-heavy: tuning all the learning rates and sparsity rates for all these iterated levels of pruning doesn't seem easy. Similarly, it's unclear why the first stage of pruning is even needed if it's possible to prune and fine tune in winograd space directly. It's unclear from reading the paper how, given a computational budget, to decide the time spent in each phase of the process.\n\n"", 'Review of Spatial-Winograd Pruning Enabling Sparse Winograd Convolution\n\nSummary:\nIn this submission, the authors propose a new method for pruning weights in the presence in CNNs in which the convolution is expressed as a CNN. The goal of the project is to demonstrate that they can achieve a network which contains fewer weights (and runs faster) then the original network with minimal sacrifice in network performance and without altering the network architecture.\n\nMajor Comments:\nMy largest comments and concerns revolve around the degree to which the proposed pruning methods results in a model that is applicable for real world devices.\n\n1. At the minimum, the authors should provide a table with the number of parameters in the (a) original networks, (b) network with baseline pruning method and (c) network with their pruning methods. (Are the savings entirely in convolutional filters or are there savings from fully connected layers?)\n\n2. If the authors are indeed arguing that a goal of network pruning is to perform faster inference, then results must be shown to justify this -- as it is not obvious that speed-ups could be achieved by just pruning weights. In the case of other methods, speed-ups may be achieved by selectively pruning channel filters (as opposed to spatial positions in the convolutional filter) or pruning fully connected layers (in fact, for VGG and AlexNet, a majority of the reduction in parameters due to pruning were found in these layers).\n\n3. Are these levels of sparsity useable in a real-world system? Often the degree of sparsity in ""vanilla"" CNNs are at levels (e.g. in AlexNet, 30-50% sparsity in higher layers) not high enough to be harnessed for a fast implementation. Selectively zero-ing out individual spatial components of a filter might reduce the parameter count but not achieve any speed up gains. That is, the sparsity must be structured in such a way as to permit a faster implementation [e.g. 1]\n\n4. Considering that one of the baselines changes the network architecture itself [2], I would be curious to understand how effective this method is versus other, simple baselines that change the network architecture such as (1) decreasing the number of filter, (2) decreasing the kernel sizes, (3) swapping a convolutional filter for a separable convolution [3, 4]. All of these baselines are simple to train and experiment with and a practitioner would probably consider in many situations where speed or # parameters are a constraint.\n\nMinor Comments:\n\n- It is unclear from the presentation whether both proposed pruning methods may be trained in tandem or in series. Please clarify in the manuscript.\n\n- Why does Figure 3a, 3b focus on maintaining 20% sparsity on the 1st layer of the network systematically all other layers in sparsity? What is special about the first layer?\n\n- Why do the authors explore a different range of sparsities in Figure 3a and Figure 3b?\n\n- The authors should discuss the source of the variability (and non-monotonicity) in the plots in Figure 3 and 4 for their proposed method. How are we to interpret this? Naively, it would be appear that the method is somewhat unpredictable in performance across a range of sparsity.\n\n- Why do the blue and purple curves in Figure 4 not space the entire range of sparsities?\n\n- Figure 5b. What is the relative accuracy measured with respect to? The baseline model at that particular epoch or at final asymptotic performance?\n\n[1] Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\nhttps://openreview.net/forum?id=B1ckMDqlg\n\n[2] Efficient sparse-winograd convolutional neural networks.\nXingyu Liu, Jeff Pool, Song Han, and William J Dally.\n\n[3] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\nAndrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam\nhttps://arxiv.org/abs/1704.04861\n\n[4] Xception: Deep Learning with Depthwise Separable Convolutions\nFrançois Chollet\nhttps://arxiv.org/abs/1610.02357\n', 'In this paper, the authors propose a spatial-Winograd pruning framework, consisting of spatial structured pruning and Winograd direct pruning.  First, spatial structured pruning allows the pruned weight in the spatial domain to be kept in the Winograd domain. Then, Winograd direct pruning can further improve the sparsity in the Winograd domain. The organization of paper is OK.  The main concern is about the practical part. In the experiment, the advantage of propose framework is marginal, compared to the relevant approaches.  More comparisons with the state-of-the-art approaches should be investigated, such as light-weight design (MobileNet, ShuffleNet).  ']","[-20, -20, -20]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and explains the proposed techniques, they express concerns about the method's fragility and complexity. The phrase 'My main concern' indicates a critical view, and the reviewer questions the necessity of certain steps and the practicality of implementation. However, the score is not deeply negative as the reviewer does provide a detailed and fair explanation of the paper's content. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present their concerns as observations rather than harsh criticisms, using phrases like 'it's unclear' instead of more confrontational language. The review focuses on the content and methodology without personal attacks or overly negative language, demonstrating a polite approach to academic critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' work, they express several major concerns and criticisms about the practical applicability of the proposed method. The review starts with a neutral summary but then lists multiple significant issues and requests for additional information and justification. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would be curious to understand' and 'Please clarify' which are polite ways of requesting more information. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism. The language is formal and avoids any personal attacks or overly harsh statements, contributing to the overall politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper's organization is 'OK', they express a 'main concern' about the practical part and state that the advantage of the proposed framework is 'marginal'. They also suggest that more comparisons should be made, indicating that the current work is not comprehensive enough. The politeness score is slightly positive (20) as the reviewer uses neutral language and doesn't use harsh criticism. They present their concerns as suggestions for improvement rather than outright criticisms. The phrase 'More comparisons... should be investigated' is a polite way of pointing out a limitation in the current work.""]"
"[""This paper presents a technique for embedding words in hyperbolic space, which extends previous non-euclidean methods to non-structured data like free text. The authors provide a new gradient based method for creating the embeddings and then evaluate them on standard word embedding benchmarks. Overall the paper is very well written and well executed. They find that in the low dimensions the approach outperforms standard Euclidean space methods while in higher dimensions this advantage disappears.\n\nThe results do not try to claim state of the art on all benchmarks, which I find refreshing and I appreciate the authors candor in giving an honest presentation of their results. Overall, I enjoyed this paper and am eager to see how the authors develop the approach further. \n\nHowever, along these same lines it would be great to have the authors provide more discussion about the next steps and potential applications for this approach. Is the interest here purely methodological? Are there potential use cases where they believe this approach might be superior to Euclidean approaches? More detail in the discussion and intro about the trajectory of this work would help the reader understand the methodological and application-specific implications. \n\nPros:\n- Clearly written and results are presented in a straightforward manner. \n- Extension of analogy reasoning to non-euclidean spaces.\n\nCons:\n- Lack of clear motivation and compelling use case. \n- It would be nice to have a visualization of the approach in 2-dimensions. While Figure 3 is instructive for how analogies work in this space, it would be great to visualize an entire dataset. I'm sure that the proposed embeddings would result in  a very different space than euclidean embeddings (as the Poincare embedding paper showed), so it would be great to have at least one visualization of an embedded dataset. Presumably this would play to the strengths of the approach as it excels in lower dimensions. \n-  The largest of embedding dimension tested was 100, and it is common to use much larger embeddings of 500-d. Do the trends they observe continue to larger dimensions, e.g. is the performance gap even larger in higher dimensions? "", 'The paper proposes an algorithm that learns word embeddings in hyperbolic space. It adopts the Skip-Gram objective from Word2Vec on the hyperboloid model and derives the update equations for gradients accordingly. \nThe authors also propose to compute the word analogy by parallel transport along geodesics on the hyperboloid.\n\nStrength: The paper is well written, both the background geometry and the derived update method are clearly explained. The novelty and theoretical contribution are adequate. \n\nWeakness: My main concern is the lack of motivation for embedding words on the hyperboloid and the choice of evaluation metrics. For Poincare embeddings, the disc area and circle length grow exponentially with their radius, and the distances on the Poincare disk/ball reflect well the hierarchical structure of symbolic data, which make it natural to embed a graph in this space and lead to great evaluation results. The geometric property of the hyperboloid model, however, does not seem to in favor of encoding non-hierarchical semantics of words and the evaluation on word similarity/analogy tasks. The evaluation results in Table 1 and Table 2 show that the hyperbolic embeddings only performs better than the Euclidean embeddings in low dimensions but worse on higher dimensions (>50), while higher dimension embeddings generally encode more semantics and thus are used in downstream tasks. It will be great if the authors could elaborate on the advantages of learning word embeddings in hyperbolic space and evaluate accordingly. ', ""The present paper aims to apply recent developments in hyperbolic embeddings of graphs to the area of word embeddings.\n\nThe paper is relatively clearly written and looks technically correct. The main contribution of the paper is in suggesting the usage of Minkowski dot-product instead of Eucledian dot-product in skip-gram model and derivation of corresponding weight update formulas taking into account the peculiarities of hyperbolic space. The suggested aproach is realtively simple, though requiring adding additional bias parameter, which doesn't look entirely natural for the problem considered. I should note, that all the update equations are relatively straitforward given the results of recent papers on hyperbolic embeddings for graphs. Experimental results show some mild to no improvement over classical skip gram model in word similarity and word analogy problems.\n\nMy main concern about the paper is that it is not entirely clear throughout the text why the proposed model should be better than any of the baselines. Currently it lookss like the paper merging 2 ideas without any clear expalanation why they should work well together. I believe that the proposed approach (or similar one) might be useful for practice of natural language processing, but to asses that one would need to base on clear motivation and support this motivation with some examples showing that hyperbolicity indeed helps to capture semantics better (like famous world analogy examples for word2vec).\n\nPros:\n- clearly written\n- technically correct\nCons:\n- technically straightforward\n- not convincing experiments\n- unclear, why the approach should work""]","[80, 20, -20]","[90, 80, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses overall approval of the paper, describing it as 'very well written and well executed' and stating they 'enjoyed this paper'. They also appreciate the authors' honesty in presenting results. The few criticisms are constructive and presented as suggestions for improvement rather than major flaws. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and encouraging tone. They use phrases like 'I appreciate', 'I find refreshing', and 'it would be great', which convey politeness and constructive feedback. The reviewer balances praise with suggestions for improvement in a considerate manner, maintaining a professional and courteous tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths, such as being well-written and having clear explanations. However, the reviewer also expresses concerns about the lack of motivation and choice of evaluation metrics, which prevents a higher positive score. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing weaknesses, and uses phrases like 'It will be great if' when suggesting improvements. The reviewer maintains a professional and constructive tone without using any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'technically correct'), they express significant concerns about the paper's motivation, experimental results, and overall convincingness. The reviewer uses phrases like 'main concern', 'not entirely clear', and 'not convincing experiments', indicating a generally critical stance. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I believe' and 'I should note' to soften criticisms. They also acknowledge positive aspects before presenting concerns, which is a polite approach. The language is not overly formal or deferential, but it avoids any rudeness or harsh criticism, striking a balance between honesty and courtesy.""]"
"[""This paper proposes a WAE variant based on a new statistical distance between the encoded data distribution and the latent prior distribution that can be computed in closed form without drawing samples from the prior (but only when it is Gaussian). The primary contribution is the new CW statistical distance, which is the l2 distance between projected distributions, integrated over all possible projections (although not calculated as so in practice).  \n  \nPlugging this distance into the WAE produces similar performance to existing WAE variants, but does not really advance the existing achievable performance.  Overall, I quite liked the paper and think it is well-written, but I believe the authors need to highlight at least one practical advance introduced by the CW distance (in which case I will raise my score). Some potential options include:\n\n1) Faster training times. It seems to me one potential advantage of the closed-form distance would be that the stochastic WAE-optimization can converge faster (due to lower-variance gradients).  However, the authors only presented per-batch processing times as opposed to overall training time for these models.   \n\n2) Stabler training. Perhaps sampling from the prior (as needed to compute statistical distances in the other WAE variants) introduces undesirable extra variance in the training procedure. The authors could run each WAE training process K times (with random initialization) to see if the closed-form distance enables more stable results.\n\n3) Usefulness of the CW distance outside of the autoencoder context.\nSince the novelty of this work lies in the introduction of the CW distance, I would like to see an independent evaluation of this distance as a  general statistical distance measure (independently of its use in CWAE). Can you use this distance as a multivariate-Gaussian goodness of fit measure for high-dimensional data drawn from both Gaussian and non-Gaussian distributions and show that it actually outperforms other standard statistical distances (e.g. in two-sample testing power)?\n\nWithout demonstrating any practical advance, this work becomes simply another one of the multitude of V/W-AE-variants that already exist.\n\nOther Comments:\n\n- While I agree that standard WAE-MMD and SWAE require some form of sampling to compute their respective statistical distance, a variant of WAE-MMD could be converted to a closed form statistical distance in the case of a Gaussian prior, by way of Stein's method or other existing goodness-of-fit measures designed specifically for Gaussians. See for example: \n\nChwialkowski et al: https://arxiv.org/pdf/1602.02964.pdf\n\nwhich like CW-distance is also a quadratic-time closed-form distance between samples and a target density.\n\nBesides having closed form in the case of a Gaussian prior (which other statistical distances could potentially also achieve), it would be nice to see some discussion of why the authors believe their CW-distance is conceptually superior to such alternatives. \n\n- Silverman's rule of thumb is only asymptotically optimal when the underlying data-generating distribution itself is Gaussian. Perhaps you can argue here that due to CLT: the projected data (for high-dimensional latent spaces) should look approximately Gaussian?\n\nAfter reading the revision: I have raised my score by 1 point and recommend acceptance."", 'The paper introduces a novel regularized auto-encoder architecture called the Cramer-Wold AutoEncoders (CWAE). It\'s objective (Eq. 7) consists of two terms: (i) a standard reconstruction term making sure the the encoder-decoder pair aligns nicely to accurately reconstruct all the training images and (ii) the regularizer, which roughly speaking requires the encoded training distribution to look similar to the standard normal (which is a prior used in the generative model being trained). The main novelty of the paper is in the form of this regularizer. The authors introduce what they call ""the Cramer-Wold distance"" (for definitions see Theorems 3.1 and 3.2) which is defined between two finite sets of D-dimensional points. The authors provide empirical studies showing that the proposed CWAE method achieves the same quality of samples (measured with FID scores) as the WAE-MMD model [1] previously reported in the literature, while running faster (by up to factor of 2 reduction in the training time, as the authors report). \n\nWhile on the AE model / architecture side I feel the contribution is very marginal, I still think that the improvement in the training speed is something useful. Otherwise it is a nicely written and polished piece of work. \n\nDetailed comments:\n(1) My main problem with this paper is that the novel objective proposed by the authors in Eq. 7 is equivalent to the objective of WAEs appearing in Eq. 4 of [1] (up to a heuristic of applying logarithm to the divergence measure, which is not justified but meant to ""improve the balance between two terms"", see footnote 2), where the authors use the newly introduced Cramer-Wold divergence as a choice of the penalty term in Eq. 4 of [1]. \n(2) When viewed in this way, CW-distance introduced in Eq (2) closely resembles the unbiased U-statistic estimate of the MMD used in WAE-MMD [1, Algorithm 2]. In other words: it may be the case that there is a choice of a reproducing kernel k such that Eq. 2 of this paper is an estimate of MMD_k between two distributions based on the i.i.d. samples X and Y. Note that if it is indeed the case, this corresponds to the V-statistic and thus biased: in U-statistic the diagonal terms (that is i = i\' and j = j\' in forst two terms of eq 2) would be omitted. If this all is indeed the case, it is not surprising that the numbers the authors get in the experiments are so similar to WAE-MMD, because CWAE would be exactly WAE-MMD with a specific choice of the kernel. \n(3) The authors make a big deal out of their proposed divergence measure not requiring samples from the prior as opposed to WAE-MMD. However, WAE-MMD does not necessarily need to sample from the prior when used with Gaussian prior and Gaussian RBF kernel, because in this case the prior-related parts of the MMD can be computed analytically.  In other words, if the computational advantage of CWAE compared to WAE-MMD comes from CWAE not sampling Pz, the computational overhead of WAE-MMD can be eliminated at least in the above-mentioned setting.\n(4) based on the name ""CW distance"" I would expect the authors to actually prove that it is indeed a distance (i.e. all the main axioms). \n(5) The authors override the CW distance: first in Theorem 3.1 they define it as a distance between two finite point clouds, and later in Theorem 3.2 they redefine it as a distance between a point cloud and the Gaussian distribution. \n(6) What is image(X) in Remark 4.1?\n\n[1] Tolstikhin et al., Wasserstein Auto-Encoders, 2017.', ""This paper proposes the Cramer-Wold autoencoder. The first contribution of the paper is to propose the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem. More specifically, in order to compute the Cramer-Wold distance, we first find the one dimensional projections of the distributions over random slices, and then compute the average L2 distances of the kernel density estimates of these projections over random slices. The second contribution of the paper is to develop a generative autoencoder which uses the Cramer-Wold distance to match the latent distribution of the data to the prior distribution.\n\nWhile I found the derivation of the Cramer-Wold distance interesting, the final form of this distance (Eq. 2), to me, looks very similar to the MMD with a particular kernel. My main question is that: what is the main advantage of the Cramer-Wold distance to an MMD with a proper kernel?\n\nThe paper points out that the main theoretical contribution is that in the case of the Gaussian distribution, the Cramer-Wold distance has a closed form. However, I believe this is also the case in the MMD, since if one of the distributions is Gaussian or analytically known, then E[k(x,x')] in the MMD can be analytically computed.\n\nThe paper further uses this closed form property of the Cramer-Wold distance to propose the Cramer-Wold autoencoder with Gaussian priors. My question here is that how is this method better than the standard VAE, where we also have an analytic form for the ELBO when the prior is Gaussian, an no sampling is required. Indeed, in VAEs, the prior does not have to be Gaussian, and as long as the density of the prior can be evaluated, we can efficiently optimize the ELBO without sampling the prior; which I don't think is the case for the Cramer-Wold autoencoder. I believe the main advantages of methods such as WAE is that they can impose priors that do not have exact analytic forms.""]","[50, -20, -20]","[80, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer states they 'quite liked the paper' and think it is 'well-written', but they also express concerns about the lack of practical advances and request additional demonstrations of the method's usefulness. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They use phrases like 'I believe the authors need to' and 'Perhaps you can argue' which maintain a collegial tone. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nicely written and polished piece of work', 'improvement in the training speed is something useful'), they express several criticisms and concerns about the novelty and contribution of the work. The overall tone suggests that the reviewer finds the paper's contribution to be 'very marginal'. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'I feel' and 'I think' to soften criticisms, and acknowledging positive aspects before presenting concerns. The reviewer also provides detailed, constructive feedback, which is a polite way to help improve the paper. However, the language is not overly effusive or extremely polite, maintaining a neutral professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper, they raise several critical questions and express skepticism about the advantages of the proposed method over existing techniques. The reviewer's tone is not overtly negative, but their questions suggest they are not fully convinced of the paper's contributions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work, and framing their criticisms as questions rather than direct criticisms. They use phrases like 'I found... interesting' and 'My main question is...' which maintain a polite and professional tone while still expressing their concerns.""]"
"['This paper proposed a general framework, DeepTwist, for model compression. The so-called weight distortion procedure is added into the training every several epochs. Three applications are shown to demonstrate the usage of the proposed approach.\n\nOverall, I think the novelty of the paper is very limited, as all the weight distortion algorithms in the paper can be formulated as the proximal function in proximal gradient descent. See http://www.stat.cmu.edu/~ryantibs/convexopt-S15/scribes/08-prox-grad-scribed.pdf for a reference.\n\nSpecifically, the proposed framework can be easily reformulated as a loss function plus a regularizer for proximal gradient. Using gradient descent (GD), there will be two steps: (1) finding a new solution using GD, and (2) project the new solution using proximal function. Now in deep learning, since SGD is used for optimization, several steps are need to locate reasonable solutions, i.e. the Distortion Step in the framework. Then proximal function can be applied directly after Distortion Step to project the solutions. In this way, we can easily see that the proposed framework is a stochastic version of proximal gradient descent. Since SGD is used for training, several minibatches are needed to achieve a relatively stable solution for projection using the proximal function, which is exactly the proposed framework in Fig. 1.\n\nPS: After discussion, I think the motivation of the method is not clear to understand why the proposed method works.  ', 'A model compression framework, DeepTwist, was proposed which makes the weights zero if they are small in magnitude. They used different model compression techniques in this framework to show the effectiveness of the proposed method. \n\nThis paper proposes a framework intending to use fewer hardware resources without compromising the model accuracy. However, when the weights are set to zero the weight matrix became sparser but still requires the whole weight matrix to be used by the computing resources, as removing some of the weights based on the sorting will not remove a node, only removes some of the connection with that node. Therefore, it is not clear how the proposed framework is helping the model compression techniques.  \n', 'The paper does not really propose a new way of compressing the model weights, but rather a way of applying existing weight compression techniques. Specifically, the proposed solution is to repeatedly apply weight compression and fine-tuning over the entire training process. Unlike the existing work, weight compression is applied as a form of weight distortion, i.e. the model has the full degree of freedom during fine-tuning (to recover potential compression errors). \n\nPros:\n\n- The proposed method is shown to work with existing methods like weight pruning, low-rank compression and quantization.\n\n\nCons:\n\n- The idea is a simple extension of existing work.\n- In Table 4, it is hard to compare DeepTwist with the other methods because activation quantization is not used.\n  ']","[-60, -50, -20]","[20, 0, 50]","[""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's novelty, stating it is 'very limited' and that the proposed framework can be easily reformulated as an existing method. The reviewer also mentions that the motivation of the method is unclear. However, it's not entirely negative as they acknowledge the paper's proposed framework and applications. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I think' to soften their criticism and provide explanations for their views. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone."", ""The sentiment score is -50 because the review expresses significant skepticism about the effectiveness of the proposed framework. While the first paragraph neutrally describes the method, the second paragraph raises a critical concern about how the framework actually helps with model compression. The reviewer states that 'it is not clear how the proposed framework is helping the model compression techniques,' which indicates a negative sentiment towards the paper's main contribution. However, the criticism is not extremely harsh, hence a moderately negative score rather than a strongly negative one. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer presents their concerns in a straightforward, professional manner without using overly courteous language or harsh criticism. The tone is matter-of-fact and focused on the technical aspects of the paper."", ""The sentiment score is slightly negative (-20) because the review starts by stating that the paper doesn't propose a new compression method, but rather applies existing techniques. It also lists more cons than pros. However, it's not entirely negative as it does acknowledge some positive aspects. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language without harsh criticism. They objectively state pros and cons without using inflammatory or rude language. The reviewer maintains a respectful tone throughout, even when pointing out limitations of the work.""]"
"['The paper proposes the use of Survival Continuous Ranked Probability score instead of maximum likelihood estimation for personalised probabilistic forecasts of time-to-event data, thus estimating a distribution over future time. The authors describe the evaluation their method using (1) proper scoring rule objectives; (2) evaluation of calibration using sharpness as a metric; (3) the survival precision recall curve. The authors then apply these techniques to predicting time-to-mortality using an RNN that takes EHR patient records to predict the probability of death at a given time point. It’s not clear how this is related to the Survival CRPS model or how this model is incorporated into the RNN.\nOverall, this is an important framework for estimating personalised predictions of survival events for patients with interval-censored data. The authors present a well thought-out paper with clearly and realistically articulated modelling  assumptions. The authors also give an excellent critique of the underlying assumptions of current state-of-the-art survival methods. The authors are also to be commended for the mathematical elegance \nAlthough the paper is very well written and extremely well structured, I struggled with the lack of experiments available in the paper.\nThe text embedded in Figure 3 is too small. \nThe results section is somewhat sparse. Although the mathematical formulation is well-motivated and structured, it’s not clear what the contribution of this work is. The difference between CRPS-INTVL and MLE-INTVL is incremental and it’s unclear what the significant benefits are of CRPS vs MLE. What would the interpretation of these differences in a real-world setting? \n', ""The authors introduce an extension of Continuous Ranked Probability Scores (CRPS) to the time-to-event setting termed Survival-CRPS for both right censored and interval-censored event data. Further, the authors introduce a scale agnostic Survival-AUPRC evaluation metric that is analogous to the precision-recall curve used in classification and information retrieval systems/models.\n\nThe claim that that the proposed approach constitutes the first time a scoring rule other than maximum likelihood seems too strong, unnecessary and irrelevant to the value of the presented work.\n\nIt is not clear how did the authors handle the irregularity (in time) of EHR encounters in the context of an RNN specification. Also, if the RNN specification considered is similar to Martinsson, 2016, why this wasn't considered as a competing model in the experiments?\n\nIn Table 1 , it is not clear what the error bars are also they seem too small.\n\nThe proposed approach addresses important questions in time-to-event modeling, namely, calibration and interval censoring. Although the connection with CRPS is interesting (first of the two equations in page 3), it is quite similar to an accelerated failure time formulation, which for a log-normal specification is standard and popular due to similar reasons to those highlighted by the authors, but not mentioned in the related work. The interval censoring is also interesting, though straightforward and perhaps not as relevant in more general time-to-event settings where events other than age are considered.\n\nThe Survival-AUPRC is not sufficiently motivated. Without motivation or an intuition of why it should be used/preferred, it seems disconnected from the rest of the paper and its contributions.\n\nWithout a more comprehensive evaluation that includes additional datasets and competing models (described in the Related Work Section) it is difficult to assess the value of the proposed approach."", ' My main concern is that the authors fail to compare their appproach to any of the modelling approaches discussed in the related works section. In particular, as mentioned by the authors the WTTTE-RNN has a similar architecture and thus would have been a crucial baseline for comparisons.\n Furthermore, I would have liked to see an evaluation on more datasets, especially since the data in Appendix H indicate that the proposed approach is only marginally better than MLE-based model fitting.\nFinally, in addition to the metrics presented, conventional metrics such as the C-statistic would have been interesting.\n\nI further miss a discussion of alternative approaches to achieve well calibrated scores, especially posthoc calibration using the validation set as discussed in Guo et al, ICML 2017.\n\nRelated work is incomplete, for example the use of tensor-trains in RNNs to model EHR data (Yang et al) - would the proposed approach not benefit for the use of such tensorization to better model the high-dimensional, sparse EHR data?\n\n\nreferences:\nGuao et al, On Calibration of Modern Neural Networks, ICML 2017\nYang et al, Modeling progression free survival in breast cancer with tensorized recurrent neural networks and accelerated failure time models, Machine Learning for Healthcare Conference 2017', 'The paper presents a new loss function for survival analysis based\non proper scoring functions to less then penalty wrong predictions\nthat are confident make under the log-loss. The paper is interesting\nhowever the benefit over the traditional maximum likelihood estimator is small and the writing needs a bunch of work. I would also like to see an eval on data with far less censoring.\n\n\nA couple of comments\n\n1) EHRs have only been generally adopted in the last couple of years. Only A couple of places have more.\n\n2) Binary classifier citation on page 1 (Avati, Rajkomar) should also cite the plethora of recent machine\nlearning for healthcare results in this field\n\n3) Likelihoods are calibrated (as is any error measured by a proper scoring loss)\n\n4) There are other methods to fit survival functions such as ""Adversarial Time-to-Event Modeling""\nby Chapfuwa in ICML 2018. There are probably also moment methods\n\n5) I think the evaluation might also want utilty because sharpness is a utility claim\n\n6) Some of the statements in the writing are funny like probability distributions are uniquely identified by parameters. I\'m not sure this is true with neural nets with symmetries. The paper doesn\'t need such claims\n\n7) Instead of log-normals, I would like to see something nonparametric like the categoricals\xa0 used for maximum likelihood estimation without latents in the limiting model in ""Deep Survival Analysis: Missingness and Nonparametrics"" by Miscouridou at MLHC 2018\n']","[50, -20, -50, -20]","[80, 50, 0, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance and mathematical elegance of the paper, praising its structure and articulation. However, they also express concerns about the lack of experiments and sparse results section, which tempers the overall positivity. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, offering praise where due ('well thought-out', 'excellent critique', 'authors are to be commended') and framing criticisms constructively ('I struggled with', 'it's not clear'). The reviewer maintains a professional and courteous tone, even when pointing out areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper addresses important questions and introduces interesting concepts, they also point out several significant criticisms. These include questioning the authors' claims, noting unclear aspects of the methodology, and expressing difficulty in assessing the value of the approach due to limited evaluation. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'it is not clear' and 'without motivation' rather than direct criticisms. They also acknowledge the positive aspects of the work before presenting their concerns. The language is constructive and aimed at improving the paper rather than being dismissive."", ""The sentiment score is -50 because the review expresses several concerns and criticisms about the paper, such as the lack of comparison to existing approaches, limited dataset evaluation, and incomplete related work. However, it's not entirely negative as it also suggests improvements and additional metrics to consider. The politeness score is 0 (neutral) because the language used is professional and objective, without being particularly polite or rude. The reviewer directly states their concerns and suggestions without using overly harsh language or excessive praise."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they also point out several shortcomings. The reviewer states that the benefit over traditional methods is small, the writing needs work, and they request additional evaluations. This indicates a generally critical stance, albeit not entirely negative. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use phrases like 'I would like to see' and 'I think', which are polite ways of making suggestions. The reviewer also provides specific, constructive feedback without using harsh language. However, some statements like 'Some of the statements in the writing are funny' could be perceived as slightly condescending, preventing a higher politeness score.""]"
"[""This paper aims to test the robustness of generative classifiers [1] w.r.t. adversarial examples, considering their use as a potentially more robust alternative to adversarial training of discriminative classifiers. To achieve this, *Deep Bayes*, a generalization of the Naive Bayes classifier using a latent variable model and trained in a fashion similar to variational autoencoders [2] is introduced, and 7 different latent variable models are compared, covering a spectrum of generative or discriminative classification models, with or without bottlenecks. Their DFX and DBX architectures in particular closely match traditional discriminative classifiers, without and with a latent bottleneck.\n\nThese 7 models are compared against a large range of adversarial attacks, depending on the kind of noise added (l_2 or l_inf) and how much the adversary can access (the full gradients of the model, its output on training data, or only the model as a black-box). The performance of the models is assessed depending on two criteria: how the performance of the classifier resists to adversarial noise, and how quickly the model can detect adversarial samples. Three methods for detecting adversarial samples are compared: the first (only applicable to generative classifiers) discards samples with a low likelihood, according to the off-manifold assumption [3], the second discards samples for which the classifier has low confidence in its classification (p(y|x) is under some threshold), and the third compares the output probability vector of the classifier on a sample to the mean classification vector of this class over the train data, and discards the sample if the two vectors are too dissimilar (meaning the classifier is over-confident or under-confident).\n\nThe main contribution of this paper is the extensive experiments that have been done to compare the models against the various adversarial attacks. While experiments were only done on small datasets like MNIST and CIFAR (generative classifiers don't scale as easily on large image datasets), they nonetheless give very interesting insights and the authors provided encouraging results on applying generative classifiers on features learned by discriminative classifiers. Theirs result shows that generative architecture are in general more robust to the current state-of-the-art adversarial attacks, and detect adversarial examples more easily. The authors also recognize that these results may be biased by the fact that current adversarial attacks have been specifically optimized towards discriminative classifier.\n\nThis is a solid paper in my opinion. The experimental setup and motivations are clearly detailed, and the paper was easy to follow. Extensive results and description of the experimental protocol are provided in the appendices, giving me confidence that the results should be reproducible. The results of this paper give interesting insights regarding how to approach robustness to adversarial examples in classification tasks, and provide realistic ways to try and apply generative classifiers in real-worlds tasks, using pre-learned features from discriminative networks.\n\n\n[1] http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf\n[2] https://arxiv.org/abs/1312.6114\n[3] https://arxiv.org/abs/1801.02774"", 'In this work the authors propose and analyse generative models as defences against adversarial examples. In addition, three detection methods are introduced and an extension to deep features is suggested.\n\nMy main concerns are as follows (details below):\n* Important prior work is not mentioned.\n* Evaluation with direct attacks is only based on (very few) gradient-based techniques, many results are not reliable.\n* There are signs of gradient masking (the common problem of robustness evaluation, in particular of only gradient-based techniques are used).\n* The way detection rates are taken into account in the perfect knowledge scenario is confusing.\n\n### Style\nI like the idea of testing many different factorisation structures. However, that comes with the drawback that one needs to constantly check back what the abbreviations mean. Together with the three detection methods, the manuscript is quite confusing at times and should definitely be streamlined. One suggestion: remove the detection methods: I did not find any real conclusion about them but they are definitely side-tracking users away from the main results.\n\n### Prior work\nThere is at least one closely related prior work not mentioned here: the analysis by synthesis model [1]. This model uses a variational auto encoder to learn class conditional distributions and shows high robustness on MNIST. Please make clear what your contribution is over this paper (other than testing several other factorisations).\n\n### Evaluation problems\nThe robustness of models should be evaluated on different direct attacks ranging from gradient-based to score-based (e.g. NES [2]) to decision-based attacks [3]. Please take a look at [1] to see how a very extensive evaluation might look like. The results can be astonishingly different for different attacks, and so basing conclusion on only one or two attacks is dangerous (in particular if you only use gradient-based ones). One can also see that in your results, just check the variations you get between MIM and PGD. Also, rather then discussing (and showing in detail) results for individual attacks, the minimum adversarial distance for a given sample that can be found by any attack is much more comparable between models (which can also streamline the manuscript).\n\nOne can see signs of gradient masking in your results. For example, in Figure 3 the MIM attacks levels out at 20% for the DBX model. That can happen for iterative attacks if the gradient is masked. Similarly, in Figure 5 DBX-ZK (zero knowledge) is better in both accuracy and detection rate than DBX-PKK (which takes the KL-detection method into account and should thus either be better in accuracy or detection rate).\n\nMore generally, the perfect knowledge case, in which the attacker knows about the detector, should only count samples as adversarials which evade the detector and change the model decision. Thus, the detection rate should be zero. Otherwise I have no idea what trade-off between accuracy and detection rate you are actually targeting and how to compare the results.\n\nAlso, some intermediate results are conflicting with each other. E.g. in 4.1 you state “the usage of bottleneck is beneficial for better robustness”, but for L2 this is not true.\n\nAlso, I am not sure how conclusive the grey-box and black-box scenarios really are: since the substitute is basically a DFX or DFZ, it’s unsurprising that adversarials transfer best to those two models.\n\n### Minor\n * In 4.1 you say “as they fail to find near manifold adversarials”, but I don’t see how there can be L-infty adversarials on MNIST that are on-manifold (remember, MNIST pixel values are basically binary). Plus, in the zero-knowledge scenario there is nothing that enforces staying on this manifold.\n * Result presentation (Figure 3/5 & Table 1) is very different for different attack scenarios, which makes them hard to compare. Please unify.\n * Is the L2 distance you report in Table 1 the mean (or median) distance to adversarial examples. If so, GBZ (for which you state that C&W “failed on attacking” has actually a smaller mean adversarial distance than some other models (for which C&W is actually quite successful).\n * Grey-box scenario doesn’t make a lot of sense: since the substitute is basically a DFX or DFZ, it’s unsurprising that adversarials transfer best to those two models. A similar confounder makes the black-box results difficult to interpret.\n* Also, taking into account that the paper is two pages longer and thus calls for higher standards\n\nTaken together, I find the general direction of the paper very interesting and I’d definitely encourage the authors to go further. At the current stage, however, I feel that (1) contributions are not sufficiently delineated to prior work, (2) the evaluation is not convincingly supporting the claims and that  (3) the manuscript needs to be streamlined (both in terms of text and figures).\n\n[1] Schott et al. (2018) “Towards the first adversarially robust neural network model on MNIST” (https://arxiv.org/abs/1805.09190)\n[2] Ilyas et al. (2018) “Black-box Adversarial Attacks with Limited Queries and Information” ( [https://arxiv.org/abs/1804.08598)](https://arxiv.org/abs/1804.08598)) \n[3] Brendel et al. (2018) “Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models” (https://arxiv.org/abs/1712.04248)', 'This work investigates an interesting direction of improving robustness of classifiers against adversarial attacks by using generative models. The authors propose the *deep Bayes classifier*, which is a deep LVM based extension of naive Bayes. Furthermore, the authors extensively explore 7 possible factorisations of the classifier. Thorough experiments are conducted to assess the capability of defending or detecting adversarial examples.  Besides, the authors incorporate discriminative features to generative classifiers and demonstrate clear robustness gain.\n\n### Highlights\n* This work proposes an attractive direction -- the use of generative model in defending or detecting adversarial attacks. I suggest this idea should be follower by more further studies.\n* The presented models are quite straight-forward but exhibit good robustness against attacks listed in the experiments.\n* Various structural possibilities of the graphical model are examined which is preferable and helps assess the effectiveness of generative classifiers.\n\n### Minors\n* Although the major point here is robustness against adversarial attacks, as mentioned by the authors, the performance on clear cases (i.e. no attacks) is unsatisfactory. Also, experiments on CIFAR are too much simplified (only 2 very unlike classes) and therefore not very convincing. \n* For the combination of generative classifier and discriminative features, I’m curious about the results on the clear CIFAR-10 multi-class problem. It should be a very positive plus if results are satisfactory.\n* The writing is sometimes hard to follow. For examples, many ad-hoc abbreviations are used across the paper causing difficulties of understanding the core idea and results.\n\n### Conclusion \nIn general, this paper brings our attention to a previously less investigated but seemingly promising research direction, i.e. robustness of generative model against adversarial attacks. The idea is insightful and proposed models are straight-forward. While only on small-scale  problems (with the presence of attacks), extensive experimental results in this paper can assist further study on this field. Thus, I recommend this paper to be accepted.   \n', 'This paper explores the potential of generative models for adversarial robustness. It presents some interesting and well formulated findings but is lacking in some meaningful ways. \n\n-It does a good job of summarizing the literature though it misses out on some very recent but relevant work\n-It introduces three detection methods and extensively evaluates them  against several zero-knowledge attack types. Notably all the attack types are gradient based methods. \n-They present detailed performance metrics on the zero-knowledge attack, and introduce the perfect knowledge attack but do not present equivalently detailed results.\n-The results are  presented in a confusing manor, and the paper is perhaps done a disservice by the inclusion of a very large number of tables both in the main text and the appendix without the necessary writing required to situate the reader.  \n-The paper also briefly mentions the ongoing debate around ""off-manifold"" conjecture, only to them assume its correctness and based the entire work on the premise. \n\n###Highlights \n*well written introduction and a good overview of generative modeling \n*very good visualizations and explanation of the detection methods \n*thorough results on zero-knowledge gradient based attack detection rates  \n*interesting direction on adversarial examples  \n\n### Areas for improvement \n*more time should be spent on discussing the off manifold conjecture; the paper is based on the correctness of this conjecture though recent work has called its validity into question\n*only gradient based attacks are discussed though the paper title suggests robustness to all attacks\n*perfect-knowledge attacks should be explored in much more detail \n* the paper should streamline the results and findings, the large number of tables and results will confuse the reader and do not add to the argument\n*recent work on generative models for adversarial robustness should be discussed (https://arxiv.org/abs/1805.09190, https://arxiv.org/abs/1811.06969)  \n*the two class cifar10 results are not particularly convincing as this is a substantial simplification of the cifar10 problem \n* the results on the full cifar10 data set make use a the extracted features of a pre-trained discriminative cifar10 network, this introduces the problem at layer activation adversarial attacks, but this is not mentioned in the paper (https://arxiv.org/pdf/1511.05122.pdf)\n\nOverall i think the work shows promise but is not yet ready for acceptance \n\n']","[90, -50, 70, -20]","[80, 20, 80, 50]","[""The sentiment score is 90 because the reviewer describes the paper as 'solid' and provides numerous positive comments about the paper's contributions, clarity, and experimental setup. They mention 'encouraging results' and 'interesting insights', indicating a highly positive view. The politeness score is 80 because the reviewer uses respectful and professional language throughout, acknowledging the authors' work and providing constructive feedback. The tone is consistently positive and supportive, without any harsh criticism. The reviewer also uses phrases like 'in my opinion' which adds a polite, non-confrontational tone to their comments."", ""The sentiment score is -50 because the reviewer expresses several major concerns about the paper, including missing prior work, unreliable evaluation methods, and signs of gradient masking. However, they do mention finding the general direction interesting, which prevents the score from being lower. The politeness score is 20 because the reviewer uses generally polite language ('I like the idea...', 'Please make clear...', 'I'd definitely encourage the authors to go further') and offers constructive criticism. However, the overall critical tone and direct pointing out of flaws prevents a higher politeness score. The reviewer balances criticism with encouragement and provides specific suggestions for improvement, indicating a professional and relatively courteous approach to the review."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its interesting direction, thorough experiments, and potential for future research. They recommend acceptance and describe the work as 'insightful' and 'promising'. However, it's not 100 as they do mention some minor criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions or curiosities rather than harsh judgments. They use phrases like 'I suggest' and 'I'm curious about' which maintain a courteous tone. The review is well-structured with clear sections for highlights, minor issues, and a conclusion, which also contributes to its professional and polite presentation."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting and well formulated findings', 'good job of summarizing the literature'), they also point out several significant shortcomings and conclude that the work is 'not yet ready for acceptance'. The overall tone suggests potential but significant room for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balances criticism with praise, and offers constructive suggestions for improvement. They use phrases like 'well written', 'very good visualizations', and 'interesting direction' to soften their criticisms, and provide specific, actionable feedback for improvement.""]"
"['Summary\n\nThe authors aim to do continual learning to solve dependent tasks using ""single-stage end-to-end learning"". The resulting ""Unicorn"" agent trains on all tasks simultaneously. The idea is to use multi-task ""off-policy learning"", which uses (old) trajectories (experience) from task A to help learning on a related task B. Authors further distinguish between goals (inputs to Q) and tasks (different reward functions). A goal might a color/shape of an object to pick up.\n\nThe core model is a UVFA that learns a goal-conditioned Q-function Q(s,a,g). \n\nSome technical aspects: \n- use n-step returns.\n- when training Q on goal g_i, authors also trajectories that were generated using Q conditioned on another goal(s) g_j. They then truncate the returns for task i when an action taken is not optimal under Q(s,a,g_j) conditioned on goal j. The intuition (seems) to be that this \n- authors do not use experience replay or a target Q-function, since the parallelized implementation is reported to be stable enough.\n- unicorn sees all train task reward functions during training (but not hold out task rewards).\n- unicorn is tested on several 3d maze environments with key-lock etc semantics. The tasks / goals seem simple, and the dependency is defined by changing colors / shapes of objects to be picked up. Authors argue unicorn has to learn to relate task rewards to these goal features.\n- unicorn is compared against baselines that 1) do single-task learning (expert) 2) learn on a sum of task rewards (glutton), 3) uniformly random baseline. \n- authors show that 1) unicorn performs better on train tasks 2) performs better on hold-out tasks. Also, authors show results for zero-shot transfer learning, with adding abstract tasks (extra reward for picking up any object) improving performance, \n\nPro\n- Simple approach (e.g., no experience replay etc), and uses only a limited set of techniques (e.g., reward truncation). \n- Reward performance suggests the model has more properly related goal features to different payoffs.\n- Analysis of qualitative behavior is nice.\n\nCon\n- The writing is a bit dense in places, e.g., the discussion of baselines is a bit hard to read.\n- Description of algorithm is wrapped in long text, a clear algorithm box would make the approach much clearer.\n- Not clear what kind of hyperparameters are introduced / used / tuned for Unicorn. \n- Authors say ""deep dependency"", but this seems to just refer to different colors / shapes between objects in the env used in the paper. How is ""dependency"" between goals and tasks defined in general? \n- The experimental setting seems a bit limited, authors only show results on a single domain, and do not offer rigorous definitions. This makes the scope of the paper rather limited.  \n\nReproducibility: \n- It\'s not clear what the variance in the baseline performance is (variance only shown for unicorn).', 'The paper proposes a novel architecture in the context of multitask learning and deep dependency structure. They try to solve their target issue in reinforcement learning, thus utilize the useful architecture UVFAs (Schaul et al.) since the model is effective to manage multiple policies into single value function. \n\nThe paper is easy to follow, but with quite long explanation. They verify their architecture UNICORN in various learning scenarios, i.e., multitask-learning, generalization to related tasks, and continual learning. And I have several remarks,\n\n- In the learning scenario, I confused that it looks a little bit far from the common definition of continual learning which is referred in machine learning area(learning various tasks in sequence, not simultaneously) but is more like an attribute learning or something.\n\n- It is ambiguous to ensure that the proposed architecture can show state-of-the-art or comparable performance. The compared baselines, such as glutton and random, look too simple and show minor performance as already described in the paper.\n\nThe deep dependency structure setting is quite interesting, also there are many useful discussion and imposing experiments. It would be great to see much clear competitiveness and identity of the architecture.', 'I tried to parse the paper\'s details multiple times but it really seems like a hard task. From what I understand, the paper is doing off-policy learning across several environments. The actors are parallelized across the environments (tasks), collecting rollouts, and the update to the learner is done on a GPU which trains on all these rollouts asynchronously collected. The learner uses a UVFA with an LSTM as its architecture. The authors learn on a set of training environments with various goals (associated with picking specific objects in an order) and test this policy\'s ability to work on new environments with a different set of goals. \n\nOverall, I find the writing really a pain to parse. I wish the authors directly wrote what they are doing quickly: ""We take Schaul\'s UVFA, make it recurrent, use the IMPALA set up of Esspholt, and show generalization to new combinations of objects to be collected as goals"".\n\nI am still trying to evaluate the paper, but for now, my rating for this is low given that the main novelty in the paper: the environments, the evaluations, the tasks are so unclear because of the verbose presentation style on trying to tell us what we already know, such as goal-conditioned learning, off-policy learning, IMPALA, etc. \n\n']","[20, 20, -60]","[50, 60, -20]","[""The sentiment score is slightly positive (20) because the review acknowledges some strengths of the paper ('Pro' section) such as the simplicity of the approach and good performance results. However, it also points out several weaknesses ('Con' section) and limitations in the experimental setting. The overall tone suggests a cautiously positive view with significant room for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout, offering both praise and criticism without using harsh language. The reviewer uses neutral phrases like 'not clear' and 'seems a bit limited' rather than more critical language, indicating a polite approach to feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths, such as being easy to follow, having interesting aspects, and conducting imposing experiments. However, they also express some concerns and confusion, which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and ends with a positive suggestion. They avoid harsh criticism and frame their concerns as 'remarks' rather than outright criticisms. The reviewer's tone is professional and courteous, even when pointing out areas for improvement."", ""The sentiment score is -60 because the reviewer expresses significant frustration with the paper's clarity and presentation, describing it as 'a pain to parse' and giving it a 'low' rating due to unclear novelty and verbose style. However, it's not entirely negative as they do attempt to understand the paper's content. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical, using phrases like 'I wish the authors directly wrote what they are doing' and describing the writing as 'a pain to parse'. The tone is more frustrated than polite, but it doesn't descend into personal attacks or extremely harsh language.""]"
"['Summary:\nThe paper proposes a system of semantic segmentation based on sequential processing of the image in a patch-wise manner with multiple ""actors"", sharing a common external memory. This approach stands in contrast to the more usual approach of single-shot prediction for the whole image, where encoder-decoder architectures or dilated convolutions are used to capture the global context. The authors then discuss three-variants of this method, out of which two use external memory (Bi-MANN, SHAMANN), and one uses memory shared between actors (SHAMANN). Results are presented on segmentation of lung X-ray data and on MNIST digit completion.\n\nComments:\nThe paper is easy to read. The authors cite the relevant literature on the baseline semantic segmentation methods, as well as neural networks with external memories. However, similar patch-wise and sequential methods have been presented in the literature (e.g. https://arxiv.org/abs/1506.07452), including ones with external storage (e.g. https://www.nature.com/articles/s41592-018-0049-4), but these are not discussed as prior work.\n\nOverall, the proposed approach is interesting, but significantly more complex than both the baselines and prior work. As is, the experimental results are not compelling enough to justify this (lack of clear quantitative improvement over state of the art). My recommendation would be to conduct additional experiments on semantic segmentation benchmark datasets. The proposed method seems promising for volumetric data as the authors note, but this also needs to be demonstrated experimentally.\n\nSome more specific & technical questions follow:\n- In Table 1, how is the confidence interval for the Dice score computed?\n- Have any experiments been done with more than 2 actors?\n- How exactly is the patch sequence formed, i.e. what is the spatial order of the patches? How much to the results depend on this order, if at all?\n- In the discussion on page 6, it seems to be implied that the reduced parameter count should allow more efficient application to volumetric data. This is a bit surprising, since with modern networks it is usually the input size that is limiting, not the number of network parameters.\n- Have experiments with Bi-MANN and Bi-LSTM been done on the X-ray segmentation data? How do the results compare to SHAMANN?\n- How does the inference and training time compare to the baseline methods?', 'The authors present a model for semantic segmentation. The proposed method casts the full image segmentation as a sequence of local segmentation predictions. The image is split in multiple patches and processed sequentially in some order. A shared memory allows the local patch predictions to propagate information to improve other patch predictions which is necessary for resolving ambiguities.  They show a set of results on an XRay segmentation dataset with a reasonable ablation and baseline study. As well as a somewhat unclear result on image completion. The paper is well written, mostly clear and novel to the best of my knowledge.\n\npros:\n- semantic segmentation is clearly very important problem with many applications\n- the method seems clean and promising\ncons:\n- the segmentation community is much more familiar with MS-COCO and VOC. I think results on those datasets will make the paper much more impactful and clear any doubts about the method.\n- it is not clear what processing order the patches are processed in. Does that matter ? This should be clearer in the paper.\n- there is a brief mention of multiple actors but it seems to me its just one Bi-MANN actor is that true ? \n- sec. 4.2 is very surprising to me. From what is written I understand that an MNIST classifier is trained on the original MNIST dataset and that it still works to 56% on the test set with the bottom blanked out. Is that correct ? What architecture is this ? Also I find it very surprising that you can recover accuracy to 96% without seeing the trained classifier at all. Anything that can help me understand how that is possible would be appreciated. Are you aware of anyone else matching these results in the literature ?', 'The authors applied the external memory module proposed by Graves et al. (2016) to the image segmentation task. SHAMANN is an extension to allow memory sharing between directions. \n\nAuthors claimed that one of the contributions is a reformulation of the semantic segmentation problem as a sequence learning task.\nThere are many previous works done in this direction,\n- ""Multi-Dimensional Recurrent Neural Networks"", 2007\n- ""Scene Labeling with LSTM Recurrent Neural Networks"", 2015\n- ""ReSeg: A Recurrent Neural Network-Based Model for Semantic Segmentation"", 2016\n- ""Robust, Simple Page Segmentation Using Hybrid Convolutional MDLSTM Networks"", 2017 \nand many more.\nAuthors should compare with those LSTM-based image segmentation approaches as well.\n\nTheir second contribution is a network with a shared external memory module between directions. However, the experiments are not enough to show the benefits of it. See the details below.\n\nHandling long-range dependencies:\n- In Section 3.3.2, authors mentioned that ""One limitation of Bi-LSTM is that the number of network parameters grows proportionally to the memorization capacity, making it unsuitable for sequences with long-range dependencies."". \nHowever, the experiments are not with long range sequences: 169 sequence length for X-ray dataset and 49 length for MNIST. A classic LSTM (not bi-directional) is known to handle up to 200 timesteps. Some comparison/analysis of handling long-range dependencies of Bi-LSTM, Bi-MANN, and SHAMANN are needed (ideally on high-resolution real images).\n\nDataset:\n-  Authors compared 3 models only on MNIST. The structure on MNIST is simple, and the resolution of images is small to show the benefit of using (shared) external memory module instead of individual memory cells. It is not surprising that the reported performance difference is small. Authors could have reported such a comparison on X-ray dataset too but they did not. I would recommend authors pick another high-resolution real-image dataset and compare the performance of these 3 models.  \n\nAdditional comparisons:\n- Various patch size\n- Longer sequence length\n- Especially a trade-off between the patch size and the sequence length on the high resolution images (larger patch size with a shorter sequence length or shorter patch size with a longer sequence length)\n\n- A comparison of Bi-LSTM with sharing weights will also be a good baseline. \n']","[-20, 60, -50]","[60, 80, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'easy to read' and the approach is 'interesting', they express several concerns. They note that similar methods have been presented before but not discussed, the experimental results are 'not compelling enough', and they recommend additional experiments. This suggests the reviewer is not fully satisfied with the current state of the paper. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions rather than direct attacks. For example, they say 'My recommendation would be...' and pose several questions for the authors to consider, which is a polite way of pointing out potential weaknesses in the work."", ""The sentiment score is 60 (positive) because the reviewer starts with a neutral description of the paper, then lists both pros and cons. The overall tone is positive, praising the paper as 'well written, mostly clear and novel'. The cons are presented as constructive feedback rather than harsh criticism. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the importance of the work and framing criticisms as suggestions or questions. They use phrases like 'I think', 'it is not clear', and 'Anything that can help me understand' which maintain a polite and collaborative tone. The reviewer also balances critique with praise, showing respect for the authors' work."", ""The sentiment score is -50 because the review is generally critical, pointing out several limitations and suggesting significant additional work. The reviewer acknowledges the authors' contributions but questions their novelty and the sufficiency of their experiments. However, it's not entirely negative as the reviewer provides constructive feedback for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer specific suggestions for improvement. Phrases like 'I would recommend' and the use of 'authors' rather than 'you' maintain a respectful tone. The reviewer also acknowledges the authors' claims before critiquing them, which adds to the politeness.""]"
"['The paper is easy to read and the presentation is clear, and I really appreciate this.\n\nThe authors address the very important topic of feature extraction and state representation learning. New results in this area are always valuable and welcome. However, my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper. \n\n1. The authors propose to learn a state representation by either training using a combined loss function, or training several representations using multiple loss functions followed by stacking. These are standard and well-known techniques in machine learning. The key contribution one looks for is in terms of new insights on why and when each approach works. The paper fails to provide much insight in this regard. Take this simple scenario: Suppose my input image is actually generated by a linear map plus gaussian noise on the true states. Then I can simply use a PCA as my ""auto encoder"" and happily learn a high quality state representation close to the ground truth. We know why this works. In the real task, the image is a complex non-linear transformation of the true states. What insights do I gain from this work in terms of how I should tackle this?\n\n2. Section 3 states some desirable characteristics in constructing a state representation. These are well-known and fundamental aspects of machine learning -- applicable to almost all models that we want to learn. In this sense, I do not find the section very informative.\n\n3. The empirical results (say, Table 1) seem too noisy to interpret (other than that using the ground truth provides the best performance). It almost seems to suggest that one should simply use random features (as done in the ""extreme learning machine"" approach). Again, not much insight to draw from this.\n\n4. Last comment. Suppose I have a new robotic goal-directed task and my inputs are camera images. Does this work tell me something that I don\'t already know in terms of learning new feature representation that is highly suitable for my task?\n\n\n\n', 'This paper aims at comparing end-to-end learning vs separately learning a state representation and subsequently a controller.\n\nWhile this would be a relevant and important topic, the paper does not currently present consistent evidence to support this hypothesis.\n\nIn particular:\n- The approach proposed in the approach is not explained in sufficient details. After reading Sec.4 I have only a very vague and high-level idea of how the proposed approach might work. In Figure.2, what is I_t? What is the model that you are training? How are you learning this model? how do you define L_inverse?\n- The cited literature about state representation learning is absolutely incomplete. Papers like Lange et al. , Wahlström et al. and Finn et al. and citations herewithin.\n- From the experimental results, it is difficult to say anything definitive about the proposed hypothesis. 1) There are multiple end-to-end approaches in the literature, with significant differences in performance. which one are you using? (it seem A2C and PPO, but to which label do they correspond in the tables?) 2) How do you tune the weights of the reward function proposed? This seems an important design choice, but it is not much discussed. 3) In the table reported (e.g., Table 1) it does not seem to me that SRL consistently outperforms other approaches. Even for the arm tasks, Random features seem to outperform the proposed approach (and indeed all the methods except the ground truth). What is going on there?\n\nOverall¸ the paper would benefit from a clearer and more detailed text, and from improved experiments and comparisons.\n\nMinor comments:\n- It is unclear to me what ""goal-based robotic tasks"" means. How do you define a task without a goal?\n- An important and missing characteristic of a suitable state representation should be the generalization. In fact, a good representation would ideally allow the agent to generalize to some degree. \n- It seems very odd to me that the ""action should be implicitly encoded into the state representation"" could you elaborate of the motivation for this and the effects?\n\nReferences:\n- Autonomous reinforcement learning on raw visual input data in a real-world application\nS Lange, M Riedmiller, A Voigtlander\nNeural Networks (IJCNN), The 2012 International Joint Conference on, 1-8\n- From pixels to torques: Policy learning with deep dynamical models\nN Wahlström, TB Schön, MP Deisenroth\narXiv preprint arXiv:1502.02251\n-  Deep Visual Foresight for Planning Robot Motion\nChelsea Finn, Sergey Levine\nInternational Conference on Robotics and Automation (ICRA), 2017 ', 'This paper discusses State Representation Learning for RL from camera images. Specifically, it proposes to use a state representation consisting of 2 (or 3) parts that are trained separately on different aspects of the relevant state: reward prediction, image reconstruction and (inverse) model learning. The paper is easy to read, and seems technically sound. However, the conclusions do not directly follow from the results, so should be made more precise. The contribution is minor, and the reasoning behind it could be better motivated. \n\nThe most important point of critique is that the conclusion that the split representation is the best is at best premature. The presented results indicate that SRL is useful (Table 1), and that auto-encoding alone is often not enough. Other than that, the different approaches tested all work well in different tasks. The discussion of the results reflects this, but the introduction and conclusion suggest otherwise.\n\nThe same problem also occurs for the conclusion about the robustness of SRL approaches. In the main text, no results are presented that warrant such a conclusion. The appendix includes some tests in this direction, but conclusions should not be based on material that is only available in the appendix. Furthermore, even the tests in the appendix are not comprehensive enough to to warrant the conclusion as written.\n\nThe second point is the motivation of the split approach: it seems in direct contradiction with the ""disentangled"" and ""compact"" demands the authors pose. Because the parts of the state that are needed for multiple different prediction tasks (reconstruction, inverse model, etc.) need to be in the final\nstate representation multiple times. Due to the shared feature extractor, the contradictory objectives (and hence the need for tuning of the weights in the cost function) are still a potential problem.\n\nMinor points:\n\n- The choice for these tasks is not motivated well. Please indicate why these tasks are chosen. It seems the robot arm task is very similar to the navigation task, due to robot arm\'s end effector being position controlled directly. Why is it worthwhile to study this task separately?\n\n- The GTC metric is not very well established (yet). Please provide some extra information on how it is calculated. This should also include some discussion on why this metric allows judging sufficiency and disentangledness. How would rotating the measurement frame of the ground-truth influence the results?\n\n- Why are the robotics priors not in Table 1?']","[-50, -50, -20]","[50, 20, 50]","[""The sentiment score is -50 because while the reviewer starts with some positive comments about the paper's readability and the importance of the topic, they quickly express significant criticisms. The reviewer states that the paper 'falls short in terms of making sufficient new contributions' and lacks new insights. They also point out that the empirical results are too noisy to interpret and that the work doesn't provide much novel information. These criticisms outweigh the initial positive remarks, resulting in a negative overall sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments and use phrases like 'I really appreciate this' and 'New results in this area are always valuable and welcome.' Even when expressing criticisms, the reviewer uses polite language such as 'my feeling is' and frames their points as questions or observations rather than direct attacks. The reviewer also provides specific examples and explanations for their criticisms, which is a constructive approach. However, the score is not higher because the review is still quite critical and doesn't offer much encouragement or suggestions for improvement."", ""The sentiment score is -50 because the reviewer expresses several significant concerns about the paper, including insufficient details in the approach, incomplete literature review, and inconclusive experimental results. However, it's not entirely negative as the reviewer acknowledges the relevance and importance of the topic. The politeness score is 20 because the reviewer uses professional and constructive language, offering specific recommendations for improvement. The tone is critical but not rude, and the reviewer uses phrases like 'the paper would benefit from' which suggests a helpful intent. The minor comments section also shows a willingness to engage with the authors' ideas, asking for elaboration rather than dismissing them outright."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('easy to read', 'technically sound'), they express several significant criticisms. The reviewer states that 'the conclusions do not directly follow from the results', 'the contribution is minor', and 'the reasoning behind it could be better motivated'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They provide constructive criticism without using harsh or rude phrasing. The reviewer uses phrases like 'The most important point of critique is...' and 'Please indicate why...', which maintain a polite tone while clearly expressing their concerns. The review also balances criticism with positive observations, further contributing to its politeness.""]"
"['The reviewer finds that the proposed method interesting. The model is very clean, and the implication in causal inference is significant. The writing is also clean and clear. The reviewer has several concerns:\n\n1) the algorithm seems not very scalable. In the two subproblems, there is one solved by a large number of parallel SDRs. SDR is quite expensive, and for each column in the data matrix one has to solve an SDR in each iteration. This is too much for large scale recommender systems. In fact, in the experiment 1 on MovieLens, the algorithm was only tested on a not-so-large dataset and run 5 iterations. The reviewer feels that more scenarios should be tested (e.g., more iterations, various sizes of dataset, etc.). Fixing the number of iterations also sounds a bit funny since it is more intuitive to stop the algorithm using some validation set or when the algorithm converges under a certain criterion.\n\n2) The algorithm works with *probability* of binary data. This is quite hard to estimate in practice. For example, people ``\'likes\'\' a movie for only once. It is hard to tell what is the probability of generating this ````""like"". It seems that the experiment part of this paper did not clearly state how to obtain the probability that the algorithm needs.\n\n3) The proposed method is a special nonnegative matrix factorization, which could be unidentifiable. How to circumvent such situation? Since identifiability of NMF affects interpretability a lot.\n ', 'The paper considers a solution to a statistical association problem. The proposed solution involves a decomposition they call a kolmogorov model (what sort is not justified in any way and confused me a lot). The decomposition has two parts 1) a discrete basis function that needs to be discovered and 2) a discrete distribution over the basis elements. The define an optimization problem (2) which has a data term and some binary and simplex constraints and they propose a relaxation and decomposition of this optimization problem. They go on to claim that (mutual) causal relations can be then inferred by inspecting the representations they have learnt but they give little details on how and what impacts this distinction has in practice.  This may be obvious to a subfield expert but it is not clear to me at all. The paper is locally consistent but I have trouble understanding the contribution and placing in the broad machine learning field. \n\nI am not an expert in causality so I cannot evaluate the contribution but I can say that what interests me are section 2.2 and sec. 4-5. And they both require a lot better writing. 2.2 made things much more intuitive but i fail to see how the indicator variable annotations (action, scifi, etc.) can possibly come out of the data. I think this is an important point to support the interpretability claim. As for 4 I think there is room for intuition building there as well as limitations (e.g. what sort of inferences can be made and not etc.) Finally for 5 i find that very interesting but i find it difficult to have the right intuition about what the support condition means and how that helps in a practical setting.\n\npros:\n- causality and interpretability are major directions of research\n- seems like a valid contribution on an interesting problem\ncons:\n- the highlevel picture is relatively clear but i find important things very difficult to grasp \n- the kolmogorov model definition i find confusing but i am not an expert in causality (the introduction should give some intuition about what that is and why it is a good idea).\n- find it very hard to have a coherent picture of the limitations and assess the contributions of the paper.', 'The paper deals with an interesting problem. The presentation is clear the the approach intuitive.  However, the reviewer has some concerns about the pertinence of the approach and the relationship with related work.\n\nIt would be very helpful if the authors could contrast and compare the proposed approach (both qualitatively and quantitatively in their numerical experiments)  with methods for sparse non-negative matrix factorization. These would also lend themselves to causal interpretation.  \n\nThe need for modeling probabilities p_u,i in the key motivating applications is questionable. Indeed in both recommendation systems and gene expression datasets the observations are not readily in the form of probabilities. For instance in the experiments, the authors normalize the level of gene expressions to make is look as a probability, which by the way is very different from the i.id uniform setup considered in setting 1. For the movielens dataset, it is unclear how the data was preprocessed to obtain the observed p_ui.\n\n\n']","[20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging positive aspects of the work, such as finding the method interesting, the model clean, and the writing clear. However, they then list several significant concerns, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their concerns as observations rather than criticisms. They use phrases like 'The reviewer feels that...' and 'It seems that...', which maintain a polite tone while expressing their concerns. The reviewer also balances their critique with positive comments, which contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros'), they express significant concerns about the paper's clarity and accessibility. The reviewer struggles to understand key concepts and the paper's overall contribution, which suggests a generally negative sentiment. However, the presence of some positive comments prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They express their concerns and criticisms in a constructive manner, using phrases like 'I find' and 'I think' to soften their critiques. The reviewer also acknowledges their own potential lack of expertise in certain areas, which adds to the polite tone. While not overly effusive, the language is consistently courteous and appropriate for a peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting problem and clear presentation, they express 'concerns' about the approach and its relationship to related work. The reviewer also questions the need for modeling probabilities in key applications, indicating some skepticism about the paper's methodology. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with positive comments and framing criticisms as suggestions ('It would be very helpful if...'). The reviewer maintains a professional tone, avoiding harsh language even when expressing concerns.""]"
"['The paper proposes a new method for anomaly detection using deep learning. It works as follows. \n\nThe method is based on the recent Multiple-Hypotheses predictions (MHP) model, the impact of which is yet unclear/questionable. The idea in MHP is to represent the data using multiple models. Depending on the part of the space where an instance falls, a different model is active. In this paper this is realized using VAEs. The details are unclear (the paper is poorly written and lacks some detailed explainations), but I am assuming that for each hypothesis (ie region of the space) different en- and decoder parameters are learned (sharing the same variational prior??). The authors mention that below this final layer all hypothesis share the same network parameters. An adversarial loss is added to the model (how that is done is not described; the relevant equation (5) uses L_hyp which is not defined) to avoid the mode collapse.\n\nWhat is interesting about the paper:\n- First of all, pushing the the MHP framework towards AD could be relevant by its own right for a very small subcommunity that is interested in this method\n- The idea of using the adv loss for avoiding mode collapse can be useful in other settings; this is def a that I learned from the paper\n- The method might actually work rather well in practice\n\nVotum. As outlined above, the paper makes some rather interesting points, but is not well written and lacks some details. I am not entirely convinced that AD and MHP is a killer combination, but the experimental results are ok, nothing to complain here (except the usual bla: make it larger, more, etc), but honestly they really fine (maybe compare also again against more related work, e.g., Ruff et al ICML 2018).', 'Summary\n-------\nThe paper proposes a technique to make generative models more robust by making them consistent with the local density. It is hypothesized that robust model will be able to detect out-of-distribution samples better and improve anomaly detection.\n\nMain comments\n-------------\n\n1. The proposed technique adds additional regularizers to the GAN loss that, in effect, state that the best hypothesis under a WTA strategy should have a high likelihood under the discriminator \'D\'. This is an interesting idea and certainly a reasonable thing to try. As stated in the abstract, the generative models are inefficient; it is likely that additional structure enforced by the regularizer helps in improving the efficiency.\n\n2. The objective in GANs is to infer the underlying distribution correctly and so far it has been found that their accuracy is heavily dependent on both the architecture as well as the computational complexity (they may improve with more training, but maybe not consistently). Therefore, it becomes hard to compare the three architectures in Figure 2 since they are all different. A more rigorous comparison would try to keep as many pieces of the architecture the same as possible so that ConAD can be compared with \'all other things being same\'. Some experiments seem to follow this idea such as \'MDN+ConAD-{2, 4, 8, 16}\' in Table 2. But in these experiments the addition of ConAD offers a mild improvement and even degrades for the maximum number of hypothesis (i.e., 16).\n\n3. Page 2, para 2, last two lines: ""For simplicity, imagine an ... the real distribution.""\n\nThe argument is not clear. It seems too trivial and almost like a straw man argument.\n\n4. Page 4: ""In anomaly detection, this is difficult since there is no anomalous data point contained in the training dataset.""\n\nThis is not true in real-world applications where most data is contaminated with anomalies. This is part of the challenge in anomaly detection.\n\nThe above also applies to the following on page 6: ""During model training, only data from the normal data class is used...""\n\n5. Page 5: ""...D minimizes Eq. 3"": Should be \'maximizes\' since the reference is to the log likelihood of real data (or, add a negative sign).\n\n6. Eq. 4: The last component should be negative since we trying to maximize the likelihood of the best hypothesis under WTA (right?).\n\n7. Table 1: The datasets are not real anomaly detection datasets (too high proportion of \'anomalies\') Moreover, the number of datasets is insufficient for rigor.\n\n8. Section 5.4: ""With our framework ConAD, anomaly detection performance remains competitive or better even with an increasing number of hypotheses available.""\n\nSection 6: ""... and alleviates performance breakdown when the number of hypotheses is increased.""\n\nThis is not entirely supported by the results in Tables 2, 3, and also 4 and 5 of supplement. The results for ConAD - {2, 4, 8, 16} are not consistently increasing.\n\nSince experiments are very few (and not real-world for anomaly detection task) because of which the observations cannot be generalized.\n\n9. Page 4 (minor) in two places: ""one-to-mapping"" -> ""one-to-many mapping""\n\n10. Page 5 (minor): ""chap. 3"" -> ""section 3""\n', 'This paper proposes an anomaly detection system by proposing the combination of multiple-hypotheses approach with variational autoencoders, and using a discriminator to prevent either head of the model to produce modes that are not part of the data.\n\nThe combination between multiple-hypotheses approach with variational autoencoders seems rather artificial to me. Why do we need to parameterized a fixed set of hypothesis if we can generate as many outputs as we want just by sample several times from the prior of the VAE? Maybe I am missing something, which brings me to the following point.\n\nThe paper is difficult to read: the motivation is not well explained, the link between anomaly detection and multiple-hypothesis methods (both in the title of the paper) is not clear. The approach seems to build on top of Breunig et al. (2000), unfortunately this paper is not well described, e.g. what does it mean global neighborhood?\nThere are many other sentences in the paper that I find difficult to understand, for example:\n""Lfake itself consists of assessment for noise- (xˆz∼N(0,1)) and data-conditioned (xˆz∼N(µz|x,Σz|x)) hypotheses and the best guess given by the WTA objective.""\n\nOn top of that there are many other elements in the paper hampering the comprehension of the reader. For example:\nWTA is used without being defined before (winner takes all)\none-to-mapping --> one-to-one mapping?\nL_[Hyps] is the same as L_[WTA]?\nMDN is not defined until Sec. 5, and doing so without giving any description about it.\nTable 3 is never referred to.\nIs Table 5 reporting results on the Metal anomaly dataset? If so please mention it in the caption.\n\nIn the experiments it is difficult to see which parts of the models make the main difference. For example, it would be interesting to have an ablation experiment assessing the importance of the discriminator.']","[-20, -20, -60]","[20, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they also express significant concerns about its clarity and completeness. The reviewer states that the paper is 'poorly written and lacks some detailed explanations' and that they are 'not entirely convinced that AD and MHP is a killer combination'. However, they do mention positive aspects like 'interesting points' and 'experimental results are ok', which prevents the score from being more negative. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, avoiding harsh language. They use phrases like 'could be relevant' and 'might actually work rather well' which soften their criticisms. The reviewer also balances negative comments with positive ones, showing a fair approach. However, the politeness is not extremely high as the criticism is still direct and not heavily cushioned with polite language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they raise several significant concerns and criticisms. The reviewer points out issues with the comparison methodology, questions some of the arguments and claims made in the paper, and notes that the experimental results don't fully support the paper's conclusions. However, the review is not entirely negative, as it does recognize the potential of the proposed technique.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting idea' and 'reasonable thing to try' when discussing the paper's strengths. Even when pointing out flaws, the language is constructive rather than harsh, using phrases like 'A more rigorous comparison would...' and 'This is not entirely supported by the results...'. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. The use of 'minor' to label less significant issues also shows consideration for the authors."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's clarity, motivation, and methodology. They find the paper difficult to read, question the necessity of the proposed approach, and point out numerous issues with explanations and definitions. However, it's not entirely negative as they acknowledge the possibility of missing something and show interest in understanding the work better. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Maybe I am missing something' and ask questions rather than making outright dismissals. The reviewer also provides specific examples and suggestions for improvement, which is constructive. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['This paper introduces actions as a co-predictor of next-states and the predicted (from current and next state) in the context of (model-based) RL. In addition they incorporate the idea of using a JSD-based objective do prediction (as the Deep InfoMax paper), which is novel to RL. The enforce a linear structure between current / next states and actions with an additional sparse nonlinear term computed from both current states and actions. From this, they are able to quantify the amount of novelty in the representation space as a measure of exploration, which can be used as an intrinsic reward.\n\nI found the paper to be very well-written and easy to understand. The prediction part is similar to that used in CPC structurally, except they include the action in two different prediction tasks and they have some built-in intrinsic rewards, which is good.\n\nI had some issues with the motivations of some of the loss functions. \n- The JSD-based objective makes sense, but I don\'t think it\'s correct to call it an ""approximation"" to the KL (this is only true where the log-ratio of the joint and the product of marginals is small). Rather, it would be better to describe this choice as simply using a different measure between the joint and marginals.\n- It seems like the best motivation for having linear relations is you can do multiple predictions using the same state / action encodings.\n- For measuring exploration (11) couldn\'t one just use the predictor models T? How does the output of T (perhaps correctly normalized with the marginals) correlate with (11)?\n\nOther notes:\nPage 2:\nFigure 1 is awfully confusing. Could this be clarified a little bit? I’m not sure what the small dots or their colors are supposed to represent.\n\nCould diversity also be added by adding a prior to the state representations (as is done in Deep InfoMax)?\n\nWhy were the vision experiments stopped at 500 x 100k (500 million) frames?  I can’t validate the SOTA claims, but it seems like the model is still improving: are there’s further experiments?\n\nAn ablation study would be nice comparing the different hyper parameters (intrinsic rewards, diversity, etc).', ""This is a very interesting paper about a novel approach to exploration in agents with state and action representations, making heavy use of recent progress in the use of deep learning for estimating and maximizing mutual information, as well as introducing an approach to model the latent space dynamics with a linear models with sparse errors.\n\nA closely related work which is not mentioned is the work of Thomas et al 2017 arXiv:1708.01289 where they also maximize mutual information between distributed representations of actions (policies, actually) and of distributed representations of changes in the state (as the result of applying the policy).\n\nThe phrase 'functionally similar states' is used several times and would require a bit of explanation.\n\nI would also like to see more motivations for the two different reward functions r_e and r_d, and why one should be computed before the update while the other should be computed after.\n\nRegarding the experiments, and this is probably the weakest part of this paper, I would have expected to see comparisons against several of the numerous exploration methods which have been proposed in the past and are discussed in the paper (with many negative comments about their weakness, but no empirical support provided). Only one (EX2) was compared. The comparison with TRPO is without exploration (if I understand well, but should be stated clearly).  It's also not clear how these results compare to the best reported results on these games (whether or not exploration is used).\n"", 'The paper proposes an approach for exploration via reward bonuses based on a form of surprise. The surprise factor is based on the next state of a particular transition, and the error in the embedding space to satisfy a linear dynamics formulation. The embedding space of the states and actions are optimized to increase the mutual-information in predicting next state, and current action - encouraging meaningful embeddings with more training, and hence gradual fading away of the extrinsic rewards.\n\nThe paper is mostly well-written, and the idea is interesting. The experimental results do show that the proposed reward augmentation leads to better performing policies, but the claims in the experimental section need to be less strong (""outperforms the baseline by a large margin"" - Figure 4 - overlapping error bars; ""state of the art"" - Figure 5 - again, error bars, and no improvement in some domains.) But overall, I think the paper can be accepted as it is an interesting approach.\n\nBelow are some comments that I hope the authors address in their rebuttal, followed by some possible typos in the current draft.\n\n- Theorem 1 content placement: The organization here is rather unclear. Currently, you present Theorem 1, and then talk about using ""JSD instead of MI"". Maybe this is a last minute mistake. In either case, it is strongly suggested that the section be reworked to be clearer.\n\n- JSD is upper bounded by ln(2); your bounds (7) and (8) would change consequently too.\n\n- Training regime employed:\n  3 epochs-512 minibatch -> assuming distinct minibatches are sampled, (512x3) samples used\n  Collected (5k*500; sparsehalfcheetah)/(50*500; swimmercatcher)/(100k*4500; atari)\n  Is this the sample usage for training? Axis labels for all plots are missing -- specifically scale of x-axis.\n  Commenting on the sample complexity -- especially as the embedding network seems easy-to-train (or insufficiently trained), would be good; optimizing a lower-bound insufficiently leads one to doubt if the bound is meaningful at all. Is the huge batch of samples mostly used in TRPO/RL part of the infrastructure?\n\n- Discussing extrinsic rewards: the pros. vs. cons of the two reward formulations, why both are used etc. would be useful.\n\n- Embedding dimension: d=8 in Gravitar and Solaris, but performance is less significant (no significance) in these domains. Is this due to insufficient training?\n\n- RL method: Including details about form of TRPO used in appendix would be good (vine/single-path). Further if entropy regularization is used, how does the exploration interplay work.\n\n- A.2 is an interesting section. A linear dynamics model being effective in MuJoCo tasks seems plausible. But an Atari example is definitely more interesting. Therefore this section can be clearer - specifically distinction between residual error and sample error.\n\nTypos:\n- Appendix \\lambda parameters unclear\n- Appendix step-size information contradictory.\n\n\nPost-response comment: while I do think the approach is interesting, the utility of it is mostly demonstrated currently through empirical experiments. These experiments are preliminary, but used to make strong arguments for the effectiveness of the proposed approach. Further, upon highlighting this in my review, the authors disagree and think it’s empirical validity is rather superior. This leaves me concerned, and after thinking about it further, I do not think this is sufficient for acceptance. Therefore, I’m reducing my score to a 5.\n\nPS: the characterization of irreducible error as a product of the limitation of a linear model may be inaccurate.']","[50, 20, 50]","[80, 60, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'very well-written and easy to understand' and acknowledges novel aspects. However, they also raise several issues and questions, balancing the positive with constructive criticism. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as 'issues' or questions rather than direct attacks, and offers suggestions for improvement. The reviewer maintains a professional and courteous tone, even when pointing out potential weaknesses in the paper."", ""The sentiment score is slightly positive (20) because the reviewer starts by calling the paper 'very interesting' and praising its novel approach. However, they also point out several weaknesses, particularly in the experimental section, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I would like to see' and 'I would have expected' which are polite ways of pointing out areas for improvement. The reviewer also acknowledges the paper's strengths before delving into criticisms, which is a courteous approach."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper is 'mostly well-written, and the idea is interesting' and suggests that 'the paper can be accepted.' However, they also point out several areas for improvement and express some concerns about the strength of the claims. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I hope the authors address' and 'it is strongly suggested,' which are polite ways of giving feedback. The reviewer also acknowledges the paper's strengths before discussing its weaknesses. However, the score is not higher because the reviewer does become more critical in the post-response comment, reducing their overall assessment.""]"
"['The paper proposes a meta algorithm to train a network with noisy labels.\nIt is not a general algorithm but a simple modification of two proposed methods.  It is presented as a heuristics and it  would be helpful to derive a theoretical framework or motivation for the proposed algorithm. \n\nMy main concern is related to the experiment results. The results of the baseline method look strange. Why there is a strong decrease in the MNIST test accuracy after 20 epochs? Standard training of neural network is very robust to label noise.  In case of  20% symmetric error  (figure 2c)  the performance degradation using standard training should be very small. \nHence it is difficult to evaluate to performance of the proposed method.\nAt the beginning of the experiment section you mentioned several algorithms   for training with noisy labels.  I expect to compare your results to at least one of them. \n    \n', 'A new method for defending against label noise during training of deep neural networks is presented. The main idea is to “forget” about wrongly labeled examples during training by an ascending step in the gradient direction. This is a meta-approach that can be combined with other methods for noise robustness; the detection of the noisy examples is specific of the base method utilised. Experimental results are promising.\n\nIn general, I find the idea original, and of potential practical use, but I believe the contribution of paper to be limited and not well supported by experiments. Moreover, I think that some claims made in this work are poorly justified.\n\n== Method\n\nThe paper would greatly benefit from some theoretical backing of the proposed optimization scheme, even on a simplified scenario. An idea would be to prove that, given a dataset with noisy labels, PumpOut converges close to the best model (= the one learned without noise), for certain hyperparameters. I think this would be new and interesting. A result of similar fashion was proven in [A].\n\nI found the following arguments not well or only heuristically supported:\n* section 2: the scaling factor \\gamma. Why using \\gamma=1 is suboptimal? One could claim that as much as you want to memorize the true image-label patterns, you also want to forget the image-noise ones.\n* Why MentorNet + PumpOut does not suffer from the selection bias effect of CoTraining? This is unclear to me\n* The non-negative version of the BackwardCorrection, and its appeal to Kiryo et al 17 is interesting, but it sidesteps its justification. A loss that can be negative does not necessarily means that it not lower-bounded. In fact, for a minimization problem to be well-defined, all you need is a lower bounded objective. Then, adding the lower bound makes your loss non-negative. Notice that Patrini et al 17 did not state that BC is unbounded, but only that it can be negative. Can you show more that that -- maybe, at least experimentally?\n\nThe statement of Theorem 2 is trivial. In fact, no proof is given as it would be self-evident. Moreover, the Theorem is not used by PumpOut. Algorithm 3 uses a if-else conditional on the scale of the backward correction, without the max(0, .). I suggest to remove this part. I have notice later that the non-negative version of BC is used as a baseline in the experiment, but I think that is the only use.\n\nRegarding the presentation, in section 3, I suggest to move the explanation of MentorNet and BackwardCorrection before their upgrade by PumpOut.\n\n== Experiments\n\nTable 1 can be removed as these are extremely common datasets.\n\nThe experimental results look very promising for applications. As a side effect of this analysis, I can also notice an improvement over BC given to the nnBC, which is nice per se. Although, I would have strengthen the empirics as follow.\n* SET2 is only run on MNIST. Why not even on CIFAR10 which is used in SET1? Any future reader will wonder “did it work on CIFAR10?""\n* A much harder instance of noise, for instance open set [B] or from a real dataset [Xiao et al 15] would have more clearly supported the use of PumpOut for real applications.\n* Can the authors elaborate on “the choices of \\beta and \\gamma follows Kirkyo et al 2017” ? And how assuming their knowledge gives a fair comparison to BC which does not require them? I believe this is a critical point for the validity of the experiments.\n\nMinor:\n* “LRELU active function’ -> activation function. What is a LRELU? LeakyReLU?\n\n[A] Malach, Eran, and Shai Shalev-Shwartz. ""Decoupling"" when to update"" from"" how to update""."" Advances in Neural Information Processing Systems. 2017.\n[B] Veit, Andreas, et al. ""Learning From Noisy Large-Scale Datasets With Minimal Supervision."" CVPR. 2017.', 'This paper presents a meta algorithm to improve the robustness of learning methods under noisy labels. The idea is to squeeze out the negative effects of noisy labels actively. The paper trains deep neural networks by stochastic gradient descent on “fitting” labels; while trains deep neural networks by scaled stochastic gradient ascent on “not-fitting” labels. Experimental results show the improvement on robustness. \n\nThe good things of the paper are clear. \n1.\tTechnical sound with reasonable idea\n2.\tProblem is well motivated\n3.\tPaper is general well written.\n\nSome comments\n1.\tThe idea using instance selection is not new. The novelty could be improved. If the paper could make more insight from either theoretical or application value, would be more interesting.\n2.\tExperiments are too standard. More divers and various data sets would be more convincing. \n']","[-50, -20, 50]","[20, 60, 75]","[""The sentiment score is -50 because the reviewer expresses several concerns and criticisms about the paper, particularly regarding the lack of theoretical framework, strange baseline results, and insufficient comparisons. However, it's not entirely negative as they acknowledge the proposal of a new algorithm. The politeness score is 20 because the language is generally professional and constructive, using phrases like 'it would be helpful' and 'I expect to compare', which are polite ways of suggesting improvements. The reviewer also explains their concerns clearly without using harsh or dismissive language. However, the tone is more neutral than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as original and potentially useful, they express significant concerns about the paper's limited contribution, lack of theoretical backing, and insufficiently supported claims. The reviewer states, 'I believe the contribution of paper to be limited and not well supported by experiments. Moreover, I think that some claims made in this work are poorly justified.' However, the score is not deeply negative as the reviewer also notes 'Experimental results are promising' and finds the idea 'original, and of potential practical use.'\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'I find,' 'I believe,' and 'I suggest,' which soften their criticisms. The reviewer also offers specific suggestions for improvement, such as 'The paper would greatly benefit from some theoretical backing' and provides detailed feedback on various aspects of the paper. While critical, the language is not harsh or rude, but rather aimed at improving the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by summarizing the paper's content neutrally, then explicitly states 'The good things of the paper are clear' before listing three positive aspects. However, the reviewer also provides 'Some comments' with two areas for improvement, balancing the positive aspects. This results in a moderately positive overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They begin with a neutral summary, explicitly acknowledge the paper's strengths, and frame their criticisms as 'comments' rather than harsh criticisms. The suggestions for improvement are presented constructively, using phrases like 'could be improved' and 'would be more interesting/convincing' rather than direct criticisms.""]"
"['Summary:\nThis paper effectively learns a variant of a Deep Value Network (Gygli et al 2017), a model consisting of an energy network that assigns scores to input-output tuples that is trained to mimic a task-specific loss. The primary differences between the model presented in this work (titled LDRSP) and DVNs are twofold: first, the initial label prediction used at test time for inference is the output of a model rather than being initialized to all zeros. Second, a GAN-inspired loss is used to train both the scoring function and the initial prediction estimator. This new setup is compared against a variety of recent structured prediction methods on the tasks of multilabel classification, semantic segmentation, and 3-class face segmentation.\n\nComments:\nI think the ideas presented in this paper are interesting, but I think their presentation could be a bit clearer. As mentioned in the summary, what you’re presenting is still more or less a deep-value network with some additions - however, you don’t refer to it as such in the body of the paper anywhere I saw. The first addition is the use of a learned model to produce the initial prediction; this is a natural extension to Deep Value Networks, and on its own is somewhat incremental in nature. I do not think you adequately explained why you chose to use a GAN-like loss to learn these models. Another baseline that would have helped justify its use would be to train your G model to predict structured outputs in the standard way (max-margin or cross-entropy loss) and then train your energy function in the DVN way. \n\nThe experimental settings are somewhat small in scope but follow the precedent set by previous structured prediction papers, which is fine. You make appropriate comparisons against previous structured prediction models as well as against different types of GAN-like losses. But, as I mentioned before, I think you needed to have more comparisons against different ways of training these networks that do not follow a GAN-inspired framework. \n\nOverall, I like the new ideas in this paper but I think a few more experimental settings are required before they should be published.\n\n=== after rebuttal ===\n\nI appreciate the response, but I still think further analysis of the model is needed to understand where the gains in performance are coming from. The claim is that this is due to the adversarial loss used, but without further ablations I feel this is too strong a claim to be making given the current evidence.\n', ""- The writing and structure of the paper can be improved. It is difficult to read without first reading Gygli et al. 2017, and this paper should be more self-contained. There are also many parts that are not clear: \n  1. What is the model structure of G? Is it another neural network, or other structured prediction approaches such as graphical models? \n  2. The GAN-based approaches listed in the experiments section are originally designed for learning generative models. What are the adaptations required to turn them into structured prediction models? This is not clear at all. \n\n- The convergence of GAN training is an ongoing research problem and in practice also affects the quality of results. Yet in this paper I don't see any details on how these adversarial networks are trained jointly (e.g., heuristics to balance the progress on G and D). The authors should give more details on these.   \n\n- The main difference of this paper compared to Gygli et al. 2017 seems to be the joint learning of a prediction model G. Instead of relying only on the valuation network D and starts iterative gradient ascent on the initial prediction of a vector y^(0) of all zeros, the authors start the iterative gradient ascent with the prediction from G (equation 7). Otherwise the paper looks very similar to Gygli et al. 2017, including the training sample generation methods. So to me the main message of this paper is that you can improve deep value networks by providing a better starting point in inference with G. The improvement is somewhat small though, between 1-2% on the datasets shown in the experiments section. \n\n- Overall this paper gives a useful but incremental improvement over the deep value network proposed by Gygli et al. 2017. However, the writing should be substantially improved to make the paper more self-contained and to include missing experiment details. \n\n=== after rebuttal ===\n\nThe authors explain some of their model choices in the rebuttal, but I am still not convinced about the difference with Gygli et al. 2017 is significant enough. \n\n"", 'Building on the work of (Gygli et al., 2017), this paper introduces a training algorithm for energy-based models for structured prediction. Similar to Gygli et al. (2017), they train an energy-based discriminator, which matches the energy value of structured outputs with their target values assigned by a value function.\nThe authors present the learning algorithm in an adversarial learning framework by describing a structured prediction model G and a discriminator D. However, it is very confusing for me to understand the proposed formulation as an adversarial framework. In an adversarial framework, at the equilibrium, G could be used as a final prediction model, however, the predicted output of G are still low quality. For example, considering Table 1, the performance of G is exactly the same as NN baseline, which suggests that only the first term of Eq. 6  participates in the training of G (because L_g(G, y*) is the exact objective of the NN baseline).\nWhat that I can easily relate to, however, is that this training algorithm is similar to Gygli et al. (2017), but uses G to get an initial point for gradient-based inference. We want this initial point to be close to the target value Eq. 6. We use the initial value (prediction of G) and the ground truth as the matching constraints (Eq. 5) (as well as the other samples that construct Eq. 10). This actually describes why D can refine the output of G (because it looks at it as an initial point that needs refinement), but the discriminators in the other adversarial frameworks can\'t refine that much (since they have reached the equilibrium). I would love to hear authors comments on my concern regarding the proposed adversarial framework.\n\nOther comments:\n1) Lg is a surrogate loss, not the task-loss. Task-loss could be F1, IOU, BLEU, etc, which is the ultimate performance measure on a task. \n2) The authors refer to G as a structured prediction model but starting from Section 4, they have switched to call it a classifier, which is confusing.\n3) ""Gygli et al. (2017) found that the key to learning energy-based models is generating proper training data."":  Is this a general statement for every energy-based model? I understand its effect when matching values, but is it still true for other training algorithms such as structural SVM training (Belanger and McCallum, 2016)? Do you have evidence to support it?\n4) ""In the experiment, we adopt the fully convolutional network (FCN) (Long et al., 2015) baseline model proposed in (Gygli et al., 2017) as our segmentation network. It consists of three 5 × 5 convolutional layers and two deconvolution layer."": The text from Gygli et al. (2017) says three convolutional layers and two fully connected layers. Are you using the same architecture? If not, can you describe the architecture in more details? \n5) The qualitative results for Gygli et al. (2017) appear in https://gyglim.github.io/deep-value-net/. The reported output for DVN row is significantly worse than the segmentation results of the same horses specifically for columns 4 and 8, while the overall reported IOU in Table 2 is exactly the same. Can you describe the source of this disagreement?\n6) Is having a continuous domain for value function v essential for the proposed training algorithm? \n\n=== After rebuttal ===\nI am not convinced that the improved performance is because of the adversarial training. I trained a simple MLP and with the right amount of regularization it gets 42.0% f1 score on Bibtex, so I am not sure that the adversarial training is very essential here.\n \n\n ']","[-20, -30, -50]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the ideas interesting, they express several criticisms and state that 'further analysis of the model is needed' and 'a few more experimental settings are required before they should be published'. This indicates overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths ('I like the new ideas'), and frames criticisms constructively ('I think their presentation could be a bit clearer', 'I think you needed to have more comparisons'). The reviewer maintains a professional tone without using harsh or dismissive language."", ""The sentiment score is -30 because the review is generally critical, pointing out several areas for improvement and describing the paper's contribution as 'incremental'. However, it's not entirely negative as it acknowledges the paper as 'useful'. The politeness score is 20 because the reviewer uses professional and constructive language, avoiding harsh criticism. They offer specific suggestions for improvement rather than outright dismissal. The phrasing is generally neutral to slightly polite, using phrases like 'can be improved' and 'should give more details' rather than more forceful or negative language."", ""The sentiment score is -50 because the reviewer expresses significant confusion and skepticism about the paper's core claims, particularly regarding the adversarial framework. They state 'it is very confusing for me to understand the proposed formulation as an adversarial framework' and raise concerns about the model's performance. The reviewer also lists several critical comments and questions, indicating overall negative sentiment. However, the score is not lower because the reviewer does express some interest in hearing the authors' responses and acknowledges building on previous work. The politeness score is 20 because the reviewer uses generally polite language, such as 'I would love to hear authors comments' and frames criticisms as questions or areas of confusion rather than direct attacks. However, the politeness is not extremely high as the review is still quite critical and direct in its questioning of the paper's claims.""]"
"['Summary: Authors proposed a model for input method for mobile or desktop devices. The goal is to convert the input sequence (from one language to another) or predict the next word. Their model is based on an LSTM with modified softmax activation function that is adjustable for large vocabulary sizes. They showed experimental results on Japanese BCCWJ data set.\n\nClarity: Paper is well-written and well-organized. Notions and methods are clearly expressed. \n\nOriginality: This paper builds on an LSTM model without enough work or idea to show novelty. \n\nSignificance: It is below average. Using LSTM is a well-known method for these types of tasks in the literature. Incremental selective softmax is potentially a good approach, however, this work lacks showing significant improvement. The experiments are limited and are done only on one data set.\n\nMore detailed comments:\n\n- My concerns about this work are both on modeling aspects and experiments. Authors mainly focus on highlighting the benefits comparing to n-gram models, and briefly discuss the ongoing developments in neural based models. For example sequential modelings using RNN\'s have shown promising results in capturing long-term dependencies [1]. Unfortunately authors did not include any discussion on how their approach would compare to that framework nor did they present any experimental comparisons to them.\n\n- Although mentioned briefly in the introduction and related work sections, no analytical or experimental comparisons are made to machine translation approaches when their work is closely related to it. I strongly suggest that authors compare their experimental results to some of benchmarks in neural based machine translation discussed in the related works.\n\n- In the incremental selection softmax, they use ""match"" to return all lexicon items matching the partial sequence. How is this done and what are the effects of it on the computational time of the algorithm? Also, It is not clear how authors correct old probabilities in IS softmax step. As mentioned, they add logits of missing vocabulary to the denominators, how do they keep the properties of softmax so that it sums up to 1? And later in the discussion authors mentioned that in practice they compute union of all missing vocabularies, it is not clear how this is done since the advantage of using IS softmax is expressed to be incremental increasing. \n\n[1] A.B. Dieng, C. Wang, J. Gao and J. Paisley. TopicRNN: A recurrent neural network with long-range semantic dependency, International Conference on Learning Representations (ICLR), 2017.', 'The paper demonstrates the main challenge of using LSTM-based language models for input method in real time is the huge amount of computation in the softmax. The authors present a system to speed up the inference by avoiding computing the full softmax in the Japanese conversion task, where the number of output words can be limited from the mapping of the input sequence through a lexicon. The experiment result is encouraging in that the proposed incremental selective softmax approach significantly reduces latency over the standard inference with the full softmax computation while not hurting accuracy much. The paper also evaluates the effect of quantization for LSTM LM model compression in terms of size and accuracy.\n\nHowever, there are a few major problems of the paper as follows:\n\n1. The main weakness in the experiment setup is that it misses a few competitive baselines in terms of inference speed, notably hierarchical softmax[1] and self normalization[2]. In the Japanese conversion task in the paper, it only needs to evaluate the scores of limited output words that are given from the mapping of the input sequence through the lexicon. This is exactly like the rescoring setup in speech recognition and machine translation, where self-normalization is typically used for efficient inference to avoid computing the expensive softmax normalization term [2,3]. Assuming the number of selected output words is K and the entire vocabulary size is V, then the time complexity is O(K logV) for the hierarchical softmax, O(K) for self normalization, but O(V) for all the baselines in the paper. Self normalization is simple to implement and works well in practice, while the proposed incremental selective softmax approach in the paper needs an additional step to sample most frequent words to adjust the normalization term. Without showing the self normalization result, I am not convinced that the proposed approach is better and needed.\n\n[1] F. Morin and Y. Bengio. ""Hierarchical Probabilistic Neural Network Language Model,"" in Proc. of AISTATS, 2005,\n[2] J. Devlin et al., ""Fast and Robust Neural Network Joint Models for Statistical Machine Translation,"" in Proc. of ACL, 2014.\n[3] Y. Shi, W. Zhang, M. Cai and J. Liu, ""VARIANCE REGULARIZATION OF RNNLM FOR SPEECH RECOGNITION,"" in Proc. of ICASSP, 2014.\n\n2. The proposed approach would only be useful in speeding up the conversion task, but not applicable to the prediction task where it needs to evaluate all words and choose the top hypotheses. Also how is the latency of the prediction task compared to conversion task? Please also add it to the experiment result.\n\n3. The idea of using quantization for neural network model compression is not novel (even for language model), although it is listed as one of the main contributions in Section 1.\n\nSo in general, I think the paper is insufficient in novelty and missing competitive baselines.\n\nSome specific comments:\n4. Figure 2(b) is not clear what it means, and not referenced anywhere in the paper.\n5. The last 3 lines in Section 3: ""as each path has different missing vocabularies"": Why is that? The candidates of the output words should only depend on the input sequence and the lexicon, based on Eq(1)(2).\n6. It is not clear how to adjust the probability in the second pass of incremental selective softmax. The description ""we compute a union of all missing vocabularies, and then recompute the logits of them in batch."" is unclear what it means.\n7. Section 4.2: ""is measure with numpy"" -> ""is measured with numpy"".\n8. Section 4.4: It is not clean how ""76x speedup"" is computed from Table 2 since all the time numbers are rounded. Consider also showing one digit after the decimal point.', 'This paper describes a search space reduction method for neural network based keyboard input methods. The paper discusses two different sampling methods to restrict the vocabulary size during beam search.  \n\nTitle: The title of the paper is too generic to describe what is actually being done in the paper. Input methods in mobile devices could have also meant speech based input or handwriting based input or swipe based input. It would be very convenient for the readers if the authors use more specific wording in the title to clarify that they are talking about neural network based keyboard typing input.\n\nComparison with prior work: Neural network based on-device keyboard input is a research topic with a lot of previous contributions and the existing literature survey seems lacking. Further it does not even cover popular techniques for inference speed-up like hierarchical softmax computation. It would be easier for the reader to appreciate the  contributions of this paper if the authors compare and contrast with more relevant prior work.']","[-30, -50, -20]","[60, 50, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (e.g., 'Paper is well-written and well-organized'), they express significant concerns about the paper's originality ('without enough work or idea to show novelty') and significance ('below average'). The reviewer also points out several limitations and suggests major improvements, indicating an overall negative sentiment. The politeness score is 60 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'I strongly suggest' and 'It is not clear' instead of more confrontational language. The reviewer also begins with positive comments before moving on to criticisms, which is a polite approach in academic reviews."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The experiment result is encouraging'), they also point out several major problems and conclude that the paper is 'insufficient in novelty and missing competitive baselines'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding personal attacks or harsh criticism. They present their concerns objectively (e.g., 'However, there are a few major problems of the paper as follows:') and offer specific suggestions for improvement. The tone is constructive rather than dismissive, maintaining a level of politeness despite the critical content."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's topic and methods, they point out significant areas for improvement, particularly in the title's specificity and the comparison with prior work. The critique suggests that the paper lacks in these areas, which gives an overall slightly negative impression. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'It would be very convenient' and 'It would be easier for the reader' which suggest a helpful tone rather than a critical one. The reviewer also acknowledges the paper's content before providing suggestions, which is a polite approach to feedback.""]"
"['This manuscript extends the direct feedback alignment (DFA) approach to convolutional neural networks (CNN) by (1) only applying DFA to FC layers with backpropagation (BP) in place for convolutional layers (2) using binary numbers for feedback matrix.\n\nOriginality wise, I think (1) is a very straightforward extension to the original DFA approach by just applying DFA to places where it works. It still does not solve the ineffectiveness of DFA on convolutional layers. And there is no much insight obtained. (2) is interesting in that a binary matrix is sufficient to get good performance empirically. This would indeed save memory bandwidth and storage. This falls into the category of quantization or binarization, which is not super novel in the area of model compression. \n\nThe experimental results show that the proposed approach is better than BP based on accuracy. However, these results might be called into question because the shown accuracies on CIFAR10 and CIFAR100 are not state-of-the-art results. For example, the top 1 accuracy of CIFAR10 in this paper 81.11%. But with proper tuning, a CNN should be able to get more than 90% accuracy. See this page for more details.\nhttp://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\nTherefore, though the claimed accuracy of the proposed method is 89%, it is still not the state-of-the-art result and it seems to be lack of tuning for the BP approach to perform similar level of accuracy. The same conclusion applies to CIFAR100. In fact, from figure 4, the training accuracy gets 100% while the testing accuracy is around 40% for BP, which seems to be overfitting. With these results, it is hard to judge the significance of the manuscript.\n\nMinor typos:\nIn Equation 1, the letter i is overloaded.', 'The paper propses to use a combination of Direct Feedback Allignment (DFA) and BackPropagation (BP) to improve upon standard back propagation.\nTo understand what is done, consider the following: Feedback Alignment is +- equal to back propagation when using random but fixed weights in the backwards pass. Direct feedback alignment uses random backprojections directly to the layer of interest. \nThe advantage of DFA is that It bypasses the normal computational graph. The advantage of this is that if compute is infinite, all of these updates can be computed in parallel instead of pipelining them as is done in standard BP.\n\nIn the current paper, the use of DFA for dense layers and BP for conv layers which is named CDFA is proposed.\nIn addition the paper also proposes a binarized version of BDFA to limit memory consumption and communication. It is claimed that the proposed techniques improve upon standard back propagation.\n\nOverall, the paper is easy to understand, but I lean towards rejecting this paper because I am not convinced by the experimental evidence. As outlined below, the key issue is that the baseline appears to be weak. Additionally, the main limitation of the proposed approach can only benefit a very limited set of architectures. \n\nPositive points:\n---------------------\nThe authors did an excellent job of introducing BP, FA and DFA in the paper. This makes the core concepts and ideas accessable without having to delve through prior work.\n\n\nThe own contributions and the key idea is easy to understand. \n\nLimitations and possible improvements\n-------------------------------------------------------\nA core limitation is that recent networks do not have a combination of dense layers and convolutional layers. In many cases the networks are fully convolutional, this limits the applicability of the proposed combination of DFA and BP. The use of additional networks would benefit the paper. Currently only VGG 16 on Cifar 10 is used. Also, the data augmentation strategy is not discussed. Of course, it would be nice if additional datasets could be included as well, but this of course depends on the computational resources the authors have available. \n\n\nThe key issue to me is that performance improvements for CIFAR are reported, but I fear that the baseline accuracy for VGG16 might be a bit low. If I memory serves me well, it should be able to achieve around 90% at least on CIFAR 10 using VGG style networks. I did a quick search and found http://torch.ch/blog/2015/07/30/cifar.html corroborating this but I did not verify this directly. \n\n\nRelated to the previous point, since this is an empirical paper, describing the hyper-parameter optimizations and final settings in detail  can convince the reader that the study is exectued correctly. Much of the information is missing now.\n\n\nSimilarly, I have trouble understanding section 4.1 and section 4.2 since I do not know the exact details of the experiments. This can be fixed easily however.\n\n\nProvide complexity estimates of the potential speedup or provide actual timing information. (Although this might not be that meaningful without much additional work given that gpu kernels are often heavily optimized).\n\n\nLast year there was a submission to ICLR about fixing the final output layer and only learning the convolutional layers. If we consider that random projections work remarkably well and can be considered approximations of kernels, it could be interesting to add a baseline where the fully connected layers are fixed and only the convolutional layers are trained. The error signal can be propagated using standard BP, FA or DFA methods but it would shed light on whether learning in the higher layers is actually needed or BP in the conv layers is sufficient.\n\nMinor possible improvements\n------------------------------------------\nFinally, I would strongly suggest that the authors perform some additional proofreading. There are quite a few strange formulations and spelling mistakes. That being said, it did not prevent me from understanding the manuscript so this remark DID NOT factor into my judgement.\n\nIn addition to remark above, I would suggest removing the second paragraph from the introduction. It feels out of place to me, and the vanishing gradient effects are not discussed in the remainder of the manuscript.\n\n\nThe list of possible optimizers before the selection for SGD+Momentum is not needed. Simply stating that SGD with momentum is used should be sufficient. \n\n\n“Training from scratch” instead of “Training from the scratch”\n', 'This paper targets at developing new DFA method to replace BP for neural network model optimization, in order to speed up the training process. The paper is generally written clearly and relatively easy to follow. \n\nMy main concern is about significance of the contribution of this paper.\n\n1. the novelty is limited. This paper only simply combines two well-known approach BP and DFA together. \n\n2. performance contribution seems not significant from the proposed approach. In the implementation, the authors only apply their approach to optimize a few top layers. A majority of the layers in the NN model are still optimized via BP. \n\n3. the authors should provide more evaluations on different NN backbones and datasets, to make the experiments stronger and more convincing.']","[-50, -30, -30]","[20, 60, 50]","[""The sentiment score is -50 because the reviewer expresses several criticisms and doubts about the manuscript's originality, significance, and experimental results. They point out that the approach is not novel, doesn't solve key issues, and the results are questionable due to not being state-of-the-art. However, they do acknowledge some interesting aspects, preventing the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'it seems' to soften criticisms. They also provide constructive feedback and specific examples to support their points. The language is not overtly polite, but it avoids rudeness and maintains a respectful academic tone."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('excellent job of introducing concepts', 'easy to understand'), they ultimately 'lean towards rejecting this paper' due to unconvincing experimental evidence and limited applicability. The review lists more limitations than positive points, indicating a generally negative sentiment. However, it's not extremely negative, as the reviewer provides constructive feedback for improvement. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing detailed, constructive feedback. They use phrases like 'excellent job' and 'easy to understand' for positive aspects. Even when pointing out limitations, the tone remains professional and helpful, offering specific suggestions for improvement. The reviewer also acknowledges their own potential mistakes ('if memory serves me well') and considers the authors' resource constraints, which adds to the politeness. The minor criticism about proofreading is delivered gently, stating it didn't affect their judgment."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is clearly written and easy to follow, they express significant concerns about the contribution's novelty, performance, and experimental rigor. The reviewer uses phrases like 'main concern' and 'limited novelty', indicating a generally negative sentiment towards the paper's significance. However, it's not entirely negative as they do mention some positive aspects. The politeness score is 50 because the reviewer uses respectful and professional language throughout, avoiding harsh criticism. They use phrases like 'generally written clearly' and offer constructive suggestions for improvement. The tone is diplomatic and objective, maintaining a polite discourse while still conveying their concerns.""]"
"['The privacy definition employed in this work is problematic. The authors claim that ""Privacy can be quantified by the difficulty of reconstructing raw data via a generative model"". This is not justified sufficiently. Why larger reconstruction error achieves stronger privacy protection? I could not find any formal relationship between reconstruction error and privacy. \n\nThe proposed method is not appropriately compared with the other methods in experiments.  In Fig. 3 the author claim that the proposed method dominates the other methods in terms of privacy and utility but this is not correct. At the specific point that the proposed method is evaluated with MNIST and Sound, it achieves better utility and better ""privacy"". However, the Pareto front of the proposed method is concentrated on a specific point. For example, the proposed method does not achieve high ""privacy"" as ""noisy"" does. In this sense, the proposed method is not comparable with ""noisy"". In my understanding, this concentration occurs because the range of \\lambda is inappropriately set. This kind of regularization parameter should be exponentially varied so that the privacy-utility Pareto front covers a wide range. \n\n--\nMinor:\nIn Eq. 1, the utility is evaluated as the probability Yi=Yi\'. What randomness is considered in this probability?\nIn Eq 2, privacy is defined as maxmin of |Ii - Ii\'|. Do you mean privacy guaranteed by the proposed method is different for each data? This should be defined as expectation over T or max over T. \n\nIn page 4. ""The reason we choose this specific architecture is that an exactly reversed mode is intuitively the mode powerful adversarial against the Encoder."" I could not find any justification for this setting. Why ""exactly reversed mode"" can be the most powerful adversary? What is an exactly reversed mode?\n\nMinimization of Eq. 3 and Eq. 4 contradict each other and the objective function does not converge obviously. The resulting model would thus be highly affected by the setting of n and k.  How can you choose k and n?', 'Summary: The paper studies the problem of training deep neural networks in the distributes setting while ensuring privacy. Each data sample is held by one individual (e.g., on a cell phone), and a central algorithm trains a learning model on top of this data. In order to protect the privacy of the individuals, the paper proposes the use of multi-layer encoders (E) over the raw data, and then send them across the server. The privacy is ensured by exemplifying the inability to reconstruct the original data from the encoded features, via running a reverse deep model (X). The notion of privacy is quantified by the Euclidian distance between the reconstructed vector via the best X and the original feature vector, maximized over E. The overall framework resembles a GAN, and the paper calls it RAN (Reconstructive Adversarial Network).\n\nPositive aspects: The problem of training privacy preserving deep models over distributed data has been a significant and important challenge. The current solutions that adhere to differential privacy based approaches are not yet practical. In my view, it is a very important research question.\n\nNegative aspects: One major concern I have with the paper is the notion of privacy considered. The notion of privacy considered in the paper makes two assumptions which I am not comfortable with: i) The protection that the notion assures is against reconstruction attacks. There has been a large body of work which shows that weaker attacks like membership attacks can be equally damaging, ii) Privacy is a worst-case guarantee. I do not see the GAN style approach taken by the paper, ensures this. ', 'Privacy concerns arise when data is shared with third parties, a common occurrence. This paper proposes a privacy-preserving classification framework that consists of an encoder that extracts features from data, a classifier that performs the actual classification, and a decoder that tries to reconstruct the original data. In a mobile computing setting, the encoder is deployed at the client side and the classification is performed on the server side which accesses only the output features of the encoder. The adversarial training process guarantees good accuracy of the classifier while there is no decoder being able to reconstruct the original input sample accurately. Experimental results are provided to confirm the usefulness of the algorithm.\n\nThe problem of privacy-preserving learning is an important topic and the paper proposes an interesting framework for that. However, I think it needs to provide more solid evaluations of the proposed algorithm, and presentation also need to be improved a bit.\n\nDetailed comments:\nI don’t see a significant difference between RAN and DNN in Figure 5. Maybe more explanation or better visualization would help.\nThe decoder used to measure privacy is very important. Can you provide more detail about the decoders used in all the four cases? If possible, evaluating the privacy with different decoders may provide a stronger evidence for the proposed method.\nIt seems that DNN(resized) is a generalization of DNN. If so, by changing the magnitude of noise and projection dimensions for PCA should give a DNN(resized) result (in Figure 3) that is close to DNN. If the two NNs used in DNN and DNN(resized) are different, I believe it’s still possible to apply the algorithm in DNN(resized) to the NN used in DNN, and get a full trace in the figure as noise and projection changes, which would lead to more fair comparison.\nThe abstract mentioned that the proposed algorithm works as an “implicit regularization leading to better classification accuracy than the original model which completely ignores privacy”. But I don’t see clearly from the experimental results how the accuracy compares to a non-private classifier.\nSection 2.2 mentioned how different kind of layers would help with the encoder’s utility and privacy. It would be better to back up the argument with some experiments.\nI think it needs to be made clearer how reconstruction error works as a measure of privacy. For example, an image which is totally unreadable for human eye might still leak sensitive information when fed into a machine learning model. \nIn term of reference, it’s better to cite more articles with different kind of privacy attacks for how raw data can cause privacy risks. For the “Noisy Data” method, it’s better to cite more articles on differential privacy and local differential privacy.\nSome figures, like Figure 3 and 4, are hard to read. The author may consider making the figures larger (maybe with a 2 by 2 layout), adjusting the position of the legend & scale of x-axis for Figure 3, and using markers with different colors for Figure 4. \n']","[-70, -20, 20]","[20, 50, 60]","[""The sentiment score is -70 because the review is predominantly critical, pointing out several significant issues with the paper's methodology, comparisons, and justifications. The reviewer expresses concerns about the privacy definition, experimental comparisons, and the mathematical formulations used. However, it's not entirely negative as the reviewer does provide constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I could not find' and 'In my understanding' which soften the critique. The reviewer also provides specific recommendations for improvement, which is a polite and constructive approach. However, the language is not overtly polite, maintaining a neutral academic tone for the most part."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the research question, they express major concerns about the paper's approach to privacy. The positive aspects mentioned are outweighed by the significant negative aspects discussed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the importance of the work before presenting criticisms. They use phrases like 'In my view' and 'One major concern I have' which soften the critique. The reviewer maintains a professional tone without using harsh or dismissive language, even when expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the topic and finds the proposed framework interesting. However, they also point out that more solid evaluations and improved presentation are needed. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides detailed suggestions for improvement. They use phrases like 'I think' and 'It would be better' instead of more forceful language. The reviewer also balances critique with positive comments, showing a considerate approach to feedback.""]"
"['In the paper, WGAN with a squared zero centered gradient penalty term w.r.t. to a general measure is studied. Under strong assumptions, local stability of a time-continuous gradient ascent/descent dynamical system near an equilibrium point are proven for the new GP term. Experiments show comparable results to the original WGAN-GP formulation w.r.t. FID and inception score.\n\nOverall, I vote for rejecting the paper due to the following reasons:\n- The proven convergence theorem is for a time-continuous ""full-batch"" dynamical system, which is very far from what happens in practice (stochastic + time discrete optimization with momentum etc). I don\'t believe that one can make any conclusions about what is actually happening for GANs from such an idealized setting. Overall, I don\'t understand why I should care about local stability of that dynamical system.\n- Given the previous point I feel the authors draw too strong conclusions from their results. I don\'t think Theorem 1 gives too many insights about the success of gradient penalty terms.\n- There are only marginal improvements in practice over WGAN-GP when using other penalty measures. \n\nFurther remarks:\n- In the introduction it is claimed that mode collapse is due to JS divergence and ""low-dimensionality of the data manifold"". This is just a conjecture and the statement should be made more weak.\n\n- The preliminaries on measure theory are unnecessarily complicated (e.g. partly developed in general metric spaces). I suggest that the authors try to simplify the presentation for the considered case of R^n and avoid unnecessarily complicated (""mathy"") definitions as they distract from the actual results. \n\n==after rebuttal==\nAfter reading the authors rebuttal I increased the my rating to 6 as they addressed some of my doubts. I still think that the studied setting is too idealized, but it is a first step towards an analysis.', ""This paper shows that an ideal equilibrium point of a SGP-WGAN is stable. It makes several assumptions that, while clear why they are needed in the proof, is unjustified in practice. The authors should elaborate on these assumptions and comment on why they are reasonable. \n\nAssumptions 1 and 3 essentially say that there is a tube (both in sample space and in parameter space) around the true data generating distribution in which the discriminator cannot distinguish. This seems a strong restriction to the effect of the discriminator is weak. For example, Assumption 1 says if given a sample slightly off the data manifold, it still cannot distinguish at all. A more reasonable assumption is the ability of the discriminator decays gracefully as samples approach the data manifold.\n\nAssumption 2 is also unjustified. Its main effect seems to be to eliminate a few terms in the projected Jacobian in the proof, but its relevance and whether it is reasonable in practice is entirely unmentioned.\n\nFinally, it is unclear why this notion of ``measure valued differentiation'' is needed. First, differentiation in measure spaces is no different from differentiation in other infinite dimensional functions spaces: the usual notions of Gateaux and Frechet differentiability apply. Second, the derivatives in questions are not true ``measure-derivatives'' in the sense that the argument to the function being differentiated is not a measure, it is a finite dimensional parameter. In the end, this seems essentially a derivative of a multi-variate function."", 'Based on a dynamic system perspective, this paper characterizes the convergence of gradient penalized Wasserstein GAN. The analytic framework is similar to the one used in Nagarajan & Kolter but requires very heavy machinery to handle measure valued differentiation. Overall the math seems solid but I have a few questions about the motivation and assumption. \n\n1. To my limited knowledge, it seems that the two-time-scale framework [1] handles both batch and stochastic settings well also from a dynamic system perspective. I am wondering why not follow their path since under their framework adding a gradient penalty does not introduce all the technical difficulty in this paper. \n\n2. The main theorem characterizes the stability or convergence but does not characterize the advantage of gradient penalty. Does it make the system more stable? At least more technical discussion around the theorem is needed. \n\n3. Besides the technicality of handling the support of the measure, what is new beyond the analysis of Nagarajan & Kolter?\n\n[1] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\nby Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter\n\nI may be missing something and would like to see the author\'s response. \n\n=== after rebuttal ===\n\nI have carefully read the authors\' response. I appreciate the explanation. After reading [1] in detail, my conclusion is still that [1] seems to be a stronger framework than the current one and easily extends to the setting with gradient penalty. Compared with Nagarajan and Kolter, the contribution of this paper seems to be minor, although technically involved. I have checked the updated pdf but haven\'t found the authors\' rigorous ""more stable"" argument.']","[-50, -50, -30]","[20, 20, 50]","[""The sentiment score is -50 because the reviewer initially votes to reject the paper, citing several critical reasons. However, after the rebuttal, they increase their rating, showing some improvement in sentiment. The overall tone remains more negative than positive. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and provide specific feedback without being rude. They also acknowledge the authors' rebuttal and show willingness to adjust their opinion, which adds to the politeness. The reviewer uses phrases like 'I suggest' and 'I don't believe' rather than making harsh declarative statements, which maintains a level of respect."", ""The sentiment score is -50 because the review is generally critical, pointing out several unjustified assumptions and unclear aspects of the paper. However, it's not entirely negative as it acknowledges the paper's contribution in showing stability of an equilibrium point. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer specific suggestions for improvement. The reviewer uses phrases like 'The authors should elaborate' and 'it is unclear why', which are polite ways to express concerns. The tone is constructive rather than harsh, maintaining a respectful academic discourse."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges that 'the math seems solid', they express several concerns and questions about the paper's motivation, assumptions, and contributions. The reviewer suggests that the paper's approach may be unnecessarily complex compared to existing frameworks and questions the novelty of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges their own potential limitations ('I may be missing something'), and expresses willingness to consider the authors' response. The reviewer also uses phrases like 'I appreciate the explanation' and 'I have carefully read the authors' response', which contribute to a polite tone. However, the criticism, while constructive, is still direct, preventing a higher politeness score.""]"
"['The paper presents an improvement on the previous work by [Neyshabur et el, ICLR 2018].\nMore precisely, an emprical generalization bound is provided by using PAC-Bayesian empirical \nbounds. To obtain the claimed improvement over the works [Barlett et al, NIPS 2017] and \n[Neyshabur et el, ICLR 2018], the authors have paid attention carefully (by putting some \nconditions) on the change of the layers (layer and interlayer cushion) as well as the activation \ncontraction. It is also worth noting that the paper is using a differrent loss function comparing \nto [Neyshabur et el, ICLR 2018], which the author called Optimal Margin Distribution Loss.\nAlthough the results seem interesting, the analysis is not convincible for me.\nA plus point is that the paper presents interesting numerical experiments showing the promising of the approach.\n\nMajor comments:\n1) The statement of the Theorem 1 is not clear: \nis it just under the assumptions of the lemmas\nor is it under all definitions and lemmas?\n2) The proof of Theorem 1 is not clear:\n how do you get the inequality (5)?\nhow do you get an upper bound on the KL divergence?\n This is not trivial for me!\n3) What is \\rho in Theorem 1 and in Definition 2?\n4) Your remark after Theorem 1 is not clear for me.\n  you claim that the product is (3) is large, what if we restrict all the spectral norms equal to 1?\n a simple counter example would fit better the explanation here, I guest.\n\nMinor comments:\n1) The Lemma 1 and 2 are almost the same to Lemma 1 and 2 in [Neyshabur et el, ICLR 2018]\nwithout precisely citations. I wonder how do you obtain your Lemma 1?\n2) page3, after formula (1), your loss will first DECREASING, not ""increasing"".\nCheck the sentence ""Fig. 1 shows, equation 1 will produce a linear loss increasing progressively with the margin distance....""\n', 'This paper presents a PAC-Bayesian bound for a margin loss.\n\nTheorem 1 seems specific to ReLU activations. I wonder whether this theorem holds for other activations since most deep neural networks can use different activations at different layers instead of only the ReLU activation for all the layers. In Section 3, only Definition 3 is related to the activation. Can an activation satisfying Definition 3 have a similar bound to Theorem 1? Moreover, since the convolutional layer is a simplified case of the fully connected layer discussed in Section 3, does the convolutional layer simplify the bound in Theorem 1?\n\nThere are some typos in this paper.\n“To derive a expected risk bound”: a -> an\n“used to formalize error-resilience in Arora et al. (2018) as following:”: following: -> follows.\n“the deep network from layer i to layer j”, “injected before level i”: i,j should be in the math mode.\n“dependent on the network structure .” there is an additional blank space after ‘structure’.', 'I consider that improving the generalization capability of neural networks on small dataset is an important line of research, and the method proposed here empirically provides great results.\n\nThe proposed margin loss (Equation 1) is said to be ""specially adapted for accelerating the convergence velocity of networks by [the authors]"". I would like this statement to be explained better, or at least backed by empirical evidence. In the current state, I consider that the paper lacks an in-depth study of the properties of this handcrafted loss. Few is said on the benefits of having both a linear behavior for points inside the margin and a quadratic loss for far points. The impact of loss hyperparameters (r, \\gamma,\\mu) should be discussed thoughtfully; at some points in the paper, r and \\gamma are referred as margin mean and margin variance parameters, but this interpretation is not explained. Moreover, almost nothing is said about \\mu.\nBy considering a simplified loss function, the provided PAC-Bayes generalization bound (Theorem 1) consider solely the flat loss region [r-\\gamma, r+\\gamma], but shed no light on the benefit of the hinge and quadratic parts. I conceive that this might be hard to study theoretically, but the authors should at least provide a empirical study of these. \n\nThe empirical experiments show great evidence that the proposed method successfully improve generalization capability of neural networks on small datasets compared to classical methods. I appreciate the Inter/intra class variance study of Tables 2 and 3. I would like the mathematical expression of the ""hinge loss"" and the ""soft hinge loss"" models to be explicitly written (it is not clear in the text if the soft hinge uses an hyperparameter). In the same spirit of my above comments, I would like to see how each loss hyperparameters impacts the results, instead of having access solely to the parameter values selected by the validation process.\n\nTypos and minor comments:\n- Abstract: ""And our ODN model also outperforms the other three loss models..."" Which three loss models?\n- Section 3: ""Specially, define L_0 as r=\\theta..."" I think it should be r=0\n- Section 4.1: model-s => models\n- Page 7 (and elsewhere): Table. 2 => Table 2\n- Please specify that ""Xent"" stands for cross-entropy\n- Figure 3: Please use larger font sizes\n- Proof of Lemma 2: Equation. 4 => Equation 4 \n']","[-20, 20, 20]","[50, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('results seem interesting', 'interesting numerical experiments'), they also express skepticism ('the analysis is not convincible for me'). The overall tone suggests more concerns than praise. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I wonder' and 'is not clear for me' instead of more confrontational language. The reviewer also provides both major and minor comments in a structured, professional manner, which contributes to the politeness of the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution ('This paper presents a PAC-Bayesian bound for a margin loss') and offers constructive feedback. However, the reviewer also points out limitations and asks questions, indicating some reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions ('I wonder whether...', 'Can an activation...'), and provides helpful feedback on typos. The tone is professional and constructive, avoiding harsh criticism while still pointing out areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the importance of the research and praising the empirical results. However, they also express several concerns and request for more explanations and evidence throughout the review. The politeness score is moderately high (60) as the reviewer uses respectful language, often saying 'I would like' or 'I appreciate' when making suggestions. They also provide constructive feedback and specific recommendations for improvement without using harsh or critical language. The reviewer maintains a professional tone throughout, even when pointing out areas that need more work or clarification.""]"
"['This paper studies the generalization properties of a two layer neural network for a nonlinear regression problem where the target function has a finite spectral norm. The generalization bound comprises of an approximation term (dependent on the width) and an estimation term (dependent on spectral norm of the target and scaling as 1/sqrt{n}). \n\nThe key contribution is the derivation of the generalization bound where the estimation term depends on the properties of the target function rather than properties of the class of two layer neural networks. These bounds are instantiated for a class of regularized estimators (with path norm regularization).\n\n1. Theoretical Novelty: While both Theorem 3 (approximation) and Theorem 4 (a posterior generalization) were mostly following known results, the key development seems to be the bound on the path norm of the regularized solution in terms of the spectral norm of the target function. Given that the estimator is a path-norm regularized estimator, this seemed to be an incremental contribution. What would be more interesting is to obtain such a bound for an unregularized estimator: either saying something about the optimization procedure or relating this kind of regularization to properties of the dataset over which it is trained.\n\n2. Regression vs Classification: While the focus of the paper is on a regression problem, the experiments and problem motivation seems to arise from a classification setting. This creates a mismatch between the what the paper is about and the problem that has been motivated. Would it be possible to extend these results to loss functions (other than squared loss ) like cross-entropy loss or hinge loss which indeed work in the classification setting?\n\n3. Comparison with Klusowski & Barron (2016): In the comparison section, it is mentioned that  Klusowski & Barron (2016) analyze a ""similar"" problem and obtain worse generalization bounds. It would be important to know the exact setting in which they obtained their bounds and how do their assumptions compare with the ones made in this paper. The comparison seems incomplete without this.\n\n4. The experiments showcase that the regularized estimator has a better path norm (and expectedly so) but almost similar (in case of MNIST actually better) test accuracy. This defeats the purpose of  showing that the regularized estimator has better generalization ability which is claimed in the introduction as well as the experiment section (calling it ""well-posed""). What this indeed shows is that even though the path norm might be big, the generalization of the estimator is till very good contradicting the statements made. \n\n5. The numbers shown in Figure 1 and the numbers reported in Table 2 do no match: while the plot shows that the scaled path norm is around 60 for both MNIST and CIFAR-10, the corresponding numbers in the table are 507 and 162. Can you please point out the reason for this discrepancy?\n\n6. Theorem 5 seems to suggest that in the noiseless case, the estimation error would scale as the spectral norm of f^*. Rather, in the noiseless setting, it seems that the correct scaling of the generalization error should be with respect to properties of the regularized estimator and the function class. Even though the spectral norm can be arbitrarily high, the generalization bound should only be dependent on the complexity of functions which can fit the current data well. It would be good to have a comment in the draft on why the current dependence is a better thing and examples where such generalization bounds are indeed better. ', 'The main contribution of the paper is claimed as providing “apriori” guarantees for generalization where the generalization bounds depend only on the norm of the “true predictor”. This in contrast to what is termed as “posterior” guarantee where the generalization bound is provided in terms of the “learned predictor”. \n\nI could not appreciate the main motivation/challenge in this distinction. In particular, if additional constraints are imposed on the learned predictor during training, then it seems straightforward that any “posterior” guarantee can be immediately converted to an “apriori” guarantee. For example, in the context of the problem in this paper, since it is known that the true function f* is approximated by a 2 layer network of path norm < 4\\gamma(f*). Thus,  if during training the empirical loss is minimized over the networks with hard constraint of $\\theta_P < 4\\gamma(f*)$, then from Lemma 2, we should immediately get a generalization bound in terms of $\\gamma(f*)$ instead of $||\\theta||_P$.\n\nThe main result in the paper (Theorem 5) seems to essentially do a variant of the above approach, except instead of a hard constraint on the path norm of parameters, the authors analyze the estimator from soft regularization (eq. 6) and provide the guarantee in terms of the regularization parameter. This although is not immediate like the hard constrained version, I do not see major challenges in the extension to regularized version. Moreover, I also do not see the immediate motivation for analyzing the regularized objective over the constrained one (at least for the purpose of generalization bounds since both estimators are intractable computationally). Please provide a response if I missed something.\n\n\nWriting:\n1 (MAIN). Proper citations missing from many places. e.g., definition of path norm, spectral norm. \nMore importantly for the theorems in Section 2, appropriate citations within the theorems are missing. For example in Theorem 2 the authors do cite Klusowski and Barron in the beginning of section but not in the theorem header. Same for Theorem 3, and 4 which are known results too. Lemma 1 follows from corollary 7 in Neyshabur et al. 2015. \n\n\n2. Undefined notation ||.||_\\infty in Assumption 1. \n3. Definition 2: please provide proper reference for the definition and for multivariate Fourier transform. \n\nMore generally it is hard to follow the notations through out the paper and the motivations for certain notations are not completely clear. Some intuition here would help. For example, the reason we care about Assumption 1 is that this class of functions are well approximated by 2 layer networks (as shown in theorem 2). This could be stated ahead of the definitions. \n\n\n Also a broader outline of the structure should help with readablity. ', 'This paper provides a new generalization bound for two layer neural network with regularization. The main analysis tool is to bound the Rademacher complexity of the network (due to regularization). While the work achieves a bound that is superior than a previous work, I personally find the work less inspiring and somewhat incremental. I have three main concerns of the result/work:\n\n1. The analysis is on a very shallow network. It is not clear how this result shed insight on understanding the success of *deep* neural network.\n\n2. The work is restricted to analyzing a NN with explicit regularization. As the authors noted themselves, such a paradigm is less popular in practice now.\n\n3. The analysis tool - bounding Rademacher complexity - is very standard', 'The authors consider the notion of path norm for two layer ReLu network, and derive a generalization bound for a path-norm regularized estimator under a regression model.\n\nI apologize for the cursory review, as I have only been asked to review this paper two days ago. I have two main concerns about this paper: it is not clear to me how the distinction between “a priori” and “a posteriori” estimates enables a better understanding of the problem of generalization, and it is not clear to me how this paper contributes to a better understanding of generalization for neural networks.\n\nA priori v. a posteriori:\n\nThe authors attempt to distinguish “a priori” and “a posteriori” bounds by whether they depend on the true or estimated regression function. However, note that “a priori bounds” are significantly different from the common meaning of a “generalization bound”, which is most often understood to obtain a model-free bound of the generalization error. I found the reference to (Dziugaite and Roy, 2017) particularly confusing, as I am not sure how a PAC-Bayesian approach corresponds to an “a priori” approach.\n\nAdditionally, it seems that the theorems in the paper are phrased in the realizable case (i.e. where the true data-generating distribution is part of the model class). I believe that this is a poor model in the context of neural networks, which are often used to approximate complex models. Indeed, the authors claim that: “if the path-norm is suitably penalized during training, we should be able to control the generalization gap without harming approximation accuracy” which is true in the realizable case. However, the authors’ experiment (table 2) show that the training (and testing!) performance tends to decrease when regularization is applied. In particular, I fail to see any evidence that \n\nThe problem of generalization in neural networks:\n\nMy other concern is that the present results fail to contribute to a broader understanding of neural network generalization. Indeed, as the authors mention in the conclusion, strong regularizers are rarely used in practice, and do not seem to particularly affect the generalization properties of neural networks [see Zhang et al. 2017]. Instead, recent efforts in the community have attempted to explain the generalization of neural networks by identifying some distinguished and favorable property of the trained network: see e.g. [Arora et al. 2018, figure 2]. This can then be observed empirically on large networks, and a basic counterfactual can be established by measuring them on networks trained on random data or at initialization. On the other hand, while it is clear that bounding the capacity of the estimator (e.g. through a norm constraint in this case) yields favorable generalization properties, it is not clear to me how relevant these are to larger networks.\n\nMinor comments:\n1. Please include references for definitions (e.g. path-norm), and theorem headers when appropriate\n2. The condition in Assumption 2 is often referred to as a “sub-gaussian tail / sub-gaussian noise”, rather than “exponentially decaying tail” (as in this particular instance, the tail decays as the exponential of a square).\n3. After Lemma 2, in the derivation for L(\\theta), the second equality sign should be an inequality. The last \\hat{L}_{B_n}(\\theta) should simply be L_{B_n}(\\theta).\n4. In table, the display is somewhat confusing: for accuracy, higher is better, whereas for \\norm{\\theta}_p / \\sqrt{n}, lower is better. Consider expressing the accuracy as error instead.\n']","[-20, -50, -50, -60]","[60, 20, 0, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they raise several critical points and concerns. The review starts with a neutral summary but then lists multiple issues and questions, suggesting the paper needs significant improvements. However, it's not entirely negative as the reviewer recognizes some value in the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Would it be possible...', 'It would be important to know...', and 'Can you please point out...' which are polite ways of requesting clarification or suggesting improvements. The critique is presented as constructive feedback rather than harsh criticism.\n\nThe reviewer also balances critique with acknowledgment of the paper's contributions, which contributes to the polite tone. However, it's not extremely high on the politeness scale as the review is still quite direct in pointing out flaws and inconsistencies in the paper."", ""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's main contribution and motivation. They state they 'could not appreciate the main motivation/challenge' and question whether the approach offers anything beyond straightforward extensions of existing methods. This indicates a negative sentiment, though not entirely dismissive.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Please provide a response if I missed something' which shows openness to dialogue. The language is not overtly polite but avoids rudeness, striking a neutral to slightly positive tone in terms of politeness.\n\nThe reviewer also provides constructive feedback on improving the paper's writing and structure, which contributes to the slightly positive politeness score. However, the overall critical nature of the review prevents a higher politeness rating."", ""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper, calling it 'less inspiring and somewhat incremental' and listing three main concerns. However, they do acknowledge some positive aspects, such as achieving a superior bound than previous work, which prevents the score from being more negative. The politeness score is 0 (neutral) because the reviewer uses professional language without being overly polite or rude. They express their concerns directly but without using harsh or insulting language. The review focuses on the content and methodology rather than personal attacks, maintaining a neutral tone throughout."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's contribution and clarity. They use phrases like 'I have two main concerns' and 'I fail to see any evidence,' indicating a largely negative view of the paper. However, it's not entirely negative as they do provide constructive feedback and acknowledge some aspects of the work. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They begin with an apology for the cursory review and use polite language like 'please include references.' However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['Paper summary: \n\nAs is made clear in the title, this paper sets out to answer the following question: “Why do deep convolutional networks generalize so poorly to small image transformations?”. It focuses on natural image transformations on translation and scaling (rotation is missing though).\n\nThe paper proposes two main explanations: \n-\tStrided convolution, called subsampling in the paper, ignores the classical sampling theorem,\n-\tCNNs will not learn invariance because of the (photographers\') biases contained in the datasets.\n\nOn a general level, the paper is a good read, it is well written and the figures clearly convey the message they’re intended to. Adversarial attacks and robustness of CNNs in general is a very interesting and important topic in ML. The originality of this work is in the approach of the problem, the paper tries to explain the reasons why CNNs are vulnerable. Related works put more emphasis on coming up with novel attacks/defense strategies. Considering natural attacks as done in this submission is particularly interesting as it is probably a more surprising shortcoming of CNNs compared to optimally designed attacks or highly unnatural perturbations. The argument about subsampling (stride) being the reason of not having translational invariance is nice, especially the theoretical insight with the Shannon-Nyquist theorem and the more figurative example on part detectors. There are nevertheless a few major concerns about this work:\n\nMajor Concerns:\n\nTheoretical arguments:\nThe theoretical argument made in this paper is interesting but to make the point stronger a more in-depth explanation would be needed.\n-\tThe step from Eq (2) to Eq (3) is not entirely clear “K does not depend on x_i”, maybe one extra sentence to explain this step would be useful. \n-\tTerms introduced such as the basis function B and the set of transformations T could be better defined.\n-\tFor the extension to other types of transformations “While the claim focuses on global translation, it can also be extended to piecewise constant transformations.” it would be important to point out what type of natural transformations can be included in this set.\n\nEmpirical evidence:\nExperiments are not fully convincing. Additional empirical evidence would be beneficial and necessary to support the claims of this:\n-\t“A natural criticism of these results is that they are somehow related to the image resizing and inpainting procedures that we used.” This is a very good point and the authors following arguments are not fully convincing. Results with different transformation procedures mentioned in the rest of the paragraph (and probably more) should be included to convince the reader.\n-\tThe theoretical argument that translation invariance is not guaranteed because of the stride (subsampling) is not fully convincing and needs further explanation and experimental verification. In fact, feature maps of the CNNs that the authors consider do indeed contain many high frequencies.\n-\tThe argument made in part 4 about the photographer’s bias seems valid for general natural transformations, but it does not apply to small transformations such as 1-pixel translations presented in the paper. Also, evidence that datasets without (or less) photographers\' bias are less susceptible to natural attacks would make the argument in the paper a lot stronger. \n-\tWhen using 6x6 avg pooling for the VGG16 architecture ”recognition performance decreases somewhat” . Results are only preliminary in the paper, but this statement needs a more thorough experimental backing. It should come with convincing quantitative evidence.\n-\tPlease include some results or citation on other work about test time augmentation to support the statement “still only provides partial invariance”.\n\nReferences and phrasing:\nGenerally previous work is well referenced in this paper, although there are some formulations that can be slightly modified to make a clear distinction between what is novel and what is previous work:\n-\tAs is very well shown in the introduction, there is a lot of work on generating adversarial examples that drastically change the output of a CNN. This should be made clear in the abstract, in fact the sentence “In this paper we show that modern CNNs [...] also happens with other realistic small image transformations”  seems to indicate that this is the novel work in the paper. This is also why I believe the first sentence “Deep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations.” is somewhat contestable. \n-\t“We find that modern deep CNNs are not invariant to translations, scalings and other realistic image transformations” as the paper points out earlier this is not a novel finding, so I would use a formulation that makes that clear and gives more emphasis to your own arguments as of why this happens.\n\nFurther Comments :\n-\tPart 5 ""Implications for Practical Systems"" could be moved to discussion as there is no new point and it seems more a reflection on what was already stated.\n-\tThe final sentence of the abstract “Taken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.” is not necessary, this is clearly true but it isn’t really contested in the ML community.\n-\t“despite the architecture being explicitly designed to provide such invariances” I agree that this has motivated the use and design of CNNs in the first place, but modern architectures are mostly designed to surpass the results on the common benchmarks rather than to provide such invariances.\n-\t”jaggedness is greater for the modern, deeper, networks compared to the less modern VGG16 network” might be worth interesting to consider if the residuals have anything to do with it.\n', ""This paper describes an empirical study of translation and scale\ninvariance properties of modern CNN architectures. The authors conduct\na thorough study of translation invariance in VGG16, ResNet50, and\nInceptionResNet with respect to the Nyquist frequency and shift-\nversus translation-invariance properties of network layers as a\nfunction of depth and subsampling rate. Empirical observations are\nquantified using a variety of metric to measure the stability of\nfeature maps under geometric transformations of the input.\n\nThe paper has the following strong points:\n\n 1. It tells an interesting (and engaging) story about a largely\n    empirical study, and while doing this never pretends to be more\n    than it is.\n 2. Empirical observations are supported by quantitative measures that\n    give compelling evidence for most observations in the paper. The\n    discussion about shiftability versus translatability is\n    particularly interesting with its link to nonlinearity, smoothing\n    and Nyquist limits.\n\nThe paper has the following weak points:\n\n 1. The reliance on inpainting for almost all experiments is somewhat\n    worrying. It is not clear that this procedure isn't introducing\n    its own biases affecting translation and scale invariance. The\n    authors make reference to a separate protocol reported in the\n    appendices, but it isn't clear which results in the appendices\n    they are referring to. A more thorough control study seems in\n    order to verify that inpainting is a reasonable simulation.\n 2. Some figures are scaled down to the limits of legibility.\n\nIn summary: I like this paper a lot, and I think it adds useful\nelements and analytical tools (both theoretical and empirical) to the\ndiscussion on invariants in modeern CNNs.\n"", 'This paper studies the lack of shift invariance in state-of-the-art neural networks, namely, the paper introduces results that show that state-of-the-art deep neural networks are affected by 1-pixel shifts because the convolutional layers in the network poorly sample the feature maps. The topic addressed in the paper is critical for many computer vision systems, as lack of shift invariance is a catastrophic failure mode. The arguments of the paper help clarifying why the networks are so sensitive to small shifts of the objects (poor subsampling) but generalize well (there is a bias in the location of the objects in the dataset).  Both of these arguments and the sensitivity of the networks to small shifts are well known in the literature, but it is great to see a paper that puts them together and tests these arguments in state-of-the-art deep nets for ImageNet.\n\nHowever, the paper could do a much better job providing evidence to support the arguments:\n\n*Few quantiative results on the sensitivity to 1-pixel shift, most results are qualitative. This makes hard to assess whether the reported results are ""accidents"" found in certain images or are general. The results that support that 1-pixel shifts affect state-of-the-art neural networks are in Figure 2b. Yet, these results are unclear, eg. is ""400 Jaggedness"" a lot?, what is the size of the embedded image?, How are the 100 images selected? Is the network performing well in those images? How does the size of the embedded image change the ""Jaggedness""? \n\n*Something that could help to strengthen the results would be to add networks with better sampling + larger pooling regions and see how this solves the lack of shift invariance. Now it has only been tested increasing the pooling regions, which misses the main point of the paper. Also, the results on these networks with larger pooling regions, are all qualitative.\n\n*The mathematical proof is done for average pooling, which is rarely used nowadays. I would suggest using max pooling. Also, the aforementioned experiment in which the size of the pooling region is increased, is it max pooling or average pooling?\n\n*Limited results on the ImageNet bias. These results are reported in one image category (Figure 5), how general are them?\n\n*The paper assumes that shifting an image embedded an object in a black background is equivalent to shifting an object in a static background. A hypothesis would be that the embedding of the image in the black background creates artificial boundaries that make the network more fragile to 1-pixel shifts than for natural images.\n\nIn summary, I think this is a paper that may arise a lot of interest, although the different arguments are known and the experiments are poorly executed.\n\n']","[50, 80, -20]","[80, 70, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with positive comments about the paper being 'a good read' and 'well written', and acknowledges the originality and importance of the topic. However, they also express 'major concerns' and suggest that additional evidence and explanations are needed, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as recommendations rather than demands. They use phrases like 'would be beneficial', 'please include', and 'could be moved', which maintain a courteous tone. The reviewer also acknowledges the strengths of the paper alongside areas for improvement, demonstrating a balanced and professional approach."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, stating 'I like this paper a lot' and highlighting several strong points. They mention that it tells an 'interesting (and engaging) story' and provides 'compelling evidence'. The few criticisms are presented as minor weak points. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'It isn't clear' rather than more accusatory language. The tone is professional and courteous, offering balanced feedback without harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the paper's contribution in combining known arguments, they express significant concerns about the execution of experiments and the lack of quantitative evidence. The review starts positively but then lists several major shortcomings, concluding that the experiments are 'poorly executed'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's potential interest and importance of the topic. They offer constructive criticism and suggestions for improvement rather than harsh criticism. The reviewer maintains a professional tone, using phrases like 'could do a much better job' and 'I would suggest' instead of more confrontational language.""]"
"['The paper talks about a method to combine preconditioning at the per feature level and Nesterov-like acceleration for SGD optimization.\n\nThe explanation of the method in Section 3 should be self-contained.  The main result, computational context, etc., are poorly described, so that it would not be easily understandable to a non-expert.\n\nWhat was the reason for the choice of the mini batch size of 128.  I would guess that you would actually see interesting differences for the method by varying this parameter.\n\nHow does this compare with the FLAG method of Chen et al from AISTATS, which is motivated by similar issues and addresses similar concerns, obtaining stronger results as far as I can tell?\n\nThe figures and captions and inserts are extremely hard to read, so much so that I have to trust it when the authors tell me that their results are better.\n\nThe empirical evaluation for ""convex problems"" is for LS regression.  Hmm.  Is there not a better convex problem that can be used to illustrate the strength and weaknesses of the method.  If not, why don\'t you compare to a state-of-the-art least squares solver.\n\nFor the empirical results, what looks particularly interesting is some tradeoffs, e.g, a slower initial convergence, that are shown.  Given the limited scope of the empirical evaluations, it\'s difficult to tell whether there is much to argue for the method.  But those tradeoffs are seen in other contexts, e.g., with subsampled second order methods, and it would be good to understand those tradeoffs, since that might point to where and if a methods such as this is useful.\n\nThe conclusions in the conclusion are overly broad.', 'This paper presents a preconditioned variant of Nesterov\'s Accelerated Gradient (NAG) for use with Stochastic Gradients. The appears to be an interesting direction given that Nesterov\'s Acceleration empirically works better than the Heavy Ball (HB) method. There are a few issues that I\'d like to understand:\n\n[0] The authors make the assumption A 1-3, wherein, \n- why should the momentum parameter mu drop exponentially? This is not required for the convex case, see Nesterov\'s (1983) scheme for the smooth case and the smooth+strongly convex case. \n- why should the bounded rate of change (A3) even be satisfied in the first case? Does this hold true even in simple settings such as optimizing a quadratic/for log loss with stochastic and/or deterministic gradients? In short, is this a reasonable assumption (which at the least holds for certain special cases) or one that helps in obtaining a convergence statement (and which is not true even in simple situations)?\n\n\n[1] Convergence under specific assumptions aside, I am not sure what is the significance of the regret bound provided. In particular, can the authors provide any reasoning as to why this regret bound is better compared to ADAM or its variants [Reddi et al, 2018]? Is there a faster rate of convergence that this proposed method obtains? I dont think a regret bound is reflective of any (realistic) practical behavior and doesn\'t serve as a means to provide a distinction between two algorithms. What matters is proving a statement that offers a rate of convergence. Other forms of theoretical bounds do not provide any forms of distinction between algorithms of the same class (adagrad, rmsprop, adam and variants) and are not reflective of practical performance.  \n\n[2] The scope of empirical results is rather limited. While I like the notion of having experiments for convex (with least squares/log loss) and non-convex losses, the experiments for the non-convex case are fairly limited in scope. In order to validate the effectiveness of this scheme, performing experiments on a suitable benchmark of some widely used and practically applicable convnet with residual connections/densenet for cifar-10/imagenet is required to indicate that this scheme indeed works well, and to show that it doesn\'t face issues with regards to generalization (see Wilson et al, 2017 - marginal value of adaptive gradient methods in machine learning).\n\n[3] The paper claims of an ""accelerated stochastic gradient"" method - this really is a loosely used term for the paper title and its contents. There are efforts that have specifically dealt with acclerating SGD in a very precise sense which the paper doesn\'t refer to:\n- Ghadimi and Lan (2012, 2013), Dieuleveut et al (2017) accelerate SGD with the bounded variance assumption. \n- Accelerating SGD is subtle in a generic sense. See Jain et al. (2017) ""Accelerating Stochastic Gradient Descent for Least Squares Regression"", Kidambi et al. (2018) ""On the insufficiency of existing momentum schemes for stochastic optimization"". The former paper presents a rigorous understanding of accelerating SGD. The latter paper highlights the insufficiencies of existing schemes like HB or NAG for stochastic optimization. ', 'Authors propose combining Adam-like per-feature adaptative and Nesterov\'s momentum. Even though Nesterov\'s momentum is implemented in major frameworks, it is rarely used, so there\'s an obvious question of practical relevance of proposed method.\n\nSignificant part of the paper is dedicated to proof of convergence, however I feel that convergence proofs are not interesting to ICLR audience unless the method is shown to be useful in practice, hence experimental section must be strong. Additionally, there\'s a veritable zoo of diagonal preconditioning methods out there already, this puts an onus on the authors to show an advantage in terms of elegance or practicality.\n\nExperimental section is weak:\n- There are 2 tunable parameters for each method. PA-SGD seems to be a bit better in the tail of optimization for convex problem, but I\'m not confident that this is not due to better tuning of parameters (ie, due to researcher degrees of freedom). Authors state that ""grid search was used"", but no details on the grid search.\n- PA-SGD seems quite sensitive to choice of alpha. \n- No comparison against momentum which is probably the most popular method for neural network training nowadays (ie, ImageNet training is done using momentum and not Adam)\n- non-linear optimization experiments are shown using logarithmic scale for y for a huge number of epochs. This amplifies the tail behavior. More relevant is measure like ""number of steps to reach xyz accuracy"", or wall-clock time\n- it seems to perform equivalent to Adam for non-linear problem\n\n']","[-50, -50, -50]","[0, 20, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses in the paper, such as poor explanation, hard-to-read figures, limited empirical evaluation, and overly broad conclusions. However, it's not entirely negative as it does suggest some interesting aspects like tradeoffs in convergence. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state criticisms plainly (e.g., 'poorly described', 'extremely hard to read') but also offer constructive suggestions and ask questions for clarification, maintaining a professional tone throughout."", ""The sentiment score is -50 because while the reviewer acknowledges the paper as 'interesting', they raise several significant concerns and criticisms. They question the assumptions, the significance of the results, the limited scope of experiments, and the use of terminology. These criticisms outweigh the initial positive comment, indicating a generally negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I'd like to understand' and 'I am not sure', which soften the criticisms. They also acknowledge positive aspects ('I like the notion of having experiments'). However, the review is direct in its criticisms without excessive politeness, hence the moderate positive score."", ""The sentiment score is -50 because the reviewer expresses several concerns and criticisms about the paper, particularly regarding the practical relevance of the proposed method and the weakness of the experimental section. However, it's not entirely negative as the reviewer acknowledges some potential benefits. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and provide specific, constructive feedback. The reviewer uses phrases like 'I feel that' and 'Authors state that' which maintain a respectful tone. The criticism is presented as observations and suggestions rather than harsh judgments, contributing to a slightly positive politeness score.""]"
"[""This paper studied the Donsker-Varadhan lower bound of KL-divergence. The authors show that with high probability, the DV lower bound is upper bounded by log of the sample size, so if the true KL-divergence is very large, then exponential sample size is needed to make the DV lower bound tight. The same argument holds true for any distribution-free high-confidence lower bound (such as DV lower bound) for KL divergence. Then the authors proposed to use an upper bound for entropy instead of lower bound for mutual information. \n\nThe idea of the paper is interesting and the proof of Theorems 1 and 2 are valid. Especially I like the idea of Theorem 1, which proves that any distribution-free high-confidence lower bound for KL divergence is upper bounded by log of sample size. This idea is similar to the paper in (Gao et al 15') which shows that mutual information estimator is upper bounded by log(N).\n\nHowever, this paper contains many fatal flaws, which significantly weaken the quality of this paper. Precisely,\n\n1. The DV lower bound is just an alternative of mutual information, helping MMI predictive coding algorithm to find good coding functions C_x and C_y. The goal of MMI predictive coding is not to estimate the mutual information I(C_x(x), C_y(y)) precisely, instead, the goal is to find good coding functions. The fact that DV lower bound is small means that we can not estimate mutual information through DV lower bound, but it does not directly imply that we can not find the coding functions. I expect some experiments to show that when mutual information is large, MMI predictive coding using DV lower bound can not find good coding functions.\n\n2. In Section 3, the formula after the proof of Outlier Risk Lemma and before Theorem 1 (btw, it is better to have numbers for these formula) seems to be problematic. The first formula shows that E_{z~q} e^{F(z)} >= (1/N)e^{F_max}, then we plug it in (4). But in (4) there is negative ln of E_{z~q} e^{F(z)}, so we should have KL(P,Q) <= something, correct? This may be a typo but this typo is so important such that it affect the readability a lot. Theorem 1 is correct but the paragraphs before Theorem 1 confuse the reader a lot.\n\n3. In Section 4, are you considering classical entropy for discrete random variables, or differential entropy for continuous random variables? I assume you are considering the latter, since most people of machine learning community are interested in continuous random variables. Then your statement of I(X;Y) <= H(X) is incorrect, since for continuous random variables, H(X|Y) can be negative. See (Thomas & Cover, Chapter 8) for a reference.\n\n4. Related to problem 3, if you are considering continuous random variables, then the statement I(X;Y)=H(X)+H(Y)-H(X,Y) is not always correct. There are cases that H(X) is infinite, H(Y) is infinite, H(X,Y) is infinite but I(X;Y) is finite. These cases does not only exist in mathematical books, but also exists in practice, especially when the data is located on a low-dimensional manifold embedded in a high-dimensional space. Therefore, your approach of decompose the mutual information is not always possible.\n\n5. Regarding to your proposed optimization problem in Section 6 (also it is better to have a number), I have some concerns. Since it involves max over \\Psi outside, and inf over \\Theta and inf over \\Phi inside, so I wonder how do you solve this problem? Can you guarantee that the solution can provide good coding functions C_x and C_y? Also, it seems that this optimization problem is proposed as an improvement over the DV lower bound method, so I wish to see some experiment showing that this method is better than the DV lower bound method, at least for some synthetic datasets.\n\nBecause of the above mentioned flaws (especially 3 and 4, and lack of experiments), I think the paper is below the standard of ICLR conference.\n\nReferences:\n[1] Efficient Estimation of Mutual Information for Strongly Dependent Variables, by Gao, Ver Steeg and Galstyan, AISTATS15'\n[2] Elements of Information Theory, 2nd edition, by Thomas and Cover.\n\n\n\n"", 'This paper is about estimating mutual information in high dimensional settings. This is a very challenging open problem, that is of interest to a diverse set of research communities.\n\nIn this paper, it is theoretically argued that the recent proposed mutual information (lower bound) estimator, MINE, that is based on the Donsker-Varadhan representation of the corresponding KL divergence expression for mutual infortmation, is fundamentally flawed for high dimensions (of discrete variables).  It is further shown that lower bounds for joint entropy are hard to obtain due to exponential sample complexity. So, the authors suggest to instead obtain an upper bound for each entropy term in the mutual information expression; cross-entropy is the suggested upper bound for an entropy term.\n\nI have some basic questions as the following.\n\nSince the recent KL divergence based MI estimator, MINE, is inaccurate in high dimensions, there should be at least a discussion on connections between your estimator and the classic nearest neighbor distances based estimator of Kraskov et al. and the extensions (I suppose, even for discrete variables, one can compute distances to obtain nearest neighbors efficiently). Also, there are kernel functions based estimators.\n\nThere is no discussion in the paper about the errors accumulating from individual entropy terms in the mutual information expression. Kraskov et al. talk about this problem of accumulating errors in their seminal paper and propose not to compute the entropy terms individually. What you are proposing is in contrast to their clever observations.\n\nDoes the analysis on upper bound for entropy term also apply to the conditional entropy in the mutual information expression ? I think, there are more subtleties that should be explained.\n\nSince the proposed approach upper bounds entropy using cross entropy term (i.e. using some machine learning model like a neural network), it is even more important to show solid empirical evaluation, for synthetic as well as real world data.\n\nThere is a subtle difference between estimating mutual information and proposing an upper/lower bound for it. At present, it is not clear if the proposed upper bound of entropy would lead to an overall upper bound or lower bound for the mutual infortmation expression. The latter is important to know both in the context of optimization based on mutual information maximization (it should be lower bound in such case), as well analyzing mutual infortmation to under complex dynamics such as in brain.\n\n', 'This paper considers the problem of estimating bounds on the mutual information. It begins by showing that popular recent estimators (e.g. MINE) are flawed, since they rely on the Donsker-Varadhan bound that cannot be estimated efficiently. They then point to entropy upper bounds as a much more feasible approach to MI approximation, and propose a framework for using them in practice. These upper bounds converge as 1/sqrt(N) to the true entropy value, making them potentially viable in practice to obtain reasonable approximations of MI. \n\nGiven the significant recent attention payed to the MINE estimator and to MI estimation in machine learning generally, I think the message of this paper is very critical to the machine learning community. This analysis of the MINE estimator alone would warrant publication. \n\nThere are currently some weaknesses to this paper, however, when compared to the typical ICLR paper. If the following issues are addressed I am prepared to raise my scoring of this paper:\n1. Provide some intuition on how to apply this type of analysis to the continuous-valued case, or some reason why such an analysis would require a different framework. The more detail the better, if bounds analogous to Theorem 1 could be proved for continuous variables and added to the paper, that would be excellent.\n2. Section 4 as written is intuitively clear, but could greatly benefit from a full rigorous analysis. There is plenty of space in the paper to do this (and the supplement is available if needed). If such an analysis can’t be done, this section should be deleted.\n3. Some empirical example of MINE converging slowly in practice would greatly add to the impact of the paper.\n\nMinor issues: \nLast sentence of Section 1 should clarify what “true entropy” means. As written it is ambiguous between the actual entropy or the cross-entropy, since both are entropies.\n\nI understand the nested optimization problem in Section 6, but the presentation is somewhat unclearly written. More exposition here would help, along with a more clear step-by-step explanation of the practical procedure.\n\nEDIT: The authors have addressed my concerns and I have raised my score.\n']","[-60, -20, 50]","[20, 50, 75]","[""The sentiment score is -60 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The idea of the paper is interesting' and 'I like the idea of Theorem 1'), they ultimately conclude that the paper is 'below the standard of ICLR conference' and list several 'fatal flaws'. The reviewer's critique is quite thorough and points out multiple significant issues, indicating a generally negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I expect', 'I assume', and 'I wonder', which show respect for the authors. They also acknowledge positive aspects before critiquing. However, the use of strong language like 'fatal flaws' and direct statements about the paper's shortcomings prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance and challenge of the topic, they raise several critical questions and concerns about the paper's approach and analysis. The reviewer points out potential flaws and missing elements in the paper, suggesting that significant improvements are needed. However, the tone is not entirely negative, as the reviewer shows interest in the topic and offers constructive feedback.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They phrase their criticisms as questions or suggestions rather than direct attacks. For example, they use phrases like 'I have some basic questions' and 'there should be at least a discussion on...' which are polite ways of pointing out potential shortcomings. The reviewer also acknowledges the challenging nature of the problem at the beginning, which sets a respectful tone. However, the score is not extremely high as the review is primarily focused on critiquing the paper rather than offering praise or encouragement."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's critical message and importance to the machine learning community, stating it 'would warrant publication.' However, they also point out weaknesses and areas for improvement, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to raise their score if concerns are addressed. They use phrases like 'I think,' 'would greatly add,' and 'I understand,' which maintain a courteous tone. The reviewer also provides specific, actionable feedback without harsh criticism, demonstrating professional politeness.""]"
"['In the paper, the authors combine the federated method, sparse compression, quantization and propose Sparse Binary Compression method for deep learning optimization.  Beyond previous methods, the method in this paper achieves excellent results in the experiments. The paper is written very clearly and easy to follow. \n\nThe following are my concerns,\n1. In the introduction, the authors emphasize that there is a huge compression in the upstream communication. How about the downstream communication, I think the server should also send gradients to clients. The averaged gradient is not compressed anymore. \n\n2. I think the method used in the paper is not federated learning. Federated learning averages the models from multiple clients. however, in the paper, the proposed methods are averaging gradients instead. It is called local updates, and is a well-known tradeoff between communication and computation in the convex optimization.\n\n3. I want to point out that the similar local update (federated learning) technique has already explored, and proved not work well. In [1] the authors showed that deploying the local update simply may lead to divergence. Therefore, the iterations of the local update are constrained to be very small. e.g. less than 64.  Otherwise, it leads to divergence. I also got similar results in my experience.  The temporal sparsity in the paper looks very small. I am curious about why it works in this paper.\n\n4. Another issue is the results in the experiments. It is easy to find out that resnet50 can get 76.2% on Imagenet according to [2]. However, the baseline is 73.7% in the paper.  I didn\'t check the result for resnet18 on cifar10 or resnet34 on cifar 100, because people usually don\'t use bottleneck block for cifars.\n\n5. In Table 2, Federated average always has worse results than other compared methods. Could you explain the reason?  If using federated average is harmful to the accuracy, it should also affect the result of the proposed method. \n\n\n[1] Zhang, Sixin, Anna E. Choromanska, and Yann LeCun. ""Deep learning with elastic averaging SGD."" Advances in Neural Information Processing Systems. 2015\n[2]https://github.com/D-X-Y/ResNeXt-DenseNet', ""The paper once again looks at the problem of reducing the communication requirement for implementing the distributed optimization techniques, in particular, SGD. This problem has been looked at from multiple angles by many authors. And although there are many unanswered questions in this area, I do not see the authors providing any compelling contribution to answering those questions. A big chunk of the paper is devoted to expressing some shallow theorems, which in some cases I do not even see their importance or connection to the main point of the paper; see my comments below. In terms of the techniques for reducing the communication burden, the authors seem to just put all the other approaches together with minimal novelty.\n\nMore detailed comments:\n- I do not really understand what the authors mean by noise damping. I would appreciate it if they could clarify that point. This seems to be a very important point as the model they propose for the noise in the process is basically based on this notion. It is a great failure on the authors' part that such a crucial notion in their paper is not clearly described. \n- The model that is proposed for noise is too strong and too simplistic. Do you guys have any evidence to back this up?\n- Theorem 2.1 is not a theorem. The result is super shallow and relatively trivial. \n- In corollary 2.1 it seems that no matter what the randomness in the system is, the algorithm is going to converge to the same solution. This is not true even for the non-strongly convex objectives, let alone the non-convex problems where there are so many stationary solutions and whatnot.\n- With regards to Fig 3 (and other related figures in the appendix) and the discussion on the multiplicative nature of compression: The figure does not seem to suggest multiplicative nature in all the regimes. It seems to hold in high compression/ low-frequency communication regime. But on the other side of the spectrum, it does not seem to hold very strongly.\n- The residual accumulation only applies when all the nodes update in all the iterations. I do not believe this would generalize to the federated learning, where nodes do not participate in all the updates. I do not know if the authors have noted this point in their federated learning experiments.\n- Theorem 3.1 is very poorly stated. Other that than it is shallow and in my opinion irrelevant. What is the argument in favor of the authors' thought that could be built based on the result of Theorem 3.1?\n- One major point that is missing in the experiments (and probably in the experiments in other papers on the same topic) is to see how much do all these compressions affect the speed of learning in different scenarios in realistic scenarios? Note that in realistic scenarios many things other than communication could affect the convergence time."", ""Lowering costs for communicating weights between workers is an important intermediate goal for distributed optimization, since presumably it can limit the parallelization achievable once available bandwidth is saturated.  This work reports reasonable approaches to try to overcome this through a mix of techniques, though none in particular seem especially novel or surprising.  For example, the abstract claims a novel binarization method, but what is described in the paper does not seem especially novel (e.g. zero the negative weights and replace positives with their mean, if negative's mean < positive's mean, else vice versa); but more importantly, the experiments don't explore/support why this approach is any better (or when worse) than other schemes.\n\nTo its credit, the paper provides experiments data (ImageNet and Cifar, not just MNIST) and models (e.g. ResNet50) that can support reasonable claims of being representative of modern optimization tasks.  What the paper is most lacking, though, is a clear and convincing argument that the large bit compression rates claimed actually lead to significant time speedups of the resulting optimization.  The paper seems to just assume that lowering communication costs is inherently good and this goodness is proportional to the rate of compression.  But as Table 3 shows, there IS some degrading in accuracy for this reduction in communication overhead.  Whether this is worth it depends critically on whether the lower overhead actually allows optimization to speedup significantly, but the time of training seems to not be mentioned anywhere in this paper.  Thus, in its current form, this paper does not clearly establish the significance and limits of their approach.  Given that the novelty does not appear high, the value of this current paper is mainly as an engineering analysis of some design tradeoffs.  And viewed that way, this paper is a bit disappointing in that tradeoffs are not acknowledged/examined much. E.g. readers cannot tell from these experiments when the proposed approach will fail to work well -- the limitations are not clearly established (all results provided are cast in positive light).""]","[-20, -70, -30]","[60, -30, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clarity and excellent results, they raise several significant concerns and questions about the methodology, results, and comparisons. These concerns outweigh the initial positive comments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their concerns as questions or observations rather than direct criticisms. They use phrases like 'I think,' 'I want to point out,' and 'Could you explain,' which maintain a polite tone while still addressing their concerns. The reviewer also begins with positive comments before moving to their concerns, which is a courteous approach in academic reviews."", ""The sentiment score is -70 because the reviewer expresses strong criticism throughout the review, stating that they 'do not see the authors providing any compelling contribution' and describing parts of the paper as 'shallow' and 'trivial'. The reviewer also points out multiple perceived flaws and shortcomings in the paper's methodology and results. The politeness score is -30 because while the reviewer maintains a professional tone overall, there are instances of blunt and somewhat harsh language. Phrases like 'It is a great failure on the authors' part' and 'Do you guys have any evidence to back this up?' come across as somewhat rude and confrontational. The reviewer does not use overtly polite language or soften their criticisms, leading to a negative politeness score."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'reasonable approaches', 'experiments data... that can support reasonable claims'), they express several criticisms. These include lack of novelty, insufficient exploration of why their approach is better, and failure to establish significant time speedups. The overall tone suggests the paper falls short of expectations.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use neutral language and provide specific feedback without harsh criticism. Phrases like 'To its credit' and 'reasonable approaches' show an attempt to acknowledge positives. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a mostly neutral, objective tone.""]"
"['This paper studies the problem of making predictions with a model trained using dropout. Authors try to provide a theoretical foundation for using dropout when making predictions. For this purpose, they show that when using dropout training we are maximizing a common lower bound on the objectives of a family of models, including most of the previously used methods for prediction with dropout. \n\nI find that the paper addresses a relevant problem and try to apply a novel approach. But, in general, I find the paper is not easy to follow and to grasp the main ideas. \n\nHere I detail my main concerns:\n\n\n1. This is one of my main concerns. The contraposition between the geometric and the average model. I don\'t like this contraposition. The average model is just the standard marginalization operation over the weights, $p(y|x) = \\int p(y|x,w)p(w|\\Theta)dw$. This is the natural solution for the prediction problem to the problem if we accept the generative model given in Eq (3). \n\nIn the case of the variational dropout, we depart from the same generative model, but we employ an approximation. It is the variational approximation the one that induces the geometric mean provided in eq (6). I.e. if we want to compute the posterior over the label y* for a sample x*, after training, we should compute the associated lower bound\n$\\ln p(y*|x*) >= E_q[\\ln p(y*|x*,w)] - KL(q|p)$\nIn this case, q(w) = p(w|\\Theta), as stated Eq (3) and in the corresponding equation provided in page 2 (the q(w) is not learnt because it only depends on the dropout rate, while the $\\Theta$ are learnt by maximum log-likelihood and do not have a $q$ associated).  This gives rise to the geometric mean approximation provided in Eq (6).  I.e. the geometric mean prediction is simply the result of using a variational approximation at prediction time.   \n\nMy problem here is that authors employ convoluted arguments to introduce this geometric mean prediction and the average prediction, without making the connection discussed above. \n\n3. Section 3.3 and 3.4 introduces new arguments for modifying the dropout rate (and the alpha) parameter at test time. But, again, I find the arguments convoluted. We consider the dropout rate a hyper-parameter of the model, the standard learning theory tells us to fix the parameters with the training data and evaluate them later when making predictions. Why should we use different dropout rates at training and testing? Authors arguments about the tightness of the bound of Eq (8) and Eq(9). are not convincing to me. \n\nSo, I don\'t find authors provide convincing answers to the raised questions at the beginning of the paper about the use of dropout when making predictions. \n\nMinor comments:\n\n1. The generative model for Variational dropout is the same than the generative model for the ""conditional model"", eq. (3). \n\n2. In Eq. (7) authors are defining the weighted power mean. I think it would be clearer to directly introduce the weighted power mean instead of the standard power mean in Section 3.2.\n\n3. Section 3.3. I find some parts are difficult to understand. ""suppose we pick a base model from the power mean family and have a continuum of subvariants with gradually reduced variance in their predictions but the same expectation."" Later, I can understand authors are referring to the possibility of reducing the dropout rate. ', 'The paper point that the dropout in training is equivalent to MAP estimate of hierarchical models when the prior distribution of weights, \\Theta, is a zero mean Gaussian. Based on that observation the authors propose several different evaluation methods for dropout. The experimental results show that the proposed evaluation methods improved the performance of language models.\n\nAre there any experimental results of the proposed evaluation methods for another type of data beyond language modeling?\n\nDo the term ""deterministic dropout"" in the last sentence of the first paragraph on page 1 and the one in Sec 3 (the first bullet) refer to the same thing? \n\nMinor: gaussian -> Gaussian', 'Different from an existing variational dropout method which used variational inference to explain Dropout, this paper proposes to interpret Dropout from the MAP perspective. More specifically, the authors utilize the Jensen inequality to develop a lower bound for log-posterior, which is used as training objective for dropout. They then exploit the power mean to develop the conditional power mean model family, which provide additional flexibility for evaluation during validation.\nEven though the way how the proposed method is analyzed/generalized is interesting, the proposed method is not convincing, but I am not absolutely sure. Besides the paper is hard to follow, some other concerns are listed below.\n(1) “…the original/usual dropout objective” and “the dropout rate” are not defined in the paper, even though they appear many times in the paper.\n(2) In the last paragraph of Sec. 2, the authors argue that utilizing their MAP objective “sidestep any questions about whether variational inference makes sense.” However, the presented MAP lower bound has its own problem, since it is derived using the Jensen inequality.  For example, as shown in Appendix C, the equality becomes true only when p(w|\\Theta) is a delta function.\n(3) How to tune the hyperparameters (alpha, lambda) of the extended dropout family in practice?\n(4) The current experiments might be weak. Additional experiments on popular image datasets are recommended.\n\nMinors:\n(1) In Eq. (3), is p(w_r|\\Theta) of the second formula identical to p(w|\\Theta) of the third formula?\n(2) In the second row below Eq. (6), E_w p(w|\\Theta) p(y|x,w) is a typo.\n']","[-30, 50, -50]","[20, 75, 20]","[""The sentiment score is -30 because while the reviewer acknowledges the paper addresses a relevant problem and tries a novel approach, they express several major concerns and find the paper difficult to follow. The reviewer states 'I find the paper is not easy to follow and to grasp the main ideas' and provides detailed critiques of the paper's arguments and methodology. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I find' and 'My problem here is' rather than making blunt criticisms. They also offer some positive comments initially. However, the review is not overly polite, as it directly states concerns without much softening language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and the improved performance of the proposed methods. However, they also raise questions and point out a minor issue, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language, frames their comments as questions rather than criticisms, and refers to the 'minor' nature of one correction. The reviewer's tone is professional and constructive throughout, without any harsh or dismissive language."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, stating it is 'not convincing' and 'hard to follow'. They list several major issues with the methodology and experiments. However, it's not entirely negative as they find some aspects 'interesting'. The politeness score is 20 because the reviewer uses relatively neutral language and softens some criticisms (e.g., 'I am not absolutely sure'). They also provide constructive feedback and suggestions for improvement, which is polite. The tone is professional and not overtly rude, but also not excessively polite.""]"
"['The paper at hand describes an approach to enable neural networks to take arbitrary structured data (basically any data that is not easily represented as a fixed-dimensional vector) as input. The paper describes how such data can be represented as a set (e.g. a sequence is represented as a set of index + data) and then an auxiliary network called the set aggregating network (SAN)  is used to represent the data in a high dimensional latent space. In addition to the idea, the paper provides a theoretical analysis of the approach which shows that with a sufficiently high dimensional representation the network is able to learn a unique representation for each input example. \n\nGood in this paper: \n - nicely on topic - this is truly about learning representations\n - interesting idea with some (albeit not-surprising) theoretical analysis\n\nNot yet great in this paper: \n - the paper feels a bit premature in multiple ways, to me most importantly the experiments appear to be really rushed. \n  Looking at table 1 - it is really unclear how to read this. The table is hardly explained and it would be good to actually compare the method to the state of the art. I understand that the authors care more about generality here - but it\'s much easier to build something generic that is very far from the state of the art than to build something that is closer to the state of the art. Also - I feel it would have been interesting to allow for a more direct comparison of the SAN results with the other methods. Similarly, in Table 2 - how far away is this from the state of the art.\n- the variable size image-recognition task seems a bit artificial - I believe that scaling images to a fixed size is a reasonable idea and is well understood and also something that humans can work with. Dealing with variable size images for the purpose of not having a fixed size vector seems artificial and unnecessary - in this case here specifically the images are same size to begin with. By using SAN you loose a lot of the understanding of computer vision research of the last decade (e.g. it\'s clear that CNNs are a good idea - with SAN - you cannot really do that anymore) - so, I feel this experiment here doesn\'t add anything. \n\nI feel these comments can probably be addressed by rethinking the experimental evaluation. At this point, I think the paper provides a nice idea with a theoretical analysis - but it doesn\'t provide enough experimental evidence that this works. \n\nMinor comments: \n - p1: Analogically -> just drop the word\n- p1: citation of Brin & Page -> this seems a bit out of place - yes, it is a method working on graphs, but it is not relevant in the context of the paper - to the best of my knowledge there are no neural networks in this. \n- p2: where Radon - >where the Radon\n- p2: ""One can easily see "" -> I cannot. Please ellaborate', '+ Results for SAN are on par with hand-crafted feature sets.\n+ An easy to implement strategy to get from a set of an arbitrary number of fixed-length input vectors to one fixed-length output vector representing the set.\n\n\n- The work is quite straight-forward and incremental as it basically replaces max-pooling with another function (RELU).\n- Adding zero tuples (x,0) as input for the SAN is basically zero-padding. Therefore, the differences/advantages to zero padding and other pooling strategies do not become clear.\n- The obvious baseline of using doc2vec for text classification is missing. This baseline would be beneficial to set the results into context. \n- Reference to Schlichtkrull et al. [1] is missing who are actually doing something quite similar for graph data.\n\n\nSince the work is quite straight-forward and the comparisons to related work are not sufficiently covered, I am currently leaning towards rejecting this paper.\n\n\n\n[1] Schlichtkrull, M., Kipf, T. N., Bloem, P., van den Berg, R., Titov, I., & Welling, M. (2018, June). Modeling relational data with graph convolutional networks. In European Semantic Web Conference (pp. 593-607). Springer, Cham.\n', 'Summary:\n\nThe paper argues that plain (fully connected) neural networks cannot represent structured data, e.g. sequences, graphs, etc. Specialized architectures have instead been invented for each such case, e.g. recurrent neural networks, graph networks etc. The paper then proposes to treat these structured data types as sets and propose a neural network method for converting a set into a fixed size vector, which can then be classified using plain neural networks. The method works by projecting each member of the set into M dimensions where they are passed through a ReLU and summed. The paper proves that given high enough dimensionality M, no information will be lost during this process. The paper performs experiments on graph data, text data and image data. The paper concludes ""We proposed a general framework for processing structured data by neural network.""\n\nQuality:\n\nThe paper seems rushed. I think the paper has some language problems which unfortunately detract from the overall impression. ""through its all one-dimensional projections"". Should that be ""through all its one-dimensional projections""? ""Analogically"". ""can lead to the >lose< of meaningful information"". ""where (the?) Radon transform"". \n\nClarity:\n\nThe aim and purpose of the paper is fairly clear. I think the method explanation is overly complicated. If I understand correctly, the proposed method is simply to map each set element to an M dimensional space using a linear projection followed by a ReLU and then summing the set elements. The section on how to implement it in practice further complicates the paper unnecessarily in my opinion. It\'s not clear why or whether the ReLU is important.\n\nOriginality:\n\nTransforming sets into fixed size vectors is not new. See e.g. [1] and [2], which the paper does not reference or compare to.\nTo the papers defence I think the main idea is to map any structured data into a set, and then use a (relatively) simple method on it.\n\nSignificance:\n\nThe paper acknowledges that methods do indeed exist for the various structured data types, but claim that they are complex, and that the proposed method is a simple general alternative. As such the significance of the paper hinges on whether the proposed method is indeed simpler, and how it compares when it comes to performance. The proposed method is simple and general, but it does require that the information lost when converting the structured data to the set is encoded as features in the set elements, e.g. the sequence index is added. For images, the normalized position must be added. For graphs, the edges should be added, which interestingly is not done in the single graph experiment (I\'d be curious how the edges could be added). This detracts somewhat from the claim to generality, since each structured data type must still be handled differently.\n\nIt\'s clear to me that the structural priors built into the specialized networks, e.g. recurrent, graph, etc. should help for these data structures. For this reason I think the proposed method will have a hard time comparing head to head. That is OK, it becomes a tradeoff between generality versus performance. Unfortunately I\'m not convinced of the performance by the experiments. Specifically the proposed method is not compared head to head against the methods it proposes to replace. \n * On the graph data it is compared against various classifiers that use a fixed size, handcrafted representation. This is disingenuous in my opinion. For graph data, the natural method it proposed to replace is a graph neural network. \n * On the sequence data it is compared against a 1D convolutional neural network. The canonical sequence model is a recurrent neural network. Also for the larger IMDB dataset the performance drop against a CNN is considerable.\n * The image experiments are probably the strongest case. Here the authors make a compelling case that the SAN pooling operator is better than max-pooling. Unfortunately the authors use a dataset which have already been size normalized during pre-processing, and then un-normalize it. It\'d be more convincing if the authors showed superior performance on a dataset of images of varying sizes using SAN, compared to normalizing them during pre-processing (with comparable runtime and parameter counts).\n\nPros:\n - Ambitious aim\n - Simple method\n\nCons: \n - Proposing to replace xyz methods, then not fairly comparing to them in their respective domains.\n - Not referencing relevant prior work on neural networks for sets.\n - Paper seems rushed/unfinished\n - Implicitly assumes classification/regression for entire structured data. In many cases, e.g. Named Entity Recognition, and many graph problems, the problem is to classify/regress on the individual elements, as part of the whole.\n\nI could see the paper accepted, if sold less as the end-all solution for structured data and more as simply an improved pooling operator, with SOTA experiments to back up the claims. This would also allow the authors to use SOTA methods for pre-processing the data, e.g. RNNs, graph neural networks, etc., as they don\'t need to compete against every method. \n\n(btw. instead of zero padding the batches, the authors can probably maintain a list of indices of set elements and use https://www.tensorflow.org/api_docs/python/tf/math/segment_sum)\n\n[1] - Vinyals, Oriol, Samy Bengio, and Manjunath Kudlur. ""Order matters: Sequence to sequence for sets."" arXiv preprint arXiv:1511.06391 (2015).\n[2] - Zaheer, Manzil, et al. ""Deep sets."" Advances in Neural Information Processing Systems. 2017.']","[-20, -50, -30]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Good in this paper'), they express more concerns and criticisms ('Not yet great in this paper'). The reviewer states the paper feels 'premature' and lacks sufficient experimental evidence, which contributes to the negative sentiment. However, it's not extremely negative as they suggest the issues 'can probably be addressed'. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledging good points before criticisms, and phrases feedback as suggestions rather than demands (e.g., 'I feel these comments can probably be addressed'). They also use polite hedging language like 'I feel' and 'I believe'. The tone is constructive rather than harsh, though not overly formal or deferential."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Results for SAN are on par with hand-crafted feature sets', 'An easy to implement strategy'), they express more significant criticisms ('quite straight-forward and incremental', 'differences/advantages... do not become clear', 'obvious baseline... is missing') and ultimately lean 'towards rejecting this paper'. This indicates an overall negative sentiment, though not extremely so. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh or rude phrasing. They present criticisms constructively and acknowledge positive aspects, which adds a degree of politeness. However, the tone remains primarily neutral and matter-of-fact, rather than overtly polite or deferential."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Ambitious aim', 'Simple method'), the overall tone is critical. The reviewer points out several significant issues with the paper, including rushed appearance, lack of fair comparisons, missing references, and unconvincing experiments. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and balancing criticisms with positive observations. The language used is respectful and avoids harsh or personal criticisms, instead focusing on the content and methodology of the paper.""]"
"['# Summary\n\nThis submission proposes a multi-task convolutional neural network architecture for end-to-end driving (going from an RGB image to controls) evaluated using the CARLA open source simulator. The architecture consists of an encoder and three decoders on top: two for perception (depth prediction and semantic segmentation), and one for driving controls prediction. The network is trained in a two-step supervised fashion: first training the encoder and perception decoders (using depth and semantic segmentation ground truth), second freezing the encoder and training the driving module (imitation learning on demonstrations). The network is evaluated on the standard CARLA benchmark showing better generalization performance in new driving conditions (town and weather) compared to the CARLA baselines (modular pipeline, imitation learning, RL). Qualitative results also show that failure modes are easier to interpret by looking at predicted depth maps and semantic segmentation results.\n\n\n# Strengths\n\nSimplicity of the approach: the overall architecture described above is simple (cf. Figure 1), combining the benefits of the modular and end-to-end approaches into a feed-forward CNN. The aforementioned two-stage learning algorithm is also explained clearly. Predicted depth maps and semantic segmentation results are indeed more interpretable than attention maps (as traditionally used in end-to-end driving).\n\nEvaluation of the driving policy: the evaluation is done with actual navigation tasks using the CARLA (CoRL\'18) benchmark, instead of just off-line behavior cloning accuracy (often used in end-to-end driving papers, easier to overfit to, not guaranteed to transfer to actual driving).\n\nSimple ablative analysis: Table 2 quantifies the generalization performance benefits of pretraining and freezing the encoder on perception tasks (esp. going from 16% to 62% of completed episodes in the new town and weather dynamic navigation scenario).\n\n\n# Weaknesses\n\n## Writing\n\nI have to start with the most obvious one. The paper is littered with typos and grammatical errors (way too many to list). For instance, the usage of ""the"" and ""a"" is almost non-existent. Overall, the paper is really hard to read and needs a thorough pass of proof-reading and editing. Also, please remove the acknowledgments section: I think it is borderline breaking the double-blind submission policy (I don\'t know these persons, but if I did that would be a breach of ICLR submission policy). Furthermore, I think its contents are not very professional for a submission at a top international academic venue, but that is just my opinion. \n\n\n## Novelty\n\nThis is the main weakness for me. The architecture is very close to at least the following works:\n- Xu, H., Gao, Y., Yu, F. and Darrell, T., End-to-end learning of driving models from large-scale video datasets (CVPR\'17): this reference is missing from the paper, whereas it is very closely related, as it also shows the benefit of a segmentation decoder on top of a shared encoder for end-to-end driving (calling it privileged training);\n- Codevilla et al\'s Conditional Imitation Learning (ICRA\'18): the only novelty in the current submission w.r.t. CIL is the addition of the depth and segmentation decoders;\n- Müller, M., Dosovitskiy, A., Ghanem, B., & Koltun, V., Driving Policy Transfer via Modularity and Abstraction (CoRL\'18): the architecture also uses a shared perception module and segmentation (although in a mediated way instead of auxiliary task) to show better generalization performance (including from sim to real).\n\nAdditional missing related works include:\n- Kim, J. and Canny, J.F., Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention (ICCV\'17): uses post-hoc attention interpretation of ""black box"" end-to-end networks;\n- Sauer, A., Savinov, N. and Geiger, A., Conditional Affordance Learning for Driving in Urban Environments (CoRL\'18): also uses a perception module in the middle of the CIL network showing better generalization performance in CARLA (although a bit lower than the results in the current submission).\n- Pomerleau, D.A., Alvinn: An autonomous land vehicle in a neural network (NIPS\'89): the landmark paper for end-to-end driving with neural networks!\n\n\n## Insights / significance\n\nIn light of the aforementioned prior art, I believe the claims are correct but already reported in other publications in the community (cf. references above). In particular, the proposed approach uses a lot more strongly labeled data (depth and semantic segmentation supervision in a dataset of 40,000 images) than the competing approaches mentioned above. For instance, the modular pipeline in the original CARLA paper uses only 2,500 labeled images, and I am sure its performance would be vastly improved with 40,000 images, but this is not evaluated, hence the comparison in Table 1 being unfair in my opinion. This matters because the encoder in the proposed method is frozen after training on the perception tasks, and the main point of the experiments is to convince that it results in a great (fixed) intermediate representation, which is in line with the aforementioned works doing mediated perception for driving.\n\nThe fine-tuning experiments are also confirming what is know in the litterature, namely that simple fine-tuning can lead to catastrophic forgetting (Table 3).\n\nFinally, the qualitative evaluation of failure cases (5.3) leads to a trivial conclusion: a modular approach is indeed more interpretable than an end-to-end one. This is actually by design and the main advocated benefit of modular approaches: failure in the downstream perception module yields failure in the upstream driving module that builds on top of it. As the perception module is, by design, outputting a human interpretable representation (e.g., a semantic segmentation map), then this leads to better interpretation overall.\n\n\n## Reproducibility\n\nThere are not enough details in section 3.1 about the deep net architecture to enable re-implementation (""structure similar to SegNet"", no detailed description of the number of layers, non-linearities, number of channels, etc).\n\nWill the authors release the perception training dataset collected in CARLA described in Section 4.2?\n\n\n\n# Recommendation\n\nAlthough the results of the proposed multi-task network on the CARLA driving benchmark are good, it is probably due to using almost two orders of magnitude more labeled data for semantic segmentation and depth prediction than prior works (which is only practical because the experiments are done in simulation). Prior work has confirmed that combining perception tasks like semantic segmentation with end-to-end driving networks yield better performance, including using a strongly related approach (Xu et al). In addition to the lack of novelty or new insights, the writing needs serious attention.\n\nFor these reasons, I believe this paper is not suitable for publication at ICLR.', ""Major Contribution:\nThis paper details a method for a modified end-to-end architecture that has better generalization and explanation ability. The paper outlines a method for this, implemented using an autoencoder for an efficient feature extractor. By first training an autoencoder to ensure the encoder captures enough depth and segmentation information and then using the processed information as a more useful and compressed new input to train a regression model. The author claimed that this model is more robust to a different testing setting and by observing the output of the decoder, it can help us debug the model when it makes a wrong prediction.\n\nOrganization/Style:\nThe paper is well written, organized, and clear on most points. A few minor points:\n1) On page 5, the last sentence, there is a missing table number.\n2) I don't think the last part FINE-TUNE Test is necessary since there are no formal proofs and only speculations.\n\nTechnical Accuracy:\nThe problem that the paper is trying to address is the black-box problem in the end-to-end self-driving system.\nThe paper proposes a method by constructing a depth image and a segmentation mask autoencoder. Though it has been proved that it is effective in making the right prediction and demonstrated that it has the cause explanation ability for possible prediction failures. I have a few points:\nThe idea makes sense and the model will always perform better when the given input captures more relevant and saturated representations. The paper listed two important features: depth information and segmentation information. But there are other important features that are missing. In other words, when the decoder performs bad, it means the encoder doesn't capture the good depth and segmentation features, then it will be highly possible that the model performs badly as well. However, when the model performs bad, it does not necessarily mean the decoder will perform badly since there might be other information missing, for example, failure to detect the object, lines and traffic lights etc.\n\nIn conclusion, the question is really how to get a good representation of a self-driving scene. I don't think to design two simple autoencoders for depth image construction and image segmentation is enough. It works apparently but it is not good enough.\n\nAdequacy of Citations: \nGood coverage of literature in self-driving."", 'This paper presents one end-to-end multi-task learning architecture for depth & segmentation map estimation and the driving prediction. The whole architecture is composed of two components, the first one is the  perception module (segmentation and depth map inference), the second one is the driving decision module. The training process is sequential, initially train the perception module, then train the driving decision task with freezing the weights of the perception module. The author evaluated the proposed approach on one simulated dataset, Experimental results demonstrated the advantage of multi-task compared to the single task. \n\nAdvantages:\nThe pipeline is also easy to understand, it is simple and efficient based on the provided results.\nThe proposed framework aims to give better understanding of the application of deep learning in self-driving car project. Such as the analysis and illustration in Figure 3. \n\nQuestions:\nThere are several typos needed to be addressed. E.g, the question mark in Fig index of section 5.1. There should be comma in the second sentence at the last paragraph of section 5.2.  \nMulti-task, especially the segmentation part is not novel for self-driving car prediction, such as Xu et al. CVPR’ 17 paper from Berkeley. The experiment for generalization shows the potential advancement, however, it is less convincing with the limited size of the evaluation data, The authors discussed about how to analyze the failure causes, however, if the perception  learning model does not work well, then it would be hard to analyze the reason of incorrectly prediction.\n\nIn general, the paper has the merits and these investigations may be helpful for this problem, but it is not good enough for ICLR.\n\n']","[-70, 50, -20]","[-20, 75, 50]","[""The sentiment score is -70 because the review is overall quite negative. The reviewer states the paper is not suitable for publication, citing lack of novelty, poor writing quality, and unfair comparisons. They do mention some strengths, but these are outweighed by the criticisms. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are some rather blunt criticisms, especially regarding the writing quality ('littered with typos', 'really hard to read') and the acknowledgments section ('not very professional'). The reviewer does not use overtly rude language, but the tone is quite harsh in places, lacking the hedging and softening language that would be expected in a more polite review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and merits, describing it as 'well written, organized, and clear on most points'. However, they also raise some concerns and suggest improvements, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. They acknowledge the paper's strengths before discussing areas for improvement, and use phrases like 'I don't think' to soften critiques, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merits of the paper ('The pipeline is easy to understand', 'The proposed framework aims to give better understanding'), they ultimately conclude that 'it is not good enough for ICLR'. They also point out several issues and limitations. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They phrase criticisms as questions or suggestions rather than harsh statements. The use of phrases like 'may be helpful' and 'has the merits' contributes to a polite tone, even while delivering a negative overall assessment.""]"
"['The paper presents a VAE that uses labels to separate the learned representation into an invariant and a covariant part. The method is validated using experiments on the MNIST dataset.\n\nThe writing in this paper is somewhat problematic. Although it is hard to put the finger on a particularly severe instance, the paper is filled with vague and hyperbolic statements. Words like ""efficiently"", ""meaningful"", ""natural"", etc. are sprinkled throughout to confer a positive connotation, often without having a specific meaning in their context or adding any information. Where the meaning is somewhat clear, the claims are often not supported by evidence. Sometimes the claims are so broad that it is not clear what kind of evidence could support such a claim.\n\nA relatively large amount of space is used to explain the general concept of invariant/covariant learning, which, as a general concept, is widely understood and not novel. There are other instances of overclaiming, such as ""The goal of CoVAE is to provide an approach to probabilistic modelling that enables meaningful representations [...]"". In fact, CoVAE is a rather specific model(class), rather than an approach to probabilistic modelling.\n\nThe paper is at times meandering. For instance, the benefits of and motivation for the proposed approach are not simply stated in the introduction and then demonstrated in the rest of the paper, but instead the paper states some benefits and motivations, explains some technical content, mentions some more benefits, repeats some motivations stated before, etc.\n\nMany researchers working on representation learning hope to discover the underlying learning principles that lead to representations that seem natural to a human being. In this paper, labels are used to guide the representation into the ""right"" representation. It is in my opinion not very surprising that one can use labels to induce certain qualities deemed desirable in the representation.\n\nTo conclude, because of the writing, limited novelty, and limited experiments, I think this paper currently does not pass the bar for ICLR.', 'This paper is well written, and the quality of the figures is good. In this paper, the authors propose an invariant-covariant idea, which should be dated back at least to the bilinear models. The general direction is important and should be pursued further. \n\nHowever, the literature is not well addressed. Eslami et al. 2018 have been cited, but some very important and related earlier works like: \n[1] Kulkarni et al. 2015, Deep Convolutional Inverse Graphics Network\n[2] Cheung et al. 2015, Discovering Hidden Factors of Variation in Deep Networks\nwere not discussed at all. The authors should certainly make an effort to discuss the connections and new developments beyond these works. At the end of section 1, the authors argue that the covariant vector could be more general, but in fact, these earlier works can achieve further equivalence, which is much stronger than the proposed covariance.\n\nThere is also an effort to compare this work to Sabour et al. 2017 and the general capsule idea. I would like to point out, the capsule concept is a much more fine-grained what & where separation rather than a coarse-grained class & pose separation in one shot. In a hierarchical representation, what & where can appear at any level as one class can consist of several parts each with a geometrical configuration space. So the comparison of this work to the generic capsule network is only superficial if the authors can not make the proposed architecture into a hierarchical separation. Besides different capsule network papers, I found another potentially useful reference on a fine-grained separation:\n[3]Goroshin et al., Learning to Linearize Under Uncertainty\n\nIn the paper, it is argued several times that the latent vector r_y contains a rich set of global properties of class y, rather than just its label and the aim is that it can learn what the elements of the class manifold have in common. But this point is not supported well since we can always make a label and this latent vector r_y equivalent by a template. I think this point could be meaningful if we look at r_y\'s for different y, where each of the dimension may have some semantic meaning. Additional interpretation is certainly needed.\n\nUnder equation (3), ""Note that v is inferred from r_y"" should be ""inferred from both r_y and x"", which is pretty clear from the fig 5. Related to this, I could imagine some encoder can extract the \'style\' directly from x, but here both r_y and x are used. I couldn\'t find any guarantee that v only contains the \'style\' information based on the architecture with even this additional complication, could the authors comment on this?\n\nEquation (5) is not really a marginalization and further equation (6) may not be a lower bound anymore. This is probably a relatively minor thing and a little extra care is probably enough.\n\nThe numbers in table 2 seems a little outdated.\n\nTo conclude, I like the general direction of separating the identity and configurations. The natural signals have hierarchical structures and the class manifold concept is not general enough to describe the regularities and provide a transparent representation. Rather, it\'s a good starting point. If the authors could carefully address the related prior works and help us understand the unique and original contributions of this work, this paper could be considered for publication.', 'The paper proposes a genarative model for images which explicitly separates the within class variation \n(the covariant part) from the across class variation (invariant part). Functionally, this achieves a similar \nresult as various recent works on incorporating invariances in neural nets, but the fact that it is able \nto explicitly construct models for both parts of the distribution is nice. Results on MNIST are good, \nbut of course this is a very simple dataset. It would be very interesting to see how the model \nperforms on a more realistic problem. \n\nAdmittedly, I am not an expert in generative models. This is a clean paper with a clear goal, it is hard \nfor me to judge how original the idea is.\n\n""Covariant"" might not be the best word to use here because it has a very specific meaning in the context \nof some other neural networks related to how quantities transform according to representations of a symmetry \ngroup. This is a potential source of confusion. ']","[-70, 20, 50]","[-20, 60, 75]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's writing style, lack of novelty, limited experiments, and overclaiming. The conclusion explicitly states that the paper does not pass the bar for ICLR. There are no positive comments to balance these criticisms. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and direct. Phrases like 'somewhat problematic,' 'overclaiming,' and 'meandering' are used without much softening language. The reviewer also doesn't offer many constructive suggestions for improvement, which contributes to the slightly impolite tone."", ""The sentiment score is 20 (slightly positive) because the reviewer starts with positive comments about the paper being well-written with good figures, and acknowledges the importance of the general direction. However, they then raise several significant concerns and criticisms, which balance out the initial positivity. The overall tone suggests the paper needs substantial revisions but has potential. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I would like to point out' and 'could the authors comment on this?' which maintain a collegial tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional, slightly formal tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's good results on MNIST and the clear goal, while also expressing interest in seeing the model's performance on more realistic problems. The reviewer admits not being an expert, which tempers the positive sentiment slightly. The politeness score is 75 (quite polite) due to the reviewer's respectful tone, use of phrases like 'it would be very interesting,' and the honest admission of their expertise level. The reviewer also offers constructive feedback about terminology without being harsh. The language throughout is professional and courteous.""]"
"['This is nicely written paper analyzing the effect of various pre-training methods and shows that language models are very effective on sequence tagging tasks (POS, CCG). The experiments are well motivated and well described.\n\nRegarding Table 1: which one of the ""LM forward"" models was used in the subsequent experiments? \n\nAre the input embeddings for the random init LSTM pre-trained or are they also randomly initialized?', ""This paper tests various pretraining objectives (language modeling, machine translation, skip-thought, and autoencoding) on two syntactic tasks: POS tagging and CCG tagging. It finds that language modeling outperforms the other pretraining objectives; additionally, randomly-initializing an encoder achieves decent performance when given a large amount of labeled data for the tagging task. The experiments in this paper are very thorough and explained well. By controlling for pretraining data size, the authors are able to reasonably claim that language modeling is superior to translation as a syntactic transfer learning task. On the other hand, I have some concerns regarding the significance of the paper's contributions, and as such I am borderline on its acceptance. \n\ncomments:\n- the experiments in the paper feel biased towards language modeling. Language modeling is the only token-level prediction task of the four objectives here, but both of the two downstream tasks are at the token level. It is perhaps unsurprising then that language modeling performs best; perhaps the authors could have considered some sentence-level downstream tasks as well to properly control for this? Or added some more word-level pretraining objectives? \n\n- sort of relatedly, the authors do not provide any explanations as to *why* language modeling is a better pretraining objective than translation. What kinds of examples do the tagging models using LM pretraining get right that the translation models do not? Such an analysis could help provide more concrete insights into what kind of information each objective is encoding.\n\n- the claim that LMs > translation is not a new finding. The authors cite Blevins et al, who find the same result on the task of dependency arc prediction. Similarly, the surprisingly good performance of random encoders was also found in Conneau et al., ACL 2018. As the main contribution of this paper seems to be a more controlled study of Blevins et al on different syntactic tasks, I don't think there is enough here for an ICLR submission. \n\n- what is the effect of the specific dataset and architecture on the results? Here we just look at a couple translation datasets (all news data) and LSTM models. Do things change when we move to transformers or more diverse domains? "", '\nI have mixed feelings about this paper. On one hand, it’s a thorough and well-written experimental paper, something which is really important but is also clearly underappreciated in the machine learning community. On the other, it was not really obvious to me why some of objectives tested here are interesting: LM objectives like ELMo have seen a lot of uptake in the NLP community (and this is definitely an NLP paper), but most of the others—like skip-thought, MT, and autoencoders—have not. So the basic research question doesn’t seem like an especially burning one. The trends in Fig. 2 show that these alternatives underperform an LM objective, which suggests that the NLP community can keep using that objective without worry—and everything else in the figure seems as we would expect. \n\nIn short, I think the paper is a well-done study on a hypothesis of perhaps minor interest. The results are sensible but confirm what we already strongly suspected, and they seem unlikely to strongly influence other research, since they confirm that everyone has been the right thing all along. I’m not entirely sure what I learned from this.\n\nTo me, the most interesting experiment is the final one in Section 6. This experiment seems like it could be the germ for a far more interesting paper getting at how these pretraining objectives help with downstream tasks. As it stands, it feels like an interesting nugget tacked on to an otherwise complete (and much less interesting) paper.\n\nPresentational comments:\n\nFig.1: really nitpicky, but the typography of the POS tags and CCG categories is all wrong. These aren’t mathematical symbols!\n\nFig 2. Slightly confused why these are broken up into two separate plots.\n\nFig 4. is hard to read due to the lurid colors and patterns, which require a lot of cross-referencing with the legend. I wonder if this would be better as simply a table. I also found it very confusing at first since the y-axes are out of sync between the two figures—initially it looked as if the legend was overlaid on a set of bars in the left figure that had the same baseline as the right figure. \n']","[80, -20, -20]","[70, 60, 50]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'nicely written' and states that the experiments are 'well motivated and well described'. This indicates a generally positive view of the paper. The politeness score is 70 (polite) because the reviewer uses respectful language throughout and frames their questions in a neutral, non-confrontational manner. The reviewer begins with praise before moving on to specific questions, which is a polite approach. The language is professional and courteous without being overly formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer praises the thoroughness of the experiments, they express concerns about the significance of the paper's contributions and are 'borderline on its acceptance'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They phrase their concerns as suggestions (e.g. 'perhaps the authors could have...') rather than direct criticisms. The review maintains a professional and balanced tone, offering specific recommendations for improvement without being harsh or dismissive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'thorough and well-written', they express 'mixed feelings' and question the relevance and impact of the research. Phrases like 'not really obvious to me why some objectives tested here are interesting' and 'I'm not entirely sure what I learned from this' indicate a lack of enthusiasm. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positives like 'well-done study' and 'interesting nugget', while framing criticisms constructively. They also use softening phrases like 'I think' and 'perhaps' when expressing negative opinions. The lack of harsh or dismissive language contributes to the polite tone.""]"
"['The paper is well written with many relevant references and easy to read. Some points that need clarification and mentioned below. \nThe main points of this paper are the use of the convolution operator to perform the message passing mean field inference. Using this operation allows us to get away from the permutohedral lattice and yet allows speed up of 100x. This also means, that training will be able to done faster. Besides this the training parameters can also be learnt. These are the main contributions. The denoising task experiment shows positive results. The idea could be used in the future by others looking for faster model inference and training.\n\nIf a Manhattan distance d is used i.e. dx,dy<k in equation (6), why is this a FullCRF? It seems like the new CRF is no longer a fully connected one. \n\nPage 5, first paragraph describing how the reorganization in the GPU is avoided is not very clear. It would be helpful to a reader to have more details and explanations about this.\n\nIt is not clear from the experimental results how much improvement allowing to train the CRF parameters gets or might get. Comparing to the Deeplab results etc for the non-trained case, the non-trained model still seems to be performing competitively. Table 2 of Table 3 does not really bring out the advantage of training. The +C, +T, +CT don\'t seem to be hugely different in terms of validation metrics. Note that Table 3 does not mention other models that might not be trained (assuming that those results are in Table 2) but the text also mentions that the training is not completely fair.\n\nIn section 5, Unary, it is mentioned that the network is not trained on larger datasets like other work, why?\nAnd under CRF, what does iterations are unrolled mean?\n\nIn section 5.1, why does the random flipping help in simulating inaccuracies?\n\n\nMinor points:\nAbstract: Add space after ""GPUs."".\nWould be good to define what Q, *, \' indicate in paragraph 4, page 2.\n""hight"" -> ""height"" in section 4.1\n\n', 'The authors propose an efficient method to perform message passing on a truncated Gaussian kernel CRF. The main contributions are the definition of a specific form of truncated Gaussian kernel that allows for fast message passing via convolutions, and the implementation of such parallelized message passing on GPU. \n\nIn my opinion, the paper fails to convey the main idea in a clear and precise manner, the notation is mixed and often confusing, furthermore there are a number of sentences that should be rephrased to be less sensationalist, or removed. The experiments seem to show performance in par with the FullCRF on decoupled training, which seem in contrast with the much bigger performance gain of the first experiment on syntetic data. No discussion has been provided as to the possible reasons of this performance gap, although the experimental settings appear to be similar. Finally, in the last experiments with end-to-end training the authors report a performance improvement over CRFasRNN, a 3 years old paper that is far away in terms of performance with the current SOTA on Pascal VOC. The authors base on a different network than that of the CRFasRNN baseline (i.e., the difference is not only in the CRF implementation, but rather the whole network before the CRF in the proposed method), it is therefore difficult to say whether the performance improvement is due to the ResNet101 + FCN unary potentials, which is not a contribution of this manuscript, or to the proposed CRF. In general, I believe that the considerable speed gain of the proposed method might be enough to justify a publication, but the paper should be phrased in that sense if that was the intention of the authors. It is unclear to me whether the main contribution they claim is segmentation performance (IoU) or speed or both. The main contributions of this work should be stated clearly, and the modelling differences w.r.t. the FullCRF model that they aim to improve should be more explicit in the text rather than let to the reader to infer comparing the formulas.\n\nOn these grounds, I suggest a major revision of the paper and I don\'t recommend publication at this stage.\n\n\n\nMAJOR\n\n1) I firmly advocate against making strong claims, unless supported by solid proofs. I strongly recommend to rephrase, if not remove, exaggerate claims such as:\n\na) ""[deep networks] lack the capability to utilize context information and cannot model interactions between predictions directly"". This is simply not true. Any CNN with enough layers will exploit contextual information. Furthermore, any autoregressive model will model the interaction between predictions directly. See e.g., ""RiFCN: Recurrent Network in Fully Convolutional Network for Semantic Segmentation of High Resolution Remote Sensing Images"" by Mou et Al., ""ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation"" by Visin et Al., or ""Predicting Deeper into the Future of Semantic Segmentation"" by Luc et Al. for video semantic segmentation.\n\nb) ""CRF inference is two orders of magnitude slower than CNN inference"": this, of course, depends on the kind of CRF.\n\nc) ""The long training times of the current generation of CRFs also make more in-depth research and experiments with such structured models impractical"": again, not true. While it\'s true that CRFs tend to be slow, research with such models is not impractical and indeed there are papers that focus exactly on that (among the others, some of the ones cited in this manuscript).\n\nd) ""we propose to add the strong and valid assumption of conditional independence"": as with every assumption, this is an approximation. I wouldn\'t claim it to be valid nor invalid, as it is simply a modeling choice.\n\ne) ""Predictions are pixel-wise and conditionally independendent (given the common feature base of nearby pixels). Structured knowledge and background context is ignored in these models."". It\'s unclear what is meant by ""structured knowledge"", but to my best understanding this sentence is misleading or wrong. Background context is considered by CNN-based models, as well as the general structure in the image.\n\nf) ""In the context of semantic segmentation most CRF based approaches are based on the Fully Connected CRF"". CRFs have been used much earlier than 2011, before Fully Connected CRF was published.\n\ng) ""This makes the theoretical foundation of ConvCRF very promising, strong and valid assumptions are the powerhouse of machine learning modelling."" The authors here propose a logical, but quite obvious, approximation, i.e., to constrain the CRF to model dependencies in a local neighborhood. This is the same implicit assumption of many other Gaussian kernels and algorithms for approximated inference. For how it\'s surely valid, and possibly strong, I don\'t see how it can make a ""theoretical foundation"". The self-congratulatory closure is unnecessary, and inappropriate.\n\n\n\n2) While CRFs have been used for a long time on visual data, the citations in this work focus mostly on the last few years. I suggest to add at least one of the following:\n* “Discriminative fields for modeling spatial dependencies in natural images"" 2003\n* ""Multiscale conditional random fields for image labelling"" 2004\n* “Textonboost: Joint appearance, shape and context modeling for mulit-class object recognition and segmentation,” 2006\n\nIt could also be beneficial to the reader to add to the references broad overview works, such as ""An Introduction to Conditional Random Fields"" by Charles Sutton and Andrew McCallum, 2011, and/or ""Structured prediction and learning in computer vision"" by Nowozin and Lampert, 2011.\n\n\n\n3) Line 5 of the algorithm adds the unary potentials at each iteration of message passing. Can you elaborate on the motivation behind this choice? The algorithm is already initialized with such potentials, and to my best knowledge unary potentials are not usually added in the mean field message passing loop. It would be interesting to compare the performance of the algorithm with and without this addition.\n\n\n\n4) Sec4.1 reports that the filters are constant over the channel dimension c and that, in other words, this can be seen as applying the convolution over the dimension c. I fail to understand this sentence. My understanding from the formula is that the same kernel is applied to all the channels of the input, i.e., the channels of the input fed to the CRF are all processed in the same way. This should be explained clearly and the reasoning behind this choice should be explained as well. Furthermore, if I am not mistaken the authors learn a different filter in each position *of the input* rather than reusing the same filters at every position. This choice should be clarified and discussed.\n\n\n\n5) Regarding the implementation, is there a reason not to apply a convolution with a flipped kernel to compute the cross-correlation? Also, IIRC if the kernel is symmetric (as should be for a Gaussian kernel) convolution and cross-correlation are the same. \n\n\n\n6) The notation is often ambiguous and at times unnecessarely heavy. I strongly recommend to go over the manuscript and use a consistent notation, making sure that every element of the notation is introduced before or right after it\'s used. In particular,\n\na) Sec3: in the text, a segmentation instance is referred to as X, while in the formula as \\hat x. \\tilde I is never introduced. k_{\\alpha} is defined but I believe never used (I suggest to drop the name if there is no reference to it). Is there a reason to drop the subscript G in the FullCRF pairwise potential? Or conversely, is there a reason to have it everywhere else? Furthermore, there doesn\'t seem to be a difference between k_G, k_g and g, I suggest to use only one consistent notation to refer to the Gaussian kernels throughout the paper. It\'s also unclear if the I superscript is needed for the feature vectors. \n\nb) Sec4.1, The shape of the Gaussian kernels is the same as that of the input. I believe that the input in this context refers to a patch and not to the whole image. If so, this should be specified, otherwise the dimensions of the kernel should be referred to with a different letter than those of the input. \n\nc) Sec4.1, I believe dx and dy refer to the in-kernel displacement. Their semantic is not clear from the text and should be defined properly.\n\nd) Sec4.1, the feature vectors are defined in the text as f_1..f_d. The formula of the kernel uses f_i^{(d)} instead. It\'s unclear what the superscripts stands for and whether it is actually useful or redundant.\n\ne) Sec4.1, x and y are not defined, I suspect they refer to the position of the pixel, which was previously encoded as p_i and p_j. Once again, the notation should be consistent across the manuscript.\n\nf) In the definition of the convCRFs, w is used for the width of the input, w_i for the weights of the kernels. In the FullCRF, w^{(1)} and w^{(2)} for the potentials, w^{(m)} for the sum over the kernels. k is used for the kernel dimension, k_G to refer to the kernel itself, as well as g. The notation could be made less ambiguous and consistent (superscript vs subscript semantics).\n\ng) Sec3, the number of pixel is defined as n but in Formula 2 N is used instead.\n\ng) Vectors and matrices should be bold-face. The use of capital letters for constants might also improve the readability of the manuscript.\n\n\n\n7) The experiments with the Conv (ConvCRF?) variants of Table 2 are not discussed in the text.\n\n\n\n8) Although Sec5.2 concludes with ""The experiments also confirm the observation of Sec5.1, that ConvCRF performs slightly better than FullCRF"", Sec5.1 reported that ""it can be seen that ConvCRFs outperform FullCRFs significantly"". The authors should decide whether the results are slightly better or outperform the baseline. In general a in-depth discussion on the performance of the algorithm is missing.\n\n\n\n9) Sec5.3, it\'s unclear what this sentence means ""introduce an auxiliary unary loss to counterbalance the vanishing gradient problem"". If such a term has been added, it should be reported in a formula and it\'s effectiveness should be supported by experimental data.\n\n\n\nMINOR\n\nm1) In the related work, the sentence ""transposed convolution layers are applied at the end of the prediction pipeline ot produce high-resolution output"" seems to suggest these are always applied, while many recent methods rely on bilinear upsampling to recover the original resolution. Please rephrase it accordingly.\n\nm2) In Parameter learning in CRF: ""the idea utilizes, that for the message passing the identity .. is valid."" This sentence doesn\'t make any sense to me. Is it possible it is a leftover?\n\nm4) In Sec3, the features vectors [...] may depend on the input image I. I am confused as to when they might be independent of the image. Can you elaborate on that?\n\nm5) In Sec3, it\'s unclear to me what the vertical bar in the Pot model stands for. I believe the correct formula should be 1_{[xi != xj]}.\n\nm6) In mean field inference, Algorithm 1 does not refer to FullCRFs.\n\nm7) End of page 6, ""Note that this gives FullCRFs a natural advantage. The performance of CRFs however is very robust [...]"". Why is this an advantage for FullCRFs? How does that relate to the following sentence?\n\nm8) Sec4.1, the authors claim that one of the key contribution of the paper is that exact message passing is efficient. Given the locality assumption, message passing is approximate - which is also why it\'s efficient. The authors could instead argue that using convolutions is faster and possibly leads to better final performance than using the permutohedral lattice approximation (although it\'s unclear whether this is the case from the experiments), with proper reference to compelling results in this direction.\n\nFinally, a few typos:\n* Abstract, space missing after GPUs\n* Introduction, Convolutional Neuronal -> Convolutional Neural\n* Introduction, order of magnitude slower then -> than\n* Introduction, to slow -> too slow\n* Parameter learning in CRF: missing space before proposed to use gradient descent\n* Parameter learning in CRF: gradient decent -> descent\n* Parameter learning in CRF: extra comma after ""another advantage of this method is""\n* Sec 3: ""weighted sum of Gaussian kernels"", the apex of the second should be ""M"" I believe.\n* Sec 3: ""can be chosen arbitrary"" -> arbitrarily\n* Sec 5.2, beginning of page 8: then -> than', ""+ well written\n+ Good idea\n- Technical section not fully clear\n- Some experimental issues\n\nThe paper is well written, and clearly explains the background material and concepts. It might almost be a bit too detailed, as the main technical section (4) feels a bit rushed. (more below). \n\nFrom what I can judge the main idea in the paper is sound. The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.\n\nThe technical section is not very clear. For example: Are the filter weights recomputed for each spatial location, is there any acceleration that speeds this up? How large can the authors make the filter kernel, before the perhutohedral lattice is faster again?\n\nFinally, the experimental section has some room for improvement. I liked the comparison of decoupled and coupled CRF training, but I didn't get much out of the synthetic experiments. I found it particularly confusing since Table 1 doesn't mention that the experiments use ground truth (test) labels that were corrupted.\nSecond, it would be nice to have a side-to-side comparison between ConvCRF and CRFasRNN. I'd recommend the authors to either use the CRFasRNN training setup for both methods, or spend the week or two training CRFasRNN using their training procedure. It is fine to do either of the two experiments and have four entries in that table.""]","[70, -60, 20]","[80, 20, 50]","[""The sentiment score is 70 (positive) because the reviewer begins by praising the paper as 'well written' and 'easy to read'. They highlight the main contributions and mention 'positive results' and potential future use of the ideas. The overall tone is supportive, though they do raise some questions and areas for improvement. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, framing their critiques as questions or suggestions rather than direct criticisms. They use phrases like 'It would be helpful' and 'It is not clear' instead of more confrontational language. The reviewer also acknowledges the paper's strengths before diving into areas for improvement, which is a polite approach to peer review."", ""The sentiment score is -60 because the reviewer recommends major revision and does not recommend publication at this stage. They point out several significant issues with the paper, including unclear presentation of ideas, confusing notation, exaggerated claims, and experimental results that don't fully support the claims. However, the score is not lower because the reviewer does acknowledge some potential value in the work's speed improvements. The politeness score is 20 because while the reviewer is direct in their criticisms, they generally use professional language and provide constructive feedback. They use phrases like 'I suggest' and 'I recommend' rather than harsh commands. The reviewer also provides detailed explanations for their concerns, which is helpful to the authors. However, there are a few instances of more blunt language (e.g., 'This is simply not true'), which prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges positive aspects like the paper being well-written and having a good main idea, but also points out several areas for improvement in the technical section and experiments. The overall tone is constructive rather than overly critical. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. They use phrases like 'might be' and 'I'd recommend' which soften the critique. The reviewer also balances positive and negative feedback, starting with positive points before moving to areas of improvement, which is a polite approach to reviewing.""]"
"[""The main idea is to incorporate linguistic-based constrains in the form of dependency trees into different variations of relation networks.\nIn general, the paper is well written and organized, the presented problem is well motivated, and the approach is very strait forward. The experimental setting is comprehensive, and the results are indeed competitive in a wide range of tasks.\nI think that using linguistic knowledge to improve Neural networks performance is very promising field, I think that you could get a much more substantial gains when applying your method in less resource-rich setups (maybe using some small subset of training for the SNLI and question duplication datasets).\nIt seems that your method relies heavily on previous works (RN, RNN-RN, latent dependency trees ,intra-sentence attention), can you please state clearly what your contribution is? does your model has any advantages over current state-of-the-art methods?   \n\nedit: I'm still not convinced about this article novelty, I really like the overall idea but it seems that this kind of contribution is better suited for short paper. "", '\n[Summary]\nThe main purpose of this paper is to propose an extension of relation networks.\nThe proposal consists of two parts: 1) to integrate constraints of dependency syntax to control which relations influence the representation, and 2) utilize a recurrent computation to capture higher-order relations.\n\n[clarity]\nThis paper is basically well written.\nMotivation and goal are clear.\n\n[originality]\nThe idea of utilizing supervised or unsupervised dependency tree as constraints to control which relations influence the representation seems novel and interesting.\nHowever, technically it consists of the combination of the previous methods, such as matrix-tree theorem for calculating conditional probabilities, and structured attention.\nTherefore, the proposed method is incremental rather than innovative.\n\n[significance]\nExperiments on several varieties of datasets revealed that the proposed method consistently improved the performance from the baseline RN.\nIn contrast, it did not outperform the current best scores for all experiments comparing with the current published best methods.\nObviously, we have no reason that we must use RNs for such tasks.\nTherefore, the actual effectiveness of the proposed method in terms of the actual task settings is unclear for me.\nI concern about the actual calculation speed of the proposed method.\nThe proposed method seems to require much higher computational cost against the baseline RNs.\n\n[Questions]\n1, Regarding the approach in general, it would be nice to see how much it depends on the quality of the dependency parse. \nFor example, we cannot always prepare a good parser for experiments on MT such as low-resource languages.\nDo you have any comments for this?\n\n2, Some experimental results showed that “RN intra-attn” was better than “Reccurent RNs”.\nThis implies for me that the higher-order dependency is useless for such tasks.\nAre there any analyses why “Reccurent RNs” did not work well?\n\n', 'The paper presents an extension of relation networks (RNs) for natural language processing. RNs are designed to represent a set as a function of the representations of their elements. This paper treats a sentence as a set of words. Whereas regular RNs assume that the representation of a set is a uniform aggregation of the representation of the pairs of elements in the set, this paper proposes to weight the relevance of the pairs according to their tree-structured dependency relations between the words. The authors evaluate on a suite of NLP tasks, including SNLI, Quora duplicate question ID, and machine translation. They show marginal improvements over naive baselines, and no improvement over SOTA.\n\nI am concerned about both the motivation for and the novelty of this work. My reading of this work is that the authors try to reverse engineer a TreeRNN in terms of RNs, but I am not sure what the reason is for wanting to use the RN framework in order to derive an architecture that, IIUC, essentially already exists. I can\'t find any fundamentally meaningful differences between the proposed architecture and the existing work on TreeRNNs, and the results suggest that there is nothing groundbreaking being proposed here. It is possible I am missing some key insight, but I do believe the burden is on the authors to highlight where the novelty is. The intro *and* related work sections should both be rewritten to answer the question: what is the insufficiency with current sentence encoding models that is addressed by this architecture? Currently, the intro addresses the tangential question: what is the insufficiency with RNs for NLP that is addressed by this architecture? If the latter is the question the authors want to answer, they need to first answer: why should we want to cast sentence encoders as RNs as opposed to any of the (many) other available architectures? Without a firmer understanding of what this paper contributes and why, I can\'t recommend acceptance. More detailed comments for the authors below. \n\n- You introduce a few naive baselines, but none of these is a TreeRNN. TreeRNNs are the obvious baseline, and you should be comparing on each and every evaluation task, even if there is no previously published result for using tree RNNs on that task. For the one result (SNLI, table 1) on which there is previous work using TreeRNNs, the table confirms my intuition that the proposed model is no improvement over the TreeRNN architecture. It seems very important to address this comparison across all of the evaluation tasks.\n- I like the notion of marginalizing over latent tree structures, but the related work section needs to make clear what is being contributed here that is different from the cited past work on this problem\n- On the MT eval, why are you missing values for zh-en on the NMT models that are actually competitive? I think many of these models are open-source or easy to reimplement? Its hard to draw conclusions when from such a gappy table.\n- Only table 2 has significance values (over naive baseline that is) which implies that the other results are not significant? That is disconcerting. \n- I am disappointed in the analysis section. As is, you provide an ad-hoc inspection of some inferred trees. I find this odd since there is no evidence that the tree-ness of the architecture (as opposed to, e.g., recurrence or attention) is what leads to quantitative improvements (at least according to the experimental results in the tables), so there is no reason we should actually expect the trees to be good or interesting. My interpretation of these cherry-picked examples is that the learning is fighting the architecture a bit, basically ""learning a tree"" that reduces to being an attention mechanism that up-weights one or two salient words. \n- The analysis I *wanted* to see instead was why recursion helped for sentence classification, it did not for MT. You give an intuition for this result but no evidence. (That is assuming that, quantitatively, this trend actually holds. Which maybe is not the case if none of the results are significant.)\n- In general, regarding evaluation, SNLI is overfit. You should use MNLI at least. I have trouble interpreting progress on SNLI as ""actual"" progress on language representation.\n- The related work section as a whole is too short. If you need to cut space, move technical content to appendix, but don\'t compromise in related work. You listed many relevant citations, but you have no context to situate your contribution relative to this past work. What is the same/different about your method? You should provide an answer to that for each and every paper you cite. ']","[20, -20, -60]","[60, 60, 20]","['The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written, organized, and motivated, with comprehensive experiments and competitive results. However, the reviewer expresses doubts about the novelty and suggests it might be better suited for a short paper, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language, offers constructive feedback, and phrases criticisms as questions or suggestions rather than direct attacks. The reviewer also acknowledges the potential of the field and offers ideas for improvement, which contributes to the polite tone.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'well written', 'novel and interesting' idea), they express several concerns and limitations of the proposed method. They note that it's 'incremental rather than innovative', doesn't outperform current best methods, and has unclear effectiveness and high computational cost. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as concerns or questions rather than direct attacks. They use phrases like 'it would be nice to see' and ask for the authors' comments, which maintains a collegial tone. The reviewer also provides specific, constructive feedback and questions, which is helpful and polite in academic discourse."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the motivation and novelty of the work, stating they 'can't recommend acceptance' without a better understanding of the paper's contribution. They point out several weaknesses and missing comparisons. However, it's not entirely negative as they do acknowledge some positive aspects ('I like the notion of marginalizing over latent tree structures'). The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am concerned' and 'It is possible I am missing some key insight' which soften the criticism. They also provide detailed feedback for improvement, which is helpful and considerate. However, some phrases like 'I am disappointed' and 'SNLI is overfit' are more direct criticisms that prevent a higher politeness score.""]"
"['Summary: \n\nThis paper proposes a method to get feedback from humans in an autonomous vehicle (AV). Labels are collected such that the human actually moves a steering wheel and depending on the steering wheel angle disagreement with the direction the vehicle is actually moving a feedback value is collected which is used to weight the scalar loss function used to learn from these demonstrations. \n\nExperiments on a simple driving simulator is presented. \n\nComments: \n\nI think this paper is attempting to address an important problem in imitation learning that is encountered quite often in DAgger, AggreVate and variants where the expert feedback is provided on the state distribution induced by the learnt policy via a mixture policy. In DAgger (where the corrections are one-step as opposed to AggreVate where the expert takes over and shows the full demonstration to get Q(s,a)) it is difficult to actually provide good feedback especially when the expert demonstrations are not getting executed on the vehicle and hence hard for humans to ascertain what would be the actual effect of the actions they are recommending. In fact there is always a tendency to overcorrect which leads to instability in DAgger iterations. \n\nThe paper proposes using a modified feedback algorithm on page 6 whose magnitude and sign is based on how much the correction signal is in agreement or disagreement with the current policy being executed on the vehicle. \n\nUnfortunately this paper is very confusingly written at the moment. I had to take multiple passes and still can\'t figure out many claims and discussions: \n\n- ""To the best of our knowledge, no research so far has focused on using any kind of human feedback in the context of AV control with learning from demonstration"" - This is not true. See: \n\n""Learning Monocular Reactive UAV Control in Cluttered Natural Environments, Stephane Ross, Narek Melik-Barkhudarov, Kumar Shaurya Shankar, Andreas Wendel, Debadeepta Dey, J. Andrew Bagnell, Martial Hebert"" who used DAgger for autonomous driving of a drone with human pilot feedback. \n\n- Lots of terms are introduced without definition or forward references. Example: \\theta and \\hat{\\theta} are provided early-on are refered to on page 3 in the middle of the page but only defined at the end of the page in 3.1. \n\n- Lots of confusing statements have been made without clear discussion like ""...we could also view our problem as a contextual bandit, since the feedback for every action falls in the same range..."" This was a baffling statement since contextual bandit is a one-step RL problem where there is no credit assignment problem unlike sequential decision-making settings as being dealt with in this paper. Perhaps something deeper was meant but it was not clear at all from text. \n\n- The paper is strewn with typos, is really verbose and seems to be written in a rush. For example, ""Since we are off-policy the neural network cannot not influence the probability of seeing an example again, and this leads can lead to problems.""\n\n- The experiments are very simple and it is not clear whether the images in figure 2 are the actual camera images used (which would be weird since they are from an overhead view which is not what human safety drivers would actually see) or hand-drawn illustrations.\n\n', ""Despite many high profile successes in research, DeepRL is still not widely used in applications. One reason for this is that current methods typically assume the agent can learn by exploring many states and actions, however, in many real world tasks, such as driving used here, poor actions can be dangerous. Therefore, methods that can provides the flexible benefits of RL while avoiding this are of significant interest, one promising general ideas pursued for this has been to use human demonstrations.\n\nA number of approaches to Inverse RL have been studied, but many make the assumption that the demonstrations are all examples of optimal behavior. This can be challenging if, for example, some examples contain suboptimal behavior, and it also means that the agent does not get to observe non-optimal trajectories and how to correct for them; the resulting policy often performs poorly due to the distributional shift between the demonstration trajectories and the trajectories induced by the learned policy.\n\nThis work attempts to correct for these problems by labeling the demonstration actions between $[-1, 1]$ indicating how good or bad the demonstration actions are. This introduces a challenge for learning, since good actions can be copied, but a bad action is more ambiguous: it does not necessarily imply the action are far away from the bad action is a good action.\n\nOne view of this work is that they introducing 3 losses for behavior cloning with weighted labels: A weighted (based on the label) L2 loss, an exponential loss and directly fitting the loss and searching over a discrete set of actions to find the highest estimate weighting. Note the current equation for $Loss_{FNET}$ doesn't make sense because it simply minimizing the output of the network, from the text it should be something like $(f - \\hat{\\theta})^2$?\n\nThe text discusses why rescaling the negative examples may be beneficial, but as far as I can tell, figure 4 you only consider $\\alpha=\\{0, 1\\}$? Based on the text, why weren't intermediate values of $\\alpha$ considered?\n\nIt could benefit from copy-editing, checking the equations and in some cases describing concepts more concisely using clear mathematical notation instead of wordy descriptions that are difficult to follow.\n\n``Thus the assumption\nthat our training data is independent and identically distributed (i.i.d.) from the agent’s encountered\ndistribution goes out the window'' This is a misleading statement regarding the challenge of distributional shift in off-policy RL. The challenge is that state distribution between the behavior policy and the learned policy may be quite different, not just not iid. Even in on-policy RL the state visitation is certainly not usually iid.\n\n``In the off-policy policy gradient RL framework, this issue is typically circumvented by changing the\nobjective function from an expectation of the learned policy’s value function over the learned policy\nstate-visitation distribution to an expectation of the learned policy’s value function over the behavior\n(exploratory) state-visitation distribution (Degris et al., 2012). In the RL framework, this could be\ndealt with by an approximation off-policy stochastic policy gradient that scales the stochastic policy\ngradient by an importance sampling ratio (Silver et al., 2014) (Degris et al., 2012). ''. The importance sampling in Degris is not to correct for the objective being under the behavior state policy and DPG (Silver et al., 2014) specifically does not require importance sampling so it shouldn't be referenced here. This paragraph seems to be conflating two issues: the distributional shift between the behavior state distribution and the policy state distribution that can make off-policy learning unstable, and importance sampling to estimate outcome likelihoods using behavior experience.\n\nThis work is on a very important topic. However, in its current form it is not well-communicated. Additionally, the best performing method is not novel (as the author's state $\\alpha=1$, the best performing setting, is essentially the same as COACH but with scalar labels). For these reasons reason, I think this work may be of limited interested."", 'This paper is clearly written and identifies an important point that exploration is dangerous in the autonomous driving domain. My key objection to this paper is that, even though the method is intended to deal with problems where exploration is dangerous and therefore should not be done, the method relies on negative examples, which are presumably dangerous. If simulations are used to generate negative examples and those are used, then the benefit of the presented method over standard reinforcement learning goes away.\n\nI have several questions/comments/suggestions about the paper:\n\n1. Can one perhaps present only mildly bad examples (e.g., mild swerving) to reinforcement learning in a way where the algorithm can understand that significant swerving, like what is shown in figure 2, is even worse?\n2. The backseat driver feedback described seems to granular. I think that, to be realistic, the algorithm should allow for feedback that is less precise (e.g., turn further, turn the other way), without requiring information on proportions.\n3. Please add an architecture diagram.\n4. In figure 4, what is the difference between the first and fourth items? They have exactly the same description in the legend.\n5. The experiments are not convincing. They lead one to conclude that negative examples are beneficial, which is good, but not surprising. Because negative examples are generated, a comparison with regular reinforcement learning should be done.']","[-50, -50, -20]","[20, 20, 60]","[""The sentiment score is -50 because while the reviewer acknowledges the paper is addressing an important problem, they express significant concerns about the clarity, accuracy, and quality of the writing. They state the paper is 'very confusingly written', contains inaccurate claims, undefined terms, and is 'strewn with typos'. The experiments are described as 'very simple'. These criticisms outweigh the initial positive acknowledgment, resulting in a moderately negative sentiment. The politeness score is 20 because the reviewer uses generally polite language, avoiding harsh personal criticisms. They use phrases like 'I think' and 'Unfortunately' to soften their critiques. However, some statements like 'This was a baffling statement' are more direct, preventing a higher politeness score. Overall, the tone remains professional while clearly communicating concerns."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic, they express significant concerns about the paper's communication, novelty, and potential impact. The review starts positively but becomes increasingly critical, concluding that the work may be of 'limited interest'. The politeness score is 20 because the reviewer uses generally respectful language and provides constructive feedback, but some statements are quite direct and potentially discouraging. The reviewer balances criticism with recognition of the work's importance and offers specific suggestions for improvement, maintaining a professional tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'clearly written' and addresses an 'important point', they express a 'key objection' to the method and state that the experiments are 'not convincing'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Can one perhaps...', 'Please add...'), and acknowledges positive aspects of the paper. The reviewer maintains a professional and constructive tone, even when pointing out weaknesses.""]"
"['This is an empirical study on the ability for DQNs trained with/without regularization to perform well on variants of the same environment (e.g. increasing difficulty of a game). The paper is well written, the experimental methodology is clear & sound, and the significance is around improved sample efficiency via warm starting from a regularized DQN to fine tune. The error bounds for the regularized models results seem uncomfortably large in some cases. Overall it looks like a good methodological paper that can inform others on taking regularization more seriously when training DQNs. Evaluating on a modified ALE environment is great, but it would have been better to see this having similar impact in real life applications.', 'Summary: \nThis paper focuses on a ""generalization"" in deep Q-network (DQN). Specifically, they showed that when features (parameters of DQN) are trained in one environment (default flavour/mode) and then used as an initialization for the same model but for a slightly different environment ( i.e. still captures key concepts of the original environment ) can boost the performance of the model in the new flavour/environment. More importantly, the performance boost is significant when DQN\'s parameters which are used to initialize the model for the new environment were trained using dropout and L2 regularization in the default flavour/mode.  For the experiments, 4 games: FREEWAY, HERO, BREAKOUT, and SPACE INVADERS which have 13 flavours (combinations of a mode and a difficulty) are used.\n\nStrengths:\n+ This paper is interesting in the sense that it empirically shows that using regularization in training deep RL can be helpful when the goal is the generalization from one flavour of an environment to another one but very similar to the original.\n+ The experiments show that using REGULARIZED FINE-TUNING and FINE-TUNING for a new flavour /mode can help with sample efficiency compared with the models which are trained from scratch [10M frames vs 50M frames and 50M frames vs 100M frames ](Table 3).\n+ The paper is well-written and it can be easily followed.\n\nWeaknesses:\n- In my view, there should be experiments in which the proposed method is compared with other approaches that improve generalization in deep RL like Zhang et al., 2018 and Justesen et al., 2018.\n- According to the paper (at least my understanding) DQN\'s hyper-parameters are tuned based on default mode/flavour environment. It is possible that results for \'SCRATCH\' results (Table 3) can be improved if DQN\'s hyper-parameters are tuned on the current flavour not default one.\n-The proposed method is only applicable when the default environment and the new one are very similar. If the environments are that similar why even bother to train first on default and then generalize to the new one? Wouldn\'t be less expensive to just focus on the target environment and find the best model on that?\n\nQuestions:\n- It is mentioned in the paper, that evaluation protocol suggested by Machado et al. (2018) is being followed in this paper. Have you followed the protocol introduced in section 4.2 of Machado et al. (2018)? If yes, the protocol in Machado et al. (2018) is for training time but numbers in Table 1 in this paper are for evaluation time. Can you elaborate?\n- Why only those 6 games were selected for the experiments? \n\nIn summary, I found this paper is interesting but my concern is about the experiments.', 'I totally disagree with the authors that any of their observations are surprising. Indeed the fact that an RL agent does not generalizes to small modifications of the task (either visual or in the dynamics) is well known. If the agent should generalize though is a different question. And I do not mean this in the sense that it is an undesirable property but rather if it is outside of what “learning one task” means. Particularly I feel this is a very pessimistic view of RL and potentially not even in-line with what happens in supervised learning. \n\nI think one mantra of deep learning (and deep RL needs to obey by it) is that one should test in the same setting as training for things to truly work. For supervised, there is a distribution of data, and the test set are samples from the same distribution. However the testing scenario used here is slightly different. During training, if I do not see car accelerating, I think it makes no sense to expect to generalize to a new game that has this property as it is out-of-distribution. Of course it would be ideal if it could do that. And to clarify, while for us some of these extensions seem very similar and minimal changes, hence it should generalize to rather than transfer to, this is just the effect of imposing our own biases on the learning process. Deep Nets do not learn like we do, and in their universe they have never seen a car accelerating -- it makes sense that it might not to be able to generalize to it. Again, I’m not arguing that we don’t want this, but rather if we should expect it as part of what the system should normally generalize to.\n\nTo that end I think this paper enters in that unresolved dispute of what generalization should be versus what is transfer. At what point do we have truly a new task vs a sample from the same task. I don’t think there is an answer.\n\nGoing back to the observations in this work. I think the fact that the environment is not stochastic reinforces this overfitting (as in the extreme you end up with a policy that just repeats the optimal sequence of actions). I think in this particular case I can see how finetuning to a variation of the task fails. However true stochasticity in the environment (e.g. having a distribution of variations) like is done in Distral paper (where each episode is a different layout) can behave as a regularizer that will mitigate a bit the overfitting. That is to say that I believe the observed behaviour will be less pronounced in complex stochastic setting. \n\nNevertheless the paper seems to highlight an important observation (and back it up with empirical evidence), namely we should use more regularization like L2 or otherwise in practice. Which is mostly absent from publications. And I think this on its own is valuable. \n']","[60, 20, -20]","[50, 70, 50]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'well written' with 'clear & sound' methodology, and notes its significance in improving sample efficiency. They also mention it's a 'good methodological paper'. However, it's not extremely positive due to some criticisms like 'uncomfortably large' error bounds and the suggestion for real-life applications. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They don't use overly formal or deferential language, but maintain a professional tone without any rudeness or harsh criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper, calling it 'interesting' and 'well-written'. However, they also point out significant weaknesses and express concerns about the experiments, which prevents the score from being higher. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, presents criticisms as 'weaknesses' rather than attacks, and frames concerns as questions for the authors to address. The reviewer maintains a professional tone, balancing positive feedback with constructive criticism."", ""The sentiment score is slightly negative (-20) because the reviewer disagrees with the authors' main claims, stating 'I totally disagree with the authors that any of their observations are surprising.' However, the reviewer does acknowledge some value in the paper's observations about regularization, which prevents the score from being more negative. The politeness score is moderately positive (50) because while the reviewer disagrees with the authors, they express their criticism in a professional and constructive manner. They use phrases like 'I think,' 'To clarify,' and 'I'm not arguing that' which soften the disagreement. The reviewer also acknowledges the paper's contributions, stating 'the paper seems to highlight an important observation... which is mostly absent from publications. And I think this on its own is valuable.' This balanced approach contributes to the overall polite tone of the review.""]"
"['This work considers a version of importance sampling of states from the replay buffer.  Each trajectory is assigned a rank, inversely proportional to its probability according to a GMM. The trajectories with lower rank are preferred at sampling.\n\nMain issues:\n\n1. Estimating rank from a density estimator\n\n- the reasoning behind picking VGMM as the density estimator is not fully convincing and (dis)advantages of other candidate density estimators are almost not highlighted.\n\n- it is unclear and possibly could be better explained why one needs to concatenate the goals (what would change if we would not concatenate but estimate state densities rather than trajectories?)\n\n2. Generalization issues\n\n- the method is not applicable to episodes of different length\n- the approach assumes existence of a state to goal function f(s)->g\n- although the paper does not expose this point (it is discussed the HER paper)\n\n3. Scaling issues\n\n- length of the vector grows linearly with the episode length\n- length of the vector grows linearly with the size of the goal vector\n\nFor long episodes or episodes with large goal vectors it is quite possible that there will not be enough data to fit the GMM model or one would need to collect many samples prior.\n\n4. Minor issues\n\n- 3.3 ""It is known that PER can become very expensive in computational time"" - please supply a reference\n \n\n- 3.3 ""After each update of the model, the agent needs to update the priorities of the transitions in the replay buffer with the new TD-errors"" - However the method only renews priorities of randomly selected transitions (why would there be a large overhead?). Here is from the PER paper ""Our final implementation for rank-based prioritization produced an additional 2%-4% increase in running time and negligible additional memory usage""\n', 'This paper addresses a problem that arises in ""universal"" value-function approximation (that is, reinforcement-learning when a current goal is included as part of the input);  when doing experience replay, the experience buffer might have much more representation of some goals than others, and it\'s important to keep the training appropriately balanced over goals.\n\nSo, the idea is to a kind of importance weighting of the trajectory memory, by doing a density estimation on the goal distribution represented in the memory and then sample them for training in a way that is inversely related to their densities.  This method results in a moderate improvement in the effectiveness of DDPG, compared to the previous method for hindsight experience replay.\n\nThe idea is intuitively sensible, but I believe this paper falls short of being ready for publication for three major reasons.\n\nFirst, the mechanism provided has no mathematical justification--it seems fairly arbitrary.   Even if it\'s not possible to prove something about this strategy, it would be useful to just state a desirable property that the sampling mechanism should have and then argue informally that this mechanism has that property.  As it is, it\'s just one point in a large space of possible mechanisms.\n\nI have a substantial concern that this method might end up assigning a high likelihood of resampling trajectories where something unusual happened, not because of the agent\'s actions, but because of the world having made a very unusual stochastic transition.   If that\'s true, then this distribution would be very bad for training a value function, which is supposed to involve an expectation over ""nature""\'s choices in the MDP.\n\nSecond, the experiments are (as I understand it, but I may be wrong) in deterministic domains, which definitely does not constitute a general test of a proposed RL  method.  \n- I\'m not sure we can conclude much from the results on fetchSlide (and it would make sense not to use the last set of parameters but the best one encountered during training)\n- What implementation of the other algorithms did you use?\n\nThird, the writing in the paper has some significant lapses in clarity.  I was a substantial way through the paper before understanding exactly what the set-up was;  in particular, exactly what ""state"" meant was not clear.  I would suggest saying something like s = ((x^g, x^c), g) where s is a state from the perspective of value iteration, (x^g, x^c) is a state of the system, which is a vector of values divided into two sub-vectors, x^g is the part of the system state that involves the state variables that are specified in the goal, x^c (for \'context\') is the rest of the system state, and g is the goal.  The dimensions of x^g and g should line up.\n- This sentence  was particularly troublesome:  ""Each  state s_t also includes the state of the achieved goal, meaning the goal state is a subset of the normal state.  Here, we overwrite the notation s_t  as the achieved goal state, i.e., the state of the object.""\n- Also, it\'s important to say what the goal actually is, since it doesn\'t make sense for it to be a point in a continuous space.  (You do say this later, but it would be helpful to the reader to say it earlier.)\n', 'The paper proposes a novel method for sampling examples for experience replay. It addresses the problem of having inbalanced data (in the experience buffer during training). The authors trained a density model and replay the trajectories that has a low density under the model. \n\nNovelty:\n\nThe approach is related to prioritized experience replay, PER is computational expensive because of the TD error update, in comparison, CDR only updates trajectory density once per trajectory.\n\nClarity:\n\nThe paper seems to lack clarity on certain design/ architecture/ model decisions.  For example, the authors did not justify why VGMM model was chosen and how does it compare to other density estimators.  Also, I had to go through a large chunk of the paper before coming across the exact setup. I think the paper could benefit from having this in the earlier sections.\n\n\nOther comments about the paper:\n\n-  I do like the idea of the paper. It also seems that curiosity in this context seems to be very related to surprise? There are neuroscience evidence indicating that humans turns to remember (putting more weights) on events that are more surprising.\n\n- The entire trajectory needs to be stored, so the memory wold grow with episode length. I could see this being an issue when episode length is too long.\n\n\n']","[-50, -50, 50]","[20, 20, 70]","[""The sentiment score is -50 because the review primarily focuses on issues and criticisms of the work, indicating a generally negative sentiment. However, it's not extremely negative as it acknowledges the work's contribution and provides constructive feedback. The politeness score is 20 because the language used is professional and objective, without harsh or rude phrasing. The reviewer uses phrases like 'it is unclear' and 'could be better explained' rather than more confrontational language. The review maintains a respectful tone while pointing out areas for improvement, which is slightly more polite than neutral."", ""The sentiment score is -50 because while the reviewer acknowledges the paper addresses an important problem and the idea is 'intuitively sensible', they state that the paper 'falls short of being ready for publication for three major reasons'. This indicates a predominantly negative sentiment, though not entirely dismissive. The politeness score is 20 because the reviewer uses generally polite language, such as 'I believe' and 'I would suggest', and acknowledges positive aspects before critiquing. However, some direct criticisms like 'significant lapses in clarity' slightly reduce the politeness score. The reviewer provides constructive feedback and suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the approach and expresses appreciation for the idea, stating 'I do like the idea of the paper.' However, they also point out some areas for improvement, such as lack of clarity on certain decisions and potential issues with memory growth. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'The paper could benefit from...' and 'I think,' which maintain a polite tone while providing feedback. The reviewer also balances critique with positive comments, showing consideration for the authors' work.""]"
"['This paper propose a new approach to dialogue modeling by introducing two\ninnovations over an established dialogue model: the HRED (Hierarchical\nRecurrent Encoder-Decoder) network. The innovations are: (1) adding a GAN\nobjective to the standard MLE objective of the HRED model; and (2)\nmodifying the HRED model to include an attention mechanism over the local\nconditioning information (i.e. the ""call"" before the present ""response"").  \n\nWriting: The writing was mostly ok, though there were some issues early in\nSection 2. The authors rather awkwardly transition from a mathematical\nformalism that included the two halves of the dialogue as X (call) and Y\n(response), to a formalism that only considers a single sequence X. \n\nNovelty and Impact:  The proposed approach explicitly combines an established\nmodel with two components that are themselves well-established.\nIt\'s fair to say that the novelty is relatively weak. The model development\nis sensible, but reasonably straightforward. It isn\'t clear to me that a\ncareful reader of the literature in this area (particularly the GAN for\ntext literature) will learn that much from this paper. \n\nExperiments: Overall the empirical evaluation shows fairly convincingly\nthat the proposed model is effective. I do wonder why would the hredGAN\nmodel outperform the hred model on perplexity. The hred model is\ndirectly optimizing MLE which is directly related to the perplexity\nmeasure, while the hredGAN include an additional objective that should\n(perhaps) sacrifice likelihood. This puzzling result was not discussed and\nreally should be.\n\nThe generated responses, given in table 3 -- while showing some improvement\nover hred and Vhred (esp. in terms of response length and specificity) --\ndo not fit the context particularly well. This really just shows we still\nhave some way to go before this challenging task is solved. \n\nIt would be useful if the authors could run an ablation study to help\nresolve the relative contributions of the two innovations (GAN and\nattention) to the improvements in results. Perhaps the improvement in\nperplexity (discussed above) is do to the use of attention. \n\nDetailed comments / questions\n\n- In the paragraph between Eqns 2 and 3, the authors seem to suggest that\n  teacher forcing is an added heuristic -- however this is just the\n  correct evaluation of the MLE objective. \n\n- In discussing the combined MLE-GAN objective in Eqn. 8 Does the MLE\n  objective use teacher forcing? Some earlier text (discussed above) leads\n  me to suspect that it does not. \n', 'This paper presents an adversarial learning model for generating diverse responses for dialogue systems based on HRED (hierarchical recurrent encoder-decoder) network. The contribution of the work mainly lies in: 1. adversarial learning, and 2. injecting Gaussian noise at word-level and sentence-level to encourage the diversity. Overall, the idea is interesting, and the automatic evaluation based on perplexity, BLEU, ROUGE, etc shows that the proposed methods outperform existing methods.\n\nSeveral suggestions:\n- It seems like injection noise at word-level almost always outperforms adding sentence-level noise. It would be better if the authors can explain why this happens and whether it can be applied for other response generation tasks.\n\n- Built on above comment, the authors can also experiment with other response generation datasets, e.g. interactions on social media.\n\n- From examples in Table 3 and 4, the generated responses are of low quality overall. I suggest the authors run human evaluation to see whether there is any significant difference among system responses by different models on aspects of informativeness and fluency at least.', '\nThe paper applies conditional GAN to the HRED model [Serban et al., 2016] for dialogue response generation, showing improvements in terms of informativeness and diversity compared to HRED and VHRED [Serban et al., 2017].\n\nThe paper is technically solid and relatively easy to follow and the results are good, but comparisons with previous work (descriptive and experimental) are rather weak. \n\n- Related work is incomplete: The paper specifically argues for the use of GAN to improve diversity in dialogue response generation, but this is not the first paper to do so. [Xu et al., 2017] presents a GAN-like setup that targets exactly the same goal, but that work is not cited in the paper. Same for [Zhang et al., 2018], but the latter work is rather recent (it still should probably be cited).\n\n- Evaluation: There is no evaluation against Xu et al., which targets the same goal. The authors didn’t even compare their methods against baselines used in other GAN works for diverse response generation (e.g., MMI [Xu et al.; Zhang et al.], Li et al.’s GAN approach [Xu et al.]), which makes it difficult to draw comparisons between these related methods. As opposed to these other works, the paper doesn’t offer any human evaluation.\n\n- It would have been nice to include an LSTM or GRU baseline, as these models are still often used in practice and the VHRED paper suggests [Serban et al., 2016; Table 1] that LSTM holds up quite well against HRED (if we extrapolate the results of VHRED vs. LSTM and VHRED vs. HRED). The ablation of GAN and HRED would help us understand which of the two is more important.\n\nIn sum, the work is relatively solid, but considering how much has already been done on generating diverse responses (including 3 other papers also using GAN), I don’t think this paper is too influential. Its main weakness is the evaluation (particularly the lack of human evaluation.)\n\nMinor comments:\n\n- Introduction: “diversity promoting training objective but their model is for single turn conversations”. \nIf these were “single turns”, they wouldn’t really be called conversations; that objective has been used with 3+ turn conversations. It can actually be applied to multi-turn dialogue as with any autoegressive generative models. For example, it has been exploited that way as a baseline for multi-turn dialogue [Li et al. 2016](“Deep Reinforcement Learning for Dialogue Generation“). Note it is not a “training objective”, but only an objective function at inference time, which is a more valid reason to criticize that paper.\n\n- “We use greedy decoding (MLE) on the first part of the objective.” Doesn’t that hurt diversity because of MLE? what about using sampling instead (maybe with temperature)?\n\n- Algorithm 1: the P_theta_G don’t seem to match the text of section 2. h_i is in sometimes written in bold and sometimes not (see also Eq 12 for comparison.)\n\n- End of section 2.1: There are multiple Li et al.; specify which one.\n\n- End of section 2.2 and 2.4: extra closing parenthesis after N(0, …))\n\n- Figures are too small to read the subscripts.\n\n[Xu et al. 2017]: Zhen Xu, Bingquan Liu, Baoxun Wang, Sun Chengjie, Xiaolong Wang, Zhuoran Wang, and Chao Qi. Neural response generation via gan with an approximate embedding layer. EMNLP 2017.\n\n[Zhang et al. 2018]: Zhang, Yizhe & Galley, Michel & Gao, Jianfeng & Gan, Zhe & Li, Xiujun & Brockett, Chris & Dolan, Bill. (2018). Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization.', 'This paper presented a dialog response generation method using adversarial learning framework. \nThe generator is based on previously proposed hierarchical recurrent encoder-decoder network (HRED), and the discriminator is a bidirectional RNN. \nNoise samples are introduced in generator for response generation.\nThey evaluated their approach on two datasets and showed mostly better results than the other systems. \n\nThe novelty of the paper is limited. \nModeling longer dialog history (beyond the current turn) is not new, this has been used in different tasks such as dialect act classification, intent classification and slot filling, response generation, etc.\nThe generator is based on previous HRED. \nAdding noise to generate responses is somewhat new, but that doesn’t seem to be well motivated or justified. \nWhy adding Gaussian noise improves the diversity or informativeness of the responses is not explained. \nThe idea of discriminator has been widely used recently for language generation related tasks.  What is new here? Is it the word-based metric? Sharing the context and word information with generator?  It would be helpful if the authors can clarify their contribution. \n  \nRegarding using MLE to first generate multiple hypotheses in generator, how is the quality of the n-best responses? \nIs there a way to measure the goodness of the responses in some kind of reranking framework, not necessarily discriminator? \n\nThe results in the table showed the proposed method outperforms the others in terms of those objective metrics. I feel some subjective evaluations are needed to strengthen the paper.\nFrom the samples responses in the table, it doesn’t look like the new method generates very good responses. \n\n\nDetailed comments: \n- Sec 2, before 2.1, last paragraph, “With the GAN objective, we can match the noise distribution, P(Z_i) to the distribution of the ground truth response, P(X_i+1|X_i).  This needs clarification. \n- Figure 1: caption, “left” and “right” are misplaced. \n- sec 2.1, last paragraph, without Z_i, the net could still learn a mapping from X_i to Y_i, but would produce deterministic outputs.  I think the authors mean that the system generates a probability distribution P(Y_i|X), the output is the most likely one from that. However, if the output is a distribution, the system can also do some sampling and not necessarily output the top one.  This is not that different from adding noise in the history — if that’s based on some distribution, then it may still be deterministic. \n']","[-20, 50, -20, -30]","[50, 80, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('empirical evaluation shows fairly convincingly that the proposed model is effective'), there are several criticisms and concerns raised. The reviewer points out issues with novelty ('novelty is relatively weak'), writing ('some issues early in Section 2'), and unexplained results ('puzzling result was not discussed'). They also suggest improvements like an ablation study. The overall tone suggests the paper has merit but significant room for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'It would be useful if...' and 'I do wonder why...' which maintain a polite and professional tone even when pointing out issues."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper's idea as 'interesting' and notes that the proposed methods outperform existing ones. However, they also point out areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering suggestions rather than criticisms (e.g., 'It would be better if...', 'I suggest...'). The tone is constructive and professional, without any harsh or rude comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'technically solid' and has 'good' results, they also point out several significant weaknesses, particularly in comparisons with previous work and evaluation. The reviewer concludes that the paper is not 'too influential' due to these shortcomings. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging strengths before discussing weaknesses, and framing criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'It would have been nice to include...' and 'The paper is technically solid' which maintain a constructive tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional, matter-of-fact tone overall."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'showed mostly better results'), they express significant concerns about the novelty and contributions of the work. Phrases like 'The novelty of the paper is limited' and critiques of the methodology indicate a generally negative sentiment. However, it's not extremely negative as the reviewer does provide constructive feedback and suggestions for improvement. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'It would be helpful if...' and 'I feel some subjective evaluations are needed...' instead of harsh criticisms. They also provide detailed comments and suggestions for improvement, which is a polite way to offer critique. The language is not overly formal or exceptionally polite, but it avoids rudeness and maintains a constructive tone.""]"
"['This paper proposes a deep probabilistic model for temporal data that leverages latent variables to switch between different learned linear dynamics. The probability distributions are parameterized by deep neural networks and learning is performed end-to-end with amortized variational inference using inference networks.\n\nThere has been a lot of recent research trying to combine probabilistic models and deep learning to define powerful transition models that can be learned in an unsupervised way, to be used for model-based RL. This paper fits in this research area, and presents a nice combination of several interesting ideas presented in related works (switching variables, structured inference networks, merging updates as in the Kalman filter). The novelty of this paper in terms of original ideas is limited, the novel part lies in the clever combination of known approaches.\n\nThe paper reads well, but I found the explanation and notation in section 4 quite confusing (although easy to improve). The authors propose a structured variational approximation, but the factorization assumptions are not clear from the notation (I had to rely on Figure 2a to fully understand them). \n- In the first line of equation 7 it seems that the variational approximation q_phi for z_t only depends on x_t, but it is actually dependent also on the future x through s_t and q_meas\n- The first line of section 4.1.1 shows that q_phi depends on x_{1:T}. However from figure 2a it seems that it only directly depends on x_{t:T}, and that the dependence on x_{1:t-1} is modelled through the dependence on z_{t-1}. \n- Is there a missing s_t in q_trans in the first line of (7)?\n- why do you keep the dependence on future outputs in q_meas if it is not used in the experiments and not shown in figure 2a? It only makes the notation more confusing.\n- You use f_phi to denote all the function in 4.1.1 (with different inputs). It would be clearer to use a different letter or for example add numbers (e.g. f^1_\\phi) \n- Despite being often done in VAE papers, it feels strange to me to introduce the inference model (4.1) before the generative model (4.2), as the inference model defines an approximation to the true posterior which is derived from the generative model. One could in principle use other type of approximate inference techniques while keeping the generative model unchanged. \n\nIt is difficult for me to understand how useful are in practice the switching variables. Reading the first part of the paper it seems that the authors will use discrete random variables, but they actually use for s_t continuous relaxiations of discrete variables (concrete distribution), or gaussian variables. As described in appendix B2 by the authors, training models with such continuous relaxations is often challenging in terms of hyper-parameter tuning. One may even wonder if it is worth the effort: could you have used instead a deterministic s_t parameterized for example as a bidirectional LSTM with softmax output? This may give equivalent results and remove a lot of complexity. Also, the fact that the gaussian switching variables perform better in the experiments is an indication that this may be the case.\n\nTo be able to detect walls the z variables basically need to learn to represent the position of the agent and encoding the information on the position of the walls in the connection to s_t.  Would you then need to train the model from scratch for any new environment?\n\nMinor comment:\n- in the softmax equation (6) there are missing brackets: lambda is at the denominator both for g and the log\n', 'This paper proposes a new model for switching linear dynamical systems. The standard model and the proposed model are presented. Together with the inference procedure associated to the new model. This inference procedure is based on variational auto-encoders, which model the transition and measurement posterior distributions, which is exactly the methodological contribution of the manuscript. Experiments on three different tasks are reported, and qualitative and quantitative results (comparing with different state-of-the-art methods) are reported.\n\nThe standard model is very well described, formally and graphically, except for the dynamic model of the switching variable, and its dependence on z_t-1. The proposed model has a clear graphical representation, but its formal counterpart is a bit  more difficult to grasp, we need to reach 4.2 (after the inference procedure is discussed) to understand the main difference (the switching variable does not influence the observation model). Still, the dependency of the dynamics of s_t on z_t is not discussed.\n\nIn my opinion, another issue is the discussion of the variational inference procedure, mainly because it is unclear what additional assumptions are made. This is because the procedure does not seem to derive from the a posteriori distribution (at least it is not presented like this). Sometimes we do not know if the authors are assuming further hypothesis or if there are typos in the equations. \n\nFor instance (7) is quite problematic. Indeed, the starting point of (7) is the approximation of the a posteriori distribution q_phi(z_t|z_t-1,x_1:T,u_1:T), that is split into two parts, a transition model and an inverse measurement model. First, this split is neither well motivated nor justified: does it come from smartly using the Bayes and other probability rules? In particular, I do not understand how come, given that q_phi is not conditioned on s_t, the past measurements and control inputs can be discarded. Second, do the authors impose that this a posteriori probability is a Gaussian? Third, the variable s_t seems to be in and out at the authors discretion, which is not correct from a mathematical point of view, and critical since the interesting part of the model is exactly the existence of a switching variable and its relationship with the other latent/observed variables. Finally, if the posterior q_phi is conditioned to s_t (and I am sure it must), then the measurement model also has to be conditioned on s_t, which poses perhaps another inference problem.\n\nEquation (10) has the same problem, in the sense that we do not understand where does it derive from, why is the chosen split justified and why the convex sum of the two distributions is the appropriate way to merge the information of the inverse measurements and the transition model.\n\nAnother difficulty is found in the generative model, when it is announced that the model uses M base matrices (but there are S possibilities for the switching variable). s_t(i) is not defined and the transition model for the switching variable is not defined. This part is difficult to understand and confusing. At the end, since we do not understand the basic assumptions of the model, it is very hard to grasp the contribution of the paper. In addition, the interpretation of the results is much harder, since we are missing an overall understanding of the proposed approach.\n\nThe numerical and quantitative results demonstrate the ability of the approach to outperform the state-of-the-art (at least for the normal distribution and on the first two tasks).\n\nDue to the lack of discussion, motivation, justification and details of the proposed approach, I recommend this paper to be rejected and resubmitted when all these concerns will be addressed.', 'Thank you for the detailed reply and for updating the draft \n\nThe authors have added in a sentence about the SLDS-VAE from Johnson et al and I agree that reproducing their results from the open source code is difficult. I think my concerns about similarities have been sufficiently addressed.\n\nMy main concerns about the paper still stem from the complexity of the inference procedure. Although the inference section is still a bit dense, I think the restructuring helped quite a bit. I am changing my score to a 6 to reflect the authors\' efforts to improve the clarity of the paper. The discussion in the comments has been helpful in better understanding the paper but there is still room for improvement in the paper itself.\n=============\n\nSummary: The authors present an SLDS + neural network observation model for the purpose of fitting complex dynamical systems. They introduce an RNN-based inference procedure and evaluate how well this model fits various systems. (I’ll refer to the paper as SLDVBF for the rest of the review.)\n\nWriting: The paper is well-written and explains its ideas clearly\n\nMajor Comments:\nThere are many similarities between SLDVBF and the SLDS-VAE model in Johnson et al [1] and I think the authors need to address them, or at least properly compare the models and justify their choices:\n\n- The first is that the proposed latent SLDS generative models are very similar: both papers connect an SLDS with a neural network observation model. Johnson et al [1] present a slightly simpler SLDS (with no edges from z_t -> s_{t + 1} or s_t -> x_t) whereas LDVBF uses the “augmented SLDS” from Barber et al. It is unclear what exactly  z_t -> s_{t + 1} is in the LDVBF model, as there is no stated form for p(s_t | s_{t -1}, z_{t - 1}).\n\n- When performing inference, Johnson et al use a recognition network that outputs potentials used for Kalman filtering for z_t and then do conjugate message passing for s_t. I see this as a simpler alternative to the inference algorithm proposed in SLDVBF. SLDVBF proposes relaxing the discrete random variables using Concrete distributions and using LSTMs to output potentials used in computing variational posteriors. There are few additional tricks used, such as having these networks output parameters that gate potentials from other sources. The authors state that this strategy allows reconstruction signal to backpropagate through transitions, but Johnson et al accomplish this (in theory) by backpropagating through the message passing fixed-point iteration itself. I think the authors need to better motivate the use of RNNs over the message-passing ideas presented in Johnson et al.\n\n- Although SLDVBF provides more experiments evaluating the SLDS than Johnson, there is an overlap. Johnson et al successfully simulates dynamics in toy image systems in an image-based ball-bouncing task (in 1d, not 2d). I find that the results from SLDVBF, on their own, are not quite convincing enough to distinguish their methods from those from Johnson et al and a direct comparison is necessary.\n\nDespite these similarities, I think this paper is a step in the right direction, though it needs to far more to differentiate it from Johnson et al. The paper draws on many ideas from recent literature for inference, and incorporating these ideas is a good start. \n\nMinor Comments:\n\n- Structurally, I found it odd that the authors present the inference algorithm before fully defining the generative model. I think it would be clearer if the authors provided a clear description of the model before describing variational approximations and inference strategies. \n- The authors do not justify setting $\\beta = 0.1$ when training the model. Is there a particular reason you need to downweight the KL term as opposed to annealing?\n\n[1] Johnson, Matthew, et al. ""Composing graphical models with neural networks for structured representations and fast inference."" Advances in neural information processing systems. 2016.']","[-20, -70, 50]","[60, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('nice combination of several interesting ideas', 'paper reads well'), they also point out significant limitations and concerns. The reviewer notes that the novelty is limited, the explanation in section 4 is confusing, and questions the practical usefulness of the switching variables. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions or suggestions rather than harsh criticisms. They use phrases like 'I found', 'It is difficult for me to understand', and 'One may even wonder' which maintain a polite tone while expressing concerns."", ""The sentiment score is -70 because the reviewer recommends rejection of the paper due to significant concerns about the methodology and clarity of presentation. The review points out multiple issues with the model description, inference procedure, and lack of justification for key assumptions. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the good description of the standard model and the demonstrated ability to outperform state-of-the-art in some tasks. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'in my opinion' and 'I recommend', which soften the critique. The reviewer also provides detailed feedback and suggestions for improvement, indicating a constructive approach rather than harsh dismissal. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' efforts to improve the paper and increases their score, but still expresses some concerns about the complexity of the inference procedure. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, thanks the authors for their detailed reply, and provides constructive feedback. They use phrases like 'I think' and 'I agree' to soften criticisms, and acknowledge the authors' efforts to address previous concerns. The reviewer maintains a professional and courteous tone while providing detailed feedback and suggestions for improvement.""]"
"['+ Theoretic explanation for the scoring function.\n+ (Promise for) Online provided source code.\n+ The paper is well-written.\n\n- The authors missed [1] which also introduces a generative model for knowledge graph embeddings. \n- The use of the datasets FB15k-237 and WN18RR instead of FB15k and WN18 (without inverse relations) would enable a better empirical evaluation. By using the flawed FB15k and WN18 datasets, the evaluation is biased towards the usage of inverse relations which should not exist in a link prediction evaluation dataset.\n- The authors are not mentioning and comparing to walk based approaches like node2vec [2], Deepwalk [3], and rdf2vec [4]. \n\n\nDue to the missing comparisons to the mentioned references above and the possible bias in the evaluation, I am leaning towards rejecting the paper.\n\n\nMinor comments:\n\n. Abbreviations like h for head are used before they are introduced.\n. ""The the"" -> ""The""\n. ""triples are likely too be obvious examples"" -> ""triples are likely to be obvious examples""\n\n\n[1] Xiao, Han, Minlie Huang, and Xiaoyan Zhu. ""TransG: A generative model for knowledge graph embedding."" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.\n\n[2] Grover, Aditya, and Jure Leskovec. ""node2vec: Scalable feature learning for networks."" Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2016.\n\n[3]  Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. ""Deepwalk: Online learning of social representations."" Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.\n\n[4] Petar Ristoski, Jessica Rosati, Tommaso Di Noia, Renato De Leone, and Heiko Paulheim. ""RDF2Vec: RDF Graph Embeddings and Their Applications."" SWJ http://www.semantic-web-journal.net/content/rdf2vec-rdf-graph-embeddings-and-their-applications-1', 'In this paper, the author proposed a way to understand the knowledge graph embedding task. More specifically, the authors try to extend the random walk model (Arora et al., 2016a) of word embeddings to KGE.\n\nSome of my detailed comments and questions below.\n\n1. To me, this paper sounds like a direct application of the method of Arora et al., 2016a to KGE. Therefore, this does look like a very obvious application, and it is not clear to me if this paper presents any new methods or if you have obtained any new insights.\n\n2. The paper claims that all prior work use some sort of heuristics in the KGE task, and their approach is a generative account that might deal with this issue? But I personally found that by using random walk and the exp function, you are also making some very strong assumptions that are similar to heuristics? How do you know it is exp function but not other function? \n\n3. I am not sure what the purpose for the evaluation section is. You mention that this paper is not about state-of-the-art results, but if you theory really works, your scoring function should beat SOTA results. \n\nOverall, I have to say that I am very disappointed with this paper, because there are no new theoretical tools being introduced, and the authors seem to be applying Arora et al., 2016a from word embedding to KGE only. ', 'This paper proposes to perform the link prediction in knowledge bases by introducing a new scoring function and theoretically motivating their method. The authors validate their proposed approach through several experiments. \n\nThis paper reads well and the results appear sound. I personally find the theoretical argument behind the proposed scoring function very interesting. Unfortunately, the contribution seems rather small to be accepted for ICLR. This is a straight application and combination of existing pieces with not much originality and without being backed up by very strong experimental results. My concerns are as follows:\n\n   - Having only results on two flawed datasets (considering the inverse relations in them) makes it hard to evaluate the quality of the method. I suggest conducting the experiments on the FB15K-237 and WN18RR from [1] instead. \n   - You only evaluate on MR and Hits@10, but it is standard to include metrics like MRR and Hits@1 and 3 also, since no metric is perfect for this task.\n   - Since the goal of the work is not providing a state of the art method, and focus on the theoretical understanding of their scoring function, it is of high importance to assess the characteristics of their embeddings and scoring function through designing other experiments. As a result, I suggest to study the geometric behavior of their embeddings and compare it to the other methods. Further, investigating the semantic purity of the embeddings by calculating the entropy of the type distribution of the entities, similar as [2], can shed more light on the significance of their method.\n\nOn overall, although the proposed method seems a direct application of Arora et al.,2016a, I find their extension novel and quite interesting, But the paper needs more experimental results to validate the idea.  \n\n\n[1] Dettmers, Tim, et al. ""Convolutional 2d knowledge graph embeddings."", AAAI-18.\n[2] Ding, Boyang, et al. ""Improving Knowledge Graph Embedding Using Simple Constraints."", ACL-18.\n']","[-50, -70, -20]","[20, -20, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (theoretical explanation, promise of source code, well-written paper), they ultimately lean towards rejecting the paper due to significant issues with comparisons and dataset choices. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism, but doesn't go out of their way to be overly polite. They directly state their inclination to reject the paper, which is honest but not particularly gentle. The reviewer balances positive and negative points, provides specific recommendations for improvement, and uses phrases like 'Minor comments' to soften criticism, all of which contribute to a slightly positive politeness score."", ""The sentiment score is -70 because the reviewer expresses clear disappointment with the paper, stating it lacks novelty and new insights. They use phrases like 'very disappointed' and question the paper's contribution. The politeness score is -20 as the reviewer's language is direct and critical, but not overtly rude. They use phrases like 'I am not sure' and 'To me' which soften the criticism slightly, but the overall tone remains negative and somewhat blunt, especially in the concluding paragraph."", ""The sentiment score is slightly negative (-20) because while the reviewer finds aspects of the paper interesting, they express concerns about the contribution being small and not suitable for ICLR acceptance. They mention the need for more experimental results and improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths ('reads well', 'results appear sound', 'interesting') while offering constructive criticism. They provide specific suggestions for improvement rather than harsh criticism. The tone is professional and courteous, even when expressing concerns.""]"
"['Good results; providing some insights on the selection of activation function.  \n\nThis paper builds upon two previous works B.Poole etc. and S.S. Schoenholz etc. who initialized the study of random initialized neural network using a mean field approach (or central limit theorem.)\nThe two principal results of this paper are \n1. Initializing the network critically on the edge of chaos.  \n2. Identifying some conditions on the activation functions which allow good ""information flow"" through the network.   \n\nThe first result is not new in general (already appeared in Schoenholz etc. and many follow up mean field papers). However, the results about ReLU (initializing (weigh_variance, bias_variance)=(2, 0)) seems to be new. The author also shows that the correlations converge to 1 at a polynomial rate (proposition 3), which is interesting. \n\nThe second one is a novel part of this paper (proposition 5). If I understand correctly, the authors are trying to identify a class of activation functions (and suitable hyper-parameters) so that the network can propagate the sample-to-sample correlations (i.e. kernel) almost isometrically (please correct me if I am wrong). This is only possible 1) the activation functions are linear; OR 2) in the regime q->0, where the activation function has small curvature (i.e. almost linear). I think the results (and insights) are quite interesting. However, I don\'t think the authors provides enough theoretical or empirical evidence to support the claim that such activation functions can perform better.  \n\n\n\ncons:\n1. I don\'t think the experimental results are convincing enough for the reasons below:\n    1.1. All experiments are conducted over MNIST with testing accuracy around 96%.  The authors should consider using large datasets (at least Cifar10).\n    1.2 The width (<=80) of the network is too small while the theory of the paper assumes the width approaches infinity. Width>=200 should be a reasonable choice. It should be possible to train a network with depth~200 and width ~200 and batch_size~64 in a single machine.   \n    1.3. Figure 6(b) seems unconvincing. ReLU network should be trainable with depth>=200; see figure 4 of the paper: ""Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice"" \n\n\n2. The claim that swish is better than tanh because the latter suffers from vanishing of gradients is unconvincing. It has been shown in Schoenholz etc and many follow-up papers that ultra-deep tanh networks (>=1000 layers) can be trained with critical initialization. \n\n3. Again, I don\'t think it is convincing to make the conclusion that swish is better than ReLU based on the empirical results on MNIST. \n\n4. Using a constant learning rate (lr=0.001) for all depths (and all widths) is incorrect. I believe the gradients will explode as depth increases. Roughly, the learning rate should decay linearly with depth (and width) when the network is initialized critically.  \n\n\nIn sum, the paper has some interesting theoretical results but the empirical results are not convincing.  \n\n\nOther comments:\n1. The authors should explain the significance and motivation of proposition 4. In particular, explain why we need f(x)~x. \n2. Consider replacing ""Proposition 4"" by  ""Theorem"", since it is the main result of the paper.  \n\n', ""Studying properties of random networks in the infinite width limit, this work suggests guidance for choosing initialization and activation function. \n\nIn my opinion, novel contribution comes for guidance for choosing activation functions and theoretical grounds for superior performance of ```'swish’ activation function. \n\nI have two main concerns :\n\nIn terms of selection on initialization, the findings seem to be mostly discussed already in Schoenholz et al (2017) [1]. In their work, Edge of Chaos is critical line separating different phases and was already shown to have power-law decay rather than exponential decay. As far as I can tell, analysis on EOC on ReLU-like activations are different from Schoenholz et al (2017) [1]. Some of the results for ReLU are already appeared in the literature e.g. Lee et al (2018) [2].\n\nAnother main concern is in the author’s experimental setup. It is hard to draw conclusions when comparison experiments were done with a fixed learning rate.  As we know learning rate is one of the most critical hyperparameter for determining performance and optimal learning rate is often sensitive to architecture choice. Especially for different non-linearity and different depth/width optimal learning rate can change.\n\nPros: \n - Clearly written and easy to understand what authors are trying to say \n - Interesting theoretical support for activation function which recently got attention due to boosting performance in neural networks\n - Nice suggestion of choosing activation function for deep networks (Proposition 4)\n      -- ELU/SELU/Softplus/Swish all satisfy this suggestion\nCons:\n - Novelty may be not strong enough as the standard analysis tool from [1] was mostly used\n - Experimental setup may suffer from some critical flaw \n\nFew comments/questions:\n- P3: Is M_{ReLU} = 2 correct, from ReLU EOC, shouldn’t it be ½?\n- For all the works using activation functions satisfying Proposition 4 (ELU/SELU/Softplus/Swish), the initialization scheme close to EOC? Does this work’s analysis actually explain performance boost over ReLU for these activation functions?\n\n[1] S.S. Schoenholz, J. Gilmer, S. Ganguli, and J. Sohl-Dickstein. Deep information propagation. 5th International Conference on Learning Representations, 2017.\n[2] J. Lee, Y. Bahri, R. Novak, S.S. Schoenholz, J. Pennington, and J. Sohl-Dickstein. Deep neural networks as gaussian processes. 6th International Conference on Learning Representations, 2018.\n"", 'The authors prove some theoretical results under the mean field regime and support their conclusions with a small number of experiments. Their central argument is that a correlation curve that leads to sub-exponential correlation convergence (edge of chaos) can still lead to rapid convergence if the rate is e.g. quadratic. They show that this is the case for ReLU and argue that we must ensure not only sub-exponential convergence, but also have a correlation curve that is close to the identity everywhere. They suggest activation functions that attain conditions as laid out in propositions 4/5 as an alternative.\n\nThe paper has many flaws:\n- the value of the theoretical results is unclear\n- the paper contains many statements that are either incorrect or overly sweeping\n- the experimental setup and results are questionnable\n\nTheoretical results:\n**Proposition 1: pretty trivial, not much value in itself\n**Proposition 2: Pretty obvious to the experienced reader, but nonetheless a valuable if narrow result.\n**Proposition 3: Interesting if narrow result. Unfortunately, it is not clear what the ultimate takeaway is. Is quadratic correlation convergence ""fast""? Is it ""slow""? Are you implying that we should find activation function where at EOC convergence is slower than quadratic? Do those activation functions exist? It would be good to compare this result against similar results for other activation functions. For example, do swish / SeLU etc. have a convergence rate that is less than quadratic?\n**Proposition 4: The conditions of proposition 4 are highly technical. It is not clear how one should go about verifying these conditions for an arbitrary activation function, let alone how one could generate new activation functions that satisfy these conditions. In fact, for an arbitrary nonlinearity, verifying the conditions of proposition 4 seems harder than verifying f(x) - x \\approx 0 directly. Hence, proposition 4 has little to no value. Further, it is not even clear whether f(x) - x \\approx 0 is actually desirable. For example, the activation function phi(x)=x achieves f(x) = x. But does that mean the identity is a good activation function for deep networks? Clearly not.\n**Proposition 5: The conditions of prop 5 are somewhat simpler than those of prop 4, but since we cannot eliminate the complicated condition (ii) from prop 4, it doesn\'t help much.\n**Proposition 6: True, but the fact that we have f(x) - x \\approx 0 for swish when q is small is kind of obvious. When q is small, \\phi_swish(x) \\approx 0.5x, and so swish is approximately linear and so its correlation curve is approximately the identity. We don\'t need to take a detour via propposition 4 to realize this.\n\nPresentation issues:\n- While I understand the point figures 1, 2 and 4b are trying to make, I don\'t understand what those figures actually depict. They are insufficiently labeled. For example, what does each axis represent?\n- You claim that for ReLU, EOC = {(0,\\sqrt{2})}. But this is not true. By definition 2, EOC is a subset of D_\\phi,var. But {(0,\\sqrt{2})} is not in D_\\phi,var, because it simply leaves all variances unchanged and does not cause them to converge to a single value. You acknowledge this by saying ""For this class of activation functions, we see (Proposition 2) that the variance is unchanged (qal = qa1) on the EOC, so that q does not formally exist in the sense that the limit of qal depends on a. However,this does not impact the analysis of the correlations."" Section 2 is full of complicated definitions and technical results. If you expect the reader to plow through them all, then you should really stick to those definitions from then on. Declaring that it\'s fine to ignore your own definitions at the beginning of the very next section is bad presentation. This problem becomes even worse in section 3.2, where it is not clear which definition is actually used for EOC in your main result (prop 4), making prop 4 even harder to parse than it already is.\n\nCorrectness issues:\n- ""In this chaotic regime, it has been observed in Schoenholz et al. (2017) that the correlations converge to some random value c < 1"" Actually, the correlation converges deterministically, so c is not random.\n- ""This means that very close inputs (in terms of correlation) lead to very different outputs. Therefore, in the chaotic phase, the output function of the neural network is non-continuous everywhere."" Actually, the function computed by a plain tanh network is continuous everywhere. I think you mean something like ""the output can change drastically under small changes to the input"". But this concept is not the same as discontinuity, which has an established formal definition.\n- ""In unreported experiments, we observed that numerical convergence towards 1 for l ≥ 50 on the EOC."" Covergence of a sequence is a property of the limit of the sequence, and not of the 50th element. This statement makes no sense. Also if you give a subjective interpretation of those experimental results, you should present the actual results first.\n- ""Tanh-like activation functions provide better information flow in deep networks compared to ReLU-like functions."" This statement is very vague and sweeping. Also, one could argue that the fact that ReLU is much more popular and tends to give better results than tanh in practice disproves the statement outright.\n- ""Tanh-like activation functions provide better information flow in deep networks compared to ReLU-like functions. However, these functions suffer from the vanishing gradient problem during back-propagation"" At the edge of chaos, vanishing gradients are impossible! As Schoenholz showed, at the edge of chaos, \\chi_1=1, but \\chi_1 is also the rate of growth of the gradient. Pascanu et al (2013) discussed vanishing gradients in RNNs, which is a different story.\n- ""Other activation functions that have been shown to outperform empirically ReLU such as ELU (Clevert et al. (2016)), SELU (Klambauer et al. (2017)) and Softplus also satisfy the conditions of Proposition 4 (see Supplementary Material for ELU)."" Firstly, SeLU does not satisfy proposition 4. f(x) \\approx x requires \\phi to be close to a linear function in the range where the pre-activations occur. Since SeLU has a kink at 0, it cannot be close to a linear function no matter how small the pre-activations are. Secondly, softplus also doesn\'t satisfy proposition 4, as \\phi(0) = 0 does not hold. Thirdly, this statement is too sweeping. If ELU / SELU / Softplus ""outperform"" ReLU, why is ReLU still used in practice? At best, those nonlinearities have been shown to outperform in a few scenarios.\n- ""We proved in Section 3.2 that the Tanh activation guarantees better information propagation through the network when initialized on the EOC."" Prop 4 only applies in the limit as \\sigma_b converges to 0. So you can\'t claim that you showed tanh as ""better information propagation"" in general.\n- ""However, for deeper networks (L ≥ 40), Tanh is stuck at a very low test accuracy, this is due to the fact that a lot of parameters remain essentially unchanged because the gradient is very small."" But in figure 6b the accuracy for tanh is decreasing rapidly, so therefore the parameters are not remaining ""essentially unchanged"", as this would also cause the accuracy to remain essentially unchanged. Also, if the parameter changes are too small ... why not increase the learning rate?\n- ""To obtain much richer priors, our results indicate that we need to select not only parameters (σb , σw ) on the EOC but also an activation function satisfying Proposition 4."" Prop 4 only applies when \\sigma_b is small, so you additionally need to make sure \\sigma_b small.\n- ""In the ordered phase, we know that the output converges exponentially to a fixed value (same value for all Xi), thus a small change in w and b will not change significantly the value of the loss function, therefore the gradient is approximately zero and the gradient descent algorithm will be stuck around the initial value."" But you are using Adam, not gradient descent! Adam explicitly corrects for this kind of gradient vanishing, so a small gradient can\'t be the reason for the lack of training success.\n\nExperimental issues:\n- ""We use the Adam optimizer with learning rate lr = 0.001."" You must tune the learning rate independently for each architecture for an ubiased comparison.\n- In figure 6b, why does tanh start with a high accuracy and end up with a low accuracy? I\'ve never seen a training curve like this ... This suggests something is wrong with your setup.\n- You should run more experiments with a larger variety of activation functions.\n\nMinor comments: \n- ""Therefore, it is easy to see that for any (σb , σw ) such that F is increasing and admits at least one fixed point,wehaveKφ,corr(σb,σw) ≥ qwhereqistheminimalfixedpoint;i.e. q := min{x : F(x) = x}."" I believe this statement is true, but I also think it requires more justification.\n- At the end of page 3, I think \\epsilon_r should be \\epsilon_q\n\nThere are some good ideas here, but they need to be developed/refined/polished much further before publication. The above (non-exhaustive) list of issues will hopefully be helpful for this.\n\n\n### Addendum ###\nAfter an in-depth discussion with the authors (see below), my opinion on the paper has not changed. All of my major criticisms remain: (1) There are far easier ways of achieving f(x) ~ x than propositions 4/5/7, i.e. we simply have to choose \\phi(x) approximately linear. (2) The experiments are too narrow, and learning rates are badly chosen. (3) The authors do not discuss the fact that as f(x) gets too close to x, performance actually degrades as \\phi(x) gets too close to a linear function. (Many other criticisms also remain.)\n\nThe one criticism that the authors disputed until the end of the discussion is criticism (1). Their argument seems to hinge on the fact that their paper provides a path to construct activation function that avoid ""structural vanishing gradients"", which they claim \'tanh\' suffers from. While they acknowledge that tanh does not necessarily suffer from ""regular"" vanishing gradients (as shown by ""Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice"" and ""Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks""), they claim it suffers from structural vanishing gradients. I do not believe that there is such a thing as structural vanishing gradients. However, even if such a concept did exist, it falls on the the authors to provide a clear definition / explanation, which they neither do in the paper nor the rebuttal.']","[20, 20, -80]","[60, 60, -20]","[""The sentiment score is 20 (slightly positive) because the reviewer acknowledges 'good results' and 'interesting' insights, but also expresses several concerns about the experimental results and conclusions. The overall tone is mixed, with recognition of novel contributions alongside significant critiques. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as suggestions rather than harsh criticisms. The reviewer also uses phrases like 'please correct me if I am wrong' and 'the authors should consider', which contribute to a polite tone. However, the review doesn't go out of its way to be overly complimentary or deferential, maintaining a professional and objective stance."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as it being clearly written and having interesting theoretical support. However, they also express two main concerns and list some cons, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing concerns, and framing criticisms as 'concerns' rather than outright flaws. They also use phrases like 'in my opinion' and 'as far as I can tell', which soften their critiques. The reviewer provides a balanced view, listing both pros and cons, and offers constructive feedback in the form of questions and suggestions, which contributes to the polite tone."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer lists numerous flaws in the paper, including unclear theoretical results, incorrect statements, questionable experimental setup, and presentation issues. The reviewer states that 'The paper has many flaws' and provides an extensive list of criticisms. Even after discussion with the authors, the reviewer's opinion 'has not changed' and 'All of my major criticisms remain'. The politeness score is -20 because while the reviewer provides detailed feedback, which is helpful, the tone is quite harsh and direct. Phrases like 'The paper has many flaws', 'Pretty obvious to the experienced reader', and 'This statement makes no sense' come across as somewhat rude. However, the reviewer does occasionally use more neutral language and acknowledges 'some good ideas', which prevents the score from being even lower.""]"
"['This very interesting paper is based on the sensorimotor contingency theory, which grounds the perception of the agent (motor perception and sensory perception) in the capacity to learn to predict future sensory experience and to build a compact internal representation of proprioception and motor states. They show that through active experience (exploration) of an environment, an agent can encode its motor state in a way that captures both the topology and the relative distances. The authors show that in the case of an environment consistent with sensorimotor transitions and with some changes in the environment that are not inconsistent with the sensorimotor transitions (resets?), the network can learn the representation h of motor that project to the actual position of the agent in the environment (albeit in very contrived 2D toy tasks).\n\nThe model does not rely on RL at all; rather, it uses the representation of motor states (proprioception) to make predictions about the sensory observations of the environment. If such an agent were to act, I presume that there would be a search procedure across motor states to make the agent reach a desired state. The paper merits publication at ICLR provided very extensive revisions are made, and I am listing here the improvements to be made.\n\nIt is cool to cite Kant, Poincaré and Nicod, whose philosophical work underlies subsequent work on representing space and sensory experience. When citing Kant, please cite the primary source, not the 1998 re-edition.\n\nThere are missing references to Wayne et al (2018) ""Unsupervised Predictive Memory in a Goal-Directed Agent"" arXiv:1803.10760 and Ha & Schmidhuber ""World Models"" arXiv:1803.10122, where an agent is shown to build a representation of the world that can be decoded into spatial position and even a map of obstacles, on previously unseen environments, using only prediction of images, rewards and actions. Please include them in your work as they considerably change the narrative of section 2 (related work). Essentially, while the claims of the paper are interesting and relevant for the representation learning community, similar work has already been done, at much larger scale, from visual observations, using RL and self-supervised learning.\n\nSection 2 is also somewhat overly critical of previous work: in (Banino et al, 2018; Cueva & Wei, 2018) ""rely[ing] on extraneous spatial supervision signals [do not] counter any claim of autonomy"", first because these signals can come from sensory perception (e.g., smell) and also because the agent is still autonomous at test time. Similarly, the depth prediction task in (Mirowski et al, 2017) is rather intuitive (stereo-vision).\n\nPart 3 is difficult to parse: it would help to use the word proprioception (or explain why it is inappropriate) when talking about motor states, and exteroception (sensing the environment). I understood the first assumption, which is local continuity in sensory and motor space as well as the ambiguity of redundant motor systems that can generate the same sensory states, but not the second assumption. From what I understand, there are two invariants in building the model of proprioception: invariance to the topology of the environment and to the distances between objects, but then this is hard to reconcile with the setup of (in)consistent transitions in a moving environment and consistent transitions in a static environment. Please rewrite this section in a way that is easier to parse for people who know state-space models and RL for navigation and grasping (who may be your audience). Moreover, all the references point to a single work, which suggests that it is a very peculiar way of approaching a much more general problem of sensorimotor prediction, and therefore begs for a clear and simple explanation.\n\nThe architecture of the model is interesting: typically deep RL papers encode the sensory observations s into a hidden representation h, to take actions and produce a motor state m. Here, the current and future motor states m_t and m_{t+1} are embedded into h_t and h_{t+1} using a siamese MLP and used, in combination with the current sensory observation s_t, to make a prediction of s_{t+1}. This is somewhat related to learning the dynamics in model-based RL; please look into and cite Pathak et al (2017) ""Curiosity-driven exploration by self-supervised prediction"", ICML and other work on intrinsic curiosity.\n\nThe experiments are in very simplistic 2D grid world environments, but it makes the analysis and understanding of the 3D representations h much more simpler to follow. On the other hand, the discrete world task is very contrived (especially the weird mapping from m to h and from p to s) and hard to relate to existing work. One difficult problem that is solved by (Banino et al, 2018) is that of path integration in 2D from egocentric velocity. Could the authors present results on such a nonlinear case?\n\nRevision: Score updated from 6 to 7.', ""The paper proposes that agents can extract the spatial structure of the world if consistently explored solely from sensorimotor predictions.\n\nThe topic of the paper is relevant and fits the conference. However, I have doubts about the generality of the claims made.\n\nStrong aspects:\nAbstract makes the reader curious and excited about the content\nInteresting and important topic for representation learning.\n\nWeak aspects:\nThe paper is written in a way that it is not easy to follow. \nImportant details are in the Appendix and some more formal description would be helpful. A clearer presentation of the three different exploration types for instance would help the reader. \nThe paper is not using standard notation and deviates from the POMDP description for not clear reason. \nIt is hard to compare and the results are in a very restricted setup.\nNo baseline or comparison to other methods are given.\nWhy does space emerge in the motor-state (h) not the sensor state?\nNot enough details given to reproduce the paper. It is nothing mentioned about code to be made public.\n\nDiscussion:\nThe argument of the paper is that it is sufficient to do sensor prediction when the world is consistently explored and changing in a consistent manner. There is no need for additional losses or the like. However, I am not convinced about the generality of this statement. What if the world is much richer and the agent and the environment undergo the typical transformations. Rotation and movement in 3D space + non-linear distortions by sensors (e.g. a camera). I am not seeing why a representation of space should emerge without any pressure for minimality or the like. The paper also assumes that the sensor is moved by the motor command in space directly and not, for instance, as a double integrator equations where the motor command is a force that accelerates a body. \nIn the current form, what it really says, is that the network figures out the actual effect of the motor command in moving the sensor around. The sensor is moved in a 2D space by the actions such that the network recovers this 2D manifold. And this can only happen if it actually observes movements and the dataset is rich enough. This distinguishes the 3 different exploration settings. \n\nDetails:\nSec 2:  Prior work: Which priors in Jonschkowski and Brock 2015 do you mean that are specific to the emergence of space? Slowness?\nSec 3: what do you really mean by motor state? In MDPs there is the notion of action that effects the state of the system. There is not really a state of the motor system? Do you mean proprioceptive sensors or actually the motor command/action.\nThe definition s = \\phi_e(m) is kind of nonstandard as one would expect a dependency on s_{t-1} which is in your notation hidden in \\epsilon.\nThe logic is not so straight forward to me. Isn't the logic such that: Given a rigid metric space: when the agent moves around the same type of movements lead to the same kind of transformations independently of there the agent is located?\nI believe this section could be streamlined and illustrated by some examples to drive the message home. Also, making a clear and potentially more explicit statement of these invariances (e.g. by an equation) and why they will be revealed by learning predictions.\n\nSec 4.2:\nImprove the description of the settings. In the first setting (MTM) subsequent sensor/motor values are independent right? So it is the same as having randomly selected isolated data points from a normal interaction. \n\nMMT setting: you write ... which can translate randomly after each transition.  This is almost the same as in MTM where you write ...translates randomly between t and t+1\nIn the Appendix you write that in MMT that environment moves only every 100 steps? \n\nBTW:\nIs the env-movement a smooth movement or a jump?\n \nFig 2: why does the green curve end so early? Is it because of your stopping criteria for training. I would like to see the same training time for all settings.\n\nFig 3 and text: Should one not expect a torus in (a)? The world is not a square but a torus, as you have cyclic boundary conditions. I am surprised to not see this in the plots. The current result somehow violates the smoothness because there is a big jump between the boundaries although in environment there is none.\n \nSec 6: par 2: ...these invariants represents for the predictive model?\n\nOut of my curiosity:\nyou write that ... casts some doubts on purely passive and observational approaches....\nIn which sense did the actions help here? Do you mean that the agent needs to know its own actions right? \nSo when it is to be done from a video (just sensor information) than the actions would need to be inferred first?\n\nTypos:\np1 par2: approache\np8 last par: could be merge\n\nupdated score after authors revision\n"", ""The paper investigates the exploratory conditions under which spatial representations will emerge as a byproduct of learning to predict the next sensory observation. In particular, the authors test three exploratory conditions:\n(i) When the set of sensory-motor interactions (st, mt, s_{t+1}, m_{t+1}) are inconsistent. \n(ii) Environment is static and set of sensory-motor interactions are consistent. \n(iii)  Environment is dynamic and the set of sensory-motor interactions are consistent. \n\nAuthors measure the quality of learned spatial representations by computing disparity between the set of agent positions and the corresponding embedding of motor commands learned by predicting the next sensory observation. They conclude that under condition (iii), the disparity is minimum -- i.e. the agent is best able to discover the spatial structure of it environment. \n\nPhilosophically, I love the direction of this work -- understanding the origins of our spatial representations. But, I am concerned with the delivery. My concerns/questions are as following:\n\n(a) Firstly, the writing is too verbose and vague without clarifying the details and there are too many references to Laflaquiere et al. I would recommend the authors to be more precise, i.e. define topological/metric invariants, clarify how in-consistent sensory/motor pairs are sampled in MTM condition and how environment is perturbed in MMT condition. These things are defined at a high-level and not precisely. \n\n(b) The whole premise of comparing the embedding of motor commands and the agent's spatial configuration only works under a special condition -- s = φε(m) (section 3 of the paper), which is not general. For e.g. if an arm is “torque controlled” it is not possible to predict the location of the arm (i.e. a potential sensory observation) just from the torques. Additional knowledge of the agent’s state such as current position and the velocity of the arm is required. In the examples mentioned in the paper, the arm is “position” controlled, i.e. given the orientation of each joint (i.e. the motor command) it is possible to predict the sensory observation.  This is a very special case. In biology for example, we control the flexing of muscle fibers using the motor system, we can’t directly output positions of the arm. The general, condition of operation should be: s_{t+1} = φε(m_t, s_t). \n\n(c) Authors argue that in order to learn metric invariants, the agent needs to observe the same sensory state under different motor commands. They further argue that in the MMT condition, where the environment also translates, this affect is achieved and therefore metric invariants are learned. My position is that this is simply an artifact of the restricted problem setup where  s = φε(m) holds. In a more general setup, s_{t+1} = φε(m_t, s_t) there is no requirement for the environment to move. An arm with different torques can be at the same position and hence the condition imposed by authors should be specified naturally even in MM environments. What do the authors think? \n\n(d) Under the condition of,  s = φε(m) difference between MM and MMT appears that in one case (MM), neural network is trained without translation perturbations, and in other case MMT is a form of data augmentation with translation perturbations. I am not sure if there is any other justification for why only topological invariants should be learned with MM and metric invariants with MMT. To me it seems like training with data augmentation leads to better metric learning. Do the authors have any other insights — I would love to know. \n\n(e) Finally the embeddings are useful, if they are useful for an end-task. I would love, if the authors evaluated the learnt embeddings in each of the three conditions for some end tasks such as reaching in case of an arm or something else that is more feasible. \n\nDespite it being a very interesting topic, due to theoretical concerns outlined above, I cannot recommend the paper for acceptance. With a strong rebuttal it is possible to convince me otherwise.  \n""]","[50, -30, -50]","[70, 20, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'very interesting' and states it 'merits publication', but also requires 'very extensive revisions'. This indicates a generally positive view with significant reservations. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits while providing constructive criticism. They use phrases like 'It is cool to cite...' and 'please include...' which maintain a collegial tone. The reviewer also provides detailed, helpful feedback without using harsh or dismissive language, even when pointing out shortcomings or suggesting improvements."", ""The sentiment score is -30 because while the reviewer acknowledges some strong aspects and the relevance of the topic, they express significant doubts about the generality of the claims and list several weak aspects. The overall tone is more critical than positive. The politeness score is 20 because the reviewer uses professional and respectful language throughout, offering constructive criticism and asking questions for clarification rather than making harsh judgments. However, the critique is direct and doesn't use overly polite phrasing, keeping the score moderately positive rather than very high."", ""The sentiment score is -50 because while the reviewer expresses interest in the topic ('Philosophically, I love the direction of this work'), they have significant concerns and ultimately cannot recommend the paper for acceptance. This indicates a negative overall sentiment, but not extremely negative due to the recognition of the work's potential importance. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges the value of the research direction, and offers detailed feedback for improvement. They also leave room for the authors to convince them otherwise with a strong rebuttal, which is a polite gesture. However, the score is not higher as the review is still critical and direct in its concerns.""]"
"['This paper proposes to introduce a new domain, the uncertain domain, to better handle the division between seen/unseen domains in open-set and generalized zero-shot learning. The approach handles test samples estimated to be from the seen class in one way, and ones that belong to either the unseen or uncertain domain in another way. This idea handles the problem that test instances may incorrectly be attributed to one of the seen classes. The authors evaluate their approach on several relevant datasets against a wide variety of methods for OSL and ZSL, and show convincing results. \n\nI have three concerns. One is that the method sections of the paper are fairly lengthy, including an extensive explanation of prior work, e.g. EVT, so time is spent reading before the reader gets to the interesting part of the proposed method, and this time could be better focused around the contributions of *this* work. \n\nFor the G-ZSL experiments, most of the methods seem to be older methods tackling ZSL not G-ZSL so perhaps more relevant baselines could be found.\n\nOn a related note, it would be good to include some qualitative examples that might reveal some intuitive reasons for the large margin between the performance of the proposed work, and other approaches; in some cases this margin seems rather large, and while the authors attempt to explain it, something beyond a textual explanation might be useful. ', 'This paper describes an approach to domain separation based on bootstrapping to identify similarity cutoff thresholds for known classes, followed by a Kolmogorov-Smirnoff test to refine the bootstrapped in-distribution zones. The authors apply these techniques to two general recognition problems: open-world recognition, and Generalized Zero-shot Learning (GZSL). Experimental results are given on a variety of datasets, and a thorough comparative evaluation on GZSL is performed.\n\nThe paper has the following strong points:\n\n 1. The motivations for each element of the proposed approaches are fairly well presented and are compelling.\n \n 2. The experimental results on GZSL are impressive, especially compared to established approaches.\n\nThe paper also has the following weak points:\n\n 1. The writing is a bit rough throughout, though not to extreme distraction. The abstract starts right off with the awkward ""This paper studies the problem of domain division problem..."" The manuscript needs more careful revision for clarity.\n\n 2. Related to the previous point, there are several elements of the technical exposition that are lacking in clarity. For example, it is unclear what eq. 9 is defining exactly. It seems to be the final decision rule, but it is not clear how seen, unseen, and uncertain samples are determined. Algorithm 1 is clear, but there is never a clear, complete definition of the end-to-end decision pipeline given. I feel like it would be difficult to reproduce the results of this article without significant trial-and-error.\n\n 3. The authors seems to have relied on the Xian et al. paper to extract data for their comparative evaluation on GZSL. There are more recent works from 2018 that should be included, such as:\n\n Arora, Gundeep, Vinay Kumar Verma, Ashish Mishra and Piyush Rai. “Generalized Zero-Shot Learning via Synthesized Examples."" CVPR 2018.\n\nIn summary, this paper has many interesting ideas, and the GZSL results are indeed impressive (with respect to the results in the comparison). However, there are many problems with clarity and missing, recent work in the comparative evaluation.\n\n', ""This paper deals with the difficult problem of novelty recognition which is the core issue in open set learning and generalized zero-shot learning. Indeed a method able to separate samples between known and unknown domains in these settings would clearly indicate the direction for their solution. The idea proposed here consists in starting from the extreme value theory and then using bootstrapping to model the confidence score for a sample of belonging or not to a certain class. Through a probabilistic evaluation (based on K-S test) on the trustworthy of each category classifiers, the domain separation is extended to consider also an uncertain domain and the separation threshold is progressively refined. Once the domains are separated, classification can be performed disjointly in each of them.\n\n+ Having a way to define known/unknown and uncertain samples on the basis of which one can\nthen proceed to solve OSL and GZSL sounds as a very effective strategy. Moreover, all the parts of the method are \nbased on reliable probabilistic principles.\n \n- Unfortunately the text is not easy to read. There are several repetitions and disordered lists (same numbers used multiple times or mixing names and numbers for the items) which distract the reader. As a side note, it would be better to avoid mentioning dataset names without their description and definition ('aPY' appears out of the blue in the introduction). \n\n- The experiments extends over different datasets and the ablation study is valuable. However to understand how the proposed method advances over the current state of the art it is important to consider and discuss the most recent publications  on OSL and GZSL. See for instance\nOpen Set Learning with Counterfactual Images, ECCV 2018\nFeature Generating Networks for Zero-Shot Learning, CVPR 2018\n\n\n\n""]","[60, 20, 20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by highlighting the paper's novel approach and its convincing results. They use phrases like 'convincing results' and 'interesting part of the proposed method', indicating a generally positive view. However, they also raise three concerns, which slightly tempers the overall positivity. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their concerns as suggestions rather than criticisms. They use phrases like 'it would be good to' and 'perhaps more relevant baselines could be found', which are polite ways of suggesting improvements. The reviewer also acknowledges the authors' efforts to explain their results, even while suggesting additional explanations might be useful."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges strong points of the paper, such as well-presented motivations and impressive experimental results. However, they also point out several weak points, including writing issues and lack of clarity in technical exposition, which balances out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging both strengths and weaknesses without harsh criticism. They use phrases like 'The paper has the following strong points' and 'The paper also has the following weak points', which maintain a professional and courteous tone. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the polite tone of the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution to a difficult problem and praises the method's basis on reliable probabilistic principles. However, they also point out significant issues with readability and the need for more recent comparisons. The politeness score is moderately positive (50) as the reviewer uses constructive language, balancing positive feedback with areas for improvement. They avoid harsh criticism and use phrases like 'Unfortunately' to soften negative points. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"[""Summary: This work provides an analysis of the directional distribution of of stochastic gradients in SGD. The basic claim is that the distribution, when modeled as a von Mises-Fisher distribution, becomes more uniform as training progresses. There is experimental verification of this claim, and some results suggesting that the SNR is more correlated with their measure of uniformity than with the norm of the gradients.\n\nQuality: The proofs appear correct to me. \n\nClarity: The paper is generally easy to read.\n\nOriginality & Significance: I don't know of this specific analysis existing in the literature, so in that sense it may be original. Nonetheless, I think there are serious issues with the significance. The idea that there are two phases of optimization is not particularly new (see for example Bertsekas 2015) and the paper's claim that uniformity of direction increases as SGD convergence is easy to see in a simple example. Consider f_i(x) = |x-b_i|^2  quadratics with different centers. Clearly the minimum will be the centroid. Outside of a ball of certain radius from the centroid all of the gradients grad f_i point in the same direction, closer to the minimum they will point towards their respective centers. It is pretty clear, then that uniformity goes up as convergence proceeds, depending on the arrangement of the centers.\n\nThe analysis in the paper is clearly more general and meaningful than the toy example, but I am not seeing what the take-home is other than the insight generated by the toy example. The paper would be improved by clarifying how this analysis provides additional insight, providing more analysis on the norm SNR vs uniformity experiment at the end. \n\nPros:\n- SGD is a central algorithm and further analysis laying out its properties is important\n- Thorough experiments.\n\nCons:\n- It is not entirely clear what the contribution is.\n\nSpecific comments:\n- The comment at the top of page 4 about the convergence of the minibatch gradients is a bit strange. This could also be seen as the reason that analysis of the convergence of SGD rely on annealed step sizes. Without annealing step-sizes, it's fairly clear that SGD will converge to a kind of stochastic process.\n\n- The paper would be stronger if the authors try to turn this insight into something actionable, either by providing a theoretical result that gives guidance or some practical algorithmic suggestions that exploit it.\n\nDimitri P. Bertsekas. Incremental Gradient, Subgradient, and Proximal Methods for Convex Optimization: A Survey. ArXiv 2015."", '\nQuality and clarity: good.\n\nOriginality and significance: This paper studies the stochasticity\nof the norms and directions of the mini-batch gradients, to\nunderstand SGD dynamics. The contributions of this paper can be\nsummarized as: a) This paper defines gradient norm stochasticity as\nthe ratio of the variance of the stochastic norm to the expectation\nof the stochastic norm. It theoretically and empirically shows that\nthis value is reduced as the batch size increases b) This paper\nempirically finds that the distribution of angles between\nmini-batch gradient and a given uniformly sampled unit vector\nconverges to an asymptotic distribution with mean 90 degrees, which\nimplies a uniform distribution of the mini-batch gradients. c)\t\nThis paper uses von Mises-Fisher Distribution to approximate the\ndistribution of the mini-batch gradients. By theoretically and\nempirically observing that the estimated parameter \\hat \\kappa\ndecreases during training, they claim that the directional\nuniformity of mini-batch gradients increases over SGD training.\n\nThe idea of measuring the uniformity of mini-batch gradients\nthrough VMF distribution seems interesting. But it is unclear how\nthe study of this stochasticity dynamics of SGD can be related to\nthe convergence behavior of SGD for non-convex problems and/or the\ngeneralization performance of SGD.\n\nThere are additional concerns/questions regarding both theoretical\npart and empirical part:\n\n[1] Section3.3: Assumption that p_i(w_0^0) =p_i(w_1^0) = p_i is not\nreasonable when theoretically comparing \\hat \\kappa(w_1^0) and \\hat\n\\kappa(w_0^0). The concentration parameter \\hat \\kappa(w) should be\nestimated by the sum of the normalized mini-batch gradients ""\\hat\ng_i(w)/||\\hat g_i(w)||"" . Instead of using mini-batch gradient,\nthis paper uses the sum of ""p_i-w"" by assuming that ""p_i(w_0^0) -w""\nis parallel to ""\\hat g_i(w)"", which is ok. However, when comparing\n\\hat \\kappa(w_0^0) and \\hat \\kappa(w_1^0), we say \\hat\n\\kappa(w_0^0) = h(\\sum p_i(w_0^0) - w_0^0) ) and \\hat \\kappa(w_1^0)\n= h(\\sum p_i(w_1^0) - w_1^0) ). It is not reasonable to use the\nsame p_i for p_i(w_0^0) and p_i(w_1^0) because p_i(w_0^0) -w_1^0 is\ndefinitely not parallel to \\hat g_i(w_1^0).\n\n[2] Section 3.3: Assumption \\hat g_i(w_t^{i-1}) \\hat g_i(w_t^0) is\nnot convincing. With this assumption, the paper writes w_1^0 =\nw_0^0 - \\eta\\sum_i \\hat g_i(w_0^{i-1}) = w_0^0 - \\eta\\sum_i \\hat\ng_i(w_0^0) = w_0^0 - \\eta \\sum_i p_i-w_0^0. These equalities are\nnot persuasive. Because, \\sum_i \\hat g_i(w_0^0) is the full\ngradient g(w_0^0) at w_0^0. In other words, these equalities imply\nthat from w_0^0 to w_1^0 (one epoch), SGD is doing a full gradient\ndescent: w_1^0 = w_0^0 -\\eta g(w_0^0), which is not the case in\nreality.\n\n[3] Experiment: Batch size should be consistent with the given\nassumption in the theoretical part. In theoretical part, \\hat\n\\kappa(w_1^0) < \\hat \\kappa(w_0^0) is based on the assumption that\n|\\hat g_i(wt^{i-1}| \\tat for all i, with *large mini-batch size*.\nBut in the experiment, they prove \\hat \\kappa(w_1^0) < \\hat\n\\kappa(w_0^0) by using small-batch size which is 64. The authors\nshould either provide experiments with large batch size or try to\navoid the assumption of large batch size in theoretical part.\n\n[4] The CNN experiment; It is better to add a discussion why the\n\\kappa increases in the early phase of training.\n\n[5] The experiment results show, by the end of training, all models\nFNN, DENN and CNN have very large value of \\kappa which is around\n10^4. This value implies that the mini-batch gradients distribution\nis pretty concentrated, and it is contradictory to the statement in\nthe introduction which is ""SGD converges or terminates when either\nthe norm of the minibatch gradient vanishes to zeros, or when the\nangles of the mini-batch gradients are uniformly distributed and\ntheir non-zero norms are close to each other\'\'. It is also\ncontradictory to the experiment in 3.2 which implies the mini-batch\ngradient are uniformly distributed after training.\n\n[6] The notations in this paper can be improved, some notations are\nusing ""i"" for batch index, some notations are using ""i"" for one\ndata sample. Some notations in Section 3.3 and 3.1 can be moved to\nSection 2 Preliminaries. It will be clearer to define all the\nnotations in one place.\n\nTypos: -Section 3.1: first paragraph, E\\hat g(w) -> E[\\hat g(w)]; -\nParagraph before Lemma2: \\hat \\kappa increases -> \\hat \\kappa\ndecreases; - Paragraph after Theorem2: double the directions in ""If\nSGD iterations indeed drive the directions the directions of\nminibatch gradients to be uniform"".', '\nGradient stochasticity is used to analyse the learning dynamics of SGD. It consists of two aspects: norm stochasticity and directional stochasticity. Although the norm stochasticity is easy to compute, it vanishes when the batch size increases. Therefore, it can be hard to measure the learning dynamics of SGD. The paper is motivated by measuring the learning dynamics by the directional stochasticity. Directly measuring the directional stochasticity with the ange distribution is hard, so the paper uses vMF distribution to approximate the uniformity measurement. The paper theoretically studies the proposed directional uniformity measurement. In addition, the experiments empirically show the directional uniformity measurement is more coherent with the gradient stochasticity.\n\n1. As I’m not a theory person, I’m not very familiar with the related work on this line. But the analysis on the directional uniformity is interesting and original. So is the vMF approximation.\n2. The theoretical analysis looks comprehensive and intuitive. And the authors did a reasonably good job on the experiments.\n3. This paper provides some insights that warn people to pay attention to the directions of SGD. But the paper didn’t provide an answer on how this study can inform people to improve SGD. It’s true that the directional uniformity increases over training and it is correlated to the gradient. But what could this bring us remains unstudied.\n4. Can the authors provide any theoretical or empirical analysis on why the directional uniformity didn’t increase in deep models like CNN and why it increases when BN and Res are applied?\n']","[-20, -20, 60]","[60, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The proofs appear correct', 'The paper is generally easy to read', 'Thorough experiments'), they express significant concerns about the paper's significance and contribution. The reviewer states, 'I think there are serious issues with the significance' and 'It is not entirely clear what the contribution is.' These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The paper would be improved by...' and 'The paper would be stronger if...', which offer constructive criticism in a polite manner. The reviewer also acknowledges the paper's strengths before discussing its weaknesses, which is a courteous approach. While not overly effusive, the language is consistently respectful and avoids harsh or rude phrasing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Quality and clarity: good', 'The idea of measuring the uniformity of mini-batch gradients through VMF distribution seems interesting'), they express several concerns and criticisms about the paper's methodology, assumptions, and consistency between theory and experiments. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'It is better to add', 'The authors should either', and 'It will be clearer to', which offer constructive suggestions rather than harsh criticisms. The reviewer also points out positive aspects before delving into concerns, which is a polite approach in academic reviews."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses interest in the paper's analysis and methodology, describing it as 'interesting and original' and 'comprehensive and intuitive'. They also mention that the authors did a 'reasonably good job on the experiments'. However, the score is not higher because the reviewer points out that the paper doesn't provide practical applications for improving SGD and leaves some questions unanswered. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging their own limitations ('As I'm not a theory person...') and phrasing criticisms as questions or suggestions rather than direct attacks. The tone is professional and constructive, offering both praise and areas for improvement without being overly effusive or harsh.""]"
"['Volumetric Convolution, Automatic Representation Learning in Unit Ball\n\nThis work proposes to tackle the challenging problem of learning on unit balls. The method uses volumetric convolutions based on the Zernike polynomial trick, which makes it convenient to use on convolution networks. Invariance to 3D rotation enables a transformation to a volumetric space, where convolutions could be used in a conventional process. Clarity of the methodology may benefit from a motivation discussed from a global perspective. The reader is currently facing heavy mathematical concepts fairly quickly with global rationale on the proposed choices, in particular, in the explanation of symmetry analysis. Clarity on the use of 2D and 3D features could also benefit from more details on what is exactly proposed. Results are shown on an object recognition task achieving performance comparable with the state-of-the-art. \n\nPositive\n+ Tackles the difficult problem of extending graph learning to arbitrary topologies, particularly on unit balls\n+ The contributions are multifold -therotical framework for modeling volumetric convolutions over functions defined on unit-balls, -derivation of the formulation, to make it usable by neural nets, -measures of axial symmetry on unit-balls\n\nSpecific comments\n- How to handle mixed topologies, for instance, with random presence of holes in the meshes\n- Extension beyond unit balls?\n- Fundamentaly, arbitrary genus-0 meshes are topologically equivalent to a sphere, however, there can be severe metric distorsion when transforming shapes to a sphere (e.g, transforming a banana to a sphere, the ends gets severely atrophied) - Does this pose a problem - how to handle these metric distorsion?\n- Zernike polynomials are based on the spherical harmonics - could this be generalized to arbitrary graph harmonics? Beyond spherical shapes?\n\n\n\n', 'There is a great amount of interest in extending the notion of equivariance in neural networks from \njust translations to other groups. In particular, in the past year a sequence of papers have appeared \nstarting with (Cohen, Geiger et al.) on ""spherical CNNs"" that achieve equivariance to rotations for images \npainted on the surface of the unit sphere.\n\nThe present paper extends these ideas to volumetric data in the unit ball (rather than just the sphere) \nby the use of Zernike polynomials. Since Zernike polynomials can be expressed as the product of spherical \nharmonics with a radial function, this is essentially the same as adding a radial component to a spherical \nCNN. \n\nThe main result of the paper appears to be Theorem 1, which shows that what the authors define as \nvolumetric convolution is equivariant to rotations. This is split across Sections 4.2 and 4.3.. However, \napart from the radial component, this result is bascally the same as the SO3-equivariance of spherical CNNs, \nas discussed in three very recent spherical CNN papers: (Cohen, Geiger et al.) (Esteves Allen-Blanchette et al) \nand (Kondor, Lin and Trivedi). However, the somewhat more abstract, representation theoretic approach \nof some of these works allows a more compact derivation than the one in the present paper.\n\nThe authors also fail to cite recent work on SE(2) and SE(3) equivariant neural networks. SE(3) comprises \nall rotations and translations of R^3, so the latter, in particular, encapuslates SO(3) equivariance as \na special case. In particular, part of the construction in (Weiler, Hamprecht and Storath, CVPR 2018) \nis to add  Gaussian radial functions to SO(2) equivariant filters, which is just the 2D analog of \nwhat is happening in the present paper. Then in (Weiler, Geiger, et al., 2018) the same is done in 3D, \nexcept of course they go further by also adding translation equivariance. Admittedly, these papers are \nvery new, so the authors might not have known about them.\n\nI also find some of the mathematical details a little puzzling:\n\n1. As explained in the spherical CNN papers, taking the cross correlation of two functions on the sphere \n(by extension, in the unit ball) naturally results in a function that lives on the rotation group SO(3), i.e. \nthe cross-correlation (or convolution) is parametrized by three Euler angles. I don\'t understand why the \nauthors restrict themselves to considering just two angles, forcing their filters to be polar, as \nderived in Section 5. This seems like an artificial restriction that will limit the power of their approach. \n\n2. The paper mentions that Zernike polynomials are ""orthogonal and complete in B^3"". I think what they mean \nis that they are an ortogonal and complete basis for an appropriate space of functions on B^3, and that \nspace of functions is L_2(B^3). However, this is still not enough. For (3) to hold, one also needs the \nbasis to be orthonormal. Please be more precise.\n\n3. In the same vein, at one point in the proof, the authors mention that ""rotations are unitary operators \nin a Hilbert space"". This is not true of Hilbert spaces in general. It requires the above orthonormality etc.. \n\n4. Exactly as a consequence of orthonorlamity, Equation 5 is essentially just a generalized Fourier transform \non B^3, hence, in principle, it can be inverted analytically. I understand that the fact that the input \nimage is rasterized complicates things and in a practical implementation it might be expedient to invert (5) \nby using the pseudo-inverse. However, this is a one-time operations and is really just a hack. It seems strange \nthat the authors use a special iterative method just to invert a close to unitary matrix.\n\nThe mathematical shortcomings of the paper could be compensated by amazingly good experimental results. \nThe actual results are good, but still not best-in-class, possibly because at the end of the day the network \nis still only rotationally equivariant and does not take into account translations. \n\nThe spherical CNN and SE(n) equivariance papers generally apply the group equivariant operations consistently \nacross multiple layers. In contrast, the present paper only applies it in the first layer, and then uses a \ncombination of tricks like multiple viewpoints and bilinear pooling to boost performance. Unfortunately, the \nbenefits of this additional conceptual complexity are not entirely borne out in the experimental results.\n', 'The work concerns convolution in the unit sphere. It differentiates itself from previously mentioned work by working in the volume space and not the surface space. While I can\'t say I understand all of the implications of the work,  I was left with several questions. Many of these questions are in regards to claims made by the authors whose answer or reference was not made clear.\n\n- It was not made clear why there is a benefit to convolving the object in the unit sphere vs the unit cube, especially given that the work was not able to perform better than other work that was based on the unit sphere. This point was the stated problem of the paper. Although it was mentioned that the unit sphere preserves all of the points of the object, it isn\'t clear if the transformation causes any deformations of the object. Furthermore, the fixing of one axis seems to be a way to hack around problems of increased dimensionality, but there was no justification given.\n\n- How does the number of trainable layers help to differentiate resource usage. Wouldn\'t a better measure be number of parameters? The authors make that claim that shallowness is a virtue, but there is little discussion as to the size of each layer in comparable terms.\n\n- Why was no ""ablation"" or ""accuracy vs trained layers"" data shown for the Modelnet40 dataset? I would think that would be stronger evidence than for the Modelnet10 data.\n\n- Why wasn\'t the 1d conv net used for creating the viewing angles included in the size of the architecture? Was there a verification as to what the filters from this network were actually giving? The authors mention how we should interpret them, but not enough information about the structure of the network is given to satisfy this question.\n\n- I would have liked to see a description of the types of features that are found by these networks.\n\n- The authors say they are only going to show experiments on one possible use case, but then make claims for other use cases. I am referencing that since the texture data in the datasets used is constant, there was no need to model the texture data. There is no experimental evidence to show this is the case, however.\n\nOverall, I think the paper would have been stronger if it had more experiments.']","[60, -30, -30]","[70, 20, 20]","[""The sentiment score is 60 (positive) because the review begins by highlighting the work's contribution to a challenging problem and its novel approach. It mentions multiple positive aspects like tackling a difficult problem, proposing a theoretical framework, and achieving comparable performance to state-of-the-art methods. However, it also suggests some areas for improvement in clarity and explanation, which prevents it from being extremely positive. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the work's merits and framing suggestions as opportunities for improvement rather than criticisms. The reviewer uses phrases like 'may benefit from' and 'could also benefit from' when suggesting changes, which is a polite way of providing feedback. The specific comments are phrased as questions or considerations rather than direct criticisms, further contributing to the polite tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the interest in the topic and some good aspects of the paper, they point out several shortcomings and limitations. The reviewer mentions mathematical inaccuracies, lack of citations to relevant recent work, and experimental results that are 'good, but still not best-in-class'. The overall tone suggests that the paper has potential but needs significant improvements.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to point out issues, such as 'I find some of the mathematical details a little puzzling' and 'Please be more precise', rather than using harsh or dismissive language. The reviewer also acknowledges the potential value of the work and the good (though not exceptional) experimental results. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, professional tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the work's novelty, they express several unanswered questions and concerns about the paper's claims and methodology. The reviewer suggests that the paper would have been stronger with more experiments, indicating dissatisfaction with the current state of the work. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, using phrases like 'I would have liked to see' and 'I think the paper would have been stronger if' rather than making harsh criticisms. The reviewer also acknowledges their own potential lack of understanding in some areas, which shows respect for the authors' expertise. However, the review is not overly complimentary, keeping the politeness score from being higher.""]"
"['This paper first proposed a variant of experience replay to achieve better data efficiency in off-policy RL. The RACER algorithm was then developed, by modifying the approximated advantage function in the NAF algorithm. The proposed methods were finally tested on the MuJoCo environment to show the competitive performance.\n\nThis paper is in general well written. The ideas look interesting, even though they are mostly small modification of the previous works. The experiments also show the promise of the proposed methods. One of my concerns is regarding the generality of ReF-ER. I am wondering if it can be also applied to the Atari domain to boost the performance there, similar to the prioritized experience replay paper. I understand that the requirement of GPUs is beyond the hardware configuration in this work, but that would be an important contribution to the community. My other questions and comments are as follows.\n- Regarding the parametric form of f^w in Eq. (7), what are the definitions for L_+ and L_-? What are the benefits of introducing min and max there, compared with the form in Eq. (11), as used in NAF? Does it cause any problems during optimization?\n- The y axis in Figure 3 is for KL (\\pi || \\mu), while the text below used KL(\\mu || \\pi) and the description regarding the change of C also seems to be inaccurate. \n- In Figure 4, do you have any explanation why using PER leads to worse performance for NAF?\n- For the implementation, did you use any parallelization to speed up the algorithm?', 'This paper presents a method for forgetting and re-weighting experiences from a buffer during updates. It is well quantified experimentally and has some interesting tricks to improve performance in DDPG and other methods in continuous control which make use of a replay buffer. The authors also present another method “RACER” which makes use of this. \n\nI would like to see this published at some point, particularly because of the interesting results on DDPG. However, while it is interesting and useful, I do I have concerns both on the novelty and experimental comparisons in the current version. For example, RACER seems similar to ACER, yet doesn’t compare to it, making it difficult to understand what is its benefit other than its use of REFER. Moreover, the authors state that without the REFER part (with PER instead), RACER doesn’t work well at all, making it difficult to assess the RACER algorithm on its own. I would suggest if the authors claim that the contribution is the REFER algorithm they assess REFER in ACER on its own to make the main contribution stronger. \n\nRegarding novelty, I suggest that more of the paper can be spent situating the work in the broader scope of experience selection. There were several other methods that could have been compared against — for example (de Bruin et al., 2015) —which also presents a forgetting method similar to this one. While that work is cited, I don\'t believe it is sufficiently contrasted against this work.\n\nBelow I will examine various points/thoughts that came up.\n\n+ well experimented, appreciated the use of confidence intervals in the appendix and extensive ablation. However, I’d like to point out that the confidence intervals for some tasks spanned anything from 0 to the max, which did not inspire confidence. However, this may be a problem with the task and not the method, so not a significant problem \n+ clearly a lot of effort went into getting all these experiments and architecting the system which is well appreciated, great job there.\n+ DDPG results are promising and may indicate the problem with DDPG is its off-policy-ness. Nice results there.\n+ For the Re-Fer part, it was a bit unclear why it is 1/c_max < p_T <c_max rather than 0 < p_T < c_max? I suppose this is because you still want to update even if your current policy has not likelihood of that action? It would be nice to point to an explanation from that part of that text even if the intuition is in the appendix, otherwise it’s a bit unclear as to why this is chosen to be the acquisition function. \n+ Along these lines it would be good to see more theoretical examination of on-policiness, rather than a binary threshold of the importance weight. \n+ This paper seemed somewhat unfocused and packed with stuff, almost like two papers together which made things a bit difficult to follow as to what the main contribution is. I believe this detracted from both methods. For example, it was unclear what the benefit of using RACER was vs. say any other method which makes use of REFER. As the authors state, RACER without the ReFer part seems to not really work well at all, which makes me question this part of the contribution. It seems like a more interesting experiment would be to update importance weighted off-policy PG algorithms with the REFER part. This would hone the message which seems to be the main contribution of the paper.\n+ I find it surprising that the authors compared PPO against RACER rather than using ACER which seems like the nearest analogue to this algorithm or IMPALA which seems to have a similar parallelized architecture.\n+ More work could have been cited on experience selection selection, for example:\n\nIsele, D., & Cosgun, A. (2018). Selective Experience Replay for Lifelong Learning.\xa0arXiv preprint arXiv:1802.10269.\nPan, Yangchen, Muhammad Zaheer, Adam White, Andrew Patterson, and Martha White. ""Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains.""\xa0arXiv preprint arXiv:1806.04624\xa0(2018).\n\n(I am aware that these are relatively new works, but after looking at the posting timestamps, I believe the original versions were posted several months at least prior to this publication.)\n\n+ Along these lines I have concerns about the novelty since de Bruin 2015 even uses a similar off-policy metric for forgetting already. There are several differences here, but I’m not sure if they’re significantly novel for publication in its current state. \n\nTypos/Grammar Issues Found:\n\n“However, the information contained in consecutive steps is highly correlated, worsening the quality of the gradient estimate, and episodes can be composed of thousands of time step.” —> “However, the information contained in consecutive steps is highly correlated, worsening the quality of the gradient estimate, and episodes can be composed of thousands of time step(s).”', 'The authors introduce two new algorithms: remember and forget experience replay (ReF-ER), and an actor-critic architecture for continuous-action problems which is significantly more computationally efficient than previous approaches (RACER). ReF-ER manages the experience in the replay memory more directly and removes trajectories (episodes) that follow policies less related to the current parameterized policy (based on the importance weights). RACER\'s main contribution is provides a closed form approximation of the action values, enabling significant gains computationally. They provide several empirical studies in benchmark domains showing the competitiveness of their approach, and the provided more stability to various continuous control algorithms (NAF, PG, u-DDPG).\n\nOverall, I think it is a nicely written paper with a lot of empirical evidence of the usefulness of ReF-ER. I am quite interested in this algorithm specifically, as the active management of experience in the replay memory is an important step towards the ER acting as a proxy to short term memory. To my knowledge this algorithm is novel, and performs admirably. I\'m less clear of the main benefits of RACER over previous approaches, except for better computational complexity. This primarily comes from a lack of empirical comparison, and not much explanation as to why key competitors were excluded. The inclusion of RACER seems to muddy the message of the paper, and a much stronger and deeper look at ReF-ER would have made for a stronger submission.\n\nI have several questions for clarity and more comments below, but overall I think the paper is quite useful for the community and contains interesting insight into active management of transitions in an experience replay buffer.\n\nPros:\n------\n\nLots of empirical studies. And a lot of details to impart intuition of the new experience replay.\n\nInteresting take on experience replay.\n\nConvincing results in many simulation benchmark domains (even though the competitors are sparse).\n\nCons:\n------\n\nThere is some ambiguity and maybe some confusion about the difference between control and off-policy learning. While I agree you are learning off-policy for control (due to the experience replay buffer containing old data), the terms off-policy and on-policy seem overused here. Statements such as ""ER has become one of the mainstay techniques to improve the sample-efficiency of off-policy RL"" aren\'t entirely correct as the experience replay buffer is primarily used in deep reinforcement learning to improve sample-efficiency, not off-policy reinforcement learning as a whole.\n\nThe RACER algorithm seems to muddy up the message of the paper quite a bit. I would have much preferred an in-depth look at ReF-ER here, rather than the introduction of two algorithms. And I think your paper would have been stronger for it. That being said, the RACER algorithm seems incomplete. While it is an improvement over prior approachers (ACER) computationally, the need to use ReF-ER is concerning. I\'m also a bit confused why ACER isn\'t used as a competitor against RACER? Even if you aren\'t outperforming the other approach on all benchmarks, the improved computational complexity is still a worthwhile improvement.\n\nNo confidence bounds in the results, although these are somewhat shown in the appendix (without the competitors shown!!). I\'m curious at the significance of the different parameter settings.\n\nQuestions:\n----------\n\nI\'m curious as to how this is related to something like rejection sampling? Or other importance sampling approaches more directly? How does your method compare with using retrace or some other off-policy algorithms? I\'m unclear on the reasons why these types of comparisons aren\'t made empirically, could you clarify more directly?\n\nDoes your algorithm help with variance issues of other off-policy algorithms? Such as just using importance weights instead of retrace? How would it effect tree backup or just the usual importance sampling? It seems likely that this would help here, as you are limiting the amount of data with high importance weights, although this might also add bias.\n\nHave you removed the target network in your experiments? This detail is not obvious in the paper currently and when you introduce ReF-ER you seem to be leading to this, but never say explicitly.\n\nYou claim that ReF-ER ""reduces the sensitivity on the network architecture and training hyper-parameters."" I\'m unclear how you show this in the results with the current paper. You do some hyperparameter studies in the appendix, but don\'t compare against other algorithms here. Could you share a bit further how you are measuring the sensitivities of your algorithm against the competitors?\n\nDo you need to anneal the cmax? What are the effects if this is set to some constant?\n\nCould you expand on the results of HumanoidStandup-v2? Why do you believe your approach does significantly worse than the baselines here?\n\nFor DDPG, what happens if you change the bounds instead of removing them entirely? Also how does your method compare on a domain without unbounded actions?\n\nIt is unclear why RACER does not work with ER/PER. Do you have any intuition here? Could this be fixed through means other than ReF-ER? \n\n\nOther minor comments (not taken into consideration for the review):\n-------\n\nPseudo code: It is a bit unclear what algorithm 1 is supposed to be, I\'m assuming ReF-ER? \n\n\nBegin revision comments:\n-----\n\nGiven the revisions to this paper, I am more confident that it will be of interest to the community. The major contributions here I see is the removal of target networks given their approach. Given this I still have concerns on clarity and still am unhappy with the lack of confidence intervals in the main experimental section. I\'ve increased my score to 7 to reflect my increase in confidence.\n']","[60, -20, 60]","[80, 60, 80]","[""The sentiment score is 60 (positive) because the reviewer states that the paper is 'well written' and the ideas are 'interesting'. They also mention that the experiments 'show the promise of the proposed methods'. However, it's not extremely positive as they express some concerns and suggest improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms as questions or suggestions rather than direct criticisms. For example, they use phrases like 'I am wondering if...' and 'Do you have any explanation why...', which maintain a polite and constructive tone."", ""The sentiment score is slightly negative (-20) because while the reviewer sees potential in the paper and appreciates the experimental work, they express significant concerns about novelty and comparisons, suggesting major revisions are needed before publication. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive feedback. They use phrases like 'I would like to see this published at some point' and 'great job there' which contribute to the polite tone. However, the critique is direct and doesn't use overly deferential language, keeping the score from being higher."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the paper, calling it 'nicely written' with 'lots of empirical evidence' and 'interesting insight'. They state it is 'quite useful for the community'. However, they also raise some concerns and questions, preventing a higher score. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful tone. They use phrases like 'I think', 'I'm curious', and 'Could you clarify' when raising questions or concerns, rather than making blunt criticisms. They also highlight positives before discussing negatives. The reviewer maintains a professional, constructive tone throughout, even when pointing out weaknesses in the paper.""]"
"['The submission proposes a new method for agent design to learn about the behaviour of other fixed agents inhabiting the same environment. The method builds on imitation learning (behavioural cloning) to model the agent’s behaviour and reinforcement learning to learn a probing policy to more broadly explore different target agent behaviours. Overall, the approach falls into the field of intrinsic motivation / curiosity-like reward generation procedures but with respect to target agent behaviour instead of the agent’s environment. While learning to model the target agent’s inner state, the RL reward is generated based on the difference of the target agent’s inner state between consecutive time steps.\n\nThe approach is evaluated against a small set of baselines in various toy grid-world scenarios and a sorting task and overall performs commensurate or better than the investigated baselines. Given its limitation to small and low-dimensional environments, it cannot be said how well the approach will scale with respect to these factors and the resulting, more complex agent behaviours. It would be highly beneficial to evaluate these aspects. Furthermore, it would be beneficial to provide more information about the baselines; in particular the type of count-based exploration. For the generated figures, it would be beneficial to include standard deviation and mean over multiple runs to not only evaluate performance but also robustness. \n\nOverall, while the agent behaviour modelling focused on a type of inner state (based on past trajectories) provides benefits in the evaluated examples, it is unsure how well the approach scales to more complex domains based on strong similarity and simplicity of the tested toy scenarios (evaluation on sorting problems is an interesting step towards to address this shortcoming). One additional aspect pointing towards the necessity of further evaluation is the strong dependence of performance on the dimensionality of the latent, internal state (Fig.4). \n\nMinor issues:\n- Reward formulations for the baselines as part of the appendix.\n- Same scale for the y-axes across figures\n\n', ""This paper presents a method for interactive agent modeling that involves learning to model a demonstrator agent not only through passively viewing the demonstrator agent, but also through interactions from a learner agent that learns to probe the environment of the demonstrator agent so as to maximally change the behavior of the demonstrator agent. The approximated demonstrator agent is trained through standard imitation learning techniques and the learning or probing agent is trained using reinforcement learning. The mind of the demonstrating agent is modeled as a latent space representation from a neural net. This latent space representation is used as the reinforcement learning signal for the learner (probing) agent similar to the curiosity driven techniques where larger changes in the representation of mind are sought out since they should lead to larger differences in demonstrator agent behavior. The authors test this in several gridworld environments as well as a sorting task and show that their method achieves superior performance and generalizes better to unseen states and task variations compared to several baseline methods. \n\nGeneral comments, in no particular order:\n\n1. The authors should provide more details on how the hand-crafted demonstrator agents were made. I assume something similar to an a* algorithm was probably used for the passing task, but what about the maze navigation task? \n\n2. The demonstrated tasks are (gridworld and algorithmic) which are very simple RL taks with low-dimensional (non-visual) state-spaces.  It's unclear how this would scale to more complex tasks with higher-dimensional state spaces such as Atari, Starcraft II or if this would work with tasks with continuous state and action spaces such as mujoco. \n\n3. The core premise behind training the learner agent with RL is using a curiosity driven approach to train a probing policy to incite new demonstrator behaviors by maximizing the differences between the latent vectors of the behavior trackers at different time steps. Because the latent vector is modeled as a non-linear function, distances between latent vector representations do not necessarily correspond to similar distances between behavior policies (for example, KL distances between two policy distributions). Since this is for ILCR, I think the authors should have taken a deeper dive into examining those latent representations and potentially visualizing those distances and how they correspond to different policy behaviors. \n\n4. The biggest flaw that I see in this method is the practicality of it's use. This method relies on the ability to obtain or gain access to a demonstration agent to learn from. In very simple tasks, such as the one presented here, the authors were able to hard-code their own demonstration agent. However, in harder tasks, this will not be feasible. If you are able to obtain or code your own agent, then you've already solved the task and there is no need to do any sort of imitation learning in the first place.  In reality, for sufficiently difficult tasks, a human would be the demonstration agent (as is done in most robotics tasks). In practice, imitation learning from a human works well since the learning can be done offline (i.e., post-hoc after a set of demonstrations are collected from the human). However, this task requires the learning to be interactive and thus the demonstrator needs to be present during the learning.  Interactively learning from a human becomes a problem if the learning takes tens of thousands of episodes of training since a human cannot reasonably be expected to be present for that amount of time. Thus, the question is 1) how well will this method work with a human acting as the demonstrator? and 2) how can this method work if you are not able to have access to a demonstrator long periods of time (or even at all)?\n\n5. My previous comment relates mainly to the application of improved imitation learning. However, I do think this is still very useful in the context of multi-agent reinforcement learning for collaborative and competitive tasks (sections 4.6 and 4.7). I think this method demonstrates a method for improved collaborative and/or competitive performances given the fact that you already have a single agent with a learned policy. \n\nOverall, I think the paper presents a really nice idea of how to improve modeling of agents. essentially, a learner agent learns how to probe a demonstrator agent to provide more information about what's being demonstrated and prevent over-fitting to a set of fixed demonstrations.   This work sounds novel to me from a reinforcement learning perspective, however, I'm not well versed on theory of mind research. \n\n\n\n\n\n\n"", 'The authors consider the scenario of two agents, a demonstrator acting in an environment to achieve a goal, and a learner, which can also interact with the environment, but whose goal is to learn the demonstrator’s policy by carrying out actions eliciting strong changes in the demonstrator’s trajectory. The former is implemented as imitation learning, i.e. policy learning, the latter as curiosity driven RL.\n\nThe authors are encouraged to review some of the related literature on optimal teaching, which also has developed a rich set of approaches to agent modeling, e.g. the work by Patrick Shafto. It may also be relevant to think about the relationship to active learning in IRL. \n\nI am not sure whether I would be able to implement and reproduce the presented work on the basis of the current manuscript including the appendix. It would be very helpful for the community to be able to do so. E.g., details on the the training of the demonstrators, their reward functions, and the behavior tracker. Particularly the ""fusion"" module remains extremely unclear.\n\nOverall, this is a nice paper, despite the fact that the example domains and problems considered are engineered strongly to allow for the proposed algorithm to be useful. Particularly for the claim of generalization to different environments, the details are all in the engineering of the particular grid world tasks, how they relate to each other and the sate representation used for the demonstrator s_d. I am not sure why it was submitted to ICLR and not the Annual Meeting of the Cognitive Science Society, though. \n\nMinor points:\n“differs from this in two folds”\n“by generate queries”\n', '1) Summary\nThis paper proposes a method for learning an agent by interacting and probing an expert agents behavior. This method is composed of a policy that learns to imitate an expert’s action, and a policy that challenges the expert in order to get it to take multiple possible routes to solve a task. The two policies share a “behavior tracker” that models the expert’s behavior, and communicates it to both policies being learned. The probing policy is optimized using a curiosity-driven reward in order to get the expert take trajectories the probing policy has not seen before. In experiments, the authors perform experiments to show how the learned agent can generalize to unseen configurations in the corresponding environments in which the agents were trained, and also use the proposed technique in a sorting task in which the method generalizes to longer arrays to be sorted.\n\n\n2) Pros:\n+ Neat idea for exploring an experts behavior by changing the environment surrounding it (probing it).\n+ Cool experiments for applicability.\n+ Well written paper and easy to understand.\n\n3 Comments:\n- Equation 1 typo?:\nTo my understanding, in curiosity driven exploration, the exploration is driven based on how well the next state can be predicted by the agent. In equation 1, different time steps are being compared, m^t and m^{t-1}, but the comparison should be between the predicted time step t and real time step t. Can the authors clarify why different time steps are compared in the equation?\n\n- Baseline missing: Random actions from expert\nA simple baseline to compare against could be to simply force the expert to take a few random actions during its trajectory and let the imitator learn from these. Comparing against this baseline could serve as evidence that we need to actually learn the probing agent to acquire a more optimal policy.\n\n- Baseline missing: Simple RNN policies that communicate hidden states.\nAnother baseline could be to simply model the imitator and probing policies as RNNs and let them communicate with each other via the hidden states. While optimizing the curiosity reward the hidden states could be used as well. If successful, this baseline can show that we actually need to model the “behavior” with a separate network.\n\n- Ablation study for the importance of fusion:\nThe authors have a “fusion” layer within the imitator and probing policies. An ablation study showing that this layer is actually necessary is missing from the paper.\n\n- Generalizability argument\nThe authors claim that they show a single starting configuration for the agents during training, and different starting configurations during testing. While I agree with this to some extent, I also think this argument may not be fully right. When the probing agent is testing the expert, it is essentially showing the imitator many different configurations of the environment. It may not be that it changes in the first time step (for obvious reasons), but it is essentially showing it many configurations of the expert. A more drastic change of the environment could make for a stronger argument. \n\n\n4) Conclusion:\nOverall, I like the idea of having a policy that tries to figure out the general behavior of a demonstrator by probing it. Having said that, I feel this paper needs to improve in the aspects mentioned above. If the authors present more convincing evidence that successfully address the comments above, I am willing to increase my score.']","[20, 50, 50, 20]","[60, 75, 70, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the approach and its performance compared to baselines. However, they also express concerns about scalability and the need for further evaluation. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive comments. They use phrases like 'it would be beneficial' and 'overall' to soften their critiques. The review maintains a professional and objective tone, balancing positive aspects with areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper presents a 'really nice idea' and 'novel' work, while also raising several substantive concerns and critiques. The overall tone is balanced between praise and constructive criticism. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames critiques as suggestions (e.g. 'The authors should provide more details...'), and acknowledges the value of the work even while pointing out limitations. The reviewer maintains a professional and courteous tone, avoiding harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because while the reviewer describes it as a 'nice paper' and acknowledges its contributions, they also point out several limitations and areas for improvement. The review is not overwhelmingly positive, but it's more positive than neutral. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'The authors are encouraged to...' and 'It would be very helpful...' demonstrate a polite tone. The reviewer also balances criticism with positive remarks, which contributes to the polite tone. However, it's not extremely polite, as it does directly point out shortcomings in the work."", ""The sentiment score is slightly positive (20) because the reviewer expresses overall approval of the paper's idea and execution, noting it's 'neat', 'cool', and 'well written'. However, they also list several significant concerns and suggest the paper needs improvement, which tempers the positivity. The politeness score is fairly high (70) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'Can the authors clarify' and 'I feel this paper needs to improve' rather than making blunt criticisms. The conclusion offers encouragement for improvement rather than outright rejection, further demonstrating politeness.""]"
"[""===============================\nI have read the authors' response and other reviewers' comments carefully. Thank you for taking great efforts to improve the paper, including providing additional results on human evaluation. (Btw, Table 1 and Table 2 are also much nicer now.)\n\nHowever, from the reviews it seems that all the reviewers agree that the novelty of this paper is limited, and the contribution is incremental.  I understand that this paper is the first and only work using adversarial framework for persona multi-turn conversation models. However, from the modeling perspective, I still think the novelty is limited.\n\nAs a summary, I have updated the score from 4 to 5 to reflect the efforts that the authors have been taken to improve the paper. However, due to reasons above, I still prefer a rejection recommendation. \n\n===============================\n\nContributions:\n\nThe main contribution of this paper is the proposed phredGAN, which is a persona-based GAN framework for multi-turn dialogue modeling. Specifically, a persona-based HRED generator is developed, with two different kinds of discriminator design. Experiments are conducted on both the UDC and the TV series transcript datasets.  \n\nWeaknesses:\n\n(1) Novelty: I would say the novelty of this paper is rather limited. This paper heavily rely on the previous hredGAN work (Olabiyi et al., 2018), and extends it by injecting attributes into the system, borrowing ideas from the persona-based Seq2seq model (Li et al, 2016b). \n\nphredGAN_a is a straightforward extension of hredGAN, while phredGAN_d further introduces a collaborative discriminator that tries to predict the attribute that generated the input utterance. However, in summary, I think this paper is not novel enough. \n\n(2) Presentation: The paper is generally easy to follow and understand. However, I would say the paper is poorly written, and needs further polishing. For example, Table 1 & 2 are pretty ugly. \n\n(3) Evaluation: Generally, I think the experiments are not convincing and also not well-executed, with detailed comments listed below. \n\nQuestions:\n\n(1) In phredGAN_a, as shown in Eqn. (4), the attribute is used as input of the discriminator, while in phredGAN_d, as shown in Eqn. (5) & (6), the attribute is used as the target of the discriminator. My question is: why not use the attribute as both input & output? That is, why not combine (4) & (6), instead of using (5) & (6)? Please clarify this. \n\n(2) In experiments, Section 3.1, the authors mention that the generator and the discriminator use a shared encoder. However, the generator and discriminator has a different role. Since the encoder is shared, then: in one step, we update the encoder to minimize the GAN objective, in the alternative step, we update the encoder again to maximize the GAN objective. So, how to deal with this conflicting role of encoder during the training? Please clarify this. \n\n(3) From Table 2, it seems that it is difficult to see that phredGAN is better than hredGAN. Can you provide some explanations here?\n\n(4) In Table 4, if the responses generated by hredGAN can be provided, that would be better to demonstrate the advantage of phredGAN. How does phredGAN compare with hredGAN qualitatively?\n\n(5) From Table 1 & 2, it seems to me there is no metric that is specifically designed to evaluate whether the model captures the attribute information. Is there a way to quantitatively evaluate this? For example, pretrain an attribute classifier, or use the collaborative discriminator in the phredGAN_d model to measure how the generated response reflect the attribute. If we can observe the performance of phredGAN is better than that of hredGAN, that would be helpful for the paper.  \n\n(6) Since the task is challenging, and the automatic metrics designed for this task is not perfect, like other papers, I think human evaluation is essential and desired for this task. However, such human evaluation is lacked in this paper.\n  "", 'This paper proposes an extension to hredGAN, which is an adversarial framework for multi-turn dialogue model, to simultaneously learns a set of attribute embeddings that represents the persona of each speaker and generate persona-based responses. The generator of the proposed system phredGAN is conditioned on both the history utterances and the speakers’ persona by concatenating the utterance encoding with attribute embeddings. For discriminator, the authors explore two versions: 1) phredGAN_a takes attributes as inputs; 2) phredGAN_d adds a dual discriminator that predicts the attribute(s) for each utterance. \n\n\nStrength: 1) to the best of my knowledge, adding persona information to an adversarial multi-turn dialogue model is novel; 2) the authors explore two different approaches to build the discriminator(s) and the idea of adding a second discriminator that predicts the attributes seems interesting.    \n\n\nWeakness:\n\n1) Novelty: The idea of learning speaker-specific attribute embeddings is very similar to the Speaker Model proposed by Li et al.(2016) http://www.aclweb.org/anthology/P16-1094 and the proposed system only makes minor changes to hredGAN https://arxiv.org/abs/1805.11752.  \n\n\n2) Presentation: \nThe writing of this paper is a little hard to follow, for example, it presents the two discriminators after the objective function (Equation 2) and does not explain the intuition behind each model. In Equation 2, the objective function, why training the discriminator to minimize the attributes prediction probability？ Simply saying the attribute prediction loss is collaborative is not clear enough. Or is the min for the second term a typo? \n\n\n3) Model:\nThe idea of adding a discriminator that predicts the attributes seems interesting. However the loss is not adversarial for the second discriminator (Equation 6), you should not indicate L_att is GAN in your notation. I’m also not convinced that this should be collaborative. Despite that the “discriminator” is trying to predict the correct attribute id, the input of the two terms in Equation 6 is different, one comes from the true data, the other comes from the generator. Shouldn’t the discriminator try to differentiate these two cases? Otherwise, it’s not a discriminator (also raise the question for Equation 2, why argmin min(L_att)).\n\n\n4) Evaluation：\nThe evaluation is not strong enough to demonstrate the benefit of the proposed model. \n\na. It only compares against one previous work that takes speaker identity into account on one dataset. Despite that the authors apply several different metrics to evaluate the proposed model, they only compare with previous models by Li et al. (2016) on perplexity and BLEU. \n\nb. The perplexity scores of the proposed models are worse than SAM by Li et al. (2016). The authors explain this by stating that the entropy for a multi-turn model is supposed to be higher than the single-turn model. It’s better to provide a more rigorous analysis. For a fair comparison, they could also train the proposed model using only one-turn history, which should be identical to Li et al.’s setting (How many turns history are you using?). The improvements of the BLEU score might also be the consequence of substituting the past generated sequence in the generator with ground truth (since the model uses the same training algorithm as hredGAN https://arxiv.org/abs/1805.11752). It’s unclear if this is the cause unless the authors provide the comparison among SAM, hredGAN, and phredGAN. \n\nc. Table 2 compares the non-persona hredGAN with phredGAN on UDC, but the authors do not provide a comparison between these two on the TV dataset in Table 1. \n\nd. The comparison between phredGAN_a and phredGAN_d is inconsistent for the two datasets (Table 1 and Table 2).', ""This paper uses the idea from 'A Persona-Based Neural Conversation Model' by Li et al and incrementally applies it to the 'Multi-turn Dialogue Response Generation in an Adversarial Learning Framework' work-in-progress by Olabiyi et al. The paper by Olabiyi uses the idea of adversarial training to the HRED work by Xing et al (Hierarchical Recurrent Attention Network for Response Generation). The paper shows very promising results for controlling the response generation based on input attributes with adversarial training. Compared to the persona based model, this work seems to outperform that model significantly as reported in Table 1 (in terms of Perplexity/Bleu). It would have been great to see the quantitative comparison in terms of other metrics (if the authors could try to reproduce their results). There are other interesting ways to incorporate attribute information into the dialogue model such as reported in the work of Lee et al (SCALABLE SENTIMENT FOR SEQUENCE-TO-SEQUENCE CHATBOT RESPONSE WITH PERFORMANCE ANALYSIS) - since this paper is primarily about personalization of responses - a comparison to some of the methods used in Lee's work would have been very relevant and made the paper much more convincing in terms of core contributions. The model and architecture is pretty convincing but the paper lacks more in-depth analysis, comparison and evaluation of the model.""]","[-50, -50, 50]","[50, 50, 70]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and contribution, ultimately recommending rejection despite some improvements. They acknowledge the authors' efforts but still find the work incremental. The politeness score is 50 because the reviewer uses polite language throughout, thanking the authors for their efforts and providing detailed, constructive feedback. They maintain a professional tone even while expressing criticism. The reviewer balances negative feedback with positive acknowledgments, uses respectful phrasing like 'I understand that...' and 'I would say...', and poses questions rather than making blunt statements."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper, they primarily focus on weaknesses and areas for improvement. The review points out several significant issues with the paper's novelty, presentation, model, and evaluation. However, it's not entirely negative as it does recognize some positive aspects.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'to the best of my knowledge' and 'it's better to provide' which soften criticism. The reviewer also balances critique with recognition of strengths. However, the language is not overly polite or deferential, maintaining a neutral, academic tone overall.\n\nThe review is structured and detailed, providing specific points for improvement without using harsh or dismissive language. This approach is constructive and polite, while still clearly communicating the paper's shortcomings."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper shows 'very promising results' and outperforms previous models. However, they also point out areas for improvement, such as lacking in-depth analysis and comparisons. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or negative phrasing. They use phrases like 'It would have been great to see' and 'a comparison... would have been very relevant' instead of more critical language.""]"
"['This paper proposes an augmentation of traditional neural network learning to allow for the inference of causal effects. Specifically, they modify the data sampling procedure of SGD during training to use matched samples that are paired via propensity score matching. Experimental results on a number of dataset show that the proposed methodology is comparable to alternative machine learning based causal inference methods. \n\nOverall, I think this is a nice idea. I have two main concerns: \n(1) The use of small batches for matching. Figure 2 does alleviate this concern to an extent, but there is a large literature in statistics and the social sciences on the effect that the quality of matches have on the final causal estimand. It is quite possible that this particular dataset is more amenable to PSM. It is also worth noting that while there is bias reduction shown in figure 2, it is not overwhelming. \n\n(2) The use of propensity scores for matching. One of the insights from the heterogeneous treatment effect literature is that it is not difficult to find cases where the propensity of treatment is identical for two sets of covariates that otherwise do not obey any real balance. This can lead to large biases in the final estimate. Given that PSM is still a relatively widely used practice, I don’t think that its use is a ground for rejection in itself, but given that neural networks are often used to estimate complex causal relations when they are used and this paper is interested in individual treatment effects it is worth noting. \n\nI found the experimental setup to do a very good job in covering large portions of the behavior of the algorithm. The final results are a little underwhelming–the proposed method does not appear to clearly define a new state of the art for the tasks it is applied to–but it is often competitive and the paper presents an interesting idea.\n', ""Summary:\nThis paper proposed to extend TARNET (Shalit et al. 2017), a representation learning approach for counterfactual inference, in the following ways.\n\nFirst, to extend TARNET to multiple treatment setting, k head networks (instead of 2) were constructed following the shared MLP layers, where each head network modeled the outcome of one treatment. This extension seemed quite straightforward.\n\nSecond, during training, for every sample in a minibatch, find its nearest neighbors from all other treatments and add them to the minibatch. The distance was measured by the propensity score, which was defined the probability of a sample being assigned to a treatment group and could be learned by a classification model (such as support vector machine used in this work). Therefore, 1) the augmented minibatch would contain the same number of samples for each treatment group; 2) different treatment group were balanced.\n\nThird, a model selection strategy was proposed by estimating the PEHE using nearest neighbor search.\n\nComments:\nThis paper is well motivated. The key challenges in counterfactual inference is how to adjust for the bias in treatment assignment and the associated discrepancies in the distribution of different treatment groups. \n\nThe main idea of this paper, i.e., augmenting the minibatch through propensity score matching for each sample, is well explained in Section 3. However, it could be better if the introduction of model architecture (in Appendix F) was presented in the method section.\n\nDid the author need to train (k choose 2) SVMs to compute the propensity scores for samples from k treatment groups?\n\nWhen comparing different approaches, as were shown in Table 3, 4 and Figure 3,4, did the author run any statistical test, such as t-test, to confirm the difference between those distributions were significant? The standard deviations of those errors seemed quite large so the difference could be non-significant.\n\nCould the author provide more explanations on why the proposed approach, i.e., minibatch augmentation using propensity score matching, can outperform the TARNET? In TARNET, each sample it only used to update the head network corresponding to the sample's treatment assignment, why would balancing samples in the minibatch can improve the estimation of treatment effect?"", '========= Summary =========\n\nThe authors propose a novel method for counterfactual inference (i.e. individual/heterogeneous treatment effect, as well as average treatment effect) with neural networks. They perform propensity score matching within each minibatch in order to match the covariate distributions during training, which leads to a doubly robust model.\n\nPM is evaluated on several standard semi-synthetic datasets (jobs, IHDP, TCGA) and PM shows state-of-the-art performance on some datasets, and overall looks quite promising. \n\n======= Comments =======\n\nThe paper is well-written, presents a novel method of some interest to the community, and shows quite good performance across a range of relevant benchmarks.\n\nI have one major issue with this work: I don\'t see why propensity-score matching *within* a minibatch should provide a substantial improvement over propensity-score matching across the dataset (Ho et al 2011). I find the cursory explanation given (""it ensures that every gradient step is done in a way that is approximately unbiased"") unconvincing, since (a) proper SGD training should be robust to per-batch biases during training (the expected loss is identical for both methods, correct?), and (b) biases should go away in the limit of large batch sizes. If indeed SGD required unbiased *minibatches* then standard minibatch SGD wouldn\'t work at all.\n\nLooking at the experimental details in the appendix, it appears that the MatchIt package was used to do PSM, rather than a careful comparison under the same conditions. Are the exact matching procedure, PS estimator model, choosing ""one of 6 closest  matches by propensity score"", batch size, etc. the same between your PM implementation and MatchIt? I\'d be very curious to see the results of a controlled comparison between Alg S1 and S2 under the same conditions (i.e. run your PM implementation on the whole dataset), and perhaps even some more clever experiments illustrating why matching within a minibatch is important. \n\nAnother hypothesis for why PM is better than PSM is that the matching distribution for PM changes at each epoch (at least due to the randomization among the 6 closest matches). Could it be that the advantage of PM is that it actually provides a randomized rather than constant distribution of matched points?\n\nCan the authors provide more motivation for why PM should outperform PSM? Or some more careful comparison of these methods isolating the benefits of PM? I think a convincing justification and comparison here could change my opinion, as I like the paper otherwise. Thanks!\n\nDetailed Comments:\n\n- There is insufficient explanation of the PM method in the main text. The method is only mentioned in a single sentence buried in the middle of a long paragraph ""In PM, we match every sample within a minibatch..."". This should be made more clear, e.g. by moving Algorithm S1 to the main text.\n- The discussion on Model Selection and the argument for nearest-neighbor PEHE is clever and well-supported by the experiments.\n- In Table 3 and 4, it\'s not clear which numbers are reported by the original authors and which were replicated by the authors.']","[20, 50, 20]","[60, 75, 70]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'a nice idea' and praises the experimental setup. However, they also express two main concerns and note that the final results are 'a little underwhelming'. This mix of positive and negative comments results in a mildly positive overall sentiment. The politeness score is moderately high (60) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting concerns. They use phrases like 'I think' and 'it is worth noting' which soften their criticisms. The reviewer also ends on a positive note, calling the paper 'an interesting idea', which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer states the paper is 'well motivated' and the main idea is 'well explained', indicating approval. However, they also raise several questions and suggestions for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions (e.g. 'Could the author provide more explanations...', 'it could be better if...') rather than direct criticisms. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to peer review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written, presents a novel method of interest, and shows good performance. However, they express a major concern about the method's justification, which tempers the overall positive sentiment. The politeness score is fairly high (70) as the reviewer uses respectful language throughout, asks questions politely, and offers constructive criticism. They use phrases like 'I'd be very curious to see' and 'Can the authors provide more motivation' which maintain a collegial tone. The reviewer also expresses willingness to change their opinion with more justification, showing openness and respect for the authors' work.""]"
"['Summary. The paper considers the robustness of neural nets against adversarial attacks. More precisely, the authors experimentally investigate the robustness of ensembles of neural nets. They empirically show that adversarially trained ensembles of 2 neural nets are more robust than ensembles of 2 adversarially trained neural nets.\n\nPros.\n* Robustness of neural nets is a challenging problem of interest for ICLR\n* The paper is easy to read\n* Experimental results compare different algorithms for 2 neural nets\n\nCons.\n* The study is experimental\n* It is limited to gradient-based attacks\n* It is limited to ensembles of size 2\n* The Ensemble2Adv is a single NN model and not an ensemble model. \n\nEvaluation.\nThe problem is significant and the use of ensemble methods for robustness against adversarial attacks is a promising line of research. The experimental study in this paper opens new lines of research in this direction. But, in my opinion, the paper is not ready for publication at ICLR. Detailed comments follow but the study is limited to k=2; the main finding is limited to the comparison between bagging two adversarially trained neural nets (SeparateEnsemble2Adv) and learning adversarially the average of two neural nets (Ensemble2adv). In my opinion, Ensemble2adv is a single model of double size and not an ensemble model thus somehow contradicting the main claim of the paper.\n\nDetailed comments.\n* Introduction, end of §2, it is said that non-gradient based attacks are still effective. But in the sequel you only consider gradient-based attacks and never discussed this question.\n* Introduction, contributions, it should be made clear at the beginning of the paper that you will consider ensembles of size 2 and only gradient-based attacks.\n* Section 2. The momentum-based attack should be cited and could be considered. ""Boosting adversarial attacks with momentum, Dong et al, CVPR18""\n* Section 3, §2, the discussion on ensemble methods is unprecise. Ensemble methods have different objectives. For instance, Bagging-like methods  aim at reducing the generalization error while others as Boosting aim at augmenting the capacity of individual models.\n* Section 3. Here is my main concern on this paper. The classical method would be bagging of neural nets with different initializations. The neural nets could be adversarially trained. This would lead to the so-called SeparateEnsemble2Adv. Here, the authors consider another method. Their method can be viewed as k(=2) copies of the same neural network with different initializations and an additional layer computing the average of the k(=2) outputs. Then adversarially learn the obtained model which leads to the so-called Ensemble2Adv algorithm. This algorithm is not an ensemble method as such. In my opinion for k=2, it is equivalent to doubling the size of a neural net, adding averaging of the outputs, and adversarially training the obtained neural net.\n* Note recent advances in ensemble NNs with papers such as Averaging weights leads to wider optima ..., Izmailov et al, UAI18; Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs, Garipov et al, arXiv:1802.10026\n* Section 4.1. Here comes the limitation k=2. The case k=4 is considered in table 1 but is not discussed elsewhere in the paper.\n* Section 4.1. I am not convinced by DoubleAdv. It is one way of doubling the size of a neural net but I am not convinced that this is the more efficient. As said before, in my opinion, Ensemble2Adv is another way for doubling the size. And many more should exist.\n* Section 5. In my opinion, the main comparisons should concern SeparateEnsemble2Adv and Ensemble2Adv. Also other methods doubling the size should be considered. \n* Section 5. For k greater than 2, SeparateEnsemblekAdv should be the better method because the adversarial learning phase could be easily parallelized.\n* I am not convinced by the discussion in Section 6.\n* Typos. and -> an l-13, p5; IFGSM5, l-19 p6; then l-6 p7; to due l-6 p9\n* Biblio. Please give complete references\n', 'The paper proposes to train an ensemble of models jointly, where the coupling lies in that at each time step, a set of examples that are adversarial for the ensemble itself is incorporated in the learning.\n\nThe experiments are thorough and compare multiple types of attacks, although they are all based on gradients (while the paper does mention recent attacks that do not rely on gradients so much). The results are rather convincing and show a clear difference between the proposed method and independently training the models of the ensemble (even if each one is training with examples adversarial to itself).\n\nThe paper is clear and well-written.\n\nPros:\n- The superior performance of the proposed method\n- The method is simple and thus could have a practical impact\n- Clear and thorough analysis\n\nCons:\n- Only gradient based attacks (which are somewhat criticized in the introduction) \n- Novelty may be a bit limited: this is a rather small variation on existing stuff (but it works rather well)\n\nRemarks:\n- Fig 2c could use the same line styles and order as Fig 2a/2b\n- ""a gap 7 accuracy""?', 'This paper presents a new adversarial training defense whereby an ensemble of models is trained against both benign and adversarial examples. The authors demonstrate on the CIFAR-10 dataset that the ensemble has improved robustness against a wide variety of white-box and transfer-based black-box attacks compared to other adversarial training techniques. The results appear significant but would greatly benefit from more thorough experiments.\n\nPros:\n- Conceptually simple and intuitive.\n- Thorough baselines and attack methods.\n\nCons:\n- Limited novelty.\n- Needs more experimental validation against other datasets (e.g. ImageNet) and models (e.g. Inception-v3).\n- Table 1 shows that the clean accuracy of adversarially trained models is significantly worse, which suggests that some aspect of training was done improperly.\n\n-----------------------------\n\nI would like to clarify regarding the listed cons:\n\n- Limited novelty: Adversarial training has been well-established as a viable defense against adversarial examples, as well as training a single model against an ensemble of adversarial examples crafted on different networks (Tramer et al. https://arxiv.org/pdf/1705.07204.pdf). While this work is sufficiently different from prior methods, its novelty is insignificant.\n- More experimental validation: Due to the limited novelty, it is crucial that the authors validate their result more thoroughly to eliminate any doubt on applicability, especially against more challenging datasets such as ImageNet. While the experiments on CIFAR-10 are certainly sufficient, it is dangerous, particularly in works on defenses against adversarial examples, to restrict only to a relatively simple dataset.\n- Tramer et al. (https://arxiv.org/pdf/1705.07204.pdf) publicly released their ensemble adversarially trained Inception-v3 model that has the same top-1 and top-5 clean accuracy on ImageNet as the base model. This serves as evidence that it is certainly possible to adversarially train a model without compromise to clean accuracy, especially on a simpler dataset such as CIFAR-10.']","[-30, 70, -20]","[50, 80, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), they ultimately conclude that 'the paper is not ready for publication at ICLR'. They express several concerns and limitations of the study, which outweigh the positive elements. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively (e.g., 'in my opinion', 'Detailed comments'). They provide specific suggestions for improvement, which is helpful and courteous. However, the score isn't higher as the review maintains a professional tone rather than being overtly friendly or complimentary."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They highlight the 'thorough' experiments, 'convincing' results, and describe the paper as 'clear and well-written'. The pros mentioned outweigh the cons, indicating a favorable sentiment. However, it's not 100 as there are some criticisms (e.g., limited novelty, focus on gradient-based attacks).\n\nThe politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They balance positive feedback with constructive criticism, and their remarks are presented in a neutral, objective manner. The use of phrases like 'rather convincing' and 'could have a practical impact' show a considerate approach to feedback. The score isn't 100 as the review maintains a professional distance rather than being overtly courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also highlight significant limitations ('Cons') and areas for improvement. The overall tone suggests that the paper has potential but requires substantial additional work. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'I would like to clarify' and provide detailed explanations for their concerns, which demonstrates a polite and helpful approach to the review process.""]"
"['This paper has two main contributions: \n 1) it extends normalizing flows to discrete settings (exploiting relaxation ideas from Jang et al and Maddison et al).\n 2) it presents an approximate fixed-point update rule for autoregressive time-series that can exploit GPU parallelism.\n\nOverall, I think the work is solid. Contribution 1 isn\'t very novel, but is useful and the authors did a good job there.\n\nContribution 2 seems more interesting, but is not as well studied. When is the fixed point update expected to work? \nWhat assumptions does it imply? How does performance improve with the number of steps K? Does simulating for a finite steps emphasize the effect of early z\'s?\nI\'m a bit surprised that the authors did not attempt to study this part of their algorithm in isolation. They make a claims \nbut never look at this in detail.\n\nThat said, the authors do a good job showing the method ""works"", and figures 3F and 3G are particularly nice. \nIn 3G, is ""autoregressive"" supposed to converge to flow eventually?\nWhy don\'t the authors also use time as the x-axis in figure 2F (like 3F)?\n\nMy biggest complaint about the paper is the writing, which does not introduce and present ideas in a clear sequential \nmanner, making the paper hard to read. I realize ELBO is standard, but at least some description of the setup in equation 1 \nis warranted. What is x,z,\\theta etc? Any paper should aim to be minimally self-contained. This continues throughout the paper, which does not really attempt to place the contribution in the larger literature, but rather just reports what the authors did and observed.\n\nSome more examples:\n\nPage 3: ""so we need to evaluate \\hat{Q}"". This isn\'t defined. The authors should mention what \\hat{Q} and \\bar{Q} are.\nSimilarly for P. After a couple of passes through the paragraph, I could figure what the authors meant, but they \nshould introduce the notation they use.\n\nIn section 2, while defining their model, they do not mention the dimension of z_t until after equation 8\n(and even here, it has to be inferred).\n\nWhat is x in 6b? What is the generative model they are doing inference on?\n\nSection 2.2: it\'s not clear to me how convergence is defined even in the discrete case. I feel this discussion \nalso really belongs to section 2.1\n\nWhile I can understand what section 2.3 is trying to say, I could not really follow the notation.\n\nI could not understand figure 1E and the associated sentence in section 2.4\n\nWhat is the take-away of section 2.3 and 2.4? The authors seem to imply working with the discrete model is \nbetter in their experiments. Maybe forewarn the reader here?\n\nThe experiments are a bit hard to follow. It is inspired by a neuroscience application, but uses only simulated data. This is fine, but rather than describe the setup in mathematical/time-series language, it is complicated the with neuroscience jargon. As such, it feels disjointed and disconnected from the rest of the paper. I already complained that earlier sections do not describe the modeling setup, this is one way the paper could be improved.\n\nIn figure 2A and 3A, are the s\'s actually z\'s?', ""Normalizing flows provide a way for variational posteriors to go beyond the mean-field assumption and introduce correlations in the posterior for latent variables. Typically, normalizing flows are only defined for continuous distributions, and the authors tackle the issue of creating flexible variational posteriors for discrete latent models. They posit a general autoregressive posterior family for discrete variables or their continuous relaxations. In order to perform variational inference with reparameterization gradients, one needs to have a sample from their variational family and be able to evaluate the density at the sample. The obvious way to sample from this autoregressive variational family is O(T) for T the number of autoregressive time-steps. Instead, they propose a method based off fixed point iterations to compute logits in parallel based off the results of previous iterations to generate an approximate sample. Moreover, they can interpret each iteration as a volume-preserving flow, so they don't have to add any terms to the density. They also use a continuous relaxation of Bernoulli random variables so they can back-propagate through a recognition network. They use their method on synthetic calcium spike data, and show that the correlated posterior is better-suited to handle uncertainty. \n\nThis is certainly original work, and it presents it in a general way. The authors' formulation of the probabilistic model and variational family in equations 6a-7b can be extended to any autoregressive family. As the authors mention, they also do not need to work only with continuous relaxations of Bernoulli random variables, as they can extend it to categorical random variables using something like the Gumbel-Softmax/Concrete distributions.   Although the idea behind parallelizing updates is not inherently elaborate, the authors provide an interesting interpretation as a normalizing flow. \n\nMy main criticism of the paper is the experiments section. The experiments are only performed on synthetic data sets. How do the methods scale to larger data sets? The authors state that iterations of the fixed point procedure converge rapidly in practice, but it seems like it's only been evaluated on these synthetic data sets. It seems like performing K fixed point iterations fixes the dependencies to be in a window of size K, so this may perform worse in practice for models that have long temporal dependencies (or for non-temporal latent discrete random variables where the ordering is not important). \n\nThe experiments also do not seem to evaluate any held-out metrics. The experiments would be stronger by e.g. approximating the marginal held-out loss (perhaps using IWAE or otherwise), since it seems almost guaranteed that more flexible variational families should achieve a tighter bound on the training set (it's possible that there were actually held-out metrics but I missed them, in which case please let me know).\n\nAnother criticism of the paper is with the clarity. The authors sometime use notation before/without defining it. For example, T is used without definition it at the beginning of page 2 and N is used without definition at the beginning of section 2.1. It makes it difficult to have intuition for the math as a result of not knowing the definitions. Even things like explicitly stating that k is a timestep index before equation 9 would be helpful. \n\nMore minor notes:\n\n-I got a lot out of Figure 1A. For Figure 1B-E, what is beta? Is there intuition for how these results change as a function of beta?\n\n-When you say Equation 8 in section 2.2 I believe you mean equation 7b.\n\nOverall, there has not been much (if any) work for correlated posterior families for discrete latent variable models, and the authors have provided a promising first step. The next step would be seeing more experimental results for a larger variety of models.\n\nPROS\n-Idea is very interesting and novel, with a nice connection to normalizing flows \n-Underexplored area of research, promising first steps.\n\nCONS\n-Experiments should be more thorough\n-Lack of clarity made it hard to understand at certain points"", 'This paper uses an autoregressive filtering variational approximation for parameter estimation in discrete dynamical systems. One issue that crops up with this *particular choice* of variational distribution is that (a) inference proceeds sequentially (by definition) and (b) this does not make use of parallelism in modern hardware. To mitigate this, the paper proposes using fixed point iterations. After the first iteration, the approximate posterior for each latent variable corresponds to a random draw from a logistic distribution. Each subsequent application of the fixed point iteration modifies the posterior distribution by incorporating information from the previous latent state. After T applications of the fixed point equation, the procedure approximates an auto-regressive variational posterior distribution. Its possible I\'ve misunderstood the point being made in Sections 2.2 - 2.4, but the paper points out that the choice of iterations ""looks like"" a normalizing flow (with Jacobian 1).\n\nThe method for inference is evaluated on two synthetic datasets. The paper finds that the flow-based approach takes less time than using the full autoregressive variational posterior and learns less bias weights than a fully factorized approach.\n\nOverall:\nI think the idea of approximating posterior distributions via fixed point iterations as presented here is interesting since it presents a reasonable way to trade off between expressivity and computational complexity. However, in this manuscript the idea is insufficiently explored and not presented clearly.\n\nClarity -- methodology:\nThe paper is poorly written. It is formatted in an awkward manner making it quite difficult to understand what model was considered here. For example, the *first equation* in the paper is a variational lower-bound. The equation is present in the absence of describing what generative model is considered in this work (or even stating what P and Q are, and how they factorize). Unless I\'m missing something, as long as the *final step* of every fixed-point iteration (at each point in time) realizes a valid prediction of the mean parameter of continuous distribution relaxed to a discrete one, the proposed method is still valid for approximate inference. Why then is the relationship to normalizing flows important to highlight or emphasize?\n\nClarity -- experimental results:\nThe baselines in the experimental section are not described. Out of the blue, one of the method describes ""supervised training"" (up until that point, I was under the impression that the model was entirely unsupervised). Where does the supervision comes from? The IWAE objective is mentioned without justification in the experimental section whereas the methodology section describes learning with the lower-bound.\n\nLarger time series problems:\nA reason, motivated by the paper, for considering this method was the potential to parallelize computation of the approximate posterior distribution on GPUs. Yet, the evaluation was conducted on significantly smaller problems. The paper would be strengthened by an evaluation on density estimation on larger, higher dimensional datasets [e.g. the benchmark polyphonic music dataset -- http://www-etud.iro.umontreal.ca/~boulanni/icml2012].\n\n*Why* does convergence happen quickly?\nAn unanswered issue is that a central claim of the paper hinges on an empirical observation -- namely that the fixed point iterations converge ""quickly"". In the absence of theory on *why* and how quickly we might expect convergence and what convergence depends on, I think there is a need for further experimentation to understand and characterize situations when we can expect rapid convergence. Intuitively, the number of fixed point iterations controls how far in the past the posterior distribution for the latent variable at timestep t depends. Rapid convergence, as observed here, could happen because the experiments only consider simplistic generative models in which the true posterior distribution is well approximated using a small temporal context from the past. ']","[20, 50, -50]","[50, 75, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the work is 'solid' and praises certain aspects ('good job', 'particularly nice'). However, they also express several criticisms and concerns, which temper the overall positivity. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'I'm a bit surprised' rather than harsh language. They offer constructive criticism and suggestions for improvement rather than outright dismissal. The reviewer balances positive comments with areas for improvement, which is a polite approach to peer review. However, the directness of some criticisms ('My biggest complaint', 'hard to read') prevents the score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the originality and novelty of the work, calling it a 'promising first step' and praising its 'interesting and novel' idea. However, they also express significant criticisms about the experiments and clarity, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as suggestions for improvement rather than harsh criticisms. They also highlight the positive aspects of the work before delving into their concerns. The use of phrases like 'My main criticism' and 'More minor notes' helps to soften the critique. The reviewer maintains a professional and courteous tone throughout, even when pointing out areas for improvement."", ""The sentiment score is -50 because while the reviewer finds the idea interesting, they express significant concerns about the paper's clarity, methodology, and experimental results. The review starts with some positive aspects but quickly moves to criticisms, stating the paper is 'poorly written' and 'insufficiently explored'. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'Unless I'm missing something', which soften the criticisms. They also acknowledge the potential of the idea. However, the directness of some criticisms (e.g., 'The paper is poorly written') prevents a higher politeness score.""]"
"['The paper presents a new Generative Adversarial Network (GAN) for learning a  \ntarget distribution that is defined as the difference between two other \ndistributions. Applications in semi-supervised learning and adversarial training \nare considered in the experimental evaluation and results are presented in \ncomputer vision tasks. \n\nThe paper is not very well written and can be hard to follow. One very important \nissue for me was motivation for defining the target distribution as a difference \nbetween two other distributions. I am not familiar with this area, but reading \nthrough the introduction it was never clear to me why this is a useful scenario, \nin practice. Furthermore, some statements in the introduction felt quite \narbitrary. For example, the authors state that PixelCNN ""does not have a latent \nrepresentation"" in a manner that makes it sound as if that is a bad thing. If \nindeed it is, then why so? It would be very helpful to motivate the setting more \nand to provide a couple of examples of where this method would be useful, in the \nintroduction. Also, regarding the MNIST example in the end of page 1, what is \nthe ""universal set""? This paragraph also felt a bit arbitrary and unclear.\n\nSome comments about the rest of the paper:\n  - The theoretical results of section 3 are just stated/listed, but are not \n    connected to algorithm 1. Please connect them to the different parts of the \n    algorithm and state in a couple sentences what they imply for the algorithm.\n  - Right after theorem 1, which assumption are you referring to when you say \n    ""the assumption in Theorem 1""?\n  - The reformulation of section 3.1 is never justified. What led you to use \n    this reformulation and why do you think it is more stable in practice?\n  - You should mention in the caption of table 4, what quantity you are \n    computing.\n\nNote that my evaluation for this paper is based mainly on the way it is written \nas, in its current state, it is hard for me to judge what is novel and what is \nuseful, and what readers are supposed to take in by reading this paper. The main \nquestion that the paper definitely needs to answer, but does not do so currently \n(in my opinion) is:\n\n  When is this method useful to readers? For solving which problems and under \n  what conditions? And also, when is this method bad and should not be used?\n\n== Experiments ==\n\nSection 5.1 is hard to follow and I don\'t quite get how it connects to the rest.\n\nAlso, in section 5.1.2 you mention that in comparison to Dai et al. (2017) your \nmethod does not need to rely on an additional density estimation network. Even \nif that is true, I cannot see how it is a useful remark given that the method of \nDai et al. seems to always beat your method.\n\n== Style ==\n\nIn figure 1, no labels or legends are provided making it hard to figure out \nwhat\'s going on at a glance. It would be very helpful to include labels and a \nlegend.\n\nEquation 2 is not written correctly. The equals sign only refers to ""V(G, D)"" \nand not the min-max of that, right? Please make that explicit by first defining \n""V(G, D)"" alone.', ""- Summary:\nThis paper considers the problem of learning a GAN to capture a target distribution p_t with only very few training samples from p_t available.\n\n- Good\nAn interesting problem formulation. \nThe proposed approach is not new, but seems to be a sensible and simple solution to the problem formulated in this paper. I would see the contributions of the paper: (1) an interesting problem formulation on how to learn p_t (with a few assumptions) (2) a sensible adaptation of GANs on this problem (with minor modifications to GANs which have been observed/adopted in many GAN literatures in the last two years)\nThe training appaoches/tricks are rather straightforward and not new as well.\n\n- Suggestions\nThe main problem of this paper is that it does not provide sufficient results on any real applications that can support its problem&model formulations. \nFor example, in which scenarios would the users of the model need to train a GAN to mimic a target distribution p_t which is a difference of another two distributions (with examples available there but unavailable in p_t)? It would be good to show significant results on real applications to show the problem and the method useful.\n\nTwo applications on semi-supervised classification and adversarial training are discussed. While both seem to be very artificial IMO if considering the used dataset and designed experiments. The results are also not convincing even for the shown two experiments compared to baselines.\n\nNo related works on addressing the similar problems have been discussed nor compared in experiments.\n\n- Theoretical results:\nWhile the authors claim new theoretical results, in fact, I didn't see any contributions here as the theories developed in section 3 are mostly rather straightforward. There have been some similar theories being developed in previous papers where a component in GAN exhibits mixture-modeled forms, such as in TripleGan (Li et al. NIPS'17). So I would not recommend the authors to claim contributions here.\n\n- Writing:\nThe paper does not seem to be polished. It may not be necessary to exceed 8 pages as many spaces in this paper could be easily squeezed (apparently). The organization could be better; Some parts are vague and difficult to understand;  the writing could be improved to be more clearly demonstrate the contributions of this paper. "", 'The paper presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect. To this end they simply model the target distribution such that adding it to one of the distribution results in another, and propose a min-max objective based on it. To show the effectiveness of the proposed DS-GAN, the authors validate it on semi-supervised learning and adversarial training tasks, on which it performs reasonably well in generating the difference between the two distributions. \n\nPros\n- The idea of learning the difference between two distributions is novel to my knowledge. Similar ideas have been explored in prior work such as [Li et al. 17] but are not doing exactly what the authors try to do. \n- The proposed method works reasonably well on semi-supervised learning and adversarial learning tasks, and thus it seems practically useful. \n\nCons\n- The proposed model is quite straightforward in its formulation, and since the paper is not addressing the importance of, or any challenges with the problem they are trying to solve, the contribution of this work appears minor. \n- The authors list theoretical results as contributions, but they are rather straightforward replacement of the p_d and p_g terms in the original theorems on optimality in [Goodfellow et al. 14] with the target distributions in this paper, that has nothing to do with what the authors claim in this paper.  Thus they add nothing to the value of the paper.\n- The motivation is very unclear when reading the introduction section, and Figure 1 does not do a good job of providing it.  \n- The experimental validation is lacking in many aspects. I think the main results should show that the difference-seeking GAN can learn distributional differences but the authors jump straight to the applications. Also, the current experimental section simply reports performances on the two tasks, without much analysis showing why it works well and how it works differently from other models. \n\nIn sum, the idea seems nice and interesting but the model is straightforward and the current results are very weak in analysis in order to make a good paper. I would recommend the authors to perform further analysis of the model either theoretically or experimentally.\n\n']","[-60, -30, -20]","[20, 20, 50]","[""The sentiment score is -60 because the review is predominantly critical. The reviewer states the paper is 'not very well written and can be hard to follow', points out several issues with motivation and clarity, and suggests multiple improvements. However, it's not entirely negative as the reviewer acknowledges potential value in the work, hence not a lower score. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language such as 'It would be very helpful...' and 'Please connect...'. The reviewer also frames criticisms as suggestions for improvement rather than outright dismissals. However, the overall tone is more neutral than overtly polite, hence a modest positive score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting problem formulation', 'sensible and simple solution'), they express significant concerns about the paper's contributions, lack of real-world applications, unconvincing results, and theoretical claims. The overall tone leans negative, but not extremely so. The politeness score is 20 because the reviewer uses generally polite language ('It would be good to...', 'I would not recommend...') and frames criticisms constructively. However, they don't go out of their way to be overly polite or complimentary, maintaining a professional tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express more significant concerns ('Cons') and conclude that the paper's results are 'very weak in analysis'. The overall tone suggests the paper needs substantial improvement. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement without using harsh or dismissive language. They acknowledge the positive aspects before presenting criticisms, and use phrases like 'I would recommend' rather than making demands, which contributes to the polite tone.""]"
"['The main contribution of this paper is a new proposed score to evaluate models that yield uncertainty values for regression.\n\nAs constituted, the paper can not be published into one of the better ML conferences. The novelty here is very limited. Furthermore there are other weaknesses to the study.\n\nFirst, the stated goal of the ""metric"" is that ""reflects the correlation between the true error and the estimated uncertainty ... (and is) scale independent and robust to outliers."" Given this goal (and the name of the paper) it is perplexing why the correlation (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) of true error and predicted error (\\sigma_i) was not tried as baseline score. The correlation would have some ""scale independence"" and I\'m sure that there are robust estimates (a simple thing would be to consider the median instead of mean, but there are probably more sophisticated approaches). This just feels like an obvious omission. If one wants to mix both predictive quality and correctness of uncertainty assessments then one could just scale the mean absolute error by the correlation: MAE/Corr, which would lead to a direct comparison to the  proposed MeRCI.\n\nSecond, the paper does a poor job of justifying MeRCI. On toy data MeRCI is justified by a confluence with existing scores. Then on the depth prediction task, where there are discrepancies among the scores, MeRCI is largely justified qualitatively  on a single image (Figure 4). A qualitative argument on a single instance in a single task can not cut it. The paper must put forth some systematic and more comprehensive comparison of scores.\n\nEven with the above issues resolved, the paper would have to do more for publication. I would want to see either some proof of a property of the proposed score(s), or to use the proposed score to inform training, etc.', 'This works presents an overview of different techniques to obtain uncertainty estimates for regression algorithms, as well as metrics to assess the quality of these uncertainty estimates.\nIt then introduces MeRCI, a novel metric that is more suitable for deep learning applications.\n\nBeing able to build algorithms that are good not only at making predictions, but also at reliably assessing the confidence of these predictions is fundamental in any application. While this is often a focus in many communities, in the deep learning community however this is not the case, so I really like that the authors of this paper want to raise awareness on these techniques. The paper is well written and I enjoyed reading it. \nI feel that to be more readable for a broader audience it would be relevant to introduce more in depth key concepts such as sharpness and calibration, an not just in a few lines as done in the end of page 2. \n\nWhile I found the theoretical explanation interesting, I feel that the experimental part does not support strongly enough the claims made in the paper. First of all, for this type of paper I would have expected more real-life experiments, and not just the monocular depth estimation one. This is in fact the only way to assess if the findings of the paper generalize.\nThen, I am not convinced that keeping the networks predictions fixed in all experiments is correct. The different predictive uncertainty methods return both a mean and a variance of the prediction, but it seems that you disregard the information on the mean in you tests. If I understood correctly, I would expect the absolute errors to change for each of the methods, so the comparisons in Figure 4 can be very misleading. \nWith which method did you obtain the predictions in Figure 4.c? \n\nTypos:\n- ""implies"" -> ""imply"" in first line of page 3\n- ""0. 2"" -> ""0.2"" in pag 6, also you should clarify if 0.2 refers to the fraction of units that are dropped or that are kept\n\n', 'The authors propose mean rescaled confidence interval (MERCI) as a way to measure the quality of predictive uncertainty for regression problems. The main idea is to rescale confidence intervals, and use average width of the confidence intervals as a measure for calibration. Due to the rescaling, the MERCI score is insensitive to the absolute scale; while this could be a feature in some cases, it can also be problematic in applications where the absolute scale of uncertainty matters. \n\nOverall, the current draft feels a bit preliminary. The current draft misses discussion of other relevant papers, makes some incorrect claims, and the experiments are a bit limited. I encourage the authors to revise and submit to a different venue. \n\t\nThere’s a very relevant ICML 2018 paper on calibrating regression using similar idea: \nAccurate Uncertainties for Deep Learning Using Calibrated Regression\nhttps://arxiv.org/pdf/1807.00263.pdf\nCan you clarify if/how the proposed work differs from this? I’d also like to see a discussion of calibration post-processing methods such as Platt scaling and isotonic regression.\n\nThe paper unfairly dismisses prior work by making factually incorrect claims, e.g. Section 2 claims\n“Indeed, papers like (Hernandez-Lobato & Adams, 2015; Gal & Ghahramani, 2016; Lakshminarayanan et al., 2017; Kendall & Gal, 2017) propose quantitative evaluations on several datasets, those classically used for evaluating the task, but only compare their average test performances in terms of RMSE. It is the quality of the prediction which is measured, and not the quality of the estimated uncertainty. They also show some qualitative results, where maps of the estimated uncertainty are displayed as images and visually evaluated. Yet, to the best of our knowledge, the literature on deep neural networks does not propose any method for the quantitative evaluation of the uncertainty estimates.”\nThis is incorrect.  To just name a few examples of prior work quantitatively evaluating the quality of uncertainty: (Hernandez-Lobato & Adams, 2015) and (Gal & Ghahramani, 2016) report log-likelihoods on regression tasks, (Lakshminarayanan et al. 2017) report log-likelihoods and Brier score on classification and regression tasks. There are many more examples. \n\nThe experiments are a bit limited. Figure 1 is a toy dataset and Table 2 / Figure 4 focus on a single test case which does not seem like a fair comparison of the different methods. The authors should at least compare their method to other work on the UCI regression benchmarks used by (Hernandez-Lobato & Adams, 2015).']","[-70, 50, -60]","[-20, 80, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that 'the paper can not be published into one of the better ML conferences' and points out several weaknesses, including limited novelty and poor justification of the proposed method. The reviewer also suggests that even with improvements, more work would be needed for publication. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism. Phrases like 'perplexing why...was not tried' and 'can not cut it' come across as somewhat harsh. However, the reviewer does use some neutral language and provides specific recommendations, which prevents the score from being lower."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses appreciation for the paper's topic and writing quality, stating 'I really like that the authors of this paper want to raise awareness on these techniques' and 'The paper is well written and I enjoyed reading it.' However, they also provide significant critiques, particularly regarding the experimental section, which balances out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism in a gentle manner. They use phrases like 'I feel that' and 'I am not convinced' rather than making harsh statements. The reviewer also provides helpful suggestions and points out typos in a neutral tone. The overall tone is professional and courteous, maintaining a positive and supportive attitude while still addressing areas for improvement."", ""The sentiment score is -60 because the review is generally negative. The reviewer states that the draft feels 'preliminary', 'misses discussion of other relevant papers', 'makes some incorrect claims', and has 'limited' experiments. They also encourage the authors to 'revise and submit to a different venue', indicating significant issues with the current work. However, it's not entirely negative as they do acknowledge some potential value in the proposed method.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone. They use phrases like 'I encourage the authors to revise' and 'Can you clarify', which are polite ways of suggesting improvements. The reviewer also provides specific examples and references to support their critiques, which is helpful and respectful. However, the directness of some criticisms (e.g., 'unfairly dismisses prior work', 'factually incorrect claims') prevents the score from being higher.""]"
"['Summary\nThe manuscript proposes to use power iterations in an approximate ""whitening layer"" to optimize the slowness objective of SFA in a very general setting. A set of experiments illustrates that this way of doing nonlinear SFA is meaningful.\n\nQuality\nAlthough the idea is pretty straight forward and the paper shows qualitative results on a number of datasets, the relative merit of the approach is empirically not well characterized.\n\nClarity\nThe manuscript is in general well written and the technical content is well accessible. However the description of the whitening layer implementation needs some more details.\n\nOriginality\nThe idea of using a whitening layer together with the slowness objective has not been explored before. There is a second ICLR 2019 submission (Pfau et al.) with a very similar idea, though.\n\nEmpirical Evaluation\nThe approximate whitening should lead to a trade-off between whitening and slowness optimization. I miss an experiment illustrating that trade-off. Also the comparison to nonlinear SFA using expansion or kernelization of hierarchical SFA is empirically not properly characterized. In the end, if one takes the slowness objective seriously, one would use the method yielding slower results.\n\nSignificance\nThe manuscript introduces a way of running nonlinear SFA with approximate constraints in a general deep learning setting with a differentiable implementation using a dedicated whitening layer based on power iterations.\n\nReproducibility\nThe data is either synthetic or publicly available. The Keras implementation of the PowerWhitening layer as well as the entire neural network along with its optimization schedule is not shared. Hence, there should be some effort involved to reproduce the experiments.\n\nPros and Cons\n1+) The idea of an approximate whitening layer is conceptually simple and clear.\n2-) The description of the practical implementation of the power iteration is slightly imprecise.\n3-) The algorithm scales badly in the number of output dimensions. This scaling is bad in a computational sense and also in a statistical sense.\n\nDetails\na) Section 6.1: Why do you need to add the noise term? What is the statistical meaning of this added noise?\nb) Section 6.1: the solutions if comparable -> the solutions is comparable\nc) References: Shaham -> ICLR 2018 paper\nd) References: nyström -> Nyström\ne) The name for the algorithm ""Power SFA"" is a little bit bold.', 'In this paper the authors present a differentiable objective for slow feature analysis, to facilitate end-to-end training.   I am not clear on the novelty of this formulation, as it appears to have been proposed in a similar form in previous works (e.g., A maximum-likelihood interpretation for slow feature analysis by Turner and Sahani - Eq., (2)) and can probably be considered straightforward.  Nevertheless, the approximate whitening layer and the way it is used is a smart approach for this problem.  The experiments are interesting and shed light on the properties of the method.  In summary, the paper may lack technical novelty in some respect, but the experiments are convincing in terms of proof-of-concept, and the approach is smart.\n\n', 'The authors state a clear summary of their contribution to Slow Feature Analysis (SFA) in Section 5: ""The key idea for gradient-based SFA is that a whitening layer can be applied subsequently to any differentiable architecture (such as deep neural networks) to enforce outputs that approximately obey the SFA constraints while still being a differentiable architecture.” As a result, the proposed method can replace the previous SFA pipeline of [fixed, non-linear feature extraction + learned linear feature extraction] with simply end-to-end [learned, non-linear feature extraction]. The resulting method is thus more flexible and expressive and less hand-crafted than traditional SFA approaches. The paper shows experiments that validate that the method can learn meaningful representations in practice.\n\nThe writing is difficult to follow, unclear in several places, and has grammatical mistakes. As a result, it is more challenging to understand the proposed method, its motivation, and its precise place among related literature. For example, the authors discuss SpIN, and from that discussion, it seems that SpIN are quite similar; SpIN was submitted to arXiv 3-4 months before the ICLR deadline and thus is not concurrent as the authors claim (on my understanding, from reading the ICLR and other ML conference guidelines).\n\nThe approach does seem somewhat incremental, though I would be open to changing my mind on author response. On one view, this method can be seen as simply replacing SFA’s fixed, non-linear feature extraction with learned non-linear feature extraction, with a trick to make it work. Deep learning consistently improves over fixed non-linear feature extractors, so it is not surprising a surprising place to incorporate neural networks.\n\nBased on the method, this paper could go either way, but given my concerns on its novelty and writing quality/clarity, I lean slightly towards reject.']","[20, 20, -30]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges some positive aspects of the manuscript ('The idea is pretty straight forward', 'The manuscript is in general well written'), they also point out several areas for improvement and limitations. The overall tone is constructive but with reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers both pros and cons, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone, using phrases like 'I miss an experiment' instead of more critical language. The detailed points are presented as helpful suggestions rather than demands, further contributing to the polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some concerns about novelty, they also acknowledge the smart approach and convincing experiments. The review starts with a neutral tone but becomes more positive towards the end, praising the 'smart approach' and 'convincing' experiments. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism and balancing negative points with positive ones. They use phrases like 'I am not clear' instead of more direct criticisms, and acknowledge the paper's strengths even while pointing out potential weaknesses."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (clear summary, validation through experiments), they express significant concerns about the writing quality, clarity, and novelty of the approach. The reviewer leans 'slightly towards reject', indicating a somewhat negative overall sentiment. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They express willingness to change their mind based on author response, which shows openness. However, the criticism is direct and doesn't use overly polite phrasing, keeping the score only moderately positive.""]"
"['This paper proposes a new metric called the image score that compares the similarity of activation between a given image with a pool of groundtruth images. The paper finds it useful for semi-supervised learning with self-teaching, where the network picks the most confident sample and use the network prediction as the label. It finds that the proposed method is better than 1) not using the unlabeled data and 2) using softmax as an indicator for model prediction certainty.\n\nMotivation: The introduction begins by motivating the interpretability story of deep learning, but I don’t see gaining any more interpretability by reading the rest of the paper. The paper proposes to improve interpretability by assigning a score to each individual example, but then the obtained scores are not properly analyzed in the paper, and only final classification accuracy is evaluated. What are the training samples that makes the model make certain decision at test time? How to measure the correlation between the usefulness of training samples and the proposed image score? These questions left unanswered in the paper. Figure 1 helps a little bit, but then the top row is not necessarily the bad images, but maybe hard examples that needs extra attention to learn. Therefore, I think the end results presented in the experiments do not align with the motivation. Rather than shooting for interpretability, this is just another semi-supervised learning paper.\n\nModels: The major issue of this paper is the model formulation that is not well motivated. The intuition of how the authors come up with the equation for computing the image score is not well explained. Hence the formulation seems very ad-hoc, and it is unclear why this is the selected method.\n\nExperiments: As a semi-supervised learning paper, a common setting for CIFAR-10 is to use 4k labeled images. Here, the method uses 30k, which is 7.5x the size of the usual setting. It also does not compare to prior semi-supervised learning work (e.g. one of the recent one is: https://arxiv.org/abs/1711.00258). The only two baselines discussed here are weak. Also the improvement from the baselines by using the proposed method is not very significant.\n\nComparison: Figure 2-4 shows some positive correlation between the accuracy and score, which is fair, but it doesn’t compare to any baselines--the only one we have is softmax baseline and it is not shown in the figure.\n\nIn conclusion, I couldn’t see how the paper improves interpretability as claimed in the introduction. The proposed method seems ad-hoc, without any justification. Being considered as a semi-supervised learning paper, it lack significant amount of comparison to prior work and adopting a common semi-supervised benchmark. Due to the above reasons, I recommend reject.\n\n---\nMinor points:\n“...almost all of the existed works investigate only the models and ignore the relationship between models and samples”. This is over-exaggerated. I believe most of the visualization techniques are dependent on the actual input samples. It is true to say about “training samples” not “samples” in general.\n\n“all correctly classified images should have similar chain of activation, while incorrectly classified images should have very different activations both within themselves and with correctly classified images”. This claim seems not backed up. How do you know it is the case for “all” correctly classified images? What defines similar/different?', 'This paper proposes image score, to use the amount of strong activations in each single image compared with the average activation on the entire dataset as a metric of how well the image is interpreted by a particular deep model. I am not sure whether that intuition makes sense, and there seem to be a lot of ways the simplistic equation can be broken. Section 2.3 shows some intuition of a higher score corresponding to higher testing accuracy, but somehow is done only on 1 class in CIFAR and I don\'t think that is generalizable to other classes and especially other classification problems.\n\nThe paper claims interpretability but I don\'t see any experiments verifying interpretability. The experiments are done on a semi-supervised learning task, where the ""image score"" is used to select some unlabeled examples as labeled by trusting a partially trained classifier. Hence we would have to evaluate it as a semi-supervised deep learning paper. Note that the amount of labeled examples in this paper is significantly higher than most semi-supervised approaches, which leaves the question that if extremely few supervised examples have been used, whether this approach will already fail. Although the model showed some improvements over the baseline, there has been no comparison at all with any existing semi-supervised deep learning approaches. Any semi-supervised learning approach usually outperforms the supervised baseline (used in this paper) by a bit, so I don\'t quite seem to believe that the results reported in this paper is significant enough. One can refer to the following paper for a few relatively new semi-supervised learning approaches:\n\nhttps://arxiv.org/pdf/1804.09170.pdf\n\nTable 4 is more baffling and less convincing. Because deep networks are volatile, it is hard to show this kind of result and hope people will be convinced. I would rather the author has trained both approaches to completion and then compare the end result. Also we still need comparisons with state-of-the-art semi-supervised learning approaches.', 'The idea of calculating a score to indicate the usefulness of a sample for training deep networks by analyzing the neural activations in semi-supervised learning is interesting.\n\nHowever, the effectiveness of the proposed method is not validated. In the cifar-10 semi-supervised image classification experiment, other semi-supervised learning methods are not compared. In my experiments, simply applying the trained model in the labeled data to obtain pseudo labels on the unlabeled data can obtain significant improvements.\n\nTheoretically, the proposed scoring method uses the pre-trained model to obtain correct activations that has two problems: (1) The evolving power that may be produced by the unlabeled data is constrained. (2) If there are a few numbers of labeled examples, it is very hard to learn a network; thus, the correct activation is not reliable. ']","[-80, -60, -50]","[20, 20, 20]","[""The sentiment score is -80 because the review is overall quite negative. The reviewer recommends rejection, points out several major issues with the paper's motivation, methodology, and experiments, and states that the paper lacks significant comparisons to prior work. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout and provide specific, constructive feedback. They use phrases like 'I couldn't see how...' and 'I believe...' rather than making blunt accusations. The reviewer also acknowledges some positive aspects, like the 'fair' correlation shown in Figures 2-4, which prevents the politeness score from being negative. However, the politeness score is not higher due to some direct criticisms like calling the baselines 'weak' and describing the method as 'ad-hoc, without any justification'."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's methodology, generalizability, and significance of results. They use phrases like 'I am not sure whether that intuition makes sense,' 'I don't think that is generalizable,' and 'I don't quite seem to believe that the results reported in this paper is significant enough.' These indicate a largely negative sentiment towards the paper's content and contributions. However, it's not entirely negative as they acknowledge some improvements over the baseline. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am not sure' and 'I don't quite seem to believe' rather than making blunt negative statements. They also provide constructive feedback and suggestions for improvement, such as comparing with state-of-the-art approaches and training both approaches to completion. This shows a level of respect and consideration for the authors, even while being critical of the work."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting idea in the first paragraph, the rest of the review is critical, pointing out significant limitations and theoretical problems with the proposed method. This indicates a generally negative sentiment, though not extremely harsh. The politeness score is 20 because the language used is professional and constructive, avoiding personal attacks or overly harsh criticism. The reviewer uses phrases like 'interesting' and 'However,' which maintain a respectful tone while still conveying criticism. The review focuses on the work itself rather than the authors, which contributes to its politeness.""]"
"['The paper provides a new system that combines a number of neural networks to predict chemical reactions. The paper brings together a number of interesting methods to create a system that outperforms the state of the art.\n\nGood about this paper: \n - reported performance: the authors report a small but very consistent performance improvement.\n - the authors propose an approach that puts together many pieces to become an effective approach to chemical reaction prediction. \n -\n\nProblematic with this paper\n - this paper is impossible to understand if you only refer to the ten pages of content. There are at least 5 pointers in the paper where the authors refer to the appendix for details. Details in many of these cases are necessary to even understand what is really being done:  p3: rewards p4: message passing functions, p5: updating states, p9: training details. Further, The paper has some details that are unnecessary - e.g. the discussion of global vs. local network on p4 - this could go into the appendix (or be dropped entirely)\n\n - the model uses a step-wise reward in the training procedure (p3) -> positive reward for each correct subaction. It is not clear from the paper whether the model requires this at test time too (which should not be available). It\'s not clear what the authors do in testing. I feel that a clean RL protocol would only use rewards during training that are also available in testing (and a final reward)\n\n - eq 7: given there is an expontential in the probability - how often will the sampling not pick the top candidate? feels like it will mostly pick the top candidate. \n\n - eq 9: it\'s unclear what this would do if the same pair of atoms is chosen twice (or more often)\n\n - the results presented in table 3: it appears that GTPN alone (and with beam search) is worse than the previous state of the art. only the various post processing steps make it better than the previous methods. It\'s not clear whether the state of the art methods in the table use similar postprocessing steps or whether they would also improve their results if the same postprocessing steps were applied. \n \n\nminor stuff: \np2: Therefore, one can view GTPN as RL -> I don\'t think there is a causality. Just drop ""Therefore""\np2: standard RL loss -> what is that? \neq. 2: interestin gchoice to add the vectors - wouldn\'t it be easier to just concatenate?\np4: what does ""NULL"" mean? how is this encoded?\np4 bottom: this is quite uncommon notation for me. Not a blocker but took me a while to parse and decrypt.\np5: how are the coefficients tuned?', 'Update:\n\nScore increased.\n\n___________________________________\n\nOriginal review:\n\nThe paper presents an approach to predict the products of chemical reactions, given the reactants and reagents. It works by stepwise predicting the atom pairs that change their bonds in course of reaction, and then adjusting the bonds between them. This can be interpreted as a stepwise graph transformation.\n\nI think this is an interesting applied ML paper with fair results. The presentation is clear and understandable. The experimental setup is reasonable. However, the paper is not ready yet to be accepted in my opinion.\n\nI think a higher score is justified if the authors address the following points:\n\n- Relation to previous work, originality\n\nIn contrast to what the authors claim, what is predicted here is not exactly the reaction mechanism, but an implementation of the principle of minimal chemical distance, which was already described by Ugi and coworkers in 1980 [see Jochum, Gasteiger, Ugi, The Principle of Minimum Chemical Distance Angew. Chem. Int. Ed. Engl. 1980, 19, p 495-505]. \nThe “insight” the authors have about treating reagents and reactants jointly is Organic Chemistry 101, and that reactions are stepwise graph transformations was also reported by Ugi et al, however, already in 1979! [Ugi, et al. ""New applications of computers in chemistry."" Angewandte Chemie International Edition in English 18.2 (1979): 111-123. ] I assume the authors were not aware of these papers, but now they are, so this needs to be modified accordingly, and these papers need to be referred to in the introduction. \n\n\n\n- Questions:\n\nThe authors suggest that graph neural networks are more generic that so-called heuristic features (fingerprints) – which, as Duvenaud et al have elaborated, can be interpreted just as graph neural networks themselves – with fixed weights. Also, there are results by the Hochreiter group which show that graph neural networks perform worse that classical chemical features under rigorous testing { DOI: 10.1039/C8SC00148K } Do the authors think their models could also improve if they used the classical fingerprints?\n\n\nIs the GRU really needed to encode the past bond changes? What happens if you remove it?\n\nThe statement that the method has the advantage of not relying on handcrafted reaction templates is somewhat overselling, because instead it uses a handcrafted complex neural network architecture. How complicated is it to train the network? If you remove some of the “tricks” of shaping the loss function, does it still train well?\n\n\nTo what degree is the ranking of the different models just a matter of hyperparameter tuning or different architectures? If you used a different graph neural net instead of an MPNN on top of your GTPN method, what would you expect? Are the differences between the models significant?\n\n\nDuring prediction, you apply a flag to the starting molecules if they are a reagent or reactant. How do you know upfront what a reagent or reactant is during inference? \n\nOn page 5 and 7, you speak of the correct sequence of reaction triples (which implies an ordering), even though earlier you claim the algorithm is order-invariant? Where do you get the ground truth labels from? I assume these are already annotated in the data.\n\n\nIn the appendix, please replace the pie chart with a bar chart.\n\n- Language:\nI would suggest the authors to adapt the language of their paper towards a more academic tone. Science is not a sports competition of getting slightly higher numbers in benchmarks, but rather about providing insights and explanations. Words like “beating” or “record” are locker room talk, and to be avoided.', 'Summary:\nThis paper develops a novel method for predicting organic chemical reactions, in particular, final product prediction from given reactants. Organic molecules consist of covalent bonds, and hence organic reactions can be regarded as an alternating multistep series of bond breaking and bond forming (i.e. qualitative understanding as ""reaction mechanisms"" against quantum chemical calculations). The developed method aims to predict this series of bond changes through a form of reinforcement learning guided with neural networks. In this sense, the setup and formulation seem largely inherited from cited previous papers by Bradshaw et al, 2018 or Kayala & Baldi, 2011 (though they are not used any RL formulation). Organic compounds at each elementary step are represented as molecular graphs, and reactions are thus a series of graph transformations. Each bond change can be considered as ""action"" at that state to form the next states to head for the final product. The method itself seems quite natural: States transitions are shared by an RNN and the hidden states and observations (molecular graphs at each step, and bond changes as actions) are used to learn ""policy"" and ""state transition"" for RL via graph neural networks. Atom pairs to lead the bond change are detected from such graph embeddings and state observations through self-attentive architectures. In addition, masking by additional indicator variables is introduced to avoid redundant training as well as determine the termination of the reaction. Experimental evaluations on a standard large benchmark dataset of USPTO show improved prediction performance compared to previous methods of Jin et al, 2017 and Schwaller et al, 2018.\n\nComment:\n- Given that a chemical reaction can be regarded as a multi-step chain of bond breaking and forming, thus the method part seems a quite natural extension of the past effort but also sounds rather incremental even though the performance gain exists.\n\n- The method part is written clearly but the problem setup seems rather unclear. The most unclear point is how the environment for RL can give any reward to each bond change. How we can know each prediction of a bond change is correct or not? Can it be supervised? Does this mean that the training set of reactions has the correct perfect information of these multi-step bond changes?? How did you construct such curated dataset for USPTO? If this is the case, the motivation to go for RL would be more understandable but this part is not explained at all. (Because it is inherited from previous work of Bradshaw et al 2018 or something?? )\n\n- Why this proposed method has no limitation whereas the previous method by Bradshaw et al, 2018 are limited to ""linear chain topology"" (?). If this method is the direct competitor, what points are important to remove this limitation of the previous method should be clarified more clearly. This method is referred multiple times in the paper, but no direct explanations exist. \n\nPros:\n\t- Nice and solid design of proposed ""graph transformation policy network""\n\t- Better prediction performance against previous methods\n\nCons:\n\t- Why this extension could break the previous limit (of ELECTRO?) remains unclear\n\t- The descriptions on the problem setup and the data are unclear. Perfectly curated as chemically correct multi-steps of bond changes are given as training set? How we can know each prediction of a bond change is correct or not?\n\t- the proposed architecture is nice but somewhat seems incremental. (heuristic combinations of existing techniques of RL and graph neural nets)\n']","[20, -20, -20]","[50, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and improvements over the state of the art. However, they also list several significant issues, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing praise with constructive criticism. They use neutral language to point out issues without being harsh or dismissive. The reviewer begins with positive aspects before addressing problems, which is a polite approach. They also offer specific suggestions for improvement, indicating a helpful intent rather than mere criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' with 'fair results' and 'clear presentation', they state that 'the paper is not ready yet to be accepted'. The reviewer provides a list of concerns and questions that need to be addressed, indicating room for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I think', 'I assume', and 'I would suggest', which are polite ways to express opinions. However, the reviewer does criticize some language choices ('locker room talk'), which slightly reduces the politeness score. Overall, the tone is professional and aimed at improving the paper rather than being overly critical."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Nice and solid design', 'Better prediction performance'), they express several concerns and criticisms. The review points out that the method seems 'rather incremental', the problem setup is 'rather unclear', and there are unanswered questions about the data and methodology. The cons outweigh the pros in the review.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns ('seems rather unclear', 'remains unclear') rather than harsh criticism. The reviewer also acknowledges the positive aspects of the work before delving into the criticisms. However, the score is not higher because the review is direct in its criticisms without much softening language.""]"
"['The author analyze the convergence properties of batch normalization for the ordinary least square (OLS) objective. They also provide experimental results on the OLS objective as well as small scale neural networks. First of all, understanding the properties of batch normalization is an important topic in the machine learning community so in that sense, contributions that tackle this problem are of interest for the community. However, this paper has a significant number of problems that need to be addressed before publication, perhaps the most important one being the overlap with prior work. Please address this point clearly in your rebuttal.\n\n1) Overlap with Kolher et al. 2018: The authors erroneously state that Kolher et al. considered the convergence properties of BNGD on linear networks while after taking a close look at their analysis, they first derive an analysis for least-squares and then also provide an extension of their analysis to perceptrons. The major problem is that this paper does not correctly state the difference between their analysis and Kolher et al who already derived similar results for OLS. I will come back to this aspect multiple times below.\n\n2) Properties of the minimizer\nThe authors should clearly state that Kolher et al. first proved that a^* and w^* have similar properties to Eq. 8. If I understand correctly, the difference seem to be that the algorithm analyzed in Kohler relies on the optimal a^* while the analysis presented here alternates between optimizing a and w. Is this correct? Is there any advantage in not using a^*? I think this would be worth clarifying.\n\n3) Scaling property\nI find this section confusing. Specifically,\na) The authors say they rely on this property in the proof but it is not very clear why this is beneficial. Can you please elaborate?\nb) It seems to me this scaling property is also similar to the analysis of Kolher et al. who showed that the reparametrized OLS objective yields a Rayleigh quotient objective. Can you comment on this?\nc) The idea of “restarting” is not clear to me, are you saying that one the magnitude of the vector w goes above a certain threshold, then one can rescale the vector therefore going back to what you called an equivalent representation? I don’t see why the text has to make this part so unclear. Looking at the proof of Theorem 3.3, this “property” seem to be used to simply rescale the a and w parameters.\nd) The authors claim that “the scaling law (Proposition 3.2) should play a significant role” to extend the analysis to more general models. This requires further explanation, why would this help for say neural networks or other more complex models?\n\n4) Convergence rate\nIt seems to me that the results obtained in this paper are weaker than previous known results, I would have liked to see a discussion of these results. Specifically,\na) Theorem 3.3 is an asymptotic convergence result so it is much weaker than the linear rate of convergence derived in Kolher et al. The authors require a sufficiently small step size. Looking at the analysis of Kolher et al., they show that the reparametrized OLS objective yields a Rayleigh quotient objective. Wouldn’t a constant step size also yield convergence in that case?\nb) Proposition 3.4 also only provides a local convergence rate. The authors argue BNGD could have a faster convergence. This does seem to again be a weaker result. So again, I think it would be very beneficial if the authors could clearly state the differences with previous work.\n\n5) Saddles for neural nets\nThe authors claim they “have not encountered convergence to saddles” for the experiments with neural networks. How did you check whether the limit point reached by BNGD was not a saddle point? This requires computing all the eigenvalues of the Hessian which is typically expensive. How was this done exactly?\n\n6) Extension of the analysis to deep neural networks\nThe analysis provided in this paper only applies to OLS while Kolher et al. also derived an analysis for neural networks. Can the authors comment on extending their own analysis to neural nets and how this would differ from the one derived in Kolher et al.?\n\n7) Experiments\nHow would you estimate the range of suitable step sizes (for both a and w) for BNGD for a neural network?\n', 'The paper presents an analysis of the batch normalization idea on a simple OLS problem. The analysis is interesting as presented but several key questions remain, as described below. It is unclear that these questions are answered to the point where the insight gained can be considered transferable to BN in large Neural Network models.  \n\n- The reason why the auxiliary variable \'a\' is included in the formulation (7) is unclear. The whole reason for using BN is to rescale intermediate outputs to have an expectation of zero and variance of one. The authors claim that BN produces ""order 1"" output and so \'a\' is needed. Can you please explain his better?\n\n- The scaling proposition 3.2 is claimed to be important, but the authors don\'t provide a clear explanation of why that is so. Two different settings of algorithms are presented where the iterates should roughly be in the same order if input parameters of the formulation or the algorithm are scaled in a specific way. It is unclear how this leads to the claimed insight that the BN algorithm is yielded to be insensitive to input parameters of step length etc. due to this proposition. also, where is the proof of this proposition? I couldn\'t find it in the appendix, and I apologize in advance if that\'s an oversight on my part.\n\n- The \'u\' referred to in eqn (14) is the optimal solution to the original OLS problem, so has form H^{-1} g for some g that depends on input parameters. Doesn\'t this simplify the expression in (!4)? Does this lead to some intuition on how the condition number of H^* relates to H? Does this operation knock off the highest or lowest eigenvalue of H to impact the condition number?  \n \n- Additionally, it is bad notation to use two-letter function names in a mathematical description, such as BN(z). This gets confusing very fast in theorems and proofs, though the CS community seems to be comfortable with this convention.  ', ""This paper provides a theoretical analysis for batch normalization with gradient descent (GDBN) under a simplified scenario, i.e., solving an ordinary least squares problem. The analysis shows that GDBN converges to a stationary point when the learning rate is less than or equal to 1, regardless of the condition number of the problem. Some practical experiments are carried out to justify their theoretical insights. The paper is in general easy to follow. \n\nPros:\nThis paper provides some insights for BN using the simplified model.\n1. It shows that the optimal convergence rate of BN can be faster than vanilla GD.\n\n2. It shows that GDBN doesn't diverge even if the learning rate for trainable parameters is very large. \n\nCons:\n1. In the main theorem, when the learning rate for the rescaling parameter is less than or equal to 1, the algorithm is only proved to converge to a stationary point for OLS problem rather a global optimal. \n\n2. To show convergence to the global optimal, the learning rate needs to be sufficiently small. But it is not specified how small it is. \n\nOverall, I think this paper provides some preliminary analysis for BN, which should shed some lights for understanding BN. However, the model under analysis is very simplified and the theoretical results are still preliminary.""]","[-50, -30, 20]","[50, 60, 60]","[""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic, they express significant concerns about the paper, particularly its overlap with prior work and weaker results compared to existing literature. The review lists multiple issues that need to be addressed, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer sees potential value in the work if improved. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'please address' and 'I would have liked to see,' which maintain a courteous tone. The reviewer also asks for clarification on several points rather than making outright negative judgments, which contributes to the polite tone. However, the review isn't overly effusive or praising, keeping it from scoring higher on the politeness scale."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the analysis as 'interesting', they express several concerns and uncertainties about the paper's claims and explanations. The review points out multiple areas where clarification or additional information is needed, suggesting that the paper falls short in some aspects. However, it's not entirely negative as the reviewer sees some value in the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'please explain' and 'I apologize in advance if that's an oversight on my part', which demonstrate courtesy. The critique is presented as a series of questions and requests for clarification rather than harsh criticisms. Even when pointing out issues like bad notation, the reviewer does so in a matter-of-fact manner without using insulting language.\n\nOverall, the review balances constructive criticism with polite language, resulting in a slightly negative sentiment but a notably polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as providing insights and being easy to follow. However, they also point out significant limitations, which tempers the overall sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging both pros and cons without harsh criticism. They use phrases like 'This paper provides some insights' and 'Overall, I think this paper provides some preliminary analysis', which maintain a professional and courteous tone even when discussing limitations.""]"
"['The scope of the paper is interesting: to additionally learn the nonlinear activation function of the neuron.\n\nThe insights provided in section 2 with eqs (2)-(5) are interesting and naturally build on the previous work of Poggio & Girosi (1990) and Smola (1998). I found this a nice new insight and the strongest part of the paper. It is e.g. revealing to see to which P and L the rectifier nonlinearity is corresponding.\n\nOn the other hand I also have a number of suggestions for further improvement:\n\n- Section 1: related to the overall function to be learned, the authors state ""this general problem has been already solved"". I think this statement is not completely correct, because depending on the choice of the stabilizer one obtains different optimal representations (e.g. Gaussian RBF or thin plate splines) as explained in Poggio & Girosi (1990). The theory does not tell what the best stabilizer is.\n\nAdditional relevant work that would be good to mention at this point, in the area of kernel methods, is e.g. learning the kernel.\n\n- It seems that no other existing work on deep kernel machines has been mentioned in the paper, while in the conclusions the authors state ""In this paper we have introduced Kernel-based deep neural networks"". \n\n- Related to the training set T_N the notation e^kappa is not explained. It is not clear how this is related to eq (1).\n\n- It would be good to comment on the difference between (3)(4) and Poggio & Girosi (1990).\n\n- unnumbered eq after (5): are there multiple solutions to the problem (non-convex)? \n\n- The explanation of the recurrent network at the end of section 2 is too limited. Moreover, LSTM is not just a neuron nonlinearity, but a recurrent network with a particular structure. To which P and L would LSTM correspond?\n\n- Fig.2: some of the nonlinearities look quite complicated and some of them are oscillatory (is this desirable? it reminds us of overfitting). Often one is interested in activation functions with a ""simple shape"" like sigmoid, tanh, relu. A more complicated nonlinearity may reduce the interpretability of the model.\n\n- The examples given are rather conceptual (though nice) examples of the proposed method. However, no comparisons with other methods have been made yet in terms of generalization performance, e.g. on a few standard classification benchmark data sets, in comparison with other deep or shallow models.\n\nA possible drawback of the proposed method might be (or maybe not) that additional unknown parameters need to be learned, which could possibly lead to worse generalization. It might be good to further investigate this.\n', 'Summary: the authors propose a method for learning activation functions in neural networks using kernels. Each activation function is modeled as a weighted set of kernels, where (as I understand it) the weights are learned simultaneously with the linear weights in the network. The authors apply their method to learn the XOR function and to a simple sequence memory task.\n\nMy main concern with the paper is that the presentation is very hard to follow. The motivation, background, and contributions of this paper are all mixed in the abstract and introduction, making it hard to understand what is the current state of learned activations, what this paper introduces, and how the work in this paper relates to prior work. Instead, I found the presentation in Scardapane et al much clearer (that paper has a clear separation of background, related work, and their contributions). By contrast, this paper has one large paragraph in the introduction that muddles together multiple threads of thought, making it hard to digest. Before the reader has had time to digest the main ideas, the paper launches into a highly technical description of the method, without a clear high level explanation of what the main technique is. A lot of the mathematical notation introduced in Sec2 is not clearly motivated.\n\nMy other main concern is with the results. The paper solves two simple tasks with their method, and it is unclear what their kernel methods really buy them. For the XOR problem, it is such a simple task that it is hard to judge the method (it seems like complex activation functions are not required to solve the task, and it is not clear what including them gets you). For the sequence memory task, it seems unfair to compare their results to recurrent networks with a *single* hidden unit. If you have networks with 2 or 4 or 8 hidden units, do they solve the task? These experiments do not shed much light on the advantages of using kernel activations in recurrent networks.', 'The paper investigates the problem of designing the activation functions of neural networks with focus on recurrent architectures. The authors frame such problem as learning the activation functions in the space of square integrable functions by adding a regularization term penalizing the differential properties of candidate functions. In particular, the authors observe that this strategy is related to some well-established approaches to select activation functions such as ReLUs. \n\n\nThe paper has some typos and some passages are hard to read/interpret. The write-up needs to be improved significantly.  \n\nWhile some of the observations reported by the authors are interesting it is in general hard to evaluate the contributions of the paper. In particular the discussion of Sec. 2 is very informal, although ti describes the key technical observations used in the paper to devise the model (Sec. 3) that is then evaluated in the experiments (Sec. 4). In particular, it is unclear whether the authors are describing some known results - in which case they should add references - or original contributions - in which case they should report their results with more mathematical rigour. Indeed, in the abstract, the authors state that a representation theorem is given, but in the text they provide only an informal discussion of such result. \n\nOverall, it is hard to agree with the authors\' conclusion that ""the KBRN architecture exhibits an ideal computational structure to deal with classic problems of capturing long-term dependencies"": the theoretical discussion does not provide sufficient evidence in this sense.\n\nSome minor points: \n\nConfusing notation: why were the alpha^k replaced with the \\chi^k between Sec. 2 and Sec. 3?\n\nUnclear motivation for some design choices. For instance 1) the justification given by the authors to neglect the linear terms from both g(x) and k(x) in Sec. 3 is unclear. 2) why was the \\ell_1 norm used as penalty for the regularizer R(\\chi) in Sec.3? One could argue that \\ell_1 is used to encourage sparse solutions, but the authors should explain why sparsity is desirable in this setting. \n\n']","[20, -50, -50]","[60, 20, 20]","[""The sentiment score is slightly positive (20) because the reviewer starts with positive comments about the paper's scope and insights, calling them 'interesting' and 'the strongest part of the paper'. However, the bulk of the review consists of suggestions for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as 'suggestions for further improvement' and using phrases like 'it would be good to' rather than making demands. The reviewer also acknowledges the paper's strengths before offering critiques. The tone remains professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's presentation and results. They describe the paper as 'very hard to follow' and criticize the lack of clear motivation, background, and contributions. The reviewer also questions the value of the results presented. However, the score is not lower because the reviewer does acknowledge some positive aspects, such as the proposed method itself.\n\nThe politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'My main concern' and 'It is unclear' rather than using harsh or dismissive language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. However, the score is not higher because the review is predominantly critical and doesn't include many positive remarks or encouragement."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as typos, hard-to-read passages, lack of mathematical rigor, and insufficient evidence for the authors' conclusions. However, it's not entirely negative as it acknowledges some 'interesting observations'. The politeness score is 20 because while the reviewer is critical, they use relatively polite language such as 'it is hard to agree' and 'some minor points' rather than harsh or rude phrasing. They also offer specific suggestions for improvement, which is constructive. The reviewer maintains a professional tone throughout, even when pointing out flaws.""]"
"['The key idea of this paper is to expand the network for training on new tasks which is termed as C-Net, and train an additional generative model which is used for predicting task id (which is called H-Net), and use the task id for selecting weights from the C-Net.\n\nPros:\n1. It is relatively easy to understand the paper. \n2. The originality of this paper lies in the usage of generative model to predict task id (H-Net). To my knowledge has not been proposed before.\n3. In contrast to previous works in multi-task learning, which assumes task id is available both during training and inference, this work tries to remove the need of task id during inference, which makes it closer to the general definition of continual learning.\n\nCons:\n1. Expanding the network for new tasks is not a novel contribution of this paper, it has already been proposed in previous works on multi-task learning. Doing expansion on all of the layers does not qualify for a major contribution in my opinion.\n2. The experimental comparison is not very fair in my opinion, \n     a. Comparing accuracy of C-Net to other methods is not very useful. Because this methods expands the network for every new task, while other methods (EWC, LwF) has limited to no expansion in the network. Given that the single network result is far from state of the art (table 3), I suppose model size could contribute to the accuracy boost.\n     b. It is not explicitly stated in the paper whether the output neurons are shared between tasks or an individual set of output neurons are used for different tasks, but from the rest of the paper I suppose disjoint neurons are used. Then the comparison between EWC and this work is not fair because EWC shares the output neurons among tasks.\nThis is not to blame this paper for not making fair comparison, since given different assumptions between methods (availability of task id, shared output neurons etc.), it is usually difficult to fairly compare between continual learning methods.  This problem is raised in another submission https://openreview.net/forum?id=ByGVui0ctm. The point here is that the accuracy of C-Net is not a good measure of how good this method is.\n3. I disagree with the point that MNIST and SVHN are similar, they have very different distributions and are very easy to tell apart with a model. One concern is that the generative H-Net may fail to work once the distributions of the tasks overlap to some extent. e.g. cifar10 vs cifar100.\n\nAs a conclusion, the key contribution of this work is using generative model to determine task id which removes the need for task id during inference. It is relatively insufficient for publication on ICLR.', 'Summary\nThis paper proposes an extension of Progressive Networks [Rusu et al. NIPS 2016] (unfortunately, not cited) where the task id is not given at test time. This is inferred by a battery of classifiers trained on data produced by generative models trained on task specific data.\nThe authors argue strong connections to similar mechanisms in the human brain and demonstrate this method on a stream of 2 or 3 vision tasks. However, the interpretation of these results is dubious.\n\nNovelty: given prior work on Progressive Nets and other methods using generative models for continual learning, novelty is limited.\n\nRelevance: the motivation and aim of this work is certainly relevant for ICLR.\n\nClarity: the paper is overall clear, although it needs a bit of rewriting to improve fluency (see for instance sec. 3.4.1).\n\nReferences: the authors should definitely cite Progressive Networks and their extension ""Progress and Compress"" (Schwarz ICML 2018), as their approach is an extension of the former with the only difference that the task id is inferred at test time by using a battery of binary classifiers.\n\nEmpirical validation: The empirical validation is limited because of:\na) lack of comparison to Progressive Nets, \nb) lack of simple baselines (e.g., how about replacing H-Net with an inference process like task_id = argmin_i=1..T loss(C-Net, task = i) ),\nc) unclear interpretation of the provided results (how can the accuracy on MNIST be 100%? are the authors reporting training accuracy?)\nd) very limited number of tasks considered (up to 3)\n\nGeneral comments\nMajor drawbacks of the proposed approach are: 1) training on new tasks can never improve performance on past tasks (unlike other methods like GEM (Lopez-Paz et al. NIPS 2017), 2) the number of parameters grow linearly with the number of tasks (an issue addressed by the Progress and Compress paper above), and 3) the overall approach is not efficient as it requires lots of data from each task in order to train the generative models.\nFinally, I think all the connections and inspiration from how the human brain works should be toned down.  Statements like ""the C-Net corresponds to the human cortex..."" should be at the very least rephrased appropriately.', 'The work proposes a structure that mimics progressive nets. Maybe the main difference from progressive nets is that backwards connection from the new features to the old features in layer 2 are not 0 out. This could cause interference, however is solved by using the task ID to not evaluate those new features when going back to a previous task. I think this is a technical detail, that does not provide any explicit advantage or disadvantage over progressive nets. \n\nEmploying GANs/VAE to predict task id also can be seen as not an ideal choice. In particular the GAN network will suffer from catastrophic forgetting, which is solved (if I understood correctly) by training the GAN with data from all tasks. Which makes one wonder, if we can affort to access data from all tasks to learn the GAN then why not the classification model too !?\n\nI think an alternative might be something like the Forget Me Not Process published and used in the original work with EWC.\n\nUnfortunately due to presence of these previous works, lack of more thorough comparison with other existing approaches, the work should not be accepted to ICLR.']","[-50, -50, -70]","[50, 20, -20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), the overall tone is critical and concludes that the paper is 'relatively insufficient for publication'. The cons outweigh the pros, and the reviewer disagrees with some of the paper's claims. However, it's not entirely negative, as the reviewer recognizes some original contributions. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses without using harsh or dismissive language. The reviewer also provides detailed explanations for their critiques, which is a polite way to give feedback. The tone is constructive rather than confrontational, even when expressing disagreement."", ""The sentiment score is -50 because the review is generally critical, pointing out several limitations and drawbacks of the paper. The reviewer notes limited novelty, issues with empirical validation, and major drawbacks of the proposed approach. However, it's not entirely negative as the reviewer acknowledges the relevance and clarity of the paper. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'the authors should' and 'I think' rather than more aggressive language. The reviewer also balances criticism with some positive comments about relevance and clarity. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the reviewer expresses significant criticism and concludes that the work should not be accepted. They point out perceived flaws in the approach and suggest that it lacks novelty compared to existing works. The politeness score is -20 because while the language is not overtly rude, it is quite direct and dismissive, particularly in the final sentence. The reviewer does not use any softening language or acknowledge potential merits of the work, which contributes to a somewhat impolite tone. The phrases 'Unfortunately due to...' and 'the work should not be accepted' are particularly blunt and contribute to the negative politeness score.""]"
"['In this paper, the authors propose a SOSELETO (source selection for target optimization) framework to transfer learning and training with noisy labels. The intuition is some source instances are more informative than the others. Specifically, source instances are weighted and the weights are learned in a bilevel optimization scheme. Experimental studies on both training with noisy label problems and transfer learning problems demonstrate the effectiveness of the proposed SOSELETO.\n\nOverall, this paper is well-written, and easy to follow. The intuition is clear and reasonable, although it is not new. Regarding the technical section, I have the following comments:\n(1)\tThe paper assumes that the source and target domains share the same feature representation parameters \\theta. This is a widely used assumption in the existing works. However, these works usually have a specific part to align two domains to support the assumption, e.g. adversarial loss or MMD. In objective of SOSELETO, I do not see such a domain alignment part. I am wondering whether the assumption is still valid in this case. From the experimental study, I find SOSELETO achieves very good results in transfer learning problems. I am wondering whether the performance would be further improved if a domain alignment objective is added in the weighted source loss.\n(2)\tEach source has a weight, and thus there are n^s \\alpha. As mini-batch is used in the training, I am wondering whether batches are overlapping or not. If overlapping, how to decide the final \\alpha_i for x^s_i as you may obtain several \\alpha_i in batches. \n(3)\tAnother point is abouth \\lambda_p. In the contents, you omit the last term Q \\alpha_m \\lambda_p in eq.(4) as you use the fact that it is very small. I am not convincing on this omission as \\lambda_p is also a weight for the entire derivative. Moreover, if \\lambda_p is very small, the convergence would be very slow. In the experimental studies, you use different \\lambda_p for different problems. Then, what’s the rule of setting \\lambda_p given a new problem?\n\nRegarding the experimental results, the experimental settings for the section 4.2 are not very clear to me. You may need to clearly state the train and test set (e.g. data size) for each method.  \n', 'This is an interesting paper claiming that on assumptions are made (or explicitly made) on the similarity of distributions. Traditionally, we learned the weights for transfer learning by matching the distributions. I am wondering if there are any relationships between those two methods. It is necessary to show the differences between the weighted source domain and the target domain, and compare them with the traditional matching methods.\n\nMy another concern is about the technical contribution. The model is very intuitive and simple. Some analyses are made for optimization. However, theoretical justifications are lacking, making the technical contribution weak and looks like a simple combination of two existing techniques. I would like to know if the weights are identifiable and what kinds of weights are preferred. \n\nBy searching, I found related papers on transfer learning with label noise and learning with label noise by importance reweighting, e.g., Yu, Xiyu, et al. ""Transfer Learning with Label Noise."" arXiv preprint arXiv:1707.09724 (2017). and Liu, Tongliang, and Dacheng Tao. ""Classification with noisy labels by importance reweighting."" IEEE Transactions on pattern analysis and machine intelligence 38.3 (2016): 447-461. However, they are not discussed in the submission. It is curious to see the relationships and differences.', 'PROS:\n* This is an interesting approach of assigning contribution weights to each source sample.\n* Could be very helpful for tasks where we have a noisy and a (small) clean dataset.\n* The method seems to be performing well for the tasks chosen, especially for the CIFAR experiments.\n* Simple idea and relatively easy to implement\n\nCONS:\n* Clarity could be improved, especially in the experimental section\n* The motivation for the SVHN 0-4 to MNIST 5-9 is not clear. It would make more sense to me to transfer between SVHN 0-5 to SVHN 5-9, or from the entire SVHN to the entire MNIST, but this particular transfer seems somewhat irrelevant to the claims. The two domains are particularly dissimilar and trying to select ""good"" SVHN samples according to 20 or 25 MNIST samples seems somewhat ill-posed. It is also particularly surprising to me that 25 MNIST samples were enough to train a LeNet to the point of 84% accuracy on the entire MNIST test set. (I\'m referring to the target-only line) Is that really the case, or was a larger training set used for that particular line?\n* There is a claim that ""SOSELETO has superior performance to all of the techniqiues which do not use unlabelled data"", however I\'m not sure whether these techniques were used as prescribed and if the comparison was fair. For example, I believe domain adaptation techniques like DANN, largely assume a common label space between the domains.\n* Comparison with previous re-weighting techniques would have been very informative.\n\nQUALITY:\n* The quality of the writing was overall high, with a few exceptions, including the related work and the experimental section.\n* In related work, the ""bilevel optimization"" section could be a bit more descriptive, maybe some of the explanationgiven in Sect. 3 could be moved here?\n* The experiments were convincing, with the exception of the SVHN to MNIST section.\n\nCLARITY:\n* I believe a better synthetic experiment could be chosen to highlight the approach: how about a truly noisy dataset that is not as separable as the ""noisy"" dataset in Figure 1? Maybe you could have the same noisy dataset but with a small portion of random points having the wrong label. For the same experiment, it should be clearly stated that your task is binary classification and what was the classifier used.\n* For the CIFAR experiments, it is very good that it performs well, but it\'d be informative to see if SOSELETO can perform even better with 10K samples.\n* It wasn\'t clear to me whether the a-values of only one batch (32 samples?) at a time were affected. If so, how does this scale to really large datasets like, say, Imagenet?\n* In the CIFAR experiments, it is mentioned that a target batch-size is chosen to be larger to enable more a-values to be affected. This seems like a typo, but it was confusing. (I assume that the source batch-size is chosen to be larger)\n* Figure 2 could use a better caption and a legend. It would also be an easier figure to parse if the x-axis was reversed (eg. if the x-axis was the fraction of data used)\n* It was not clear to me what ""true transfer learning"" means as opposed to domain adaptation.\n\nORIGINALITY:\n* It seems that this idea has been explored before, however I\'m not personally familiar with that work. I would have definitely liked to see comparisons with it though.\n\n\nSIGNIFICANCE:\n* This is a simple idea that seems to work well. As I wrote above, it would be great to know how it compares to other re-weighting techniques.']","[50, -20, 20]","[80, 50, 60]","[""Sentiment Score (50): The review begins with a positive tone, stating the paper is 'well-written, and easy to follow' with a 'clear and reasonable' intuition. However, it also includes several critical comments and suggestions for improvement, balancing the positive aspects. This mix of praise and constructive criticism indicates a moderately positive sentiment.\n\nPoliteness Score (80): The reviewer uses polite and professional language throughout. They begin with positive comments before moving to constructive criticism. The use of phrases like 'I am wondering' and 'you may need to' instead of more direct criticisms shows a considerate approach. The reviewer also acknowledges the paper's strengths and the effectiveness of the proposed method, which contributes to the overall politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' initially, they express several concerns and criticisms throughout the review. They point out lacking theoretical justifications, weak technical contribution, and missing discussions on related work. These critiques outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout. They frame their criticisms as 'concerns' and use phrases like 'I am wondering' and 'I would like to know,' which maintain a respectful tone. The reviewer also offers constructive suggestions and references to related work, which is helpful and courteous. However, the directness of some criticisms prevents the score from being higher."", ""The sentiment score is slightly positive (20) because the review begins with listing pros and acknowledges the interesting approach and good performance of the method. However, it also includes several cons and areas for improvement, balancing out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'Clarity could be improved', 'It would make more sense to me'). The reviewer maintains a professional tone while providing both positive feedback and areas for improvement, without using harsh or rude language.""]"
"['This paper describes a method of training neural networks without update locking. The idea is a small modification on top of Czarnecki et al. Critic training, where instead of using final loss as a critic target, one bootstraps from critics on other layers. In particular, if only one module is present, these two approaches are actually identical. To be more precise, the only difference between these two methods is that (7) in Critic training would change to l(L_i, L_N). As a consequence, method becomes forward unlocked too. It is worth noting, that in the appendix of Czarnecki et al. it is shown that this particular method (critic training) under simple conditions actually ""degenerates"" to deep supervision (which is forward unlocked too). Consequently unlocking property as such is not a big contribution of the proposed method. Rest of the paper includes following elements:\n- empirical evaluation showing improvement over critic training by 0.4% in CIFAR10 and 0.9% in CIFAR100 when using 3 splits.\n- expansion on using the model for progressive inference.\n\nGiven standard deviation of errors in Table 1. it is not clear how significant these improvements are. How many samples were used to estimate these quantities? It is worth noting, that Critic training was showed to be outperformed by Sobolev Training in the same paper authors cite, but its performance is not reported despite looking like a well defined baseline. In particular, can these two methods be combined? \n\nI believe that this is an interesting research direction, however paper in its current form seems as a small incremental improvement over sota, and could be significantly improved by for example:\n- providing more comprehensive evaluation (including estimating accuracy to lower std errors)\n- adding other baseline solutions (such as Sobolev training, cDNI, or deep supervision)\n- considering any form of convergence/dynamics analysis of the proposed approach\n\n\n\n', 'This manuscript presents a new method that can conduct local training of a deep neural network. \nBriefly speaking, the proposed method first cuts a very deep network into a few groups and then train the parameters of each group almost independent of the other groups. The main idea is to attach a local critic module to each group and the error gradient is back propagated to each group from its local critic module instead of the last layer of the whole network.\nSuch an idea seems to work well and the resultant performance decrease is acceptable when the original network is not very large. However, when the original network is complex, the performance decrease may be relatively big. \n\nAnother benefit of this local critic training is that in addition to the main model, it can also produce several submodels that can be used for ensemble inference and progressive classification. \n\nIn summary, this manuscript proposes an interesting idea, but not sure empirically how useful it will be since for a complex network, this method may result in relatively big performance decrease. For a simple network, although the performance decrease is small, but there is no need to use the proposed training method for a simplex network.', ""This paper proposes an alternative training paradigm for DNIs: instead of training an auxiliary module to approximate the gradient provided by the following modules of the original model, they train it to approximate directly the final output of the original model. Although the approach does not seem to improve significantly, if at all, over Sobolev training of these modules (denoted 'critic' in the paper), this method seems simpler and offer side benefits which seem to be the main contribution of this paper. \nIndeed Table 4 and 5 show for example how they can, after training the full model, extract a submodel requiring significantly less computation and parameters with little loss in the performance. Alternatively, they also propose a method to do progressive inference for similar reasons. \nThe ensembling result is interesting, but the figure 4 is not necessarily clear on the significance of this result, especially since the standard deviation is not shown in this figure.\nThe idea proposed in this paper is interesting, however, the experiments are restricted on relatively small and simple architectures and limited on two very similar datasets (CIFAR-10 and CIFAR-100), making the argument less compelling. ""]","[-20, -20, 20]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'an interesting research direction', they also describe it as a 'small incremental improvement' and suggest several ways it 'could be significantly improved'. The reviewer points out limitations in the current work and questions the significance of the results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the potential of the work ('interesting research direction') and offering constructive suggestions for improvement rather than harsh criticism. The reviewer maintains a professional tone, using phrases like 'I believe' and 'it is worth noting' to soften their critiques."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the method as 'interesting' and notes some benefits, they express significant doubts about its usefulness and effectiveness, especially for complex networks. The reviewer points out that the method may result in 'relatively big performance decrease' for complex networks, and for simple networks, there's 'no need to use the proposed training method'. These criticisms outweigh the initial positive remarks.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the method and its results, and phrase their criticisms as observations rather than direct attacks. Phrases like 'seems to work well' and 'interesting idea' show a level of courtesy. However, the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a more neutral professional tone overall."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting ideas and potential benefits, such as the ability to extract efficient submodels. However, they also point out limitations, like the lack of significant improvement over existing methods and the restricted experimental scope. The politeness score is moderately positive (50) as the reviewer uses neutral and professional language throughout, avoiding harsh criticism. They present both positive aspects and constructive feedback in a balanced manner, using phrases like 'seems simpler' and 'interesting, however,' which maintain a respectful tone while still conveying areas for improvement.""]"
"['This paper deals with the open set classification problem, where in addition to the known classes, the method should also be able to recognize the unknown class. The main idea is based on two parts: learning a discriminative representation, and a threshold based detection rule. To learn the embedding, the authors propose to minimize the inner class distance (between each instance to its center) and enlarge the distance between centers. The outlier score of an instance is computed as the minimum distance between known class prototypes. Experiments on various datasets show the ability of the learned method.\n\nI\'m not completely sure whether the whole approach is novel or not in the open set recognition domain, but both parts are not novel enough. Pulling similar instances together and pushing dissimilar ones away is the main idea in embedding learning. The ii-loss is similar to the triplet-center loss in the paper ""He et al. Triplet-Center Loss for Multi-View 3D Object Retrieval. CVPR18"". \n\nAlthough in the experiments the proposed method achieves good results in most cases, the reviewer suggests the authors comparing with more baselines to make the work solid.\n1. Comparing with other embedding learning methods with the same outlier detection score. \nThe authors should prove that the proposed embedding is important enough in the open set case. For example, using the center loss (Wen et al. A discriminative feature learning approach for deep face recognition. ECCV16), triplet-center loss, triplet loss (computing class centers after embedding).\n\n2. Discuss more on the outlier score part. \nHow to differentiate the known class outlier and new class? Will the problem be more difficult when the unknown class contains more heterogeneous classes? The authors can also apply existing open set recognition rule on the learned embedding.\n\nSome detailed questions:\n1. What\'s the difference between ""the network weights are first updated to minimize on ii-loss and then in a separate step updated to minimize cross entropy loss"" and optimize both loss terms simultaneously?\n2. ""We assume that a certain percent of the training set to be noise/outliers"", how to determine the concrete value? Is 1% the helpful one for all cases?\n3. Since there is not optimize over the unknown classes in training, could the reason for ""the unknown class instances fully occupy the open space between the known classes"" is the unknown classes are randomly sampled from the whole class set? For example, if classes about animals are known classes and classes about scene compose the unknown class, will the unknown class also occupy the whole space in this case?\n4. What is the motivation of making ""the unknown class instances fully occupy the open space between the known classes""?', '\nThe paper focuses on open set classification where one wants to design a classifier able to accurately classify samples from training (known classes) and able to reject samples from unknown classes. Such a feature is would be clearly desirable for all machine learning classification algorithms. The paper presents a representation learning based approach for this problem. \n\nThe idea is very simple. It consists in learning a neural classifier with a constraint on the representation space of samples (i.e. the one implemented in a chosen hidden layer of the network) aiming at optimizing a Fisher-discriminant-like criterion. This criterion aims at minimizing the variance of the representation of the samples within a class and to make representations of samples from different classes (actually the means per class) well separated. The learning is eventually performed by adding a usual cross entropy classification loss on the output layer to the Fisher like criterion. The rejection of samples from unknown classes is performed via a threshold on the minimum distance of a sample representation and the class means in the representations space.  The idea is well thought but the innovation is indeed low. \n\nExperiments are performed on three, but small, datasets including the simple Mnist dataset. Experimental results compare the proposed approach and its variants to two recent baselines, OpenMax and G_OpenMax. Experiments show the proposed approach outperform the two baselines but in some cases the confidence interval is quite large and prevent definitive conclusions (e.g. up to 0.05 in Table 2). Visualization of projected data show as expected the interesting feature of the representation space. Yet the experimental analysis does not seem as deeps the ones in the two papers where baselines were published. For instance results are shown with respect to a measure of the experimental setting named openness in [Ge and al.]. Moreover the paper by  [Ge and al.] conclude to the superiority of their proposal with respect to OpenMax which is not fully consistent with the results reported in this paper. Also experiments were performed on much bigger datasets in these two references with ILSVRC 2012 dataset in [Bendale and al., 2016] while [Ge and al.]  used a handwritten diet dataset with more than 350 classes. It would drastically strengthen the paper if the authors could provide comparative results on these datasets too.', 'The paper proposed a NN-based model for open set recognition via finding a better feature space where larger inter-class (P2) and smaller intra-class distances (P1) are satisfied. In the proposed model, the inter- and intra-class distances are measured basing on the mean of final linear layer features from each class, and a kind of L2 loss is defined to ensure the properties of the feature space during the training progress. Then the proposed outlier score defined as the minimum inter-class distance becomes the key for the open set recognition task.\n\nGenerally, this paper is well written and easy to read. The proposed threshold estimation method for outlier score based on assumed contamination ratio is reasonable. And three datasets in two domains are used to prove the model’s effectiveness.\n\nMajor comments:\n1.\tThis paper seems less novel.\nThere exist several methods aiming to find a better feature space satisfying the mentioned feature distance properties by adjusting the optimized loss functions, such as Center Loss (Wen et.al 2016) and Additive Angular Margin (Deng et.al 2018). I think the idea Combining ii-loss with Cross Entropy Loss proposed in this paper is quite similar to the Center Loss except that\na)\tthe ii-loss contains a part for maximizing the minimum inter-class distance;\nb)\tthe ii-loss and cross entropy loss are optimized separately.\nSince results shown in Center Loss that without pushing the inter-class distance, the feature space still satisfied P1 and P2, this paper seems not that novel, at least some comparation can be added to analyze the improvement for adding the inter-class part.\n\n2.\tThis paper seems less convincing as well.\nThe paper introduces that the two properties (larger inter-class and smaller intra-class distances) can lead to larger spaces among known classes for the instances of the unknown classes to occupy. However, it keeps uncertain if this can be generalized to unseen classes. In this sense, it is better to conduct some additional theoretical analysis or perform more experiments to validate this. In particular, only one plot was performed to verify this point on one single dataset. Maybe more plots of the distributions can be provided on more additional datasets.\n']","[-20, -20, -30]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('achieves good results in most cases'), they express significant doubts about the novelty of the approach and suggest multiple areas for improvement. The reviewer states 'I'm not completely sure whether the whole approach is novel or not' and 'both parts are not novel enough', indicating a lack of confidence in the paper's originality. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'the reviewer suggests' and phrase criticisms as suggestions for improvement rather than direct attacks. The reviewer also balances critique with acknowledgment of the paper's strengths. However, the score is not higher as the review is quite direct in its criticisms, particularly regarding novelty."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and some positive aspects, they also point out several limitations and areas for improvement. The reviewer mentions 'low innovation', limited experimental analysis compared to baselines, and the need for more extensive experiments on larger datasets. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, acknowledging the paper's merits while providing constructive criticism. They use phrases like 'well thought' and 'interesting feature' alongside their critiques, maintaining a balanced and courteous tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('well written', 'easy to read', 'reasonable'), they express significant concerns about the paper's novelty and convincingness. The reviewer states the paper 'seems less novel' and 'seems less convincing', which are substantial criticisms. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'I think' and 'it is better to' which maintain a collegial tone even while expressing concerns.""]"
"['The authors describe q-activation functions, stochastic relatives of common activation functions used in neural networks.  It seems like the main argument is to use them because you get a performance improvement with them. \n\nWhile the experiments appear to show better training at early epochs, none of the models appear to have been trained to convergence.  Additional justifications for why (or when) to use this should be described.\n\nWhy does the method outperform particularly when dropout is included?\n\nI also expect the lack of monotonicity in the q-activation functions to lead to the creation of (exponentially) more local minima.  Any comments?\n\nQuality: the experiments need some further work.\nClarity: aside from a few points, the paper is written clearly.\nOriginality: the work appears original to me\nSignificance: TBD, but the main argument appears to be that it leads to empirical comparative gains (but on networks not designed to be SOTA).\n\nSmall points:\n""By prop 2, g_q(x) agrees with with original activation function"".  What does ""agrees with"" mean?\n""Fig 2. Darker color --> lighter color?""\n""(Conclusion) ... can goes[sic] deeper on the error surface."" To me, the experiments only show marginally better performance', ""\n############ Updated Review #################\n\nI have read the author(s)' rebuttal. My decision stays unchanged. In my opinion, this first step is not significant enough, and the presentation is clearly below the acceptance threshold for ICLR. Additionally, the author(s) did not update their submission to reflect the changes. I thereby recommending rejection to this submission. \n\n##########################################\n\nThis work proposes to replace the regular deterministic activation functions used in artificial neural nets with stochastic variants. In particular, the author(s) considered the q-derivatives of standard activation functions. \n\nThe author(s) claimed that ``By Proposition 2, the p-derivative of the q-activation g_q(x) agrees with the original activation function f.'' I have trouble understanding this. I assume by original activation function the author(s) meant f(x), then how can Eqn (4) agree with f(x)?\n\nAt the bottom of pp. 3, the author(s) wrote: ``q-neuron ... combines stochasticity and some second-order information in an easy-to-compute way.'' I definitely can not agree with this point. Basically, q-neuron is the ``derivative'' of the original activation function, so there is no surprise that its derivative links to the second derivative of f(x). I can always use the high order derivative of some function as activation and claim now we are combining even higher order information into the neural network, but does that help? I don't think so. \n\nIt really annoys me to see that four out of the eight pages are occupied by gigantic figures, which should be placed in supplementary material in my opinion. A simple table could do the job equally well in the text. We are not interested in nitty-gritty details on how the training evolves. Let alone the datasets tested are all small-scale image classification tasks. At least the author(s) should diversify their test beds (e.g., NLP tasks and ImageNet scale experiments) and model architectures (e.g., RNN, ResNet). \n\nWhat's also missing from their experiments is a fair comparison with the real counterparts. I do not see comparisons with dropouts, and to more direct activation function randomization schemes (additive noise to regular activation functions). \n\nTo summarize, I can not approve this paper as it falls well below the acceptance level of an ICLR. In its current form, it's more like a sketchy note rather than a serious academic paper. I would encourage the authors to significantly enrich the content of this writing before considering resubmitting to another venue. \n"", 'The authors introduce concept of q-calculus into neural networks along with its advantages. They define a family of stochastic activation functions based on standard functions together with q-calculus.\n\nI have a single question, if the proposed stochastic activation functions can also be achieved through deterministic neurons together with noise schemes like dropout (or any others)? If yes, is it still useful to use q-neurons. sorry, if I missed something obvious.\n\nAs mentioned by the authors the experiments only showcase a slight improvement in performance which may not be consistent when tried across larger set of experiments.']","[-20, -80, 20]","[50, -30, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (originality, clarity), they express several concerns and criticisms about the work. The reviewer points out that the experiments need further work, questions the lack of training to convergence, and raises concerns about potential issues with the method. The overall tone suggests that the paper needs significant improvements.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and provide constructive feedback. The reviewer acknowledges positive aspects of the paper and uses phrases like 'I expect' and 'Any comments?' to soften their criticisms. The language is not overly formal or polite, but it avoids any rudeness or harsh criticism."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions throughout, recommending rejection and stating the paper falls 'well below the acceptance level'. They use phrases like 'I can not approve this paper' and 'it's more like a sketchy note rather than a serious academic paper', indicating a very negative sentiment. The politeness score is -30 because while the reviewer maintains some professional language, there are instances of blunt and somewhat rude expressions. Phrases like 'It really annoys me' and 'I definitely can not agree with this point' come across as impolite. The reviewer also dismisses the authors' work rather harshly, calling it a 'sketchy note'. However, they do offer some constructive feedback and encourage improvement, which prevents the score from being even lower."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' introduction of a new concept and its advantages. However, they express some skepticism about the significance of the improvements and raise a question about alternative approaches. The politeness score is high (80) due to the respectful tone throughout the review. The reviewer uses polite language such as 'sorry, if I missed something obvious' when asking a question, showing consideration for the authors. The review is constructive and doesn't use any harsh or critical language, maintaining a professional and courteous tone throughout.""]"
"['This paper presents a method for increasing the efficiency of sparse reward RL methods through a backward curriculum on expert demonstrations. The method in the paper is as follows: assuming access to expert demonstration and a resettable simulator, the start state of the agent in the beginning of training is sampled from end of demonstration (close to the rewarding state) where the task of achieving the goal is easy. Then gradually through a curriculum this is shifted backwards in the demonstration, making the task gradually harder. \n\nThe proposed method is closely related to 1) “Learning Montezuma’s Revenge from a Single Demonstration” a blog post and open-source code release by Salimans and Chen (OpenAI Blog, 2018) where they show that constructing a curriculum that gradually moves the starting state back from the end of a single demonstration to the beginning helps solve Montezuma’s revenge game 2) “Reverse Curriculum Generation for Reinforcement Learning” by Florensa et al. (CoRL 2017) , where they start the training to reach a goal from start states nearby a given goal state and gradually the agent is trained to solve the task from increasingly distant start states. \n\nThe approach is evaluated on a pair of tasks, a maze environment and a stochastic four-player game, Pommerman. In the maze environment, they compare to vanilla PPO and Uniformly sampled starting points across the expert trajectory. The Backplay method outperforms the vanilla baseline, however, from the training curves (~3500 epochs) in the appendix A4, it looks like the Uniform sampling baseline is doing as well or better than the proposed method. As pointed out by the authors themselves the reverse curriculum does not seem necessary in this environment. Also, it is unclear to me whether the curves shown is comparable as the starting point of the agent, at least in the beginning of training, is close to the goal with higher success rate for the Backplay method compared to baselines. A good convincing assessment would be to report success rate against the same starting point for all methods preferably not from the starting point of the demonstrations to assess generalisation of these methods for which authors briefly report unsuccessful results. \n\nThe Pommerman environment is more complex and the results reported are more interesting. Figure 3 shows the results on four different maps for which expert demonstrations are generated from a Finite-Machine Tree-search method (a competitive method in this environment). I’m slightly confused by the plots and the significant drops in performance once the curriculum is finished and agent encounters the start position of the demonstration trajectory (epoch 250). Is this affected by the schedule of the curriculum? Also, the choice of terminating training at epoch 550 is not clear as the method does not seem to have converged yet (the variance is quite high) and would be interesting to observe the dynamics of learning as the training proceeds and whether it converges to a stable policy at all. I am also slightly unclear regarding the performance difference between Standard method in Figure 3(c) and 3(d). If the Standard method is still the same baseline, vanilla PPO, why such huge performance difference? In my understanding, only the Uniform and Backplay methods should be affected by the quality of demonstrations? I believe this figure needs more explanation and clarity. I am also not clear on why Standard method is terminated at epoch 450 while other methods are trained until epoch 550. Figure 4 reports results of generalisation to 10 unseen maps but again the choice of terminating training after 550 epochs is not clear to me as the method again does not seem to have converged. \n\nOverall, the choice of parameters is not well motivated, these include the window size for sampling the start point, the schedule for shifting the start point, batch size (102400 seems large to me and this choice is never explained), horizon (in appendix A3 reported to be 1707 for Maze while in the main text it is reported as 200 steps), termination of training (3500 for Maze, Figure 7, and 550 in Pommerman, Figure 3). \n\nI commend the authors for honestly reporting their method’s shortcomings such as failure in generalisation, however, I find that the work lacks significance and quality. There is not much novelty in the proposed method and there is a clear lack of comparisons to existing sample efficient LfD techniques such as Generative Adversarial Imitation Learning (GAIL). I believe this paper requires substantial improvements for publication and is not up to the ICLR standards in its current form.\n', 'Thanks for your submission.\n\nThe  authors present a very elegant strategy of using Backplay, that learns a curriculum around a suboptimal demonstration. The authors show the technique reaches an upper bound on sample complexity especially in sparse reward environments. The strength of the paper is the ability to learn from even 10 sub-optimal demonstrator trajectory thereby achieving optimality in reaching the goal. The biggest limitation of the method as with other vanilla model free RL is the lack of generalization. \n\nA bit more motivation on the simplified assumption that function approximation would have been better. Although, such a simplification seems to be a natural candidate to be upper bounded by the longest shortest path from v_0 to v_*; consideration of such simplicaton on the neighbourhood structure of the graph with respect to the maximum vertex degree seems to be missing or cliques. Although, the authors comment about the strong assumptions being made to aid the analysis. \n\nThe authors explain the analysis in a very precise and the analysis seems to work. Although, the part of the analysis where connections are drawn to the reciprocal spectral gap is not very clear. \n\nThe authors discuss the limitation of the analysis in the case of the binary tree, that follows from the arguments before.\n\nIt will be great to see a more systematic approach to deciding how fast/slow the window should be updated to unify some of the findings from the empirical experiments as that seems to affect the way the agent trains using Backplay.', 'The paper presents a strategy for solving sparse reward tasks with RL by sampling initial states from demonstrations. The method, Backplay, starts by sampling states near the end of a demonstration trajectory, so that the agent will be initialized to states near the goal. As training progresses, the initial state distribution is incrementally shifted towards earlier steps in the demonstration, until the agent is trained starting from the original initial state. The authors further provide an analysis of the sample complexity of this method on a simple MDP. The method is demonstrated on a maze navigation task and a challenging game Pommerman.\n\nThe method is simple and sensible, but not particularly novel. As the authors pointed out, a very similar strategy for using demonstrations was previously presented in an OpenAI blogpost, Learning Montezuma’s Revenge from a Single Demonstration. However since that work was not published, it should not be held against this paper. That being said, sampling initial states from demonstrations is a tried-and-true strategy in RL, and the manually designed curriculum is also not particularly novel. Therefore the method is mainly a minor tweak to longstanding techniques. The paper has also acknowledges these previous works. As such, a more thorough evaluation with previous methods, such as those for automatic curriculum generation (e.g. Florensa et al. 2017 and Aytar et al. 2018) is vital, but is very much lacking in the current set of experiments.\n\nThis work can also benefit from a more diverse set of tasks to better evaluate the effectiveness of the method, and provide more insight on when such a strategy is beneficial. The experiments were conducted only on discrete grid world tasks, and additional experiments in continuous domains could be valuable. In the maze task, Backplay is not significantly better than uniform. Pommerman is a much more compelling task and shows more promising improvements from backflip. However, training seems to have been terminated fairly early, before the performance for most policies have converged. In particular, the standard dense policy in figure 3c seems to be doing pretty well, will it catch up to the backplay policy with more training? It is also pretty unexpected that the uniform policies are doing so poorly, worse than the standard policy for the Pommerman experiments. Do the authors have any intuition on why this might be the case?\n\nIn figure 3, what is the initial state distribution used to evaluate the various methods? Are all policies initialized to the original initial state of a task, or are initial states sampled from the demonstrations? Given the periodic drops in performance for the backplay policies, it appears that the initial states might be changing according the curriculum during evaluation. If that is the case, it might not be a fair comparison for the other policies, especially for the standard policies, which are trained under different initial states.\n\nAs detailed in the appendix, the sliding windows for the curriculum do not seem to have a lot of overlap. This might be a potentially problematic design decision, since the sudden change in the initial state distribution, may cause the policy to “forget” about strategies learned for previous initial states. Has the authors experimented with other more gradual transition strategies?\n\nI think this paper in its current form does not yet meet the bar for ICLR. But this line of work could be a potentially promising direction. More thorough evaluation, better baselines, and more diverse tasks can help to strengthen this work. Further analysis on the effects of different initialization strategies could also make for a compelling contribution.']","[-70, 70, -30]","[20, 80, 50]","[""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's novelty, methodology, and results. They state that the work 'lacks significance and quality' and is 'not up to the ICLR standards'. The reviewer points out several issues with the experiments, unclear explanations, and lack of comparisons to existing techniques. However, it's not entirely negative as they do acknowledge some positive aspects, such as the authors' honesty in reporting shortcomings.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I commend the authors' and 'I believe this paper requires substantial improvements' rather than using harsh or dismissive language. The reviewer also provides detailed feedback and explanations for their concerns, which is a courteous approach to peer review. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is 70 (positive) because the reviewer starts with praise for the authors' strategy, calling it 'very elegant' and highlighting its strengths. They mention the paper's ability to learn from sub-optimal demonstrations as a significant achievement. While there are some critiques and suggestions for improvement, the overall tone is appreciative and constructive. The politeness score is 80 (polite) due to the reviewer's respectful language throughout. They begin with 'Thanks for your submission' and use phrases like 'It will be great to see' when suggesting improvements. The reviewer acknowledges the authors' work positively and frames critiques as opportunities for enhancement rather than outright criticisms. The language is professional and courteous throughout, maintaining a respectful tone even when pointing out limitations or areas for clarification."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The method is simple and sensible'), they express significant criticisms and state that the paper 'does not yet meet the bar for ICLR'. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They avoid harsh or dismissive language, instead using phrases like 'This work can also benefit from...' and 'More thorough evaluation... can help to strengthen this work.' The reviewer maintains a professional tone while clearly communicating their concerns.""]"
"['This is a clear and well written paper that attempts to improve our ability to predict in the setting of massive multi-label data which, as the authors highlight, is an increasingly import problem in biology and healthcare. \n\nStrengths:\nThe idea of using the hierarchical structure of the labels is innovative and well-motivated. The experimental design and description of the methods is excellent. \n\nWeaknesses:\nOverall the results are not consistently strong and there is a key baseline missing. The approach only seems help in the ""rare label, small data"" regime, which limits the applicability of the method but is still worthy of consideration. \n\nMy biggest reservation is that the authors did not include a baseline where the classes are reweighted according to their frequency. Multilabel binary cross-entropy is very easy to modify to incorporate class weights (e.g. upweight the minority class for each label) and without this baseline I am unable to discern how well the method works relative to this simple baseline.\n\nOne more dataset would also strengthen the results, and since I am suggesting more work I will also try to be helpful and be specific. Predicting mesh terms from abstracts would qualify as a massive multilabel task and there is plenty of public data available here: https://www.nlm.nih.gov/databases/download/pubmed_medline.html \n\nFinally, there is one relevant paper that the authors may wish to consider in their review section: https://www.biorxiv.org/content/early/2018/07/10/365965', 'The authors propose a new training scheme for training neural networks for multi-label prediction tasks by introducing ontology relationships between labels.\nThe paper motivates very well by the observations that some labels include very small amount of data points.\nHowever, the authors don’t really investigate why such labels are rarely observed and the experiments don’t include any significance.\nThus overall I don’t think the paper is ready for publishing for ICLR yet.\n\nBelow are some more detailed comments:\n1) The authors discuss nicely about the intuition to introduce the Bayesian networks in the tasks of disease prediction. Essentially, the probability of assigning the label (leaf node) should be account for the probability of it being observed, namely the prior. Thus it is not surprising that for the rare labels, the proposed method would yield higher precision. However, the experiments don’t really include any significance measurement; especially for such tasks where the number of testing examples with rare labels is small (5~10 positive examples), significance measurement or some forms of hypothesis testing is a must-have in order to draw conclusion about the performance comparison. Answering such significance issue with tests for overfitting would be nice.\n\n2) My other major concern is for the protein function prediction task, the reason of why for certain labels, the number of instances is small, could be due to that a) there don’t exist much biological web-lab evidence, or b) among the population, there indeed only exist small number of proteins associated with such labels. The proposed method can address b) but not necessarily address a).\n\n3) The paper discusses the other results very briefly in Section 5 but doesn’t include any experiment comparison. Thus it is not convincing that the proposed method is making contribution to the field of disease prediction, protein function prediction or even general multi-label prediction. I would suggest to include the comparison with the state of the art methods for each application.\n\n4) Particularly for protein function prediction, another line of studies is to use protein protein interaction networks or other sources such as functional pathways rather than using sequence information alone (ref below). Some discussion would be nice.\n\nSchwikowski, Benno, Peter Uetz, and Stanley Fields. ""A network of protein–protein interactions in yeast.""\xa0Nature biotechnology\xa018.12 (2000): 1257.\nCao, Mengfei, et al. ""New directions for diffusion-based network prediction of protein function: incorporating pathways with confidence.""\xa0Bioinformatics\xa030.12 (2014): i219-i227.\n\n', 'This paper proposes a neural network, the outputs of which create a ""Bayesian network of sigmoids"". This is for use in massively multi-label situations where the class outputs are connected to some ontology. By using the ontology, the performance on long-tail classes with few examples should be improved.\nI like the method. It is intuitive and easy to implement. The only issue I have with the features and model is when in 3.1.2 the weights for the medical labels as input to the encoder are said to be \'tied\' to the output label embeddings. I would like to have seem more justification for this (perhaps just the keeping number of parameters down?) or evaluation as to whether it helped - I think it may have hindered because of how the output label is used in the dot product.\nThe stated difference between this work and previous hierarchical softmax models is that they use DAG structures, not just tree structures. However, of the two datasets they try, only one (proteins) has a DAG structure to the ontology, and they do not have a baseline comparison with a hierarchical softmax model.\nThe method does show improvements at low number of examples against a flat sigmoid model in the small disease prediction and protein function prediction, but other results are mixed, especially for the proteins with the DAG ontology, which is where one would have liked to see an advantage.\nI would like to have seen performance against a hierarchical soft max framework, or on some openly available or benchmark datasets, otherwise it is hard to judge the utility of the method.\n']","[20, -50, 20]","[70, 50, 60]","[""The sentiment score is 20 (slightly positive) because the reviewer starts by praising the paper as 'clear and well written' and highlights its strengths, but also points out significant weaknesses and reservations. The overall tone is constructive but with substantial critiques. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and offers constructive criticism. They even try to be 'helpful' by suggesting a specific dataset. The language is professional and courteous, avoiding harsh or dismissive statements."", ""The sentiment score is -50 because the reviewer expresses several concerns and states that the paper is not ready for publishing, indicating a negative sentiment. However, they do acknowledge some positive aspects like good motivation and nice discussion of intuition, which prevents the score from being extremely negative. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I would suggest' and 'Some discussion would be nice', which are polite ways of providing feedback. The reviewer also acknowledges the positive aspects of the paper before diving into criticisms, which is a polite approach to reviewing."", ""The sentiment score is slightly positive (20) because the reviewer expresses liking the method, calling it 'intuitive and easy to implement'. However, they also raise several concerns and criticisms, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I would like to have seen' and 'I like the method' which maintain a polite tone. The reviewer balances positive comments with areas for improvement, maintaining a professional and courteous approach throughout the review.""]"
"['The papers proposed to use normalizing flow policies instead of Gaussian policies to improve exploration and achieve better sample complexity in practice. While I believe this idea has not specifically been tried in previous literature and the vague intuition that NF leads to more exploration that helps learning a better policy, the novelty of combining these two seems limited, and the paper does not seem to provide enough justification to using NF policies instead of alternative policy distributions both in theory and in the experiments.\n\n1. About Section 4.2. I believe that the normalizing flow in question would transform the volume of a Gaussian? So there would exist some parameter setting for a flow model that also shrinks volume, thereby resulting in lower variance policies? The arguments would thereby depend heavily on the specific architecture and initialization of the flow model, which is not discussed in detail. \n\nAlso, why is finding a high variance policy better in terms of the trust region argument? Isn\'t the whole point of using trust region that the new policy should be closer to old policy to prevent performance degradation? I also think that a fair comparison would be compare KL between normalizing flow policies, instead of KL between NF and Gaussian.\n\n2. The TRPO experiments seem wrong -- at least the results don\'t match what is reported in the ACKTR paper for Reacher and InverseDoublePendulum envs -- there the TRPO policy at least learns something. Also TRPO in general does not perform as bad as it may seem, see ""Deep RL that matters"" paper by Henderson et al. Maybe this is because of using OpenAI baselines code which seems to have worse TRPO performance.\n\nThere is also no experiments on ACKTR on the small Mujoco tasks (even in the Appendix), which seems to be a rather big oversight given the authors have already done even harder tasks for ACKTR + NF.\n\nMoreover I think a fair comparison is to use almost the same architecture for implicit and gaussian, where the only difference is where you sample the noise. For Gaussian with flows, you can first use an MLP to produce deterministic outputs and then use flow to generate the mean actions. Otherwise it is impossible to say whether the architecture or the implicit distribution contributes more to the success.\n\nOne could also use truncated Gaussian distributions / Beta distributions / Gaussian + tanh, since Mujoco actions beyond (-1, 1) is treated as -1 or 1, so Gaussian should already be bad. It is unclear whether NF is able to outperform these settings. \n\nMinor points:\n\n- Fix citations. Please use \\citep throughout.\n- Is Equation (6) correct? Seems like \\Sigma_i should be the inverse of g_i(\\epsilon)? Also this is the ""change of variables formula"" not ""chain rule"".\n- Why is normalizing flow not part of the background?\n- Add legends in Figure (1)\n- Figure 2(c), I believe with max entropy you could already obtain diverse ant trajectories?\n- I believe in the context of generative models, ""implicit"" typically means the case where likelihood is not tractable? Here the likelihood is perfectly tractable.', ""This paper generalizes basic policy gradient methods by replacing the original Gaussian or Gaussian mixture policy with a normalizing flow policy, which is defined by a sequence of invertible transformations from a base policy.\n\nAlthough the concept of normalizing flow is simple, and it has been applied to other models such as VAE, there seems no work on applying it for policy optimization. Thus I think this method is itself interesting.\n\nHowever, I find the paper written in a way assuming readers very familiar with related concept and algorithms in reinforcement learning. Thus although one can get the general idea on how the method works, it might be difficult to get a deeper understanding on some details.\n\nFor example, normalizing flows are defined in Section 4, and then it is directly claimed that normalizing flows can be applied to policy optimization, without giving details on how it is actually applied, e.g., what is the objective function? and why one needs to compute gradients of the entropy (Section 4.1)?\n\nAlso, in the experiments, it is said that one can combing normalizing flows with TRPO without describing the details. I can't get how exactly normalizing flows + TRPO works.\n\nThe experiments also talk about 2D bandit problem, and again, without any descriptions. BTW, in the Section 4.3, what does [-1, 1]^2 mean? (I have seen {-1, 1}^2, but not [-1, 1]^2).\n\nIt seems that the authors only use the basic normalizing flow structures studied in Rezende&Mohamed (2015) and Dinh et al (2016). However, there are more powerful variants of normalizing flows such as the Multiplicative Normalizing Flows or the Glow. I wonder how good the results are if these more advanced versions are used. Maybe they can uniformly outperform Gaussian policy?\n\nUpdate:\nI feel the idea of this paper is straightforward, and the contribution is incremental. To improve the paper, stronger experiments need to be performed. "", 'The authors in this work present an approach to policy optimization that relies on an alternative policy formulation based on normalizing flows. This is a relatively simple modification (this is no criticism) that essentially uses the same TRPO algorithm as previous approaches, but a different mechanism for generating the distribution over actions. The crux of the authors’ approach is detailed in equations (6) and (7), although it could have been useful to see more of the discussion of the architecture from appendix B in the actual text of the paper.\n\nThe authors then go on to analyze the properties and expressiveness of the resulting properties and show that it is more capable of capturing complex interactions than a simple Gaussian. It was somewhat unclear, however, in section 4.2 what the exact form of the policies being compared are. Is this a simple example with only the parameters of the Gaussian, or was the Gaussian parameterized by a multi-layer model? Further, one thing I would also have liked to see the authors question more is, for the problems they attack, whether this expressiveness is more useful “during exploration” or for the ultimate performance of the final policy.\n\nThe authors, finally, show that this approach is able to out-perform the alternative Gaussian policy. Ultimately this approach seems to be a simple modification (or replacement) of the standard policy formulation, and one that seems to lead to good performance gains. ']","[-60, -20, 50]","[20, 50, 60]","[""The sentiment score is -60 because the reviewer expresses significant skepticism about the paper's novelty, justification, and experimental results. They point out several perceived flaws and limitations, suggesting the work is not sufficiently convincing or well-executed. However, it's not entirely negative as they acknowledge some potential in the idea. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I believe' and 'Maybe this is because' which soften the criticism. They also offer constructive suggestions for improvement, which is polite. However, the review is not overly polite, maintaining a direct and critical stance appropriate for peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting concept and novelty, they express several concerns about the clarity of explanations, lack of details, and the need for stronger experiments. The reviewer suggests that the contribution is incremental and improvements are needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I think,' 'I find,' and 'I wonder,' which maintain a polite tone while expressing their concerns. The reviewer also acknowledges positive aspects before presenting criticisms, which is a polite approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the work's merits and potential performance gains, while also offering constructive criticism. The review is not overwhelmingly positive but recognizes the value of the approach. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as suggestions or areas for improvement rather than harsh judgments. The reviewer uses phrases like 'it could have been useful' and 'I would also have liked to see' which maintain a polite tone while providing feedback.""]"
"['This paper proposes a simple method for knowledge distillation. The teacher and student models are matched using MMD objectives, the author demonstrates different variants of matching kernels specializes to previously proposed variants of knowledge distillation.\n\n- The extensive evaluation suggests that the MMD with polynomial kernel provides better results than the previously proposed method.\n-  It is interesting to see that MMD based transfer has more advantage on the object detection tasks.\n- Can the author provides more insights into the behavior of different kernels, for example visualizing, the gradient map might help us to understand why certain kernel works better than another one?\n- Did you consider translation invariance or other spatial properties when designing your kernels?\n\nIn summary, this is an interesting paper with good empirical results. The technique being used generalization is quite straightforward, but the paper also includes a good amount of discussion on why the proposed approach could be better and I think that really helps the reader.\n', 'This paper targets knowledge distillation of a large network to a smaller network. The approach is summarized by equations (3) and (4), which in short proposes that one should use the maximum-mean-discrepancy (MMD) of the network activations as a loss term for distillation.  \n\nWhen considering CIFAR image classification tasks, it is shown that only when using a specific quadratic polynomial kernel (which as described in https://arxiv.org/pdf/1701.01036.pdf is tantamount of applying neural style transfer) the proposed approach is able to match the performance of the seminal paper of Hinton et al.  When embarking to imagenet, the proposed approach is only able to match the performance of standard knowledge distillation by adding the quadratic term (texture in neural style synthesis jargon). This is actually a sensible proposal. Yet, the claims about MMD as a way of explaining neural style transfer has appeared in the paper cited above, which the authors mention.\n\nThe idea of transferring from one domain to another using MMD as a regularizer appeared in https://arxiv.org/pdf/1605.06636.pdf by Long et al --- indeed equation (3) of this paper matches exactly equation (10) of Long et al. Note too that Long et al also discuss what kernels work well and which work poorly due to vanishing gradients and propose parametrised solutions. This is something this paper failed to do.\n\nThe two works cited above make me wonder about the novelty of the current paper.  In fact, this paper ends us being an application of the neural style transfer loss function to network distillation. As such this could be useful, if not already done by someone else previously.\n\nI find that the paper is poorly written, with many typos, and lacks focus on a single concrete story. The CIFAR experiments fail to use KD+NST (ie the thing that works for imagenet - neural style transfer) and section 5.3 appears trivial in light of the cited works. For all these reasons, I am inclined to reject this paper.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n', 'This submission proposes a novel loss function, based on Maximum Mean Discrepancy (MMD), for knowledge transfer (distillation) from a teacher network to a student network, which matches the spatial distribution of neuron activations between the two.\n\nThe proposed approach is interesting but there is significant room for improvement. In particular:\n\n*Clarity*\n\nIt is not clear how the distribution of neuron activation are matched between the teach and student network. The C_T and C_S are not defined specifically enough. Does it include all layers? Or does it only include a specific layer (such as the last convolution layer)?\n\n*Interpretability*\n\nSection 4.1. tries to interpret the approach but it is still not clear why matching distribution is better. The MMD loss proposed could run into problem if the classification task does not involve ""spatial variation"". For example, for a extremely simple task of classifying three classes ""R"", ""G"" and ""B"" where the whole image has the same color of R, G and B respectively, the spatial distribution is uniform and the proposed MMD loss would be 0 even if the student network\'s channels do not learn discriminative feature maps. Another example is when a layer has H=W=1.\n\n*Significance*\n\nThe experiment shows that polynomial-two kernel gives better result, but Sec. 4.3.2. mentions that it is equivalent to Li et al. (2017b) in this case.\n\n*Practical usefulness not justified*\n\nIn the experimental section, the student network\'s number of parameters and FLOPS are not detailed, so it is unclear how much efficiency gain the proposed method achieved. Note in practice small networks such as MobileNet and ShuffleNet have achieved significantly better accuracy-efficiency trade-off than the teacher networks considered here (either for CIFAR10 or for ImageNet1k).\n\n*Improvement not significant*\n\nThe results obtained by the proposed approach is not very significant compared to ""KD"" along.']","[80, -70, -50]","[70, -20, 20]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' with 'good empirical results' and praises the discussion included. They highlight the extensive evaluation and interesting findings. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as questions (e.g., 'Can the author provide...'). The tone is professional and encouraging, without any harsh criticism. The reviewer balances positive comments with suggestions for improvement, maintaining a courteous and supportive tone throughout the review."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's novelty and contribution, ultimately recommending rejection. The reviewer points out several issues, including lack of originality, poor writing quality, and failure to improve upon existing methods. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. The reviewer directly states the paper is 'poorly written' and 'lacks focus,' and uses phrases like 'failed to do' without cushioning the criticism. However, the reviewer does provide some balanced feedback and acknowledges potentially useful aspects, preventing the score from being lower."", ""The sentiment score is -50 because the review starts with a mildly positive statement about the approach being 'interesting,' but then immediately follows with 'there is significant room for improvement' and lists several criticisms. The reviewer points out issues with clarity, interpretability, significance, practical usefulness, and the lack of substantial improvement over existing methods. These criticisms outweigh the initial positive comment, resulting in an overall negative sentiment. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh or rude expressions. They phrase criticisms as observations or questions rather than direct attacks. However, the score is not higher because the review is quite direct in its criticisms without much softening language or positive reinforcement.""]"
"['[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? somewhat\n\n[Novelty] Are the problems or approaches novel? reasonably\n\n[Soundness] Is the paper technically sound? yes, I think. I did not thoroughly check the equations.\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? somewhat\n\n[Clarity] Is the paper well-organized and clearly written? yes, except the experiments\n\nConfidence: 2/5\n\nSeen submission posted elsewhere: No (but I did find it on arXiv after writing the review)\n\nDetailed comments:\n\nIn this work, the authors propose a new type of memory cell for RNNs which account for multiple types of time series. In particular, the work combines uniformly sampled observations (“normal” RNN input), time-decaying observations, non-decaying observations which may change, and static features which are not time-dependent. Empirically, the proposed approach outperforms an RNN with TLSTM cells in some cases.\n\n=== Comments\n\nI found the proposed approach for incorporating the different types of time series reasonable. This work definitely leans heavily on ideas from TLSTM and others, but, to the best of my knowledge, the specific combination and formulation is novel, especially concerning the “non-decaying time series” observations.\n\n However, I had difficult coming up with an example of a “static decay feature”. It would be helpful to give a concrete example of one of these in the main text. (It is also not clear to me why the difference in time between the time of the last event in a sequence and the prediction time for that sequence would be considered a “static decay” feature rather than just a “static” feature.)\n\nMy main concern with the paper is that the experimental design and results are not especially easy to follow; consequently, they are not as convincing as they might be. First, the sparsity mechanism is rather simple. In many domains (e.g., the medical domain considered in several of the cited papers), missingness is non-uniform and is often meaningful. While “meaningfulness” may be difficult to simulate, burstiness (non-uniformity) could be simulated. Second, for the groups, it is not clear whether all combinations of, e.g., 2 (informative) feature were sparsely sampled or if only one group of 2 was chosen. If the former, then some measure of variance should be given to help estimate statistical significance. Third, the particular classification task here is, essentially, forecasting one of the input variables. While that is certainly a relevant problem, many other time series classification or regression problems are not tied so directly to observations. It is not clear if these results are relevant in that setting.\n\n=== Typos, etc.\n\nThe plots and figures in the paper are very difficult to read. Larger versions, or at least versions with increased fonts, should be used.\n', 'Summary\n========\nThe paper addresses the problem of irregular spacing in sequential data with five different irregularity types. The solution is based on modifying LSTM cell.\n\nComment\n========\nIrregular and multiple spacing presents in many real world applications with time-stamped events. The problem is therefore important to address properly. However, I found the evaluation of the proposed solution is less convincing. The main results in Figure 5 are not informative. \n\nThere have been related works addressing irregular and multiple spacing (not just missing data as cited in the paper):\n\n- Pham, T., Tran, T., Phung, D., & Venkatesh, S. (2016, April). DeepCare: A deep dynamic memory model for predictive medicine. In Pacific-Asia Conference on Knowledge Discovery and Data Mining (pp. 30-41). Springer, Cham.\n- Koutnik, J., Greff, K., Gomez, F., & Schmidhuber, J. (2014). A clockwork RNN. arXiv preprint arXiv:1402.3511.\n- Chen, C., Kim, S., Bui, H., Rossi, R., Koh, E., Kveton, B., & Bunescu, R. (2018, October). Predictive Analysis by Leveraging Temporal User Behavior and User Embeddings. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management (pp. 2175-2182). ACM.\n\n\n\n', ""The paper addresses limitations of the LTSM method for modeling time series. The work is motivated by applications where multiple time series need to be combined while they may get updated in an asynchronous fashion. Authors mention IoT applications in the Intro and give examples from a power consumption data set and a churn prediction application in their numerical experiments sections. \nThe paper's main contribution is to shrink down time series into 5 different categories which have different sampling schemes: (1) dense (2) sparse (3) decay (4) static decay (3) static standard, and proposing building blocks to incorporate these in a unified recurrent mechanism. \nThe paper's motivation for introducing sparse input to LTSM was rather straightforward and convincing, and the churn prediction application is an excellent motivation for this. I had a harder time following why the 3 other types of features needed to be included as well at this point. Perhaps a more problem oriented explanation with concrete examples could have helped. Or those features should not yet be used as generalizations but kept for future work.\nOverall I think the paper has several interesting ideas. Even though not all are as convincing, I think the paper is thought provoking and may interest the ICLR community."", 'This paper proposes a new type of recurrent neural network which takes into account five different features: in addition to the prevalent dense features, the author(s) also consider(s) sparse features, time features, global static and changing features. The differences in feature types are reflected in the cell state or output state update rules. Experiments on a modified UCI dataset and a proprietary dataset show that the proposed model outperforms the time-variant LSTM (TLSTM).\n\nPros:\n1. By decomposing the cell state into different components for different feature types (dense vs sparse, short term vs long term) and update them in different manners, the model takes advantage of the feature type information.\n2. By updating sparse feature related cell states only when sparse features are present, it could be potentially computationally cheaper than treating everything as dense (although in the paper due to more parameters the proposed model is actually slower).\n\nCons:\n1. The contributions are not significant. It seems that TLSTM already ""accounts for asynchronous feature sampling"" (Sec 1) and the novelty here lies most in how sparse features are treated.\n2. The presentation is sometimes confusing. For example, in Figure 5 which presents the main results, what\'s the ""relative change in F1 score"" and what\'s the unit in the plot? If it\'s percentage the gains seem to be too small and could be potentially due to the additional parameters. Besides, what does ""group sampling"" mean exactly? Furthermore, legend seems to be missing.\n3. Crucial implementation details are missing. The paper mentions that ""the number of features grows"" in the proposed model. Are sparse features and static features used or not in TLSTM? \n4. What\'s the difference between a static decay feature (Sec 3.5) and decay features (Sec 3.2)? Isn\'t the static decay feature varying with time as well?\n\nMinor comments:\n1. Figure 1 and 5 are too small and hard to read.\n2. Sec 3.3, ""updated based on Equation 1 and Equation 2"", but none of the equations are numbered in this paper.\n3. Some discussions on the proprietary dataset seem to be irrelevant. I\'d rather see how are sparse features generated for the UCI dataset.\n4. The decay function $g= 1 / log (e + \\alpha^T x_t^{\\delta})$, how can we make sure that as time passes it decreases as time passes?\n\n\nOverall, I think explicitly taking into account different feature types in the LSTM cell update rules is interesting, but the contributions of this paper compared to TLSTM are not significant enough for acceptance, and the presentation can be made more clear.']","[20, -20, 50, -50]","[60, 50, 75, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and soundness of the paper, and sees value in the approach. However, they express concerns about the experimental design and results presentation, which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'I found the proposed approach reasonable' and 'My main concern is...' which maintain a polite tone while still conveying critiques. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem, they express skepticism about the evaluation and results, stating they are 'less convincing' and 'not informative'. They also point out missing citations of related work, which implies the paper is incomplete. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They acknowledge the importance of the problem and provide constructive feedback by suggesting additional related works to consider. The tone is academic and objective, maintaining politeness while still conveying concerns about the paper's evaluation."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges interesting ideas in the paper and its potential to interest the ICLR community, despite some reservations. They mention the paper is 'thought provoking' and has 'convincing' aspects, but also note that not all ideas are equally convincing. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I think' to soften critiques and provide specific suggestions for improvement rather than harsh criticism. The tone is professional and considerate throughout the review."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('pros'), the overall tone is critical. The reviewer states that 'the contributions are not significant' and concludes that the paper is not strong enough for acceptance. This negative assessment outweighs the positive points mentioned. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They balance negative feedback with positive observations and use phrases like 'I think' to soften critiques. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a neutral, professional tone overall.""]"
"[""This paper shows that gradient descent mostly happens in a tiny subspace which is spanned by the top eigenvectors of the Hessian. Empirical results are shown to support the claim. This finding is interesting and provides us some insights to design more efficient optimization algorithms. Overall, this paper is interesting and easy to follow. \n\nThe experiments in section 2 do a decent job supporting the claim that gradient descent happens in a tiny subspace and the subspace is mostly preserved over long periods of training. However, I would like to add a couple more points to the discussion: \n\n- It's not surprising that the magnitude of gradient is larger in the high curvature directions, which means that the learning would always first happen in top subspace if the learning rate is small enough. It would be interesting to tune the parameter of learning rate to see if the phenomena would occur across different learning rate (especially large learning rate).\n- The argument of gradient descent happening in a tiny space is quite obvious if the Hessian has only a few large eigenvalues. Therefore, it would be interesting to discuss the spectrum of the Hessian a little bit.\n- Contrary to plain gradient descent, natural gradient is able to learn low curvature directions (small eigenvalues). It would be interesting to show some experiments with natural gradient methods.\n\nFollowing section 2, the authors give a toy model to further backup their claims. However, I find the example is too restrictive and may not explain why the subspace would be preserved over the training. If I understand right, the loss function of the toy model is convex and Hessian is a constant over time. For this kind of toy model, the Hessian (or equivalently the Fisher matrix) only depends on the input distribution, so it's easy to see that the Hessian would be low-rank and preserved throughout the training. However, neural networks are highly non-convex, so it's unclear to me whether the implications of the toy model would generalize. I encourage the authors to analyze more complicated models. \n\nTo summarize, I think this paper is interesting and well-written. However, it lacks convincing explanation why the subspace would preserve over the training (to me, it's more interesting than the point that gradient descent happens in tiny subspace). Anyway, it is not completely reasonable to expect all such possible discussions to take place at once. "", 'The authors build on recent works that study the spectrum of the Hessian of deep networks (e.g. Sagun et al). Previous work argues that Hessian is approximately low-rank i.e. there are few large eigenvalues and many small eigenvalues. This work argues that after some training, large eigenvectors of the Hessian converges to a subspace and stays there.\n\nIntuitively, this papers message makes sense and is interesting. I also agree with the tiny subspace argument in the paper. However, I am not convinced by a couple of things and I believe further evidence is necessary. \n\n1) Authors claim the top subspace has same rank k (where k=number of classes) and backs this up with linear classifier with 2 class (toy model). It is clear that any noiseless k-class linear classifier has its gradient lie on a k dimensional subspace. Similarly, for a deep network, I agree with hessian of the final layer will be rank k however earlier layers can have different ranks as a function of complexity of the lower level representations. My worry is that perhaps the Hessian of the final layer is somehow dominating over the other ones. Ideally, I would like to see analysis of individual layers to reach a conclusion. Is first layer also approximately rank k?\n\n2) Similarly, we need to see the eigenvalue distribution of the Hessian. Say there is a single very large eigenvalue and all others are small. The same claim would still hold. So it is not clear if number of classes really plays a role from the available experiments. This can indeed happen is the classes are correlated for instance. Authors can perhaps plot gradient over top k/2 subspace to reveal if their claim is specific to number of classes.', ""This paper describes an interesting phenomenon: that most of the learning happens in a small subspace. However, the experimental evidence presented in this paper is a bit lacking. The authors also cook up a toy example on which gradient descent exhibits similar behavior. Here are a few detailed comments:\n\n1. The Hessian overlap metric is suitable for showing the gradient lies in an invariant subspace of the Hessian, but does not show it lies in the dominant invariant subspace. \n2. There are well-established notions of distances between subspaces in linear algebra, and I suggest the authors comment on the connection between their notion of overlap between subspaces and these established notions.\n3. The authors make a few statements along the lines of ``the Hessian is small, so the objective is flat''. This is a bit misleading as it is possible for the gradient to be large but the Hessian to be small.""]","[60, -20, -20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer starts by highlighting the paper's interesting findings and its ease of understanding. They mention that the experiments 'do a decent job supporting the claim' and describe the paper as 'interesting and well-written'. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I would like to add', 'It would be interesting to', and 'I encourage the authors to', which maintain a polite and collaborative tone. The reviewer also acknowledges that it's not reasonable to expect all possible discussions in one paper, showing understanding towards the authors' constraints."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting aspects and intuitive message, they express significant doubts and request further evidence. The phrase 'I am not convinced' and the detailed critiques indicate a somewhat skeptical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits before presenting criticisms. They use phrases like 'I agree' and 'Ideally, I would like to see' which maintain a constructive tone. The reviewer also offers specific suggestions for improvement, which is a polite way to address concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper describes an 'interesting phenomenon', they also state that the 'experimental evidence presented in this paper is a bit lacking'. This indicates some reservations about the quality of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, such as 'interesting phenomenon' and 'I suggest', and provides constructive feedback without harsh criticism. The reviewer also balances positive and negative comments, which contributes to a polite tone. The specific recommendations are presented in a neutral, professional manner, further supporting the politeness score.""]"
"['This paper gives a new algorithm for learning a two layer neural network which involves a single convolutional filter and a weight vector for different locations. The algorithm works on any symmetric input data. The techniques in this paper combines two previous approaches: 1. the algorithm Convotron for learning a single convolutional filter (while the second layer has fixed weight) on any symmetric input distributions; 2. non-convex optimization for low rank matrix factorization.\n\nThe main observation in the paper is that if the overlap in the convolutions is not large (in the sense that each location of the convolution has at least one input coordinate that is not used in any other locations), then the weight that corresponds to the non-overlapping part and the weights in the second layer can be computed by a matrix factorization step (the paper gives a way to estimate a gradient that is similar to the gradient for a linear neural network, and then the problem is very similar to a rank-1 matrix factorization). After this step, we know the second layer and the algorithm can generalize the previous Convotron algorithm to learn the full convolutional filter.\n\nThis is an interesting observation that allows the algorithm to learn a two-layer neural network. On the other hand this two layer neural network is still a bit limited as there is still only one convolutional filter, and in particular there is only one local and global optimum (up to scaling the two layers). The observation also limited how much the patches can overlap which was not a problem in the original convotron algorithm. \n\nOverall I feel the paper is interesting but a bit incremental.', 'I believe the authors need to give more intuition on the importance of such a study, and how it can lead to improvement in real life application.\nThe work seems interesting but is limited and as the authors mentioned it might be a good start for further investigation. However, what I really wanted to see was a simple comparison on a dataset like MNIST with conventional CNN being trained via SGD, for example.\nAlso, there are some small typos you may need to fix, e.g ""will be play"" -> ""will be playing"".', 'This paper studies the theoretical learning of one-hidden-layer convolutional neural nets. The main result is a learning algorithm and provable guarantees using the algorithm.  This result extends previous analysis to handle the learning of the output layer weights, and holds for symmetric input distributions with identity covariance matrix.\n\nAt a high level, the proof works by using the non-overlapping part of the filter to reduce the problem to matrix factorization. \nThe reduced problem corresponds to learning a rank-one matrix, from which one can learn the output layer weight vector approximately. Given the output weight vector, then the hidden layer weight is learnt using the Convotron algorithm from previous analysis. I think that the technical contribution is interesting.\n\nWeakness: Given the existing work (Goel et al. 2018), I am concerned that the current work is a bit incremental. Secondly, it is unclear if the technical insight has any applications or not. How does the proposed algorithm work on real world data? Even some simple comparisons to other algorithms on a few datasets would provide insight.\n\nQuestion: Where does Assumption 3.2 arise in the proof? Is it necessary (for the proof)?\n\nOther issues: A few typos you may need to fix (e.g. the S notation in Thm 3.1, first sentence in Sec 4.3).\n']","[20, -20, 20]","[50, 50, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'interesting' and presents a balanced view of its strengths and limitations. They describe the main observation as 'interesting' but also note that the approach is 'a bit limited' and 'a bit incremental'. The overall tone is mildly positive but not enthusiastic. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present criticisms in a constructive manner, avoiding harsh or dismissive language. The review focuses on the content of the paper rather than making personal comments about the authors. The tone is respectful and objective, which is appropriate for a peer review."", ""The sentiment score is slightly negative (-20) because the reviewer expresses concerns about the study's importance and limitations. They suggest more intuition is needed and request additional comparisons, indicating the work is not fully satisfactory. However, it's not entirely negative as they acknowledge the work seems interesting and could be a good start for further investigation. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I believe' and 'what I really wanted to see,' which are polite ways to express opinions. The mention of typos is done gently. The overall tone is professional and courteous, even while pointing out areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the technical contribution as interesting and provides a detailed summary of the paper's approach. However, they also express concerns about the work being incremental and lacking real-world application, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I am concerned that...', 'it is unclear if...'), and offers helpful suggestions for improvement. The reviewer also asks a polite question about a specific assumption and points out typos in a non-confrontational manner.""]"
"['Summary\n=======\nThis paper introduces spread divergences. Spread divergences are obtained by taking the divergence between smoothed/noisy versions of two distributions. A spread divergence between two distributions of non-overlapping support can be defined even when the corresponding divergence is not. The authors discuss conditions under which the data generating process can be identified by minimizing spread divergences and apply spread divergences to the examples of PCA, ICA, and noiseless VAE.\n\nReview\n======\nWith a lot of papers focusing on generative modeling, divergence minimization is of great relevance to the ICLR community. Adding noise to distributions to ensure overlapping support is intuitive and has been used to stabilize training of GANs, but I am unaware of any work focusing on questions of identifiability and efficiency. I especially like the example of slowing EM in ICA with small noise. Here, some empirical results are lacking which analyze the speed/correctness of the identification of parameters for various choices of divergence/model noise. These would have greatly enhanced the paper. Instead, the available space was used to show model samples, which I find less helpful.\n\nIn Section 3.2 and Section 6 the authors argue that choosing noise which maximizes the spread divergence is optimal or at least preferable. This seems counterintuitive, given that the point of the noise was to make the distributions more similar. Please elaborate on why maximizing the divergence is a good strategy.\n\nMinor\n=====\nThe paper seems hastily written, with some grammar issues, typos, and sloppy use of LaTeX, e.g.:\n\n–\xa0""-\\log"" instead of ""\\log"" in definition of KL divergence in the introduction\n–\xa0""Section 2.2"" not ""section(2.2)"", ""Equation 24"" not ""equation(24)""\n–\xa0""model (Tipping & Bishop, 1999)"" instead of ""model Tipping & Bishop (1999)""\n–\xa0""\\mid"" instead of ""|""\n–\xa0""x"" instead of ""y"" in Equation 28\n\nPlease provide a reference for the EM algorithm of ICA.', '\nPros:\n\n- interesting idea.\n\nCons:\n\n- the paper forgets the state of the art for comparisons (optimal transport, data processing inequalities)\n- the paper formally shows little as most results are in fact buried in the text and it is hard to tell the formal from the informal.\n- experiments fall short of really using the setting proposed\n- the paper focuses too much on keeping the identity of the indiscernibles and forgets the study of other properties (including downsides, such as variance increase)\n\nDetail:\n\n* The paper claims to propose a ""theory"" for spread divergences (conditioning a f-divergence by a ""third-party"" conditional distribution on supports which makes supports match) still keeping the identity of indiscernibles. \n\n* The paper recycles the notion of Spread f-divergences from Zhang et al. (which makes a circular reference to this paper for the introduction of these divergences).\n\n* The paper motivates the notion of spread divergences by the fact that f-divergences impose matching supports (Section 1), not mentioning that optimal transport theory is a much natural fit for any such kind of setting (e.g. Wasserstein distances). This is a big omission and a missed occasion for a potentially interesting discussion.\n\n* The paper then claims that ""spread noise makes distributions more similar"" (Section 2.1), not mentioning that equation (8), which it claims to have been shown by Zhang et al. paper (see below), is in fact a data processing inequality *long known*. They will find it, along with a huge number of other useful properties, in series of IEEE T. IT papers, among which Pardo and Vajda\'s ""About distances of discrete distributions satisfying the data processing theorem of information theory"",  Van Erven and Harremoes, ""Re ́nyi Divergence and Kullback-Leibler Divergence"" (for the KL / Rényi divergence, but you have more references inside), etc. .\n\n* The paper then goes on ""showing"" (a word used often, even when there is not a single Theorem, Lemma or the like ever stated in the paper...) several properties (Section 2.2). The first states that (9) is equivalent to P being invertible. It is wrong because it is just in fact stating (literally) that P defines an injective mapping. The second states that (11) is equivalent to (12), without the beginning of a proof. I do need to see a proof, and in particular how you ""define"" an invertible transform ""p^-1"".\n\n* The paper then gives two examples (Sections 3, 4). In Section 3, I am a bit confused because it seems that p and q must have supports in IR, which limits the scope of the example. The same limitation applies to Section 4, even when it is a bit more interesting. In all cases, the authors must properly state a Lemma in each Section that states and shows what is claimed before Section 3.\n\n* The paper then makes several experiments. Unless I am mistaken, it seems that Section 5.1 relies on a trick that does not change the support from x to y. Therefore, what is the interest of the approach in this case ? In Section 5.2, isn’t the trick equivalent to considering ICA with a larger \\gamma ?\n\n* A concern is that the paper says little about the reason why we should pick one p(y|x) instead of another one. The focus is on the identity of indiscernibles. The paper also forgets some potential drawbacks of the technique, including the fact that variance increases — the increase can be important with bad choices, which is certainly not a good thing.', 'This paper proposes a way to define f-divergences for densities which may have different supports. While the idea itself is interesting and can be potentially very impactful, I feel the paper itself needs quite a bit of work before being accepted to a top venue.  The writing needs quite a bit oof polish for the motivations to clearly stand out. Also, some of the notation makes things way more confusing that it should be. Is it possible to use something other than p() for the noise distribution, since the problem itself is to distinguish between p() and q(). I understand the notational overload, but it complicates the reading unnecessarily. I have the following questions if the authors could please address:\n\n1) The inequality of Zhang et a. (2018) that this paper uses seems to be an easy corollary of the Data Processing Inequality :https://en.wikipedia.org/wiki/Data_processing_inequality Did I miss something? Can the authors specify if that is not the case?\n\n2) In terms of relevance to ICLR, the applications of PCA, ICA and training of NNs is clearly important. There seems to be a significant overlap of Sec 5.3 with Zhang et al. Could the authors specify what the differences are in terms of training methodology vis-a-vis Zhang et al? It seems to me these are parallel submissions with this submissions focussing more on properties of Spread Divergences and its non deep learning applications, while the training of NNs and more empirical evidence is moved to Zhang et al. \n\n3) I am having a tough time understanding the derivation of Eq 25, it seems some steps were skipped. Can the authors please update the draft with more detail in the main text or appendix ?\n\n4) Based on the results on PCA and ICA, I am wondering if the introduction of the spread is in some ways equivalent to assuming some sort of prior. In the PCA case, as an exercise to understand better, what happens if some other noise distribution is used ? \n\n5) I do not follow the purpose of including the discussion on Fourier transforms. In general sec 3 seems to be hastily written. Similarly, what is sec 3.2\'s goal ? \n\n6) The authors mention the analog to MMD for the condition \\hat{D}(p,q)=0  \\implies p =q. From sec 4, for the case of mercer spread divergence, it seems like the idea is that  ""the eigenmaps of the embedding should match on the transformed domain"" ? What is [a,b] exactly in context of the original problem? This is my main issue with this paper. They talk about the result without motivation/discussion to put things into context of the overall flow, making it harder than it should be for the reader. I have no doubt to the novelty, but the writing could definitely be improved.']","[50, -70, -30]","[60, -20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper's topic and appreciates certain aspects ('I especially like...'), but also points out some lacking elements and areas for improvement. The overall tone is constructive rather than dismissive. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the paper's relevance, and frames criticisms as suggestions or questions rather than harsh judgments. The reviewer also provides specific, helpful feedback for improving the paper, which is a polite gesture. However, the score isn't higher due to the direct mention of grammar issues and typos, which, while valid, could be seen as slightly impolite if not carefully worded."", ""The sentiment score is -70 because the review is predominantly negative. While it acknowledges an 'interesting idea', the majority of the review focuses on significant shortcomings, including omissions of state-of-the-art comparisons, lack of formal proofs, limited experiments, and overlooked drawbacks. The reviewer uses strong negative language like 'falls short', 'forgets', and 'wrong'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. Phrases like 'It is wrong' and 'I do need to see a proof' come across as somewhat abrupt and demanding. The reviewer also uses sarcastic quotation marks around 'showing', which adds to the negative tone. However, the review isn't overtly rude, maintaining some level of academic decorum, which is why the score isn't lower."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the idea is interesting and potentially impactful, they express several concerns about the paper's writing, clarity, and content. They state the paper 'needs quite a bit of work before being accepted' and list multiple areas for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms constructively, and asks questions politely (e.g., 'Could the authors specify...', 'Can the authors please update...'). They also acknowledge positive aspects before giving criticism. However, the score is not higher as the review is still direct in its critique and doesn't use overly deferential language.""]"
"['This paper proposes an effective attack technique for the widely used optical flow based classification models in white-box and black-box settings. The most interesting result is on the sparsity and frame salience, which could have a lot of applications. But the main idea is to transfer the standard attack techniques from image to video domain. I have some concerns as below. \n\n1. Page 3, ""...while the temporal stream alone achieves 83.7%. Thus, if the motion stream can be fooled, the entire model is compromised.""\n\nThis statement is not exactly correct. Motion stream is better on UCF101 and HMDB51 dataset, which are two medium scale action recognition dataset. On other large-scale datasets like Sports1M, Kinetics, ActivityNet, etc., motion stream performs much worse than spatial stream. Hence, the motivation of the paper is unclear. Especially for real-world applications, due to real-time requirement, people usually just use the spatial stream. Hence, the current flow attack setting has limited usage. It is very important to show attack results on spatial stream as well. \n\n2. For FlowNet2, authors use gradient of the loss wrt the input images. However, FlowNet2 is a very large network consisting of 5 FlowNets. I am curious what the gradients will look like after the long back-propagation. Can authors comment on this by drawing a figure of magnitude distribution of gradients in the very early layers? \n\n\nDue to limited novelty, I recommend an initial rating of 5. \n\n\n\n', 'Summary:\nThis paper presents a framework for generating adversarial perturbations for videos. Specifically, the paper proceeds by using a standard image-based adversarial noise generation setup (such as the FGSM scheme), and applies it to the motion stream of a two-stream action recognition pipeline; this motion stream typically using optical flow images. As such flow generation is usually done offline and thus is not differentiable, the paper resorts to the recent FlowNet 2.0 scheme that uses an end-to-end learnable deep flow generation model. Three variants of the scheme are provided, (i) that perturbs all frames in a flow stack, (ii) that perturbs only a sparse set of frames as decided by the importance of a frame to action classification, and (iii) a variant of (ii) that recalculates the gradients for all frames if the ones selected in (ii) were not adversarial. Experiments are provided on UCF101 dataset and show promise. Analysis is presented on the transferability of  the learned noise to flow images generated via external means.\n\nStrengths:\n1) The different variants of the scheme and sparse selection of the frames to be perturbed are interesting. \n2) The paper makes some interesting observations, namely that (i) only a single frame perturbation might be sufficient to make the video adversarial, and (ii) perturbations computed via FlowNet models are not transferable to those with flow computed via external software -- which is often the practice.\n\nWeaknesses:\n1) I think the main weakness of this paper is the lack of any surprise/significant novelty in the presented approach. The main idea follows the common trend in adversarial noise generation for image classification problems, except that the inputs are a stack of frames instead of  a single one; however, such a setting do not seem to bring along any non-trivial challenges. In the second contribution of this paper -- on the sparse selection of frames to attack, there is a lack of clarity in how one would do the iterative attacks at test time, given such sparse frame selection is done via computing the frame level saliency values via the classification loss, which depends on ground truth class labels, which are unavailable at test time. \n\n2) There are previous works that have attempted video level adversarial perturbation generation, which the paper do not cite or contrast to; such as a few below. Further, the literature survey fails to provide any compelling motivation as to why video perturbation generation is any difficult than image based noise generation -- it does not appear so from the subsequent text that this problem deserves any special treatment in the considered context.\n[a] Learning Discriminative Video Representations Using Adversarial Perturbations, Wang and Cherian, ECCV 2018\n[b] Sparse Adversarial Perturbations for Videos, Wei et al., arxiv, 2018\n\n3) It is unclear why the paper chose to consider flow produced by a FlowNet model as their inputs for the attack? Why not consider the flow images directly? Of course, the optical flow algorithm may not be differentiable, but that is perhaps besides the point; the focus should be in perturbing flow, in whatever way it is generated. To that end, given that flow (on static camera images) can be sparse, it would be interesting to see how would a perturbation be generated that needs to operate on local regions (where motion happens). In my opinion, using a FlowNet model for flow generation trivializes the proposed algorithm.\n\n4) It could have been interesting if the paper also provided some qualitative results of the optical flow images generated by FlowNet after adding perturbations to the input frames. Are these flow images also quasi-impercitable? \n\nOverall, I think the paper has some observations that may be slightly interesting; however, it lacks novelty and the analysis or presentation are unconvincing.', 'The paper addresses the problem of adversarial attack for an optical-flow-based action recognition in both the white-box setting (i.e., gradients are available) and the black-box settings (i.e., the gradients cannot be computed by the optical flow algorithm). A video is partitioned into fixed-size temporal intervals, a state-of-the-art deep optical flow estimator is applied on each pair of two consecutive frames within the interval, and perturbations are applied to each frame (or selected frames using saliency cues) within the interval to attack the recognition system using Fast Gradient Sign Method (FGSM). Experiments are carried out on the UCF-101 dataset, in the white-box and black-box settings, and show that the method is able to effectively attack the system.\n\nStrengths:\n- Considering the relatively unexplored problem of attacking action recognition in the temporal domain .\n- Extending the Fast Gradient Sign Method (FGSM) to the temporal domain\n\nWeaknesses:\n - Novelty seems incremental. What appears to be novel is the extension of FGSM from image classification to action recognition (i.e., Sec 3.2) -- specifically, the gradient computation through both the action classifier and the optical flow estimator.  The paper proposes a simple solution that incorporates an existing differential deep optical flow network (FlowNet2.0) into another existing differential action classification model (TwoStream Network). Combining two existing networks seems insufficient for the problem statement as explained next.\n\n- Experiments seem unconvincing. Sec. 5.1 and 5.2 present effectiveness of the proposed attacking approach when using FlowNet2.0 as the optical flow estimator. However, the attacking effectiveness (i.e.,  accuracy drop) may be a consequence of using FlowNet2.0 which is known to be sensitive to additive perturbations.  FlowNet2.0-based action recognition is more sensitive to the perturbations than other methods like TVL1 and Far. \n\n']","[-30, -60, -20]","[20, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper ('The most interesting result is on the sparsity and frame salience'), they express several concerns and criticisms. The reviewer states that the main idea is not novel ('to transfer the standard attack techniques from image to video domain') and concludes with a low rating recommendation ('Due to limited novelty, I recommend an initial rating of 5'). These critical points outweigh the positive aspects, resulting in a slightly negative sentiment overall. The politeness score is 20 because the reviewer uses generally respectful language and frames criticisms as 'concerns' rather than outright flaws. They also ask for the authors to comment on certain aspects, showing engagement with the work. However, the tone remains professional rather than overtly polite, hence a moderately positive score."", ""The sentiment score is -60 because the review is overall quite negative. The reviewer states the paper 'lacks novelty' and the analysis is 'unconvincing'. They list several weaknesses and criticisms, though they do acknowledge some strengths and 'slightly interesting' observations. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They phrase criticisms as observations or suggestions rather than harsh judgments. For example, they say 'I think the main weakness...' and 'It could have been interesting if...' rather than using blunt or rude phrasing. The reviewer also acknowledges some positive aspects before diving into criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out significant weaknesses. The review starts positively by describing the paper's approach and noting its strengths, but then lists more substantial weaknesses, questioning the novelty and experimental validity. This suggests an overall slightly negative sentiment towards the paper. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present both strengths and weaknesses objectively without using harsh or dismissive language. The reviewer provides constructive criticism and explains their concerns clearly and respectfully, maintaining a polite tone even when pointing out limitations.""]"
"['The primary purpose of this paper, from what I understand, is to show that fake samples created with common generative adversarial network (GAN) implementations are easily identified using various statistical techniques. This can potentially be useful in helping to identify artificial samples in the real world.\n\nI think that the reviewers did an excellent job of probing into different statistical perspectives, such as looking at the continuity of the distribution of pixel intensities and the various higher moments of spectral data. I also must applaud the fact that they did not relegate themselves to image data, but branched out to speech and music data as well.\n\nOne of the first findings is that, with MNIST and CIFAR, the pixel intensities of fake samples are noticeably different when viewed from the perspective of a Kolgomorov-Smirnov Test or Jensen-Shannon Divergence comparison. This is an interesting observation, but less so than it would be if compared to something such as a variational autoencoder (VAE), which fits a KL distribution explicitly. IWGAN and LSGAN are using different metrics in their loss functions (such as Wassertein and least squares), and thus the result is not surprising or novel. I think if the authors had somehow shown how they worked their metrics into IWGAN or LSGAN to achieve better results, this could have been interesting.\n\nAnother observation the authors make is about the smoothness of the GAN distributions. This may not be so easily wrapped into the loss function, but it seems easily remedied as a post-processing step, or perhaps even a smoothing layer in the network itself. Nevertheless, this is an observation that I have not seen discussed in the literature so there is merit to at least noting the difference. It is confusing that on page 4, the authors state that they hypothesized that the smoothness was due to the pixel values themselves, and chose to alter the distribution of the original pixels in [0,1]. However, they state that in Figure 5, the smoothness remained ""as expected."" Did the authors misspeak here?\n\nI found the music and speech experiments very interesting. The authors note that the synthetic Bach chorales, for instance, introduce many transitions that are not seen in the training and testing set of real Bach chorales. This, again, is interesting to note, but not surprising as the authors are judging the synthetic chorales on criteria for which they were not explicitly optimized. I do not believe these observations to be paper-worthy by themselves. However, the authors I believe have a good start on creating papers in which they specifically address these issues, showing how they can create better synthetic samples by incorporating their observations.\n\nAs to the writing style, there are many places where the writing is not quite clear. I would suggest getting an additional party to help proofread to avoid grammatical mistakes. I do not believe that the mistakes are so egregious as to impede understanding. However, it could distract from the importance on the authors future innovations if not corrected.\n\nOne last note. The title of the paper is ""TequilaGAN: How to Easily Identify GAN Samples."" This makes it seem as if the authors were introducing another type of GAN, like LSGAN or DCGAN. However, they are not. As a matter of fact, nowhere else in the paper is the word ""TequilaGAN"" mentioned. This title seems a bit sensational and misleading.\n\nIn the end, although I did find this paper to be an interesting read, I cannot recommend it for publication in ICLR.\n\n----\n\nEdit - November 29, 2018: Increasing my rating from a 4 to a 5 after discussion with the authors. Though their insights are not unknown, I think the authors are right in the fact that this is not explicitly discussed, at least not in the peer-review research with which I am familiar. But I don\'t think this by itself merits an ICLR publication.', ""The ability to detect generated samples is a very interesting topic and has recently triggered a lot of discussion. The paper is well written, easy to follow and the authors have done an extensive evaluation in a number of different GAN applications.\n\n\nComments:\n\n1) Methodology - The GANs being evaluated were trained ignoring the statistics that the authors use to detect generated samples, and thus it is expected that there will be a difference. Have the authors attempted to include those in the loss function? It is a fair argument to say that some are not differentiable, but there are ways one could still incorporate them e.g. using REINFORCE. What do the authors thing about that?\n\n2) Following (1), as far as the specifications are known one could train a GAN to fake them. What do the authors think about that? Do the authors think they could detect samples from that or such statistics could be used to devise better GAN losses?\n\n3) The authors conclude that the smoothness and the differentiability of a loss function will always result to an inductive bias. However, that's an assumption given that there are no experiments trying to fake the detection, or experimenting with a large number of different architectures.\n\n4) In CIFAR10 the authors state that the distributions of pixels was quite different specially in the values close to -1. Another way to see neural networks is as differentiable compressors. Many times, value distortions are correlated to the amount of compression. Have the authors seen differences in e.g. larger architectures?\n\n5) On a last note, I would change the title as there is no proof that these tests / assumptions would hold for further research in the field. It would be great to show that the statistics used to detect GAN samples cannot be tricked.\n\nMinor comments:\n1) p.1 In the context of Verified Artificial IntelligenceSeshia [...] - needs a space.\n2) p.3 Spectral centroid in 2 [...] - 2 -> Figure 2.\n3) p.7 Figure 8 doesn't have a caption.\n4) P.7 There are some figures above SPEECH without a figure number.\n5) P.7 Reference to table 9b seems to be missing."", ""The paper proposes statistics to identify fake data generated using GANs based on simple marginal (summary) statistics or formal specifications automatically generated from real data. The proposed statistics mostly boil down to the fact that continuous-valued generator neural networks can’t adequately generate data distributions that are topologically different from the distribution in the latent z-space. The differences in the summary data/ feature statistics and statistics corresponding to formal specifications between fake and real data are of the above nature. \n\nThis seems fairly obvious but I haven’t seen this property of GANs being exploited to distinguish between GAN generated and real-data\n\nThis property/ shortcoming of the generator is not surprising at all and has been acknowledged before. See, for example, the discussions in,\n\nKhayatkhoei et al, Disconnected Manifold Learning for Generative Adversarial Networks, arXiv:1806.00880 (NIPS, 2018)\n\nThis has spurred various approaches to mitigate this shortcoming. See, for example,\n\nBen-Yosef and Weinshall, Gaussian Mixture Generative Adversarial Networks for Diverse Datasets, and the Unsupervised Clustering of Images, arXiv:1808.10356\n\nJang, Gu and Poole, Categorical Reparameterization with Gumbel-Softmax, arXiv:1611.01144 (ICLR 2017)\n\nSo, the fact that summary statistics predicated on discreteness of data or discreteness of their dependencies can distinguish GAN-generated data from real data is not surprising at all. In fact, in the paper itself, figure 10 and 11 show that for continuous data like speech, the proposed statistics are unable to distinguish between the fake and real data. \n\nBeyond this, even though it's interesting, there isn’t enough contribution in the paper.  It would be great if the authors can extend this observation and show if such statistics can always be found and tricks like Gumbel-Softmax/ GMM-GANs etc are doomed to fail or if certain extentions of GAN architectures can handle such statistics.\n\nFurthermore, the paper needs to provide more clarity/ clarifications about the following:\n\n1.\tApart from formal specifications, the rest of the statistics are ad-hoc (e.g. the spectral centroid or the spectral slope which are just borrowed from the audio domain) – why should these be good for images? \n2.\tTraining choices do not seem principled – GANs are trained till generated samples look like real samples. Why not use parameter settings and train to produced state of the art results with chosen architectures?\n3.\tFigure 1: Why does the CDF for the real data start in the middle of the figure? The figure purportedly shows bimodal 1D data for which the CDF should be a step function whereas the reference data has an inclined line. Why?\n4.\tUsing the term ‘spectral’ (centroid and slope) for image features is misleading when spectral features are not computed.  Do these features capture spectral properties of images. How? Why are these good features?\n5.\tWhat does an “asymptotically converging activation function” mean?\n\n6. Some typos need to be corrected. Figure # and caption (with dataset name) for Figure 6 needs to be provided, etc.\n""]","[-20, 70, -30]","[60, 80, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer found the paper interesting and praised some aspects, they ultimately cannot recommend it for publication and pointed out several shortcomings. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive feedback. They use phrases like 'excellent job', 'must applaud', and 'interesting observation', while also clearly stating criticisms in a professional manner. The reviewer balances positive and negative comments, and even increases their rating after discussion with the authors, showing openness to dialogue."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive statement about the topic being 'very interesting' and mentions that the paper is 'well written, easy to follow' with 'extensive evaluation'. The overall tone is constructive and appreciative of the work. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, poses questions in a considerate manner (e.g., 'What do the authors think about that?'), and offers suggestions politely. The review maintains a professional and courteous tone, even when pointing out areas for improvement or raising concerns. The use of phrases like 'It would be great to...' and the inclusion of minor comments at the end further demonstrate the reviewer's politeness and attention to detail."", ""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they express significant criticisms and limitations. The reviewer states that the main finding 'seems fairly obvious' and 'is not surprising at all'. They also mention that 'there isn't enough contribution in the paper'. However, it's not entirely negative as they do suggest ways to improve and extend the work. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'It would be great if the authors can...' and asking clarifying questions rather than making harsh criticisms. They also provide constructive feedback and suggestions for improvement. However, the language is not overly polite or deferential, maintaining a neutral academic tone for the most part.""]"
"['In this paper, the authors investigate the accuracy-efficiency tradeoff for neural language models. In particular, they explore how different compression strategies impact the accuracy (and flops), and more interestingly, also how it impacts the power use for a RaspberryPi. The authors consider the QRNNs and SRUs for this purpose and use standard datasets for their analysis. I am torn about this paper. On one hand, I feel that the analysis is interesting, thoughtful and detailed; the power usage statistics bring a different perspective to the compression community. The section on inference time pruning was especially interesting to read. On the other hand however, there is limited novelty in the setup. The authors use standard, well known, compression algorithms on common neural language modeling architectures and datasets and use out-of-the-box tools for their ultimate analysis. Further, the paper needs additional work before it can be accepted in my opinion. I detail my arguments below:\n\n- The authors begin by discussing SwiftKey and similar apps but I\'m not sure if its clear that they use neural language modeling as the backend. Do the authors have a source to validate this claim?\n- Knowledge distillation is another algorithm that has been found to be quite competitive in compressing models into smaller versions of themselves. Have the authors experimented with that? \n- The R@3 is an good metric but I suggest that the authors look at mean reciprocal rank (MRR) instead. This removes the arbitrary-ness of ""3"" while ensuring that the metric of interest is the accuracy and not probability of being correct (perplexity). \n- Can you comment on the sensitivity of the results to the RPi frameworks? For instance, the RPi deployment tools, architecture, and variance in the predictions? \n- Along the same line, I\'m curious how generalizable the RPi results are for other computing architectures. For those of us who are not experts on hardware, it would be nice to read about whether similar tradeoffs will exist in other architectures such as mobile phones, GPUs or CPUs. \n- Could the authors add some meta-analysis about the results? If the perplexity goes up as a consequence of compression, what kinds of tokens it that localized to? Is it primarily rare words that the model is less confident about, or are the probabilities for most words getting skewed?\n- Finally, I feel that such an exploration will catch on only if the tools are open-sourced and made easy to replicate/use. If there were a blog or article summarizing the steps needed to replicate the power measurement (including sources from where to buy the necessary hardware), more people would be inclined on adding such an analysis to future neural language modeling work. \n\nI am willing to revisit my rating, as necessary, once I read through the rebuttal. \n\n\nUPDATE:\n\nAfter reading the rebuttal, I am increasing my score to 6. The authors alleviated some of my concerns but my major concerns about their novelty and the impact of their results remains. ', ""This paper proposes to evaluate the accuracy-efficiency trade off in QRNN language model though pruning the filters using four different methods. During evaluation, it uses energy consumption on a Raspberry Pi as an efficiency metric. Directly dropping filters make the accuracy of the models worse. Then the paper proposes single-rank update(SRU) method that uses negligible amount of parameters to recover some perplexity. I like this paper focuses on model's performance on real world machines.\n\n1) The proposed approaches just work for QRNN, but not for many other neural language models such as LSTM, vanilla RNN language models, the title could be misleading. \n\n2) In the experiment section, I think one baseline is needed for comparison: the QRNN language model with a smaller number of filters trained from scratch. With this baseline, we can see if the large number of filters are needed even before pruning.\n"", ""This paper presents an investigation of perplexity-efficiency tradeoffs in deploying a QRNN neural language model to mobile devices, exploring several kinds of weight pruning for memory and compute savings. While their primary effort to evaluate pruning options and compare points along the resulting tradeoff curves doesn't result in a model that would be small and fast enough to serve, the authors also introduce a clever method (single-rank weight updates) that recovers significant perplexity after pruning.\n\nBut there are many other things the authors could have tried that might have given significantly better results, or significantly improved the results they did get (the top-line 40% savings for 17% perplexity increase seems fairly weak to me). In particular:\n\n- The QRNN architecture contains two components: convolutions alternate with a recurrent pooling operation. The fact that the authors report using a PyTorch QRNN implementation (which runs on the Arm architecture but doesn't contain a fused recurrent pooling kernel for any hardware other than NVIDIA GPUs) makes me afraid that they used a non-fused, op-by-op, approach for the pooling step, which would leave potentially 10 or 20 percentage points of free performance on the table. The QRNN architecture is designed for a situation where you already have optimized matrix multiply/convolution kernels, but where you're willing to write a simple kernel for the pooling step yourself; at the end of the day, pooling represents a tiny fraction of the QRNN's FLOPs and does not need to take more than 1 or 2 percent of total runtime on any hardware. (If you demonstrate that your implementation doesn't spend a significant amount of time on pooling, I'm happy to bump up my rating; I think this is a central point that's critical to motivating QRNN use and deployment).\n\n- Once pooling is reduced to <2% of runtime, improvements in the convolution/matmul efficiency will have increased effect on overall performance. Perhaps your pruning mechanisms improved matmul efficiency by 50%, but the fact that you're spending more time on pooling than you need to has effectively reduced that to 40%.\n\n- Although the engineering effort would be much higher, it's worth considering block-sparse weight matrices (as described in Narang et al. (Baidu) and Gray et al. (OpenAI)). While this remains an underexplored area, it's conceivable that block-sparse kernels (which should be efficient on Arm NEON with block sizes as low as 4x4 or so) and blockwise pruning could give more than a 50% speedup in convolution/matmul efficiency.\n\n- In a real-world application, you would probably also want to explore quantization and distillation approaches to see if they have additional efficiency gains. Overall results of 10x or more wall clock time reduction with <5% loss in accuracy are typical for domains that have seen more optimization for mobile deployment (especially mobile-optimized CNNs like MobileNet), so I think that's entirely possible for your application.""]","[-20, 50, -20]","[60, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting, thoughtful and detailed analysis'), they express significant concerns about the paper's novelty and need for additional work. The phrase 'I am torn about this paper' indicates mixed feelings, but the overall tone leans negative with statements like 'limited novelty' and 'needs additional work before it can be accepted'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive feedback, and expresses willingness to reconsider their rating. They use phrases like 'I suggest', 'I'm curious', and 'Could the authors' which maintain a polite tone while providing criticism. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite approach to criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the paper's focus on real-world performance, stating 'I like this paper focuses on model's performance on real world machines.' However, they also point out limitations and suggest improvements, which balances the overall sentiment. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism without harsh or dismissive language. They use phrases like 'I think' when suggesting improvements, which maintains a polite tone. The review is structured and professional, providing specific recommendations without being overly critical or negative."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express significant concerns about missed opportunities and potential improvements. The reviewer suggests that the results are 'fairly weak' and lists several areas where the authors could have done better. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I'm happy to bump up my rating' and 'it's worth considering'. They offer constructive criticism and suggestions rather than harsh criticism. The reviewer also acknowledges the potential difficulty of some suggestions ('the engineering effort would be much higher'). Overall, the review is critical but expressed in a respectful and helpful manner.""]"
"['The authors argue that catastrophic forgetting may cause mode collapse and oscillation, and propose a novel plug-and-play  regularizer that can be applied to a variety of GANs\' training process to counter catastrophic forgetting of the discriminator. The regularizer is a clever adaption of EWC and IS into the context of GAN training. With the authors\' formulation, this regularizer will account for the discriminator\'s parameter from all previous ""tasks"" (snapshots taken at certain iterations) with extra memory budget of only one set of parameters, while assigning higher regularization strengths to parameters learned from recent tasks. Experiments demonstrate such regularizer improves GAN models including DCGAN, SN-DCGAN, WGAN-GP on image generation tasks and textGAN on text generation tasks.\n\nPros:\nThe paper is well-written. The formulation of online memory and controlled forgetting are clever, giving rise to the adaption of EWC and IS as a practical regularizer to overcome the problem of catastrophic forgetting in GANs. The experiments also demonstrate the regularizer is superior than historical averaging and SN on the synthetic dataset, and it is able to improve multiple GAN models in both image and text generation tasks.\n\nCons/Suggestions:\n1. Although I can see the method is working, the empirical evidence to support ""mode oscillation"" is not strong enough for me. I think in order for continual learning to make perfect sense, mode oscillation should be an obvious issue for GANs; otherwise, we probably don\'t need remembering the history, as the generator is probably evolving towards the right direction even in the vanilla approach. Still, since there have been several papers showing history is important, it should be helpful in some sense. In Figure 1, I cannot tell whether in (d), the generator returned to the previous space (probably refers to (a)). Even the centers of mass of (a) and (d) look different for me. Figure 2 (left) only shows the distribution of generated data is changing as the training proceeds in vanilla GANs, since few of them (some shallow blue lines) have low peaks in previous datasets. If the mode oscillates and the generator returns to previous state, there should at least be another peak along the line, which is missing in curves on later datasets (darker blue ones). (I guess I have understood this figure correctly, but Figure 2 seems horizontally flipped to me. Since you are testing on previous fake datasets, and the accuracy should drop on previous datasets; however, the accuracy drops on later datasets in the figure.)\n\n2. I doubt the authors may not have tried enough sets of hyper parameters for baseline models. In table 1, the variance of GAN, GAN + l2 weight and GAN + SN are significantly higher than the others. I don\'t think with l2 weight regularizer, the model will be much more unstable than the authors\' approach.\n\n3. The authors didn\'t give the results of their regularizer with LeakGAN on text generation. Currently their model has lower test BLEU than LeakGAN, which indicates lower fluency, but its self BLEU is lower than LeakGAN, which indicates higher diversity. It would be much better if the proposed method can surpass LeakGAN on both metrics.\n\n4. Using inception score on mixture of eight Gaussians may not make much sense, if they are using the ImageNet pre-trained model, since such a model is not trained to fit this distribution. Still, the author has reported symmetric KL. \n\n5. The authors did not specify their inception score on real Celeb-A and CIFAR10 images. \n\n\nOverall, I tend to accept this paper for its contribution on methods. It would be even better if my concerns could be addressed.\n\nEdit: after seeing the review of Reviewer 3, I find the proposed method seems to be the same as Online EWC and I have downgraded the rating. The authors should address these concerns.', ""This paper connects continual learning and GAN training together, and propose to use standard continual learning schemes (EWC etc) to improve GAN training.\n\nContinual learning for GANs is certainly an important problem to look at. Even though I like the problem, I'm not convinced with the solution provided by the paper. \n\nThe paper in it's current form, in terms of technical contributions and experimental analyses presented to support the hypotheses it started with, is not good enough to be accepted in ICLR. My comments:\n\n1) Catastrophic forgetting of discriminator: Interesting view about mode collapse. I have following concerns:\n(a) I like the view in which the training is shown as a sequential process. I wonder if we could solve the issue of catastrophic forgetting of discriminator by storing sufficient fake examples from previously generated samples from the generator. Storing previous generations has already been explored, however, just to prove the point that forgetting is an issue, it would be interesting to store enough samples for the mixture of Gaussian setting and analyse.\n\n(b) Why not thinking of catastrophic forgetting of generator? What if we constrain the generator to not-to-forget about previously generated samples by Fisher or something similar? In this case, every new task in the training process will have sufficient fake samples from all the modes.\n\n2) Lack of technical contributions: The approach, in which EWC or IS is being used to regulate the discriminator's parameters, seems to be straightforward. The issue of multiple parameters is being resolved by storing one Fisher/Score vector using moving average type scheme. This, to me, is almost same as Online EWC or EWC++. Both these papers have already addressed this issue and discussed them in great detail. How is this approach different?\n\n3) Not sure what exactly Fig 2 is conveying as D_1^{gen}, \\cdots, D_T^{gen} should almost be the same, so training on one and testing forgetting on other doesn't actually say much. I think we can't conclude anything from this figure, at least using MNIST experiments.\n\nMinor:\n4) I'm assuming that you call your method EWC/IS GAN (I think it wasn't explicitly mentioned in the paper). Why don't you call Seff et al. 2018 (they used EWC with GAN for the first time) work EWC-GAN? I personally feel that it's important to give acronyms so that it doesn't undermine previous works. Just to clarify, I'm not advocating the work by Seff et al..\n\n5) Please provide citations for mode collapse\n\nOnline EWC: Progress & compress: A scalable framework for continual learnin, ICML 2018.\nEWC++: Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence, ECCV 2018.\n"", ""Summary:\nThis paper proposes the use of GANs as a realistic benchmark for continual learning, and shows how continual learning techniques applied to the discriminator can alleviate mode collapse. Existing continual learning approaches for discrete task structure (EWC and IS) are adapted to the continually shifting domain of GANs, and evaluated on a toy mixture of Gaussians, CelebA and CIFAR-10 image generation as well as textGANs.\n\nThis is a clearly written paper that nicely addresses some of the challenges of bridging the toy problems of continual learning with a real world problem of GAN training. The experiments and ablations are thorough, but the empirical gains in terms of improving GAN metrics are relatively minor. It's also not obvious that GAN training is really a continual learning problem, as every time the generator distribution shifts, the discriminator has to shift as well. Thus progress on stabilizing and improving GANs might not transfer back to domains that truly represent continual learning where the goal is to build a single network that perform well at all points in time. In terms of more realistic benchmarks for continual learning, I believe a controlled synthetic dataset would be more practical than the sequence of GAN checkpoints proposed here.\n\nStrengths:\n+ Clearly written, with good background discussion of continual learning approaches and challenges.\n+ Interesting adaptation of EWC and IS to the continual setting with task rates, online memory (sum of quadratics is quadratic), and controlled forgetting with a time decay.\n+ Thorough experiments and ablations on toy tasks, CelebA and CIFAR-10, and textGANs. Nicely includes error bars and compares computation time for each approach.\n\nWeaknesses:\n- The paper could benefit from more discussion on the goals of continual learning, and what is wrong with existing toy benchmarks. Why not come up with a tractable toy problem that addresses these difficulties directly?\n- I remain unconvinced that GANs as a good benchmark for continual learning. For example, it has been argued that many of the problems with GANs arise from dynamics of minimax optimization difficulties, and there are many recent approaches that were not compared to that focus on this optimization aspect of GAN training (Metz et al., Roth et al., Mescheder et al.). How would you relate these theoretical ideas to continual learning?\n- Most the experimental improvements are incremental. How did you choose or tune hyperparameters of your approach? ""]","[50, -60, -20]","[80, 20, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with a balanced overview, highlighting both pros and cons. They acknowledge the paper's contributions and clever formulation, but also express some doubts and suggestions for improvement. The overall tone leans positive, with the reviewer stating they 'tend to accept this paper for its contribution on methods'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or concerns rather than direct attacks. They use phrases like 'I think', 'I doubt', and 'It would be much better if' to soften their critiques. The reviewer also acknowledges the paper's strengths before diving into areas for improvement, which is a polite approach to peer review."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's contributions and experimental analyses, stating it's 'not good enough to be accepted'. They use phrases like 'not convinced' and list several major issues. However, they do acknowledge the importance of the problem, preventing the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I like the problem' and 'Interesting view' to soften their criticism. They also offer constructive suggestions and explain their concerns in detail, which is considerate. The language is not overly formal or polite, but it avoids rudeness, resulting in a slightly positive politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express significant doubts about the core premise and contributions. The reviewer states the empirical gains are 'relatively minor' and questions whether GANs are truly a good benchmark for continual learning. They also note that most improvements are 'incremental'. However, the tone is not entirely negative, as they praise the clear writing and thorough experiments. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledging strengths alongside weaknesses. They phrase criticisms as questions or suggestions rather than harsh statements. The review maintains a professional and constructive tone, even when expressing doubts about the paper's approach.""]"
"[""This paper gives various PAC-Bayesian generalization guarantees and some\nempirical results on parameter perturbation in training using an algorithm\nmotivated by the theory.\n\nThe fundamental issue addressed in this paper is whether parameter\nperturbation during training improves generalization and, if so, what\ntheoretical basis exists for this phenomenon.  For continuously\nparameterized models, PAC-Bayesian bounds are fundamentally based on\nparameter perturbation (non-singular posteriors).  So PAC-Bayesian\ntheory is naturally tied to parameter perturbation issues.  A more\nrefined question is whether the size of the perturbation should be\ndone on a per-parameter bases and whether per-parameter noise levels\nshould be adaptive --- should the appropriate noise level for each\nparameter be adjusted on the basis of statistics in the training data.\nAdam and RMS-prop both adapt per-parameter learning rate eta_i to be\nproportional to 1/((E g_i^2) + epsilon) where E g_i^2 is some running\nestimate of the expectation over a draw of a training point of the\nsquare of the gradient of the loss with respect to parameter i.  At\nthe end of the day, this paper, based on PAC-Bayesian analysis,\nproposes that a very similar adaptation be made to per-parameter noise\nduring training but where E g_i^2 is replaced by the RMS value \\sqrt{E\ng_i^2}.  It seems that all theoretical analyses require the square\nroot --- the units need to work.  A fundamental theoretical question,\nperhaps unrelated to this paper, is why in learning rate adaptation the\nsquare root hurts the performance.\n\nThis paper can be evaluated on both theoretical and empirical grounds.\nAt a theoretical level I have several complaints.  First, the\ntheoretical analysis seem fairly mechanical and without theoretical\ninnovation. Second, the analysis obscures the prior being used (the\nlearning bias). The paper first states an assumption that each\nparameter is a-priori taken to be uniform over |w_i| <= \\tau_i and the\nKL-divergence in the PAC-Bayes bound is then log tau_i/sigma_i where\nsigma_i is the width of a uniform posterior over a smaller interval.\nBut later they say that they approximate tau_i by |w_i| + kappa_i with\nkappa_i = \\gamma |w_i| + epsilon.  I believe this works out to be\nessentially a log-uniform prior on |w_i| (over some finite range of\nlog |w_i|).  This seems quite reasonable but should be made explicit.\n\nThe paper ignores the possibility that the prior should be centered at\nthe random initialization of the parameters.  This was found to be\nessential in Dziugaite and Roy and completely changes the dependence\nof k_i on w_i.\n\nAnother complaint is that the Hoefding bound is very loose in cases\nwhere the emperical loss is small compared to its upper bound.  The\nanalysis can be more intuitively related to practice by avoiding the\nrescaling of the loss into the interval [0,1] and writing expressions\nin terms of a maximum bound on the loss L_max.  When hat{L} << L_max\n(almost always the case in practice) the relative Chernoff bound is\nmuch tighter and significantly alters the analysis.  See McAllester's\nPAC-Bayesian tutorial.\n\nThe theoretical discussion on re-parameterization misses an important\npoint, in my opinoin, relative to the need to impose a learning bias\n(the no-free-lunch theorem).  All L_2 generalization bounds can be\ninterpreted in terms of a Gaussian prior on the parameters.  In all\nsuch cases the prior (the learning bias) is not invariant to\nre-parameterization.  All L_2 generalization bounds are subject to the\nsame re-parameterization criticism.  A prior tied to a particular\nparameterization is standard practice in machine learning for in all\nL_2 generalization bounds, including SVMs.  I do think that a\nlog-uniform prior (rather than a Gaussian prior) is superior and\ngreatly reduces sensitivity to re-parameterization as noted by the\nauthors (extremely indirectly).\n\nI did not find the empirical results to very useful.  The value of\nparameter perturbation in training remains an open question. Although\nit is rarely done in practice today, it is an important fundamental\nquestion. A much more thorough investigation is needed before any\nconclusions can be drawn with confidence. Experimentation with\nperturbation methods would seem more informative than theory given the\ncurrent state of the art in relating theory to practice.\n"", ""The authors prove a PAC-Bayes bound on a perturbed deterministic classifier in terms of the Lipschitz constant of the Hessian. They claim their bound suggests how insensitive the classifier is to perturbations in certain directions. \n\nThe authors also “extract” from the bound a complexity measure for a particular classifier, that depends on the local properties of the empirical risk surface: the diagonal entries of the Hessian, the smoothness parameter of the Hessian, and the radius of the ball being considered.  The authors call this “metric” “PAC-Bayes Generalization metric”, or pacGen.\n\nOverall, this seems like a trivial extension of Neyshabur et al. PAC-Bayes bounds. \n\nThe experiments demonstrating that pacGen more or less tracks the generalization error of networks trained on MNIST dataset is not really surprising. Many quantities track the generalization error (see some of Bartlett’s, Srebro’s, Arora’s work). In fact, these other quantities track it more accurately. Based on Figure 2, it seems that pacGen only roughly follows the right “order” of networks generalizing better than others. If pacGen is somehow superior to other quantities, why not to evaluate the actual bound? Or why not to show that it at least tracks the generalization error better than other quantities?\n\nThe introduction is not only poorly written, but many of the statements are questionable. Par 2: What complexity are you talking about? What exactly is being contradicted by the empirical evidence that over-parametrized models generalize? \n\nRegarding the comment in the introduction: “ Dinh et al later points out that most of the Hessian-based sharpness measures are problematic and cannot be applied directly to explain generalization.”, and regarding the whole Section 5, where the authors argue that their bound would not grow much due to reparametrization:\nIf one obtains a bound that depends on the “flatness” of the minima, the bound might still be useful for the networks obtained by SGD (or other algorithms used in practice). The fact that Dinh et al. paper demonstrates that one can artificially reparametrize and change the landscape of a specific classifier does not contradict any generalization bounds that rely on SGD finding flat minima. Dinh et al. did not show that SGD finds classifiers in a sharp(er) minima that generalize (better).\n\nIn the experiment section, the authors compare train and test errors of perturbed (where the perturbation is based on the Hessian) and unperturbed classifiers. However, they don't compare their results to other type of perturbations, e.g. dropout. It’s been shown in previous work that certain perturbations improve generalization and test error.\n\nThere are numerous typos throughout the paper.\n\n\n****************\n\n[UPDATE]\n\nI would like to thank the authors for implementing the changes and adding a plot comparing their algorithm with dropout. While the quality of the paper has improved, I think that the connection between the perturbation level and the Hessian is quite obvious. While it is a contribution to make this connection rigorous, I believe that it is not enough for a publication. Therefore, I recommend a rejection and I hope that the authors will either extend their theoretical or empirical analysis before resubmitting to other venues."", 'The authors study generalization capabilities of neural networks local minimums thanks to a PAC-Bayesian analysis that grasps the local smoothness properties. Even if some assumptions are made along the way, their analysis provides a metric that gives insight on the accuracy of a solution, as well as an optimization algorithm. Both of these result show good empirical behavior.\n\nHowever, despite my favorable opinion, I consider that the paper presentation lacks rigor at many levels. I hope that the criticism below will be addressed in an eventual manuscript.\n\nIt is confusing that Equations (4) and (9) defines slightly differently \\sigma*_i(w*,\\eta,\\gamma). In particular, the former is not a function of \\eta. \n\nThe toy experiment of Figure 1 is said to be self-explainable, which is only partly true. It is particularly disappointing because these results appear to be really insightful. The authors should state the complete model (in supplementary material if necessary). Also, I do not understand Figures (b)-(c)-(d): Why the samples do not seem to be at the same coordinates from one figure to the other? Why (d) shows predicted green labels, while the sample distribution of (b) has no green labels?\n\nIt is said to justify the perturbed optimization algorithm that Theorem 1 (based on Neyshabur et al. 2017) suggests minimizing a perturbed empirical loss. I think this is a weak argument for two reasons:\n(1) This PAC-Bayes bounds is an upper bound on the perturbed generalization loss, not on the deterministic loss.\n(2) The proposed optimization algorithm is based on Theorem 2 and Lemma 3, where the perturbed empirical loss does not appear directly.\nThat being said, this does not invalidate the method, but the algorithm justification deserves a better justification\n\nThere is a serious lack of rigor in the bibliography:\n- Many peer-reviewed publications are cited just as arXiv preprints\n- When present, there is no consistency in publication names. NIPS conference appears as ""Advances in Neural ...,"", \'NIPS\'02"", ""Advances in Neural Information Processing Systems 29"", ""(Nips)"". The same applies to other venues.\n- Both first name initials and complete names are used \n- McAllester 2003: In In COLT\n- Seldin 2012: Incomplete reference\n\n Also, the citation style is inconsistent. For instance, the first page contains both ""Din et al, (2007) later points out..."" and ""Dziugaite & Roy (2017) tries to optimize..."" \n\nTypos:\n- Page 3: ...but KL(w*+u | \\pi) => KL(w*+u || \\pi)\n- In this/our draft: Think to use another word if the paper is accepted\n- Line below Equation (5): \\nabla^2 L => \\nabla L (linear term)\n- it is straight-forward -> straightforward\n']","[-30, -60, -20]","[20, -20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper, they express several significant criticisms and concerns. The review starts with a neutral tone but becomes increasingly critical, pointing out theoretical and empirical shortcomings. The reviewer uses phrases like 'I have several complaints,' 'The paper ignores,' and 'I did not find the empirical results to very useful,' indicating a generally negative sentiment. However, it's not entirely negative as the reviewer also recognizes the importance of the topic and some merits of the paper.\n\nThe politeness score is 20 because the reviewer maintains a professional and academic tone throughout, avoiding personal attacks or overly harsh language. They use phrases like 'In my opinion' and 'I believe,' which soften the criticism. The reviewer also acknowledges the importance of the topic and the potential for future research. However, the directness of some criticisms, while not impolite, prevents the score from being higher."", ""The sentiment score is -60 because the reviewer expresses significant criticism throughout, calling the work a 'trivial extension', questioning many of the authors' statements, and ultimately recommending rejection. However, they do acknowledge some improvements made by the authors, preventing the score from being even lower. The politeness score is -20 because while the reviewer uses some polite phrases like 'I would like to thank the authors', the overall tone is quite critical and dismissive, with phrases like 'poorly written' and 'numerous typos'. The reviewer also directly states their recommendation for rejection, which is somewhat blunt. However, they do offer some constructive feedback and explanations for their criticisms, preventing the score from being extremely negative."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses a 'favorable opinion' initially, they follow up with significant criticism about the paper's presentation lacking rigor 'at many levels'. They also list several specific issues and areas for improvement. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I hope that the criticism below will be addressed' and frames their comments as suggestions rather than demands. They also begin with positive aspects before moving to criticisms. However, some direct statements about lack of rigor and disappointment prevent a higher politeness score.""]"
"['This paper presented a novel approach for modeling a sequence of characters as a sequence of latent segmentations. The challenge here was how to efficiently compute the marginal likelihood of a character sequence (exponential number different of segmentations). The author(s) overcame this by having a segment generation process independent from the previous segment (only depends on a sequence of characters). The inference is then required a forward algorithm. To generate a segment, a model can either select a lexical unit (pre-processed from a training corpus) or generate character by character. \n\nOn the experiments, the author(s) showed that the model recovered semantical segmentation on many word segmentation dataset (including phonemes). The lexical memory and the length regularization both contribute significantly as shown in the analysis. The language modeling result (BPC) was also competitive with LSTM-based LMs. \n\nI think the overall model is interesting and well motivated, though it is a bit disappointing that the author(s) needed to use an extra regularizer to constraint the segment length (from the lexical memory?). Perhaps, the way they build a lexical memory should be investigated further. The experiment should also show an evidence that SNLM(+memory, -length) was overfitted as claimed.\n\nThe validation and test dataset have been modified to remove ""samples"" containing OOV characters. How many have been removed? The author(s) could opt for an unknown character similar to many word-level datasets.\n\nThe use of word segmentation data was quite clever, but this also downplayed other work that is not aimed to recover human-semantic segmentations. For example, a segment ""doyou"" on page 10 might be considered as a valid segmentation since it appears a whole lot. HM-LSTM though did poorly on the segmentation task but performed rather well on PTB LM task, but the author(s) decided to omit this comparison.\n\nSome minor comments:\n- A typo in the introduction ""... semi-Markov model. The the characters inside ..."".\n- Eq 3 is a bit hard to follow. Perhaps, a short derivation should be presented.\n- Is it possible to efficiently generate a sequence?\n\n[Updated after reconsidering other reviews]\nAlthough this paper misses some related work and comparison models, I think it still has a valid contribution to language modeling: a character-level language model that produces plausible word segmentation.', 'This paper proposes a neural architecture for segmental language modeling\nthat enables unsupervised word discoveries. The architecture employes a \ntwo-stage architecture that a word might be a type, or a sequence of characters\nof its spellings. \nThis idea is basically similar to Nested Pitman-Yor language models \n(Mochihashi et al. 2009) and two-stage language models (Goldwater et al. 2011),\nbut the authors seem not to notice these previous work.\nExperimental results show some improvements on naive baselines, but clearly \nbelow the state-of-the-art in unsupervised word segmentation.\n\nAs noted above, the crucial drawback of this paper is that the authors are\ncompletely unaware of latest achievements on unsupervised word segmentation\nand discovery, rather than old, simplistic baselines such as Goldwater+ (2009,\nidea is based on Goldwater+ ACL 2006) or Berg-Kirkpatrick (2010).\nThe idea of using characters and words is already exploited in Mochihashi+\n(ACL 2009) in a nonparametric Bayesian framework; it has a better F1 than this\nwork by a large margin. Moreover, it is recently extended (Uchiumi+ TACL \n2015) to also include latent word categories as well as segmentations to yield \nthe state-of-the-art accuracies on F1=81.6 on PKU corpus, as compared to 73.1 \nin this paper. \nNote that they employ a prior distribution on segment lengths as a (mixture of) \nPoisson distributions or negative binomials whose parameters are \nautomatically learned during inference, as compared to a post-hoc regularization\nused in this paper.\n\nIn a Bayesian framework, interpolations between words and characters are\ntheoretically derived and quite carefully learned, and regularizations are\nautomatically adjusted. While neural architectures have some potentials \nto improve over them, current heuristic architectures that have lower \nperformance does not have any advantage over these methods, \nboth theoretically and empicially.\n', '[Note to the authors: I was assigned this paper after the reviewing deadline.]\n\nThe authors train language models on unsegmented text, simultaneously discovering word boundaries\nwithout direct supervision. Given the past history, but ignoring past segmentation decisions\nto keep computations tractable, the model predicts the next character segment (word-like unit)\nby combining a character-level LSTM with a lexical memory. To prevent overusing the\nlexical memory, which would lead to poor generalization, the authors propose a segment\nlength penalty.\n\nStrengths:\n\nThe model architecture is interesting, combining the benefits of a character-level\nmodel (open vocabulary) with those of a lexical model (effective for frequent character\nsequences).\n\nDespite the exponential number of possible segmentations, inference remains tractable\nusing dynamic programming (with some simplifying assumptions).\n\nThe ablation study clearly shows that both the lexical memory and the length penalty\ncontribute significantly.\n\nWeaknesses:\n\nThe writing quality is somewhat weak. Many errors should have been caught when\nproofreading the paper (e.g. ""The segmentation decisions and decisions"" and \n""The the characters"" on page 1).\n\nI am confused by the key-value pairs of the lexical memory. Shouldn\'t character\nsequences be keys, and their trainable vector representations be values?\n\nIt is hard to evaluate how good the language models are, as the strength of the\nbaselines is unclear. How well-tuned is the LSTM?\n\nComparison to some other segmentation approaches (not necessarily with language modeling)\nis limited. In particular, adaptor grammars perform very well on the Brent corpus [1].\nHowever, [2] is mentioned briefly. As these other approaches work better for segmentation,\nthe authors should carefully justify why having a single model that does both language\nmodeling and word segmentation well matters. Many neural approaches have also been\nsuggested for Chinese word segmentation (among others [3]). In these papers, results on the\nPKU dataset are much better.  Are these directly comparable with yours?\n\nI would have liked a finer analysis of the impact of the length penalty.\nA plot showing how validation likelihood and segmentation performance vary as\n\\lambda is increased could potentially be interesting.\n\n[1] Johnson and Goldwater. ""Improving nonparameteric Bayesian inference: experiments on\nunsupervised word segmentation with adaptor grammars"", HLT, 2009\n\n[2] Berg-Kirkpatrick et al. ""Painless Unsupervised Learning with Features"", NAACL, 2010\n\n[3] Yang et al. Yang, Jie, Yue Zhang, and Fei Dong. ""Neural Word Segmentation with Rich Pretraining"", ACL, 2017']","[50, -70, 20]","[70, -20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novel approach and interesting model, while also providing constructive criticism. The reviewer notes that the model is 'well motivated' and shows competitive results, but also expresses some disappointment about certain aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing suggestions for improvement rather than harsh criticism. Phrases like 'I think the overall model is interesting' and the use of 'the author(s)' show respect. The reviewer also balances critique with praise, maintaining a professional and courteous tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several critical flaws in the paper, such as the authors being 'completely unaware of latest achievements' and the work having 'lower performance' compared to existing methods. The reviewer also states that the paper's approach 'does not have any advantage' over existing methods. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism. Phrases like 'crucial drawback' and 'completely unaware' come across as somewhat harsh. The reviewer does not use any particularly polite language or attempt to balance criticism with positive feedback, which contributes to the slightly negative politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper, including the interesting model architecture, tractable inference, and effective ablation study. However, they also point out significant weaknesses, such as poor writing quality and limited comparisons to other approaches, which tempers the overall sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, balancing praise with criticism. They use phrases like 'The model architecture is interesting' and 'I would have liked' rather than harsh language. The reviewer also provides helpful suggestions and references, indicating a collegial approach. However, the directness in pointing out flaws (e.g., 'The writing quality is somewhat weak') prevents the score from being higher.""]"
"['This is very solid work and the framework allows one to plug-in existing complexity measures to provide complexity upper bounds for (some) DNNs. The main idea is to rephrase an empirical risk minimization problem in terms of a binary optimization problem \nusing a discretization of the continuous variables. Then this formulation is used to provide a as a moderate-sized linear program of its convex hull. \n\nIn my opinion, every paper that provides insights into the complexity and generalization of deep learning is an important contribution. Moreover, the present paper is based on \na recent insight of the authors, i.e., it is based on solid grounds. However, it would have been nice to also show some practical insights. The main take-aways message is that we need exponential time. Is this practical for networks with with millions of parameters? Or does this imply that deep learning is hopeless (in theory)? To be fair, the authors touch upon this in the conclusions, but only 1-2 sentences. This discussion should be extended. Nevertheless, I agree that the bridge built is important and may indeed trigger some very important future contributions. \n\nThe authors should, however, also review other work on linear programming for deep networks coming from the machine learning community such as \n\nBrandon Amos, Lei Xu, J. Zico Kolter:\nInput Convex Neural Networks. \nICML 2017: 146-155\n\nGiven the background of the average ICLR reader, the authors should also introduce (at least the intuitions) improper and proper learning setups in the introduction before using them.   This also holds for other terminology from complexity theory. Indeed, the authors cannot introduce/review all complexity theory. However, they should try their best and fill the rest by a reference to an introductionary book or directly to the appendic. Without, while important for the ICLR community, the authors run the risk that the paper would better be suited by a learning theory venue. ', ""This paper studies the problem of proper learning of deep neural network. In particular, the focus is on doing\napproximate empirical risk minimization over the class of neural networks of a fixed architecture. The main \nresult of the paper is that approximate ERM can be formulated as an LP problem that is of size exponential in the\nnetwork parameters and the input dimensionality. The paper uses a framework of Bienstock and Munoz that shows how to \nwrite a binary optimization problem as a linear problem with size dependent on the treewidth of an appropriate graph\nassociated with the optimization problem. In order to apply the framework, the authors first discretize the parameter\nspace appropriately and then apply analyze the treewidth of the discretized space. The authors also provide treewidth\nanalysis of specific architectures including fully connected networks, and CNNs with various activations.\n\nMost of the technical work in the paper involves analyzing the treewidth of the resulting discretized problem. The nice \nfeature of the result is that it holds for worst case data sets, and hence, the exponential dependence on various\nparameters is unavoidable. On the other hand, it is unclear to me as to how these ideas might eventually lead to \npractical algorithms or shed light on current training practices in the deep learning community. For instance, it would\nbe very interesting to investigate if under certain assumptions on the data generation process, one can get small LPs\nthat depend exponentially only in the depth, as opposed to the input dimensionality.  \n\nI also feel that section 5 does not add much to the main results of the paper and can be skipped or moved entirely to the appendix. On a technical note, I don't see where the dependence on the input dimensionality appears in Theorem 5.1. "", 'This work reformulates the neural network training as an LP with size that is exponential in the size of the architecture and data dimension, and polynomial in the size of the data set. They further analyze generalization properties. It extends previous works on 1-hidden-layer neural-nets (say, In Arora et al. (2018)). \n\nPros: Establish new time complexity (to my knowledge) of general neural-nets. \n\nCons: It seems far from having a practical implication. Exponential complexity is huge (though common in TCS and IP communities). No simulation was presented. Not sure which part of the approach is useful for practitioners.\n    My feeling is that the paper is a bit too theoretical and less relevant to ICLR audience. More theoretical venues may be a better fit. \n\nOther questions:\n--The authors mentioned “that is exponential in the size of the architecture (and data dimension)  and polynomial in the size of the data set;” and ""this is the best one can hope for due to the NP-Hardness of the problem "". \na)\tThe time complexity is exponential in both the size of neural-net and the data dimension (the latter seems to be ignored in abstract). Is there a reference that presents results on NP-hardness in terms of both parameters, or just one parameter? \nb)\tThe NP-hardness reduction may give an exp. time algorithm. Is there a simple exponential time algorithm? If so, I expect the dependence on the size of the data set is exponential, and the contribution of this paper is to improve to polynomial. The authors mentioned one discretization method, but are there others? More explanation of the importance of the proved time complexity will be helpful. \n\n-- Novelty in technical parts: The idea of tree-width graph was introduced in Bienstock and Muñoz (2018). The main theorem 3.1 is based on explicit construction for Theorem 2.5, and Theorem 2.5 is an immediate generalization of a theorem in Bienstock and Muñoz (2018) as mentioned in the paper. Thus, this paper looks like an easy extension of Bienstock and Muñoz (2018) --intuitively, minimizing polynomials by LP seems to be closely related to solving neural-nets problems by LP. Could the authors explain more on the technical novelty? \n\nUpdate after rebuttal: I\'d like to thank the authors for the detailed response. It addressed most of my concerns.\n    The analogy with MIP makes some sense, as huge LPs are indeed being solved every day. However, an important difference is that those problems cannot be solved in other better ways till now, while for deep learning people are already successfully solving the current formulations. I still think this work will probably not lead to a major empirical improvement.\n     I just realize that my concern on the practical relevance is largely due to the title ""Principled Deep Neural Network Training through Linear Programming"". It sounds like it can provide a better ""training"" method, but it does not show a practical algorithm that works for CIFAR10 at this stage. The title should not sound like ""look, here is a new method that can change training"", but ""hey, check some new theoretical progress, it may lead to future progress"". I strongly suggest changing the title to something like ""Reformulating DNN as a uniform LP"" or ""polynomial time algorithm in the input dimension"", which reflects the theoretical nature. \n    That being said, the MIP analogy makes me think that there might be some chance that this LP formulation is useful in the future, maybe for solving some special problems that current methods fail miserably.  In addition, it does provide a solid theoretical contribution. For those reasons (and assuming the title will be changed), I increase my score. \n']","[60, 20, -20]","[80, 60, 60]","[""The sentiment score is 60 (positive) because the reviewer describes the work as 'very solid' and an 'important contribution'. They appreciate the paper's insights and solid foundation. However, they also express some reservations about practical insights and suggest expanding the discussion on certain points, which prevents a higher score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames suggestions as constructive feedback rather than criticism. Phrases like 'In my opinion' and 'it would have been nice' indicate a polite tone. The reviewer also balances critique with praise, showing respect for the authors' work while providing helpful recommendations."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the technical merits of the paper and its 'nice feature', but also expresses some reservations about its practical applicability and suggests improvements. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'it would be very interesting to investigate'). The reviewer also acknowledges the paper's strengths before offering critiques, which is a polite approach. However, the score is not extremely high as the language, while polite, is not excessively formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros ('Establish new time complexity'), they express more cons and concerns. They state the paper seems 'far from having a practical implication' and is 'a bit too theoretical and less relevant to ICLR audience'. The reviewer also questions the novelty, suggesting it might be 'an easy extension' of previous work. However, the score isn't deeply negative because the reviewer does recognize some value and provides constructive feedback. The politeness score is moderately positive (60) because the reviewer maintains a professional tone throughout, uses phrases like 'Could the authors explain more...', and thanks the authors for their response. They also provide detailed feedback and suggestions for improvement, which is considerate. The language is not overly formal or deferential, hence not scoring higher, but it's consistently respectful and constructive.""]"
"['Summary: The paper suggests a method to reducing the space consumption of training neural nets, in exchange for additional training time. The method stores in memory only a subset of the intermediate tensors computed in the forward step, and then in the backward step it re-computes the missing tensors as they are needed by interpolating forward (again) between the stored tensors. The paper also gives a combinatorial algorithm for choosing which tensors to store on a given computation DAG annotated with vertex costs.\n\nEvaluation: I generally like the paper. The proposed method is simple and straightforward, and seems to lead to a noticeable improvement in space usage during training.\nThe part related to decomposing a DAG into ""close sets"" looks like it might overlap with existing literature in graph theory; I don\'t have concrete references but the authors may want to check this. The ACG solver algorithm looks somewhat wasteful in terms of the degree of the polynomial running time, but since actual computation graphs are tiny in computational terms, I guess this is not really an issue.\nOne point not addressed in the experiments is what is the overhead incurred in training time by the two space-efficient methods over usual training. I suppose one expects the training time be less than twice longer, since the re-forwards amount to one additional complete forward step per forward-backward pair.\nAnother thing that would be interesting to see is the actual stored vertices (V_R) that were chosen empirically for the rows in table 1 (or at least some rows). Since the computational graphs of the tested networks are small, and some are well-known, I imagine it should doable (though this is merely a suggestion).\n\nConclusion: The paper is simple and looks reasonable, with no major issues that I could detect.', 'In Cutting Down Training Memory by Re-forwarding the authors present a method for structuring the computation graph of a DNN to save training time.  The authors given experiments that show that the method can save up to 80% training memory.\n\nThe idea paper is nice however, this draft needs more writing work to bring to a conference standard in my opinion.\n\nMy objection to the writing begins with the Definition and example of a “Close set” which I details below.  \n\nI also have further suggestions:\n\n\nQuestions & doubts\n\nDefinition 1 : Close set\n\n* A set of vertices and edges that start from v_i and that end at  v_j.\n \n1. Vertices don’t start or end at vertices so I am already confused\n2. No notation has been introduced yet for close set so I am not sure what i and j refer to.  Also I suspect you want “or” and not “and” otherwise there could only be one possible “edge” (i,j)\n\n* sij = {v,e} is called a close set such that ∀v1 ∈ sij, v1 has no edge to any v2 \\not\\in sij ∪ {vi , vj }\n\n1. Do you mean this is a set with two elements v and e?  Probably not?\n2. Is v1 and v2 meant to be generic vertices?  If so it quite unnatural to also use v_i and v_j.  I.e., probably the name of two specific vertices in your graph is “v1” and “v2”\n3. Another question is the close set s_{ij} unique or are their potentially multiple s_{ij}?\n\n* The edges of sij are all the edges between v1 , v2 ∈ sij , all the edges between vi and v ∈ sij \n\n1. Not getting what’s going with v1 and v2 versus vi and vj.\n\nExamples of close set \na Probably you should phrase as there can exist a close s_{2,4} since …\n\nAfter reading this I got general idea that close set correspond to connected component with no connections except to oldest ancestor and youngest child.  But that is a guess — the notation and precision in the definition as well as the examples led me to have too many doubts.\n\nAlso\n\nP3 Case(1) is n and N the same?\n\nWith respect to algorithm 5 Can you discuss its computation time?\n\nIn summary this is potentially interesting work but the writing should be sharper, their should be less ambiguity of interpretation of close set. \n\nI should note — this reviewer lacks confidence in his review in so far as they have next to zero experience with DNNs.  So if given the problems in the manuscript the contribution paper would be for example a key result for DNN training this reviewer would not be able to recognize it as such.\n', ""\nThis paper introduces a re-forwarding method to cut the memory footprint for training neural networks. It improved on top of previous work that did re-forwarding for linear computation graph, and this work also supports non-linear computation graph. \n\nPros:\n(1) This paper is solving an important problem saving the training memory of deep neural networks. GPU price and GPU memory increase non-proportionally, and many machine learning tasks require large GPU memory to train.  Though, there's rich literature in the area of saving the GPU memory for training. \n\n(2) This paper evaluated a large number of neural networks (Alexnet, VGG, ResNet, DenseNet). The evaluation is extensive. \n\nCons: \n(1) this paper has incremental contribution compared with Chen et al. (2016). Chen et al worked on linear computation graph. Extending the algorithm from linear graph to non-linear graph is important but the technical contribution is incremental and thin. \n\n(2) the improvement over previous work is quite marginal. For example, the memory saving went from 2894MB to 2586MB for VGG16, from 2332Mb to 1798MB for ResNet-50, just to pick a few widely used architectures. \n\n(3) The paper only reported the memory saving, but didn't report the latency overhead. It's important to know how much latency overhead is brought by this algorithm. If we save 2x memory but the training time also get much longer, users will simply reduce the virtual batch size by half and do forward the backward twice to simulate the same physical batch size. So, the authors should be clear how much training time is brought by such algorithm and report the *end-to-end training time* in Table 1, with and without re-forwarding. "", 'I took a look at the revision.  I am glad to see that the authors clarified the meaning of ""optimality"" and added time complexity for each algorithm. The complexities of the algorithms do not seem great (3rd or 4th order polynomial of N) as they appear to be checking things exhaustively, but perhaps they are not a big issue since the decomposition algorithm is run only once and usually N is not huge. I wonder if more efficient algorithms exist.\n\nIt is also nice to see that the time overhead for one training step is not huge (last column of Table 1). While I still think it is better to see more complete training curves, the provided time overhead is a proxy. \n\nI hope the authors can further improve the algorithm description, for example, the pseudo-code of Algorithm 1 is very verbal/ambiguous, and it would be better to have more implementation-friendly pseudo-code.\n\nDespite the above-mentioned flaws, I think this work is still valuable in handling the memory consumption of arbitrary computation graph in a principled manner. \n\n=============================================================================\nThis paper presents a method for reducing the memory cost of training DNNs. The main idea is to divide the computational graph into smaller components (close sets), such that the dependency between components is low, and so one can store only tensors at key vertices in each component during the forward pass. In the backward pass, one needs to re-forward the data within each close set for computing the gradient. \n\nThe idea is quite intuitive and the example in linear computational graph in Section 3 clearly demonstrates the basic idea. The main technical development is in the case of arbitrary computation graph (Section 4), where the authors explain how to divide the computational graph into different types of close sets. I have not read the proofs in appendix, but it is clear that the technical development is mainly in discrete math rather than machine learning. For this part, my suggestions are:\n1. give better algorithm description: what are the inputs and outputs of each algorithm, for the examples in Figure 2-4 (and perhaps with costs for each vertex), which vertices do the final algorithm decide to store\n2. analyze the complexity of each algorithm\n3. provide clear definition of ""optimality"" and its proof: the authors mentioned in a few places about the method being ""optimal"", but the paper needs to be crystal clear about ""for what problem is the method optimal"", ""optimal in what sense (the objective)"".  \n\nThe more concerning part is the experimental evaluation. While I believe that the proposed method can save memory cost, there is no result on the additional time cost for re-forwarding. Therefore, it is not clear if it is worth the extra complication of using re-forwarding in an end-to-end sense: the authors motivated in Section 1 that saving memory cost allows one to use larger mini-batches, and an important benefit of large mini-batch is to accelerate training, see, e.g.,\nGoyal et al. Accurate, large minibatch SGD: Training imagenet in 1 hour. \nHoffer et al. Train longer, generalize better: Closing the generalization gap in large batch training of neural networks.\nIt is less desirable to use re-forwarding it if it causes significant latency in the backward pass and training. An good demonstration of the memory vs. time tradeoff would be the training curves of loss vs. running time.\n\nThe other detail I would appreciate is how the authors implemented the algorithm, and whether the proposed method is likely to be deployed on popular ML frameworks, which would improve the significance of the work.\n\n']","[70, -30, -20, 50]","[60, 50, 50, 75]","[""The sentiment score is 70 (positive) because the reviewer states they 'generally like the paper' and describes the method as 'simple and straightforward' leading to 'noticeable improvement'. The conclusion also states the paper 'looks reasonable, with no major issues'. However, it's not extremely positive as the reviewer does point out some areas for improvement or further investigation. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'may want to check', 'would be interesting to see'), and acknowledges the paper's strengths. The tone is professional and constructive, without any harsh criticism, though it doesn't go out of its way to be overly polite either."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the idea as 'nice', they express significant concerns about the writing quality and clarity of definitions. They state that the draft 'needs more writing work to bring to a conference standard'. The reviewer lists several issues and confusions, indicating a generally critical stance. However, they do mention the potential interest of the work, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'in my opinion' and 'I should note', which soften their criticisms. They also acknowledge their own potential limitations as a reviewer. The language is not overly formal or polite, but it avoids rudeness and maintains respect for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they list more 'Cons' and express concerns about the paper's incremental contribution and marginal improvements. The reviewer also points out missing information about latency overhead. However, the score is not deeply negative as the reviewer recognizes the importance of the problem and the extensive evaluation.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They present both pros and cons in a balanced manner, using neutral language like 'this paper has' rather than making personal criticisms. The reviewer also offers constructive suggestions for improvement, such as reporting end-to-end training time. While not overly effusive, the language is respectful and appropriate for a peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges improvements made by the authors and sees value in the work, despite mentioning some remaining flaws. They use phrases like 'I am glad to see' and 'It is also nice to see', indicating positive sentiment. However, they also point out areas for further improvement and express some concerns, which prevents the score from being higher.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, such as 'I hope the authors can' and 'I would appreciate'. They provide constructive criticism without being harsh or dismissive. The reviewer also acknowledges the value of the work even while pointing out areas for improvement. The tone is professional and courteous, though not excessively formal or deferential, which is why the score is not higher.""]"
"[""I read the other reviewers' comments as well as the rebuttal. I think that the other reviewers make a number of valid points, especially with regards to the theoretical analysis of the paper. Therefore, I do not feel confident in championing this paper. \n\nPS: I am downgrading my confidence in my evaluation.\n\n---\n\nPaper 93 proposes an empirical evaluation of the memorization properties of convnets. More specifically, it evaluates three aspects:\n-\tFirst it evaluates whether convnets can learn to distinguish images from two different sets by training a binary classifier. The conclusion is that, indeed, deep convnets can learn to make such a decision. As could be guessed from intuition, the larger the capacity of the network and the smaller the size of the sets, the higher the accuracy.\n-\tSecond, it evaluates whether we can detect that a group of samples of a dataset was used to train a model. For this purpose, it is proposed to compute the distribution of maximal activation scores of the output softmax layer and to make use of the Kolmogorov-Smirov distance between the cumulative distributions. It is shown experimentally that one can detect (even partial) leakage with such a technique.\n-\tThird, it evaluates whether we can detect that a single images was used to train a convnet. Two simple techniques are proposed. The first one considers that a sample is part of the training set if it correctly classified. The second one considers that a sample is part of the training set if its loss is below a threshold. It is shown experimentally that one can make such a decision with moderate accuracy.\n\nOn the positive side:\n-\tThis is a topic that should be of broad interest to the ICLR community.\n-\tThe paper is generally well-written.\n-\tThe experiments are reported on large-scale datasets on high-capacity networks which is more realistic than small-scale settings.\n\nOn the negative side:\n-\tIt is unclear whether the data augmentation techniques is applied only at training time or also at test time. In other words: at test time, do you present the original images only or transformed images too?\n-\tIn section 4, it is unclear why only the maximal activation of the softmax layer is used to characterize a sample? Why not considering the full distribution that should contain richer information? Why just focusing on the output layer and why not using the info available at intermediate layers?\n-\tSection 5 is somewhat less clear than the previous sections. The authors should more clearly define what the private, public and evaluation sets are, right from the beginning. The purpose of the public set is explained only in section 5.2.\n-\tThe experimental results of section 5.2 are somewhat disappointing. Even with no data augmentation, and even with the original networks, membership can only be assessed with a 90% accuracy. Results are much lower in less favorable cases, sometimes close to random (see last line of Table 3). This seems to be too low to be of practical use. This might be because the Bayes and MAT attacks are too simplistic. Again, why not using the distribution of the outputs of all layers? Why focusing only on the output of the last layer?\n"", 'Summary of the paper:\n\n\nThe paper has two intertwined goals. These goals are to illuminate the\ngeneralization/memorization properties of large and deep ConvNets in\ntandem with trying to develop procedures related to identifying\nwhether an input to a trained ConvNet has actually been used to train the\nnetwork. The latter task is generalized to detecting if a\nparticular dataset has been used to train a ConvNet. These goal are\ntackled empirically with multiple sets of experiments on largescale\ndatasets such as ImageNet22k and modern deep ConvNets architectures\nsuch as VGG and ResNet.\n\n\n\nPaper\'s positive points\n\n+ The paper has a very comprehensive set of references in the areas it\ntouches upon.\n\n+ Some of the experimental results presented are quite\ninteresting. They show that regularization data-augmentation helps\nprevent a network from explicit memorization and could be used as a\nway to help make training data more anonymous.\n\n+ Large scale experiments are reported on modern architectures.\n\n\nPaper\'s negative points\n\n- The paper makes use of a result from the David MacKay textbook\n  which defines the capacity of a single layer network to memorize the\n  labelling of $n$ inputs in $d$-dimensional space. If I\'m not\n  mistaken, from this result the authors extrapolate that the capacity\n  of a (deep) neural network is proportional to the number of\n  parameters in the network. This is true, but there are a\n  couple of caveats. The first is that the coefficient of\n  proportionality must depend very much on the number of layers in the\n  network. Increasing the network\'s depth increases the efficiency of\n  the representation (i.e. fewer total parameters needed to have the\n  same representational power as a shallow network). And as MacKay\n  also says in his book (chapter 44 quoting findings from Radford\n  Neal) that for MLPs what determines the complexity of the typical\n  function (once the network has a large enough width) represented by\n  the MLP is the ""characteristic magnitude of the weights"". So the\n  regularization technique applied is very significant in the\n  controlling the effective capacity of a network. This paper\n  experimentally shows that is the case multiple times as it is shown\n  that with increasing degrees of regularization (figure 1, figure 2)\n  it becomes harder and harder to memorize the positive training\n  images. It would be great if the paper also made some attempt to\n  consider these connections. Or at least comment on how these factors\n  could be incorporated into a more sophisticated analysis of the\n  capacity of a network.\n\n\n\n- There is a slight oxymoron in the premise of the first set of\n  experiments. The network is forced to memorize a set of\n  positive examples relative to the negative set it sees during\n  training. What is memorized I presume depends a lot on the negative\n  set used for training (its diversity, closeness to the positive set\n  and how frequently each negative example is seen during\n  training). This issue is not really commented upon in the paper. Is\n  there a training task which would allow one to more explicitly\n  memorize the image (some sort of reconstruction task) as opposed to\n  an in/out classification task?\n\n- This paper is a slightly difficult read - not because of the\n  language or the presentation of the material but more because there\n  is not one main coherent argument or goal for the paper. This is\n  reflected in the ""Related work"" section where 4 different\n  issues/tasks are referred to. Each one of these topics is worthy of\n  a paper in itself, but this paper dips into each one and then\n  swiftly moves onto the next one. For example in section 3 the paper\n  explores if a network can be forced to explicitly memorize a set of\n  images and how the size of this set is affected by the number of\n  parameters in the network and data augmentation. High-level\n  conclusions are made: more parameters in the network implies more\n  images can be memorized and data-augmentation makes explicit\n  memorization more difficult. Then it is off to considering\n  pre-trained networks and determining whether by analyzing the\n  statistics of the responses at different layers one can decide if a\n  set of images was used for training or not (or similar tasks). Yes\n  the different sections are related but it is does not feel like they\n  build upon each other to help form a clearer picture of memorization\n  within neural networks.\n  \n\n- The conclusions focus on the importance of section 3 and\n  the results of the experiments performed. Do the conclusions accurately\n  reflect the opinions of the author? If yes, would\n  it better to re-organize the paper and devote more of it to the\n  material presented in section 3 and filling this out with more\n  analysis and experiments to perhaps explore the issue of the\n  capacity of a network in more \n\n\nQueries/ points that need some clarification\n\n- I\'m a little unclear when data-augmentation is included in the\n  training phase whether the goal is to be able to also recognise\n  perturbed versions of the input images at test time. In section 3 is\n  a perturbed positive image considered a positive training image? And\n  in the testing phase are only unperturbed versions of the positive\n  images given to the ConvNet as input?\n\n- Last paragraph page 4: ""when the accuracy gets over 60\\% and again\n  at 90\\%"". Is this training or validation accuracy?\n\n\n\n\nTypos possible errors spotted along the way:\n\n* First paragraph page 5: ""more shallow"" --> ""shallower""\n* Page 7, first paragraph of section 5.: ""is ran"" --> ""is run""\n* Using ""scenarii"" for the plural of ""scenario"" I would say is pretty\n  non-standard and most people would use ""scenarios""', '==============Final Evaluation================\nI have gone through the other reviews as well as the author response.\nFirstly, I would like to thank the authors for providing detailed responses to my questions.\n\nIn general, I agree with R2 that the paper generally has some potentially interesting ideas and results but the manner in which the current draft is organized and presented makes it hard to grasp them and there is a lack of coherent message about what the paper is about.\n\nMoreover, from my understanding the analysis in David McKay’s book (Chapter 41) concerns a single neuron (and the number of parameters for a single neuron). As pointed out by R2, with depth there are a lot more number of possible ways in which one could carve out decision boundaries to separate data points, thus, it is not clear that the loose linear upper bound holds Specifically, as one might expect with depth it could be possible that linear capacity increase is a lower bound (I am not suggesting that it is, but that possibility should be considered and explained in the paper). Similarly, it would be good to formally connect the capacity to the rate of memorization before making a statement about them being related (as suggested in the initial review). In general, I feel this section could use some tighter formalism and justifications.\n\nI also remain unconvinced by the response to my issue with the claim “Our experiments show that our networks can remember a large number of images and distinguish them from unseen images”, where the negative images are also seen by the memorization model, so they are not unseen. The authors address this by saying 3M of the 15 M negatives have been seen. That does not seem like a small enough percentage to claim that these are “unseen” images.\n\nIn general, I feel the paper is interesting but would benefit from a major revision which makes the message of the paper more clear, and addresses these and other issues raised in the review phase. Thus I am holding my current rating.\n==================\n\nSummary\nThe paper trains classification models to classify a labeling of a subset of images (assigned with label 1) from the rest of the images (assigned with a label 0). Firstly, the paper shows that deep learning models are able to learn such classifiers and get low training loss. It then proposes to use this model to ``attack’’ task-specific models to perform membership inference, i.e. figuring out if an image provided in a set was used in training or not. \n\nStrengths\n+ The paper thoroughly covers related work and provides context.\n+ Results on confidence as a signature of a dataset are interesting.\n\nWeaknesses\n\n[Motivation]\n1. In general, recent work has found that the raw number of parameters has little to do with the size of the model class or the capacity of a model for deep models, and thus work like [A] has been trying to come up with better complexity measures for models to explain generalization. Thus, without sufficient justification the assertion in the paper that the capacity of the network is well approximated by the number of parameters does not seem correct. Also, the claim in Fig. 1 that the transition from ‘’high capacity’’ to low capacity happens at the number of parameters in the network seems a bit loose and hard to substantiate from what I understand, and should be toned down. (*)\n\n[Capacity]\n2. Sec. 3.3, Fig. 3: The capacity (in terms of parameters)of both Resnet-18 and VGG-16 is higher than the capcity for YFCC100M dataset for n=10K images (comes to 161K bits), while the capacity of Resnet-18, with 14.7 million parameters (assuming float32 encoding) has 14.7 * 32 bits = 470.4 million bits, thus capacity alone cannot explain why VGG converges faster than Resnet-18, since both networks exceed the capacity, and capacity does not seem to have an established formal connection to rate of memorization. This is something which would need to be explained/ substantiated separately. (*)\n\n3. Scenario discussed in Sec. 4 seems somewhat impractical. Given a set of m images, it is not clear that a classifier that is trained to detect between train and validation is sufficient, as one might also need to figure out if it is neither train nor val, which is a very practical scenario.\n\n4. Fig. 3 (right): It is not clear why the fact that the classifier is able to predict which dataset the image ‘m’ corresponds to is useful or practical, as this seems to be a property of the set ‘m’ rather than the property of the trained classification model (f_\\theta). Please clarify. On the other hand it is clear that using the confidence of the model to predict the dataset is a useful property, but the right side of the Fig. is very confusing. (*)\n\n6. It is not clear to me what the point of Sec. 5 is, given a trained model, one wants to figure out if an image was present in the training of the model. While the baseline approaches seem to make use of the model confidence, I cannot see how the proposed approach (which uses a classifier) makes use of the original model. It is also not clear why Table. 3 does not report the Bayes baseline results. Also, does this section use the classifier for predicting the dataset, or is the approach reported in the section, the MAT approach?\n\n7. ``Our experiments show that our networks can remember a large number of images and distinguish them from unseen images’’ -- this does not seem to be true, since the model is trained on both n as well as N -n ``unseen’’ images which it labels as the negative class, thus the negative class is also seen by the memorization model. (*)\n\nMinor Points\n1. It is not clear that training a network to classify a set from another set is necessarily equivalent to ``memorization’’. In addition, the paper would also need to show that such a model does not generalize to a validation set of images. This is probably obvious given the results from Zhang et.al. but should be included as a sanity check.\n2. Figure 3: it is confusing to call the cumulative distribution of the maximum classification score as the CDF of the model (y-axis fig. 3 left) as CDF means something else generally in such contexts, as the CDF of a predictor.\n\n\nReferences:\n[A]: Blier, Léonard, and Yann Ollivier. 2018. ``The Description Length of Deep Learning Models.’’ arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1802.07044.\n\nPreliminary Evaluation\nThere are numerous issues with the writing and clarity of the paper, while it seems like some of the observations around the confidence of classifiers are interesting, in general the connection between those set of results and the ``memorization’’ capabilities of the classifier trained to remember train vs val images is not clear in general. Important points for the rebuttal are marked with (*).\n']","[-20, -20, -30]","[50, 60, 60]","['The sentiment score is slightly negative (-20) because the reviewer expresses a lack of confidence in championing the paper and mentions several negative points, including disappointing experimental results and unclear aspects of the methodology. However, they also note some positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses of the paper without using harsh or dismissive language. They provide constructive feedback and suggestions for improvement, which contributes to the polite tone.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (comprehensive references, interesting experimental results, large-scale experiments), they also point out several significant negative points and areas for improvement. The critique is more extensive than the praise, indicating an overall slightly negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It would be great if...' and 'I'm a little unclear...' which are polite ways of suggesting improvements or asking for clarification. The reviewer also balances criticism with positive feedback and provides constructive suggestions. However, the score is not extremely high as the review is still quite direct in its criticism.\n\nThe language used is formal and academic, avoiding personal attacks or harsh language. The reviewer also takes the time to point out potential typos, which shows attention to detail and a desire to help improve the paper rather than simply criticize it."", ""Sentiment score: The review expresses mixed feelings, acknowledging some interesting ideas and results but highlighting significant issues and recommending major revisions. The overall tone leans negative, with phrases like 'I remain unconvinced' and 'would benefit from a major revision', indicating dissatisfaction with the current state of the paper. However, it's not entirely negative, as it recognizes potential value in the work.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They begin by thanking the authors for their detailed responses, which is a polite gesture. The criticism is presented constructively, using phrases like 'it would be good to' and 'I feel the paper is interesting but would benefit from', rather than harsh or dismissive language. The reviewer also acknowledges the possibility of their own misunderstanding in some areas, which shows humility and respect for the authors' work.""]"
"['To generate a sequence of high-level visual elements for recreation or translation of images, the authors propose differentiable ""canvas"" networks and ""drawer"" networks based on convolutional neural networks. One of the main ideas is the replacement of the ""canvas"" networks instead of non-differentiable ""renderer"" to end-to-end train the whole model with mean-squared error loss. It seems to be a novel approach to optimize drawing actions. It is reasonable to use separate networks to approximate the behavior of renderer and to fix the parameters of the ""canvas"" networks to maintain the pretrained rendering capability.\n\nIntegrating the high-level visual constructs for recreation or translation of images is to eliminate or attenuate visual artifacts and blurriness, as mentioned in the introduction of the paper. Qualitative comparison with the other state-of-the-art methods is shown in Figure 6f; however, it fails to show significant improvement over them. Quantitative results do not include in the comparison, but only for the ablation study to determine the proposing method. Although the paper proposes an interesting approach to enhance an image generation task, the provided evidence is weak to support the argument, which should be useful for their criteria.\n\nMoreover, experimental details fall short to ensure the validity of experiments. How do you split the dataset as train/val/test? Are the reporting figures (L2 loss) from test results? How are the statistics of the datasets you used?\n\nIn Related Work, the authors describe ""reinforcement learning methods can be unstable and often depend on large amounts of training samples."" Many RL methods use various techniques to stabilize the learning, and this argument alone cannot be the grounding that the supervised approach is better than RL. Unsupervised learning also needs a large amount of data. What is the point of this paragraph (the second paragraph in Related Work)?\n\n\nQuality: \n  Figure 1-3 are taking too much space, which might lead to exceeding 8 pages. \n\nClarity:\n  The experimental procedure is not clear. Please clarify the issues mentioned above. It is not hinder to understand the content; however, the writing can be improved by proof-reading and correcting a few grammatical errors.\n\nOriginality and significance:\n  Using the differentiable ""canvas"" networks to avoid non-differentiable ""renderer"" is a novel approach as far as I know. \n\nPros:\n  Differentiable drawing networks are underexplored in our community.\n\nCons:\n  It failed to show the excellency over pixel-wise generation methods and limited to simple visual elements, line drawings or box generations. This work does not explore ""brush strokes"" in paintings.\n\n\nMinor comments:\n\n- In Related Work, the inline citation should be ""Simhon & Dudek (2004)"" instead of ""(Simhon & Dudek, 2004)"", and this may apply to the others.\n\n- In Figure 2, the Hint should be x_n, the current state, or target image X for regeneration (X\' for translation)?\n\n- In 4.1, a typo, ""Out state consists of"" to ""Our state consists of"".', 'This is an interesting paper with simple idea and good results. I like the fact that the authors adopt simple autoencoder-like models instead of GANs or RL.\nFollowing are a couple questions that I am concerned about:\n1. Is the ordering of strokes important at all? I suspect that a drawer model that outputs 10 strokes in one pass could perform the same. It might be unnecessary to learn an RNN in this context. Can the authors comment on this?\n2. Quantitative evaluations are not well-presented. In Table 1 and Table 2, it is better to normalize pixel wise loss so that the readers could understand the actual error on each pixel.\n3. Section 4.3 and 4.4 do not have any quantitative evaluations.\n4. How does this system compare with other works, like GANs or RL? Quantitative comparisons are preferred.\n\nThe limitation of the proposed approach is also clear: first it is limited to one kind of curves (like a primitive shape in graphics); second it does not learn when to stop, which is already mentioned in the discussion.\n', ""This paper presents an unsupervised method for generating images in a high-level domain (brush strokes and geometric primitives). The proposed system is comprised of two neural networks: the drawer D and a forward model C of an external renderer R. The latter is trained on the rollouts produced by sending random actions to R. The forward model is then freezed and used to train D, i.e., the network that repeatedly interacts (sends commands) with the C to produce a desired image. Since everything is differentiable, D can be optimized via regular gradient descent.\n\nPros:\n+ The paper is written clearly and relatively easy to read\n+ The idea to replace the non-differentiable renderer with a differentiable approximation makes sense. Pure RL setups (i.e., in [Ganin et al., 2018]) are quite sample inefficient and hard to train due to high variance of REINFORCE.\n+ The proposed method is tested both in 2D (drawings and floor plans) and 3D (prisms) domains and yields relatively good results.\n\nCons:\n- The datasets used in the paper are quite simplistic. I’m wondering how hard it is to train a forward model for more complex data. At the very least, I would want to see how the method handles the 3D experiment when the view is not axis-aligned and there is more variety in the number of primitives and their types.\n- The performance of the method especially on drawings and floor plans is not excellent. The drawer tends to reproduce line art with small disjoint strokes - very different from how humans would accomplish this task. A similar observation can be made for floor plans (the system outputs small pixel-like boxes that tile bigger rooms). This suggests that recovered commands do not really correspond to the higher-level structure of the input. Unlike in RL approaches, injection of prior knowledge about the data (e.g., the floor plan should be reproduced using the minimum possible number of rectangles) seems problematic within the proposed framework.\n- It’s unclear how to use the approach for non-continuous actions (e.g., choosing types of primitives in 3D or different instruments in music).\n- It seems the method may suffer from significant exploration problems in more complex settings. Consider an image of a rectangle that the system should reproduce. Say, it initially outputs a box that doesn’t intersect with the target one. The gradient of l^2-distance between those two images in the pixel space is non-zero but it is zero w.r.t. the action taken since no small change of the action parameters would make the generated box intersect with the target (assuming that the target is far from the model’s output) so l^2 will stay the same.\n- I would love to see some comparison (preferably quantitative - speed of training, quality of reconstructions, etc.) to an RL system. So far, in the paper, there is only one figure showing a couple of images produced by such system.\n\nNotes/questions:\n* Section 2, paragraph 2: The systems by Xie et al. and Ganin et al. are very distinct. The former models the appearance of a single stroke while the latter is more similar to the present paper and synthesizes the entire image using strokes of a predefined appearance.\n* Section 3.3, paragraph 3: “pixel-wise maximum” - it seems to be a fairly restrictive setup which only works when the model increases intensity of pixels.\n* Section 3.4: This is a straightforward idea and is not novel (e.g., already used in some demonstrations of the method in [Ganin et al., 2018])\n* Section 4.2, paragraph 2: During training, do you use all the patches or randomly sample them? Is your loss computed per patch or for the entire image?\n\nIn summary, the paper presents an interesting idea but the execution needs some improvement (especially, in terms of evaluation) before the paper is ready to be accepted to the conference.\n\nAfter going through the authors' comments and the revised version of the paper, I keep the rating as is. The paper needs a more convincing evaluation section as well as some clean up (e.g., references to figures and tables in the text)""]","[-20, 50, -30]","[50, 70, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the approach, they express significant concerns about the lack of evidence supporting the method's effectiveness and the incomplete experimental details. The reviewer points out that the qualitative comparisons fail to show significant improvement, and quantitative results are missing for comparison with other methods. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'it seems to be,' 'please clarify,' and offering both pros and cons. They also provide constructive feedback and specific suggestions for improvement, which contributes to the polite tone. However, the criticism is direct and unambiguous, preventing a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by calling the paper 'interesting' and praising its 'simple idea and good results'. They also express appreciation for the authors' approach. However, the review then lists several concerns and limitations, which balances out the initial positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than criticisms. They use phrases like 'Can the authors comment on this?' and 'it is better to', which are polite ways of offering feedback. The reviewer also acknowledges the authors' own discussion of limitations, showing consideration for their perspective."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') and the overall conclusion suggests significant improvements are needed before acceptance. The reviewer states that 'the paper presents an interesting idea but the execution needs some improvement' and maintains their rating after revisions, indicating a slightly negative sentiment. The politeness score is 60 because the reviewer uses respectful and professional language throughout, acknowledging positive aspects before presenting criticisms, and uses phrases like 'I would love to see' and 'I'm wondering' to soften suggestions. The tone is constructive rather than harsh, even when pointing out flaws.""]"
"['The paper studies failure modes of deep and narrow networks. I find this research extremely valuable and interesting. In addition to that, the paper focuses on as small as possible models, for which the undesired behavior occurs. That is another great positive, too much of a research in DL focuses on the most complex and general cases in my opinion. I would be more than happy to give this paper a very strong recommendation, if not for numerous flaws in presentation. If those get improved, I am very eager to increase my rating. Here are the things that I think need an improvement:\n1. The formulation of theorems.\nThe paper strives for mathematical style. Yet the formulations of the theorems are very colloquial. Expression ""by assuming random weights"" is not what one wants to see in a rigorous math paper. The formulations of the theorems need to be made rigorous and easy to understand, the assumptions need to be clearly stated and all concepts used strictly defined.\n2. Too many theorems\n9 (!) theorems is way too much. Theorem is a significant contribution. I strongly suggest having 1-2 strong theorems, and downgrading more technical lemmas to a lemma and proposition status.\nIn addition - the problem studied is really a study of bad local minimas for neural networks. More mentions of the previous work related to the topic would improve the scientific quality additionally, in my opinion.\n', ""In this paper, the authors investigate the collapse of deep and shallow network to a constant function under the following setting:\n1. Very shallow networks, width ~ 10\n2. ReLU activation function.  \n3. Symmetric weights and biases initialization.  \n4. Vanilla feed forward networks.  \n\nThe main take-home message is: don't use neural networks (NNs) that are both deep and shallow.  \n\nThe theoretical analysis is built on the observation: \n1. Every neuron (after applying ReLU) is equal to zero with probability 1/2. \n2. For narrow network and for any fixed input, there is a high chance that all neurons in a particular hidden layer are all zero. All neurons after that layer are all zero if zero-bias initialization is used.  \n3. The authors conclude that derivatives of all parameters vanish but the bias of the last layer.\n4. As a result, the network collapse to its mean (median) if mean squared loss (L1 loss) is used because only the bias of the last layer is being updated during training. \n\nPros.\n1. I think the phenomenon that shallow and deep NNs collapse to a constant is very interesting. \n2. The authors provide empirical and theoretical insights in favor of wider networks: have a better chance to avoid vanishing gradients.  \n3. For shallow networks, it might be better not to use ReLU.  \n\nCons:\n1.The analysis works in a very limited setting, works for ReLU but not other activations: tanh, erf, SELU etc. \n2. Very shallow networks are not popular in practice. Width>=100 is popular for fully-connected layers. \n3. The phenomenon observed by the paper can easily be addressed using any of the following trick: \n   3.1. Non-symmetric initialization  (set the mean to be non-zero). \n   3.2 . wider networks. \n4. Most of the analysis (and theorems)  are about one single input. In another word, distribution of the inputs have not been taken into account.  \n5. I don't think the author provides a completely rigorous justification for the collapse phenomenon.  \n\nOther comments. \n1. Eq (2) in page 4 is not trivially correct. The expectation operator (w.r.p. to lower layers) is moved into the activation function phi, justification is needed for this step.  \n2. Theorem 4: when the Lebesgue measure of $\\Omega$ is NOT finite, it is unclear how to define a uniform probability distribution on it.  \n3. Theorem 4: the integrability assumption on y should depend on the loss: for L2 loss (L1 loss), squared (absolutely) integrable  should be used. They are not the same.  "", ""This paper shows that the training of deep ReLU neural networks will converge to a constant classifier with high probability over random initialization (symmetric weight distributions) if the widths of all hidden layers are too small.\n\nOverall, the paper is clearly written. I like the main message of the paper and the simplicity of its analysis. To some extent, I think that the results could add to our current understanding of the limitations of deep narrow networks, both theoretically and practically. \n\nOn the other hand, my main concern at the moment is that the results seem to be informative only for low dimensional data and networks of small width. In particular, the bound on depth in eq (5) scales too fast with width. Figure 6 shows that with width 16 the bound on depth is already too loose that it could be of any use in practice.\n\nOther comments and questions:\nIn Figure 6+7, it's not clear how many times each experiment is repeated in order to get the numerical estimations of probabilities, and which exactly weight distributions are used here?\n\nThe statement of Theorem 1 and its proof looks a bit suspicious to me. This theorem first makes an assumption on a given network with fixed weights, but then makes some statement about random weights...This apparently does not make much sense to me because a given network has nothing to do with random weights, but the current proof is actually using the assumption made on the given network as a constant classifier to prove the probabilistic statement. I hope to see some clarification here.\n\nIt would be interesting to discuss the results of this paper with recent work [1,2] which also studied deep narrow networks but from other perspectives:\n[1] Neural networks should be wide enough to learn connected decision regions. ICML 2018\n[2] The Expressive Power of Neural Networks: A View from the Width. NIPS 2017""]","[50, -20, 20]","[80, 50, 60]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses strong interest in the research, calling it 'extremely valuable and interesting' and praising the focus on smaller models. However, they also mention 'numerous flaws in presentation' which tempers the overall positivity. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout. They use phrases like 'I would be more than happy' and 'I am very eager to increase my rating,' showing consideration for the authors. Even when pointing out flaws, the language remains constructive and courteous, offering specific suggestions for improvement rather than harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more 'Cons' listed, and the overall tone suggests significant limitations in the paper's approach and applicability. The reviewer points out that the analysis works in a very limited setting, the phenomenon can be easily addressed, and that the author doesn't provide a completely rigorous justification for the collapse phenomenon. These criticisms outweigh the positive points, resulting in a slightly negative sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present both pros and cons in a balanced manner, and their criticisms are presented as objective observations rather than personal attacks. The use of phrases like 'I think' and 'it might be better' softens the critique. However, the review doesn't go out of its way to be overly polite or complimentary, keeping it from scoring higher on the politeness scale."", ""The sentiment score is 20 (slightly positive) because the reviewer expresses appreciation for the main message and simplicity of analysis, stating it could add to current understanding. However, they also express concerns about the results' applicability, which tempers the positivity. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They use phrases like 'I like' and 'it would be interesting,' which maintain a constructive tone. The reviewer also asks questions and suggests improvements rather than making harsh criticisms, further contributing to the polite tone.""]"
"[""The paper proposes a data-dependent regularization method which is coupled with softmax loss to train deep neural networks for classification. The paper turns to Orthogonal Low-rank Embedding (OLE) loss for the geometric constraint that one class of data/feature are assumed to reside on a low-rank subspace that subspaces of different classes are orthogonal ideally. The probability in the softmax is then modeled as cosine similarity between data feature and the class-specific subspaces. In this way, geometric loss and softmax loss have the common goal for optimization. Moreover, during training, the geometry enforced on one batch of features is simultaneously validated on a separate batch using a validation loss. The experiments seem to suggest such a model helps avoid overfitting/memorizing noisy training data. The paper reads well and is easy to follow.\n\nHowever, the paper is limited in technical novelty and practical significance. Here are some concerns -- \n\n1) The paper only studies one method based on OLE, though it cites the center loss [19]. How does the center loss behave in face of noisy training label? Would it also be able to refuse to fit the noisy training data?\n\n2) As each class has its own (low-rank) subspace, and the rank is reduced by imposing the nuclear norm. It seems that the proposed method is hard to extend to many classes (class number is larger than the dimension)?\n\n3) The datasets in the experiments are quite small in scale and class number. It is not persuasive unless tested on larger scale data or with large class number.\n\n4) The proposed method seems to be limited in deal with discrete labels (e.g., classification), is it easy to extend to continuous target, say regression problems like depth estimation and surface normal estimation?\n\n5) While the authors claim as a main contribution that the proposed GRSVNet is a general framework, it is hard to see how this framework can be used in other tasks other than classification.\n\n6) The experiments are less persuasive. It's better to add the error bar to see the improvement by the proposed method is not due to random initialization. Running time should also be compared, as nuclear norm seems to be time consuming."", 'The paper proposes a framework for data-dependent DNN regularization which claimed to be capable of producing highly discriminative features residing in orthogonal-low-rank subspaces. The main claim is that the proposed regularization makes the neural network not memorizing from the training data and motivate learning the intrinsic patterns.  The experiments were done with three image dataset. \n\nThe main problem with this paper is the low training accuracy, but the high testing accuracy (Table 1). This implies that the model has a high bias and low variance. Intuitively the model is consistently predicting a wrong target function (probably from the self-validation).\n\n', 'Previous works have shown that DNNs are able to memorize random training data, even ignoring the enforcing of data-dependent geometric regularization constraints. In this work, authors show convincing results indicating that this is due to a lack of consistency between the main classification loss (typically soft-max cross entropy) and the selected geometric constraint. Consequently, they propose a simple approach where the softmax loss is replaced by a validation loss that is consistent with the enforced geometry. Specifically, for each training batch, instead of considering a join loss (soft-max cross entropy + geometric constraint), they apply a sequential process, where each training batch is split into two sub-batches: a first batch used to apply the geometric constraint, and a second batch (based on the proposed feature geometry) where a validation loss is used to generate a predicted label distribution. Authors test the proposed idea using an implementation that enforces that samples from each class belong to an independent low-rank sub-space (enforced geometric constraint). Results verify the main hypothesis. Specifically, the resulting model is able to fit real data but not data with random labels. The strength of this evaluation is enhanced including results from relevant baselines. In terms of generalization of real data, the proposed approach offers a small increase in accuracy.\n\nPaper is well written, main hypothesis is relevant, and results are convincing. While not a complete answer to the main questions related to the abilities of DNNs to fit and generalize on real data, this paper offers relevant insights related to the role of finding/using a suitable loss function to train DNNs. These results are relevant to the community and they can illuminate future work, so this reviewer recommend to accept this paper.']","[-20, -50, 80]","[60, 0, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper reads well and is easy to follow'), they express several concerns and limitations of the paper, stating it is 'limited in technical novelty and practical significance'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, presenting their concerns as suggestions ('It's better to add...') and questions ('How does...?') rather than harsh criticisms. They also begin with some positive comments before moving to their concerns, which is a polite approach in academic reviews."", ""The sentiment score is -50 because the review starts neutrally by summarizing the paper's claims, but then points out a significant problem with the results, indicating a negative sentiment. The criticism is substantial enough to suggest the reviewer is not convinced by the paper's claims, but not entirely dismissive. The politeness score is 0 (neutral) because the language used is direct and professional, without being particularly polite or rude. The reviewer states the problem objectively without using harsh language or personal criticism, but also without any overtly courteous phrasing."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, stating it is 'well written,' has a 'relevant' hypothesis, and 'convincing' results. The reviewer also recommends accepting the paper, indicating strong approval. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively without harsh criticism. The reviewer offers constructive feedback and praises the paper's strengths, maintaining a professional and courteous tone. The language is not overly formal or excessively polite, hence not reaching the highest politeness score.""]"
"['To exploit the near neighbor/manifold features, this paper proposes to combine k-nearest neighbors of each training data point into the neural network models.  Specifically, the authors propose two families of models built on the popular sequence to sequence neural network models and memory network models, which mimic the k-nearest neighbors model in model learning. Besides, the final label of the classification task will be learned, a sequence of nearest neighbor labels and a sequence of out-of-sample feature vectors (for oversampling) will be also learned in the same time, similar with the multi-task approaches. Since the proposed models are based k-nearest neighbor calculations, which is time-consuming, they also design an algorithm for the ‘out-of-core’ situation, say load a small portion of data each time to approximately calculate the neighbors. Experiments show that some proposed models work better than baselines in classification and oversampling.\nStrong points:\n(1) As similar with the multi-task setting, the proposed model can output some side useful results, such as oversampling vectors.\n(2) The proposed models work well on the ‘out-of-core’ situation, which shows that the models are robust.\nConcerns or suggestions:\n(1) The training data $x$ is just one data point, it is not a sequence of data. So the idea to model it in a sequence to sequence setting does not make sense.\n(2) K-nearest neighbors are a set but not a sequence. To model them as a sequence is also strange. The i-th nearest neighbor does not necessarily dependent on the i-1-th nearest neighbor. For example, we consider the one-dimensional case, the focus data may lie between its first and second nearest neighbors. In this case, there is no clear sequence dependence from the second neighbor to the first neighbor. \n(3) The experiments are not sufficient. They only compare with some weak baselines, such as KNN. As the classification task, there are many state-of-the-art models. Besides of these standard classification models, we strongly suggest comparing with the previous method, Wang et al. (2017), which also proposes to combine the k-nearest neighbors into memory network models. I am surprised that the authors did not compare with this very related work. In my opinion, the idea of utilizing nearest neighbors as external memory in Wang et al. (2017) makes more senses.\n(4) The experimental results of some proposed sub-models (key parts of final models) are even worse than the basic kNN model. I should say that the results are not good enough to support the proposed methods. ', 'I had a hard time understanding this paper. The approach is clearly about combining kNN with neural networks, but it wasn’t clear how it is done. After reading the whole paper, my guess is that kNN is done on raw data first, and then its results are used for training a neural network. In particular, a network is trained to predict the labels of neighboring samples, which are obtained by kNN beforehand. A simple figure explaining it in the introduction would be very helpful since the idea is not that complex. \n\nAlso, the authors also fail to give an adequate explanation on why the method works. The only reason I can think of is that this regularization forces the model to detect if a sample near a class boundary. This is because when a sample is far from boundaries and surrounded by samples of the same class, the model would simply predict that class label. The same is true when predicting out-of-sample vectors because the average position of K\'th neighbor is likely to overlap with the input sample due to the randomness of sampling. \n\nI don’t really see why a memory-based model is introduced. The external memory is used for holding random samples. It is not clear how the model can use such random samples for making predictions. Also, the authors give no explanation to why it should help. The results also don’t show the benefit of a memory-based model. Maybe the authors should look into models that output a set instead of a sequence since neighbors are more like a set in their structure.\n\nThe experimental results show clear improvements over basic baselines, so the method is doing some regularization. However, I\'m not very familiar with datasets used here and their state-of-art. They are relatively low dimensional compared to usual datasets used in deep learning. It is not clear if the method can scale to high dimensional data such as images. The vanilla neural network is not really a strong baseline here. Since the authors proposed a regularization technique, it should be compared with other regularization techniques in neural networks.\n\nPros:\n- a simple idea\n- encouraging experimental results\n\nCons:\n- confusing read\n- no clear intuition is given\n- restricted to low-dimensional datasets\n- strong baselines needed\n- the plots are too small to see (impossible to see when printed)\n\nOther comments:\n- The authors are using the term ""feature vector"" to refer to a data point. However, in the context of neural networks, ""feature vector"" often means a hidden representation of a neural network. \n- why repeat ""randomly draw B samples"" R times? why not directly sample RxB samples?\n- ""it is quite implausible that only affine ..."" any evidence to support this?\n- The model is not really ""sequence-to-sequence"" since the input is not a sequence.\n', 'This work uses sequence-to-sequence and memory network neural nets to learn a\nnetwork that not only predicts a label, but also predicts nearest neighbors and\ntheir label.  The intuition is that by training on a related but harder task,\nthe network is forced to learn not just about sampled points but about the\nbehavior in regions around the actual training examples.\n\nTheir work shows that imposing these additional requirements on the model does\nresult in better performance on unseen data, where only the label of the unseen\ndata point is required as output.  They show that learning more about the \nglobal {feature,label} distribution improves F1 scores, and suggest that their\nmethods can be used as an example generator for datasets with class imbalance.\n\nThe writing was clear.  I had only 1 misunderstanding that cause me trouble,\nnamely the first sentence of ""Classification"", where I might put the word\n\'benchmark\' up front rather than at the end of this somewhat long sentence.\nBy the time \'knn benchmark\' appeared some paragraphs later, I realized I\nhad missed something, and had to backtrack.\n\nFigs 1--3 are only viewable on screen with fairly extreme magnification. I\nfound different viewers varied in legibility at these extreme zoom settings.\nHowever, when expanded so y-axis numbers could be deciphered, it turned out\nthat actual improvements in F1 score were rather modest.\n\nFor 4 datasets, their F1 scores of their best method, V2VSLS, improved by ~ 1.5\nto 6%.  They found that their methods were less affected by out-of-core\ncomputation than the benchmark kNN F1 scores.\n\nI did have some questions about the problem formulation.  I did not really\nunderstand why the models wanted to reproduce the exact ordering of the\nnearest neighbors, other than this is easy to formulate.  This makes sense\nfor n.n. label sequences, where further points might be in some neighboring\nclass.  But for predicting the feature vectors of n.n., it seems that the\nexact order is not robust, in the sense very small distance changes can cause\nabrupt shifts in the target nearest-neghbor ordering.  Is there some way\nfor me to understand why this does not pose a problem?  Or is there perhaps\na way to make the loss function a bit less dependent on the precise order\nof the generated feature vector sequence?\n\nIn the computational experiments, with the choice of datasets, it was often\nhard for me to judge how much different aspects of their 4 network structures\nwere really being excercised.  The main issue is the all problems used only\n2--3 classes.  I could not guess what fraction of data points had actual label\nchanges within the 5 n.n..  For many datasets, ""same class"" might be a pretty\ngood predictor of nearest neighbor label.\n\nAlternatively, one can consider the other extreme, of very many classes.\nDoes it still make sense to try to predict the order of nearest neighbor labels in\nsuch a setting?\n\nThe authors provide evidence of some performance improvement, but I would\nencourage them to provide some intuition about what the networks are actually\nlearning.  Some of this can be done with their existing data.\n\nFor example, on average, what are the distances from predicted feature vectors\nto the actual nn feature vectors?  If the feature sequence is typically badly\npredicted, then this might allow the authors to propose that the network is\n*actually* learning some simpler features of the the distributions underlying\nan actual {feature,label} sequence.  This might allow simplified training losses,\nbased, on things like direction and distance to same-label cluster center,\ndirection+distance to average same-class nn.s, direction and distance to\nclosest differently labeled cluster, etc.  Or does their data suggest that\ntheir models are actually learning the precise nearest neighbor ordering?\n\nSuch considerations might be able to improve the OOC training, since\n""global"" aspects of the distribution features (like ""cluster center"")\nremain approx. valid as training batches changes.\n\nThe other question I had was with the oversampling proposition.  The extent\nof class imbalance in the datasets is not described.  Perhaps it belongs in\nTable 1.  Their approach seems a lot of work for modest gains usually available\nwith oversampling.  Can the authors provide any guideline for how many members a\nminority class should have before using their sequence-to-sequence technique?\n\nPros: they improve generalization to unseen data.\nCons: their models are considerably more complex, and they do not analyze their\ndata in enough detail to suggest whether their complexity is necessary, or perhaps\ncould be reduced.  Figures are too small (many unreadable in printed copy).\nDatasets have very few classes and the extent to which nearest neighbors are\nof different class not reported.\n']","[-50, -40, 20]","[50, 20, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some strong points of the paper, they express several significant concerns and suggestions for improvement. The review starts positively but becomes increasingly critical, especially regarding the experimental results and comparisons. The politeness score is 50 because the reviewer uses professional and respectful language throughout, even when expressing concerns. They use phrases like 'we strongly suggest' and 'I should say' which maintain a polite tone while conveying criticism. The reviewer also acknowledges the paper's strengths before delving into concerns, which is a courteous approach in academic reviews."", ""The sentiment score is -40 because the review is generally critical, pointing out several issues with the paper such as lack of clarity, inadequate explanations, and limitations of the study. However, it's not entirely negative as it acknowledges some pros like 'a simple idea' and 'encouraging experimental results'. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They use phrases like 'I had a hard time understanding' and 'It is not clear' rather than harsh or rude language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work's improvements and clear writing, but also points out several limitations and areas for improvement. The review begins with a neutral summary, then highlights positive aspects like improved performance and clear writing. However, it also raises concerns about figure legibility, modest improvements, and the need for more intuition about what the networks are learning. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or encouragements rather than demands. The reviewer acknowledges both pros and cons, and uses phrases like 'I had only 1 misunderstanding' and 'I would encourage them to provide' which maintain a polite tone while offering feedback.""]"
"['The authors propose a data-dependent dropout variant that produces dropout candidates based on their predictive saliency / relevance. Results are reported for 4 datasets (Cifar10, Cifar100, Caltech256 and UCF101) and 4 different models (CNN-2, AlexNet, VGG16 and VGG19), and suggest an increase in generalization performance over other dropout approaches (curriculum dropout, standard dropout, no dropout), as well as increase in the network\'s plasticity as measured by some existing metrics from the literature. The authors conclude that Excitation Dropout results in better network utilization and offers advantages for network compression (in the sense of neuron pruning).\n\nOverall I find the idea to be interesting and fairly novel, and commend the authors for the fluid writing style. However, I find key issues with the testing and experiments. Specifically, the lack of confidence bounds for individual results makes it impossible to determine whether the reported incremental improvements are actually significant over those of existing approaches. Likewise, I criticize the choice of methods the authors have chosen to compare against, as several other data-dependent dropout approaches (e.g. Information Dropout) exist that may be conceptually closer (and therefore more comparable) to the proposed approach. I also question the choice of tested network architectures and the placement of the dropout layer.\n\nThe paper could be of high significance if all claims in the paper could be backed up by experiments that show the advantage of Excitation Dropout to be not a random effect. I will therefore give a lower score for the paper in its current form, but am willing to revise my rating the major points below are properly addressed.\n\nPros:\n+ novel mechanism to improve dropout, results seemingly superior over other methods\n+ achieves better utilization of network resources and achieves robustness to dropping out neurons at test time\n\nCons:\n- results without error bars, unclear if advantage is significant\n- did not compare against most relevant competing methods\n\n\nMAJOR POINTS\nSection 2 - The comparison to Moreiro et al. is not entirely clear. A fairer comparison would be with some of the other methods listed which also focus on answering the question of which neurons to dropout, or approaches which determine the dropout policy based on information gained from the data, such as Information Dropout (Achille & Soatto). The authors state that Morerio et al are the state-of-the-art in dropout techniques, however based on the results presented here (Figure 3) it seems to perform just as well as standard dropout. Perhaps there are architecture-specific or data-specific issues? In any case this example undermines the confidence of the claims.\n\nSection 3.2, equation 3 - is there some theoretical underpinning as to how this equation was modelled, or was it chosen simply because it covers the expected corner cases described in paragraph 4 of this section? Also, given the intuition in this paragraph (e.g. p_EB = 1 / N), it is correct to assume this equation models the dropout probability but only for fully connected layers? What about dropout in convolutional layers? Though some previous statements do point to the usage of dropout predominantly for fully connected layers, I feel that this context is missing here and should be explicitly addressed. The caption to e.g. Table 1 seems to imply the authors add a single dropout layer in one of the fully connected layers, however this begs the question as to why this positioning was chosen - why only one dropout layer, and why precisely at that location? The scope of the claims should be adapted accordingly.\n\nSection 4.2 - ""After convergence, ED demonstrates a significant improvement in performance compared to other methods"". If five trained models were used, then some sense of measure of uncertainty should be given throughout. For example, in the Cifar10 results for Figure 3, it is difficult to say whether the marginal improvement from about 80% (standard dropout and curriculum dropout) to about 82% (excitation dropout) is significant or not. Perhaps this would be less of an issue if the authors had worked with e.g. ImageNet, but for these smaller datasets it would definitely be worth to be on the safe side. I highly suspect that statistically speaking (perhaps with the exception of the results on Caltech256), the effects of all of these dropout variants are indistinguishable from each other. I urge the authors to include a measure of the standard deviation / 95% confidence interval across the models that were tested.\n\nThe results presented sub-section 4.3 do not justify the claim that the models trained with Excitation Dropout tend to be more informative. Perhaps the definition of ""informative"" should be expanded upon in length. Can the authors show that the alternative paths learned by the models augmented with Excitation Dropout indeed carry complimentary information and not just redundant information?\n\nFigure 5 shows interesting results, but once again begs the question of whether there is any significant difference between standard dropout and curriculum dropout. I encourage the authors to include confidence bounds for each trace. Likewise, there is an inherent bias in the results, in that the leftmost figure compares EB and CD in the context in which EB was trained, i.e. dropping of ""most salient"" neurons. The comparison is one-sided, however, as no results are reported from the context in which CD was trained, i.e. dropping neurons more frequently as training progresses. Comparing these results would bring to light whether the performance boost see in Figure 5 is a function of ""overfitting"" to the training manner or not.\nAlso, I believe the results for the second column (dropping out least relevant neurons) are misleading. To the best of my understanding, as p_c increases, at some point neurons start to be dropped that actually have high relevance. This could explain why all curves start out similarly and EB slowly begins to stick out - at this point the EB models once again start to be used in the context within which they were trained, in contrast to the other approaches. The authors should perhaps also explicity clarify why this second column gives any more information than the first.\n\n\n\nMINOR POINTS\n\nThe authors propose Excitation Dropout as a guided regularization technique. Batch normalization is another standard regularization technique which is often compared with dropout. In particular, for deep CNNs, batch normalization is known to work very well, often better than the standard dropout. In the experiments here, to what extent was batch normalization and / or any other widely utilized network regularizers used? Is it possible that the regularizing effect found here actually comes from one of these? I.e. were the models that were not trained from scratch trained with batch normalization? It would be good if more data could be provided for EB vs. other regularizing techniques, if the claim is that EB is a novel regularizer.\n\nSection 3.1 - ""We choose to use EB since it produces a valid probability distribution for each network layer"". Though this is a nice property, were there any other considerations for choosing the saliency method? Recent work (Adebayo et al, ""Sanity Checks for Saliency Maps"") has shown that even some well established saliency techniques are actually independent from both the model and data. As this approach relies heavily on the correctness of EB, I feel that a further justification should be given to validate its use for this scenario other than just based on the type of output it produces.\n\nSection 3.1, equation 2 - more detail and reasoning should be given as to why connections with negative weights are excluded from the computation of the conditional probability, if possible without referring the reader to the EB paper. Why is this justified? Is this probability modelled for a specific activation function? \n\nThe authors do not provide the details of the CNN-2 architecture (even in the appendix) and simply refer to another article. If the majority of the results presented in the paper are based on this network (including a reference made to a specific layer of the network in subsection 4.2) – which is not commonly known – why not to detail the network architecture and save additional effort for the reader?\n\nHow are the class-wise training and test images chosen for Caltech256 dataset?\n\nThe authors test the CNN-2 architecture on Cifar10 and Cifar100, and AlexNet, VGG16, and VGG19 on UCF101. I feel that at least a couple architectures should be validated with more than a single dataset, or the authors should justify the current matching between architectures and datasets. Table 2 is unclear regarding what models were used for what datasets (caption could be interpreted to mean that VGG16 was also used for Cifar and Caltech, however other statements seem to say otherwise).\n\n""To prove that the actual boost in accuracy with ED is not provided by the choice of specific masks,..."" I suggest that the authors rephrase or explain this sentence in more detail. To the best of my understanding, it is precisely the fact that different masks are used, each reflective of the particular input used to generate the forward activations, that gives boost in performance over ""standard"" dropout methods by identifying salient paths in the network.\n\nAlthough it is a very important experimental detail, only in the end of sub-section 4.2, it becomes clear in which layers Excitation Dropout was applied. \n\nY-axis labels are missing for the left panels in Figure 3.\n\nThe authors randomly choose to abbreviate Excitation Dropout as ED in some paragraphs, while write the full form in others.  \n\nTable 2 - It is not clear that the ""Neurons ON"" metric refers to the ""average percentage of zero activations"" explained below. \n\nTable 2 - How is peak p_EB measured? Is this an average over a set of test images after convergence? If so, I similarly suggest for confidence bounds to be introduced. It would be interesting to compare this to intermediate values (e.g. after every epoch) during training. Same question for entropy of activations and entropy of pEB. This information would be useful for reproducibility.\n\nTable 2 - Where do the delta values in Table 2 come from? If empirically determined, it should be stated explicitly.\n\nTable 2 - In general, because the metrics provided in Table 2 are averages (second paragraph of this Section 4.3), both (to the best of my understanding) across input subsets (e.g. averging results over many test inputs) and models (caption to Table 1), I feel Table 2 in its current form raises confusion given the lack of confidence bounds. I recommend the authors to clarify what type of averaging was done and to introduce e.g. standard deviations across all reported scores. The authors should refrain from using the term ""significantly"" while describing results if no statistical testing was done, or explicitly clarify their usage of this term.\n\nTable 2 - In general, Table 2 reports results on selected metrics which, if the authors\' hypothesis is correct, should have a clear trend as training progresses. An interesting idea to explore would be to include an analysis (in the appendix) of how these factors change over the course of the training procedure. Intuitively, it seems plasticity is something that should be learned slowly over time, so if these plots were to reveal something different, it would be indicative that something else is going on.\n\nFigure 4 - Judging heatmaps is difficult as it depends on the visual perception of the reader. Thus, it is difficult to judge whether, as the authors claim, ED is indeed less ""peaky"" than the other alternatives. I suggest that the authors use a perceptually uniform heatmap, and to acompany these figures with e.g. the histogram of the heatmap values. Likewise, it is unclear how the multi-model aspect of the testing plays a role in generating these results. From the 5 originally trained models, how was the model selected that generated these results? Was there averaging of any kind?\n\nFigure 5: the text is too small to be readble\n\nIs ""re-wiring"" the most appropriate term to use to describe what is happening at inference time? Although different paths may be used, the network connections themselves are fixed and thus this is a potential source for confusion.\n\nWhat do numbers in Table-4 in the appendix represent? Test accuracy? ', ""This is an interesting idea that seems to do better than regular dropout.\nHowever, the experiment seem a bit artificial, starting with less modern network designs (VGG) that can benefit from adding dropout. State of the art computer vision networks don't seem to need dropout so much, so the impact of the paper is unclear.\n\nSection 4.4: How does this compare to state-of-the-art network compression techniques? (Deep compression, etc)\n"", 'This paper presents a variation of dropout, where the proposed method drops with higher probability those neurons which contribute more to decision making at training time. This idea is evaluated on several standard datasets for image classification and action recognition.\n\nPros:\n1. This paper has interesting idea related to dropout, and shows some benefit.\n2. Paper is well-written and easy to understand.\n\nCons:\n1. There are many variations in dropouts and they all claim superiority to others. Unfortunately, most of them are not justified properly. Excitation dropout looks interesting and has potential, but its validation is not strong enough. Use of Cifar10/100, Caltech256, and UCF 101 may be okay for concept proofing, but not be sufficient for thorough validation. Also, the reported results are far from the state-of-the-art performance of each dataset. I would recommended to add the idea to the network \n to achieve the state-of-the-art performance because it will show real extra benefit of ""excitation"" dropout. \n\n2. There are many variations of dropouts including variational dropout, L0-regularization, and adaptive dropout, and the paper needs to report their accuracy in addition to curriculum dropout.\n\n3. Dropout does not exist in many modern deep neural networks and its usability is a bit weak. It would be better to generalize this idea and make it applicable to ResNet-style networks.\n\n4. There is no clear (theoretical) justification and intuition why excitation dropout improves performance. More ablation study with internal analysis would be helpful.\n\nOverall, this paper has interesting idea but needs more efforts to make the idea convincing.']","[-20, 20, -20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the idea interesting and novel, they express significant concerns about the methodology and results, stating the paper needs major revisions before it could be considered high quality. They point out several major issues like lack of confidence bounds and comparisons to relevant competing methods. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement. They use phrases like 'I commend the authors' and 'I encourage the authors to' which maintain a collegial tone despite the critical feedback. The reviewer also expresses willingness to revise their rating if issues are addressed, showing openness to the authors' perspective."", ""The sentiment score is slightly positive (20) because the reviewer starts by calling it an 'interesting idea' and notes that it performs better than regular dropout. However, this positivity is tempered by concerns about the experimental setup and unclear impact, leading to a only mildly positive overall sentiment. The politeness score is moderately positive (50) as the language is professional and constructive. The reviewer uses phrases like 'interesting idea' and frames criticisms as questions or observations rather than direct attacks. There's no harsh language, but also no overtly polite phrasing, resulting in a score that's positive but not extremely high."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting idea', 'well-written'), they express several significant concerns and state that the paper 'needs more efforts to make the idea convincing'. The overall tone suggests that the paper has potential but falls short in several important areas. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as recommendations (e.g., 'I would recommend', 'It would be better'). The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out weaknesses.""]"
"['The paper studies discrete time dynamical systems with a non-linear state equation.  They assume the non-linear function is assumed to be \\beta-increasing like leaky ReLU. Under this setting, the authors prove that for the given state equation for stable systems with random gaussian input at each time step, running SGD on a fixed length trajectory gives logarithmic convergence.\n\nThe paper is well-written and proves strong convergence properties. The deterministic result does not seem very novel and uses the idea of one-point strong convexity which has been studied in various prior works. However the bounding of the condition number of the data matrix is interesting and guarantees are near-optimal. The faster convergence for odd activations is a good observation. Overall, I think the paper is good. I do list some concerns:\nQuestions/concerns:\n- The deterministic theorem (Theorem 4.1) seems similar to Theorem 3 in [1] with SGD instead of GD. Also under the distribution being symmetric, it can be derived from [2] with $k=1$. \n- Can the ideas be extended to other commonly used activations such as ReLUs/Sigmoids? Sigmoids have exponentially small slope near origin.\n- The proof seems to rely on the fact that due to the gaussian input added each time step and stable system assumption after a sufficient number of time steps, the input-output pairs will not be highly correlated. So the data is sufficiently uncorrelated taking enough data. What happens if this data at each step is not gaussian?\n- In the unstable setting, the solution proposed just samples from different trajectories which by default are independent hence correlation is not an issue, this seems a bit like cheating. \n- In RNNs, the motivation of the work, the hidden vectors are not observed, thus this setting seems a bit restrictive.\n- If SGD was performed on only one truncated series, do the results still hold?\n\nOther comments:\n- There has been previous work on generalized linear models which work in more general settings like GLMtron [3]. The authors should update prior work on generalized linear models as well as neural networks.\n- Typo on Page 2 y_t = h_{t+1} not y_t = h_t.\n\n[1] Dylan J. Foster, Ayush Sekhari, and Karthik Sridharan. Uniform Convergence of Gradients for Non-Convex Learning and Optimization. NIPS 2018.\n[2] Surbhi Goel, Adam Klivans, and Raghu Meka. Learning One Convolutional Layer with Overlapping Patches. ICML 2018.\n[3] Sham M. Kakade et al. Efficient learning of generalized linear and single index models with isotonic regression. NIPS 2011.\n\n\n--------------\nI would be maintaining the same score. I agree that the paper has nice convergence results that could possibly be building steps towards the harder problem of unobserved hidden states however, there is more work that could be done for unstable systems and possible extension to ReLU and other activations to take it a notch higher. ', 'This paper studies the ability of SGD to learn dynamics of a linear system + non-linear activation. That is, in the standard LTI setting, the dynamics of a system evolve according to\n\nh_{t+1} = Ah_t + Bu_t,\n\non input u_t.\n\nIn addition, this paper considers the setting where the evolution is:\n\nh_{t+1} = \\phi(Ah_t + Bu_t)\n\nfor \\phi a non-linear activation function. \n\nThis is a difficult problem. Though system identification was for many decades a large and active area in the control community, the understanding of system identification from a modern statistical perspective (understanding sample complexity and computational complexity simultaneously) is surprisingly lacking. This is evidenced by the fact that the first results along these lines for the simplest possible (SISO, LTI) system, came only recently (Hardt, Ma, Recht ’16). \n\nThis paper attacks a more general setting, due to the presence of the nonlinearity.\n\nHowever, the present setting is significantly limited in another sense: the authors assume that the state is observed directly. This is in contrast to the typical situation where we observe only a projection of the state, or possibly even a noisy such projection. Indeed, this is one of the critical complications in the work of Hardt, Ma and Recht. Without it, i.e., under the assumption that the entire state trajectory can be directly observed, much more is possible, and indeed much more has been done. For example, work by Bento, Ibrahimi and Montanari ’10, solves a more difficult problem in that they estimate sparse dynamics (in appropriate sample complexity). Jalali and Sanghavi ’11 generalized the work of Bento et al., to the setting where some of the components of the state are not all observed, but rather some are latent.\n\nThe motivating application for this work is estimating RNNs. In this case, the state variable represents the critical information that is carried from one time to the next in the RNN. Presumably the setting here is to show that if indeed data are generated by an RNN, then we can compute this using SGD and backprop. Towards this, the assumption of having access to the internal state is a difficult one. On the one hand, this is a hard and important problem. On the other, we really won’t have access to such an internal state. There are of course other problematic aspects, such as robustness, the inability to use ReLU (Defn 3.1). But the observation model seems important. Again, I believe this is especially so, because the considerable complications present in Hardt, Ma, Rect ’16 specifically seemed to be a consequence of the observation model being partial.\n\nThe inability to use ReLU at first look does not seem like a great limitation. But then one problematic aspect here seems that the proof concept and direction critically rely on this, as they basically reduce to the setting of linear activations — something which, presumably, is impossible for something like ReLU. So it is not only the results, but also the developed machinery, that seem to be inherently limited.\n\nThis is, overall, an interesting paper, attacking an important and also very challenging area. As with all papers in this vein, we are left with having to make a judgement call on whether this simplified scenario is indeed a good first step towards solving the problems we are hoping to solve. Is it developing the right insight, right tools, etc. While I find there is a lot of interesting and good work in this paper, I am not completely convinced about this last point.', 'This work considers the problem of learning a non-linear dynamical system in which the output equals the state.  Under several assumptions (input is Gaussian, non-linear activation is strictly increasing, stable system) it is shown that SGD converges linearly to the ground truth system with near-optimal sample complexity. The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. The main challenge is to show the covariance is well-conditioned under the reduction. In a nutshell, this is done by splitting the trajectory to sub-trajectories with independent states and using results from random matrix theory on matrices with independent rows.\n \nThis work tackles a very challenging problem and the results are interesting. The guarantees are strong – linear convergence to the ground truth parameters and near-optimal sample size. Given that not much is known on deep non-linear networks, I think that the result is significant. The main weakness of the paper is the assumption that the state equals the output. Another minor weakness is the clarity and presentation of results:\n1.       The proof outline of the main result is hard to follow. There is no proof outline of Theorem 4.2 in the main text. The proof is highly technical and there are many technical ideas that were moved to the appendix. For instance, the proofs in sections C and D are not mentioned in the main text. I suggest to write a summary of the steps required to prove the main result and how all of the technical ideas are combined together.\n2.       There is no reference and comparison to the paper of Mei et al. [1] that study single neuron models.\n3.       It is claimed that by increasing beta the convergence is faster. However, I am not sure why this is meaningful. By changing beta the ground truth changes as well. For beta = 0 the ground truth dynamical system is linear and for beta = 1 the ground truth is a non-linear dynamical system with ReLU. Since a ReLU network is more expressive, generally in the case of beta = 1 the ground truth is more difficult to learn than beta = 0. Therefore, we should expect convergence to be slower than beta=0 or not occur at all. Am I missing something?\n4.       The Gaussian assumption is not stated clearly in the text. It can be deduced only from the statements of the theorems and the conclusion section.\n5. In Theorem F.1, it is claimed that all rows of E are equal. However, in the statement of the theorem it is not mentioned that the rows of A are identically distributed. Should this assumption be included in the statement?\n\n[1] Mei, Song, Yu Bai, and Andrea Montanari. ""The landscape of empirical risk for non-convex losses."" arXiv preprint arXiv:1607.06534 (2016).\u200f \n\n\n-----------Revision------------------------\n\nI am not changing the score. I disagree with AnonReviewer2 regarding the significance of the results.  The assumption that the states are observed is indeed a weakness of the paper. However, understanding non-linear dynamical systems is extremely challenging and this paper provides strong convergence guarantees. Furthermore, there are several insights in the analysis that may be useful in future work.\n\n']","[50, -20, 50]","[75, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer states 'Overall, I think the paper is good' and acknowledges strong points like 'well-written' and 'proves strong convergence properties'. However, they also list several concerns and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'Questions/concerns' rather than direct criticisms. They also offer constructive suggestions and references to improve the paper, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and addressing an 'important and challenging area', they express significant reservations about the limitations of the study, particularly the assumption of direct state observation and the inability to use ReLU. The reviewer is 'not completely convinced' about whether this approach is the right step towards solving the intended problems. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the difficulty of the problem and the interesting aspects of the work. They present their criticisms in a constructive manner, explaining their concerns without using harsh or dismissive language. The reviewer maintains a professional tone, balancing positive comments with their critiques."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the work as tackling a 'very challenging problem' with 'interesting' and 'significant' results, showing 'strong guarantees'. However, they also point out some weaknesses, particularly the assumption that the state equals the output, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive comments. They phrase their concerns as questions or suggestions (e.g., 'Am I missing something?', 'I suggest to write...') rather than direct criticisms. The reviewer also balances positive and negative feedback, starting with the strengths before discussing areas for improvement, which is a polite approach to reviewing.""]"
"['This paper presents a new approach to an active learning problem where the idea is to train a classifier to distinguish labeled and unlabeled datapoints and select those that look the most like unlabeled.\n\nThe paper is clearly written and easy to follow. The idea is quite novel and evokes interesting thoughts. I appreciated that the authors provide links and connections to other problems. Another positive aspect is that evaluation methodology is quite sound and includes comparison to many recent algorithms for AL with neural networks. The analysis of Section 5.5 is quite interesting.\nHowever, I have a few concerns regarding the methodology. First of all, I am not completely convinced by the fact that selecting the samples that resemble the most unlabeled data is beneficial for the classifier. It seem that in this case just the data from under-explored regions will be selected at every new iteration. If this is the purpose, some simpler methods, for example, relying on density sampling, can be used. Could you elaborate how you method would compare to them? I can see this method as a way to measure the representativeness of datapoints, but I would see it as a component of AL, not an AL alone. What would happen it is combined with Uncertainty and you use it to labeled the points that are both uncertain and resemble unlabeled data? \nBesides, the proposed approach does not take the advantage of all the information that is available to AL, in particular, it does not use at the information about labels. I believe that labels contain a lot of useful information for making an informed selection decision and ignoring it when it is available is not rational.  \nNext, I have conceptual difficulties understanding what would happen to a classifier at next iteration when it is trained on the data that was determined by the previous classifier. Seems that the training data is non-iid and might cause some strange bias. In addition to this, it sounds a bit strange to use classification where overfitting is acceptable.\nFinally, the results of the experimental evaluation do not demonstrate a significant advantage of the proposed method and thus it is unclear is there is a benefit of using this method in practice. \n\nQuestions:\n- Could you elaborate why DAL strategy does not end up doing just random sampling?\n- Nothing restrict DAL from being applied with classifiers other than neural networks and smaller problems. How do you think DAL would work on simpler datasets and classifiers?\n- How does the classifier (that distinguished between labeled and unlabeled data) deal with very unbalanced classes? I suppose that normally unlabeled set is much bigger than labeled. What does 98% accuracy mean in this case?\n- How many experiments were run to produce each figure? Are error bars of most experiments so small that are almost invisible?\n\nSmall comments:\n- I think in many cases citep command should be used instead of cite. \n- Can you explain more about the paragraph 3 of related work where you say that uncertainty-based approach would be different from margin-based approach if the classifier is neural network?\n- Last sentence before 3.1: how do you guarantee in this case that the selected examples are not similar to each other (that was mentioned as a limitation for batch uncertainty selection, last paragraph on page 1)?\n- It was hard to understand the beginning of 5.5, at first it sounds like the ranking of methods is going to be analysed.\n- I am not sure ""discriminative"" is a good name for this algorithm. It suggested that is it opposite to ""generative"" (query synthesis?), but then all AL that rank datapoints with some scoring function are ""discriminative"".', 'The paper is proposing a distribution matching as a metric for active learning. Basic intuition is: if we can make the distribution of labelled and unlabelled examples similar to each other, training error in one will approximate the training error in the other. Hence, a model learned using labelled ones will do well in unlabelled ones. The main tool to enforce this distributional distance is using adversarial learning similar to GANs or gradient reversal network for domain adaptation.\n\nThe idea is definitely interesting. I am not sure about why should it work (I explained in detail later), but it does work well empirically. Moreover, it is very easy to implement. Given any learned or hard-coded features, learning a simple binary classifier is sufficient to implement the method. The mini-queries idea in 4.1 is especially interesting. Handling large batches in active learning is always a problem but this neat trick make it much easier.\n\nI think the proposed method is counter intuitive as the discussion does not explain why should it work better than random sampling. Clearly if labelled samples are randomly sampled, labelled and unlabelled data is coming from the exactly same distribution. Hence, the distance (H-divergence, TV-distance etc.) between them is 0. My main question to authors is why does this method work better than random sampling? A similar question is; since they are coming from the exact same distribution, what is the meaning of minimizing empirical H-divergence? I think a more detailed study on a toy problem could potentially explain this. Authors can generate 1-D or 2D samples from a well defined distribution (eg. Gaussians with different means/variances for each class) and visualize what is the algorithm actually doing. \n\nConsidering my point that these data points are actually coming from the same distribution, discussion in Section 3.1 is rather unjustified. Most of the entities discussed in that section are probabilistic entities (generally speaking expected values) and does not differ between labelled and unlabelled case since they have same underlying distribution. Their empirical values are different but this is beyond the study of Ben-David(2010). Therefore, I am not sure does the Section 3.1 is contributing to the paper without any explicit connection to the empirical divergence minimization. More importantly a much similar work from domain adaptation is [Unsupervised domain adaptation by backpropagation, ICML 2015] and it should also be discussed in the paper.\n\nSome minor issues:\n- Are the hyper-parameters kept fixed for all experiments. In other words, does the training size of 5k and 15k share hyperparameters? Which might be sub-optimal.\n- The experiments use very large batch sizes. A smaller batch sizes might separate the algorithms better.\n- References in the text have some issues. There are missing commas between references in the text. There are also some cases where \\citep should have been used but \\citet is used. A careful pass over them might be beneficial.\n\nIn summary, I think the paper is interesting, easy to implement and possibly useful to the large part of the community since active learning is very important problem. I think the major weakness of the paper is the fact that authors did not give a clear explain why does it actually work. I think it is crucial for authors to provide a theoretical or an empirical study which answer this question.\n', ""Thank you for this enjoyable paper. \n\nSummary: The authors propose a novel approach to active learning as follows. At each iteration they develop a classifier that can discriminate between the samples in the labeled and unlabeled sets; they select the top few samples that are most likely to be from the unlabeled set as per this classifier, and request the oracle to provide labels for this batch next. This simple idea is shown to have a principled basis and theoretical background, related to GANs and to previous results from the literature. They provide clear algorithms and open source code for easy verification, and public testing. They provide good experimental verification on CIFAR-10 and MNIST benchmarks. I personally look at new papers more for novel ideas and good intuition/theoretical justification than an immediate improvement in benchmark results, so I enjoyed this paper thoroughly. \n\nResults: Among other things they show that their algorithms ranks the samples to be next labeled quite differently than uncertainty sampling based approaches; that their method is at least as accurate/sample-efficient as the state of the art ; and that some previously published experimental results are incorrect(!). As the authors will probably agree I am not convinced the proposed method is better than previous algorithms in any statistically significant way, but the novel idea itself is worth publishing even if it is just as good as the state of the art. \n\nNovelty: I liked the paper very much because it provides quite an innovative new approach to look at active learning, which resembles GANs and Core set ideas in some ways, yet differs in significant ways that are critical for active learning. I've been working and publishing in related areas for a long time so I genuinely found your central idea refreshing and new.\n\nRelevance: The paper is very relevant to the ICLR community and addresses critical questions. \n\nQuestion:\nMy intuition as a Bayesian is that we most need to find labels that maximize the mutual information I(y,w) where w are the weights of the neural net. In practice this corresponds to the samples x which have the maximum class uncertainty, but for which the parameters under the posterior disagree about the outcome the most, eg see discussion below equation 2 for  Bayesian Active Learning by Disagreement (BALD) in this paper https://arxiv.org/pdf/1112.5745.pdf . In essence: The above means that the labels that provide most information about the classification model are most valuable for active learning. \n\nHowever, your approach intuitively ignores the conditional distribution(ie py(|x)), and instead tries to make the original unconditional distribution p(x) between the labeled and unlabeled sets similar. Yet, it works beautifully. So: Why does this work? What is the intuition?\n""]","[20, 50, 90]","[60, 75, 80]","[""The sentiment score is slightly positive (20) because the reviewer starts with positive comments about the paper being clearly written, novel, and having a sound evaluation methodology. However, they also express several concerns and questions, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges positive aspects before presenting concerns. They use phrases like 'I appreciated' and 'Could you elaborate' which contribute to a polite tone. The review maintains a professional and constructive approach, even when expressing doubts or criticisms."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the paper 'interesting' and 'possibly useful', praising its ease of implementation and empirical results. However, they also express significant concerns about the lack of theoretical justification and explanation for why the method works. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions or suggestions rather than harsh criticisms. They also balance negative points with positive ones and use phrases like 'I think' to soften their critiques. The reviewer maintains a professional and courteous tone while still providing thorough feedback."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'enjoyable', state that they 'liked the paper very much', and found the central idea 'refreshing and new'. The reviewer also praises the paper's novelty, relevance, and theoretical justification. While they note that the proposed method may not be statistically significantly better than previous algorithms, they still consider the novel idea worth publishing. The politeness score is 80 because the reviewer uses consistently polite and respectful language. They begin with a thank you, use phrases like 'I personally look at...', and frame their question at the end in a curious and respectful manner. The reviewer also acknowledges the authors' potential agreement with a point, showing consideration. While very polite, it doesn't reach the maximum score as it maintains a professional tone rather than being excessively deferential.""]"
"['This paper centers around adding a reward term that, as I understand it, rewards the agent for having seen sequences of rewards that have low variability. This is an interesting idea, however I find the clarity of the main part of the paper (section 4.1, where this new term is defined) quite poor. That section makes several seemingly arbitrary choices that are not properly explained, which makes one wonder if those choices were made mostly to make the empirical results look good or if there are some more fundamental and general concepts being captured there. In particular, I have to wonder where the 100 in the definition of R_H comes from, and also how sigma_max would be determined (it is very hard to get a good intuition on such quantities as an RL practitioner).  \n\nThe paper also introduces “hot-wire exploration”, basically trying the same action for a while during the initial stage, which is a nice exploration heuristic for Atari, but I am not sure how generally applicable the idea is beyond the Atari testbed.\n\nIn general, I am always a bit wary of experimental results that were obtained as a result of introducing additional hyper-parameters or functional forms. However, the results look pretty good, and the authors do manage to show some amount of hyperparameter robustness, which makes me wish the design choices had been more clearly explained..\n', 'Recommendation: Weak reject\n\nSummary:\nThe paper proposes a variant of deep reinforcement learning (A2MC) for environments with sparse rewards.  The approach replaces the standard environment reward function with a combination of the current reward and the variability of rewards in the last T timesteps, with a goal of decreasing variability.  The authors further propose a “hot-wiring” exploration strategy to bootstrap agents by taking either random actions or actions that have been done in the recent history.  Empirical evaluations in standard benchmarks including several sparse reward Atari games show empirical improvement of this approach over a baseline (ACKTR).\n\n\nReview:\n\nThe paper has strong empirical results that show the A2MC outperforming or reaching the same performance as the baselines in a large number of Atari and MuJoCo domains.  The authors also provide results with and without the hot-wiring feature, which helps isolate its contribution.  However, overall the paper lacks theoretical rigor and most of the proposed changes are done without principled reasons or convergence guarantees.   There is no way of telling from the current paper whether these changes could lead to divergence or suboptimal behavior in other domains.  Examples of such changes include:\n\n* The averaging of the reward terms at different timescales in Equation 4 is the core of the algorithm but is derived ad-hoc.  Why is this a good equation?  Is lack of variability really a desired property and may it lead to a suboptimal policy?  Can anything be said about how it changes behavior in a tabular representation?\n\n* The exponential equation with a constant of 100 appears out of nowhere in equation 5.  Is this a general equation that will really work in different domains and reward scales?\n\n* The variability weights in equations 6 and 7 are never tested empirically – what happens if they are left out?  Where did this equation come from?\n\n* Overall, it is unclear if the combination of rewards at different time scales in equation 10 is stable and leads to convergence.  The terms show resemblance to the eligibility trace equations but lack their theoretical properties.\n\nTo make the paper ready for publication, the authors need to justify which of these changes are “safe” in that they guarantee the behavior of the algorithm cannot become much worse, or need to point directly to other methods in the literature that have used such changes and cite the pros and cons that were seen with those changes.\n\nRelated to the theme above, the paper does not properly cite other methods used with sparse rewards in traditional RL or Deep RL, especially eligibility traces, which seem highly related to the current approach.  The following related work edits are needed:\n\n* The overall approach is thematically similar to eligibility traces (see the standard Sutton and Barto textbook), except that the authors here use variability rather than combining the reward terms directly.  Eligibility traces are built exactly for these sorts of sparse reward problems and combine short and long-term rewards in a TD update. But there has been substantial investigation of their theoretical properties in the tabular and function approximation cases. The current method needs to compare and contrast to this long-standing method both theoretically and empirically. \n\n* Two other methods that should have been considered in the experiments are experience replay and reward shaping, both of which are beneficial with deep RL in sparse domains.  Experience replay is mentioned in the paper but not implemented as a competitor.  I realize ER is not as computationally efficient as the new approach but it is an important (and stable) baseline.  Reward shaping is not mentioned at all, but is again an important and stable baseline that has been used in such problems – see “Playing FPS Games with Deep Reinforcement Learning” (AAAI, 2017).\n\n* Finally, the related work section mentions a lot of competitive algorithms but does not implement any of them in comparison, which makes it hard to claim the current approach is the best yet proposed.\n\n']","[-20, -40]","[50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and good results, they express concerns about clarity, arbitrary choices, and the general applicability of some concepts. The reviewer is 'wary' of the experimental results and wishes for better explanations. However, it's not entirely negative as they recognize the potential and some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting idea' and 'nice exploration heuristic' to acknowledge positive aspects. Even when expressing concerns, they use polite language such as 'I find the clarity... quite poor' and 'I have to wonder' rather than using harsh or dismissive language. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach in academic reviews."", ""The sentiment score is -40 because the review starts with a 'Weak reject' recommendation and highlights several significant issues with the paper, including lack of theoretical rigor, unjustified changes, and missing comparisons to important baselines. However, it does acknowledge some strong empirical results, preventing an extremely negative score. The politeness score is 20 because the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. The reviewer acknowledges the paper's strengths before delving into weaknesses and uses phrases like 'To make the paper ready for publication...' which imply the issues are fixable. The tone remains respectful and focused on improving the work rather than dismissing it entirely.""]"
"['This paper proposes a technique for channel-wise quantization of CNNs\nto 8-bit, fixed point precision. The authors propose several\ntechniques for analyzing the statistical properties of output channel\nactivations in order to select the best fractional bit length for each\nchannel. Experimental results on eleven different CNN architectures\ndemonstrate that the approaches proposed result in significantly less\naccuracy loss when compared to a layer-wise baseline.\n\nThe paper has the following strengths:\n\n 1. The experimental results on eleven different architectures (of\n    varying depth and breadth) are convincing, and are consistently\n    better than layer-wise MAX for choosing fractional bit length.\n\nThe paper has the following weak points:\n\n 1. There is not much coherence between the description of the\n    approach in section 2.1, Figure 1, Algorithm 1, and\n    Figure 2. Notation is used in Algorithm 1 which is never defined.\n 2. Related to the previous point, the proposed technique has a lot of\n    moving parts and I don\'t feel that it would be easy to reproduce\n    the results of the paper. There are some vague statements, like\n    ""We resolve this complication by pre-coordinating the fractional\n    lengths of the weights"", which require significantly more\n    precision. This issue -- one of the main issues with channel-wise\n    versus layer-wise quantization -- is never returned to in the\n    definition of the method.\n 3. The experimental comparison with layer-wise quantization is\n    somewhat lacking. Is layer-wise MAX the state-of-the-art in CNN\n    quantization? The results comparing channel-wise and layer-wise\n    MAX are already convincing, but are the moment-analysis approaches\n    not equally applicable to layer-wise quantization?\n    State-of-the-art results that are less sensitive to outliers\n    should be included in Table 1. A comparison with layer-wise\n    approaches would be nice to have also in Figure 4 to show\n    sensitivity to profiling set size.\n\nThe experimental results in the paper are impressive, and the analysis\nmotivating the approach is convincing. However, there are presentation\nand clarity issues in the technical development, and the comparative\nanalysis is lacking broader comparisons with the state-of-the-art (to\nbe fair, the authors recognize that layer-wise MAX as a baseline is\nparticularly susceptible to outliers). These two aspects combined,\nhowever, lead me to the opinion that this work is just not quite ready\nfor publication at ICLR.\n', 'This paper proposes an new 8-bit quantization strategy for rapid deployment. \n\n8-bit quantization has attracted many attentions recently. And it is already well used in GPU servers (cudnn), phones, ARM chips and various ASIC neural network chips. In these situations, almost no performance drop is observed for classification and detection tasks.\n\nSo, the novelty of this paper is limited.', 'The paper proposes channel-wise 8-bit quantization rather than layer-wise. It further takes advantage of work using moment analysis instead of just MAX values to avoid susceptibility to outliers. The main take-away seems to be that channel-wise set ups limit the need for outlier removal and the care with which you select your data subset when performing quantization.\n\nPros:\n- using channel-wise quantization (with MAX values or moment-analysis) yields improvement over layer-wise MAX approaches\n- limits the amount of care that is needed to be taken when applying quantization (e.g. size of data subset used)\n- shows differences in degradation when blindly applying quantization methods to different networks; with less (but still some) variation in degradation when applying channel-wise quantization\n\nCons:\n- unclear how much is gained over layer-wise and MAX value methods with careful tuning/removal of outliers; would be good to see if careful tuning closes the gap or if channel-wise methods are the clear winner\n- unclear if the layer-wise set up with moment-analysis could help to avoid the need for outlier removal altogether and (potentially) offer similar improvements to the channel-wise set up; a few more experiments are important to determine specifically if improvement is with respect to channel-wise or moment-analysis since only layer-wise MAX results are presented\n- clarity, presentation, and organization can be improved to help with flow, avoid confusion, and improve readability\n\nOverall:\nThe paper offers nice empirical results regarding the relative ease with which one can quantize networks when considering channel-wise quantization (and moment-analysis), but the overall novelty is limited. With the limited novelty, the primary benefits appear to be the ease of quantization for rapid deployment and channel-wise setups. Comparisons with stronger baseline numbers when using layer-wise methods would give a more complete picture. In addition, having these stronger tuned baseline numbers on even more networks would be great to show that the channel-wise method has clear impact across the board, even with respect to well-tuned layer-wise baselines. These results could give better support for the importance of the novelty.']","[-20, -50, 20]","[60, 0, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they ultimately conclude that the work is 'not quite ready for publication at ICLR'. They point out several weaknesses, including lack of coherence in the method description, difficulty in reproducing results, and insufficient comparison with state-of-the-art methods. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths and impressive experimental results before discussing the weaknesses. The critique is constructive and specific, without using harsh or dismissive language. The reviewer also fairly notes that the authors recognize some limitations of their baseline comparison."", ""The sentiment score is -50 because the reviewer expresses a somewhat negative view of the paper's novelty, stating that '8-bit quantization has attracted many attentions recently' and is 'already well used', concluding that 'the novelty of this paper is limited'. This indicates a lack of enthusiasm for the paper's contribution, though it's not entirely dismissive. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer states their opinion directly without using overly harsh language or personal attacks, but also without any notably courteous phrasing. The review is brief and matter-of-fact in tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and empirical results, noting 'nice empirical results' and improvements over existing methods. However, they also point out limitations and areas for improvement, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'would be good to see' and 'clarity can be improved' rather than harsh or demanding language. The review maintains a professional tone, offering both pros and cons in a balanced manner without being overly effusive or critical.""]"
"['This paper analyzes the surface of the complete orthogonal dictionary learning problem, and provides converge guarantees for randomly initialized gradient descent to the neighborhood of a global optimizer. The analysis relies on the negative curvature in the directions normal to the stable manifolds of all critical points that are not global minimizer.\n\nExploring the surface of a function and analyzing the structure of the negative curvature normal to the stable manifolds is an interesting idea. However, I believe I miss some thing important in this paper. This paper seems not to be self contained. I do not understand the paper very well. See details below. Therefore, I have reservations about the paper.\n\n*) The terminology ""stable manifolds"" is used from the first page, while its formal definition is given on page 4.\n*) P3, the dictionary learning problem is not formally given. It is stated in the paper that the task is to find A and X, given Y. However, what optimization problem does the author consider? Is it \\min_{A, X} \\|Y - A X\\|_F^2? assuming both dictionary A and sparse code X are unknown or \\min_{A} \\|Y - A X\\|_F^2 assuming only dictionary is unknown?\n*) P3, second paragraph in Section 3: what is the variable q? It is not defined before.\n*) P3, third paragraph in Section 3: What is the function row()? Why does row(Y) equal row(X)?\n*) P3: How does the dictionary learning problem reformulate into the problem in the third paragraph of Section 3? If I understand correctly, the task is to find A, X such that A^* Y = X since A is orthogonal. Consider the first column in A and denote it by q. Then the first column of X is approximated by q^* Y. Since X is sparse, the task is to find q so that q^* Y as sparse as possible. But how about the other columns in matrix $A$? \n*) The Riemannian gradient algorithm is not stated in this paper.\n\n\n', 'The authors analyze the convergence performance of Riemannian gradient descent based algorithm for the dictionary learning problem with orthogonal dictionary and sparse factors. They demonstrate a polynomial time convergence from a random initialization for a smooth surrogate objective for the original non-smooth one. The problem and the analysis are of interest, but I have several questions regarding the paper as follows.\n\nMy first concern is that the analysis is on a smooth surrogate of the non-smooth sparse minimization for solving the dictionary learning problem, so it is not clear what is relationship between the global minimizer of the smooth problem to the underlying true dictionary. More specifically, how far is the global minimizer of problem (1) or (2) to the true dictionary parameter, and whether they share (approximately) the space or components regarding the sparse factors. Without clarifying this, it is not well motivated why we are interested in studying the problem considered in this paper at the beginning. Intuitively, since the recovered factors are not sparse anymore, it will impact the dictionary accordingly due to the linear mapping, which may lead to a very different set of dictionary components. Thus, explicit explanation is necessary here to avoid such degenerate case.\n\nMy second concern is the eligibility of assuming the dictionary A to be an identity matrix and extending it to the general orthogonal matrix case. The analysis uses the fact that rows of A are canonical basis, i.e., each row only has one non-zero entry. I do not see a straightforward extension by replacing A to be an orthogonal matrix as the authors claimed on page 3, since then the inner product of one row of A and one column of X is not just the corresponding entry of the column of X. It will be helpful if the authors can explain this explicitly or adjust the analysis accordingly to make this valid.\n\nAnother issue is the clarity of the paper. Some statements in the paper are not very clear. Form example, on page 3, third paragraph of Section 3, what does row(Y) = row(X_0) mean? Also, in eqn (1), y_k means k-th column of Y, and in eqn (2), q_i means i-th entry of q? Since both are bold lower case letters, clear distinction will help. Moreover, the reference use (. ) instead [ .], which can be confusing sometimes. \n', 'The paper presents a convergence analysis for manifold gradient descent in complete dictionary learning. I have three major concerns:\n\n(1) The optimization problem for complete orthogonal dictionary learning in this paper is very different from overcomplete dictionary learning in practice. It is actually more similar to tensor decomposition-type problems, especially after smoothing. From this point of view, it is not as interesting as the optimization problem.\n\nArora et al. Simple, Efficient, and Neural Algorithms for Sparse Coding, 2015\n\n(2) Some recent works focus on analyzing gradient descent for phase retrieval and matrix sensing. These obtained results are significantly improved and near-optimal. However, the convergence rate in this paper is very loose. Besides, the paper even does not look into the last phase of gradient descent, when there exists restricted strong convexity. Thus, only sublinear convergence rate is presented.\n\nChen et al. Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval, 2018\n\nThe quality of this paper could be improved, if the author could sharpen their analysis.\n\n(3) The analysis for the manifold gradient methods is something new, but not very significant. There have already been some works on manifold gradient methods. For example, the following paper has established convergence rates to second order optimal solutions for general nonconvex function over manifold.\n\nBoumal et al. Global rates of convergence for nonconvex optimization on manifolds. 2016.\n\nThe following paper has established the asymptotic convergence to second order optimal solutions for general nonconvex function over manifold.\n\nLee et al. First-order Methods Almost Always Avoid Saddle Points, 2017.\n\n']","[-50, -20, -60]","[20, 60, 20]","[""The sentiment score is -50 because the reviewer expresses reservations about the paper and states they don't understand it well. They mention missing important elements and the paper not being self-contained, which indicates a negative sentiment. However, they do acknowledge that the idea is interesting, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses polite language throughout, such as 'I believe I miss something important' and 'I have reservations,' rather than using harsh or critical language. They also phrase their concerns as questions or observations rather than direct criticisms. The slightly positive score reflects this professional and courteous tone, although it's not overly effusive or extremely polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interest of the problem and analysis, they express several concerns and questions about the paper. The review starts with a neutral tone but then lists multiple issues, indicating more negative than positive sentiment overall. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than harsh criticisms. They use phrases like 'It will be helpful if...' and 'More specifically,...' which maintain a constructive and polite tone. The reviewer also acknowledges the potential interest of the work before diving into their concerns, which is a polite approach to criticism."", ""The sentiment score is -60 because the reviewer expresses three major concerns about the paper, indicating a generally negative view. They point out limitations in the problem formulation, loose convergence rates, and lack of significant novelty. However, it's not entirely negative as they suggest ways to improve the paper. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They avoid harsh or personal comments, instead focusing on the content and suggesting improvements. The tone is academic and objective, maintaining a level of courtesy despite the critical nature of the review.""]"
"['PAPER SUMMARY:\n\nThis paper introduces a biologically motivated black-box attack algorithm. \nThe target model in this case is DNN applied to the ASR context (automatic speech recognition system). \n\nNOVELTY & SIGNIFICANCE:\n\nThe proposed approach extends the previous genetic approach of (Alzantot et al., 2018) to attack a more complicated ASR system (that handles phrases and sentences). The new contribution here is an add-on momentum mutation component on top of the existing genetic programming architecture of (Alzantot et al., 2018) as illustrated in Figure 3.\n\nThis however appears very incremental seeing that integrating the mutation component into existing system is straight-forward and that mutation is not even a new concept -- it has always been a vital component in genetic programming paradigm.\n\nIt is also unclear how this mutation component improves over the existing work (more on this in the sections below).\n\nAnother issue is this work seems to ignore the recent literature on adversarial black-box attacks to DNN model. To list a few:\n\nChen, P.-Y.; Zhang, H.; Sharma, Y.; Yi, J.; and Hsieh, C.-J. 2017b.\nZOO: Zeroth-order optimization-based  black-box attacks to deepneural networks without training substitute models. \nIn Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (15-26) ACM\n\nCheng,  M.;  Le,  T.;  Chen,  P.-Y.;  Yi,  J.;  Zhang,  H.;  and  Hsieh,C.-J.2018.\nQuery-efficient hard-label black-box attack:  An optimization-based approach. arXiv preprint arXiv:1807.04457\n\nWhile these works have not been used to attacking ASR system, they should be directly applicable to such system since after all, they are black-box attacks. I think the proposed method needs to be compared with these works.\n\nTECHNICAL SOUNDNESS:\n\nI find it surprising that even though the proposed method is claimed to be a black-box attack but in the end, it actually exploits the fact that the target model uses CTC decoder. This pertains specifically to the target model\'s internal architecture and a black-box attack is not supposed to know this.\n\nCLARITY:\n\nThe paper is clearly written.\n\nEMPIRICAL RESULTS:\n\nI do not understand this statement:\n\n""That 35% of random attacks were successful in this respect highlights the fact that black box\nadversarial attacks are definitely possible and highly effective at the same time""\n\nWhy is 35% successful attack rate a positive result? The result tends to suggest that this is an attack with low success rate. \n\nThe 2nd paragraph in 3.2 seems to give a vague explanation: ""the vast majority of failure cases are only a few edit distances away from the target. \n\nThis suggests that running the algorithm for a few more iterations could produce a higher success rate, although at the cost of correlation similarity"".\n\nGiven the above statement, I do not see why the authors didn\'t actually ""run the algorithm for a few more iterations"" to verify it ...\n\nI am also curious why is the success rate of the proposed method is significantly lower than that of the existing system -- I assume ""single word black box"" is the work of (Alzantot et al., 2018).\n\nI find the empirical evaluation somewhat sloppy: why are the tested method not compared on the same benchmark? How do we interpret the results then?\n\nREVIEW SUMMARY:\n\nThe paper misses the recent literature on black-box attack. The authors need to compare with those to demonstrate the efficiency of their proposed work. I also find the contribution of this paper too incremental & its empirical evaluation appears somewhat sloppy and not convincing (see my specific comments above). ', 'In ""Targeted adversarial examples for black box audio systems"" the authors look at an adversarial problem in neural nets for audio processing. There is quite a lot of recent interest in adversarial problems in machine learning. That work is mostly on the image side, and so this work is very topical. The problem is to modify an audio signal without changing how it sounds to the human ear, so that it is interpreted as the attacker wishes by the neural network. In the black box approach, the weights of the neural network are not known by the attacker. The attacker however must be able to present modified audio and learn the network\'s interpretation as often as the attacker wants. This work is very exciting and topical, and of interest to the ICLR community.\n\nThe authors demonstrate a proof of concept using the recent DeepSpeech model, and they connect very well with recent literature on adversarial networks.\n\nThe particular algorithm the authors propose is based on genetic algorithms. I thought that this was a weak part of the paper, because genetic algorithms are quite ad hoc and have few theoretical guarantees when compared to SMC, MCMC, nested sampling or herding, which all do basically the same thing as genetic algorithms. This can lead to loose ends, such as the ""momentum mutation"" introduced by the authors in 2.2, wherein probability of mutation increases as the population fails to adapt. It is true that momentum mutation would avoid local maxima, but it would also take the solution away from global maxima through a sort of ""sampling noise"" (the global maxima is a point at which the population also ""fails to adapt"", as there\'s no more adaptation to be done). It\'s unclear if this is a problem, but things like annealed importance sampling also deal with the same problem (or effective sample size of SMC), and they have theory to back them up.\n', 'This paper proposes a black-box attack on multi-word ASR systems.  Most work on black-box attacks have focused on tasks in vision. This work adds to the literature on attac\nks on speech systems. The key novelties are the handling of a loss function over multiple decodings as well as the use of novel genetic algorithms to generate the adversari\nal examples.\n\nA weakness of this paper is that they do not compare to the closely related Alzantot et al. work. While the latter is focused on single word settings and is thus solving an\n easier problem, what would happen if the Alzantot et al. method was applied to each\n\n\nWhile the idea is interesting but incremental, the evaluation of the approach is weak.\n\n1. Insted of choosing random pairs of words as target phrases, it would be interesting to pick phrases that are likely to occur in English and to ask how success rate varie\ns as a function of the initial phrase and target phrase.\n\n2. To confirm that the resulting adversarial examples are similar to audio samples in the original dataset, the authors should do user studies. This is a key component in e\nvaluating the efficacy of such attacks. The cross correlation is useful but does not get at perceptual similarity.\n\n3. Table 1 is not useful since either the datasets are different or information is not given on the specific white box attacks.\n\n4. Does increasing the iterations lead to a higher success rate as claimed at end of page 7?\n\n\nAbstract:\n1. This sentence is misleading : ""Current work..are known"" given the Alzantot et al. work focuses on black-box attacks.\n']","[-60, 70, -30]","[20, 60, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty, technical soundness, and empirical results. They describe the work as 'very incremental', question the claimed contributions, and find the evaluation 'somewhat sloppy'. However, it's not entirely negative as they acknowledge some positive aspects like clear writing. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I find it surprising' and 'I am curious why' rather than harsh language. They also offer specific suggestions for improvement, which is constructive. The reviewer balances negative feedback with some positive comments, contributing to a relatively polite, though critical, review."", ""The sentiment score is 70 (positive) because the reviewer expresses enthusiasm for the work, calling it 'very exciting and topical' and 'of interest to the ICLR community'. They also praise the authors for connecting well with recent literature. However, it's not 100 because the reviewer does point out a weakness in the methodology. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, acknowledging the value of the work before offering criticism. The critique is presented as a suggestion rather than a harsh judgment, using phrases like 'I thought that this was a weak part' instead of more direct criticism. The reviewer also explains their concerns in detail, which is a polite way to offer feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting idea', 'adds to the literature'), they also point out several weaknesses and areas for improvement. The overall tone suggests the paper needs significant work. The politeness score is 20 because the reviewer uses generally polite language and constructive criticism, avoiding harsh or rude phrasing. They offer specific suggestions for improvement rather than outright dismissal. However, the criticism is direct, which prevents a higher politeness score.""]"
"['This manuscript joins a crowded space of methods for low bit quantization to enable inference on more efficient hardware. In the past, these methods often were limited to 8-bit quantization, or smaller networks, or result in accuracy degradation. This paper is part of a recent crop of methods that achieve full accuracy on ResNet50 with 4-bit weights and activations. \n\nThe method in this paper is based around a simple, yet powerful observation: Fine-tuning at low precision introduces noise in the gradient. Using the relationship between noise, batch-size and learning rate, that has recently been receiving a lot of attention in the context of large batch training, they compensate for this added noise by increasing the batch size. \n\nI like the simplicity and effectiveness, and believe that this method will be a useful addition to the toolbox for low-precision inference. \n\nOverall, the paper is well written, and the claims are well supported experimentally. Results are demonstrated on a wide range of networks, including various configurations of ResNet, DenseNet, Inception. It\'s not clear whether these experiments are from a single run. If they are, with sub 1% differences between methods we are getting close to the run-to-run variability, and it would be preferable to see results averaged across multiple runs. \n\nUltimately, I am on the fence if this is a sufficient contribution for acceptance. In particular, this paper claims ""first evidence ... matching the accuracy of full precision"". While this may in a narrow technical sense be the case, PACT https://arxiv.org/abs/1805.06085 also works on ResNet50 without an accuracy drop. While this is not published work, it was rejected at ICLR last year, making it hard to recommend acceptance here. There is also work concurrently submitted to this forum (which I obviously don\'t expect the authors to cite or take into account, but want to mention for the sake of completeness) such as https://openreview.net/forum?id=HyfyN30qt7 which achieves the same or better results, and does not require 8-bit BN scale factors and 32-bit bias. \n\nThis manuscript could be made stronger in multiple ways, e.g. by combining with the recently proposed clipping techniques like Choi et al. (2018), and pushing towards 2 or 3 bit training, or eliminating all larger bit-width parameters to make for easier hardware design. \n', '\nSummary:\nThis paper proposes three methods to improve the performance of the low-precision models. Firstly, to reduce the number of training iterations, the authors propose to do quantization on pre-trained models rather than training from scratch. Secondly, the authors propose to use large batches size and proper learning rate annealing with longer training time to reduce the gradient noise introduced in quantization. Experimental results demonstrate the effectiveness of the proposed methods.\n\nContributions:\n1.\tThe authors hypothesize that noise introduced by quantization is the limiting factor for training low-precision networks and present empirical evidence to support this hypothesis.\n2.\tThe authors formulate the error as equation (1) and propose two techniques (large batches size and proper learning rate annealing) to minimize the final error.\n3.\tThe authors conduct a series of experiments to demonstrate the effectiveness of the proposed methods.\n\nCons:\n1.\tThe novelty of this paper is limited. Firstly, fine-tune the pre-trained model is a well-known method in quantization. Secondly, using large batches size and proper learning rate annealing are more like tricks in hyper-parameter tuning rather than a method. \n\n2.\tIn table 2, the performance of the model in the second row (batch size=400) is worse than the baseline ones (batch size=256). In order to keep the same number of weight updates, the author increases the number of epochs during training, which results in performance improvement. Do large batches size really contribute to performance improvement? Whether the performance gain is due to the large batches size or more sampling data?\n\n3.\tThe authors claim that large batches size can reduce the gradient noise introduced by quantization. It would be better to show the introduced noise with different batch sizes in figure 1. \n\n4.\tThis paper is not the first time for ResNet-50 with 4-bit quantization to outperform the full-precision network. EL-Net[1] has trained a 4-bit precision network, which leads to no performance degradation in comparison with its full precision counterpart.\n\n5.\tThe title in experiments part is too long and confusing. It will be better to keep the short and meaningful title.\n\n\nReferences\n[1] Zhuang B, Shen C, Tan M, et al. Towards Effective Low-bitwidth Convolutional Neural Networks[J]. 2017.\n', 'This paper proposes a fine-tuning scheme for quantized network which can achieve higher accuracy ( in 8bits case) than the original full-precision (32 bits) network. The main finding/motivation of this paper is that in order to make the fine-tuning works, the retrain needs to overcome the gradient noise that is introduced by weight quantization. Therefore, it considers several typical retraining techniques: large batch size training, retraining from full-precision network instead of quantized one from scratch,  lower weight decay. \n\nI think it is an interesting paper, and the result is quite promising. In fact, I have not seen any quantized network that can perform better than the original full-precision network. While in terms of novelty, no new techniques/algorithms are proposed, and it is combing standard strategies used in retrain networks. In addition, I have several questions for this work:\n\n1) It seems that training longer time will benefit the fine-tuning a lot. What if we can also train the original model for some additional amount of training time(like 165 epochs in Table 2), and then quantize this full-precision network without retrain, will the proposed scheme still have better accuracy than this naive way? \n\n2) Will these fine-tuning strategies/findings be generalized to other datasets or other models? In this paper, only results in ImageNet are shown.\n\n3) Can I use these fine-tuning strategies to improve other quantization methods? For example, I could use larger batch size when training for other fine-tuning methods, and will it also make their quantized models better than the original precision model?\n\n4) As mentioned in the paper, the proposed quantized network is used to  speed up the inference time. Some results for inference time using the proposed quantized network will be super interesting.\n\nOverall, the proposed fine-tuning scheme has promising results. My main concern for this paper is its novelty and whether it can be generalized to other models.']","[50, -20, 50]","[75, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the simplicity and effectiveness of the method, stating it will be a 'useful addition to the toolbox'. However, they are 'on the fence' about acceptance, suggesting room for improvement. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths ('well written', 'claims are well supported') while offering constructive criticism. They use phrases like 'I like' and 'I believe' to soften their opinions, and provide specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Experimental results demonstrate the effectiveness of the proposed methods'), they list more cons than pros. The reviewer points out limitations in novelty, questions the effectiveness of some methods, and suggests improvements. However, the score is not deeply negative as the reviewer does recognize some contributions.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to present their critiques (e.g., 'It would be better to...', 'Do large batches size really contribute...?') rather than harsh or dismissive statements. The reviewer also acknowledges the positive aspects of the paper before presenting criticisms, which is a polite approach in academic reviews."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' and the results as 'quite promising'. However, they also express concerns about novelty and generalizability, which tempers the positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's strengths. The reviewer's tone is constructive and professional, avoiding harsh or dismissive language.""]"
"['This paper suggests a new metric for assessing the quality of hierarchical clustering. Dasgupta recently suggested the first such metric with interesting properties. This has encouraged a number of recent works about designing algorithms that work well for the metric and other similar metrics. This paper suggests a new metric for evaluating hierarchical clustering of given graph data. \n\nHere are the main comments about the paper:\n- I am not convinced about the advantages of the new metric over the previously suggested metrics by Dasgupta and Cohen-Addad et al.\n    - Theoretical analysis shows properties of the new metric that are similar to that of Dasgupta (since the metric itself has similarities). However, the advantage of the new metric is not very clear. \n    - Experimental analysis just shows that the new metric is different from Dasgupta’s but again there is no evidence to suggest why the new metric may be better. \n\n- In the abstract it is mentioned that “The best representation of the graph for this metric in turn yields a novel hierarchical clustering algorithm.” I do not understand this. Which novel algorithm is being referred to? \n\n- Again, it is mentioned in the abstract that “Experiments on both real and synthetic data illustrate the efficiency of the approach”. What efficiency is being referred to here and what is the approach? What I see is that known clustering algorithms are used to compare the new metric with the previous one by Dasgupta.\n\nOverall, I think more work is needed in this paper. There are some non-trivial observations but unless the authors make the motivation for defining this new metric for evaluation more clear.\n\nOther comments:\n- Section 5: NP-hardness has not been shown and it is just mentioned that the authors believe that the problem is NP-hard just as the problem associated with the cost function of Dasgupta et al.', 'This paper proposes a new formulation of hierarchical clustering for graphs.\n\nQuality:\nThe proposed formulation has not been analyzed in detail and its advantage is not clear compared to existing approaches.\nIn addition, there are some existing measures for hierarchical clustering, for example, the dendrogram purity[1].\nIt would be interesting to analyze the relationship between the proposed method and such existing measures. \n[1] Heller, K. A. and Ghahramani, Z.: Bayesian Hierarchical Clustering, ICML2005\n\nClarity:\nThis paper is clearly written and easy to read.\nThe proposed criteria is carefully derived and well explained.\nI feel that the title of the paper is not appropriate as it says the paper is about graph representation learning while a graph (representation) is already given as an input in the setting discussed in this paper. ""Learning hierarchical representation ..."" would be better.\n\nOriginality:\nThe originality is not high as most of theoretical discussion is based on the existing work and the resulting hierarchical clustering algorithm is a straightforward extension of the average linkage method.\nOf course, it is quite interesting if a minor change makes a big difference in clustering performance (theoretically and/or empirically), but such result is not given.\n\nSignificance:\nSignificance of the contribution is not high as the advantage of the proposed formulation is not clear.\nOne of interesting questions is: how about higher order relationships between nodes?\nThe proposed method takes up to second order relationships between nodes, that is, edges into account.\nSince the proposed formulation can naturally include higher order relationships, it would be interesting to analyze such relationships in hierarchical clustering.\n\nPros:\n- The paper is clearly written.\n- The proposed formulation of hierarchical clustering is interesting.\nCons:\n- The advantage of the proposed formulation is not presented.\n- Experiments are not thorough.', 'This paper introduces a relative entropy metric for evaluating hierarchical clustering. The paper is not well-written and its contributions are not clear to me. The abstracts and introduction promising for a novel hierarchical clustering algorithm, but I can only understand that they are using an agglomerative algorithm with the inter-cluster similarity of Eq. 10.\nThey show that their similarity metric reduces to the previous work by setting \\pi = p or uniform. However, in the experiments, they only use these two cases, which does not support the importance of using relative entropy metric.  I guess picking the best \\pi is an important part of this approach which has been left out. \nThe authors violate the blindness of the paper by including a link to their github page, for which an anonymous repository should have been used.\nIt also worth noting that nowadays the graph representation term is often used for graph embedding, which makes the title very misleading. ']","[-50, -20, -70]","[20, 50, -20]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings and expressing skepticism about the advantages of the proposed metric. The reviewer states that 'more work is needed' and that they are 'not convinced about the advantages of the new metric.' However, it's not entirely negative as the reviewer acknowledges some 'non-trivial observations.' The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I think' and 'I am not convinced' rather than making harsh declarative statements. The reviewer also provides specific points for improvement, which is helpful and courteous. The language is generally neutral, neither overly polite nor rude, but leans slightly towards politeness in its constructive approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'interesting formulation'), they express several criticisms about the paper's originality, significance, and lack of clear advantages over existing methods. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing critiques with positive observations, and offering constructive suggestions for improvement. They use phrases like 'it would be interesting' and 'I feel that' which soften the criticism. The review maintains a professional and courteous tone without being overly formal or effusive."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper is 'not well-written' and its contributions are 'not clear'. They also point out several shortcomings, such as the lack of support for the importance of the relative entropy metric and the violation of blind review guidelines. The only slightly positive aspect mentioned is the promising abstract and introduction, but this is quickly followed by criticism. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the feedback. Phrases like 'The paper is not well-written' and 'I can only understand that...' come across as somewhat blunt. The reviewer also doesn't offer any positive reinforcement or constructive suggestions for improvement, which contributes to the slightly impolite tone.""]"
"['In this work, the authors attempt to unify existing adaptive gradient methods under the Bayesian filtering framework with the dynamical prior.  In Ollivier, 2017, a framework is proposed to connect Bayesian filtering and natural gradient.  On the other hand,  in Khan et al., 2018. an approach is proposed to connect natural gradient and adaptive gradient methods.  The main contributions of this work are (1)  introducing a dynamical prior and (2) recovering RMSProp and Adam as special cases. \n\nHowever, the proposed dynamical prior is very similar to the fading memory technique used in Ollivier, 2017. (see Proposition 3 of Ollivier, 2017) \nFurthermore, the authors argue that this work recovers a root-mean-square form while Khan et al., 2018 recovers a different sum-square form. Unfortunately, the authors have to use a series of unnatural approximations to recover the root-mean-square form. In fact, as mentioned in Khan, 2017b  this proposed method without these approximations is also a mean-square form. (also see Eq (2.28-2.29) of Ollivier, 2017)\n\nSince the authors mainly follow Ollivier, 2017 and make unnatural approximations,  the work has a limited impact.  To get a higher rating, the authors should clearly give justifications and insights of these approximations.\n\nDetailed comments:\n(1) On Page 1,  ""The typical approach to Bayesian filtering, where we infer a distribution, ... jointly, forces us to use extremely strong, factorised approximations, and it is legitimate to worry that these strong approximations might meaningfully disrupt the ability of Bayesian filtering to give close-to-optimal updates.   ... we instead consider ... that incorporates factorisation into the problem setting, and therefore requires fewer approximations downstream. ""\nThe proposed method is equivalent to jointly perform Kalman filtering with full-covariance with an additional diagonal-approximation step. This additional step might also meaningfully disrupt the ability of Bayesian filtering. Furthermore, such approximation ignores the off-diagonal terms in the low-rank approximation at Eq (8). \n\nMinor: You should use \\approx at Eq (8) since a rank-1 approximation is used.  \n\n(2) On page 2, ""It has been noted that under specific circumstances, natural gradient is approximate Bayesian filtering (Ollivier, 2017), allowing us to link Bayesian filtering to the rich literature on natural gradients.  However, this only occurs when the dynamical prior in the Bayesian filtering problem has a specific form: the parameters being fixed over time (i.e.  arguably an online data, rather than a true Bayesian filtering setting)."" \nThe authors should comment the difference between the dynamical prior and the fading memory technique (see Proposition 3 of Ollivier, 2017) where at page 14 of Ollivier, 2017, Ollivier mentions that ""this is equivalent ... or to the addition of an artificial process noise ... in the model"".  I think Ollivier\'s idea is very similar to the dynamical prior used at Eq (1) of this submission.  Furthermore, the second-order Taylor expansion with a Fisher information-based estimation of Hessian (see the equation below Eq(1) of this submission) is exactly the same as Ollivier\'s Extended Kalman filter (see  Eq 2.25 at Lemma 9  and Lemma 10 of Ollivier, 2017).  The authors should cite Ollivier, 2017.\n\nMinor: Eq (6) should be E_p [ - \\nabla_z^2 \\log p(d|z) ] = E_p  [ e e^T ], where ""-"", the negative sign is missing. Please see the definition of the Fisher information matrix.\n \n(3) On page 2, ""While there have been attempts to use natural gradients to recover the Adam or RMSprop root-mean-square form for the gradient normalizer, in practice a different sum-square form emerges (Khan & Lin, 2017; Khan et al., 2018). In contrast, we show that to recover the Adam or RMSprop form for the gradient normalizer."" \nKhan et al., 2018 is a mean-square form for variational inference due to the entropy term of the variational distribution. (see Sec 3 and 5 of  Khan et al., 2018 and Khan, 2017b )\nUnfortunately, the ""root-mean-square form"" does not appear naturally in this submission. In practice, the proposed update is also a mean-square form  (see Eq (2.28-2.29) of Ollivier, 2017 and Khan, 2017b) without a series of unnatural approximations used in this submission.\nTo justify these assumptions, the authors should explain when ""the steady state posterior variance"" (see sec 2.21) and  ""a self-consistent solution"" (see sec 7.1) achieve.  As far as I know, \\sigma^2_t = \\sigma^2_{t+1} in sec 2.2.1 only holds in the limit case when t-> \\inifity.  Why does the equality hold at each time step t? The authors should give a justification or an intuition about these approximations since this paper is a theory paper. Please also see my next point.\n\n(4) Section 7.1 is also confusing.\nIn sec 7.1, the authors assume that A \\in O(\\eta). However, A=\\eta^2/(2\\sigma^2) in sec 2.2 and A_{1,1} =  ( \\eta_w^2+\\eta^2 )/ (2\\sigma^2) at Eq (14). In both cases, A can be \\in O(\\eta^2). This is very *critical* since the authors argue that O(\\eta^3) can be neglected in sec 7.1.  The authors use this point to show that Adam is a special case. \nIf A \\in O(\\eta^2), we know that ""A \\Sigma_{post}"" \\in O(\\eta^3) should be neglected. At the last equation on page 10,  the authors do not neglect ""A \\Sigma_{post}"". Why?  The authors should clarify this point to avoid doing *selective* neglection.  Again, the impact of this paper should be inspiring new adaptive methods.\nThe authors also mention that the second-order term in A is neglected in sec 7.2. Any justification? \n\n\nReferences\n[1] Ollivier, Yann. ""Online Natural Gradient as a Kalman Filter."" arXiv preprint arXiv:1703.00209 (2017).\n[2] Khan, Mohammad Emtiyaz, and Wu Lin. ""Conjugate-computation variational inference: Converting variational inference in non-conjugate models to inferences in conjugate models."" arXiv preprint arXiv:1703.04265 (2017).\n[3] Khan, Mohammad Emtiyaz, et al. ""Vprop: Variational Inference using RMSprop."" arXiv preprint arXiv:1712.01038 (2017b).\n[4] Khan, Mohammad Emtiyaz, et al. ""Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam"" (2018)\n\n', '* Description\n\nThe paper considers the following random process on the parameters z (modeled as Gaussians):\n- shrink z towards zero and add Gaussian i.i.d. noise to it.\n- update the parameters to the posterior w.r.t. a batch, where the likelihood is approximated as a diagonal multivariate normal distribution.\nThis results in a Kalman filter like updates. There have been related methods proposed performing Bayesian learning in the form of assumed density filtering, considered as separate learning algorithms. At the same time methods such as RMSprop and Adam were previously derived from completely different considerations. The work can derive these methods in the Bayesian framework with certain additional assumptions / simplifications. It allows to naturally explain tracking the gradient statistics as uncertainties and the normalization of the gradient in the existing methods as the update of the mean parameters in the Kalman filter taking into account these uncertainties. \nThe experiments on MNIST show that derived more Bayesian variants of RMSprop and Adam can improve generalization in terms of test likelihood and test error. \n\n* Assessment\n\nThe provided derivation of Bayes like learning algorithms is relatively simple and could be very useful in practice and in further improvement of the learning methods. The approximations used are not completely clear. The clarification of the idea of a separate optimization problem per variable is necessary. The provided experiments, if there is nothing subtle, are clearly done and would be sufficient.\nThere are some open questions such as: does the method in fact learn useful variances of the parameters, i.e. really performs an approximate Bayesian learning? Overall if find it a promising novel research direction of high practical relevance.\n\n* Clarity\n\nIntro:\nWhy is the unnumbered equation on page 1 is called a “Bayesian optimization problem”? There is so many sings called Bayesian that one cannot be sure what it means. In the context of the paper it should be a Bayesian learning problem, but I do not see a posterior distribution over the parameters. Overall, I did not get the point of the discussion in the introduction and Figure 1 altogether. Everything it says to me is that global minimize coordinates are dependent through the objective. I do not see what the unnumbered equation on page 1 has to do with Bayesian inference and how the correlation of parameters in the posterior distribution is related to the dependencies in the minimizer. Could authors please seriously consider clarifying this section?\nIn what follows the paper keeps a factorize approximation to the posterior of parameters of a NN in the form of a Gaussian distribution per coordinate. It thus does not in any way avoid making this restrictive assumption.\n\nResults:\nSorry, I am not familiar with the background behind (6). Which value of z is assumed in the conditional expectation, is it conditioning on “z = \\mu_{prior}”? How come the approximation to the variance of the data likelihood does not depend on the data? If we make this approximation, how much it is still relevant to the Bayesian learning?\n\nWhat are the overheads of the proposed methods? I expect they scale as easily to large problems as SGD?\n\n* Experiments\n\nFrom Figure 2 it seems that BRMSprop and BAdam can achieve relatively good results for large range of eta in 10^-5 to 10^-2 and it seems from the trend that even smaller eta would work. Does it mean they do not need in fact tuning of the learning rate? \nThe experiment uses 50 epochs, do the compared methods reach the convergence? Could the authors consider an experiment running best setting of parameters per method with twice as many epochs?\nSome artificial toy experiments could be of interest. For example, consider a classification problem with a 1D Gaussian data distribution in each class and the logistic regression model with 2 parameters. Does the method approximate the posterior distribution?\n\n* Related work\n\nThe approach to Bayesian learning taken in the paper needs to be better discussed. I think it is from the family of methods known as “assumed density filtering”, occurring in:\nGhosh et al. “Assumed Density Filtering Methods for Scalable Learning of Bayesian Neural Networks”\nwith earlier works well described in \nMinka T. “Expectation propagation for approximate Bayesian inference”. \nIn particular equation (5) of the submission is well known.\nThe work  Khan et al. 2018 “Fast and scalable Bayesian deep learning by weight-perturbation in Adam” also derives Bayesian learning algorithms in the forms closely similar to RMSprop and Adam and interprets the running statistics as uncertainties. However it takes the variational Bayesian learning approach, which means the reverse KL divergence is used somewhere. Could the authors discuss conceptual similarities and differences to this work?\n', 'Paper summary: The authors analyze stochastic gradient descent through the lens of Bayesian filtering. In doing so they (approximately) recover several common adaptive gradient optimization schemes. The paper focuses on a theoretical construction of this framework and offers a limited empirical study.\n\nDetailed comments:\n\nI thought that the paper presented some interesting ideas but amongst the many things discussed there is very little which is empirically gratified. While the Bayesian filtering framework is interesting in that it recovers slight variations of existing algorithms, and also caters for some recent practical tricks, I do not feel that it substantially improves our theoretical understanding of these methods.\n\n1) I found the notation difficult to follow in the introduction and parts of section 2. I have highlighted several places explicitly below. I found paragraphs 2 and 3 of the introduction particularly challenging.\n\n2) I found the introduction of Bayesian filtering challenging to follow. For example, which form of the likelihood is assumed for the Taylor expansion? How/why is $\\mu_{like}$ identified using the gradient? Linking to Kalman filtering made things easier to follow.\n\n3) I think that the related work, and possibly a chunk of section 2, should include a discussion of Noisy Natural Gradient [1]. While the derivation differs, the motivation and final form of the updates seem to have a large overlap but this work is not cited.\n\n4) Start of 2.1: ""z will have on element representing a single parameter"", after which z is treated as a vector. I believe this sentence is present to distinguish RMSProp from Adam when momentum is added but I found it confusing at first.\n\n5) I found the comparisons between BRMSProp-vs-RMSProp and BAdam-vs-Adam fairly unconvincing. The assumptions are not clearly demonstrated to have little practical significance and Figure 2. does not seem to support the claim that these methods are strongly related. Is it possible to demonstrate empirically that these algorithms have equivalent behaviour under some limiting factors? And if not, is there a good reason for this that still justifies the comparison? I would appreciate some clarifications on these points.\n\n6) I am not sure what you mean by ""We now assume that the data is strong enough to reduce the uncertainty in the momentum below its levels under the prior"". I believe that I am following the mathematical arguments correctly but I find this phrasing misleading. Furthermore, this section uses e.g. ppth and wpth to refer to coordinates, I think it would be clearer to simply write Sigma_{pp}, etc.\n\n7) Section 4.2 is lacking justification in my opinion (am I missing something?). I think that this section needs to have the derivation clearly laid out (in the appendix would be fine). Furthermore, the NAWD algorithm is not explored empirically, or analyzed theoretically at all. I would argue that more evidence is needed that this is a reasonable thing to do before it is meaningful to include it in the final print of this paper. In general, sections 4.4 - 4.7 feel a little out-of-place and thrown together. I think there are interesting comments here which are certainly worth including but their presentation should be rethought and some empirical investigation would be valuable.\n\nMinor comments:\n\n- In introduction, how exactly does $w\'_i$ differ from $w_i$?\n- In introduction, after para 2, the notation in the equation is confusing, e.g. overloading w_i(t) and w_i(mu_{-i}(t)).\n- In introduction,  para 3, ""must depend on other parameters"" - this seems like an obvious statement but it is presented as being crucial\n- Should ""Related Work"" start at 1 or 2?\n- (VERY MINOR) In section 2.2 and 2.3, ""christen"" seems like an add choice of word. Perhaps just ""call""?\n- Equations 10 and 11 introduce an independence assumption on the dimensions of the parameter vector. I think this should be explicitly stated.\n- Section 7.2 heading typo: MOMEMTUM\n\nClarity: I found the paper challenging to follow in places due to choices of notation (and a weak background in Kalman filtering and related techniques).\n\nSignificance: I do not feel that this work offers a strong case for significance. The empirical evaluation is very limited. The theoretical framework introduces is interesting but is not justified particularly well in the paper and does not directly offer explanations for many of the observations noted in this paper and elsewhere.\n\nOriginality: To my knowledge, the ideas presented in the paper are original and hint at potentially interesting viewpoints of optimization.\n\nReferences:\n\n[1] Zhang et al. ""Noisy Natural Gradient as Variational Inference"" https://arxiv.org/pdf/1712.02390.pdf']","[-50, 50, -30]","[20, 70, 50]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several limitations and areas for improvement. The reviewer states that the work has 'limited impact' and uses phrases like 'unnatural approximations' and 'should clearly give justifications'. However, it's not entirely negative as it acknowledges the authors' attempts and contributions. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use polite phrases like 'the authors should comment' and 'please see' when making suggestions. The reviewer also provides detailed explanations and references to support their critiques, which is a respectful approach. However, some direct criticisms like 'limited impact' and 'unnatural approximations' prevent the score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the potential usefulness and novelty of the work, calling it a 'promising novel research direction of high practical relevance.' However, they also raise several questions and concerns, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, often framing criticisms as questions or suggestions (e.g., 'Could authors please seriously consider clarifying this section?'). They also acknowledge their own potential lack of understanding in some areas ('Sorry, I am not familiar with the background behind (6).'). The reviewer maintains a professional tone, offering constructive feedback without harsh criticism."", ""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper, such as limited empirical study, difficulty in following the notation, unconvincing comparisons, and lack of justification in some sections. However, they also mention some positive aspects like 'interesting ideas' and 'original' work, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, often framing criticisms as personal opinions (e.g., 'I found', 'I think') and offering suggestions for improvement. They also acknowledge positive aspects of the paper. The reviewer maintains a professional tone without using overly harsh language, even when pointing out weaknesses in the paper.""]"
"['This paper proposes a generalization of variational auto-encoders to account for meta-data (attributes), learning new ones, in a way that these can be controlled to generate new samples. The model learns how to decouple the attributes in an adversarial way by means of a discriminator. The problem is interesting, but I found two main issues with this paper:\n1.- Lack of clarity: I found the paper difficult to follow, even after reading Sec. 2 and 3 several times.\n2.- Almost absence of experiments: The paper only has one experiment, which is in the appendix, and is about sampling using the MNIST dataset. Given that this paper proposes a model, whose properties can be assessed by means of experiments, the fact that there is nothing of the kind provides no support to any benefits the model may have.\n\nOther points:\nWhat in the model prevents the solution of z_* being just random (independently of x)?\n\nThis paper seems relevant Esser, Patrick, Ekaterina Sutter, and Björn Ommer. ""A Variational U-Net for Conditional Appearance and Shape Generation."" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.', 'The paper proposes a generative network capable of generating variations of a given input, conditioned on an attribute. Earlier papers generated variations of the input in the presence of the attribute and this attribute was assumed to be known during training. This paper proposes to automatically discover these attribute and thus work to produce variations even in the absence of known attribute information.\n\nThe paper is dense, but it is well written. It has mixed ideas from several papers - the basic VAE architecture, combined with a discriminator and regularizations over latent space. The key thing, of course, is the design of the attribute function. There seems to be an interesting interaction between the encoder, discriminator and the attribute function that requires more investigation. This is acknowledged in the conclusion as well.\n\nThe work is original and the results on the MNIST dataset are very interesting. I think the significance of this work lies in the fact that this can be a starting point for several interesting future works in this direction.', ""This paper introduces a new framework for learning an interpretable representation of images and their attributes. The authors suggest decomposing the representation into a set of 'template' latent features, and a set of attribute-based features. The attribute-based features can be either 'free', i.e. discovered from the data, or 'fixed', i.e. based on the ground truth attributes. The authors encourage the decomposition of the latent space into the 'template' and the 'attributes' features by training a discriminator network to predict whether the attributes and the template features come from the same image or not.\n\nWhile the idea is interesting, the paper is lacking an experimental section, so the methodology is impossible to evaluate. Furthermore, while the authors spend many pages describing their methodology, the writing is often hard to follow, so I am still confused about the exact implementation of the attribute features \\phi(x, m) for example. The authors do point to the Appendix for their Experiments section, however this is not a good idea. The paper should be self-contained and the authors should not assume that their readers will read the information presented in the Appendix, which is always optional. \n\nUnfortunately, even the experimental section presented in the Appendix is not comprehensive enough to evaluate the proposed method. The authors train the model on a single dataset (MNIST), no baseline or ablation results are presented, and all the results are purely qualitative. Given that the ground truth attribute decomposition for MNIST is not known, even the qualitative results are impossible to evaluate. I recommend that the authors present quantitive results in the updated version of their paper (i.e. disentanglement metric scores, the log-likelihood of the reconstructions), including new experiments on a dataset like dSprites or CelebA, where the ground truth attributes are known.""]","[-60, 80, -50]","[20, 70, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, particularly regarding its lack of clarity and insufficient experimental support. The reviewer states two 'main issues' which indicate a largely negative view of the paper. However, it's not entirely negative as the reviewer acknowledges that the problem is 'interesting'. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional and neutral language. They don't use harsh or rude words, and they frame their concerns as observations ('I found') rather than direct attacks. The reviewer also offers a potentially relevant paper for the authors to consider, which is a constructive gesture. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, describing it as 'well written', 'original', and having 'very interesting' results. They also highlight the significance of the work and its potential for future research. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths and potential impact without harsh criticism. They offer constructive observations and suggestions in a courteous manner, such as noting areas that 'require more investigation' rather than pointing out flaws."", ""The sentiment score is -50 because while the reviewer acknowledges the idea as interesting, they express significant concerns about the lack of experimental section, unclear writing, and insufficient evidence to evaluate the method. The overall tone is critical, but not entirely negative. The politeness score is 20 because the reviewer uses polite language such as 'I recommend' and 'Unfortunately,' softening their criticisms. They also acknowledge positive aspects ('the idea is interesting') before presenting concerns. However, the criticism is direct and doesn't employ overly deferential language, keeping the score only slightly positive.""]"
"['Post-rebuttal update: The review process has identified several issues such as missing citations and lack of clarity with respect to aims of the paper. Although the authors have failed to update the paper within the rebuttal period, their responses show an understanding of the issues that need to be addressed as well as a broad appreciation of work in EC that would be included in a final version, making it a useful resource for the wider ML community. On top of this they will include an even larger amount of empiricial data from the experiments they have already run, which is a valuable resource considering the amount of compute needed to obtain this data.\n\n---\n\nThe current landscape of reinforcement learning - particularly in domains with high-dimensional structured input spaces such as images or text - relies heavily on backpropagation-based reinforcement learning algorithms.  An alternative that has re-emerged is ES, due to its simplicity and scalability. However, ES can also be considered a gradient-based method. In this paper, the authors apply a similar treatment to GAs, another simple method at its most basic. The authors claim to have 3 main contributions: extending the scale to which GAs can operate, suggesting that gradient-based methods may not achieve the best performance, and making available a vast array of techniques available from the EC literature; they demonstrate the latter by utilising novelty search (NS).\n\nIn my opinion the authors do indeed have a valuable contribution in a) demonstrating that a simple GA can successfully be applied to larger networks than was previously thought to be possible and b) introducing a novel software implementation that allows GAs to be efficiently scaled/distributed (similar in nature to the work of Salimans et al.). This is by itself valuable, as, along with recent work on ES, it potentially extends the range of problems that are perhaps best tackled using black-box optimisation techniques. Going against the prevailing trends in order to investigate alternative methods is an underappreciated service to the community, and I believe the evaluation of the methods and the choice of comparative methods to be just about satisfactory. As exemplified by NS, there is a wealth of techniques from the EC literature that could be applied to many topical problems, and the authors\' main contributions opens up the road for this.\n\nA lot of care has been put into evaluation on Atari games. The details in the main paper and supplementary material, with, e.g., clear definitions of ""frames"", make me believe that fair comparisons have taken place. All methods in the table, including GAs, perform best at some games (except for RS, which is a necessary baseline for GAs). It would be better to provide more data points that relate to prior works - such as scores at 200M frames to evaluate sample complexity (indeed, the authors note that good solutions can be found by GAs within a few generations, so it would be best to tabulate this) and at ~ 4d to evaluate wall-clock time (is it possible to push performance even further?). Since the GA presented is very rudimentary, I consider the baselines in the main paper to be reasonable, but it would be misleading to not present newer work. The authors do so in the supplementary material, and it is promising to note that the GA still achieves state-of-the-art performance in a few games even when compared to the most sophisticated/distributed state-of-the-art DRL algorithms developed in a concentrated effort over the last few years. Despite having an NS variant, it is a shame that the authors did not show that this could potentially improve performance on Atari, when BCs such as the game RAM or preferably random CNN features are easily available.\n\nThe authors also evaluate on a maze that is a staple task in the EC literature to demonstrate the power of NS. While the results are unsurprising, it is a reasonable sanity check. The final evaluation is on a difficult continuous control task, in which GAs solve the task, but have much poorer sample complexity than ES. Given the range of continuous control tasks used to benchmark RL algorithms nowadays, the authors would do well to present results across more of these tasks. Again, NS was not evaluated on this task.\n\nA major weakness of this paper is the presentation. The authors discuss some interesting findings, but would be better served by being more concise and focused. In particular, the emphasis should be more on showcasing quantitative results. Doing so, with more continuous control tasks, would make the claims of this paper more substantiated.', 'This paper looks at a specific implementation of a ""genetic algorithm"" (GA) when applied to learning Atari games.\nUsing a black-box ""random search"" technique, with a few heuristic adaptations, they find performance that is roughly competitive with several other baseline methods for ""Deep RL"".\nMore generally, the authors suggests that we should revisit ""old"" algorithms in Machine Learning and that, when we couple them with larger amounts of computation, their performance may be good.\n\nThere are several things to like about this paper:\n- The authors place a high importance on implementation details + promise to share code. This seems to be a paper that is heavily grounded in the engineering, and I have high confidence the results can be reproduced.\n- The algorithm appears broadly competitive on several Atari games (although Table 1 is admittedly hard to parse).\n- The algorithm is generally simple, and it\'s good to raise questions of baseline / what are we really accomplishing.\n\nHowever, there are several places where this paper falls down:\n- The writing/introduction is extremely loose... terms are used and introduced without proper definition for many pages. \n    + How would be think about the venn diagram of ""evolutionary strategies"", ""genetic algorithms"", ""deep Q networks"", ""deep RL algorithms"" and ""random search""... there is clearly a lot of overlap here.\n    + The proposed deep GA has a ""deep Q network"" (or is it a policy... the paper does not make this clear), forms a type of ""evolutionary strategy"" and, at its heart is a type of ""random search"", but is it not also a ""deep RL algorithm""?\n    + It is not until page 3 that we get a proper definition of the algorithm, and it\'s hard to keep track of the differences the authors want to highlight compared to the ""baselines"".\n    + What do we gain from the claim ""old algorithms work well""... gradient descent is also an old algorithm, as are seemingly all of the alternatives? Is age in-of-itself an asset?\n    + Statements like ""compression rate depends on the number of generations, but in practice is always substantial"" are very loose... what does the ""practice"" refer to here, and why?\n\n- There is very little insight/analysis into *how* or *why* this algorithm performs better/worse than the alternatives. I don\'t feel I understand if/when I should use this algorithm versus another apart from a wall of seemingly random Atari results. In fact, there is a large literature that explains why GAs give up a lot of efficiency due to their ""black box"" nature... what do the authors think of this?\n\n- This paper seems purely focused on results rather than insight, with many hacks/tweaks to get good results... should we believe that GA+novelty search is a general algorithm for AI, or is it just another tool in the arsenal of a research engineer? \n    + In the end, the algorithm doesn\'t actually seem to outperform state-of-the-art on these Atari baselines... so what are we supposed to take away from this.\n\nOverall, I don\'t think that this paper provides very much in the way of scientific insight.\nFurther, the results are not even superior to existing algorithms with stronger groundings.\nFor me, this leads it to be a clear reject... even though they probably have code that reliably solved Atari games in a few hours.', 'This paper demonstrates that Genetic Algorithms can be used to train deep neural policies for Atari, locomotion, and an image-based maze task. It\'s interesting that GAs can operate in the very high-dimensional parameter space of DNNs. Results show that on the set of Atari games, GAs perform roughly as well as other ES/DeepRL algorithms.\n\nIn general, it\'s a bit hard to tell what the contribution of this paper is - as an emperical study of GA\'s applied to RL problems, the results raise questions:\n\n1) Why only 13 Atari games? Since the algorithm only takes 1-4 hours to run it should only take a few days to collect results on all 57 games?\n\n2) Why not examine a standard GA which includes the crossover operator? Do the results change with crossover?\n\n3) The authors miss relevant related work such as ""A Neuroevolution Approach to General Atari Game Playing"" by Hausknecht et al., which examines how neuroevolution (GA based optimization which modifies network topology in addition to parameters) can be used to learn policies for Atari, also scaling to million-parameter networks. This work already showed that GA-based optimization is highly applicable to Atari games.\n\n4) Is there actual neuroevolution going on? The title seems to imply there so, but from my reading of the paper - it seems to be a straightforward GA (minus crossover) being applied to weight values without changes to network topology.\n\nI think this paper could be strengthened by providing more insight into 1) Given that it\'s already been shown that random search can be competitive to RL in several Mujoco tasks (see ""Simple random search provides a competitive approach to reinforcement learning"") I think it\'s important to understand why and in what scenarios GAs are preferable to RL and to ES given similar performance between the various methods. 2) Analysis as to whether Atari games in particular are amenable to gradient-free optimization or if GA\'s are equally applicable to the full range or RL environments?\n', 'The authors explore the use of GAs as an alternative to gradient based methods for DeepRL and show performance comparisons indicating competitive /on par performance when compared to the existing methods. \n\nPros:\n-I liked the idea of exploring other avenues for approaching DeepRL problems, and challenging existing paradigms or trends. \nThis has a couple of implications - it might lead to expanding the toolbox for DeepRL problems, and it also might lend insight regarding these problems that could lead to new directions in exploring other methods. In other words, exploring WHY GA do better (and even RS!) could be useful, and this study is a foray in that direction. \nIt could also (as they point out) lead to useful hybrid approaches.\n-Their implementation will be made available and includes some useful features (compact network encoding, etc). \n-They demonstrate very nice speeds that can be impactful especially for more resource limited scenarios. \n\nCons: \n-There has been some exploration of use of GA for games, though not in DeepRL (AFAIK). They should cite previous efforts and explain what is their contribution specifically above and beyond previous efforts.\n-Although I applaud the authors for making exploratory efforts into this alternative approach and demonstrating competitive performance, the reader is left with some degree of ""so what?"". In other words, WHEN should this method be applied? How does it fit into the existing toolkit?\n-This is in some ways a conceptual exploration, and it shows interesting things that open ""why"" questions. Why does GA do better in some cases? They address this nicely in the discussion but more exploration in that direction would be useful. \n\nOverall I like this paper for its conceptual contribution that may provide insight that will help the field grow in interesting directions, and for the implementation it will provide. \n\n\n\n', 'The authors show that using a simple genetic algorithm to optimize the weights of a large DNN parameterizing the action-value function can result in competitive policies. The GA uses selection truncation and elitism as heuristics; compact-encoding of the genome to improve system efficiency. Results on Atari are presented, along with a comparison with standard gradient-based RL algorithms and ES.\n\nPros:\n\nThe knowledge that on a moderately complex optimization problem such as RL on Atari with pixel inputs, learning can be achieved using parameter perturbation (combined with heuristics) is valuable to the community. The authors’ motivation --- that GAs could prove to be another interesting tool for RL --- is well-founded. The efficient implementation using CPU-GPU hybridization and the compact-encoding is a good engineering contribution and could help accelerate further research.\n\nCons:\n\na.) One issue is that the results are presented in a somewhat hard-to-read manner. Table 1. shows numbers on 13 selected Atari games, of which 3 work best with GA (considering 1B frames). Comparison on all games helps to understand the general applicability of GAs. This is provided in Table 6., but the GA (1B) is missing. So are we comparing ES (1B) vs GA (6B) in Table 6 on all games? I can understand that DQN/A3C take days to run that many frames, but what does a ES (1B) vs GA (6B) comparison tell us? Am I reading it right?\n\nb.) Deep RL algorithms are approximations of theoretically sound ideas; so is ES in a way. What would help make this an even better paper is if the authors attempt to demystify the GA results. For example, I would have enjoyed some discussion on the potential reasons for the superiority of GAs on the 3 games in Table 1. Are these hard exploration environments and the parameter-space exploration in GA outperforms the action-space (e-greedy) exploration in A3C (DQN)? Random search is also better than DQN on those 3 environments --- Is the availably of good policies around the initial weight distribution contributing to the GA results in anyway? Furthermore, it would be interesting to pick out the worst games for GA from Table 5. (cases of catastrophic failure of GA), and analyze the shortcomings of GA. This would be helpful in further advancing research in GAs for deep RL. As a suggestion, ablation studies could go some distance in improving the interpretability, since the GA in the paper uses critical choices (parameter-noise variance, population-size etc.) and heuristics (truncation, elitism, etc.) that affect performance w.r.t baselines.\n\nOther comments:\n\nComparing GA+NS with A3C/DQN under environments with deceptive rewards is not completely fair. If the GA is armed with an exploration strategy like NS, so should the standard RL algorithms (e.g. by adding count-based, curiosity exploration). \n\nSection 4.3 (Humanoid discussion) could be move to Appendix since it currently doesn’t work with GA, and if anything, increases doubts on the robustness of GA since the Humanoid DNN is fairly small.\n']","[50, -60, -20, 70, 50]","[75, 20, 50, 80, 75]","[""The sentiment score is 50 (moderately positive) because the reviewer acknowledges valuable contributions of the paper, such as demonstrating the applicability of GAs to larger networks and introducing a novel software implementation. The reviewer also appreciates the authors' effort in going against prevailing trends. However, the score is not higher due to some criticisms, such as the need for more data points and evaluations on additional tasks. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. The reviewer provides constructive criticism and suggestions for improvement without using harsh or dismissive language. Phrases like 'In my opinion' and 'I believe' are used to soften critiques, and the reviewer balances positive feedback with areas for improvement."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('several things to like'), the majority of the review focuses on criticisms and shortcomings of the paper. The reviewer concludes with a 'clear reject' recommendation, indicating a strong negative sentiment overall. The politeness score is 20 because the reviewer maintains a professional tone throughout, acknowledging positive aspects before presenting criticisms. They use phrases like 'There are several things to like about this paper' and present their criticisms in a constructive manner. However, the language is not overly polite or deferential, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns and criticisms. The review starts positively but quickly shifts to questioning the paper's contribution and highlighting multiple areas for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'it's interesting that' and 'I think this paper could be strengthened by,' which soften the criticism. They also pose their concerns as questions rather than direct criticisms. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral to slightly positive tone in terms of politeness."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, highlighting several pros and its conceptual contribution. They use phrases like 'I liked the idea', 'very nice speeds', and 'Overall I like this paper'. However, it's not 100 as they also mention some cons and areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts with phrases like 'I applaud the authors'. They present criticisms constructively, often framing them as opportunities for improvement rather than outright flaws. The tone is professional and encouraging, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the value and contributions of the paper, noting several 'pros', while also providing constructive criticism and suggestions for improvement. The tone is generally positive, but the 'cons' and 'other comments' sections indicate areas for improvement, balancing out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as suggestions or questions rather than direct attacks. Phrases like 'would help make this an even better paper' and 'I would have enjoyed' indicate a constructive and collegial tone. The reviewer also provides detailed explanations for their comments, showing engagement with the work and respect for the authors' time and effort.""]"
"['The authors focus solely on universal adversarial perturbations, considering both epsilon ball attacks and universal adversarial patches. They propose a modified form of adversarial training inspired by game theory, whereby the training protocol includes adversarial examples from previous updates alongside up to date attacks.\n\nOriginality: I am not familiar with all the literature in this area, but I believe this approach is novel. It seems logical and well motivated.\n\nQuality and significance: The work was of good quality. However I felt the baselines provided in the experiments were insufficient, and I would recommend the authors improve these and resubmit to a future conference.\n\nClarity: The work was mostly clear.\n\nSpecific comments:\n1) At the top of page 5, the authors propose an approximation to fictitious play. I did not follow why this approximation was necessary or how it differed from an stochastic estimate of the full objective. Could the authors clarify?\n\n2) The method proposed by the authors is specifically designed to defend against universal adversarial perturbations, yet all of the baselines provided defend against conventional adversarial perturbations. Thus, I cannot tell whether the gains reported result from the inclusion of ""stale"" attacks in adversarial training, or simply from the restriction to universal perturbations. This is the main weakness of the paper.\n\n3) Note that as a simple baseline, the authors could employ standard adversarial training, for which the pseudo universal pertubations are found across the current SGD minibatch.\n\n\n', 'In this paper, the authors proposed universal perturbation based robust training framework. With the aid of universal perturbation, the conventional robust training framework can be further interpreted as a fictitious play. Interesting algorithm and results are reported in the paper. My detailed comments are listed as follows. \n\n1) Some details of the proposed algorithm 1 are missing. In step 3, is just single SGD step performed? The generation of universal perturbation is not clearly discussed in Sec. 3.4. How to handle the expectation over the parameters of the affine transformation applied to the patch? MC particle-based approximation for these random parameters? If so, how many particles are used? \n\n2) I am confused on Algorithm\\,2 (AT). Is step 5 same as the robust adversarial training algorithm proposed by Madry \n et al.? What I recall is that SGD (for outer minimization) is only performed over perturbed samples, No? Please clarify it.\n\n3) In experiments, the authors mentioned ""The accuracy (dotted line in the plots) is the fraction of examples that have been correctly classified for a batch of 10000 samples randomly chosen in the train, validation and test sets."" Please clearly define the train/validation/test datasets, e.g., size and how to generate adversarial examples for testing. \n\n4) In Figure 4-6, is only the universal perturbation based attack evaluated? It does not seem a fair comparison, since the proposed min-max problem builds on the generation of universal perturbations. I wonder how robustness of the proposed method against per-sample perturbation, e.g., C\\&W attack. I think it might be important to find a third-party attack method, e.g., C\\&W or physically transformed attacks, to test both fictitious play and robust adversarial training.\n\nIn general, the paper contains interesting ideas and results. However, there exist questions on their implementation details and empirical results. \n', 'Being familiar but not an expert in either game theory or adversarial training, my review will focus on the overall soundness of the proposed method\n\nSummary:\n\nThe authors propose to tackle the problem of adversarial training.\nDeep networks are know to be susceptible to adversarial attacks.\nAdversarial training is concerned with the training of networks that both achieve good performance for the original task while being robust to adversarial attacks.\n\nThey propose to focus on universal adversarial perturbations, as opposed to per-sample perturbations. The latter is a subclass of the former. \nIt doesn’t strike as the most natural scenario: I can’t really think of a practical image classification scenario where one would want to perturb a whole dataset of image with a single perturbation. That said, this focus leads to simpler algorithms (complexity and storage wise) which are worth exploring.\n\nThe authors first present the min-max problem of adversarial training at hand where a classifier f mimizes a loss L for a dataset D, while the conman maximizes the loss over perturbation of the dataset \\epsilon.\nThey then introduce an algorithm to solve it inspired by fictitious play:\nA sequence of classifiers and perturbed datasets are created iteratively by the two players (classifier, conman) and each player uses the complete history of its opponent to make its next move.\n\nThe objective solved by each player  is :\nconman: fool all past classifiers with a single new perturbation\nclassifier: be robust to all past perturbations so far.\n\nAlthough it makes intuitive sense, it is unclear from the manuscript whether this formulation provides any convergence guarantees. It would be great to know whether the connection to fictitious play is purely inspirational or if any of the theoretical guarantees from game theory apply here.\n\nThe conman’s objective to fool all past classifiers is the bottleneck (in terms of storage) and an approximation is proposed: the mean loss over past classifiers is replaced by the loss under a single ‘average’ classifier trained on all past dataset, with the intuition that this average classifier summarizes all past classifiers\n\nA particular algorithm for perturbation learning is described and the proposed algorithm is compared against two baselines: a pre-existing adversarial training algorithm, an non-adversarial algorithm\n\nThe metrics chosen are accuracy and adversarial accuracy.\nOn standard classification tasks, adversarial algorithms perform slightly less well on the original task (accuracy) but are robust to perturbation as expected,\n\nIt would be interesting to know if these good performances extend to per-sample perturbations: Do a network trained on universal perturbations perform well against per sample perturbation? \n\n\nRemarks:\nsgn missing in the adversarial patch update (and who is alpha?)\nintroduce terminology: white box black box\n']","[-20, 20, 20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and quality of the work, they express concerns about insufficient baselines and recommend resubmission to a future conference. This suggests the paper is not yet ready for acceptance in its current form. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the strengths of the paper, and frames criticisms constructively as recommendations or questions. They use phrases like 'I believe', 'I felt', and 'Could the authors clarify?' which maintain a polite tone while expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'interesting ideas and results' and mentions 'Interesting algorithm and results are reported in the paper.' However, the score is not higher due to the presence of several questions and concerns raised about implementation details and empirical results. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions rather than direct criticisms (e.g., 'Please clarify', 'I wonder how...'), and begins with positive comments before moving to more critical points. The reviewer also uses neutral, professional language without any harsh or rude expressions."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the value of the proposed method, noting that it leads to 'simpler algorithms' and is 'worth exploring'. They also mention that the approach 'makes intuitive sense'. However, they raise some questions and concerns, which prevents the score from being higher. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions rather than direct attacks. For example, they use phrases like 'It would be great to know' and 'It would be interesting to know', which are polite ways of requesting more information. The reviewer also acknowledges their own limitations ('Being familiar but not an expert'), which adds to the overall polite tone.""]"
"['The paper gives convergence guarantees to the true neural network classifier for the networks that are explicitly regularizing the (exact) Lipschitz constant of the network. The bound stated decays as ( log(n)/n )^{1/m}, where n is the number of training points and m is the dimension of the data manifold. Thus the decay rate is pretty slow when the data lies on a high-dimensional manifold. I believe it should also depend on the volume of the data manifold.\n\nComputing the exact Lipschitz constant of the network is intractable. All the theorems apply to minimization problem defined in (1) with the exact Lip(u,X) being regularized, and not to the minimization problem of the lower bound (2). I believe there are also no convergence guarantees how quickly this lower bound on the Lipschitz constant approaches Lip(u,X), unless some assumptions are made on the smoothness of the data manifold (comments and insights would be appreciated). Thus in my opinion the current results have little practical importance. Nevertheless, it’s still interesting to see some ideal-setting guarantees being established.\n\n\nTheorem 2.7: Is m == m_0 (the dimension of the data manifold)? Shouldn’t the bound be 2*C*L_0….? (assuming lemma 2.9 is correct)\n\nCor 2.8: Where does the volume Vol(M) of the manifold disappear? Is C in equation (6) the same C as in Theorem 2.7? Also, it looks like the bound should bound should have C^2 (assuming theorem 2.7 is correct, and the C’s are the same).\n\n\nIntroduction: I assume u(x,w) is not the last layer map, but a map from the input space to the labels (i.e., the whole neural network function and not just the map from the last hidden layer to the labels). If I am correct, it’s misleading to refer to u(x,w) as the last layer map. And if it is the last layer map, please justify why it is enough to consider the Lipschitz constant of the last layer.\n\nThe term “clean data” is never defined. My guess is that “clean data” refers to the realizable  setting, and “noisy” to agnostic, where the hypothesis space consist of neural networks of arbitrary size.\n\n\n“Our analysis can avoid the dependence on the weights because we make the assumption that there are enough parameters so that u can perfectly fit the training data. The assumption is justified by Zhang et al. (2016).”\nNote, that the network used in practice achieve zero classification error, as demonstrated by Zhang et al, but I doubt the cross entropy loss (that is usually being minimized) is exactly zero.\n\nRemark 1.4 “will result in an expected loss..”  (there is also a typo here) should specify that you are talking about empirical error (0-1 loss), since I don’t think the loss function is fixed anywhere earlier in the text.\n\nRemark 2.2 : Just wanted to note, that it is more common to call L(u,\\rho) risk. The gap between L(u,\\rho) and the empirical risk L(u,\\rho_n) is usually called the generalization error (and only in the case of zero empirical risk, L(u,\\rho) is equal to the generalization error). I did check the reference in Goodfellow et al. book, and I see that it is consistent with your definition.\n\nJust below Remark 2.2:\n“We would also expect the sequence of generalization losses L[u_n ; \\rho] to converge to zero in the case of perfect generalization.”\nOnce again, this is true only in the realizable setting.\n\nCould the authors comment on the connection to Cranko et al. 2018 work?\n\nTypos:\nIn the abstract, no which: “..corrupted labels which we prove convergence to...”\n“...a candidate measure for the Rademacher complexity, which a measure of generalization...”.\n“1-Lipschitz networks with are also important for Wasserstein-GANs”\nSection 2.1 “is it clear that u0, is a solution of “, should be “it is”\n\n\n---------\n[UPDATE]\n\nRegarding the comment ""Our paper resolves the question posed in ICLR Best paper 2017 ""Understanding deep learning requires rethinking generalization"""", I don\'t think that analyzing networks with explicit regularization resolves the questions stated in Zhang et al paper. As other reviewers mentioned, there are a number of other papers that formally define quantities that correlate with the generalization error, and are larger for random vs true labels. There are also other papers showing that one can tune some parameters of the optimization algorithm to avoid overfitting on random labels (while it is a modification to the algorithm, it is still similar to explicitly regularizing the Lipschitz constant of the network) (see e.g., Dziugaite et al work on SGLD).\n\nTherefore, the claim in the abstract ""A second result resolves a question posed in Zhang et al. (2016): how can a model distinguish between the case of clean labels, and randomized labels?"" needs to be toned down a bit.\n\nIn my opinion, the work presented in this paper is a valuable contribution to learning theory. The new version of the paper is easy to read. Therefore, I recommend acceptance if the authors change the claim about resolving  the questions posed by Zhang et al.\n\nAnother typo:\n - for convergence, we require that the network also grow(s), ', 'Disclaimer:  I am not a working expert in this specific area.  I have used spectral normalization for my own applications, and have working expertise in leveraging Lipschitz properties for various flavors of stability analyses.\n\nThis paper proposes a error convergence analysis for Lipschitz-regularized neural nets.  The analysis is framed in function space of the neural net and assumes the ability to solve the learning minimization problem.   The authors contrast their analysis with other analysis approaches in several ways.  First is that their analysis is ""more direct"" and second is that their analysis is independent of the learning approach (e.g., spectral normalization + SGD). \n \n\n***Clarity***\n\nThe paper is mostly clearly written.  Some of the statements are presented without sufficient description.  For instance:\n\n-- What does it mean when the paper states that their analysis is ""more direct"" than previous work?  There was no discussion of previous work beyond that comment.\n\n-- The statement of Lemma 2.9 is not entirely clear.  Is \\sigma_n a vector of white gaussian random variables?\n\n-- Definition 2.3 precludes the hinge loss.  Comments?\n\n-- Example 2.6, the regularized cross entropy loss doesn\'t satisfy L(y,z) = 0 if and only if y=z.  It might not even satisfy L >= 0. \n Comments?\n\n-- Since the function is Lipschitz, in the noisy case, can one say anything about the guarantees near the manifold for some definition of near?  E.g., can one bound how bad the tail parts of Figure 3 can be?\n\n\n***Originality***\n\nIt seems to me that the analysis aims to set up the problem such that one can leverage standard results in probability theory.    For instance, the proof of Theorem 2.7 is quite straightforward given Lemma 2.9.  Of course, setting up the problem properly is 90% of the work.  The analysis for the noisy case is much more involved.  It is unfortunately beyond my expertise to properly judge originality in this case.  Perhaps the authors can comment on how the way they set up the problem is novel?\n\n\n***Significance***\n\nMy biggest question mark w.r.t. significance are the claims of how this analysis compares with previous work.\n\n-- What does ""more direct"" analysis mean?\n\n-- What is the significance of an algorithm-agnostic analysis?  I understand the appeal from a certain perspective, but can the authors point to previous literature (perhaps not in deep learning) where an algorithm-agnostic analysis was shown to give more insight?\n\n\n***Overall Quality***\n\nConditioned on the problem setup being novel and the comparison with related work clarified, I think this is a solid contribution.\n', 'The paper studies generalization through a general empirical risk minimization procedure with Lipschitz regularization.\nGeneralization is measured through distance of the empirical minimizer function to a true labeling function u_0, or to the minimizer of the expected regularized loss.\n\nThe approach of studying generalization through the lens of Lipschitz stability over the data is interesting,\nand the study directly considers minimizers of regularized optimization objectives, which is different than\nrecent generalization bounds which often provide guarantees on a given network regardless of how it was trained.\n\nHowever, various aspects of the setup seem quite disconnected from practice in the context of deep neural networks,\nand the obtained guarantees are quite weak and not always connected to generalization:\n\n- the approach relies on a constant L_0 in the objective which is assumed known in advance (although it is usually set to 0 in practical methods), and determines the nature of convergence. In particular, the results for small L_0 (referred to as ""noisy labels"") only shows convergence to a minimizer u^* of the expected *regularized* loss, thus does not characterize generalization in the usual sense since u^* is biased. More generally, the distinction between \'clean\' and \'noisy\' labels is confusing and should be clarified: the paper seems to assume that the true labeling function u_0 may itself produce incorrect labels deterministically even with infinite data, which is an odd way to formulate the learning problem.\n\n- the convergence rates obtained in the paper exhibit a curse of dimensionality (O(n^{-1/m}) where m is the dimensionality of the data manifold). Given that most other bounds for neural networks do not exhibit such a dependence on dimension, this seems to be a weaker guarantee, unless the setting captures an improvement in a different setting. (edit: I removed the previous remark on parametric rates, which was inaccurate) Some of the constants also seem to grow exponentially with m. Either way, this should be discussed in the paper.\n\n- possibly related to the previous point, all the theory in the paper is agnostic to the function class considered, given that it simply considers all lipschitz functions in the variational problem (1). Given that the authors attempt to explain generalization of neural networks, this seems like a non-negligible disconnect since there could be approximation errors. In particular, even if deep networks can perfectly fit training data, it is not clear that they can achieve the best trade-off with the Lipschitz constant in the regularized objective (1).\n\n- the assumptions on the prediction space (simplex) and the used loss functions also seem disconnected from practice (the cross-entropy loss usually includes a softmax). Note that while usual networks can fit randomly labeled data (Zhang et al.), this does not mean their loss is 0. Yet the analysis seem to rely on having zero loss on training points, even in the case of \'noisy labels\'.\n\nAdditionally, the use of covering arguments in the input space in the proposed approach is related to the study of generalization through robustness [Xu & Mannor (2010), ""Robustness and Generalization""]. The authors should discuss the relationship to this work.\n\nMore comments:\n- the term \'converge\' in the title is not clear. In the abstract, what does \'verification\' mean?\n- Section 2.3: \n  m_0 == m ?\n  How does C grow with m in Theorem 2.7 and Corollary 2.8?\n  What is meant by \'perfect generalization\'?\n  Is eq. (6) realistic for classification losses?\n- Section 2.4: clarify what is meant by \'noisy labels\'']","[20, 50, -30]","[60, 80, 50]","[""The sentiment score is slightly positive (20) because while the reviewer points out some limitations and issues, they also acknowledge the work as 'interesting' and a 'valuable contribution to learning theory'. They recommend acceptance with minor changes. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, asks for clarifications politely ('Could the authors comment on...'), and offers constructive feedback. They also acknowledge the positive aspects of the work. The reviewer maintains a professional tone, avoiding harsh criticism while still pointing out areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as a 'solid contribution' and praises aspects like clarity, while also raising several questions and concerns. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 80 (quite polite) due to the reviewer's respectful language, use of phrases like 'Perhaps the authors can comment' and 'It is unfortunately beyond my expertise', and the disclaimer at the beginning showing humility. The reviewer raises concerns and questions in a tactful manner, using phrases like 'My biggest question mark' rather than direct criticism."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The approach of studying generalization through the lens of Lipschitz stability over the data is interesting'), the majority of the review focuses on limitations and criticisms of the paper. The reviewer points out several disconnects from practical applications, weak guarantees, and issues with assumptions. However, the tone is not entirely negative, as the reviewer offers constructive feedback and suggestions for improvement.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The approach... is interesting' and offer specific, constructive feedback without using harsh or dismissive language. The reviewer also provides detailed explanations for their criticisms and suggestions for improvement, which is a polite way to offer feedback. However, the score is not higher because the review is primarily critical and doesn't include many positive reinforcements or courtesies beyond what is necessary for professional communication.""]"
"['This paper looks to predict ""unstructured"" set output data. It extends Rezatofighi et al 2018 by modeling a latent permutation.\n\nUnfortunately, there is a bit of an identity crisis happening in this paper. There are several choices that do not follow based on the data the paper considers. \n1) The paper claims to want to predict unordered sets, yet the model is clearly indicating a dependence in the order of the outputs and the input p_m(\\pi | x_i, w) (1); this feels like a very odd choice to me. The outputs are either unordered sets, where you would have a permutation invariant (or exchangeable) likelihood, or they are ordered sequence where the order of the outputs does matter, as some are more likely than others.\n2) The paper still makes very odd choices even if one ignores the above and wants to model some orderings as more likely than others. The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense. Conditioned on the permutation of the set, the points are exchangeable. Let\'s just consider a 2 element ""set"" at the moment Y = (y_1, y_2). Order matters, so either this is being observed as pi=(1, 2) or pi=(2, 1), both of which depend on the input x. However, the likelihood of the points does not actually depend on the order in any traditional sense of the word. we have:\np_\\pi((1, 2) | x, w) p_y(y_1 |  x, w, (1, 2)) p_y(y_2 |  x, w, (1, 2)) + p_\\pi((2, 1) | x, w) p_y(y_1 |  x, w, (2, 1)) p_y(y_2 |  x, w, (2, 1))\n*Note that in here (as in eq. 2) the output distribution p_y does not know what the index is of what it is outputting, since it is iid.* So what does this mean? It means that the order (permutation) can only affect the distribution in an iid (exchangeable, order invariant) way. Essentially the paper has just written a mixture model for the output points where there are as many components as permutations. I don\'t think this makes much sense, and if it was an intentional choice, the paper did a poor job of indicating it.\n3) Supposing even still that one does want a mixture model with as many components as permutations, there are still some issues. It is very unclear how the dependence on \\pi drops out when getting a MAP estimate of outputs in section 3.3. This needs to be justified.\n\nThere are some stylistic shortcomings as well. For example, the related works paper would read better if it wasn\'t one long block (i.e. break it into several paragraphs). Also, the paper claims that it will use a super script m to denote a known cardinality, yet omits \\mathcal{Y}_i^{m_i} in the training set of the first sentence in 3.1. But these and other points are minor.\n\nThe paper should not be published until it can resolve or make sense of the methodological discrepancies between what it says it looks to do and what it actually does as described in points 1), 2), and 3) above.', '— Summary\nThe method extends [21], which proposes an unordered set prediction model for multi-class classification. For that problem, [21] can assume logistic outputs for all distinct classes. This work extends set prediction to the object detection task, where box identity is not distinct — this is handled by an additional model output that reasons about the most likely object permutations. The permutation predictions are used during training, but are not needed at inference time — as shown in Fig1 and Eq 7. Results are on detection of overlapping objects and a CAPTCHA toy summation example.\n\n— Clarity \nThe exposition is not particularly clear in several places: \n - U^m in Eq 1 is undefined and un-discussed. What probability term does it correspond to? It is supposed to make probabilities of different cardinalities comparable, but the exact mechanism is unclear. \n - The term p(w) disappears on the left hand side of Eq 2. \n - Notation in Sec. 3.2 is very cumbersome, making it hard to follow. Furthermore, I found the description ambiguous, preventing me from understanding how exactly the permutation head output is used in Eq 5. Specifically, there is some confusion about estimation of w~, which seems based on frequency estimation from past SGD iterations (Eq 3). If so, why does term f2 in Eq 5 contain the permutation head output O2 and how do the two relate? \n - The network architecture is never described, especially the transition from Conv to Dense and the layer sizes, making the work hard to reproduce. The dimensions of the convolutional feature map matter (probably need to be kept tractable). \n\n— Significance\nKey aspects of the model are not particularly clear, specifically about how the permutation prediction ( the key novelty here) is used to benefit training. \n— Term f2 in Eq5 uses w~ estimates, which appeared to be based on statistics from past SGD runs, yet also depends on the output of the permutation head O2. Am I misinterpreting the method?\n— In the paragraph right after Eq5, it’s claimed that “Empirically, in our applications, we found out that estimation of the permutations from just f1 [in Eq5] is sufficient to train properly … by using the Hungarian algorithm”. So then f2 term is not even used in. Eq5? If so, what is the significance of the permutation head other than adding an auxiliary loss? \n\nFurthermore, there are no experimental results demonstrating the effect of the permutation head and the design choices above — if we could get by with only using the Hungarian algorithm, why bother classifying an exponential number of permutations? Do they help when added as an auxiliary loss?  \n\nWhile the failure of NMS to detect overlapping objects is expected, the experiments showing that perm-set prediction handles them well is interesting and promising. Solving the general case with larger images and many instances would increase the impact significantly — and likely require a combination of perm-set prediction and image tiling, although this is just a hypothesis. The Captcha toy example also shows some interesting behavior emerging — without digit-specific annotations (otherwise it would be multi-class classification setup from [21]), the model can handle the majority of summations correctly. \n\n— Experimental results\nThe results are interesting proofs-of-concept but a few more experiments/answers would be helpful:\n- It still appears that PR curve in the high-precision regime (fig 3b) has lower precision than FRCNN/YOLO. Any idea as to why? \n- Ablation results on the effect of the permutation predictions vs Hungarian algorithm, etc would be helpful, as discussed above. \n- How sensitive is the method to seeing a certain cardinality? What if it never sees 3 pedestrians in an image, but only 1,2,4 will it fail to predict 3? Or alternatively, if we train a model that can handle up to 5-6 entities with examples than have <=4? What is the right way of data augmentation for this model (was there any and should there be?)\n- Given that values for U differ across applications, how sensitive is the output / how much sweeping did you have to do?\u2028\n\n-- Related work\nTo the best of my knowledge it\'s representative. It would help to cite more recent work that decreases detector dependence on NMS. For example, ""Learning Non-Maximum Suppression"", Hosang, Benenson, Schiele, CVPR 2017 or ""Relation Networks for Object Detection"", by Hu et al, CVPR 2018 and references therein. ', '\nThe paper is really interesting. Set prediction problem has lots of applications in AI applications and the problem has not been conquered by deep networks. \n\nThe paper proposes a formulation to learn the distribution over unobservable permutation variables based on deep networks and uses a MAP  estimator for inference.  It has object detection applications. The results show that it can outperform YOLOv2 and Faster R-CNN in a small pedestrian detection dataset which contains heavy occlusions. \n\nThe limitation is clearly stated in the last part of the paper that the number of possible permutations exponentially grows with the maximum set size (cardinality). \n\nIn the author response period, I would like the author give more details about the pedestrian detection experiments, such as how many dense layers are used after ResNet-101, what are the training and inference time, is it possible to report results on PASCAL VOC (only the person class).\n\nThe method is exciting for object detection funs.  I would like to encourage the authors to release the code and let the whole object detection community overcome the limitation in the paper. \n\n\n\n']","[-80, -20, 80]","[-20, 50, 90]","[""The sentiment score is -80 because the review is highly critical of the paper, pointing out several major methodological issues and stating that the paper should not be published until these are resolved. The reviewer uses phrases like 'identity crisis', 'very odd choices', and 'does not make sense', indicating strong disapproval. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. Phrases like 'Unfortunately, there is a bit of an identity crisis happening in this paper' and 'I don't think this makes much sense' are quite direct and could be perceived as somewhat impolite in academic discourse. However, the reviewer does acknowledge some minor positive aspects and uses some hedging language ('a bit', 'feels like'), which prevents the score from being even lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the work, they express several concerns about clarity, significance, and experimental results. The review points out multiple areas where the exposition is unclear, questions the significance of certain model components, and suggests additional experiments that would strengthen the paper. However, the reviewer also recognizes some promising aspects of the work, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'would be helpful' and 'any idea as to why?' which come across as polite suggestions rather than harsh criticisms. The reviewer also acknowledges the interesting and promising aspects of the work, balancing their critique with positive observations. While direct in their feedback, the language remains respectful and focused on improving the paper rather than attacking the authors."", ""The sentiment score is 80 (positive) because the reviewer expresses strong interest in the paper, calling it 'really interesting' and 'exciting'. They highlight the paper's novelty, its outperformance of existing methods, and encourage code release. The only slight negative is mentioning a limitation, but this is presented as an opportunity for improvement. The politeness score is 90 (very polite) due to the consistently positive and encouraging tone. The reviewer uses phrases like 'I would like to encourage the authors' and 'exciting for object detection funs', showing enthusiasm and respect. They also frame their request for additional information politely during the author response period. The language is professional and supportive throughout, without any harsh criticism or demanding tone.""]"
"['The authors are tackling sample efficiency in the reinforcement learning setting by designing a reward function that encourages exploration. To achieve this they propose you use the successor function which basically counts how often a state has been visited. At first the show this for discrete settings and extend their approach to the continuous state spaces in the Atari 2600 environments. \n\nThe paper is well written and the motivation and methods are clear from the beginning. \n\nMy biggest concerning is regarding the experimental results of this work. In Table 1 the authors show the results for the tabular games River Swim and Six Arms and copare their approach which they dub ESSR to three methods (E3, R-MAX, MBIE). The numbers in the table indicate that their method ESSR is outperforming E3 and R-MAX on both environments but is itself outperformed by MBIE. The authors don\'t mention this at al in the respective paragraph nor do the provide a reason as to why this could be case. Also, they neither introduce any of these methods nor do the explain the meaning of the acronyms. Only in the section 6 (of 7) they talk about related works are R-MAX and E3 introduced briefly. But yet again, MBIE is not mentioned. \n\nI have similar concerns about the results presented for the Atari benchmarks. In table 2 the authors compare their method to the classic DQN approach and two more approaches. While their approach outperforms DQN in almost all tasks, this does not hold for the remaining algorithms. Their method is being outperformed in all but one (Venture) task, where they report a higher variance and a small performance boost compared to DQN_e^MMC. Also it is not clear to me where the numbers for the DNQ_e^MMC come from. The authors just say ""[...] denotes another baseline used in the comparison"". Is this the proposed method of this work but without the successor representation?\n\nIn my opinion this work is lacking some clear and convincing results.  Is the main benefit of this method that it does not rely on domain-specific knowledge? If so, then it is not communicated clearly. The authors mention this briefly in the conclusion but provide no further analysis', 'Being familiar but not an expert in reinforcement learning, my review will focus on the overall soundness of the proposed method\n\nSummary:\n\nThe authors are interested in the problem of sample efficiency in reinforcement learning, i.e. how to learn a policy achieving good performance (discounted reward) in a RL setting using as little interaction with the environment as possible.\nTo do this the authors propose to learn a policy in a new environment where the reward has changed: an exploration bonus is added to the reward that should bias the agent towards the least frequently visited states.\n\nThe algorithms proposed throughout the manuscript are extensions of a two-part algorithm of the following flavour: 1) An estimate of visitation count is done in an online fashion using a modified version of the successor representation (SR). 2) This estimates parametrizes the exploration bonus of the environment . Both learning algorithms are optimized together.\n\nThis initial algorithm is fairly simple in its description and builds on well established ideas in RL. The authors then ‘evaluate the effectiveness of the proposed exploration bonus in a standard model-based algorithm’ against other baselines. They do explain how the model is learned, but not how the policy is optimized.\n\nThe remainder of the manuscript applies the same idea to different settings.\nFor large state spaces, The SR expected visits are learned using TD along with state action value functions. The counts of visitations are replaced by features that are also learned.\n\nOverall, the manuscript is rather confusing.\nThe SSR theorem is stated (with no real intuition and the actual bounds on n(s) left for the reader to derive). It is not well motivated. Why would we want expected counts and not the discounted version?\nThen the remainder of the paper actually makes no use of this theorem, but only use it as a distant inspiration. Tentative connections are made such as TD underestimating SR thus leading to a result more akin to SSR, which is highly speculative. It is also irrelevant since features are learned anyway.\n\nThe final proposed architecture has many additions to a simple DQN (the reconstruction + the exploration bonus + the MMC). This makes it difficult to understand what the contribution of the exploration bonus is.\nIt does not help that results are manually extracted from histograms found in  papers.\n\nOverall, although the intuition is interesting (though not so new).\nThe overall motivation and structure of this manuscript makes think it does not match the standards of ICLR for publication\n', 'This paper proposed a new exploration strategy, based on the successor representation (SR), which can be used as a pseudo bonus in reinforcement learning. The authors also showed the connection between the state visit count and the SR, in the tabular case. Finally, the proposed algorithm had been tested on simulated examples, and several hard exploration Atari domains.\n\nIn general, there are some interesting ideas in this paper, while the empirical justification may not be strong enough. My pros and cons are summarized as follows. \nPros:\n- The idea of using SR for pseudo count in deep RL is novel.\n- Theorem 1 shows the interesting connection between state visit count and the proposed SR.\n- The experiments on Atari games show some promise for using SR (but not that much).\nCons:\n- There are a few inconsistencies regarding the use of SR. For example, the tabular case used the minus l1 norm as the reward bonus; however, the Atari case instead set the bonus to be the reciprocal of the l2 norm. \n- Other than the Montezuma\'s Revenge, it\'s difficult to draw the conclusion that using SR can generally lead to better exploration performance, based on the last two columns of Table 2.\n- The definition of loss L_{SR} is a bit unclear: Is there something similar to the Bellman equation you can say about SR? I also don\'t quite understand the motivation for the architecture between \\phi and \\psi in Figure 1.\n- A few small comments/questions are listed as follows.\n  1. When discussing the impact of the introduced auxiliary task, it would be more convincing to show the performance of games other than Montezuma\'s Revenge.\n  2. Why is it true that ""... because a reward of 1 is observed..."", in the second paragraph of Section 4?\n  3. What is the value of \\tau in the loss L_{TD} on Atari domains?']","[-30, -70, 20]","[50, 20, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The paper is well written and the motivation and methods are clear'), they express significant concerns about the experimental results and lack of clear, convincing outcomes. The reviewer points out several issues with the presentation and interpretation of results, which contributes to the overall negative sentiment. However, it's not extremely negative as the reviewer does recognize some merits of the paper.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'My biggest concern is...' and 'In my opinion...', which are polite ways to express criticism. The reviewer also acknowledges positive aspects of the paper before diving into concerns. While direct in their critique, they avoid harsh or rude language, instead focusing on specific issues in a constructive manner."", ""The sentiment score is -70 because the review is largely negative. The reviewer states that the manuscript is 'rather confusing', lacks proper motivation, and 'does not match the standards of ICLR for publication'. They criticize the paper's structure, clarity, and relevance of certain parts. However, they do acknowledge some positive aspects like 'interesting intuition', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'my review will focus on' and 'Overall, although the intuition is interesting' which soften the criticism. The reviewer also explains their reasoning for their critiques, which is a polite approach. However, the overall negative feedback and direct language prevent the score from being higher on the politeness scale."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some interesting ideas and novel aspects of the paper, particularly in the 'Pros' section. However, the score is not higher due to the significant 'Cons' section and the statement that 'empirical justification may not be strong enough.' The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, presents both pros and cons objectively, and phrases criticisms as questions or suggestions rather than direct attacks. The reviewer also uses phrases like 'it would be more convincing' instead of more aggressive language. The overall tone is professional and constructive, maintaining politeness while still providing critical feedback.""]"
"['This paper introduced a GAN-based method to learn language universal representations without parallel data. The model architecture is analogous to an autoencoder. The encoder is a compound of language-universal mapper plus a language-specific LSTM. For decoding, another language-universal module first map language-universal representation back to language-specific embedding space, then another LSTM decoder generates the original sentence. The authors used GAN to encourage intermediate representation to be language-universal. The authors tested the proposed method on zero-shot semantic analysis and NLI tasks and showed nice results.\n\nOverall the proposed method is novel and nice, and experiment results are good. On both tasks the proposed method performs better than NMT methods on target languages while still achieving competitive performance on source languages. The paper is also clearly written and could be useful for future research on multilingual transfer.\n\nMy main complaint is around Figure 5, Table 3, and the corresponding analysis.\n1. In Figure 5, does it make more sense to show the perplexity of a standard LM. That is, train 7 independent LMs and report averaged perplexity. My concern is that, even with \\lambda=0.0, the model still have modules u and h that are shared across languages, and therefore I\'m not sure if it implies ""representative power of UG-WGAN grows as we increase the number of languages"". It could be that the language-universal impose more constraints to model all languages, so the two variation (\\lambda=0.0 or 0.1) come closer to each other.\n\n2. In Figure 3, the perplexity difference is huge when number of languages is 2. In Table 3, however, the authors show no fundamental differences between the English and Spanish language models. I feel the two arguments contradict to each other. Is it because of the language pairs are different? The authors should provide more explanation on that.\n\nMinor:\n1. Equation 1 and 2 in page 2. Are they both compound functions? Why the first one use \\circ and the second one use parenthesis?', ""This paper proposes the idea of language agnostic representation which could potentially provide zero shot solution if the downstream task is trained using another language. The solution uses linguistic features from every sentence, trains language model for multiple languages simultaneously, and matches distribution by using Wasserstein distance measure. \n\npros:\nThe motivation of this paper is clear. \nThe method proposed looks reasonable. \nThe experimental results also make sense. \n\ncons:\n\nKey technical parts are not clear. The description of the training method is vague, e.g., the author(s) mentioned 'we utilized dropout and locked dropout where appropriate'. What does 'appropriate' mean? The training procedure was described in only few sentences. For example, it is not clear to me if a batch is fully random, or a batch consists of same number of sentences from each language, or a batch consists of same number of sentences from two languages, and how you train the WGAN. It is a bit surprising to me that different lambda gives similar performance. \n\nThe writing of the paper is not clear. Here are some of the reasons:\n1. The last paragraph in Section 2 does not fit into 'related work' section at all, instead, it is almost a repetition of the last paragraph in Section 1. \n2. The notations in Section 3 are very inconsistent. Just to name a few: the input dimension of function $e_j$ defined in the last paragraph in page 2 is not consistent with (1); the '$\\circle$' operation in (1) is not explained (although I can guess what it means); the $j_alpha, j_beta$ are not consistent with the $j^{th}$ language; in the last equation in page 3, the summation should be from 1 to m (instead of 0 to m) if there are m languages, and the superscript in $w$ is not defined. \n3. Key references missing, for example: there is no reference when deriving (4) using the 'Kantarovich-Rubenstein' duality. \n4. The organization for section 4 is not clear. The first sentence is quite confusing, and the content is a mixture of architecture design, training details, and experimental settings. Instead, one should separate these contents and address each of them. \n5. At the beginning of section 5.1, the hypothesis in the sentence 'to test this hypothesis' actually refers to the last paragraph in section 4. Figure 4 should be referred to in the last paragraph in section 5. 'english', 'german', 'chinese' should be 'English', 'German', 'Chinese'. \n"", 'This paper starts with the bold aim of extracting Montague\'s universal grammar from multiple languages. In order to do so, the authors train multiple language models where each LM is explicitly factorized into language-specific and language-independent representations. The authors then apply the GAN framework to the language-independent parts to enforce all languages to share the same latent space. The claim here is that the language independent parameters capture the essence of universal grammar. The authors show that their framework enables effective zero-shot learning of tasks over new languages (for example sentiment classifier learned on top of English data generalize to Chinese when trained on the universal grammar embeddings). \n\nThe paper is overall well written and the experimental results are convincing.\n\nThe gripe, however, I have is that this paper makes the claims that go too far without evaluating them. It is entirely sufficient to claim that you\'re trying to learn language agnostic parameters/embeddings --  I\'d be happy with that. But the paper goes further and claims to be learning a form of universal grammar. To justify this claims, it is not sufficient to show in the experiments that the new representations do better at sentiment and NLI. The authors must show that this captures the ""innate"" language learning abilities akin to human babies. While the paper aims to do some analysis in the discussion section, it is not unsatisfactory. As the paper says in the discussion section ""From a machine learning perspective, we’re interested in extracting informative features and not necessarily a completely grammatical language model. That being said it is of interest to what extent language models capture grammar and furthermore the extent to which models trained toward the universal grammar objective learn grammar.""\n\nThe problem is that simply comparing LM perplexities is not a solid test of whether this model has learned some form of universal grammar. First, this paper does not define a clear falsifiable hypothesis on the proof of learning universal grammar. One example of testing for learning grammar can be: does this model learn basic syntactic rules of a new language (e.g. as the authors suggested -- head-first or head-final syntax, or rules of conjugation)  with a small amount of data after being training a universal representation with n languages? There have been a series of recent papers on checking if Language Models have appropriately learned syntax. See e.g. Tal Linzen\'s work https://arxiv.org/pdf/1809.04179.pdf. Just to be clear I am not suggesting citing works in unpublished places but potentially using some of the tests suggested in these papers.\n\nIn conclusion, I think this work is useful but I also think it makes really grandiloquent claims without verifying them. That to me is a dangerous precedent.']","[70, -40, -30]","[80, 20, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses an overall positive view of the paper, describing the method as 'novel and nice' and the results as 'good'. They also mention that the paper is clearly written and could be useful for future research. However, it's not a perfect score due to some complaints and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They frame their concerns as questions or suggestions rather than harsh criticisms. The use of phrases like 'My main complaint' and 'Minor:' to introduce critiques is a polite way to structure feedback. The reviewer maintains a professional and constructive tone throughout the review."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects ('pros'), the majority of the review focuses on criticisms and areas for improvement ('cons'). The reviewer points out several issues with clarity, organization, and technical details, which outweigh the positive comments. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'a bit surprising to me' and 'It is not clear to me' rather than harsh language. The reviewer also balances criticism with positive feedback at the beginning. However, the directness of some criticisms prevents a higher politeness score."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is well-written and has convincing results, they express significant concerns about the paper's claims being too bold and unverified. The reviewer states that the paper 'makes the claims that go too far without evaluating them' and calls this a 'dangerous precedent'. However, it's not entirely negative as they do see value in the work, calling it 'useful'. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects of the paper and offering constructive criticism. They use phrases like 'The paper is overall well written' and 'I think this work is useful'. Even when expressing concerns, they do so in a professional manner, suggesting improvements rather than just criticizing. The tone remains academic and objective throughout, without resorting to personal attacks or overly harsh language.""]"
"['The proposed method is advantageous in that it only requires changes to some parts of the original ResNet or LSTM, without having to significantly change the network structure or training algorithm. It also reports empirical success of using high-precision skip connections in ResNet and cell/hidden state updates in LSTMs.\n\nHowever, it is unclear why it is necessary to keep a high-precision activation/gradient flow. What is the problem with existing quantized networks that do not have these high-precision-flow? Also, how does the high-precision flow interact with the rest of the network (with low-precision operations)?\n\nMoreover, the proposed method has limited novelty as the use of full-precision skip connections has been proposed in Bi-Real (Liu et al. 2018).\n\nMinor:\n- It is hard to tell that the weight histogram in Figure 3 is similar to a Laplacian distribution. It can also be approximated by other distributions (such as Gaussian or piecewise-linear distributions).\n- What kind of activation quantization is used?\n- In the experiments, when is the cosine similarity between the quantized and full-precision networks computed? after training or on an intermediate training step?\n- What are the axes in Figure 5? Why is there only one local minimum in Figure 5(d)? Why the training with PH converges even slower than without PH at the early stage of training?', 'This paper studies methods to improve the performance of quantized neural networks.  The paper is largely centered around the idea of ""precision highways"" (full-precision residual connections) that run in parallel to fully-quantized convolutions.  However, the paper also throws in a toolbox of other methods like distillation from a teacher network, a quantization method based on the Laplace distribution, and a fine tuning scheme.\n\nThe paper reports performance for the resulting networks that is impressive but still believable.   They also do very extensive experiments, including an ablation study in Table 1 that I really liked, and a study of how the precision of the skip connections impacts overall performance.   I also like the visualizations of how quantization impacts the loss surface.\n\nMy main concern about this paper is that is has conceptual overlap with other approaches.  The authors are not the first to quantize resnets, and other papers have looked at teacher training and distillation as a method of refinement.  The authors are fairly upfront about this though, and I think this paper is the first to do a really thorough investigation of the impacts of skip connections in their own right.    Realistically, fully binarizing neural nets without modification is unlikely to lead to good performance.  The idea of leaving the skip connections with higher precision is a good compromise that achieves hardware friendliness along with strong performance, so I think it\'s worth having a paper like this that takes a closer look at this approach.\n\nA few questions I had:\n1)  I can\'t tell exactly what methods are being used in Table 1.  When the ""highway"" box is unchecked, does this mean the skip connection is absent?  Or that it exists but with full precision?  Or maybe that the skip connection branched after the quantization instead of before?   Also, what fine-tuning methods is used when the ""teacher"" box is un-checked?\n\n2) You implemented your own version of Zhuang\'s method.  However, I\'d like to know how your numbers compare to the original reported numbers in Zhuang\'s paper.\n\nOne other minor criticism - When you fine-tune a modified network, the activations and weights will change.  It could be that the networks is modifying its parameters to account for (i.e., cancel out) the quantization errors.  For this reason I don\'t interpret Figure 4 as evidence for accumulation of error.  Perhaps this type of behavior would exists if you fine-tuned two full-precision networks using different random seeds, or different teacher networks.', 'This paper investigates the problem of neural network quantization. The main idea is to employ an end-to-end precision highway to reduce the accumulated quantization error and meanwhile enable ultra-low precision in deep neural networks.  The experimental results on the 3- and 2-bit quantizations of ResNet-18/50 and 2-bit quantization of an LSTM model demonstrate the effectiveness of the proposed method. \n\nThis paper is well written and organized. The idea of utilizing a high-precision information flow to reduce the accumulated quantization error is technically sound. The empirical studies on accumulated quantization error, loss surface analysis, model performance, and hardware cost are quite thorough and solid. \n\nThe idea of precision highway, however, is quite similar to the skip connections used in Bi-Real Net. Therefore, it may be a good idea to provide a thorough discussion over these two different methods so as to make the distinction.\n\nIn Table 2, the results of Bi-Real Net is based upon 1 bit activation/weight quantization, while the proposed method uses 2 bit activation/weight quantization. To give a fair comparison, it may be better to provide 1 bit activation/weight quantization results of the proposed method.']","[-20, 70, 80]","[50, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some advantages of the proposed method, they also express significant concerns and criticisms. The review starts positively but then raises several important questions and points out limitations, including a lack of novelty. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They raise criticisms and questions in a constructive manner, without using harsh or dismissive language. The reviewer also provides specific, helpful feedback in the 'Minor' section, which contributes to the politeness score."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, praising its 'impressive but still believable' results, 'extensive experiments', and the thoroughness of the investigation. They acknowledge the paper's value despite some conceptual overlap with other approaches. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions rather than direct criticisms. They also balance their critique with positive comments, showing appreciation for specific aspects of the paper like the ablation study and visualizations. The reviewer's tone is professional and courteous, offering suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written and organized' and the idea as 'technically sound'. The experimental results are described as 'thorough and solid'. The only criticism is minor, suggesting additional comparisons and discussions. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. Phrases like 'it may be a good idea' and 'it may be better' are used to politely suggest improvements, maintaining a courteous tone throughout the review.""]"
"['The paper attempts to examine the reasons behind the strong generalisation performance of DNNs trained via SGD. The authors propose an analysis which offers a fresh view to this problem. This view has been articulated very well, and is based on sound mathematical arguments. \n\nOn the other hand, since there is no formal theorem to support the introduced assumptions, the authors have attempted to provide empirical evidence through experiments with standard DNN architectures and benchmark datasets. However, this is where the weakness of this paper lies: The provided empirical evidence, while nicely executed, is not enough to convince the critical reader. We need experiments with more diverse datasets and experimental setups. \n\nAlthough I accept the claim of the authors concerning the lack of space, they could also trim the Introduction so as to free up some space, as well as provide an indefinite number of extra supporting evidence in the form of Supplementary Material/Appendices. \n\n\n', 'The paper analyzes the empirical spectral density of DNN layher matrices and compares them with the traditionally-regularized statistical models, and develop a theory to identify 5+1 phases of training based on it. The results with different batch sizes illustrate the Generalization Gap pheneomena, and explains it as being causes by implicit self-regularization.\n\nHowever, the paper seems a little bit handwavy to me, without any serious theoretical justification. For example, why are \\mu=2 and 4 chosen as the threshold between weakly/moderately/very heavy-tailed? In addition, the paper is build upon o the 5+1 model as in Figure 2 and the graphical comparison between the empirical ESD and the expected ESD of the five models in Table 1, and they lack any mathematical/rigorous definition---see table 2. The simulations are performs over a particular data set and a particular setting, and I wonder if the observations would be different for a different data set and a different setting. \n\nAs a result, it may give some important intuition, but the content is not sufficiently rigorous to my knowledge.\n', 'This manuscript studies the implicit regularization of neural networks from the perspective of random matrix theory. The authors provide both empirical and theoretical results that aim to show that the empirical spectral density of weights of DNN captures the implicit regularization phenomenon. However, the results are far from rigorous theory and it is not clear how recent results in MP theory yields the statements made in the paper. \n\n\nDetailed comments:\n\n1. The empirical studies seem interesting. It seems that two kinds of results are shown. The first one is that ESD fits perfectly for small models, and the second one is that deep models fit heavy-tailed random matrices class. It would be interesting to see more details about how these models are trained, as training greatly affects the value of the weights.\n\n2. Theoretical results are not clearly stated. In section 2, the authors introduce the basics of MP theory. However, it is not clear how to derive the theory in this paper based on the MP theory. It seems that the main theory is the ""5+1 phases of training"". The definition of these 6 phases is not even explicitly given in this paper. Moreover, the theory of all these phases seems to depend on equation (3) , but there are no lemmas or propositions that gives a rigourious theoretical guarantee.']","[20, -50, -50]","[60, 20, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's fresh perspective and sound mathematical arguments, but also points out significant weaknesses in the empirical evidence. The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and constraints while offering suggestions for improvement. The critique is presented in a professional and considerate manner, without harsh or rude language."", ""The sentiment score is -50 because the review starts with a positive note about the paper's analysis and results, but then expresses significant concerns about the lack of theoretical justification and rigor. The reviewer uses phrases like 'a little bit handwavy' and 'not sufficiently rigorous,' indicating a generally negative sentiment despite acknowledging some positive aspects. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'to my knowledge' and 'I wonder if,' which soften the criticism. However, the language is not overly polite or deferential, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is -50 because the review expresses significant concerns about the manuscript's theoretical rigor and clarity. The reviewer states that 'the results are far from rigorous theory' and that it's 'not clear how recent results in MP theory yields the statements made in the paper.' However, the score isn't lower because the reviewer acknowledges some positive aspects, such as 'interesting' empirical studies. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language like 'it would be interesting to see' and 'it is not clear how,' rather than harsh criticisms. The reviewer also offers constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score. However, the score isn't higher because the review doesn't include explicitly polite phrases or compliments beyond acknowledging the interesting empirical studies.""]"
"['The paper analyzes the strategy that a visual question answering model (FiLM) uses to verify statements containing the quantifier ""most"" (""most of the dots are red""). It finds that the model is sensitive to the ratio of objects that satisfy the predicate (that are red) to objects that do not; as the ratio decreases (e.g. 10 red dots compared to 9 blue dots), the model\'s performance decreases too. This is consistent with human behavior.\n\nStrengths:\n* The introduction lays out an ambitious program of comparing humans to deep neural networks.\n* The experimental results are interesting (although of modest scope) and support the hypothesis that the network is not counting the objects but rather is using an approximation that is sensitive to the ratio between the red and non-red items.\n\nWeaknesses:\n* The architecture of the particular model is described very briefly, and at multiple points there’s an implication that this is an investigation of “deep learning models” more generally, even though those models may vary widely. While the authors are using an existing model, they shouldn\'t assume that the reader has read the paper describing that model. I would like to see more discussion of whether it is at all plausible for this model to acquire the pairing strategy, compared to alternative VQA models (e.g., using relation networks).\n* I found it difficult to follow the theoretical motivation for performing the work. The goal seems to be to test whether the network is performing the task in way that ""if not human-like, at least is cognitively plausible"". I don\'t understand what is meant by cognitively plausible but not human-like; perhaps an example of a cognitively implausible mechanism would help clarify this issue. Later in the same paragraph, the authors argue that ""in the case of a human-centered domain like natural language, ultimately, some degree of comparability to human performance is indispensable"". This assertion is not justified, and seems surprising to me; we have very useful natural language processing systems that do not perform in a way that is comparable to humans (the hedge ""some degree of"" is really neither here nor there). In general, I don\'t understand why we would want a visual question answering system that returns approximate answers -- isn\'t it better to have it count exactly how many red dots there are compared to non-red dots?\n* The authors assume that explicit counting is not ""likely to be learned by the \'one-glance\' feed-forward-style neural network"" evaluated in the paper. What is this statement based on? Why would a ""one-glance"" network have trouble counting objects? (What is a “one-glance network”?)\n* Another vague concept that is used without clarification: it is argued that if the network implements something like the Approximate Number System, that shows that it can ""learn and utilize higher-level concepts than mere pattern matching"". What is ""pattern matching"" and how does it differ from ""higher-level concepts""?\n* Why would the pairing strategy in a neural network be affected by the clustering of the objects? I understand why a human who needs to saccade back and forth between the two groups of objects might lose track of the objects that have been paired so far, but I don\'t understand why that would affect the architecture in question.\n\nMinor comments:\n* Is the definition of ""most"" really a central piece of evidence for ""the apparent importance of a cardinality concept to human cognition""? Our ability to count seems sufficient to me. Perhaps I\'m not understanding what the authors have in mind here.\n* Please use the terms ""interpretation"" and ""verification"" consistently.\n* ""One over the other strategy"" -> ""one strategy over the other"".\n* The paper is almost 9 pages long, but the contribution does not appear more substantial than a standard 8-page submission.\n', 'Problem and contribution:\nThe paper studies if the Visual Question answering model “FILM” from Perez et al (2018) is able to decide if “most” of the objects have a certain attribute or color. \nFor this it tries to mimic the setup used to test human abilities in the study by Pietroski et al. (2009).\n\nThe main contribution of this is work is a discussion of how a model could solve the problem of deciding “most” and the study which shows that the studied model has some ability to do this. From this the paper concludes that the model is likely to have some approximate number system.\n\n\nStrengths:\n1.\tThe paper looks at a new angle to study and characterize CNN models in general, and VQA models in particular by looking into the psycholinguistic literature experimental setup studied with human subjects.\n2.\tThe paper studies different variants of controlling for different factors (e.g. pairing data points, area used, different training data and pre-trained vs. trained from scratch CNN models)\n3.\tIt is interesting to see that the models performance reasonably aligns with the curve predicted by “Weber’s law”.\n\n\nWeaknesses:\n4.\tNumber of objects vs. ratios is not disentangled: While the paper clarifies that not only a smaller number of objects are used, it would be interesting to understand if similar conclusions hold if only the same number or about the same number of total objects are used but the ratios change (at least for more extreme ratios, 1:2, this seems to be the case as they achieve 100% accuracy).\n5.\tThe paper only focusses on a single VQA model (FILM) which limits the understanding if this observation is specific to this model; what about other models such as the one from Hudson & Manning (2018), or Relation Networks (Santoro et al) or even simpler baselines: A system which two attention mechanisms (without normalizations) which are sum pooled and then compared would sort of explicitly encode the idea of the APN system. It would be valuable to compare them to see how different systems (can) solve this task. I would expect that the architecture favors certain capabilities; e.g. Relation Networks might lead more to a paring-based strategy. Or Zhang et al. (2018) might be able to exploit explicit counting to solve the task.\n6.\tThe “most” ability or APN ability seems to be highly related to accumulation in neural networks. The paper FiLM uses global max-pooling and I am wondering if this affect this ability. \n7.\tThe study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data. \n7.1.\tMaybe beyond the scope of this work, but it would be interesting to understand how much training data different models need to obtain this capability.\n8.\tFor evaluation: Are there distractors, i.e. elements which don’t belong to set A or B? If not, how would distractors affect it.\n9.\tClarity: \n9.1.\tThe equation between equation (1) and (2) misses a number [I will call it 1.5 for now]\n9.2.\tIn formula (1.5) “<=>” seems to be used at different levels (?) it would be good to use brackets to make clear which level “<=>” refers to.\n\nMinor:\n10.\tThe title suggests that the paper studies multiple VQA models but only a single model is studied.\n\nConclusion:\nThe paper looks into an interesting direction to study CNN models but has some limitations including studying only a single VQA model type, limited to artificially generated images. \n', 'This paper studies how the FiLM visual question answering (VQA) model answer questions involving the quantifier ‘most’. This quantifier is chosen for study because it cannot be expressed in first order logic (i.e., high-order logic is required), and secondly because there are two different algorithmic approaches to answering questions involving ‘most’ (cardinality-based strategy and pairing-based strategy). Experiments are performed by designing abstract visual scenes with controlled numerosity and spatial layouts, and applying methodologies from pyscholinguistics. The paper concludes that the model learns an approximate number system (ANS), consistent with the cardinality-based strategy, with implications for understanding the conditions under which existing VQA models should perform well or badly (and possibly for improving VQA models). \n\nStrengths:\n- The research question is clear and well-conceived. In general, it seems there are significant opportunities for better collaboration between the experimental psychology and machine learning communities, and this is a good example of the benefits.\n- The paper is clear, highly-focused, and well-written.\n\nWeaknesses:\n- The arguments for why the experimental evidence actually supports the existance of an approximate number system (ANS) could be made more clear. For example, the section on “Ratios andWeber fraction” argues that “these curves align well with the trend predicted by Weber’s law”, but does not explain how the experimental data would present if the alternative hypothesis (pairing-based strategy) was being used. What would the pairing-based strategy look like in Figure 6 right? Are there not significance tests that could be used to more carefully quantify the level of support for the two alternative strategies?\n- The experiments seem very similar to Wu et al. 2018, which is considered to be prior work under the ICLR guidelines. While this paper is acknowledged in the related work, it would be helpful to expand further on the relationship between these works, so the originality and contribution of this paper can be better evaluated.\n- In some ways it is not that surprising that the CNN more easily learns an approximate number system rather than a pairing-based algorithm, as the later would presumably need to learn a different convolutional filter for every possible spatial arrangement of the pairs (which would be very sample inefficient). Therefore, it might be interesting to consider, are there any circumstances under which the CNN would learn a pairing based algorithm? For example, what if the spatial configuration of the pairs was simplified, so they were always side-by-side at a fixed distance? If pairing-based algorithms emerged under simplified scenarios, this might have implications for the design of CNN filters (if we want models that are capable of learning these types of functions).\n\nSummary:\nI regard this as a good paper, with a couple of weakness that could be addressed as indicated.']","[-30, 20, 60]","[50, 80, 80]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they list several significant weaknesses and express confusion about key concepts, indicating an overall negative sentiment. However, it's not extremely negative as they do recognize some positive aspects. The politeness score is 50 because the reviewer uses professional and respectful language throughout, framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I would like to see' and 'I found it difficult to follow' which are polite ways of expressing concerns. The review maintains a constructive tone, even when pointing out weaknesses, which contributes to its politeness."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper and finds the research direction interesting, despite pointing out some weaknesses. The review begins by highlighting the paper's contributions and lists three specific strengths before moving on to weaknesses. The conclusion also notes that the paper 'looks into an interesting direction'. However, the presence of multiple weaknesses and limitations prevents a higher positive score. The politeness score is high (80) because the reviewer uses professional and respectful language throughout. They present criticisms as 'weaknesses' rather than flaws, and use phrases like 'it would be interesting' or 'it would be valuable' when suggesting improvements. The reviewer also balances positive and negative feedback, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer describes it as a 'good paper' and highlights several strengths, including a clear research question and well-written content. However, they also point out some weaknesses, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively as suggestions for improvement, and acknowledges the paper's strengths before discussing weaknesses. The reviewer maintains a professional and courteous tone, using phrases like 'it would be helpful' and 'it might be interesting to consider' when suggesting changes.""]"
"['This work presents a method to translate non-systematic names of chemical compounds into their systematic equivalents. Beyond that, a corpus of systematic and non-systematic chemical names is introduced that were extracted from chemistry and manually labelled.\n\nThe paper is well-structured and the authors introduce the problem setting very nicely to a machine learning audience, explain the challenges and motivate the architecture of their model. The model is a combination of tested approaches such as a spelling error correction, a byte pair encoding tokenizer and a sequence-to-sequence model consisting of (Bi)LSTMs and attention mechanisms. \n\nThe evaluation appears solid. The model achieves significantly improved results on the proposed corpus, even though compared to a underwhelming baseline. The analysis could be improved by showing and explaining some examples of failed translation attempts. It would also be interesting to see how the failed attempts are distributed over the error types (spelling, order, common name, synonym). The authors suggest a scenario where non-systematic names are converted and checked against a database of systematic names. For this, it would be interesting to know whether there are cases where a non-systematic name was translated into the wrong (but valid) systematic name.\n\nConcluding, the paper presents an interesting application for machine translation, a new dataset and a method that successfully labels 50% of the given corpus.\n\nMinor issue: The color scale of Fig. 5 is hard to recognize due to low contrast.', 'Pros: This seems like very competent and important work in an under-served area: Doing the mapping (or ""entity linking"") of chemical names to their standardized systematic forms. It\'s not my area, but I was frankly surprised when the paper said there was only one relevant prior piece of work, but having searched for a few minutes on Google Scholar, I\'m at least inclined to believe that the authors are (approximately) right on that one. (This stands in stark contradistinction to the large quantity of biomedical entity recognition and linking work.) So, it\'s valuable to have work in this area, and the approach and application are sensible. In one sense, this gives the work significance and originality (as to domain). The paper is also clearly written, and certainly sufficiently accessible to an ML reader.\n\nCons: Unfortunately, though, I just don\'t think this qualifies for acceptance at ICLR. It\'s application of known techniques, and lacks any ML novelty or sufficient ML interest. It would only be appropriate for an ""ML applications"" track, which ICLR does not have. And while its performance is _way_ better than that of the only previous work on the topic that they know, accuracy of mapping non-systematic chemical terms (54.04%) is still low enough that this technique doesn\'t seem ready for prime time. \n\nOther comments: In table 5, you show that a prior pipeline stage of spelling correction is definitely useful in your system (table 5). And yet, given the power of deep learning seq2seq transductions, and the potential to use them for spelling correction, one might wonder whether this prior step of spelling correction is really necessary. It might be interesting to explore further where it helps and whether the gains of spelling correction might be obtainable in other ways such as using data augmentation (such as spelling error insertion) in the seq2seq training data. The Golebiewski bib entry is lacking any information as to where it is published, which seems especially bad for the key citation to prior work of the whole paper. In general, the bibliography has issues: non-ASCII characters have been lost (you either need to LaTeX-escape them or to load a package like utf8, and capitalization of acronyms, etc. should be improved with curly braces.', 'Name standardization is an important problem in Chemical Information Extraction. In the chemical literature, the same chemical could be referred to by many different names. This work focusses on standardizing non systematic names (for example Asprin to 2-Acetoxybenzoic acid). \n\nThe authors approach this as a machine translation problem. They create a parallel corpus of non-systematic and systematic names and build a seq2seq model for accomplishing this task. The authors report accuracy and BLEU score for the translation task.\n\nMy main concern with this work is novelty. It seems like this is a straightforward application of an existing model for this task. Also it is not clear why BLEU score is an appropriate metric for this task. Is it okay for downstream applications to have the systematic name partially right?\n\nOverall, I think this paper does not present substantially new ideas to merit publication.']","[70, -20, -70]","[80, 60, 20]","[""The sentiment score is 70 (positive) because the reviewer generally praises the paper, describing it as 'well-structured' with a 'nicely' introduced problem setting. They commend the model's 'significantly improved results' and call it an 'interesting application'. However, it's not 100 as they suggest some improvements and mention a 'minor issue'. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They use phrases like 'could be improved' and 'it would be interesting' when suggesting changes, which maintains a polite tone. The overall language is professional and courteous, without any rude or dismissive comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance and competence of the work, they ultimately recommend rejection for ICLR due to lack of ML novelty and insufficient accuracy. The politeness score is moderately positive (60) as the reviewer uses respectful language, acknowledges the paper's strengths, and provides constructive feedback. They use phrases like 'very competent and important work' and 'clearly written', while softening criticisms with phrases like 'Unfortunately, though' and offering suggestions for improvement. The reviewer maintains a professional tone throughout, balancing praise with constructive criticism."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the novelty of the work and concludes that the paper does not merit publication. The phrases 'My main concern' and 'does not present substantially new ideas' indicate a negative sentiment. However, it's not entirely negative as the reviewer acknowledges the importance of the problem and describes the authors' approach objectively. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They avoid harsh or personal criticisms, instead focusing on the work itself. The use of phrases like 'It seems like' and 'I think' softens the criticism, making it more polite than a blunt rejection.""]"
"['This paper has proposed a new algorithm for semi-supervised learning, which incorporate biased negative data into the existing PU learning framework.\n\nThe paper was written in clarity and easy to follow overall. However, the original motivation for having biased negative data are not explained very clear. The relation to dataset shift was very interesting, but it’s unclear what’s the exact connection between the proposed algorithm and the dataset shift. Maybe the authors can elaborate a little more on their point here in the future revision.\n\nThe paper has made some assumption about the relation between the latent random variable and the label in section 2.4. In the experiment, data sets are generated following the exact assumption. That’s not surprising to see that the proposed algorithm that fits the assumption will perform better than the previous methods without this assumption. In practice, there’s no way to really verify this assumption. Thus, it’s more interesting to see how the algorithm performs under the more generic semi-supervised learning setting, with unbiased, or biased negatives that don’t really fit the exact assumption in this paper.\n\nMoreover, I’d like to see more intuition on why adding biased negative data will further improve upon nnPNU. The author provided some explanation in section 4.3, which seems just observations on the FPR and FNR, rather than the fundamental explanation for the advantage of this algorithm.\n\nChoice of baseline methods is also limited. The original paper [1] for PNU has included a bunch of benchmark algorithms for semi-supervised learning. The authors should also include more benchmark algorithms for comparison, e.g. those listed in Section 5.2 in [1].\n\n[1] Sakai, Tomoya, et al. ""Semi-supervised classification based on classification from positive and unlabeled data."" arXiv preprint arXiv:1605.06955 (2016).', 'This paper studied classification problem, with Positive, Unlabeled and biased Negative labeled data. The paper presents a two-step method, where the first-step is instance weighting and the second-step is standard binary classification. The paper shows theoretical proofs on the error estimation. Experiments on several well-known data sets are conducted and compared. \n\nThe good things of the paper are clear. \n\n1.\tTechnical sound with statistical foundation\n2.\tTheoretical foundation\n3.\tProblem is general\n4.\tPaper is general well written.\n\nSome weak points as well\n1.\tApplication value is not so big, as there is no real application problem and the experiments are based on simulation.\n2.\tAlthough the studied problem is reasonable, the setup is a bit too general and need rather strict condition to have a good method. \n', 'The authors \x0crst present standard binary (positive negative or PN) classi\x0cca-\ntion, followed by positive unlabeled (PU) classi\x0ccation, that they motivate with\nexamples, such as one-class remote sensing classi\x0ccation. The new setting that\nthey introduce and study is called positive unlabeled biaised negative (PUbN\nclassi\x0ccation) and adds a biaised negative sample to PU learning. They give\nmotivating examples and compare this setting to the existing literature. A con-\nvincing case is made regarding the di\x0berence between the PUbN problem and\nthe known problems of semi-supervised learning and dataset shift.\nThey start by recalling the notations and nature of standard binary classi\x0c-\ncation, PU classi\x0ccation and the nnPU (non-negative PU) strategy, as in the\nprevious PU learning papers. Then, they present the semi-supervised setting\nunder the name PNU learning, which simply studies the minimization of a con-\nvex combination of the PN risk and the PU risk. As in PU learning, a correction\nexists to avoid considering the estimate of the negative risk to be negative, re-\nferred to as nnPNU.\nFinally, the authors introduce PUbN learning as the problem in which we\nonly have access to negatives that follow the law p(x\\mid y = -1; s = +1), where s\nis a latent variable that formalizes the bias.\nAs in PU learning, the authors derive an unbiased estimator of the risk that\ninvolves only distributions for which data is available. However, they need\nto reweight the P and bN distribution by the unknown posterior probability\n\x1bsigma(x) = p(s = +1\\mid x) of s. Considering s as the label, the problem of learning\na probabilistic classi\x0cer separating the elements for which s = +1 and s = \U001000001\ncan be seen as a PU learning problem, which gives an estimator ^\x1b of sigma,\nand makes the method practical.\nThey derive estimation error bounds, that depend on the mean squared\ndi\x0bfference between \x1bsigma and sigma^\x1b and a term of order n^-1/2 where n is the cardinal\nof the smallest sample. They considered the function ^\x1b as a \x0cxed function in\ntheir bounds, which implies that the bounds are only true if some of the data is\nkept for the estimation of sigma^\x1b. Finally, they present a variant of their algorithm\nfor PU learning, named PUbNnN where unlabeled instances are not all given\nthe same weight, but weighted according to sigma hat\x1b. The experiments use neural networks with stochastic optimization, on the classic datasets MNIST, CIFAR-10 and 20 Newsgroup. They report better per-\nformance using their technique on all datasets. The authors documented their\nexperiences thoroughly in the appendix. However, I did not \x0cfind information\nabout the nature of the estimator of the posterior probability sigma^\x1b, which is im-\nportant for reproducibility. Furthermore, in appendix B, choosing sigma^\x1b = 0 will\nminimize the criterion . Finally, they proceed to justify the dominance of\nthe variant of their method over usual nnPU learning.']","[-20, 50, 70]","[60, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clarity', 'easy to follow'), they raise several concerns and suggest multiple improvements. The overall tone indicates that significant revisions are needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'Maybe the authors can elaborate' and 'I'd like to see' which are polite ways of suggesting improvements. The reviewer also balances critique with positive comments, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting several 'good things' about the paper, including its technical soundness, theoretical foundation, and general writing quality. However, this is balanced by the mention of 'weak points', suggesting a mixed but overall positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout, acknowledges the paper's strengths before mentioning weaknesses, and frames criticisms as 'weak points' rather than using harsh or dismissive language. The reviewer maintains a respectful tone while providing constructive feedback."", ""The sentiment score is 70 (positive) because the reviewer presents the authors' work in a favorable light, using phrases like 'convincing case is made' and noting that the authors' technique reported 'better performance' on all datasets. The review thoroughly describes the authors' methodology and contributions without significant criticism. The politeness score is 80 (quite polite) as the reviewer uses respectful and professional language throughout, acknowledging the authors' efforts and thoroughness. The reviewer does offer some constructive feedback at the end, but does so in a polite manner, using phrases like 'I did not find information about' rather than more critical language. The overall tone is academic and courteous, focusing on the content rather than making personal judgments.""]"
"['In this paper, the authors try to interpret the prediction mechanism of Layered Neural Networks (LNNs). The authors proposed to first define a feature vector that represents the roles of each hidden layer unit, via computing Pearson correlation coefficient. Then a hierarchical clustering method is applied to the generated feature vectors, such that tree-structured relationships among hidden layer units are revealed.\n\nThe purpose of the paper is to understand the prediction mechanism of Layered Neural Networks (LNNs). But based on the results in the experiments, I do not think the model achieves this purpose. Given the tree structure of LNN for the MNIST data set, I am still not able to understand how this LNN distinguishes the digit 0 from other digits. I am also not able to understand why a particular sample is classified as 0 rather than 6.\n\nIn Section 1, the authors mension that there are existing clustering-based methods that interpret LNN. The authors do not compare the proposed methods with these existing methods, either quantitatively or qualitatively. So I am also not sure the contribution of this paper, provided the existing methods.\n\nIn Section 3.1, the authors state that ""there is no method that can reveal whether an increase in the input dimension value has a positive or negative effect on the output value of a hidden layer unit"". I do not agree with this statement, because Ross et.al (2017) has proposed to measure it via gradient, although they are trying to solve a slightly different problem. Since the output of a hidden unit is a non-linear function of the input, I am not convinced that the proposed method that computes Pearson correlation coefficient is better choise than computing the gradient.\n\nThe proposed method provides a tree structure to describe the relationships between the hidden layer units. The authors also do not illustrate why learning the tree structure is particularly important. We can also run k-means with cosine similarity on the generated vector $v$, and learn the number of clusters via Bayesian information criterion (BIC). The authors do not explain why the tree-structured clustering results are more superior than the k-means clustering results.\n\nIn summary, I recommend rejection of this paper, because 1) I do not think the proposed method achieve its purpose; 2) It is not appropriately compared with existing methods; and 3) I am not convinced that the method is designed properly.\n\n\nReferences\nRoss, Andrew Slavin, Michael C. Hughes, and Finale Doshi-Velez. ""Right for the right reasons: training differentiable models by constraining their explanations."" Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI). 2017.', 'Pros\n\n1.\tThe paper is fairly clear.\n2.\tThe problem is important: analyzing the internal computations of layered networks.\n3.\tThe method seems to be a slight improvement on an existing method: the use of hierarchical clustering is nice.\n4.\tFigs. 3 and 5 superimposing the analyzed clusters on top of the network diagram are cool.\n\nCons\n\n5.\tThe paper wastes valuable space writing out in detail the equations for backpropagation in a standard feed-forward MLP.\n6.\tThe paper does not have an acceptable review of relevant prior work. This is particularly problematic as the proposal seems to be a rather small tweak to prior work of two 2018 papers by Watanabe et al. But there is extensive other literature attempting to address this problem, especially in the vision domain, where their main example - poor over-worked MNIST - resides.\n7.\tIn my view, attempts to understand processing in NNs exclusively at the individual-unit level are essentially doomed at the outset. These networks crucially represent their information in distributed representations and it is joint action by multiple units rather than action by individual units that drives processing. Consider the “effect” variable analyzed in this paper, which is a simple correlation between the activity of a target hidden unit and the activity of a particular input or output unit. Suppose whenever hidden unit i is active, hidden unit j is also active, and vice versa. Now suppose j strongly drives output unit k via a connection with a large weight, while unit i has no connection at all to unit k. Then i will have a strong “effect” on k! The correlations between the activity of i and k is the same as the correlation between j and k, even though the causal interaction between i and k is nil, while the causal interaction between j and k is strong. In this especially transparent situation, it is the joint action of i and j that matters, and it so happens that this joint action has no contribution from i.\n8.\tSo in addition to the problems arising from analyzing exclusively at the individual-unit level, there is the problem of defining “effect” by correlation instead of causation.\n9.\tI don’t myself gain any insight into how the MNIST network is working by looking at the clusters diagrammed in Fig. 4. There is no discussion of the fact that nearly all of their input-“effect” maps look like a slanted oval which is either on-center-off-surround or the reverse (no comment on the superficial, at least, connection to the receptive fields of neurons in the early mammalian visual system). Just how do these cluster maps explain anything? \n10.\tThe maps for the other example, time-series of prices of root vegetables, are even more baffling, but, superficially at least, the input maps suggest the hidden units are doing Fourier analysis; even this obvious observation is not made in the paper, however.\n', ""Sorry, I am not convinced by this paper.\n\nI just don't believe that one can really gain any useful insight into neural networks by this kind of visualization.  In my opinion, all these kinds of visualization can give is the false believe that one understands what the network is doing.  (If you think about it, understanding itself is a rather vague and subjective term).  I guess my point is, these kinds of visualization don't seem to generate any actionable knowledge.  And how would one even meaningfully compare the outputs of competing methods of this general type?\n\n""]","[-80, -50, -80]","[20, 20, -20]","[""The sentiment score is -80 because the reviewer recommends rejection and provides several critical points about the paper's shortcomings. The review highlights that the proposed method doesn't achieve its purpose, lacks comparison with existing methods, and has questionable design choices. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I do not think' and 'I am not convinced' rather than harsh language. The reviewer also provides specific reasons for their recommendation and cites relevant literature, which adds to the constructive nature of the feedback despite its overall negative sentiment."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (clarity, importance of the problem, slight improvement on existing methods), the majority of the review focuses on significant criticisms. These include wasted space, lack of proper literature review, fundamental issues with the approach, and lack of insight gained from the results. The politeness score is 20 because the reviewer uses relatively neutral language and starts with positive points, but doesn't use overtly polite phrasing. The criticism is direct but not rude, maintaining a professional tone throughout."", ""The sentiment score is -80 because the reviewer expresses strong skepticism and disagreement with the paper's approach. They state they are 'not convinced' and 'don't believe' in the usefulness of the method, indicating a highly negative sentiment. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'I just don't believe' and 'false believe' come across as somewhat impolite in an academic context. The reviewer doesn't offer constructive criticism or soften their language, which contributes to the slightly negative politeness score.""]"
"['General comment\n==============\nThe authors describe an attention mechanism for training with images of different sizes. The paper is hard to understand due to major grammatical errors and unclear descriptions. Methods for training with images of different sizes have been proposed before, e.g. spatial pyramid networks. I also have concerns about their evaluation. Overall, I believe that the paper is not ready to be submitted to a conference or journal.\n\nMajor comments\n=============\n1. Methods for training with images already exists, e.g. spatial pyramid pooling (http://arxiv.org/abs/1406.4729) or fully-convolutional networks (https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf). These are not cited in the paper and not included as baselines in their evaluation.\n\n2. The attention mechanisms looks similar to classificat soft-attention (https://arxiv.org/abs/1502.), which is not cited in the paper.\n\n3. The paper contains major spelling and grammatical errors, making it hard to understand important aspects.\n\n4. I can not see a clear improvement of their method over ResNet and DenseNet when the same number of model parameters is about the same. Without making sure that the number of model parameters is about the same, it is unclear if the performance gain is due the increased number of model parameters or the methodology.', 'I was excited about the title and abstract but my expectation started to fall as I parsed through the main text. Here are some of my major concerns:\n\n1. The entire text is plagued by syntax errors that sometimes inhibit the narrative and prevent the proper understanding.\n\n2. Section 3 explains the architecture clearly, but fails to justify, perhaps in theory or at least in intuition, why AIN could have any advantage with such a distinct choice of parameterization. Nor can I find any solid evidence from the experiments that this is indeed the case. \n\n3. Section 4 seems ad-hoc, simply presenting tables without ablation study makes it hard to trust the proposed architecture.\n', ""This paper presents a strategy to overcome the limitation of fixed input image sizes in CNN classifiers. To this end, the authors incorporate some local and local attention modules, which fit inputs of arbitrary size to the fixed-size fully connected layer of a  CNN. The method is evaluated on three public classification benchmarks: CIFAR-10, ImageNet and Kaggle-Furniture128. \n\nThe results are better than those of the baseline architecture with fixed input size.\n\nEven though the need of handling arbitrary input size is an interesting problem, I have several major concerns about this paper:\n\n- One of the main problems of this paper is its presentation, both the writing and methodology. The writing is very poor, with continuous errors and many wrong definitions and concepts. For example, authors talk about ‘data argumentation’, ‘pooling reduces the size of the hidden layers’,’back-to-back convolutional layers’\n\nFurther, the paper is not well structured, which makes it very hard to follow.\n\nMethodology:\n\nAnother major concern is that I do not see how this approach allows the network to be input-size independent. If one looks at table 1, in both AIN-121 and AIN-169 the GAIL module employs kernel sizes equal to M/32xN/32, with M and N denoting the input image sizes. In this case, for each image, the kernel size will be different and, consequently, the number of learnable parameters. It is not clear to me how this is solved in this paper, as it ultimately results in a ‘different’ architecture for each different input size.\n\nWhen doing the sum on the proposed module, what does the result represent? absolute sum? mean of the sum? I also believe that a lot of information is lost when performing this operation (for example going from 32 to 1), in addition of the other spatial reductions during the network forward pass. Please comment on this and give a more detailed information about the proposed module.\n\nEvaluation: \nIn CIFAR-10, authors say that ‘keep MOST of the setting similar to ResNet’. What is then difference with the training with ResNet? For a fair comparison both settings should remain the same. In addition, what is the benefit of evaluating this approach on CIFAR-10, as the images are all of the same size? Furthermore, improvement is marginal with respect to the baselines (and it is not clear what is the reason behind the improvement), while increasing the model complexity by nearly 50%.\n\nKaggle-Furniture128: Why the learning is stopped exactly at epochs 38 and 53? Is this the same for all the networks? DenseNet and ResNet are pre-trained with what dataset?\n\nImageNet: In table 4, while the results for the baselines are evaluated on the validation set, the test set is used for evaluating the proposed approach. Furthermore, some results on the test set are obtained with ‘augmentations’. The reported values should correspond to the original test set without any kind of modification.\n\nMinor comments:\n\nThe authors assess the input fixed-size problem as a main problem in image processing. Despite being a limitation, some other image processing tasks, such as semantic segmentation, do not suffer from this problem, as CNNs are fully convolutional, and can accommodate images of arbitrary size.\n\nMany inconsistencies between terms: LAIL and then LAIN and GAIL and GAIN.'""]","[-80, -60, -70]","[-20, 20, -20]","[""The sentiment score is -80 because the review is predominantly negative. The reviewer states that the paper is 'hard to understand', has 'major grammatical errors', and is 'not ready to be submitted'. They express concerns about the evaluation and lack of citation of existing methods. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism. The reviewer does not use polite phrases or acknowledge any positive aspects of the work. However, they do provide specific recommendations for improvement, which prevents the score from being lower."", ""The sentiment score is -60 because the review starts with initial excitement but quickly shifts to disappointment and lists several major concerns. The reviewer uses phrases like 'my expectation started to fall' and 'plagued by syntax errors,' indicating a negative sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects, like the clear explanation in Section 3. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'Here are some of my major concerns' instead of more aggressive language. The reviewer also provides specific, constructive feedback rather than blanket criticism. However, the politeness is not extremely high as the language is quite direct and doesn't include many softening phrases or positive reinforcement."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses 'several major concerns' about the paper, including poor writing, wrong definitions, unclear methodology, and questionable evaluation practices. While there is a brief positive mention of the results being better than the baseline, this is overshadowed by the numerous criticisms. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and direct. Phrases like 'The writing is very poor' and 'Another major concern' come across as harsh. The reviewer doesn't soften criticisms with polite language or positive reinforcement, which contributes to the slightly negative politeness score.""]"
"['The focus of this paper is to show that finite-width deep neural networks with fully connected layers and ReLU activations are rate-distortion optimal approximators of certain classes of functions, meaning the approximation error decays exponentially in the number of neurons in the network. The function classes explored in this paper are: 1-d polynomials (on bounded intervals), 1-d sinusoidal functions (on bounded intervals), and other 1-d functions built from compositions or linear combinations of these, such as the so-called class of “oscillatory textures” and a class of continuous but nowhere differentiable functions known as Weierstrass functions. Finally, the paper also shows that as the desired approximation accuracy goes to zero finite-width deep ReLU networks require asymptotically fewer neurons than finite-depth wide ReLU networks in approximating a broad class of smooth functions.\n\n\nThe paper is well-written and the technical results are presented in a way that is easy to understand. The results are somewhat novel, although they do build off other recent works, namely Yarotsky (2016) and Telgarsky (2015). However, the authors were careful to cite when they reuse proof techniques from these and other works. The results in the main text appear to be technically sound. I did not check carefully all the proofs in the supplemental materials.\n\n\nMy major criticism is that the focus on certain specific function classes (oscillatory textures, Weierstrauss functions) seems arbitrary, and leaves open many questions. For example, there is existing work on the approximation ability of deep ReLU networks for functions in more general Holder and Sobolev spaces:\n\nHadrien Montanelli and Qiang Du. Deep ReLU networks lessen the curse of dimensionality. arXiv preprint arXiv:1712.08688, 2017.\n\nJ. Schmidt-Hieber. Nonparametric regression using deep neural networks with ReLU activation function. ArXiv e-prints, August 2017.\n\nI was left wondering how the present results relate to these works, and what insight we get from understanding these particular function classes that we don\'t get from understanding Holder or Sobolev spaces.\n\n\nMajor comments\n\n\nIn Section 3, I found the progression of the results from approximation of x^2, to multiplication xy, and to general smooth functions to be very natural and well-motivated. However, sections 4 and 5 seem lack somewhat in motivation, since here the authors focus on very specific function classes (sinusoidal functions, oscillatory textures, and Weierstrass functions). While these results are still interesting, focusing on such specific functions is less satisfactory, since it raises questions about the true scope of the results (e.g., will similar approximation rates extend to other fractal functions, or just Weierstrauss functions?). Could the authors give further justification for why these function classes are interesting to focus on, or why they limit themselves in this way? Can the authors also put these results more into context with existing results on the approximation with ReLU networks?\n\n\nThe authors state multiple times that “all our results apply to the multivariate case” but that they restrict themselves to the univariate case for simplicity of presentation. While this is fine, some indication of how the results are altered in the multivariate case would be useful. For example, does the fixed-width M in multivariate generalizations of Prop 3.1--3.3 need to be bigger, smaller, or the same? What other constants are dimensionally dependent? Do the multivariate generalization of their results bear the ""curse of dimensionality"", i.e., does the number of neurons needed to reach epsilon accuracy depend geometrically on the dimension?\n\nMinor comments\n\n\nA conclusion or discussion section summarizing the overall technical contribution would be useful for the reader. Also, it would be useful to include some discussion on remaining open problems or future work.\n\nOn pg. 2, the authors state “the approximation results throughout the paper guarantee that the magnitude of the weights in the network does not grow faster than polynomially in the cardinality of of the domain over which the approximation takes place”. What does “cardinality of the domain” here mean? I think the authors mean the size D of the interval [-D,D] over which the approximation is valid.\n\nOn pg. 7, the authors say “We note that this result allows to show that local cosine bases (cite) can be approximated by deep ReLU networks with exponential error decay…”. I think the authors mean to say “...this result allows us to show…” or “this result allows one to show…”. Although it’s not clear to me whether this means it has been shown (it’s a direct corollary), or could possible be shown (it’s a corollary, but needs some non-trivial work). Also, one line to specify what a “local cosine basis” is would be helpful.', 'This paper describes results regarding approximations of certain function families using ReLU neural networks. The authors emphasize two points about these networks: finite width and depth that is logarithmic in the approximation error parameter $\\epsilon$. \n\nThe first result concerns approximation of polynomials, which is used as a building block for all subsequent results. This result itself is quite simple and mostly follows from simple observations or known results, though it is possible that these have not been explicitly written in this form anywhere. The other results concern smooth functions, and some kinds of non-smooth functions such as the Weirstrass function. There are two neat observations (i) using the sawtooth function to approximate sinusoidal ones and (ii) using overlapping ""approximation"" to simulate an indicator. \n\nThe paper is refreshingly well-written and pleasant to read. Most of the results are tailored to work for either periodic functions, or can be expressed as: if piecewise polynomials are a good approximation, then so are constant depth neural networks with ReLU. I\'m not sure that ICLR is the best venue for these kinds of results, as any connection with learning is at best tenuous, and the kind of approximation results don\'t seem to have any direct bearing on machine learning.', 'A main theme of the paper is showing that constant-width ReLU networks with depth increasing ploy-logarithmically in 1/\\eps can achieve the desired accuracy over the classes considered. \n\n- It seems to me that a major claim of the paper is that previous results did not have constant-width approximations. \n\nHowever, this does not seem accurate to me. For example, for polynomials, the statement “the width of the approximating network does not grow with the degree of the polynomial as is the case in Yarotsky (2016)...” does not seem true. The constructions in Yarotsky (2016) which much of the present work appears to be based on, in fact, allow for a constant-width approximation of polynomials of degree “n” in “d”-variables, over the cube, with \n\nwdith = 9, and depth ~ m \\log m [\\log (1/\\eps) + \\log m] where m = n + d. (*)\n\nThis bound is quite similar to Prop. 3.3 (with maybe even sharper dependence on “m”: m(\\log m)^2 versus m^2 in the paper. PS. I would also  double-check C in Prop. 3.3 which could be growing logarithmically in m.)\n\n(*) can be seen by inspecting the arguments around (14)-(15) in Yarotsky (2016) and noting that c_1 ~ \\log m in that argument. For example, considering d=1 which is the focus of the present paper, Yarotsky (2016) shows a constant-width approximation to the product function (x,y) \\mapsto xy which can be used to build a constant width-approximation to the monomial of the highest degree in the polynomial by recursive composition. All other monomials can be accessed serially at various depths of that architecture.\n\n- Much of the subsequent results in the paper are based on this constant-width approximation of polynomials as the authors point out. This is not that surprising given the Taylor approximation. For example, in Theorem 4.1, the first few lines of the proof show that the cosine can be approximated with a polynomial of degree m = O(\\log (1/\\eps)). Combining this with the polynomial approximation result one gets a constant-width approximation with \ndepth ~ \\log(1/\\eps)^2 or \\log(1\\eps)^2 \\log \\log (1/\\eps) \ndepending which version of the polynomial approximation result one believes (m \\log m versus m as the prefactor as discussed above).  In other words, it appears to me that the proof of Theorem 4.1 can be shortened considerably. It would be a corollary of the polynomial approximation. \n\n- A novelty of the present work over Yarotsky (2016) that the authors point out is avoiding skip connections in Proposition 3.1. (Perhaps this is true also for Prop. 3.3? Not discussed.) I haven’t checked the details here, but assuming correctness, I agree that it is quite interesting. I am not sure however if it is a significant improvement over the existing results.\n\n- The discussion of Section 5 and 6 might be new in this context and somewhat interesting. However, at least that of Section 5 again seems to be a natural byproduct the polynomial approximation result.\n\n- I would like to point out that there are other results on finite-width approximation by ReLU networks, establishing some quite sharp bounds, for example,\nHanin and Sellke 2017: arXiv:1710.11278\nYarotsky 2018: arXiv:1802.03620\nIn light of these, it wouldn’t be that accurate to claim that the issue of constant-width approximation is considered for the first time in the present paper.']","[50, 50, -50]","[80, 80, 20]","[""The sentiment score is 50 (moderately positive) because the reviewer begins by praising the paper as 'well-written' and the results as 'somewhat novel' and 'technically sound'. However, they also express a 'major criticism' about the focus on specific function classes, which tempers the overall positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than direct criticisms. They use phrases like 'Could the authors give further justification' and 'some indication... would be useful', which are polite ways of requesting improvements. The reviewer also acknowledges the authors' work and cites relevant literature, showing respect for the authors' efforts and the broader scientific context."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being 'refreshingly well-written and pleasant to read' and having 'neat observations'. However, they also express some reservations about the venue's suitability and the direct relevance to machine learning. The politeness score is 80 (quite polite) due to the reviewer's use of positive language like 'refreshingly well-written' and 'pleasant to read'. They also present their criticisms in a constructive manner, without using harsh or dismissive language. The reviewer maintains a professional and respectful tone throughout, even when expressing doubts about the paper's suitability for the venue."", ""The sentiment score is -50 because the reviewer expresses significant doubts about the novelty and accuracy of the paper's claims. They point out several instances where the paper's assertions seem to be inaccurate or already covered by existing literature. The reviewer does acknowledge some potentially interesting aspects, but overall the tone is critical. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'It seems to me' and 'I would like to point out' which soften the criticism. The reviewer also gives credit where due, noting some aspects as 'quite interesting'. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a mostly neutral, academic tone.""]"
"['This paper presents the following main insight (quoting the authors): Resnets classify input patterns based on the sum of the transient dynamics of the residuals in different layers.\nThe authors formulate this insight mathematically, and experimentally demonstrate its validity on a toy binary classification problem. They also show that the behaviour of a Residual network trained on MNIST is in line with the claims. Finally, a method to adapt the depth of a Residual network during training is proposed and applied to the toy classification problem.\n\nThe paper is generally of good quality and easy to understand. My only complaint: the introduction (including related work) is too long and I think it will be unclear to a general reader before reading section 2, where the terms used in the paper are explained and clarified. I think it will be an improvement to leave out detailed discussion of related work for a separate section, and focus on clarifying what the paper is about.\n\nOverall, while the paper is related to an interesting and potentially fruitful perspective of neural networks (as dynamical systems), in my view the contributions are not significant at this stage. That the sum of transients determines network outputs is almost by design, and can be shown without a dynamical systems perspective. Using the paper’s notation, one can sum over the equations for all the layers to obtain this.\n\nx(1) = x(0) + y(1)\n…\nx(T) = x(T-1) + y(T)\n————————————————————————\nx(T) = x(0) + sum(y(t))\n\nSince the classification is performed using x(T), it is clear that the sum of transients is what causes the change in representation and that y(T) can be the same or not for different class inputs.\n\nBased on my understanding, I don’t find the findings to be significantly novel or surprising. In particular, I don’t see any concrete benefits of employing a dynamical systems perspective here. Nevertheless, the experimental analysis is interesting, and I’m hopeful that this direction will lead to more insights in the future.\n\nThe final contribution is a new method to learn the depth of Residual networks during training, but this is insufficiently explored (only tested on the toy dataset) so its practical significance can not be evaluated at this stage.\n\n\nMinor notes:\n- Note that many citations are textual when they should be parenthetical.\n- The reference “No & Liao (2016)” has incorrect author name.', 'This paper aims to view the computations performed by residual networks through the lens of transient dynamical systems. A rough intuition is provided, followed by experiments in a toy concentric circle example and on MNIST. Finally, a method to determine the appropriate depth of ResNets is proposed, though experiments are only performed in the toy concentric circle experiment. \n\nThe approach of attempting to interpret feedforward networks through a dynamical systems perspective is an interesting and worthwhile one. However, this paper suffers from a number of flaws, and is clearly not ready for publication. \n\nThe clarity of this paper can be significantly improved. In general, the text is confusing, and as currently written, it is difficult to understand the central narrative of the manuscript. The review of literature in the introduction is relatively complete, though again, the presentation makes this section difficult to understand. \n\nScientifically, it is clear that further experiments on less toy datasets and settings will be required. While MNIST is useful for prototyping, experiments on datasets such as CIFAR (or ideally ImageNet) will be necessary to evaluate whether the observations made hold in more realistic settings. Moreover, the primary claim: that ResNets sum the residuals across layers is by definition true and by design. The scientific contribution of this statement is therefore questionable.\n\nIn addition, the case analyzed in the majority of the paper -- weight sharing across all layers -- is an unusual one, and as Figure 3 shows, clearly changes the network dynamics. The use of sigmoid activation functions is also an unusual one given that ResNets are generally trained with ReLU activations. \n\nFinally, the proposed method for determining the optimal depth for ResNets is an interesting idea, and worth further examination. However, the paper currently evaluates this only on an an extremely toy dataset of concentric circles. Evaluation on more realistic datasets (comparatively) with appropriate baselines will be required to determine whether this method is in fact helpful. \n', 'In this paper the authors analyse the role of residuals in the performance of residual networks (res-nets) with shared layer weights and propose a method to adapt the depth of such networks during training. They exploit  the fact that res-nets identical blocks / shared layer weights are discrete time dynamical systems to conduct their analysis. Their main contribution seems to be an empirical evaluation of the role of transient dynamics in the performance of such res-nets. Experiments are done on a toy dataset on concentric circles and MNIST data.\n\nI find the scope of the paper very narrow (res-nets with shared weights) even though there seem to be quite some other papers addressing this problem.\n\nClarity and quality of writing. It seems to me that the paper could  be much better written, the authors present long trains of thoughts and sometimes unsubstantiated arguments and at times there seems to be no clear storyline. In particular I would strongly  suggest a rewrite of  Sections 1, 2.1, and 4.  The storyline often very sketchy and is littered with hypothetical claims or less relevant information that can distracts and confuse the reader. I find that the hypotheses are not well formulated,   the claimed contributions of the paper don\'t seem to be significant enough and they should also be better connected to the experimental sections. Sometimes there are some odd choices of concepts/words such as ""softmax algorithm"" and ""classification behaviour.""\n\nTechnical quality and contribution. The main technical contribution of the paper seems to be the observation that  that the solution of an  ODE if the integral of the RHS an that one can derive an ODE for the residuals only. I don\'t find  these results significant/relevant enough to justify the publication of this paper.  I expected a better written and more informative Section 2.1: some approximations of rates of convergence, a bit more about basins of attraction. I am also a bit skeptical about the claim that the analysed network us a prey-predator model. \n\nExperimental section. I find the description of experiments in Sec 4 very hard to read. The metrics are not clearly defined (not sure visualisations serve the purpose either), and the performed experiments are not well motivated and explained, for example in Section 4/P2 while I think I understand what the authors want to show (path of relevant neurons), I find the purpose of the whole experiment not very relevant.  I better analysis of the number of fixed points for classification tasks should be added, comparison of resulting features to other methods such as simple MLPs with same last layer could help . More relevant datasets should be be added e.g. CIFARxxx., ImageNet.\n\nOverall: I find that this paper needs to be improved both in terms of readability and technical contribution to ready for publication.']","[-20, -60, -60]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'generally of good quality and easy to understand', they also state that 'the contributions are not significant at this stage' and that they 'don't find the findings to be significantly novel or surprising'. The reviewer expresses hope for future insights but overall seems underwhelmed by the current work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects of the paper, and frames criticisms constructively. They use phrases like 'I think it will be an improvement' and 'I'm hopeful that this direction will lead to more insights in the future', which maintain a polite and encouraging tone even while expressing concerns."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper 'suffers from a number of flaws' and is 'clearly not ready for publication'. They point out several issues with clarity, scientific rigor, and limited experiments. However, they do acknowledge some positive aspects, such as the interesting approach and the potential of the proposed method for determining optimal depth, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'can be significantly improved' instead of more harsh language, and they acknowledge the potential value of the research direction. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer finds the paper's scope narrow, writing quality poor, and technical contribution insufficient. They use phrases like 'needs to be improved' and 'not significant/relevant enough to justify publication'. However, it's not entirely negative as they do acknowledge some aspects of the work. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and use polite language like 'I would strongly suggest' and 'I find'. They also provide specific recommendations for improvement, which is constructive. However, some phrases like 'odd choices' and 'very hard to read' are somewhat blunt, preventing a higher politeness score.""]"
"['The authors describe a framework of how to learn a ""fair"" (demographic parity) representation that can be used to train certain classifiers, in their case facial expression and activity recognition. The method describes an adversarial framework with a constraint that bounds the distortion of the learned representation compared to the original input.\n\nClarity:\nThe paper is well written and easy to follow. The appendix is rather extensive though and contains some important parts of the paper, though the paper can be understood w/o it.\n\nI didn\'t quite follow Sec 3. It is a bit sparse on the details and the final conclusion isn\'t entirely clear. It also isn\'t clear to me how general the conclusions drawn from the Gaussian mixture model are for more complex cases.\n\nNovelty:\nAdversarial fairness methods are not new, but in my opinion the authors do a good job of summarizing the literature and formalizing the problem. I am not fully familiar with the space to judge if this is enough novelty.\n\nUsing the distortion constraint is interesting and seems to work according to the experiments. Generally though, I think that distortion can be a very restrictive constraint. One could imagine representations with a very high distortion (e.g. by completely removing the sensitive attribute) and predictive qualities equivalent to the original representation. Some further discussion of this would be good.\n\nExperiments:\nThe experiments are somewhat limited, but show the expected correlations (e.g. distortion vs predictiveness). \n\nOverall, I do believe that this work is in the right direction in this more and more popular area of great importance. I also think that contributions compared to other works could be made more clear, as well as additional experiments and discussions of the shortcomings of this approach may be added.', 'This paper present an adversarial-based approach for private and fair representations. This is done by learned distortion of data that minimises the dependency on sensitive variable while the degree of distortion is constrained. This problem is important, and the analysis from game-theory and information theory perspectives is interesting. However, the approach itself is similar to Edwards & Storkey 2015, and I find the presentation of this paper confusing at a few points. \n\nFirst, while both the title and abstract suggest it is about learning representation, the approach might be better considered as data-augmentation. As described a bit later: ""...modifying the training data is the most appropriate and the focus of this work"". This contradiction with more commonly accepted meaning of representation learning (learning abstract/high level representation of data) is confusing.\n\nAlthough the authours argued this work is different from Edwards & Storkey 2015, I think they are quite similar. The presented method is almost a special case of this previous work: it seems that one can obtain this model by modifying Edwards & Storkey\'s model as follows (referring to the equations in Edwards & Storkey\'s paper): (1) removing the task (Y) dependent loss in eq. 9. (2) assume the encoder transforms X to the same data space so the decoder can be removed, so eq. 7 become equivalent to the distortion measure in this paper. There are other small differences, such as adding noise and the exact way to impose constraint, but I doubt whether the novelty is significant in this case.\n\nOther places that are unclear include: proposition 1 -- what does ""demographic parity subject to the distortion constraint"" mean? demographic parity was defined earlier as complete independence on sensitive variable, so how can ""complete independence"" subject to a constraint? In addition, it would be helpful introduce S is binary. This information was delayed to section 3 after the cross-entropy loss that assumes binary S was presented.\n\nOverall, I think this paper is interesting, and the analysis offers insights into related areas. However, the novelty is not enough for acceptance at ICLR, and the presentation can be improved.', '    The paper authors provide a good overview of the related work to Private/Fair Representation Learning (PRL). Well written, The theoretical approach is extensively explained and the first sections of the paper are easy to follow. The authors demonstrate the model performance on or the GMM, the comparison between theoretical and data driven performance is a good case study to understand the PRL.\n\nWe usually expect to see related work in the first sections, in this case it\'s has been put just before the conclusion. It can be still justified by the need o introduce the  PRL concepts before comparing with other works.\nThe GMM study case is interesting, but incorporates strong assumptions. Moreover, for a 4 or 8 dimensional GM, 20K data points are more than enough to infer the correct parameter. It would have been more useful if it was used to comapre between the mentioned methods in ""Related Work"".\n\nThere seems to be important parts of the paper that has been put in the appendices: how to solve the constrained problem, Algorithm.... Similarly, some technical details were expanded in the paper body (Network structure).\n\nThe authors mentioned the similarities with other works and their model choices that set theirs apart from other. Yet, the paper doesn\'t provide performance ( accuracy, MI) comparison to other works. There seems to be a strong similarity with Censoring representations with an adversary, Harrison Edwards and Amos Storke (link: https://arxiv.org/abs/1511.05897). Difference : distortion instead of H divergence, non-generative autoencoders.\n\nConsequently, I question the novelty of the paper\'s contribution. Without extensive comparison with other methods and especially to similar ones mentioned in the related work, there is little to say about the ""state-of-the-artness"". Yet, it is important to acknowledge the visible effort behind the paper and how the author(s) managed to leverage the simplicity and power of GANs.\n\nOn a lighter note:\nA)- the paper mention ""state-of-the-art CNNs, state-of-the-art entropy estimators, MI, generative models"", for the Machine Learning community, many of these elements have been around for a while now.\nB)- ""Observe that the hard constraint in equation 2 makes our minimax problem different from what is extensively studied in the machine learning community"": I would argue it\'s not an objective statement.\n \n\n\n']","[50, -30, 20]","[75, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, good literature summary, interesting approach) while also pointing out areas for improvement (limited experiments, need for more clarity on contributions). The overall tone suggests the work is promising but could benefit from some enhancements. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. Phrases like 'I believe this work is in the right direction' and 'The paper is well written and easy to follow' demonstrate a polite and professional tone."", ""The sentiment score is -30 because while the reviewer acknowledges the importance of the topic and finds some aspects interesting, they express significant concerns about the novelty and clarity of the paper. The reviewer states that the approach is similar to previous work and that the presentation is confusing at several points. They conclude that the novelty is not enough for acceptance at ICLR. However, the score is not extremely negative as the reviewer does find some value in the paper's analysis and insights.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find' and 'I think' to soften criticisms, and they balance negative points with positive observations. The reviewer also offers specific suggestions for improvement, which is constructive. While not overly warm, the language is consistently polite and appropriate for academic discourse."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths, such as providing a good overview, being well-written, and demonstrating visible effort. However, they also raise concerns about novelty and lack of comparison with other methods, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive criticism. They use phrases like 'good overview,' 'well written,' and 'visible effort,' which contribute to a polite tone. Even when expressing concerns, the reviewer maintains a professional and courteous demeanor, using phrases like 'I question' rather than making harsh statements. The reviewer also offers suggestions for improvement, which is a polite way to provide criticism.""]"
"['This paper proposes an objective function for auto-encoding they\ncall information maximizing auto encoding (IMAE).  To set the stage\nfor my review I will start with the following ""classical"" formulation\nof auto-encoding as the minimization of the following where we are\ntraining models for P(z|x) and P(x|z).\n\nbeta H(z) + E_{x,z sim P(z|x)} -log P(x|z) (1)\n\nHere H(z) is defined by drawing x from the population and then drawing\nz from P(z|x).  This is equivalent to classical rate-distortion coding\nwhen P(x|z) is an isotropic Gaussian in which case -log P(x|z) is just\nthe L2 distortion between x and its reconstruction.  The parameter\nbeta controls the trade-off between the compression rate and the L2\ndistortion.\n\nThis paper replaces minimizing (1) with maximizing\n\nbeta I(x,z) + E_{x,z sim P(z|x)} log P(x|z) (2)\n\nThis is equivalent to replacing H(z) in (1) by -I(x,z).  But (2)\nadmits a trivial solution of z=x.  To prevent the trivial solution this\npaper proposes to regularize P(z) toward a\ndesired distribution Q(z) and replacing I(x,z) with KL(P(z),Q(z))\nby minimizing\n\nbeta KL(P(z),Q(z)) + E_{x,z sim P(z|x)} - log P(x|z) (3)\n\nThe paper contains an argument that this replacement is reasonable\nwhen Q(z) and P(z|x) are both Gaussian with diagonal covariances.  I\ndid not verify that argument but in any case it seems (3) is better than (2). \nFor beta large (3) forces P(z) = Q(z) which fixes H(z) and the a-priori value\nH(Q).  The regularization probably has other benefits.\n\nBut these suggestions are fairly simple and any real assessment of their\nvalue must be done empirically.  The papers experiments with MNIST\nseem insufficient for this.\n', '* This paper proposed a principled framework for auto-encoding through information maximization. A novel contribution of this paper is to introduce a hybrid continuous-discrete representation. The authors also related this approach with other related work such as \\beta-VAE and info-VAE, putting their work in context. Empirical results show that the learned representation has better trade-off among interpretability and decoding quality.\n\n* It seems a little strange to me to incorporate the VAT regularization to the IMAE framework in Section 4.2, as this is not included in the overall objective in Equation (10) and earlier analysis (Proposition 1 and 2). Will the conclusions in Proposition 1 and 2 change accordingly due to the inclusion of VAT regularization?\n\n* The paper states that IMAE has better trade-off among interpretability and decoding quality. But it is still unclear how a user can choose a good trade-off according to different applications. More discussion along this direction would be helpful.\n\n* I guess the L(y) term in Equation (10) is from Equation (9), but this is not stated explicitly in the paper.', 'Summary: the paper proposes a method for unsupervised disentangling of both discrete and continuous factors of variation in image data. It uses an autoencoder learned by optimising an additive loss composed of Mutual Information (MI) I(x;y,z) between the image x and the discrete+cts latents (y,z) and the reconstruction error. The mutual information is shown to decompose into I(x,y), I(x,z) and TC(y;z), and the I(x,z) is treated in a different manner to I(x,y). With Gaussian p(z|x), and it is shown that I(x,z_k) is maximal when p(z_k) is Gaussian. So KL(p(z_k)||N(0,1)) is optimised in lieu of optimising I(x,z), and I(x,y) (and TC(y;z)) is optimised by using mini-batch estimates of marginal distributions of y (and z). The paper claims improved disentangling of discrete and continuous latents compared to methods such as JointVAE and InfoVAE.\n\nPros:\n- The derivation of the loss shows a nice link between Mutual information and total correlation in the latents.\n- It is a sensible idea to treat the MI terms of the discrete latents differently to the continuous latents\n- The mathematical and quantitative analysis of MI and its relation to decoder means and variances are informative.\n\nCons:\n- There is not enough quantitative comparison of the quality of disentanglement across the different methods. The only values for this are the accuracy scores of the discrete factor, but for the continuous latents there are only qualitative latent traversals of single models, and I think these aren’t enough for comparing different disentangling methods - this is too prone to cherry-picking. I think it’s definitely necessary to report some metrics for disentangling that are averaged across multiple models trained with different random seeds. I understand that there are no ground truth cts factors for Mnist/FashionMnist, but this makes me think that a dataset such as dSprites (aka 2D Shapes) where the factors are known and has a mix of discrete and continuous factors would have been more suitable. Here you can use various metrics proposed in Eastwood et al, Kim et al, Chen et al for a quantitative comparison of the disentangled representations.\n- In figure 4, it says beta=lamda=5 for all models. Shouldn’t you be doing a hyperparameter sweep for each model and choose the best value of hyperparameters for each? It could well be that beta=5 works best for IMAE but other values of beta/lambda can work better for the other models.\n- When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. You also say that VAT helps maintain local smoothness so as to prevent overfitting. Then shouldn’t you also be comparing against JointVAE + VAT? Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy. Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n- In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper. Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n- There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n\nQs and comments:\n- It’s not clear why posterior approximation quality (used as a starting point for motivating the loss) is an important quantity for disentangling.\n- I see that the upper bound to I(x;z_k) in (4) and the objective in (6) have the same optimum at p(z_k) being Gaussian, but it’s not clear that increasing one leads to increasing the other. Using (6) to replace (4) seems to require further justification, whether it be mathematical or empirical.\n- In proposition 2, I’m sceptical as to how meaningful the derived bound is, especially when you set N to be the size of the minibatch (B) in practice. It also seems that for small delta (i.e. to ensure high probability on the bound) and large K_2 (less restrictive conditions on p(y) and \\hat{p}(y)), the bound can be quite big.\n- \\mathcal{L}_theta(y) in equation (10) hasn’t been introduced yet.\n- The z dimension indices in the latent traversal plots of Figure 2 don’t seem to match the x-axis of the left figure. It’s not clear which are the estimates of I(x;z_k) for k=8,3,1 in the figure.']","[-20, 60, -20]","[50, 70, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and provides a detailed analysis, they ultimately express skepticism about the sufficiency of the experiments ('The papers experiments with MNIST seem insufficient for this'). This suggests that the reviewer is not fully convinced by the paper's findings. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout, explaining concepts clearly and avoiding harsh criticism. They use phrases like 'To set the stage for my review' and 'I did not verify that argument but in any case it seems (3) is better than (2)' which indicate a respectful approach to the review process. The reviewer also acknowledges the potential benefits of the proposed method ('The regularization probably has other benefits') before expressing their concerns, which contributes to the overall polite tone."", ""The sentiment score is 60 (positive) because the review starts with acknowledging the paper's novel contribution and its relation to existing work. It also mentions positive empirical results. However, it's not extremely positive as it raises some questions and suggests improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'It seems a little strange to me' and 'More discussion along this direction would be helpful' indicate a polite approach to giving feedback. The reviewer also acknowledges the paper's strengths before pointing out areas for improvement, which is a polite review strategy."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they list more cons and raise several critical points. The review begins with a balanced summary and mentions some positive aspects, but the majority of the content focuses on limitations and areas for improvement. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, framing them as suggestions or areas for improvement rather than harsh criticisms. The reviewer also acknowledges the paper's strengths and uses phrases like 'I think' and 'I understand' to soften their critiques, showing consideration for the authors' perspective.""]"
"['This work proposes a learning method based on deep subspace clustering. The method is formulated by identifying a deep data embedding, where clustering is performed in the latent space by a revised version of k-means, inspired by the work [1]. In this way, the proposed method can adapt to account for uni-modal distributions. The authors propose some variations of the framework based on soft cluster assignments, and on cumulative learning of the cluster means.\nThe method is tested on several scenarios and datasets, showing promising results in prediction accuracy.\n\nThe idea presented in this work is reasonable and rather intuitive. However, the paper presentation is often unnecessarily convoluted, and fails in clarifying the key points about the proposed methodology. The paper makes often use of abstract terms and jargon, which sensibly reduce the manuscript clarity and readability. For this reason, in my opinion, it is very difficult to appreciate the contribution of this work, from both methodological and applicative point of view. \n\nRelated to this latter point, the use of the term “Bayesian nonparametric” is inappropriate. It is completely unclear in which sense the proposed framework is Bayesian, as it doesn’t present any element related to parameters inference, uncertainty estimation, … Even the fact that the method uses an algorithm illustrated in [1] doesn’t justifies this terminology, as the clustering procedure used here only corresponds to the limit case of a Dirichlet Process Gibbs Sampler when the covariance parameters goes to zero. Moreover, the original procedure requires the iteration until convergence, while it is here applied with a single pass only. The procedure is also known to be sensitive to the order by which the data is provided, and this point is not addressed in this work. \n\nFinally, the novelty of the proposed contribution is questionable. To my understanding, it may consist in the use of embedding methods based on the approach provided in [1]. However, for the reasons illustrated above, this is not clear. There is also a substantial amount of literature on deep subspace embeddings that proposes very similar methodologies to the one of this paper (e.g. [2-5]).  For this reason, the paper would largely benefit from further clarifications and comparison with respect to these methods.  \n\n\n\n\n\n[1] Kulis and Jordan,  Revisiting k-means: New Algorithms via Bayesian Nonparametrics, ICML 2012\n\n[2] Xie, Junyuan, Ross Girshick, and Ali Farhadi. ""Unsupervised deep embedding for clustering analysis."" International conference on machine learning. 2016.\n[3] Ji, Pan, et al. ""Deep subspace clustering networks."" Advances in Neural Information Processing Systems. 2017.\n[4] Jiang, Zhuxi, et al. ""Variational deep embedding: An unsupervised and generative approach to clustering."" IJCAI 2017\n[5] Kodirov, Elyor, Tao Xiang, and Shaogang Gong. ""Semantic autoencoder for zero-shot learning. CVPR 2017.', 'The paper proposes a meta-learning method that utilizes unlabeled examples along with labeled examples. The technique proposed is very similar to the one by (Ren et al. 2018), only differing in the choice of a different clustering algorithm (Kulis and Jordan, 2012) instead of soft k-means as used by Ren et al. \n\nI feel the contrast to Ren et al, is not provided to the degree it should be. The Appendix paragraph A4 is not sufficient in terms of explaining why this method is conceptually different or significantly better than the related approach. It is hard for me to certify the merits of their work, including explaining the experimental results.\n\nI also do not understand the significance of ""multi-model clustering"" in this context. Also, by their definition of ""variadic"", how is this more variadic than Ren et al. or Snell et al.?\n\n', 'Update after Author Rebuttal\n--------------\nAfter reading the rebuttal, I\'m pleased that the authors have made significant revisions, but I still think more work is needed. The ""hard/soft"" hybrid approach still lacks justification and perhaps wasn\'t compared to a soft/soft approach in a fair and fully-correct way (see detailed reply to authors). I also appreciate the efforts on revising clarity, but still find many clarity issues in the newest version that make the method hard to understand let alone reproduce. I thus stand by my rating of ""borderline rejection"" and urge the authors to prepare significant revisions for a future venue that avoid hybrids of hard/soft probabilities without justification. \n\n(Original review text below. Detailed replies to authors are in posts below their responses).\n\nReview Summary\n--------------\nWhile the focus on variadic learning is interesting, I think the present version of the paper needs far more presentational polish as well as algorithmic improvements before it is ready for ICLR. I think there is the potential for some neat ideas here and I hope the authors prepare stronger versions in the future. However, the current version is unfortunately not comprehensible or reproducible.\n\nPaper Summary\n-------------\n\nThe paper investigates developing an effective ML method for the ""variadic"" regime, where the method might be required to perform learning from few or many examples (shots) and few or many classes (ways). The term ""variadic"" comes from use in computer science for functions that can a flexible number of arguments. There may also be unlabeled data available in the few shot case, creating semi-supervised learning opportunities.\n\nThe specific method proposed is called BANDE: Bayesian Nonparametric Deep Embedding. The idea is that each data point\'s feature vector x_i is transformed into an embedding vector h(x_i) using a neural network, and then clustering occurs in the embedding space via a single-pass of the DP-means algorithm (Kulis & Jordan 2012). Each cluster is assumed to correspond to one ""class"" in the eventual classification problem, though each class might have multiple clusters (and thus be multi-modal).  \n\nLearning occurs in an episodic manner. After each episode (single-pass of DP-means), each point in a query set is embedded to its feature vector, then fed into each cluster\'s Gaussian likelihoods to produce a normalized cluster-assignment-probability vector that sums to one. This vector is then fed into a cross-entropy loss, where the true class\'s nearest cluster (largest probability value) is taken to be the true cluster. This loss is used to perform gradient updates of the embedding neural network.\n\nThere is also a ""cumulative"" version of the method called BANDE-C. This version keeps track of cluster means from previous episodes and allows new episodes to be initialized with these.\n\nExperiments examine the proposed approach across image categorization tasks on Omniglot, mini-ImageNet, and CIFAR datasets.\n\n\nStrengths\n---------\n* I like that many clusters are used for each true class label, which is better than rigid one-to-one assumptions.\n\n\nLimitations\n-----------\n* Can only be used for classification, not regression\n* The DP-means procedure does not account for the cluster-specific variance information that is used at other steps of the algorithm\n\n\nSignificance and Originality\n----------------------------\nTo me, the method appears original. Any method that could really succeed across various variadic settings would be significant.\n\n\n\nPresentation Concerns\n---------------------\n\nI have serious concerns about the presentation quality of this paper. Each section needs careful reorganization as well as rewording.\n\n## P1: Algo. 1 contains numerous omissions that make it as written not correct.\n\n* the number of clusters count variable ""n"" is not updated anywhere. As writting this algo can only update one extra cluster beyond the original n.\n* the variable ""c"" is unbound in the else clause. You need a line that clarifies that c = argmin_{c in 1 ... n} d_ic\n\nWould be careful about saying that ""a single pass is sufficient""... you have *chosen* to do only one pass. When doing k-means, we could also make this choice. Certainly the DP-means objective could keep improving with multiple passes.\n\n## P2: Many figures and tables lack appropriate captions/labels\n\nTable 1: What metric is reported? Accuracy percentage? Not obvious from title/caption. Should also make very clear here how much labeled data was used.\n\nTable 2: What metric is reported? Accuracy percentage? Not obvious from title/caption. Should also make how many labeled and unlabeled examples were used easier to find.\n\n## P3: Descriptions of episodic learning and overall algorithm clarity\n\nReaders unfamiliar with episodic learning are not helped with the limited coverage provided here in 3.1 and 3.2. When exactly is the ""support"" set used and the ""query"" set used? How do unlabeled points get used (both support and query appear fully labeled)? What is n? What is k? What is T? Why are some points in Q denoted with apostrophes but not others? Providing a more formal step-by-step description (perhaps with pseudocode) will be crucial.\n\nIn Sec. 3.2, the paragraph that starts with ""The loss is defined"" is very hard to read and parse. I suggest adding math to formally define the loss with equations. What parameters are being optimized? Which ones are fixed?\n\nAdditionally, in Sec. 3.2: ""computed in the same way as standard prototypical networks""... what is the procedure exactly? If your method relies on a procedure, you should specify it in this paper and not make readers guess or lookup a procedure elsewhere.\n\n\n## P4: Many steps of the algorithm are not detailed\n\nThe paper claims to set \\lambda using a technique from another paper, but does not summarize this technique. This makes things nearly impossible to reproduce. Please add such details in the appendix.\n\nMajor Technical Concerns\n------------------------\n\n## Alg. 1 concerns: Requires two (not one) passes and mixes hard and soft assingments and different variance assumptions awkwardly\n\nThe BANDE algorithm (Alg. 1) has some unjustified properties. Hard assignment decisions which assume vanishing variances are used to find a closest cluster, but then later soft assignments with non-zero variances are used. This is a bit heuristic and lacks justification... why not use soft assignment throughout? The DP means procedure is derived from a specific objective function that assumes hard assignment. Seems weird to use it for convenience and then discard instead of coming up with the small fix that would make soft assignment consistent throughout.\n\nFurthermore, The authors claim it is a one pass algorithm, but in fact as written in Alg. 1 it seems to require two passes: the first pass keeps an original set of cluster centers fixed and then creates new centers whenever an example\'s distance to the closest center exceeds \\lambda. But then, the *soft* assignment step that updates ""z"" requires again the distance from each point to all centers be computed, which requires another pass (since some new clusters may exist which did not when the point was first visited). While the new soft values will be close to zero, they will not be *exactly* zero, and thus they matter. \n\n## Unclear if/how cluster-specific variance parameters learned\n\nFrom the text on top of page 4, it seems that the paper assumes that there exist cluster-specific variances \\sigma_c. However, these are not mentioned elsewhere, only a general (not cluster-specific) label variance \\sigma and fixed unlabeled variance sigma_u are used.\n\n## Experiments lack comparison to internal baselines\n\nThe paper doesn\'t evaluate sensitivity to key fixed hyperparameters (e.g. \\alpha, \\lambda) or compare variants of their approach (with and without soft clustering step, with and without multimodality via DP-means). It is difficult to tell which design choices of the method are most crucial.\n']","[-50, -50, -60]","[0, 20, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('promising results', 'reasonable and rather intuitive idea'), the overall tone is critical. The reviewer expresses significant concerns about the paper's clarity, methodology, and novelty. The politeness score is 0 (neutral) because the reviewer maintains a professional tone without being overly polite or rude. They express criticisms directly but without harsh language, using phrases like 'in my opinion' and 'the paper would largely benefit from' to soften the critique. The review balances some positive comments with substantial criticisms, maintaining a neutral, academic tone throughout."", ""The sentiment score is -50 because the reviewer expresses several concerns and criticisms about the paper. They state that the proposed method is very similar to existing work, that the contrast to previous work is not sufficiently explained, and that they don't understand some key aspects of the paper. These points indicate a generally negative sentiment, though not extremely so.\n\nThe politeness score is 20 because the reviewer uses relatively neutral language and avoids harsh criticism. They use phrases like 'I feel' and 'It is hard for me to certify' rather than making blunt negative statements. The reviewer also acknowledges the work done by the authors, even while critiquing it. However, the score is only slightly positive as the review doesn't contain explicitly polite language or praise."", 'The sentiment score is -60 because the reviewer expresses significant concerns and recommends rejection, stating \'I thus stand by my rating of ""borderline rejection""\'. However, they do acknowledge some positive aspects like the interesting focus and potential for improvement, preventing an extremely negative score. The politeness score is 20 because the reviewer uses generally professional language and offers constructive feedback, saying things like \'I hope the authors prepare stronger versions in the future\'. However, they are also quite direct in their criticisms without excessive softening language, keeping the score only moderately positive. The reviewer balances politeness with clear communication of their concerns.']"
"['This paper proposes an unpaired image-to-image translation method which applies the co-segmentation network and adaptive instance normalization techniques to enable the manipulation on the local regions.\n\nPros:\n* This paper proposes to jointly learn the local mask to make the translation focus on the foreground instead of the whole image.\n* The local mask-based highway adaptive instance normalization apply the style information to the local region correctly.\n\nCons:\n* There seems a conflict in the introduction (page 1): the authors clarify that “previous methods [1,2,3] have a drawback of ....” and then clarify that “[1,2,3] have taken a user-selected exemplar image as additional input ...”. \n* As the main experiments are about facial attributes translation, I strongly recommend to the author to compare their work with StarGAN [4]. \n* It is mentioned in the introduction (page 2) that “This approach has something in common with those recent approaches that have attempted to leverage an attention mask in image translation”. However, the differences between the proposed method with these prior works are not compared or mentioned. Some of these works also applied the mask technique or adaptive instance normalization to the image-to-image translation problem. I wonder the advantages of the proposed method compared to these works.\n* The experiment setting is not clear enough. If I understand correctly, the face images are divided into two groups based on their attributes (e.g. smile vs no smile). If so, what role does the exemplar image play here? Since the attribute information has been modeled by the network parameters, will different exemplar image lead to different translation outputs? \n* The github link for code should not provide any author information.\n\n[1] Multimodal Unsupervised Image-to-Image Translation\n[2] Diverse Image-to-Image Translation via Disentangled Representations\n[3] Exemplar Guided Unsupervised Image-to-Image Translation\n[4] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation\n\nOverall, I think the proposed method is well-designed but the comparison and experiment setting are not explained well. My initial rating is weakly reject.', 'Summary--\nThe paper tries to address an issue existing in current image-to-image translation at the point that different regions of the image should be treated differently. In other word, background should not be transferred while only foreground of interest should be transferred. The paper propose to use co-segmentation to find the common areas to for image translation. It reports the proposed method works through experiments.\n\nThere are several major concerns to be addressed before considering to publish.\n\n1) The paper says that ""For example, in a person’s facial image translation, if the exemplar image has two attributes, (1) a smiling expression and (2) a blonde hair, then both attributes have to be transferred with no other options"", but the model in the paper seems still incapable of transferring only one attribute. Perhaps an interactive transfer make more sense, while co-segmentation does not distinguish the part of interest to the user. Or training a semantic segmentation make more sense as the semantic segment can specify which region to transfer.\n\n2) As co-segmentation is proposed to ""capture the regions of a common object existing in multiple input images"", why does the co-segmentation network only capture the eye and mouth part in Figure 2 and 3, why does it capture the mouth of different shape and style in the third macro column in Figure 4 instead of eyes? How to train the co-segmentation module, what is the objective function? Why not using a semantic segmentation model?\n\n3) The ""domain-invariant content code"" and the ""style code"" seem rather subjective. Are there any principles to design content and style codes? In the experiments, it seems the paper considers five styles to transfer as shown in Table 1. Is the model easy to extend to novel styles for image translation?\n\n4) What does the pink color mean in the very bottom-left or top-right heatmap images in Figure 2? There is no pink color reference in the colorbar.\n\n5) Figure 5: Why there is similariy dark patterns on the mouth? Is it some manual manipulation for interactive transfer?\n\n6) Though it is always good to see the authors are willing to release code and models, it appears uncomfortable that github page noted in the abstract reveals the author information. Moreover, in the github page,\neven though it says ""an example is example.ipynb"", the only ipynb file contains nothing informative and this makes reviewers feel cheated.\n\nMinor--\nThere are several typos, e.g., lightinig.', 'The paper deals with image to image (of faces) translation solving two main typical issues: 1) the style information comes from the entire region of a given exemplar, collecting information from the background too, without properly isolating the face area; 2) the extracted style is applied to the entire region of the target image, even if some parts should be kept unchanged. The approach is called LOMIT, and is very elaborated, with source code which is available (possible infringement of the anonymity, Area Chair please check). In few words, LOMIT lies on a cosegmentation basis, which allows to find semantic correspondences between image regions of the exemplar and the source image. The correspondences are shown as a soft mask, where the user may decide to operate on some parts leaving unchanged the remaining (in the paper is shown for many alternatives: hair, eyes, mouth). Technically, the paper assembles other state of the art techniques,  (cosegmentation networks, adaptive instance normalization via highway networks) but it does it nicely. The major job in the paper lies in the regularization part, where the authors specify each of their adds in a proper way. Experiments are nice, since for one of the first times provide facial images which are pleasant to see. One thing I did not like were on the three set of final qualitative results, where gender change results in images which are obviously diverse wrt the source one, but after a while are not communicating any newer thing. Should have been better to explore other attributes combo.  ']","[-40, -50, 70]","[50, 20, 60]","[""The sentiment score is -40 because the overall tone is somewhat negative, with the reviewer pointing out several cons and concluding with a 'weakly reject' recommendation. However, they do mention some pros and describe the method as 'well-designed', which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without being harsh or rude. They use phrases like 'I strongly recommend' and 'I wonder' which maintain a polite tone. The reviewer also balances criticism with positive comments, which contributes to the politeness of the review."", ""The sentiment score is -50 because the review starts with a neutral summary but then lists several 'major concerns' that need to be addressed, indicating significant issues with the paper. The reviewer points out multiple problems with the methodology, results interpretation, and even suggests that the authors' approach might not be the most appropriate for the task. The politeness score is 20 because while the reviewer is direct in pointing out issues, they use professional language and offer constructive criticism. They use phrases like 'There are several major concerns to be addressed' rather than harsh or dismissive language. The reviewer also acknowledges positive aspects, such as the authors' willingness to release code. However, the comment about feeling 'cheated' by the lack of informative content in the shared notebook slightly reduces the politeness score."", ""The sentiment score is 70 (positive) because the reviewer generally speaks favorably about the paper, describing the approach as 'very elaborated' and praising the experiments as 'nice'. They mention that the paper 'assembles other state of the art techniques... but it does it nicely'. The only negative point is a minor criticism about the final qualitative results. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. They use phrases like 'Should have been better to explore' instead of more direct criticism. The reviewer also maintains a professional tone, focusing on the content rather than making personal comments about the authors.""]"
"['The paper presents an inference method (implicit distribution particle smoothing) for neural Hawkes processes that accounts for latent sequences of events that influence the observed trajectories.\n\nQuality\n+ The paper combines ideas from multiple areas of machine learning to tackle a challenging task of inference in multivariate continuous-time settings.\n- The figures reported from the paper are comparative graphs with respect to particle filtering, and so the absolute level of performance of the methods is not characterized.  Reporting of distribution of sample weights and or run-times/complexity would strengthen the paper.\n\nClarity\n- notation is complex replete with symbols ""@"" and text in math formulas\n- It\'s not clear what p (""the data model"") and p_miss (""the missingness mechanism"") represent, and therefore why in equation 1: p(x,z) = p(xvz)p_miss(z| xvz) where v is the union symbol.  In addition, how it\'s related to MAR and MNAR is unclear. If e.g. following Murphy, one writes MAR as: p(r|x_u, x_o) = p(r|x_o), r is a missingness vector, x_u is x unobserved, and x_o is x observed, then r corresponds to observation or not, whereas in the manuscript p_miss is on the values themselves, i.e. on the space where z={k_{i,j}@t_{i,j}} resides.  We know, from the definition of MNAR that we can\'t use only the observed data to correctly infer the distributions of the missing values, and so while one can probabilistically predict in MNAR setting, their quality remains unknown.  If none of the experiments touch upon MNAR data, perhaps it is possible to omit this part.\n\nOriginality\n+ the work is rich, complex, original, and uses leading methods from multiple areas of ML.\n\nSignificance\n+ the significance of this work could be high, as it may provide a way to conduct difficult inference in an effective way to produce increasingly flexible modeling of trajectories amidst partial observation.\n- however the exposition (particularly the experiments) does not fully demonstrate this.', 'The authors propose a particle smoothing approach with an approximate minimum Bayes risk decoder to impute missing events in the Neural Hawkes Process (NHP). The main goal is to address the missing events problem in continuous-time event analysis, which is an important problem in practice. The core idea is within the framework of particle smoothing. \n\nTo formulate the posterior distribution of the missing event, the authors consider both the left-to-right past events and the right-to-left future events. The paper first applies the NHP to capture both the observed and inferred missing events to learn a representation of the past events, and then uses a similar NHP to learn the representation of the observed events from the future. Based on the two representations, it then formulates the intensity function of the missing events and uses the thinning algorithm to sample different particles. Based on the proposed distribution, the paper also considers to decode a single prediction achieving the Minimum Bayes Risk. Experiments on synthetic datasets with 10 different initializations and two real datasets show that the proposed smoothing approach is better than the filtering baseline. \n\nIn general, this paper considers an important problem which is under active research in literature recently. However, there are a few weaknesses of the paper that should be addressed. \n\n1. The proposed technique is tightly connected to NHP, which could limit the applicability of the approach to other temporal point processes. The essential idea is similar to Bi-LSTM to learn the representation from both ends of a sequence of asynchronous temporal events. There are several different ways to represent the inter-event time to feed into the network other than NHP. Can the proposed method also be applied to other processes?\n\n2. Within the particle filtering framework, each particle (hypothesis) is weighted by the likelihood of the sequence of observed events under that hypothesis. It turns out that the integral part of Equation 5 does not have an obvious analytical solution under NHP. Then, we first need a set of samples to approximate the likelihood evaluation. Later, we also need to sample particles. I am not quite convinced the computational efficiency of this approach in real applications of practice. Also, there is no analysis either empirically or analytically about the impact of the accumulative sampling errors on the inference performance. Furthermore, to learn the proposed distribution, the paper applies the REINFORCE algorithm under the proposed distribution q. But REINFORCE is known for large variance issue. Given that we already need lots of samples for the likelihood, it is unclear to me how stable the algorithm could be in practice.\n\n3. The experimental evaluation is weak. For particle filtering and smoothing, it is known that the filtering techniques are candidates for solving the smoothing problem but perform poorly when T is large. That\'s why it is necessary to develop more sophisticated strategies for good smoothing\nalgorithms. As a result, it is unfair to only compare the smoothing approach with the filtering baseline. \n\nActually, what people really care about is how different techniques can behave in real data to impute realistic missing events. From this perspective, I suggest to use the QQ-plot to evaluate the goodness of fitting on the synthetic dataset. For example, given a sequence of events generated from an independent temporal point process, we can randomly delete events, and then apply different techniques, including Linderman et al. (2017), Shelton et al.(2018), to impute missing events. Finally, we can compare the imputed sequence of events with the groundtruth. \n\nIn addition, sequential monte carlo approach often suffers from skewed particle issue where one particle gradually dominates all the other particles with no diversity. It is unclear how the proposed approach is able to handle this. \n\nOne missing related paper is ""Learning Hawkes Processes from Short Doubly-Censored Event Sequences""\n\nSection 5.2 can be significantly strengthened if comparing with at least one of these approaches.\n\n4. The paper is fairly written. I had some trouble reading back and forth for understanding Figure 1 since it has long caption that is not self-contained. The annotation of Section 2 is also too heavy to quickly skim through to memorize. ', ""This paper tackles a very important and practical problem in event stream planning. The problem is very interesting and the approach taken is standard.\n\nThe presentation of the paper is not clear enough. The notations and definitions and methods are presented in a complicated way. It's difficult to follows.\n\nFrom the contribution point of view the paper looks like to be a combination of several existing and well developed approach: Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment. It's not very surprising to see these elements together. It would have helped if the authors made it clear why each part is chosen and clearly state what is the novelty and contributed of the paper to the field.\n\nThe paper in its current format is not ready for publication. But it's a good paper and can be turned to a good paper for the next venue.""]","[50, -20, -20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the review acknowledges both strengths and weaknesses of the paper. It praises the originality, complexity, and potential significance of the work, but also points out areas for improvement in clarity and experimental reporting. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, balancing positive feedback with constructive criticism. They use phrases like 'would strengthen the paper' instead of more direct criticisms, and acknowledge the potential importance of the work even while suggesting improvements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and some strengths of the paper, they raise several significant concerns and weaknesses. The review starts positively but then lists multiple issues with the approach, experimental evaluation, and presentation. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. They use phrases like 'I suggest' and 'can be significantly strengthened' which maintain a respectful tone while providing feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the potential of the paper, they also point out significant issues with clarity, presentation, and novelty. The reviewer states that the paper is 'not ready for publication' in its current form, which contributes to the negative sentiment. However, they also mention it's a 'good paper' that can be improved, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's potential and providing constructive criticism. They avoid harsh language and end on an encouraging note, suggesting the paper could be suitable for a future venue. The reviewer maintains a professional tone while clearly communicating the paper's shortcomings.""]"
"['Overview: \nThis nicely written paper contributes a useful variance reduction baseline to make the recent formalism of the DiCE estimator more practical in application. I assess the novelty and scale of the current contribution as too low for publication at ICLR. Also, the paper includes a few incorrect assertions regarding the control variate framework as well as action-dependent baselines in reinforcement learning. Such issues reduce the value of the contribution in its current form and may contribute to ongoing misunderstandings of the control variate framework and action-dependent baselines in RL, to the detriment of variance reduction techniques in machine learning. I do not recommend publication at this time.\n\nPros:\nThe paper is well written modulo the issues discussed below. It strikes me as a valuable workshop contribution once the errors are addressed, but it lacks enough novelty for the main conference track.\n\nIssues:\n\n* (p.5) ""R_w and b_w are positively correlated by design, as they should be for variance reduction of the first order gradients.""\n\nThis statement is not true in general. Intuitively, a control variate reduces variance because when a single estimate of an expectation of a function diverges from its true value according to some delta, then, with high probability, some function strongly correlated with that function will also diverge with a similar delta. Such a delta might be positive or negative, so long as the error may be appropriately modeled as drawn from some symmetric distribution (i.e. is Gaussian).\n\nControl variates are often estimated with an optimal scaling constant that depends on the covariance of the original function and its control variate. Due to the dependence on the covariance, the scaling constant flips sign as appropriate in order reduce variance for any delta. For more information, see the chapter on variance reduction and subsection on control variates in Sheldon Ross\'s textbook ""Simulation.""\n\nThe fact that a control variate appears to work despite this is not surprising. Biased and suboptimal unbiased gradient estimators have been shown to work well for reasons not fully explored in the literature yet. See, for example, Tucker et al.\'s ""Mirage of Action-Dependent Baselines"", https://arxiv.org/abs/1802.10031.\n\nSince the authors claim on page 6 that the baseline is positively correlated by design, this misunderstanding of the control variate framework appears to be baked into the baseline itself. I recommend the authors look into adaptively estimating an optimal scale for the baseline using a rolling estimator of the covariance and variance to fix this issue. See the Ross book cited above for full derivation of this optimal scale.\n\n* The second error is a mischaracterization of the use and utility of action-dependent baselines for RL problems, on page 6: ""We choose the baseline ... to be a function of state ... it must be independent of the action ...."" and ""it is essential to exclude the current action ... because the baselines ... must be independent of the action ... to remain unbiased."" In the past year, a slew of papers have presented techniques for the use of action-dependent baselines, with mixed results (see the Mirage paper just cited), including two of the papers the authors cited.\n\nCons\n* Much of paper revises the DiCE estimator results, arguing for and explaining again those results rather than referring to them as a citation. \n* I assess the novelty of proposed contribution as too low for publication. The baseline is an extension of the same method used in the original paper, and does not generalize past the second order gradient, making the promising formalism of the DiCE estimator as infinitely differentiable still unrealizable in practice.\n* The experiments are practically identical to the DiCE estimator paper, also reducing the novelty and contribution of the paper.\n\n*EDIT: \nI thank the authors for a careful point-by-point comparison of our disagreements on this paper so that we may continue the discussion. However, none of the points I identified were addressed, and so I maintain my original score and urge against publication. In their rebuttal, the authors have defended errors and misrepresentations in the original submission, and so I provide a detailed response to each of the numbered issues below:\n\n(1) I acknowledge that it is common to set c=1 in experiments. This is not the same as the misstatements I cited, verbatim, in the paper that suggest this is required for variance reduction. My aim in identifying these mistakes is not to shame the authors (they appear to simply be typos) but simply to ensure that future work in this area begins with a correct understanding of the theory. I request again that the authors revise the cited lines that incorrectly state the reliance of a control variate on positive correlation. It is not enough to state that ""everyone knows"" what is meant when the actual claim is misleading.\n\n(2) Without more empirical investigation, the authors\' new claim that a strictly state-value-function baseline is a strength rather than a weakness cannot be evaluated. This may be the case, and I would welcome some set of experiments that establish this empirical claim by comparing against state-action-dependent baselines. The authors appear to believe that state-action-dependent baselines are never effective in reducing variance, and this is perhaps the central error in the paper that should be addressed. See response (3). Were the authors to fix this, they would necessarily compare against state-action-dependent baselines, which would be of great value for the community at large in settling this open issue.\n\n(3) Action-dependent baselines have not been shown to be ineffective. I wish to strongly emphasize that this is not the conclusion of the Mirage paper, and the claim repeated in the authors\' response (3) has not been validated empirically or analytically, and does not represent the state of variance reduction in reinforcement learning as of this note. I repeat a few key arguments from the Mirage paper in an attempt to dispel the authors\' repeated misinterpretation of the paper.\n\nThe variance of the policy gradient estimator, subject to a baseline ""phi,"" is decomposed using the Law of Total Variance in Eq (3) of the Mirage paper. This decomposition identifies a non-zero contribution from ""phi(a,s)"", the (adaptive or non-adaptive) baseline. The Mirage paper analyzes under what conditions such a contribution is expected to be non-negligible. Quoting from the paper:\n""We expect this to be the case when single actions have a large effect on the overall discounted\nreturn (e.g., in a Cliffworld domain, where a single action could cause the agent to fall of the cliff and suffer a large negative reward).""\nPlease see Sec. 3, ""Policy Gradient Variance Decomposition"" of the Mirage paper for further details.\nThe Mirage paper does indeed cast reasonable doubt on subsets of a few papers\' experiments, and shows that the strong claim, mistakenly made by these papers, that state-action-dependence is always required for an adaptive control variate to reduce variance over state dependence, is not true. \n\nIt should be clear from the discussion of the paper to this point that this does _not_ imply the even stronger claim in ""A Better Second Order Baseline"" that action dependence is never effective and should no longer be considered as a means to reduce variance from a practitioner\'s point of view. Such a misinterpretation should not be legitimized through publication, as it will muddy the waters in future research. I again urge the authors to remove this mistake from the paper.\n\n(4) I acknowledge the efforts of the authors to ensure that adequate background is provided for readers. This is a thorny issue, and it is difficult to balance in any work. Since this material represents a sizeable chunk of the paper and is nearly identical to existing published work, it leads me to lower the score for novelty of contribution simply by that fact. Perhaps the authors could have considered placing the extensive background materials in the appendix and instead summarizing them briefly in the body of the paper, leaving more room for discussion and experimental validation beyond the synthetic cases already studied in the DiCE paper.\n\n(5), (6) In my review I provided specific, objective criteria by which I have assessed the novelty of this paper: the lack of original written material, and the nearly identical experiments to the DiCE paper. As I noted in response (4) above, this reduces space for further analysis and experimentation.', 'In this paper, the author proposed a better control variate formula for second-order Monte Carlo gradient estimators, based on a special version of DiCE (Foerster et al, 2018).  The motivation and the main method is easy to follow and the paper is well written.  The author followed the same experiments setting as DiCE, numerically verifying the advantages of the newly proposed baseline, which can estimate the Hession accurately. \n\nThe work is essentially important due to the need for second-order gradient estimation for meta-learning (Finn et al., 2017) and multi-agent reinforcement learnings.  However, the advantage of the proposed method is not verified thoroughly. The only real application demonstrated in the paper, can be achieved the same performance as the second-order baseline using a simple trick.  Since this work only focuses on second-order gradient estimations, I think it would be better to verify its advantages in various scenarios such as meta-learning or sparse reward RL  as the author suggested in the paper.\n\nFinn, Chelsea, Pieter Abbeel, and Sergey Levine. ""Model-agnostic meta-learning for fast adaptation of deep networks."" ICML 2017.\nFoerster, Jakob, et al. ""DiCE: The Infinitely Differentiable Monte-Carlo Estimator."" ICML 2018.\n', 'Thank you for an interesting read.\n\nThis paper extends the recently published DiCE estimator for gradients of SCGs and proposed a control variate method for the second order gradient. The paper is well written. Experiments are a bit too toy, but the authors did show significant improvements over DiCE with no control variate.\n\nGiven that control variates are widely used in deep RL and Monte Carlo VI, the paper can be interesting to many people. I haven\'t read the DiCE paper, but my impression is that DiCE found a way to conveniently implement the REINFORCE rules applied infinite times. So if I were to derive a baseline control variate for the second or higher order derivatives, I would ""reverse engineer"" from the exact derivatives and figure out the corresponding DiCE formula. Therefore I would say the proposed idea is new, although fairly straightforward for people who knows REINFORCE and baseline methods.\n\nFor me, the biggest issue of the paper is the lack of explanation on the choice of the baseline. Why using the same baseline b_w for both control variates? Is this choice optimal for the second order control variate, even when b_w is selected to be optimal for the first order control variate? The paper has no explanation on this issue, and if the answer is no, then it\'s important to find out an (approximately) optimal baseline for this second order control variate. \n\nAlso the evaluation seems quite toy. As the design choice of b_w is not rigorously explained, I am not sure the better performance of the variance-reduced derivatives generalises to more complicated tasks such as MAML for few-shot learning.\n\nMinor:\n1. In DiCE, given a set of stochastic nodes W, why did you use marginal distributions p(w, \\theta) for a node w in W, instead of the joint distribution p(W, \\theta)? I agree that there\'s no need to use p(S, \\theta) that includes all stochastic nodes, but I can\'t see why using marginal distribution is valid when nodes in W are not independent.\n\n2. For the choice of b_w discussed below eq (4), you probably need to cite [1][2].\n\n3. In your experiments, what does ""correlation coefficient"" mean? Normalised dot product?\n\n[1] Mnih and Rezende (2016). Variational inference for Monte Carlo objectives. ICML 2016.\n[2] Titsias and Lázaro-Gredilla (2015). Local Expectation Gradients for Black Box Variational Inference. NIPS 2015.', 'This paper extends the ""infinitely differentiable Monte Carlo gradient estimator"" (or DiCE) with a better control variate baseline for reducing the variance of the second order gradient estimates.\n\nThe paper is fairly clear and well written, and shows significant improvements on the tasks used in the DiCE paper.\n\nI think the paper would be a much stronger submission with the following improvements:\n\n- More explanation/intuition for how the authors came up with their new baseline (eq. (8)). As the paper currently reads, it feels as if it comes out of nowhere.\n- Some analysis of the variance of the two terms in the second derivative in eq. (11). In particular, it would be nice to show the variance of the two terms separately (for both DiCE and this paper), to show that the reduction in variance is isolated to the second term (I get that this must be the case, given the math, but would be nice to see some verification of this). Also I do not have good intuition for which of these two terms dominates the variance. \n- I appreciate that the authors tested their estimator on the same tasks as in the DiCE paper, which makes it easy to compare them. However, I think the paper would have much more impact if the authors could demonstrate that their estimator allows them to solve new, more difficult problems. Some of these potential applications are discussed in the introduction, it would be nice if the authors could demonstrate improvements in those domains.\n\nAs is, the paper is still a nice contribution.']","[-60, 50, 50, 60]","[20, 75, 80, 80]","['The sentiment score is -60 because the reviewer does not recommend publication and identifies several significant issues with the paper, including incorrect assertions and lack of novelty. However, they do note some positive aspects like the paper being well-written. The politeness score is 20 because the reviewer uses generally professional language and acknowledges some strengths, but there are a few somewhat blunt criticisms. The reviewer provides detailed explanations for their critiques and offers constructive suggestions, which maintains a level of politeness despite the overall negative assessment.', ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the work and praises the paper's clarity and motivation. However, they also express concerns about the thoroughness of the method's verification. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language, constructive criticism, and positive acknowledgments. They begin with positive remarks, use phrases like 'I think it would be better,' and provide specific suggestions for improvement without harsh criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with a positive statement ('Thank you for an interesting read') and acknowledges the paper's contributions and potential interest to many people. However, they also point out significant issues, particularly regarding the choice of baseline and the toy-like nature of the experiments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'Thank you,' 'well written,' and 'can be interesting to many people,' which contribute to a polite tone. Even when pointing out issues, the reviewer maintains a professional and courteous demeanor, using phrases like 'For me, the biggest issue' rather than more confrontational language."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'fairly clear and well written' and mentions that it shows 'significant improvements'. They also state that it's 'a nice contribution'. However, it's not extremely positive as they suggest several improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their suggestions as improvements rather than criticisms. They use phrases like 'I think', 'I appreciate', and 'it would be nice' which maintain a courteous tone. The reviewer also ends on a positive note, reinforcing the politeness of the review.""]"
"['This paper proposes a new policy gradient method for reinforcement learning.\nThe method essentially combines SARAH and trust region method using Fisher information matrix.\nThe effectiveness of the proposed method is verified in experiments.\n\nSARAH is a variance reduction method developed in stochastic optimization literature, which significantly accelerates convergence speed of stochastic gradient descent.\nSince the policy gradient often suffers from high variance during the training, a combination with variance reduction methods is quite reasonable.\nHowever, this work seems to be rather incremental compared to a previous method adopting another variance reduction method (SVRG) [Xu+2017, Papini+2018].\nMoreover, the advantage of the proposed method over SVRPG (SVRG + policy gradient) is unclear both theoretically and experimentally.\n[Papini+2018] provided a convergence guarantee with its convergence rate, while this paper does not give such a result.\nIt would be nice if the authors could clarify theoretical advantages over SVRPG.\n\nMinor comment:\n- The description of SVRG updates in page 2 is wrong.\n- The notation of H in Section 3.1 (""ODE analysis"") is not defined at this time.\n', 'The paper extends Sarah to policy optimization with theoretical analysis and experimental study. \n\n1) The theoretical analysis under certain assumption seems novel. But the significance is unknown compared to similar analysis. \n\n2) The analysis demonstrates the advantage of Sarah over SVRG, as noted in Remark 1. It would be better to give explicit equations for SVRG in order for comparison.\n\n3) Experimental results seem to show empirically that the SARAH is only comparable to SVRG.\n\n4) Presentation needs to be improved. ', 'This paper investigates how the SARAH stochastic recursive gradient algorithm can be applied to Trust Region Policy Optimization. The authors analyze the SARAH algorithm using its approximating ordinary and stochastic differential equations. The empirical performance of SARAPO is then compared with SVRPO and TRPO on several benchmark problems.\n\nAlthough the idea of applying SARAH to reduce the variance of gradient estimates in policy gradient algorithms is interesting and potentially quite significant (variance of gradient estimates is a major problem in policy gradient algorithms), I recommend rejecting this paper at the present time due to issues with clarity and quality, particularly of the experiments.\n\nNot enough of the possible values for experimental settings were tested to say anything conclusive about the performance of the algorithms being compared. For the values that were tested, no measures of the variability of performance or statistical significance of the results were given. This is important because the performance of the algorithms is similar on many of the environments, and it is important to know if the improved performance of SARAPO observed on some of the environments is statistically significant or simply due to the small sample size.\n\nThe paper also needs improvements in clarity. Grammatical errors and sentence fragments make it challenging to understand at times. Section 2.3 seemed very brief, and did not include enough discussion of design decisions made in the algorithm. For example, the authors say ``""the Fisher Information Matrix can be approximated by Hessian matrix of the KL divergence when the current distribution exactly matches that of the base distribution"" but then suggest using the Hessian of the KL of the old parameters and the new parameters which are not the same. What are the consequences of this approximation? Are there alternative approaches?\n\nThe analysis in section 3 is interesting, but the technique has been applied to SGD before and the results only seem to confirm findings from the original SARAH paper.\n\nTo improve the paper, I would suggest moving section 3 to an appendix and using the extra space to further explain details and conduct additional simpler experiments. Additional experiments on simpler environments and policy gradient algorithms (REINFORCE, REINFORCE with baseline) would allow the authors to try more possible values for experimental settings and do enough runs to obtain more conclusive results about performance. Then the authors can present their results applying SARAH to TRPO with some measure of statistical significance.']","[-20, -20, -60]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution and its reasonable approach, they express concerns about its incremental nature compared to previous work and the lack of clear advantages over existing methods. The reviewer also points out missing theoretical analysis and some errors in the paper. However, the tone is not entirely negative, as they recognize the potential of the method and suggest improvements. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging the paper's merits and offering constructive criticism. They use phrases like 'It would be nice if...' and 'Minor comment:', which maintain a polite tone while providing feedback. The reviewer also balances criticism with positive observations about the paper's approach and experimental verification."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('novel', 'demonstrates advantage'), they also point out several limitations and areas for improvement. The overall tone suggests that the paper is not particularly impressive or groundbreaking. The politeness score is slightly positive (20) as the reviewer uses neutral language and offers constructive feedback without harsh criticism. They use phrases like 'It would be better' and 'needs to be improved' which are polite ways of suggesting changes. The review is professional and objective, avoiding overly negative or positive language."", 'The sentiment score is -60 because the reviewer recommends rejecting the paper due to issues with clarity and quality, particularly in the experiments. They point out several significant shortcomings, which indicates a negative sentiment. However, the reviewer does acknowledge that the idea is interesting and potentially significant, which prevents the score from being even lower. The politeness score is 50 because the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement and explain their concerns in detail without using harsh or dismissive language. The reviewer maintains a respectful tone while providing critical feedback, which is indicative of politeness in academic peer review.']"
"['The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes). \nAs in JMVAE (Suzuki et al., 2016) (which was not proposed for zero-shot learning), decoders are then used to reconstruct objects from the latent space to the input sources.\n\nMy main concerns are about novelty. The contribution of the paper is limited or not clear at all, even when reading Section C in the appendix. The proposed approach is a straightforward extension of JMVAE (Suzuki et al., 2016) where a loss function is added (Eq. (3)) to minimize the KL divergence between the outputs of the encoders (which corresponds to optimizing the same problem as most zero-shot learning approaches).\nThe theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero-shot learning approaches but with VAEs.\n\nConcerning experiments, Generalized Zero shot learning (GZSL) experiments seem to significantly outperform other methods, whereas results on the standard zero-shot learning task perform as well as state-of-the-art methods. \nDo the authors have an explanation of why the approach performs significantly better only on the GZSL task?\n\nIn conclusion, the contributions of the paper are mostly experimental. Most arguments in the model section are actually simply intuitions.\n\n\nafter the rebuttal:\nAfter reading the different reviews, the replies of the authors and the updated version, my opinion that the ""explanations"" are simply intuitions (which is related to AnonReviewer3\'s concern ""Regarding advantages of learning a joint model as opposed to unidirectional mappings"") has not been completely addressed by the authors. Fig. 4 does address this concern by illustrating their point experimentally. However, I agree with AnonReviewer3 that the justification remains unclear.', 'The paper proposes an approach to generalized zero-shot learning by learning a shared latent space between the images and associated class-level attributes. To learn such a shared latent space and mapping for the same which is generalized and robust -- the authors propose ‘modality invariant variational autoencoders’ -- which allows one to perform shared manifold learning by training VAEs with both images and attributes as inputs. Empirical results demonstrate improvements over existing approaches on the harmonic mean metric present in the generalized zero-shot learning benchmark. Other than the concerns mentioned below, I like the basic idea adopted in the paper to extend Vedantam et. al. (2018)’s joint-VAEs (supporting unimodal inference) to the framework of generalized zero-shot learning. The proposed approach clearly results in improvements over baselines and existing approaches.\n\nComments:\n- A minor correction. The paper claims the bias towards seen classes at inference for the existing GZSL approaches is due to the inability of obtaining training data for the unseen classes. In my opinion, this should be rephrased as the inability to learn a generalized enough representation (joint or otherwise) that is aware of the shift in distribution from seen to unseen classes (images or attributes) as this information is not available apriori.\n- Writing Clarity Issues. In general, there is significant repetitions along certain lines throughout the introduction and approach. While the paper overall does a good job of explaining the motivation as well as the approach, some of the sections (and sentences within) could be written better to express the point being made. Specifically, the first paragraph in the introduction seems to be structured more from a few-shot setting. The paper would benefit from talking about few-shot learning first and then extending to the extreme setting of zero-shot learning. Similarly, the second paragraph in the introduction could be written more succinctly to express the point being made. The sentences -- “Moreover, it is difficult….widely available” -- are difficult to understand. Tables 4 and 5 should be positioned after the references section.\n- A point repeatedly made in the paper suggests that learning unidirectional mappings from images to attributes (or otherwise) suffers from generalization to unseen classes. While I agree with this statement, most methods in GZSL hold out a subset of seen classes as validation (unseen) classes while learning such a mapping -- which I believe was also being done while learning the joint model in MIVAE (Can the authors confirm this? Is yes, how were these classes chosen?). As such, the authors should stress on the advantages learning a joint latent model over both modalities offers as opposed to unidirectional mappings while mentioning the above points.\n- Learning the joint latent space for images and attributes has been referred to as learning a shared manifold in the paper -- with associated terms such as manifold representation being used as well. Sharing a latent space need not imply learning an entire manifold as the subspace captured by the latent space might as well be localized in the manifold in which it exists. Can the authors comment more on this connection with respect to the points around “shared manifold learning”?\n- During inference, the authors operate in the latent space to find the most-relevant class by enumerating over all classes the KL-divergence between the unimodal encoder embeddings. Is there a particular reason the authors chose to operate in the latent space as opposed to operating in a modality space? Specifically, given an image the authors could have used the p(a|z) decoder to infer the attribute given the encoded z -- and subsequently finding the 1-nearest neighbor in that space. Any reason why this approach was not adopted? \n- On page 4, regarding the term L_dist in the objective for MIVAE, the authors draw the connections made in the appendix of Vedantam et. al. (2018) regarding the minimization of KL-divergence between the bimodal and a unimodal variational posterior(s). While the connection being made is accurate, the subsequent solution modes identified in the following paragraph -- “When equation 2 becomes minimum…” -- do not seem accurate. At minimality, unimodal encoders should be equivalent to the bimodal encoder marginalized over the absent rv under the conditional distribution of the data. Could the authors comment on whether the version presented in the paper is intended or is merely a typographical mistake?\nSection 5 experiments suggest the learning rate used in practice was 10^3. Assuming a typo, this should be presumably 10^-3.\n\nExperimental Issues. \n- The authors should explicitly mention if they are using the proposed split throughout all baselines and approaches for GZSL evaluations. It’s not explicitly mentioned in the text and is an important detail that should not be left out. Only the appendix mentions the number of seen/unseen classes.\n- How did the authors select a validation split (held out seen classes) to train MIVAE? Did they directly borrow the training and validation splits present in the proposed split? Or did they create a split of their own? If latter, how was the split created? In general, I am curious about how the MIVAE checkpoint for inference was chosen.\n- In section 5.2, the reasons in the 3rd paragraph elaborating \\lambda_map=1 vs 0 not being too different for AWA and aPY are not clear. Could the authors comment a bit more on them?\n\nThe authors adressed the issues raised/comments made in the review. In light of my comments below to the author responses -- I am not inclined towards increasing my rating and will stick to my original rating for the paper.', ""This paper proposes a multimodal VAE model for the problem of generalized zero shot learning (GZSL). In GZSL, the test classes can contain examples from both seen as well as unseen classes, and due to the bias of the model towards the seen classes, the standard GZSL approaches tend to predict the majority of the inputs to belong to seen classes. The paper proposes a multimodal VAE model to mitigate this issue where a shared manifold learning learn for the inputs and the class attribute vectors.\n\nThe problem of GZSL is indeed important. However, the idea of using multimodal VAE for ZSL isn't new or surprising and has been used in earlier papers too. In fact, multimodal VAEs are natural to apply for such problems. The proposed multimodal VAE model is very similar to the existing ones, such as Vedantam et al (2017), who proposed a broad framework with various types of regularizers in the multimodal VAE framework. Therefore, the methodological novelty of the work is somewhat limited.\n\nThe other key issue is that the experimental results are quite underwhelming. The paper doesn't compare with several recent ZSL and GZSL approaches, some of which have reported accuracies that look much better than the accuracies achieved by the proposed method. The paper does cite some of these papers (such as those based on synthesized examples) but doesn't provide any comparison. Given that the technical novelty is somewhat limited, the paper falls short significantly on the experimental analysis.""]","[-50, 50, -60]","[20, 75, 20]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the novelty and theoretical contributions of the paper, stating that 'the contribution of the paper is limited or not clear at all' and that 'the theoretical aspect of the method is limited'. However, they do acknowledge some positive experimental results, which prevents the score from being more negative. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding harsh language. They use phrases like 'My main concerns are' and 'Do the authors have an explanation', which are polite ways of expressing criticism and asking for clarification. The reviewer also acknowledges positive aspects of the work, showing a balanced approach. However, the overall critical nature of the review prevents the politeness score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the basic idea of the paper and acknowledges improvements over baselines, but also raises several concerns and issues. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g. 'The paper would benefit from...'), and balances positive and negative feedback. The reviewer also uses polite phrases like 'Can the authors confirm this?' and 'Could the authors comment more on this?' when requesting clarifications."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the idea isn't new or surprising, the methodological novelty is limited, and the experimental results are 'underwhelming'. They also mention that the paper falls short significantly on experimental analysis. However, it's not entirely negative as they acknowledge the importance of the problem. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'The problem of GZSL is indeed important' and avoid harsh or personal criticisms. The language is direct but maintains a respectful tone throughout.""]"
"['The proposed approach aims to mitigate catastrophic forgetting in continual learning (CL) problems by structure learning: determining whether to reuse or adapt existing parameters, or initialise new ones, when faced with a new task. This is framed as an architecture search problem, applying ideas from Differentiable Architecture Search (DARTS). The approach is verified on the Permuted MNIST dataset and evaluated on the Visual Decathlon, showing an improvement.\n\nI think this is an interesting idea with potential, and is worth exploring, and the paper is well-structured and easy to follow.\n\nUnfortunately, I feel the paper fails to consider recent work on CL, both in terms of discussion and benchmarking. The only previous work that is compared is EWC, on permuted MNIST, and the Visual Decathlon performance is only compared to simple baselines (such as adding an adapter or fine tuning) which makes it difficult to gauge the contribution.\nThere are recent works, some with better results on more difficult problems, such as Variational Continual Learning [1], Progress and Compress [2], or (Variational) Generative Experience Replay [3][4].\nGiven the approach is based on dynamically adding parameters or modules, Progressive Networks and Dynamically Expandable Networks (both cited) are especially relevant and should be compared (I believe the former may be related to the “adapter” baseline, but this should be made explicit).\n\nI have some questions / discussion points:\n- What\'s the intuition behind implementing the “adapt” operator as additive bias over the previous weights, rather than just copying the previous weights and fine tuning?\n- In the general case, if the architecture search is a continuous relaxation (softmax combination of operators), why is the ""adapt"" operator necessary? Wouldn\'t this already be a linear combination of new and old parameters? (In the example case of a 1×1 adaptor it makes sense, but this is a special restricted case which adapts with a smaller set of parameters)\n- How is the structure regulariser backpropagated into the parameters of each layer? As I understand, it is composed of a constant discrete term z (number of parameters in each option), multiplied by architecture softmaxes alpha; the gradient with respect to each alpha is a constant, and so this has the effect of scaling the gradients of each operator.\n- For the ""reuse - tuned"" case, isn’t the model effectively maintaining a new network for each task?\n\nI also have a number of other comments:\n- Reference to figure in page 6 should be figure 4, not 5.\n- I think the readability of the paper would benefit from another few proofreads; there are a number of grammatical issues throughout, and several sentence fragments, eg. in the top para of page 2: “..., it has the potential to encourage information sharing. Since now the irrelevant part can be handled…”.\n\nI would encourage the authors to strengthen the experimental comparison by incorporating stronger, external baselines, and improving some of the minor writing issues.\n\n[1] Nguyen, Cuong V., et al. ""Variational Continual Learning."" ICLR, 2018.\n[2] Schwarz, Jonathan, et al. ""Progress & Compress: A scalable framework for continual learning."" ICML, 2018.\n[3] Shin, Hanul, et al. ""Continual learning with deep generative replay."" NIPS, 2017.\n[4] Farquhar, Sebastian, and Yarin Gal. ""Towards Robust Evaluations of Continual Learning."" arXiv, 2018.', '\nThis paper proposes a new approach to mitigate the catastrophic forgetting for continual learning. The model is composed to the neural architecture search and parameter learning based on the intuition that largely different tasks should allow to use different network structure to train them. In structure learning, they introduce three candidate to decide network architecture, reuse, adaptation and new. In the experiments, they show that their model outperforms SGD and EWC.\n\nBasically, the intuition of structure learning and the validation of that is straight forward and easy to follow. However, I’m not sure that the proposed model can outperform the recent continual learning methods, such as IMM(Lee et al, 2017), DEN or  RCL(Ju Xu et al, 2018). There is only a relatively weak(and old) comparison with l2, and EWC.\n\n-\tIn the equation (4), I wonder that, in the model, the hyperparameter(lambda_i or beta_i) of regularizer looks different according to the task, is it correct?\n-\tAs shown in the Fig. 2) three choice-reuse, adaptation, and, new, is decided in the layer level. But with a semantic intuition, such that two different task can share specific features and simultaneously each of them requires the different neural space to learn discriminative ones at layer l, it seems better if the model could search structure much flexible. Is there some of experimental trial or plan about these kind of joint-adoption?\n-\tWhat is the main contribution of adaptation? I wonder that only reuse and new can work well including the role of adaptation, or not.\n-\tIs there any experiments to compare the recent continual learning methods(as I mentioned), in terms of AUC(or accuracy) and the network capacity?\n\nMinor remarks,\nPage 3: \t“is been” -> is\n\t“unlikely”-> unlike\nPage 4: \t“sharealbe” -> shareable\nPage 5: \t“, After” -> , after\n\t“permuated” -> permuted\nPage 6:\t“Fig. 5” -> Fig. 4\n\n', ""The paper considers the problem of sequential learning where data access for the previous tasks is completely prohibited. Authors propose a conceptually simple framework to learn structures (it is the selection of reusing, adapting previously learned layers or training new layers) as well as corresponding parameters in the sequential learning.\n\nThe paper is potentially interesting and providing possibly important framework for life-long learning. It is well written in most of cases and easy to follow (however I got the impression that the paper was rushed in the last minute; there are some trivial typos and very low resolution images etc.)\n\nHowever, I have a huge concern about the empirical evaluations.  This area is really huge and has attracted lots of interest from many researchers, meaning that we lots of methods to compare. Nevertheless, authors only focus on providing insights on effects of different components of the propose model. This is also critical but comparing against state-of-the-arts is also very important. Especially, comparing against Lee et al 2017 seems essential. I can see the difference against that paper from the authors' argument in the related work, but that is the difference not comparison. It would be great to compare the performances as well as the number of increased memory sizes as the number of task increases.\n\nMoreover, the details should be provided; for instance provide the explicit form of R(s). \n\n---------------------------------------------\n\nThanks for the update. But are they fair comparisons (evaluation only in terms of accuracy)? Different methods expand the network different amount. Hence, they should be compared on this metric too.""]","[-20, -20, -20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and potential, they express significant concerns about the lack of consideration for recent work and comparisons to stronger baselines. The reviewer also points out several issues and questions about the methodology. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I think,' 'I feel,' and 'I would encourage' to soften their critiques. The reviewer also provides specific suggestions for improvement and additional references, which is helpful and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('intuition... is straight forward and easy to follow'), they express significant doubts about the model's performance compared to recent methods and point out several areas for improvement. The overall tone suggests the paper needs substantial work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions ('I wonder that...', 'Is there...'), and offers constructive feedback. They also provide helpful minor remarks for improving the paper. The language is professional and avoids harsh or dismissive statements, maintaining a courteous tone even when expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'potentially interesting' and 'well written in most cases', they express a 'huge concern about the empirical evaluations' and point out several areas for improvement. The lack of comparison with state-of-the-art methods and the need for more details are significant criticisms. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and phrases suggestions politely (e.g., 'It would be great to...', 'Thanks for the update'). The reviewer maintains a professional tone even when expressing concerns.""]"
"['This paper proposed a LBPNet for character recognition, which introduces the LBP feature extraction into deep learning. Personally I think that this idea is interesting for improving the efficiency of CNNs, as traditionally LBP has been demonstrated its good performance and efficiency in some vision tasks such as face recognition or pedestrian detection. However, I do have the following concerns about the paper:\n\n1. Calculation/Implementation of Eq. 4: I do not quite understand how it derived, and how to use Eq. 3 in calculation. I suggest the authors to explain more details, as this is the key for implementation of LBP layers.\n\n2. Effects of several factors on performance in the experiments are missing: (1) random projection map in Fig. 5, (2) $k$ in Eq. 2, and (3) the order of images for computing RHS of Eq. 3. In order to better demonstrate LBPNet, I suggest to add such experiments, plus training/testing behavior comparison of different networks. \n\n3. Does this network work with more much deeper?\n\n4. Data: The datasets used in the experiments are all well-aligned. This makes me feel that the RHS of Eq. 3 does make sense, because it will capture the spatial difference among data, like temporal difference in videos. How will the network behave on the dataset that is not aligned well, like affnist dataset?\n\n5. How will this network behave for the applications such as face recognition or pedestrian detection where traditionally LBP is applied?\n', 'In this work, a neural network that uses local binary patterns instead of kernel convolutions is introduced. Using binary patterns has two advantages: a) it reduces the network definition to a set of binary patterns (which requires much less storage than the floating point descriptions of the kernel weights used in CNNs) and b) allows for fast implementations relying only on logical operations (particularly fast on dedicated hardware).\n\nThis work is mostly descriptive of a proposed technique with no particular theoretical performance guarantees, so its value hinges mostly on its practical performance on real data. In that sense, its evaluation is relatively limited, since only figures for MNIST and SVHN are provided.\n\nA list of additional datasets is provided in Table 5, but only the performance metric is listed, which is meaningless if it is not accompanied with figures for size, latency and speedup. The only takeway about the additional datasets is that the proposed LBPNet can match or outperform a weak CNN baseline, but we don\'t know if the latter achieves state-of-the-art performance (previous figures of the baseline CNN suggest it doesn\'t) and we don\'t know if there\'s significant gain in speed or size.\n\nRegarding MNIST and SVHN, which are tested in some more detail, again, we are interested in the performance-speed (or size) tradeoff, and it is unclear that the current proposal is superior. The baseline CNN does not achieve state of the art performance (particularly in SVHN, for which the state-of-the-art is 1.7% and the baseline CNN achieves 6.8%). For SVHN, BCNN has a much better performance-speed tradeoff than the baseline, since it is both faster and higher performance. Then, the proposed method, LBPNet, has much higher speed, but lower performance than BCNN. It is unclear how LBPNet\'s and BCNN\'s speeds would compare if we were to match their performances. For this reason, it is unclear to me that LBPNet is superior to BCNN on SVHN.\n\nAlso the numbers in boldface are confusing, aren\'t they just incorrect for both the Latency and Error in MNIST? Same for the Latency in SVHN.\n\nThe description of the approach is reasonably clear and clarifying diagrams are provided. The backpropagation section seems a bit superficial and could be improved. For instance, backpropagation is computed wrt the binary sampling points, as if these were continuous, but they have been defined as discrete before. The appendix contains a bit more detail, where it seems that backpropagation is alternated with rounding. It\'s not justified why this is a valid gradient descent algorithm.\n\nAlso how the scaling k of the tanh is set is not explained clearly. Do you mean that with more sampling points k should be larger to keep the outputs of the approximate comparison operator close to 0 and 1?\n\nMinor:\n\nWhat exactly in this method makes it specific to character recognition? Since you are trying to capture both high-level and low-level frequencies, it seems you\'d be capturing all the relevant information. SVHN data are color images with objects (digits) in it, what is the reason that makes other objects not be detectable with this approach?\n\nEnglish errors are pervasive throughout the paper. A non-exhaustive list:\n\nFig 4.b: X2 should be Y2\nparticuarly\n""to a binary digits""\n""In most case""\n""0.5 possibility""\n""please refer to Sec ..""\n""FORWARD PROPATATION""', '1. The paper introduces the idea of some existing hand-crafted features into the deep learning framework, which is a smart way for building light weighted convolutional neural networks.\n\n2. I have noticed that binary patterns used in the paper are trainable, which means that these binary patterns can be seen as learned convolution filters with extremely space and computational complexity. Thus, the proposed method can also be recognized as a kind of binary network. \n\n3.  The baseline BCNN has a different architecture to the network using the proposed method. Thus, comparisons shown in Table 3 and Table 4 are somewhat unfair.\n\n4. The capability of the proposed method was only verified on character recognition datasets. Does it can be easily used for other tasks such as face recognition or object detection on some relatively large datasets?']","[20, -30, 20]","[60, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the interesting idea of the paper and its potential for improving CNN efficiency. However, the bulk of the review consists of concerns and suggestions for improvement, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions ('I suggest...') and personal opinions ('Personally I think...'). The reviewer also acknowledges the potential merits of the work before listing concerns. The language is professional and constructive, avoiding harsh criticism while still clearly communicating areas for improvement."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects of the work (e.g., 'The description of the approach is reasonably clear'), they express several significant concerns and limitations. These include limited evaluation, unclear superiority to existing methods, and issues with the backpropagation explanation. The reviewer also points out errors in the paper and suggests areas for improvement, indicating an overall critical stance.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'it is unclear to me' and 'could be improved' rather than harsh criticisms. The reviewer also provides specific suggestions and asks clarifying questions, which is a polite way to address concerns. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, objective tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's smart approach in the first point and recognizes the method's potential in the second point. However, the reviewer also raises concerns about the fairness of comparisons and the limited scope of verification, which tempers the overall positivity. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms as observations or questions rather than direct attacks. Phrases like 'I have noticed' and 'Does it can be easily used' indicate a polite, inquiring tone rather than a harsh critique.""]"
"['The main context for this paper is two recent publications: Giusti et al.’s ""A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots” (2016) and Smolyanskiy et al.’s ""Toward Low-Flying Autonomous MAV Trail Navigation using Deep Neural Networks for Environmental Awareness” (2017). \n\nGiusti introduced a dataset of trail images (later called the “IDSIA dataset”) acquired by having a hiker wear three head-mounted cameras. The forward facing image is associated with a label “go straight”, whereas the two side images are associated with labels for “go left” and “go right”. Giusti then trained a convolutional neural network to predict these labels and used the network to guide a ""quadrotor micro aerial vehicle”. \n\nSmolyanskiy improves on Giusti’s work by (1) gathering additional trail image data using three cameras mounted to face forward but with lateral offsets and (2) using this additional data to train a 6 output neural network (“Trailnet”) which predicts both view orientation and lateral offset. In addition, they also combined predicted pose relative to the trail with predictions of localized objects and a depth map for potential obstacles. They compared several neural network architectures for predicting the view angle on the IDSIA data as well as the closed-loop performance of each network in avoiding collisions while operating within a UAV on a previously unseen trail. Though Trailnet did not achieve the highest accuracy (84% vs. the max 92% achieved by ResNet-18), it was the only network that achieved 100% collision avoidance on their UAV test course. \n\nThis paper, ""A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS”, attempts to evaluate two potentially better convolutional neural networks for UAV trail guidance. They fine tune pertained Inception-Resnet and MobileNet models to predict the IDSIA dataset. These then both achieve better accuracy on the IDSIA test set and were analyzed for inference time and power consumption. These two models are then run through a single simulated path, where both seem to perform adequately across 2 turns in the path. \n\nThis paper has a variety of essential flaws.\n\n1. A large portion of the text is devoted to their hardware and UAV control but they were not able to actually run models on a physical UAV ""due to a hardware bug we were facing with the FCU”. \n2. The paper claims to ""introduce to the best of our knowledge, a very first comparative study of three algorithms in order to find a better motion control of a drone for detecting a trail”. This is a confusing claim since a comparison of neural network architectures is a central part of the evaluation in the Smolyanskiy paper. \n3. The higher accuracy on view orientation does not seem relevant since it was also achieved by Smolyanskiy et al. with networks that they then showed performed worse when combined with object detection, obstacle depth inference and combined controller.\n4. The sentence ""An important goal of our method is to demonstrate the effectiveness of low cost systems for the complex task of flying an autonomous drone” appears to have been plagiarized from “Learning to Fly by Crashing” (2017) which contains ""A important goal of our method is to demonstrate the effectiveness of low cost systems for the complex task of flying in an indoor environment”. ', 'The paper initiates a comparison between different SOTA convolutional neural networks for UAV trail guidance with the goal of finding a better motion control for drones. They use a simulator (but not a physical UAV)  to perform their experiments, which consisted on evaluating tuned versions of Inception-Resnet and MobileNet models using the IDSIA dataset, achieving good results in the path generated.  \n\nI think that the authors have perform an interesting evaluation framework, although not novel enough according to the literature. It is also great that the authors have included an explicit enumeration of all the dimensions relevant for their analysis (which are sometimes neglected), namely, computational cost, power consumption, inference time and robustness, apart from accuracy. \n\nHowever, I think the paper is not very well polished: there are quite a lot of grammatical, typing and aesthetic errors. Furthermore, the analysis performed is an A+B approach from previous works (Giusti et al.2016, and Smolyanskiy et al, 2017) and, thus, it is hard to find the novelty here, since similar comparisons have been already performed. Therefore, the paper needs major improvements in terms of clarity regarding the motivations in the introduction.\n\nAlso, one third of the paper is devoted to the software and hardware architecture used in the study, which I think it would be better fitted in an appendix section as it is of no added scientific value. Another weakpoint is that the authors were unable to run their DNN models on a physical drone in real time due to a hardware bug... I think the paper would benefit from a more robust (real) experimentation since, as they are, the presented results and experiments are far from conclusive.', 'Summary:\n\nThis paper considers the task of trail navigation task recently explored by Giusti et al. and Smolyanskiy et al. The authors describe their setup for physical experiments with a drone, and compare three neural network architectures for trail navigation on the IDSIA dataset. Experiments in a simulator are also reported.\n\n\nGood aspects of the paper:\n\nThe pairing of simulation with trail navigation is an interesting idea, though it is not explored much in this paper.\n\n\nBad aspects of the paper:\n\nAlthough the presence of physical experiments is suggested by pages 3 and 4, there are no physical experiments actually reported in the paper. In Section 5, this is revealed to be due to a hardware bug. The authors should not include these descriptions if they are not tied to reported experiments.\n\nOne of the main contributions of the paper is stated to be the comparison between neural network architectures. The two architectures compared to the TrailNet model from Smolyanskiy et al. are selected for their performance on the ImageNet classification task, and are shown to outperform TrailNet on salient metrics. However, comparing only three architectures is a very small comparison, and is not much of a contribution to the research problem.\n\nThis paper does not introduce new methods for approaching the problem of trail navigation. In its current form, it is a small comparison of existing classification architectures on the IDSIA dataset.\n\nThe paper also contains a number of minor errors. For instance, in Table 2 there is a footnote that leads nowhere, “introduced in Sif” is cited incorrectly, “in recent times jet (2014)” is cited incorrectly, and the figures are grainy (this isn’t really an error, but do try to make figures crisp in the future, e.g. with pdf images).']","[-70, -20, -60]","[-20, 50, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'a variety of essential flaws' and proceeds to list four major issues, including inability to run models on a physical UAV, questionable claims of novelty, irrelevance of higher accuracy results, and potential plagiarism. These criticisms significantly outweigh any positive aspects mentioned. The politeness score is -20 because while the reviewer maintains a professional tone overall, the language becomes increasingly critical and direct, especially when pointing out flaws. The use of phrases like 'essential flaws' and the direct accusation of plagiarism contribute to a somewhat impolite tone. However, the review isn't overtly rude, maintaining some level of objectivity in its critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting evaluation framework', 'great that the authors have included an explicit enumeration'), they also point out several significant shortcomings. These include lack of novelty, poor polish, and the need for 'major improvements'. The overall tone suggests the paper needs substantial work.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think' to soften criticisms and acknowledge positive aspects before presenting negative points. However, they don't go out of their way to be overly polite or complimentary, maintaining a balanced, objective tone typical of academic reviews."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges some good aspects (like the pairing of simulation with trail navigation), it lists several significant criticisms. These include the lack of reported physical experiments despite their description, the limited scope of the neural network architecture comparison, and the absence of new methods for trail navigation. The reviewer also points out minor errors in the paper. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'Good aspects of the paper' and 'Bad aspects of the paper' to organize their thoughts, and provide constructive feedback such as suggesting to make figures crisp in the future. The language is not overly harsh or personal, but rather focuses on the content of the paper itself.""]"
"['=== Post-rebuttal update ===\n\nThe authors\' rebuttal provided many of the details I was seeking. I asked a few additional questions which were also recently addressed, and I encourage the authors to include these clarifications into the final draft of the paper.\n\nHence, I\'ve increased my score for this paper.\n\n=== Pre-rebuttal review ===\nThis paper presents a meta-learning approach to zero-shot learning. The idea is to train a correction module which is trained to produce a correction to the output of a previously trained task module. The hypothesis is that the correction should depend on the nature of the training data of the task module, and so the correction module receives as input a representation of the training data of the task module. An episodic approach is then used for training the correction module, whereby many different task modules are trained on various subsets of the total training data, the rest being used as unseen data for the correction module.\n\nThe proposed idea is original and the results are strong. Generally, I\'d be inclined to see this paper published.\n\nHowever right now, the paper lacks A LOT of details on how the experiments were run. I would like to see these answered in the rebuttal, before I consider raising my rating for this paper:\n- What are the architectures used for M_T and M_C?\n- What distance functions was used for training?\n- What optimizer was used for training?\n- How was convergence established in the inner and outer while loops of algorithm 1?\n- Text mentions that before evaluation, M_T is trained on all data in D_S. How is this done exactly (e.g. how is convergence assessed)?\n- How is the T_S computed exactly?\n- How expensive is it to run Algorithm 1 (i.e. to train the correction module)? Since a new task module M_T needs to be trained for each subset S^s, it seems like it might be expensive to run... if not, why?\n\nI would also strongly suggest the authors release their code if this paper ends up being published.\n\nIn summary:\n\nPros\n- Claims SOTA results on two good benchmarks for zero-shot learning\n- Approach is original\n\nCons\n- Paper lacks a lot of methodological and experimental details\n\nSome minor details:\n\n- ""We found the task module performance improves slightly when the output of the task module is feed into a classifier with a single hidden layer that is also trained to classify samples from the task model’s training dataset."" => I don\'t understand what this means. Isn\'t the output of the task module already trained to classify samples from its training dataset? So why is this additional single hidden layer needed?\n- Typos:\n  - on few shot learn => on few shot learning\n  - but needs not => but need not\n  - image image classification => image classification\n  - the the compatibility => the compatibility\n  - psuedo => pseudo\n  - ""The task module is trained to minimize"" => that reads like an unfinished sentence\n  - \\hat{\\mu}_U \\hat{\\mu}_U => \\hat{\\mu}_U \n  - inputted => input\n  - FOr => For\n  - it\'s inputs => its inputs\n  - otherhand => other hand', 'This paper presents an interesting idea by formulating the problem of zero-shot learning in a meta-learning framework.  Specifically, the proposed model consists of two components: the task module and the correction module, where the former module learns to map the text description of a class to the sample mean and the latter one updates the predictions for unseen classes.   \n\nThe presentation of this paper is very poor.  Proposed meta-framework has some flaws. And, the experiments are not persuasive enough to demonstrate the significance of the proposed framework.  \n\nThe proposed zero-shot classifier is based on the nearest centroid.   Authors formulate the learning problem as mapping the text description of each class to sample mean of the data of the class.   Within a meat-training instance, the training performance is based on L2 distance between the mapped mean and the sample mean of each class.   This setup is wired.  This because, no matter how many data (x, y pairs) we get, the proposed method only makes the prediction based on the pre-calculated mean.  In other words, the ""number of samples"" in a meta-training dataset becomes the number of unique classes appears in training.    For instance, if we have 10 classes in the $D_\\mathcal{S}$, and10000 samples per class,  the proposed setup will consider the meta training only consist of 10 data points.   \n\nIn addition, the proposed method heavily rely on the feature extractor of the image.  The classification performance could be poor if two the mean of different classes close to each other.    Even they are not, the proposed framework cannot provide sample-level generalization.  \n\nAnother confusion I have is why the training of the task module is not based on a fixed correction module?   \n\nThe experiments also have many problems.  Authors need to clearly state how they construct meta-training, validation and testing instance.   Since the proposed framework is a meta-framework, authors need to report their performance in different meta-train/test splits.  The conventional split of CUB and NAB is only considered as a single split.  How well the proposed framework generalizes to other meta splits?     How well the proposed method performance to a generalized zero-shot setting?  \n\nThere are many typos.  Auhtors definitely need to improve their writing and the layout of the paper. \n\n\n\n', 'Summary: This paper proposes a “meta-learning” approach for zero-shot learning. There is a Task Module that works in a conventional zero-shot way: Training to predict a class prototype using the auxiliary/text data description of that task. The new part is the added Correction Module that inputs both the target/zero-shot task description, the training task description, and the current prediction of the task module, and then outputs a correction vector that is added to the output of the task-module to produce the final output. The resulting system achieves state of the art results on zero-shot fine-grained classification (CUB and NAB).\n\nAssessment: Overall this might be a good idea worthy of publication at some point. But despite the good results, the current realisation is not well analysed about exactly how and why it works, with no insight being provided; and leaves some doubt about the validity of the comparative experiments. The writing is also very rushed. It is not ICLR standard yet.\n\nStrengths:\n+ Interesting idea overall.\n+ Good results.\nWeaknesses:\n- Poor clarity. \n- Some experimental evaluation questions. \n- Poor analysis.\n\nComments:\n1. The correction module inputs the full set of training features T_s (Alg1-L13). However the training dataset is fixed, therefore this input is effectively a constant. So its not clear how a constant input can possibly be useful. \n1.1 Possibly this has something to do with the episodic training, but this is exactly the kind of thing that should be analysed and explained, but is not discussed at all.\n2. The paper is sold as a meta-learning paper, but it’s not clearly explained what is the “meta” part of the algorithm.\n3. Its not explained anywhere how exactly the T_s, T_s^u, etc are fed into the correction network. Is it average pooling? It seems that simple average pooling is unlikely to be adequate given the large number (150) of classes in CUB.\n4. There are no experimental details such as hyper parameters, network architecture, etc.\n5. Based on the ablation study (Tab 2), the baseline task network without correction network already achieves state of the art results. Conceptually the task-network alone is a very standard “regression” based approach to ZSL of the type that people tried almost 10 years ago. So what is the explanation for why its so good? This makes the comparison to all the competitors in Tab1 suspect. If there is some reason (E.g., better image feature extractor or pre/post-processing) that makes the ultra simple baseline there already outperform SotA, then you have to ask how all the prior methods would perform if they were run with the same tweak. \n6. Overall no insight provided about what kind of corrections are made, when they are useful, etc. This is important to provide insight about how/why correcting outputs can work.\n7. There is nothing particularly unique about this setup for ZSL. It could equally be applied to correct outputs in the case of few-shot learning (CF: Prototype Networks). It would be more convincing if it was applied to both settings and analysed better for both.\n8. The writing is very rushed. There are lots of writing and editorial errors. To name a few: P4 Extra “Task module is trained to minimise.” P4 “\\mu_u” Is repeated. Citation style “Mohamed Elhoseiny & Elgammal” is wrong, check the bibtex.\n']","[20, -60, -50]","[60, -20, 20]","[""Sentiment score (20): The review starts with a positive tone, acknowledging the originality of the idea and strong results. The reviewer is 'inclined to see this paper published'. However, they express significant concerns about missing details, which lowers the overall sentiment. The post-rebuttal update indicates an increase in score, suggesting an improvement in sentiment, but the specific increase is not quantified.\n\nPoliteness score (60): The reviewer maintains a professional and respectful tone throughout. They use polite language such as 'I'd be inclined to see this paper published' and 'I would like to see these answered'. The reviewer provides a balanced view, listing both pros and cons. They offer constructive criticism and specific suggestions for improvement, which is considerate. The use of 'please' in requesting code release also adds to the politeness. However, the directness in pointing out the lack of details ('the paper lacks A LOT of details') slightly reduces the politeness score from being very high."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges an 'interesting idea' at the start, it quickly shifts to criticizing the paper's presentation, methodology, and experiments. Phrases like 'very poor', 'has some flaws', and 'not persuasive enough' indicate a strongly negative sentiment. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite blunt and critical. The use of phrases like 'This setup is wired' and pointing out 'many typos' without softening the criticism shows a lack of politeness. However, it's not extremely impolite, as it does focus on the work rather than personal attacks."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths ('Interesting idea overall', 'Good results'), the overall tone is critical. The reviewer states that the paper is 'not ICLR standard yet' and lists several significant weaknesses and concerns. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'might be a good idea' and 'Overall this might be a good idea worthy of publication at some point', which soften the criticism. However, the reviewer is also direct in pointing out flaws, which prevents a higher politeness score. The reviewer provides constructive feedback and specific points for improvement, which is polite in academic contexts, but doesn't use overtly polite language or praise excessively.""]"
"['AFTER REBUTTAL:\nI think that in its current version the paper is not yet ready for publication. Several issues have been raised by fellow reviewers as well. I think that they are not trivial and they regard key aspects like paper structure, quality of exposition and experimental analysis. I have detailed my initial opinion in response to the author request for more details.  I hope this will serve as useful  guidelines for improving the paper in the future. \n\n------------\nThe method tackles the problem of interpretability that is a very important issue for usually black-box deep networks. Unfortunately it is not very clear how is the achieved. I have read several times the part explaining the influence maps and the clustering based on them and it still doesn\'t make a lot of sense to me. I think that part has to be better justified and exposed. Moreover, results do not support the claim which makes me doubt even more about how effective the method proposed actually is. In conclusion, I think that better exposition and more solid experimental analysis is needed.  \n\nAlso please check some writing problems: \n\n> Introduction: \n""to acquire a generative function mapping a latent space (such as Rn)"" >  difficult to read, rephrase. \n""making it difficult to add human input"" > confusing. What do you mean by human input? I assume you refer to having control to make decisions about design. \n\n> Section 3.1\n""the internal variable may leave the manifold it is implicitly embedded in as a result of the model’s training"" : not clear, rephrase. \n\n', 'This paper proposes to examine generative adversarial networks by using counterfactual reasoning. The authors propose to examine modularity through the lens of interventions on the generative networks. After observing that the nodes within the generative network obey a deterministic relationship, they propose a proxy for intervention which takes samples and creates “hybrid” samples by replacing the activation output of one sample with the others. Given the vast number of nodes that exist within a generative network, the authors propose a heuristic for choosing the nodes to perturb. \n\nI found the underlying premise of this paper to be very strong (identifying modularity in generative networks), however I think there is a substantial amount of work that should go into this paper before acceptance. While the authors begin by working within the framework of causal reasoning there is no mention of what the effect is that they are seeking to measure, i.e. what is the causal estimand here? The influence maps provide an intuitive answer to this, but not one that defines a clear estimand. I would like to see additional evaluation. The evidence provided largely leaves the reader to interpret results subjectively, rather than providing clear evidence. I was also uncomfortable with the selection on hyperparameters (3 clusters). It would be very nice to either have a selection criterion or show the sensitivity of the proposed methodology to other choices. \n\nOverall, I think this is an interesting idea in a very important area, but one that is not quite ready for publication.\n\nSome editorial comments:\n\nThe layout of this paper is slightly strange. After the introduction, the authors introduce the notion of disentanglement and lead with an example from optics. This motivation should either be moved to the introduction or removed. After the definitions the authors jump into a related work section that feels slightly disjointed from the previous section.\n\nI found definition 1 to be abstruse. In addition there are a couple of typos that should be addressed (“consists in a distribution” → “consists of a distribution”). It is non-standard to lead with the latent variables. I think it makes for a much easier narrative to describe the observed variables and structure first, before carrying on to the latent variables. Additionally, I believe you are stating an observation made by Pearl (2001) that after observing the noise variable, relationships become deterministic. This is slightly non-obvious from the wording used (and is also missing the proper reference).\n\nParens are missing from the following citation:\n“generative models encountered in machine learning Besserve et al. (2018).”  → “generative models encountered in machine learning (Besserve et al., 2018).” ', 'The work provides a way to investigate the modular structure of the deep generative model. The key concept is the “distribute over channels of generator architectures”. \nstrong points:\n1) using the causality to investigate the modular of the deep generative model. \n2) the key concept is interesting and straightforward. \n3) the observations in the experiments are interesting. \n\nBut I have the following concerns, \n1) the concept of counterfactual is consistent with that in the causality context? \n2) more details of the causal model of the deep learning are needed,\n3) more details of section 3.1 and 3.2 are needed, especially why these processes are proper interventions?  ']","[-70, -30, 50]","[20, 50, 75]","[""The sentiment score is -70 because the reviewer clearly states that the paper is not ready for publication and points out several significant issues with the paper, including problems with structure, exposition, and experimental analysis. The reviewer also expresses doubt about the effectiveness of the proposed method and states that the results do not support the claims made. However, it's not entirely negative as the reviewer acknowledges the importance of the topic and offers suggestions for improvement.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They offer hope for future improvement and frame their criticisms as 'guidelines for improving the paper'. The reviewer also uses polite phrases like 'I think' and 'I hope this will serve as useful guidelines'. However, the directness of some criticisms and the overall negative assessment prevent a higher politeness score."", ""The sentiment score is -30 because while the reviewer finds the premise strong and interesting, they express significant concerns about the paper's readiness for publication. They mention substantial work needed, lack of clear causal estimand, insufficient evaluation, and issues with hyperparameter selection. The overall tone is more negative than positive, but not extremely negative.\n\nThe politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths and potential importance of the topic. They offer constructive criticism and specific suggestions for improvement. The tone is professional and helpful, avoiding harsh or dismissive language. However, it's not overly effusive or extremely polite, maintaining a balanced, objective stance."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting strong points of the work, indicating appreciation for the research. However, they also express several concerns, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the strengths before presenting concerns. They phrase their criticisms as questions or requests for more information rather than direct criticisms. The use of phrases like 'But I have the following concerns' maintains a professional and courteous tone while providing constructive feedback.""]"
"['This paper presents an empirical analysis of the convergence of deep NN training (in particular in language models and speech).\n\nStudying the effect of various hyperparameters on the convergence is certainly of great interest. However, the issue with this paper is that its analyses are mostly *descriptive*, rather than conclusive or even suggestive. For example, in Figure 2, it is shown that the convergence slope of Adam is steeper than that of SGD, when the x-axis is the model size. Very naturally I would be interested in a hypothesis like “Adam converges quicker than SGD as we increase the model size”, but there is no discussion like that. Throughout the paper there are many experimental results, but results are presented one after another, without many conclusions or suggestions made for practice. I don’t have a good take-away after reading it.\n\nThe writing of this paper also needs to be improved significantly. In particular, lots of statements are made casually without justification. For example,\n\n“If hidden dimension is wide enough to absorb all the information within the input data, increasing width obviously would not affect convergence” -- Not so obvious to me, any reference? \n\n“Figure 4 shows a sketch of a model’s convergence curve ...” -- it’s not a fact but only a hypothesis. For example, what if for super large models the convergence gets slow and the curve gets back up again?\n\nIn general, I think the paper is asking an interesting, important question, but more developments are needed from these initial experimental results.', 'Understanding the effects of over-parametrization in neural network training has been a major challenge, albeit a lot of progress has been made in the past few years. The present paper is another attempt in this direction, with a slightly different point of view: the work characterizes the impact of over-parametrization in the number of iterations it takes an algorithm to converge. Along the way, it also presents further empirical observations such as the distance between the initial point and the final point and the angle between the gradients and the line that connects the initial and final points. Even though the observations presented are very interesting, unfortunately, the paper doesn\'t have the level of rigor required that would make it a solid reference. \n\nThe work presents its results somewhat clearly in the sense that one can simply reconstruct to probe in order to replicate the observations. This clarity is mainly due to the simplicity of the questions posed. There is nothing inherently wrong with simple questions, in fact, the kind of questions posed in the present paper are quite valuable, however, it lacks detailed study and rigor of a strong empirical work. Furthermore, the style of the exposition (anecdotal) and several obvious typos make the work look quite unfinished. \n\nHere are some flaws and suggestions that would improve the work substantially:\n- A deeper literature review would help guide the reader put the paper in a better context. Especially, the related work section is quite poor, how exactly do those papers appear related to the present work? Do they support similar ideas or do they propose different perspectives?  \n- The exposition should be made more to the point and concise (for instance 3rd paragraph of section 4.3 where it starts with Figure 5(a) What\'s meant by over-fitting regime, is it worse gen error, is it merely fitting tr data?.. How do we ""know"" from Figure 2, what\'s a strong evidence? Some concepts such as the capacity do not have precise and commonly agreed upon definitions, the paper uses those quite a bit and sometimes only later on the reader understands what it actually refers to... The misalignment section is also quite unclear.)\n- The observations can be formalized and the curve fitting should be explained in further detail, the appendix touches upon simple cases but there is a strong literature behind those simple cases that could be quite useful for the purposes of the paper. \n- The authors have a lot of data available at no point the power law decay and exponent fitting are discussed. For a paper whose main point is this precise scaling, this looks like a major omission unless there is a specific reason for it (other than the hardness of fitting exponents to power laws). Merely showing the observables in a log-log plot weakens the support of the main claims.\n- The theoretical argument provided is just an elementary observation whose assumptions and conditions are not discussed. It is not a straightforward task, for instance, a suggestion for a theoretical result on the distance between the initial and final weights is presented here: Lemma 1 A.3 https://arxiv.org/abs/1806.07572 (distance shrink as the number of parameters increase consistent with the observations of the present paper) (note that this is in addition to the several early-2018 mean field approximations to NNs whose solutions are found in the limit where the number of  parameters tend to infinity)\n- All the figures from 5 to 8 are presented very quantitatively such as looking at different layers and observing the percentage reductions. The message one can gain from such presentations are extremely limited and not systematic. I encourage the authors to formulate solid observables that can and should be tested in further detail. \n\nEven though the paper is touching upon very interesting questions, at its current stage, it is not a good fit to be presented in a conference as it only presents anecdotal evidence. There is a lot of room to improve, but the good news is that most of the improvement should be straightforward.\n', 'This paper discusses the effect of increasing the widths in deep neural networks on the convergence of optimization. To this end, the paper focuses on RNNs and applications to NLP and speech recognition, and designs several groups of experiments/measurements to show that wider RNNs improve the convergence speed in three different aspects: 1) the number of steps taken to converge to the minimum validation loss is smaller; 2) the distance from initialization to final weights is shorter; 3) the step sizes (gradient norms) are larger. This in some sense complements the theoretical result in Arora et al. (2018) for linear neural networks (LNN), which states that deeper LNNs accelerates convergence of optimization, but the hidden layers widths are irrelevant. This also shows some essential difference between LNNs and (practical) nonlinear neural networks. \n\n### comments about writing ###\nThe findings are in general interesting and inspiring, but the explanations need some further improvement. In particular, the writing lacks some consistency and clarity in the wordings. For example, it is unclear to me what ""weight space traversal"" means, ""training size"" is mixed with ""dataset size"", and ""we will show that convergence ... to final weights"" seems to be a trivial comment (unless there is some special meaning of ""convergence rate""), etc. It also lacks some clarity and organization in the results -- some more summarizing comments and sections (and in particular, a separate and clearer conclusion section), as well as less repetitions of the qualitative comments, should largely improve the readability of the paper.\n\n### comments about results ###\nThe observations included in the work may kick off some interesting follow-up work, but it is still a bit preliminary in the following sense:\n1. It lacks some discussions with its connection to some relevant literature about ""wider"" networks (e.g., Wide residual networks, Wider or deeper: revisiting the ResNet model for visual recognition, etc.).\n2. It lacks some discussions about the practical implication of the improvement in optimization convergence with respect to the widening of the hidden layers. In particular, what is the trade-off between the validation loss increase and the optimization convergence speed-up resulted from widening hidden layers? A heuristic discussion/approach should largely improve the impact of this work.\n3. The simplified theory about LNNs in the appendix seems a bit too far from the explanation of the difference between the observations in this paper and Arora et al. (2018).\n\n### typos and small suggestions ###\n1. It is suggested that the full name of LNN is provided at the beginning, and the font size should be larger in Figure 1.\n2. There are some mis-spellings that the authors should check (e.g., gradeint -> gradient).\n3. In formula (4), the authors should mention that the third line holds for all $t$ is a sufficient condition for the previous two equivalent lines.']","[-30, -50, -20]","[20, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges the topic is interesting and important, they express significant concerns about the paper's descriptive nature, lack of conclusive analysis, and need for improved writing. The overall tone is more negative than positive, but not extremely negative. The politeness score is 20 because the reviewer uses respectful language and offers constructive criticism. They acknowledge the paper's potential and importance of the topic, softening their criticisms with phrases like 'I think' and 'more developments are needed'. However, they don't use overtly polite language, maintaining a professional tone throughout."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('observations presented are very interesting', 'results presented somewhat clearly'), the overall tone is critical. The reviewer states the paper 'doesn't have the level of rigor required' and 'lacks detailed study and rigor of a strong empirical work'. They list several flaws and suggest substantial improvements, indicating a generally negative view of the paper's current state. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'unfortunately' and 'I encourage the authors to', which soften the criticism. They also offer constructive feedback and suggestions for improvement, rather than just criticism. However, some direct statements about the paper's weaknesses prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the findings are 'interesting and inspiring', they also point out several areas needing improvement. The review highlights issues with writing consistency, clarity, and organization, and notes that the work is 'still a bit preliminary'. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. Phrases like 'it is suggested that' and 'should largely improve' indicate a polite tone. The reviewer also acknowledges positive aspects of the work before offering critiques, which is a polite approach to reviewing.""]"
"['In this paper, the authors propose a heuristic method to overcome the exploration in RL. They store trajectories which result in novel states. \nThe final state of the trajectory is called goal state, and the authors train a path function which given a state and a subgoal states (some states in the trajectory) the most probably action the agent needs to take to reach the subgoal. These way they navigate to the goal state. The goal state is claimed to be achieved if the feature representation stoping state is close to goal (or subgoal for subgoal navigation).\n\n\nThe authors mainly combine a few previous approaches ""Self-Imitation Learning,"" ""Automatic Goal Generation for Reinforcement Learning Agents,"" and ""Curiosity-driven exploration by self-supervised prediction"" to design this algorithm which makes this approach less novel.\n\nGeneral comment; there are variable and functions in the paper that are not defined, at least at the time, they have been used. The Rooms environment is not described. What is visit_times[x] and x is not a wall? What is stage avg reward? and many others\n\nThe main idea of the algorithm is clear, but the description of the pieces is missing.\n\nIt is not clear in stochastic setting how well this approach will perform. \n\nThe authors state that\n""Among different choices of the modeling, we choose inverse dynamics (Pathak et al., 2017) as the environment model, which has been proved to be an effective way of representing states under noisy environments.""\nI took a look at this paper and could not find neither proof or quantification of ""effective""-ness. Please clarify what the meaning this statement is.\n\nWhy s=s\' is ambiguous to the inverse dynamics?\n\nWhat is the definition of acc in fig2?\n\nwhy (consin+1)^3/8 is chosen?\n', 'In this paper, the authors propose an exploration strategy based on the explicit storage and recall of trajectories leading to novel states. A pool of such trajectories is managed over time, and a method is proposed so that the agent can learn how to follow a path corresponding to these trajectories so as to explore novel states. The idea is demonstrated in a set of room experiments, and quickly shown efficient in Montezuma\'s Revenge and PrivateEye Atari games.\n\nOverall, the idea has some merits, but the empirical study is weak and the paper suffers from unsufficient writing effort (or more probably time).\n\nWhat I like most in the paper is the split of exploration methods into 3 categories: adding some ""intrinsic reward"" bonuses to novel states (curiosity-driven exploration) , trying to reach various goals (goal-driven exploration) and using memory to reach again novel states (memory-driven exploration). Actually, this split may be debated. For instance, some frameworks based on goals have been labelled curiosity-driven, e.g. ""Curiosity-Driven Exploration of Learned Disentangled Goal Spaces"" (Laversanne-Finot, Péré and Oudeyer, CoRL 2018), but anyways I find it useful. That said, this aspect of the introduction is reiterated in the ""Related Work"" section in a quite redundant way, whereas both parts could have been better integrated. Furthermore, the related work section is hardly a draft, I\'ll come to that later.\n\nThe presentation of the method in Section 2 is rather clear and convincing. My only concern is about the assumption that the agent is always starting in the same state. This assumption may not hold in many settings, and the approach appears to be quite dependent on it. A discussion of how it could be extended to a less restricting assumption would be welcome.\n\nThe experimental section is weaker. A few concerns:\n- I could not find much about the number of seeds, trials, the way to depict some variance, the statistical significance of the differences between results presented in Figure 1. The same is true about Figs. 2, 3 and 5.\n- In Fig.2, the claim that the author\'s method learns better models is hardly supported by the left-hand-side plot, and significance is not assessed.\n- I\'m puzzled about the very low performance of baselines in the plots of Fig. 3. Could the author explain why these performances are null.\n- The Atari games section helps figuring out that the framework is not too specific of the rooms environment, but the lack of analysis does not help making sure that this is just the explicit recall mechanism that is responsible for superior performance and why.\n\n\nAnother point about this section is that poor writing does not help understanding some points.\n- to me, the first sentence of Section 3.2.2 does not make sense at all.\n- in the caption of Fig. 4, ""The second row is the heatmaps for states that the number of times being selected as a target state."": I don\'t get what it means, thus I don\'t understand what that row shows.\n- Fig.5 comes with no caption\n\nAbout the related work:\n- The comparison to other methods using memory needs to be expanded. In particular, I would put HER-like mechanisms here rather than in 4.1, as ""explicit recall"" shares some importan ideas with ""experience replay""\n- Section 4.4 (HRL) is not useful as is.\n\nFinally, in the conclusion, the claim that the method can be combined with ""many sota exploration methods"" is not supported, as the authors have only tried two and did not analyse the results in much details.\n\n\ntypos:\n\n- p4:\nwe can easily counting\n(include borders) => including\nis provide => provided\n\nare less less-visited states: quite inelegant\n\n- p7:\nIn Montezuma\'s Revenge, Comparing => comparing\nWhere they encourage => remove ""Where""\n\n- p8:\nrecallcan => recall can\nthe problem of reach goals => reaching\nit succesfully reproduce => reproduces\n\nThe last paragraph of Section 4.2 needs a careful rewriting, as long sentences with parenthese in the middle appear to be some draft version.\n\ncontrol(Pritzel => Missing space\nOur method use memory => uses\nAlthough ..., but => remove but\n\nThe path function can be seen as a form of skills => skill?\nBesides, the ""can be seen"" needs to be further explained...\n\nAppendix\n\nFinally, we provided => provide\n\nis around (math formula) => cannot you be more specific?', 'This paper is the first showing that achieving self-generated tasks during spontaneous exploration and getting reinforced by self-supervised signals is a promising way for the agent to develop skills itself.\nThe scores are demonstrative on several tasks.\nIt opens interesting direction for further research.\n\nREM: \nfew typos like ""An state""\nPlease plot in dash the count methods in the graphs (use oracle information)\n\nAnnexe C shall be integrated into the core of the paper. Could be simplified.\nThe cosine metrics shall be better integrated in it.']","[-30, -30, 80]","[20, 20, 50]","[""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper such as lack of novelty, missing definitions, and unclear aspects. However, it's not entirely negative as it acknowledges that the main idea is clear. The politeness score is 20 because the reviewer uses neutral language and phrases criticisms as questions or suggestions rather than direct attacks. They use phrases like 'Please clarify' and 'It is not clear' which maintain a professional tone. The reviewer also provides specific, constructive feedback, which is helpful and respectful to the authors."", ""The sentiment score is -30 because while the reviewer acknowledges some merits of the paper ('the idea has some merits', 'The presentation of the method in Section 2 is rather clear and convincing'), they express several significant criticisms. These include 'the empirical study is weak', 'the paper suffers from unsufficient writing effort', and multiple concerns about the experimental section. The overall tone is more negative than positive, but not extremely negative. The politeness score is 20 because the reviewer uses generally polite language ('What I like most in the paper is...', 'Could the author explain...') and offers constructive criticism. However, some phrases are more direct ('the related work section is hardly a draft'), which prevents a higher politeness score. The reviewer also provides specific suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is 80 (positive) because the reviewer starts by highlighting the paper's novelty and importance, stating it's 'the first showing' a promising approach. They also mention that the scores are 'demonstrative' and that it 'opens interesting direction for further research', all indicating a positive view of the paper. The politeness score is 50 (slightly polite) because while the reviewer doesn't use overtly polite language, they maintain a professional and constructive tone throughout. They offer suggestions for improvement without harsh criticism, using phrases like 'shall be' instead of more demanding language. The mention of typos is brief and not emphasized. The overall tone is matter-of-fact but respectful, hence a slightly positive politeness score.""]"
"['The paper presents a new version of CIFAR10 that is labelled by multiple people (the test part of the data). They use it to improve the calibration of several image classifiers through “fine-tuning” and other techniques\nThe title is too general, taking into account that this setting has appeared in classification in many domains, with different names (learning from class distributions, crowd labellers, learning from class scores, etc.). See for instance,\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3994863/\nhttp://www.cs.utexas.edu/~atn/nguyen-hcomp15.pdf \nAlso, at the end of section 2 we simply reach logloss, which is a traditional way of evaluating the calibration of a classifier, but other options exist, such as the Brier score. At times, the authors mention the trade-off between classification accuracy and cross-entropy. This sounds very much the trade-off between refinement and calibration, as one of the possible decompositions of the Brier score.\nThe authors highlight the limitations of this work, and they usually mention that the problem must be difficult (e.g., low resolution). Otherwise, humans are too good to be useful. I suggest the authors to compare with psychophysics and possible distortions of the images, or time limits for doing the classifications. \nNevertheless, the paper is not well motivated, and the key procedures, such as “fine-tuning” lack detail, and comparison with other options.\nIn section 2, which is generally good and straightforward, we find that p(x|c) being non-overlapping as a situation where uncertainty would be not justified. Overlap would simply say that it is a categorisation (multilabel classification) problem rather than a classification problem, but this is different from the situation where labels are soft or given by several users. \nIn the end, the paper is presented from the perspective of image recognition, but it should be compared with many other areas in classification evaluation where different metrics, presentation of the data, levels of uncertainty, etc., are used, including different calibration methods, as alternatives to the expensive method presented here based on crowd labelling.\nPros:\n-\tMore information about borderline cases may be useful for learning. This new dataset seems to capture this information.\nCons:\n-\tThe extra labelling is very costly, as the authors recognise.\n-\tThe task is known in the classification literature, and a proper comparison with other approaches is required.\n-\tNot compared with calibration approaches or other ways where boundaries can be softened with less information from human experts. For instance, a cost matrix about how critical a misclassification is considered by humans (cat <-> dog, versus cat <-> car) could also be very useful, and much easier to obtain.\n', ""The authors propose to improve classification accuracy in a supervised learning framework, by providing richer ground truth in the form a distribution over labels, that is not a Dirac delta function of the label space. This idea is sound and should improve performance.\n\nUnfortunately this work lacks novelty and isn't clearly presented.\n(1) Throughout the paper, there are turns that used without definition prior to use, all table headers in table 1. \n(2) Results are hard to interpret in the tables, and there are limited details. Mixup for example, doesn't provide exact parameters, but only mentions that its a convex sum.\n(3) There is no theoretical justification for the approach.\n(4) This approach isn't scalable past small datasets, which the authors acknowledge. \n(6) This has been already done. In the discussion the authors bring up two potential directions of work:\n   (a) providing a distribution over classes by another model - > this is distillation (https://arxiv.org/abs/1503.02531)\n   (b) adding a source of relationships between classes into the objective function -> this is (https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf)\n\n"", 'The authors create a new dataset with label distributions (rather than one-hot annotations) for the CIFAR-10 test set. They then study the effect of fine-tuning using this dataset on the generalization performance of SOTA deep networks. They also study the effects on adversarial robustness.\n\nI think that datasets such as the one generated in this paper could indeed be a valuable testbed to study deep network generalization and robustness. There are many nice benefits of label distributions over one hot labels (that the authors summarize in Section 2.) The paper is also clear and well-written. \n\nThat being said, I do not find the investigation of this paper completely satisfactory. For instance in the generalization experiments, the numbers presented seem to show some interesting (and somewhat surprising) trends, however the authors do not really pursue these or provide any insight as to why this is the case. I also find the section on robustness very weak.\n\nDetailed comments:\n\n- The theoretical contribution mentioned in the appendix does not really seem to be a contribution - it is just a simple derivation of the loss under label distributions. Theoretical contributions are not necessary for a paper to have merit - the authors should remove this statement from the introduction as it detracts from the value of the paper.\n\n- I find it somewhat surprising that the accuracy of the models does not change on training with Cifar10H. Do the authors have any intuition as to why this is the case? The model cross entropy seems to go down, indicating that probability assigned to the correct class increases. I would think that training with label distributions would actually reduce misclassification on confusing instances. It would be interesting to see how the logit distributions change for different examples. For instance, how does the model confidence change on correctly vs wrongly classified examples?\n\n- The authors mention that they run each hyperparameter configuration for three random seeds. It would be nice then to see error bars for the results reported Tables 1 and 2, particularly because the differences in accuracy are small. Did the authors try different train-test splits of the test set? It would also be helpful if the authors could make plots for the results in these tables (at least in the appendix). It is hard to compare numbers across different tables.\n\n-I find the results in Table 2 confusing. Comparing the numbers to Table 1, it seems that mixup does not really change accuracies/loss. The model names in Table 2 do not exactly match Table 1 so it is hard to identify the additional gain from using mixup that the authors mention. The authors should add plots for these results to illustrate the effect of adding mixup more clearly.\n\n-I am not convinced by the section on robustness. Firstly, it is not clear to me why the authors chose FGSM which is known to be a somewhat simple attack to illustrate improved robustness of their model. To perform a useful study of robustness, the authors should study SOTA attacks such as PGD [Madry et al., 2017]. I also do not understand the claim that the top-1 choice becomes less confident after training with CIFAR10H -- this seems to be contradicted by the fact that the cross entropy loss goes down. The authors should provide supporting evidence for this claim by looking at changes in confidence (see point 3 above). Also, the comment about the trade-off between accuracy and robustness seems vague - could the authors clarify what they mean?\n\nOverall, I like the premise of this paper and agree that with the potential benefits of the dataset generated. However, I think that the current experiments are not strong enough to corroborate this.\n']","[-30, -50, -20]","[20, 20, 60]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('Pros'), they also highlight several significant limitations and criticisms ('Cons'). The reviewer points out that the paper lacks proper motivation, comparison with existing approaches, and sufficient detail in key procedures. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, using neutral language to express criticisms. They acknowledge the potential usefulness of the work and provide constructive suggestions for improvement, which contributes to the politeness. However, the review doesn't go out of its way to be overly polite or complimentary, keeping the score relatively close to neutral."", ""The sentiment score is -50 because while the reviewer acknowledges that the idea is 'sound and should improve performance', they also state that the work 'lacks novelty and isn't clearly presented'. The review then lists several significant criticisms, indicating an overall negative sentiment. However, it's not extremely negative as the reviewer does recognize some merit in the idea.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout and uses relatively neutral language. They begin with a positive comment before moving to criticisms, which is a polite approach. The criticisms are presented as factual observations rather than personal attacks. However, the score is only slightly positive because the review is quite direct in its criticisms without much softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'datasets such as the one generated in this paper could indeed be a valuable testbed', 'The paper is also clear and well-written'), they express significant concerns about the investigation and findings ('I do not find the investigation of this paper completely satisfactory', 'I find the section on robustness very weak'). The reviewer provides several critiques and suggestions for improvement, indicating that the paper needs substantial work. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use polite language ('I think', 'It would be nice', 'could the authors clarify') and balance criticism with positive comments. The reviewer also provides detailed feedback and suggestions for improvement, which is a courteous approach in academic peer review.""]"
"[""Quality: The paper proposed a new method to learn some physics prior in an environment along with a new SpatialNetwork Architecture. Instead of learning a specific dynamics model, they propose to learn a dynamics model that is action-free, purely learning the extrinsic dynamics.  They formulate this problem as a video prediction problem. A series of experiments are conducted on PhysWorld (a new physics based simulator) and a subset of Atari games.\nClarity: The writing is good.\nOriginality: This work is original as most of the model-based RL works are focusing on learning one environment instead of common rules of physics.\nsignificance of this work: This work propose an interesting direction to pursue.\n\ncons:\n1. In Figure 4, the authors show that a pretrained model can learn faster than random initialization. However, it is hard to ablate the factor that causes this effect.  Does the dynamics predictor learn the physics priors or is it just because it learn the visual prior of the shape of the objects, etc? \n2. The baseline for atari games is quite limited. First of all, 3 out of 5  atari games  in the original PPO paper show that ACER performs better than PPO. (asteroid, breakout, DemonAttack). I think it is better to make some improvement upon state-of-the-art methods.\n3. All the experiments are shown with only 3 random seeds, without error bar in the main paper. Although the reward plots are shown in Figure 11. \n4. 5 out of 10 atari games are similar to PPO (according to Figure 11). It's hard to be conclusive when half of the experiments are positive and the rest are not. \n5. Lack of discussion about ego-dynamics. There are physics priors for both the environment and the controller. Usually the controller/agent  requires an action to predict its dynamics. Then why should we omit the ego-dynamics and only model the outer world. \n6. Physics prior usually happen in physical environment. The proposed method works well in the physworld environments. But is there some task that are more realistic than atari games that can leverage the power of physics priors more? It's good that this method works in some atari games. But isn't learning the dynamics of atari games a bit off the topic? \n7. The transfer learning experiments should contain a baseline -- maml/reptile. Since you are learning physics prior, it is fair to add meta-learning baselines for comparison.\n\nI think the direction is interesting and the effort is made well. But the experiments are less convincing than the abstract/introduction.\n"", 'Summary\nThis paper propose to learning a dynamics model with future prediction in video and using it for reinforcement learning.\nThe dynamics models is a variants of convolution LSTM and it is trained mean squared error in the future frame.\nThe way of using dynamics model for reinforcement learning is similar to Weber et al., 2017, where K step prediction of the dynamics model is uses as an augmented input of the policy.\n\nStrength\nTraining dynamic model to understand physic and using it for reinforcement learning is an interesting problem that worth exploring. This paper tackles this problem and demonstrated experimental setting based on physics games. \n\nWeakness\nThe part for understanding dynamics model is very close to existing convolutional LSTM model (Xingjian et al., 2015), which is a popular baseline in video modelling community and how pretrained dynamics model is used for reinforcement learning is similar to Weber et al., 2017, but this paper does not provide comparison to any of these two baseline. \nSince the difference with these existing method is subtle, clear comparison with these method and difference in characteristic is essential to show the novelty of the paper. \n\nOverall comment\nThis paper address the interesting problem of understanding dynamics for solving reinforcement learning, but the suggested method is not novel and comparison with existing close methods are not performed.', 'A method for learning physics priors is proposed for faster learning and better transfer learning. The key idea in learning physics priors using spatial net, which is similar to a convolutional LSTM model for making predictions. Authors propose to improve the sample efficiency of Deep RL algorithms, by augmenting PPO’s state input with 3 future frames predicted by the physics prior model. \n\nAuthors show that using Spatial-Net leads to better prediction of the future as compared to previous methods on simple simulated physics environment and can be incorporated to improve performance on ATARI games. \n\n(a) I am a bit unclear on how Spatial-Net is trained along with the policy in the IPA architecture. In section 5.1 it is mentioned that, “We train both SpatialNet and the policy simultaneously and use Proximal Policy optimization (PPO) as our model free algorithm”, however earlier in Section 3 it is mentioned that first the agent is pre-trained with prediction and then the pre-trained model is used with the RL algorithm. Can the authors clarify the training procedure? Is it the case that the Spatial-Net is first pre-trained with some data and then fine-tuned along with the environment rewards? Do the policy-net and the frame prediction net share any parameters? \n\n(b) Is the comparison in Table 2/Figure 5 fair in terms of number of frames seen by the agent? Let a PPO agent see N frames? How many frames does the IPA agent say (both for training spatial Net + Policy). \n\n(c) How about baselines, where instead of augmenting PPO with any additional frames, the Policy is initialized with weights learned by Spatial Net? Other baseline is to jointly optimize for future frame prediction + environment reward (in this case atleast some parameters between the spatial net and the policy net will be shared), but without augmenting the input state with future predicted frames? \n\nThe Spatial net architecture is similar to convolutional LSTM — and I therefore don’t think that is a significantly novel technical contribution. The application of spatial net to augment frames in the state is although novel in my best knowledge. The above questions will help me understand the experiments better. Right now the method is slightly unclear to me and the results on ATARI (figure 11) are a bit underwhelming. Also, why did the authors chose the specific ATARI games that they reported results on — why not other games too? ']","[-20, -50, 20]","[60, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and interesting direction of the work, they express several significant concerns about the experiments and results. The review starts positively but ends with 'the experiments are less convincing than the abstract/introduction,' indicating overall disappointment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the effort made, and frames criticisms as suggestions or questions rather than harsh statements. They use phrases like 'I think it is better to' and 'It's good that' which maintain a constructive tone. The reviewer also balances criticism with positive remarks about the work's originality and potential significance."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting problem and some strengths, they express significant concerns about the novelty of the method and lack of comparisons with existing approaches. The overall tone is more negative than positive, but not entirely dismissive. The politeness score is 20 because the reviewer uses professional and respectful language throughout, acknowledging strengths before discussing weaknesses. They avoid harsh criticism and use phrases like 'worth exploring' and 'interesting problem'. However, the language is mostly neutral and matter-of-fact rather than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential of the proposed method, particularly in improving sample efficiency and performance on ATARI games. However, they also express some concerns and request clarifications, which tempers the overall positivity. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, phrases their concerns as questions rather than criticisms, and acknowledges the potential contributions of the work. They use phrases like 'Can the authors clarify' and 'The above questions will help me understand' which demonstrate a constructive and collaborative tone. The reviewer also provides specific suggestions for improvements and additional experiments, which is helpful and courteous in academic discourse.""]"
"['The paper proposes an alignment of two manifolds that is performed in a low-dimensional parameter space corresponding to a low-pass ""filtering"" of the Graph Fourier transform obtained from the underlying data graphs for the two manifolds. The numerical results show the quality of the alignment for some toy image datasets and a biological dataset.\n\nThe derivation of the technical details of the approach is not clear - see the comments below on Pages 5,6 and 9 in particular. The paper is not clear enough for acceptance at this point.\n\nDetailed comments:\n\nPage 2: Grammar error ""that is invariant batch effects"". When denoising is discussed, can you explain whether this is denoising or simply regularization? When is the selected subspace a good approximation for the ""signal subspace""?\nPage 3: Should X^(S) be X^(s)? When W and W(s) are defined, do they also rely on a neighborhood graph? It appears that in the definition of psi_j the eigenvectors phi_j should be obtained from W, not P (which is how they are defined earlier in the page).\nPage 4: There is an abuse of notation on f, used both as a linear function on X(s) and an element of X(s).\nPage 5: Typos ""exlpained"", ""along the along the"". It is not clear what applying a window to eigenvalues means, or what the notation g_xi(lambda) means. The construction of the filters described here needs to be more explicit. h_xi is undefined. How is H in (1) defined when i = 1?\nPage 6: M should be M(s1,s2). Typesetting error in Lambdabar(s). Which matrix is referred to in ""the laplacian eigenvalues of each view""? What is the source and target of the embedding E? How is the embedding applied to data x(s1), x(s2)?\nPage 7: Figure 1a appears to have an error in the orientation of one of the blue ""3""s. The text on the arrow between the manifold embeddings does not agree with the notation in the paper. In Figure 1b, it is not clear which image is the original point and which images are the neighbors, or why some images are smaller than others. Results for the other algorithms are missing (why no comparison?). Typo ""Wang&Mahadevan"". Can you be more specific as to why that algorithm was ""unable to recover k-neighborhoods"" in certain cases?\nPage 8: Why no comparison with Wang & Mahadevan in Figure 2?\nPage 9: There is little description as to how manifold learning is applied in the biological data example. What is the ambient dimensionality and the dimension of the manifolds? How are the ""abundances"" extracted from the data? \n""Which we explore in 4"" -> ""Which we explore in Fig. 4""', 'This paper tackles the problem of noisy measurements collected from same samples that may result in different experimental data collection scenarios, especially in biology. Given S different data batches of the same samples, this paper aims to perform manifold alignment between each batch using feature correspondences.\nThe motivation is that even though data points from each experiments may differ due to noise coming from different factors, they should at least exhibit some correlations in the feature space. Such correlation is exploited by embedding each batch of data in a space represented by diffusion coordinates computed using an anisotropic kernel. Inter-batch correlations are computed between diffusion coordinates of each batch, which are exploited to construct an isometric transformation between each pair of diffusion coordinates of batch datasets. The later transformation is used to construct an aligned graph Laplacian where each batch have similar representations. \n\nThis paper tackles an important problem using a novel approach where instead of aligning each pair of data-points it is attempting to align geometries of batch specific manifolds. The authors show through a toy experiment on MNIST that the proposed algorithm indeed is able to align manifolds accurately. Moreover it is also able to perform manifold denoising and achieves superior classification results compared to two existing approaches. Finally, the proposed algorithm is applied to a practical biological case and shows that it is indeed able to align data from two different immune profiles.\n\nAlthough the paper tackles efficiently an important problem, I am concerned about the experimental section and think it would be improved by taking the following points into account: \n\n•\tThe proposed approach is compared only with two other algorithms. For example, one could compare the denoising ability to [Hein and Maier 2006: manifold denoising] or [Cui et al: Generalized unsupervised Manifold Alignment] for manifold alignment. Furthermore, it would be informative to see how the proposed approach compares to recent domain adaptation approaches as they attempt to map data from different domains into a shared \nrepresentation which is rather similar to what the proposed algorithm is doing.\n•\tExperiments are all performed using rather simple datasets. It would be interesting to see how the algorithms would perform on slightly more complicated images such as Cifar 10 for example. \n•\tIt is not clear what are the next steps to perform after obtaining Eq. 2\n•\tIt is not clear what are the number of filters in Figure 2 a).\n•\tFigure 1 needs to be clarified further: What are DM1, DM2, DM3 mean? What are the columns and rows in Figure1-b (bottom)? \n', ""The authors pointed out that the measurements in biology and natural science suffer from batch effects such as the variations between batches of data measured at different times or by different sensors. In order to analyze different batches of data, an alignment or a calibration is frequently needed. The authors propose to use that though there is variation among different batches, these batches all share an underlying intrinsic manifold structure, which may admit a set of alignable coordinates.\n\nTechnically, the authors propose to choose the diffusion kernel method, which is one of the spectral methods, to extract the harmonic like eigenfunctions defined on the manifold, for each of the batches of data. Using these harmonic-like coordinates, the authors assume there exists an isometric rotation in the between each pair of batches such that their coordinates can be aligned under this orthogonal rotation.\n\nComments:\nOverall I think the problems pointed out do exist and this is an interesting proposal to use the manifold structure to align the data. But there are some weak points in this proposal:\n1. It's well known that spectral methods are frequently sensitive to perturbations of the datasets. At the beginning of section 2.2 the authors propose to use a normalization to construct the kernel, however, I don't quite understand how this would solve the instability to perturbations. \n\n2. In my opinion, the equation (1) is the most interesting construction in this paper. This motivation for this tensors construction is not strong enough and I would suggest put more detail into this construction. My understanding is the window functions g introduced here serve for an invariance purpose such that when the frequency slightly shift (or rotate), the correlation computed should be stable. But the tradeoff of choosing a proper window should be discussed carefully, potentially with different dataset since different dataset may have a different sensitivity to perturbations across different batches. \n\n3. In section 3.1, the first motivating example is quite confusing. The authors demonstrated the alignment of two rotated MNIST digits, 3. For each digit, the underlying manifold is S1. S1 is diffeomorphic to its rotation. So I'm not so sure what's the underlying manifold geometry used to align them.  My understanding is that this alignment doesn't come from the S1 manifold but comes from some additional structure in the image signal. Fig1(b) is also a little confusing that I couldn't figure out what's drawn there.\n\nOverall, to use the underlying manifold structure to align data batches is an interesting and straightforward proposal, but I hope the authors can address these question carefully and make the argument stronger. ""]","[-50, 50, -20]","[20, 80, 60]","[""The sentiment score is -50 because the review starts with a neutral description of the paper but then states that 'The paper is not clear enough for acceptance at this point,' indicating a negative overall sentiment. The reviewer points out several issues and areas needing clarification, which further supports the negative sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the numerical results showing quality alignment.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to point out issues, such as 'The derivation of the technical details of the approach is not clear' instead of using harsh criticism. The reviewer also asks questions for clarification rather than making accusatory statements. However, the score is not higher because the review doesn't include explicitly polite phrases or compliments, maintaining a mostly neutral, matter-of-fact tone."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the importance of the problem and the novelty of the approach, praising the paper's ability to align manifolds and achieve superior classification results. However, they express concerns about the experimental section, indicating room for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'I am concerned' and 'it would be improved by' rather than harsh or dismissive language. The reviewer also provides specific, actionable suggestions for improvement, which is a polite and professional approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper, they point out several weak points and areas that need improvement. The review starts positively but then focuses on critiques, suggesting an overall slightly negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as suggestions or questions rather than harsh judgments. They use phrases like 'I think,' 'I hope,' and 'I would suggest,' which maintain a polite tone while providing constructive feedback.""]"
"['The paper produces a heat-map of ride-share requests in four cities in the USA. For each city \'block\' they produce a time-sequence of 2016 images representing a week-long run from combining each 5-minute interval. This is used with a GAN to produce new data. The techniques applied, although not commonly used in the context of ride sharing / hailing, have been used extensively in other literature.\n\nSome major points on the paper:\n1) A GAN approach is normally used to generate more data when enough real data is not obtainable. However, here you only use one week of data from a much larger set. Surely, it would be better to make use of all the weeks available?\n\n2) It is not clear how the heat-maps once produced could be used in the future. There is a hint in the results section about how they can be converted back to ride requests, but this is not clearly defined.\n\n3) There are a number of cases where you state that some approach has been found to be better. However, no evidence is presented for how you determined this to be true.\n\n4) The conversion of data to heat-maps has been used extensively in prior research. Although I\'m not directly aware of the use in machine learning I am aware of the use in transport - ""Interactive, graphical processing unit- based evaluation of evacuation scenarios at the state scale"". The novelty here seems to be the application to this specific problem.\n\nMore specific points:\n- ""Our real ride request data sets consist of all the ride requests for an entire week for the four cities."" - it\'s not clear - are all four cities used to train one model?\n\n- ""Hence the week-long data should be quite representative."" - This fails to take into account such things as national holidays or other major events such as sports. Did your chosen week contain one of these?\n\n- ""Hence we believe the ride request data sets also reflect the overall urban mobility patterns for these cities."" - This is a huge assumption, which would seem to need evidence to back it up.\n\n- ""and lump together all the ride requests within each interval."" - Presumably you mean that all time values are to the granularity of 5 minutes? \n\n- ""We arbitrarily sized each block to represent an image of 24\x0224 pixels"" - this seems particularly small.\n\n- ""Each image of that block is labeled with a time interval (for our experiments, the hour in a day)."" - Can the variability within an hour not make this more difficult? \n\n- ""We find that small networks are appropriate for the training data"" - evidence to support this.\n\n- ""This network is pre-trained on the training data"" - which training data are you referring to?\n\n- ""This is found to increase the efficiency of the training process"" - evidence?\n\n- ""In this work we set the block size for each of the four cities to be\n1200 \x02 1200 meters"" - how was this value arrived at?\n\n- You state that GPUs were no more efficient, it would be good to see more analysis of this.\n\n- ""To help enhancing the scalability"" -> ""To help enhance the scalability""\n\n- ""and other useful functions"" - such as?\n\n- Figure 4 would probably work better as a speedup graph.\n\n- ""Running times for sampling ride requests from the trained models and stitching the images of all the blocks together are significantly less than the training times, and are not included in these results."" - at least some figures to give an idea of scale should be provided.', 'The paper works on a very interesting problem: generating ride hailing demand map using deep learning technique. The idea is novel and interesting. The paper adopts two metric to evaluate the performance of the algorithm and shows that the performance is good. However, the problem is a little far from real world cases, which limits the contribution of the paper.\n\nThe title of the paper is very attractive. Before reading the paper, I was very excited and wanted to see the algorithm could generate the driving trajectory by using GAN. However, it can only generate the pickup location, which makes me a little disappointed. In real world applications, in riding hailing industry, the demand/supply estimation have been wide investigated. And it can be very accurate. It is not clear why we need to generate it. On the other hand, the paper only adopts conventional GAN to this application. Technically the contribution is not significant. The paper only considers time slot for generating the new data. In this area, much more information has been used. The authors are suggested to survey the smart transportation or riding sharing research area. The training solution is not satisfied. The model is only trained for each small area in the city. The training set is very limited, which may make the model overfit. Thus the experiments and the results are not convincing. In current GIS or transportation area, usually we would use a unique model for the whole city. At least the authors should discuss their algorithm for the scale issue.\n\nOverall, the paper works on a very interesting problem. However, the current solution should be improved.\n', 'The authors propose an interesting idea of generating synthetic data sets for ride sharing. In particular, they split the space/time into small spatial/temporal cells (50mx50m and 5min) each containing number of requests (or a scaled version of it), and train a conditional GAN to output these cell values given an input 5-min time label. They validate the results using metrics from graph and fractals theory.\nWhile the idea is interesting, the execution of the paper is lacking. Some details are missing and especially key things such as metrics should be explained better.\n- How is the data represented? It says that pixel represents the number of ride requests, how exactly? Then, in the next paragraph it is said that pixel represents presence/absence of ride requests, so which one is it. This is a critical part of the proposal and is not well explained.\n- y-axis in Figure 2 is not explained.\n- Metrics should be better explained. How are edges defined, when you only model requests, not destinations? This is far from being clear.\n- In addition, how is D2 defined? Do we compute one for each time, or how? What exactly is ""side e"", what is a ""side"" here? Basically both metrics are not well defined.\n- ""We can claim strong similarity ..."", what is this justified by?\n- Second paragraph in Section 3.1 is not clear, reads very strangely.\n-  Labels are being mentioned before being defined, adding to confusion.\n- It is clear from Figure 2 that workdays and weekends are very different, yet the authors chose to ignore that fact during modeling. They do mention that we can choose any labeling we want, but still strange that for the experiments this was not taken into account.\n- The authors mention that cells as 1.2km x 1.2km, but Figure 3 shows much different resolution. Seems that the figure is just given as an example, but reading the text one gets an impression that the figure was actually used in the paper. This needs to be clarified.\n- For the classifier, it says that ""time sequence of the data"" is a label, what does this mean? You mean the actual label, or some time sequence? This is confusing, although it seems that simply the 5-min label was used.\n- Could we add the metrics to the loss, to enforce them as the authors say that that would result in strong similarity?\n- One of the major flaws of the paper is missing baseline. It is very difficult to appreciate the results without any reference result.\n- Again, I am not sure how results in Section 5.2 are computed when only requests are modeled.\n- Footnote 2 in the conclusion mentions baselines, yet there are none mentioned in the paper.']","[-30, -30, -50]","[50, 50, 20]","[""The sentiment score is -30 because the review, while not overtly negative, points out several major issues with the paper and questions some of the authors' assumptions and methodologies. The reviewer acknowledges the novelty of the application but expresses concerns about the data usage, clarity of methods, and lack of evidence for certain claims. This indicates a somewhat negative sentiment, though not extremely so. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'it would be good to see' and 'it's not clear' rather than making harsh criticisms. The reviewer also acknowledges positive aspects of the work. However, the score is not higher as the review is direct in its criticisms and doesn't use overly polite language or praise."", ""The sentiment score is -30 because while the reviewer acknowledges the interesting problem and novel idea, they express disappointment and point out several limitations and areas for improvement. The overall tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses polite language throughout, offering suggestions and constructive criticism rather than harsh judgments. They begin with positive aspects before moving to critiques, and use phrases like 'the authors are suggested to' which maintains a respectful tone. The review concludes with a balanced statement, acknowledging the interesting problem while suggesting improvements, which contributes to the overall politeness."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting idea, they express significant concerns about the execution of the paper. The review lists numerous issues and missing details, indicating a generally negative sentiment. However, it's not entirely negative as they do recognize the potential of the idea.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout. They use phrases like 'The authors propose an interesting idea' and frame their criticisms as suggestions or questions rather than direct attacks. However, some statements like 'While the idea is interesting, the execution of the paper is lacking' are quite direct, preventing a higher politeness score.\n\nThe reviewer provides specific, constructive feedback and asks for clarifications rather than dismissing the work outright, which contributes to both the moderate negative sentiment and the slightly positive politeness score.""]"
"['The presented analysis well characterizes the behavior of the spatially transformed adversarial inputs and the proposed defense is empirically confirmed to achieve more accurate and robust classification under attacks.\n\nOne concern is that the defender cannot learn whether the adversary employs spatially transformed AEs or pixel-based AEs (or some others). What happens if the classifier trained with the proposed defense accept pixel-based AEs? I recommend the authors to associate spatially transformed AEs with pixel-based AEs to learn whether the proposed defense performs more robustly compared to existing defenses. If the proposed defense method performs well for spatially transformed AEs but is vulnerable to pixel-based AEs, it is useless.\n\nIt should be better to discuss more on computational efficiency of the proposed defense since it contains SDP solving. Is the proposed deense works with larger datasets such as CIFAR100 or ImageNet?\n\n \n', 'Summary: The paper studies a new attack model based on spatial transformations. The authors first formalize an attack model based on spatial transformation and then study attacks and defenses for this model. \n\nClarity: While the paper studies an important problem -- it\'s important to move out of the norm ball based attack models and consider different attacks like spatial transformations, in the current version, the presentation lacks clarity in both the formulation of the attack model, attacks, defenses and explanation of the results. For example, the impossibility result isn\'t clear: the claim is that any classifier has adversarial spatial transformations that are successful in causing misclassifcation for some threshold on the size of transformation. There is no explanation of how large this threshold is in practice. Is it small enough to be called an ""impossibility result""? What does this threshold intuitively depend on?\n\nOriginality: The key contribution seems to be the formalization of some notion of spatial transformation. However, the final expression (Proposition 1) basically looks just like an l_p norm but after transforming it by some ""fixed"" matrix M. The expressions for this new attack model where || M r|| < \\eps for some perturbation \\eps look pretty similar to the case previously considered (where M was essentially identity). For example, Raghunathan et al. 2018 and Hein & Andriushchenko 2017. The paper is also missing discussion on the structure of this matrix M, and how it changes the attacks and defenses in practice\xa0\n\nSignificance: I think the problem of spatial transformation based adversarial examples is important and the authors have the right goals. However, the current presentation makes it hard to understand the main results provided and hence I would rate that the contribution is not very significant. \n\nOverall: I highly recommend the authors to revise the presentation and clarify a) the main conceptual differences of the new attack model (matrix M of proposition 1) b) Formalize the impossibility and possibility results carefully with concrete theoretical/empirical results to back the claims', 'This paper proposed a defense against spatially transformed adversarial inputs and give the two main results on possibility (still possible to construct adversarial training methods to improve robustness) and impossibility (always exist spatially-transformed adversarial examples for any given networks and thus no certified defense) \n\nThe topic of studying certified defenses on adversarial examples is important, and I think the direction of dealing with spatially-transformed adversarial examples is interesting. However, this paper only analyze a simple one hidden layer neural network and the technique (e.g. sec 4, possibility result) does not seem to easily scale to deeper networks and networks with other types of layers (e.g pooling layers). Also, \n\nI also feel the clarity of the paper should be improved.  \n\nHere are some questions:\n1. Are there other metrics to measure spatial transformation? For the current setting as introduced in sec 2.1, it looks like there is no a uniform spatial transformation on the full image but rather different transformation applied on different local areas. Does it make more sense to say rotate the full image by some angle or shift it by some distance?\n \n2. What is the pi_infty and pi_2 in Theorem 1? Why is it called Lower bound attack in sec 3.1? \n\n3. What is the difference between f_fro, f_spe and f_sdp? \n\n4. In Figure 6 (b), is the classification accuracy the nominal test accuracy of a classifier? If so, then the accuracy is too low (<90% for mnist) and thus considering the corresponding attack rates (Fig 6(a)) on these models are not meaningful. Please explain.\n']","[50, -50, -20]","[70, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with a positive comment about the analysis and empirical confirmation of the defense's effectiveness. However, they also express concerns and recommendations for improvement, balancing out the overall sentiment. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, framing their concerns as recommendations and suggestions rather than harsh criticisms. They use phrases like 'I recommend' and 'It should be better to discuss' which maintain a constructive and polite tone. The reviewer also acknowledges the strengths of the work before presenting their concerns, which is a polite approach to peer review."", ""The sentiment score is -50 because the reviewer expresses several concerns about the paper's clarity, originality, and significance. They state that the presentation lacks clarity, the key contribution seems limited, and the overall significance is not very high. However, they do acknowledge the importance of the problem being studied, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, avoiding harsh criticism. They offer constructive feedback and recommendations for improvement, such as 'I highly recommend the authors to revise the presentation and clarify...'. The tone is professional and aimed at helping the authors improve their work, rather than being dismissive or rude."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and finds the direction interesting, they express several concerns about the paper's limitations and clarity. The reviewer points out that the analysis is limited to a simple one-layer network, the technique may not scale well, and the clarity of the paper needs improvement. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and constructive language throughout. They begin by acknowledging the paper's merits and importance of the topic. When expressing concerns, they use phrases like 'I think' and 'I feel,' which soften the criticism. The reviewer also poses questions rather than making outright negative statements, which is a polite way of pointing out potential issues. The tone remains professional and objective throughout, without any harsh or rude language.""]"
"[""This paper proposes to use a  stochastically quantized network combined with adversarial training to improve the robustness of models against adversarial examples. The main finding is that, compared to a full precision network, the quantized network can generalize to unseen adversarial attacks better while training only on FGSM-perturbed input. This provides a modest speedup over traditional adversarial training.\n\nWhile the findings are certainly interesting, the method lacks experimental validation in certain aspects. The comparison with other adversarial training methods is not standardized across networks, making the efficiency claims questionable. Furthermore, I am uncertain whether the authors implemented expectation over transformations (EoT) for the C&W attack.  Since the network produces randomized output, vanilla gradient descent against an adversarial loss is likely to fail. It is conceivable that by taking an average over gradients from different quantizations, the C&W adversary would be able to circumvent the defense better. I would be willing to reconsider my review if the authors can address the above weaknesses.\n\nPros:\n- Surprising result showing that quantization leads to improved generalization to unseen attack methods.\n\nCons:\n- Invalid comparison to other adversarial training techniques since the evaluated models are very different.\n- Lack of evaluation against EoT adversary.\n- Algorithm 1 is poorly presented. I'm sure there are better ways of expressing such a simple quantization scheme.\n- Figures 2 and 3 are uninteresting. The fact that the model is robust against adversaries implies that the activations remain unchanged when presented with perturbed input."", 'The paper proposes to quantize activation outputs in FGSM training. The algorithm itself is not novel. The straight through approach for training quantized network has been used in previous papers, as also pointed out by the authors. The new thing is that the authors found that quantization of activation function improves robustness, and the approach can be naturally combined with FGSM adversarial training. Experimental results show comparable (and slightly worse) results compared to adversarial training with PGD, while the proposed approach is faster in training time. \n\nI have the following questions/comments: \n\n1. Why not do SQA with PGD-adversarial training? If SQA+FGSM performs similar to PGD training, SQA+PGD might perform even better. \n\n2. There are several important papers missing in the discussion/comparisons: \n- Quantization improves robustness has been reported in a previous paper: ""Defend Deep Neural Networks Against Adversarial Examples via Fixed andDynamic Quantized Activation Functions"". How does the proposed algorithm compare with this paper? \n- Adding stochastic noise in each layer has been used in some recent papers: ""Towards Robust Neural Networks via Random Self-ensemble"". It will be good to include into discussions. \n\n3.  I can\'t find the comparison between PGD-training and SQA on MNIST. Are they also comparable on MNIST? Showing results on more datasets will make the conclusion more convincing.  If the benefit of the proposed approach is training time, showing the scalability on ImageNet will make the argument stronger. \n\n', 'The paper proposes a model to improve adversarial training, by introducing random perturbations in the activations of one of the hidden layers. Experiments show that robustness to attacks can be improved, but seemingly at a significant cost to accuracy on non-adversarial input.\n\nI have not spent significant time on adversarial training, and review the paper under the following understanding: It was observed that the decision regions of a class are sprinkled with ""holes"" that get misclassified. These holes are neither naturally occuring. Their existence allows a potential attacker to coerce a model into mis-classifying by providing specially crafted inputs, in order to attain a benefit. Therefore, those holes are called ""adversarial"" examples. The risk is heightened by the fact that adversarial examples are commonly not mis-classified by humans (or even detectable by the eye). To ""plug"" the holes, one includes adversarial examples in the training, called ""adversarial training."" A resulting system should now have a much improved accuracy for the ""holes"", while ideally not affecting classification accuracy for the natural examples, which will continue to constitute nearly 100% of the samples the system will be used on. (The ""hole"" metaphor may not be entirely appropriate, since the space of adversarial examples that are neither misclassified by humans nor detectable is likely much larger than the space of naturally occuring samples.)\n\nThe paper proposes a way of plugging the hole by quantizing layer activations. The results show that this makes the system robust to adversarial attacks.\n\nClarity:\n\nI spent a lot of time figuring out, as someone who has not spent a lot of time with this, what is being evaluated. It is very unclear whether the non-clean systems in Tables 1 and 2 do apply FGSM etc. also in training (in combination with SQA), or only to the test samples. Table 4, the wording in 4.2, and the wording of the Conclusion indicate that they are. But then, where do I find the accuracy on the naturally-occuring (non-manipulated) samples?\n\nThe only combination of interpretations that makes sense in the end is to parse ""The networks are all trained with fast single-step adversaries"" as to mean ""The networks are all trained with FGSM"", and that the non-Clean columns in Table 1 refer to test data perturbed by the respective method, while the Clean column shows the accuracy on the natural data. This *must* be clarified in the final version, as it took way too long to understand this. I strongly suggest to do this with the naming: change small_full to small_FGSM, and small_SQA to small_SQA+FGSM.\n\nAssuming I figured this out right, the tables still lack the baseline accuracy of doing nothing (clean-clean), so one can know how much the nearly-100% use case gets affected.\n\nResults:\n\nThe second concern I have is that, assuming my reading of the results as described above is correct, that the SQA method quite severely affects accuracy on the clean test data, e.g. increasing the error rate on CIFAR by 72% (from 12.33% to 17.06%). There must be a discussion on why such severe performance hit is worth it, especially since there often is an accuracy cliff below which there is a steep loss of usability of a system. For example, according to my personal experience in speech recognition, the difference between 12% and 17% is the difference between decent and unacceptable user experience (also considering that a few percent of errors are caused by ambiguities in the ground-truth annotations themselves, which should be the case for CIFAR as well).\n\nFigure 1 seems a little misleading in this regard since the areas of good accuracy are very condensed. It should be rescaled, as only the area close to the optimum performance is relevant. It does not matter whether we degrade from 99.x% to 77% or 58%, or even 95-ish. All of those hurt performance to the point of not being useful.\n\nIt would be nice to discuss what an accuracy metric would be that is useful for the end user. It would have to be a combination of the expected cost of a misclassification of a natural image and the expected cost caused by attacks. A good method would improve this overall metric. A paper attempting to address adversarial attacks should at least discuss this topic briefly, in my view.\n\nTechnical soundness:\n\nA technical question I have is whether the min-max normalization may be too susceptible to outliers. A single extreme activation can drastically shift the threshold for \\lambda=1. How about a mean-var normalization? If there is batch or layer normalization in the system, your activations may already be scaled into a consistent range anyway, that might allow you to use a constant scaling on top of that.\n\nAnother question I have is: quantization is often modeled as adding uniform noise. Why not add noise directly? And why uniform noise? For example, would compute g = h + Gaussian noise with std dev=(max-min)/lambda work equally well? What is special about quantization?\n\nAnd another technical question: My guess is that the notable loss of accuracy is caused by the strong quantization (two values only in the case of \\lambda=1). I think the paper should show results for larger lambdas, specifically whether there is a better trade-off point between the accuracy loss from quantization vs. robustness to adversarial samples.\n\nSection 3/SQA: ""This is the reason why we rescale g^i to the original range of h^i"" This seems wrong. I think the main reason is that one would not want to totally change the dynamic ranges of the network, as it may affect convergence merely by scaling. You\'d want to limit any impact on convergence to the quantization itself.\n\nSignificance:\n\nI think the significance is limited. Given that the accuracy impact of the mitigation method is very large, I do not consider this paper as substantially solving the problem, or even bringing a practical solution much closer in reach.\n\nPros:\n - tnteresting idea;\n - comparison against various attacks.\n\nCons:\n - Hard to understand because it was left unclear what is evaluated, at least to readers who are not familiar with a possibly existing implied convention;\n - The method seems to harm accuracy on clean data a lot, which is the main use case of such a system.\n\nI would in the current form reject the paper. To make it acceptable, the clarity of presentation, especially of the results, must be improved, but more importantly, more work seems necessary to reduce the currently significant accuracy hit from the method, and the trade-off of quantization level vs. robustness should be addressed.\n\nMinor feedback:\n\nPlease review the paper for grammar and spelling errors (e.g. ""BinaryConnect constraints"" or the use of ""make"", which is often not correct).\n\nIn Algorithm 1, I suggest to not use \'g\', as it may be mis-read as ""gradient."" Unless this is a common symbol in this context.\n\n""Thus, we propose SQA"" warrants another \\subsubsection{}, to indicate where \\subsubsection{BinaryConnect} ends.\n\nSection 2.2\'s early reference to SQA is a little confusing, since SQA has not formally been defined. I would smooth this a little, e.g. change ""SQA can be considered"" to ""We will see that our SQA, as introduced in the next section, can be considered""\n\n""an alternative is to approximate it"" probably should be ""our approach is to approximate it""']","[-20, -20, -50]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the findings as 'interesting' and notes a 'surprising result', they express significant concerns about the experimental validation and comparison methods. The reviewer states they would be 'willing to reconsider' if the authors address these weaknesses, indicating the review is not entirely negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging both pros and cons, and offers constructive criticism. They use phrases like 'I am uncertain' and 'I would be willing to reconsider' which maintain a polite tone while expressing concerns. The reviewer also provides specific suggestions for improvement, which is a courteous approach in academic peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Experimental results show comparable results'), they also point out several limitations and missing elements. The overall tone suggests that the paper has potential but needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames their comments as questions or suggestions rather than harsh criticisms. They use phrases like 'I have the following questions/comments' and 'It will be good to include', which maintain a respectful tone. The reviewer also acknowledges the authors' contributions while suggesting areas for improvement, which contributes to the polite tone."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('interesting idea', 'comparison against various attacks'), they ultimately recommend rejecting the paper due to significant concerns about clarity and the method's impact on accuracy. The overall tone is critical, indicating more negative than positive sentiment. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and explaining their reasoning clearly. They use polite phrases like 'I suggest' and 'Please review', and frame criticisms as areas for improvement rather than outright failures. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral-to-slightly-positive level of politeness typical in academic discourse.""]"
"['The paper makes its intent plainly clear, it wants to remove the assumption that demonstrations are optimal.  Thus it should show that in a case that some demonstrations are bad, it outperforms other methods which assume they are all good. The method proposed, while interesting, well-conceived and potentially novel, is not convincingly tested to this end. \n\nThe paper should also show that the method can detect the bad demonstrations, and select the good demonstrations. \n\nThe experiments are on toy tasks and not existing tasks in the literature. Why not use an existing dataset/domain and simply noise up the demonstrations?\n\nFurthermore, many crucial details are omitted, such as the nature of the heuristic function K, and how precisely the weighting $c_i$ is adapted (section 4.4). Is it done by gradient descent? We would have to know what K is, and if it is differentiable to know this.\n\nAlso the writing itself needs a thorough revision.\n\nI think there may well be promise in the method, but it does not appear ready for publication.\n', 'The problem is described as doing imitation learning from a set of demonstrations that includes useless behavior. Authors propose a method that is an extension of MAML which selects the useful demonstrations by their provided performance gains at the meta-training time.\n\nPaper clearly demonstrates significant amount of work. Pieces from different modern method implementations (like MAML, TRPO, GAIL, multiple custom loss functions) are combined to work together. Also four custom task domains are implemented with MuJoCo. Finally decent amount of experiments are run.\n\nUnfortunately, all that hard work can\'t be justified by the motivations that are very artificial in details and by the final task performance.\n\nFirst of all, the setup includes small number of demonstrations where almost none of them are seemingly successful (judging by the videos). This is a very artificial setting that does not reflect the actual imitation learning problems like demonstrations provided by humans. There, normally the problem is either dealing with small number of demonstrations that are all typically successful but similarly suboptimal or dealing with small number of distinct demonstrators which are again successful but have significantly different styles. In the summary video, authors motivate the case by learning from sources like internet videos, but that setting is also very far away from the case here, because such video collections are much larger but more importantly the main problem is dealing with the third person perspective. All the experiments here is done from first person demonstrations (in one case with a slightly different body).\n\nBiggest caveat of the paper is that it is promoted as a purely imitation learning method. Yet everything hinges on the existence of a ""task heuristic"" which is nothing but a reward function. If such function exists, all these first person demonstrations can be judged and selected based on that function. There would be no need for a complicated meta-learning scheme. Also the task could be trained directly on that reward by reinforcement learning. Also computation of this heuristic function is not specified. As far as I understand, it is a different quantity than the sparse ""Task Success Reward"".\n\nFinally, the final performance of the imitating agents are far from accomplishing the task, though they show some resemblance to the imitation behavior. This is not all that surprising, given small number of demonstrations and high dimensional control problems.\n\nOverall, the details of the setup makes the problem very artificial, the final performance is not impressive. Method is an amalgamation of bunch other recent work, which gives the impression of creating complexity for its own sake. I do not think that this method will be useful for moving the field forward and produce any impact. ', 'Summary/Contributions:\nThis paper focuses on an imitation learning setup where there some of the provided demonstrations which are irrelevant to the task being considered. The stated contribution of the paper is a MAML based algorithm to imitation learning which automatically determines if the demonstrations are ""suitable"".  The authors also employ a mutual information based maximization term between the demonstrations and the pre-update and post update trajectories.  \n\nPros:\n- The tasks proposed in the problem seem interesting.\n\nCons:\n- The problem statement seems to be of limited scope.\n- The use of the task heuristics seems a bit ad-hoc. \n- The final policies are unimpressive\n\nJustification for rating:\nThe major weakness of this paper in my view are that the setup is of somewhat limited scope since receiving irrelevant demonstrations in the form used by the paper would be unnecessarily costly. The domains considered by the paper seem interesting, but the learned policies are not very compelling. I also feel that the MAML baselines + avg finetuning baselines are somewhat limited giving the new domains. I would appreciate for instance a comparison to off-policy learning methods with demonstrations which the authors discuss in the related work (Hester et al. 2017, Nair et al. 2017, Yang et al. 2018). The justification between using mutual information regularization term also does not seem well-motivated and orthogonal to the problem statement. For instance, a diversity of demonstrations should in principle allow for more information between the demonstrations and the induced change.\n\nOther:\nThe writing and grammar of the paper needs serious revision. There are error throughout the paper starting from the abstract. ']","[-50, -70, -60]","[0, 20, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings of the paper, but also acknowledges some positive aspects ('interesting, well-conceived and potentially novel'). The reviewer concludes that the paper is not ready for publication, which is a negative outcome. The politeness score is 0 (neutral) because the language used is professional and objective, without being particularly polite or rude. The reviewer provides constructive criticism without using overly harsh language, but also doesn't use explicitly polite phrases. The tone is matter-of-fact and focused on the content of the paper rather than personal opinions or emotions."", ""The sentiment score is -70 because the review is predominantly negative. While the reviewer acknowledges the significant amount of work done, they criticize the motivations as 'very artificial', the final task performance as not impressive, and the method as overly complex. They also state that they don't think the method will be useful or impactful. The politeness score is 20 because the reviewer uses relatively polite language, acknowledging the work done and using phrases like 'unfortunately' to soften criticism. However, the overall tone is still critical, preventing a higher politeness score. The reviewer provides detailed explanations for their criticisms rather than making blunt or rude statements."", ""The sentiment score is -60 because the review is predominantly negative, with more cons than pros listed. The reviewer criticizes the paper's limited scope, unimpressive results, and weak baselines. They also mention the need for serious revision of writing and grammar. However, it's not entirely negative as they do acknowledge some interesting aspects, hence not a lower score. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language like 'I would appreciate' and 'The major weakness in my view'. They also start with a neutral summary and mention some pros before cons. However, some phrases like 'unimpressive' and 'needs serious revision' are quite direct, preventing a higher politeness score.""]"
"['In this paper, the novel MAOP model is described for self-supervised learning on past video game frames to predict future frames. The presented results indicate that the method is capable of discovering semantically important visual components, and their relation and dynamics, in frames from arcade-style video games. Key to the approach is a multi-level self-learning approach:  more abstract stages focus on simpler problems that are easier to learn, which in turn guide the learning process at the more complex stages.\nA downside is that it the method is complex, consisting of many specific sub-components and algorithms, which in turn have again other sub-components. This makes the paper a long read with a lot of repetition, and various times the paper refers to the names of sub-components that are only explained later. Other methodological details that are relevant to understand how the method operates are described in the Appendices. I expect that if the paper would be better structured, it would be easier to understanding how all the parts fit together. Another downside of this complexity is that the method seems designed for particular types of video game frames, with static backgrounds, a fixed set of objects or agents. It is unclear how the method would perform on other types of games, or on real-world videos. While the method therefore avoids the need for manual annotation, it instead encodes a lot of domain knowledge in its design and components.\nI also didn\'t fully understand how the self-supervised model is used for Reinforcement Learning in the experiments. Is the MAOP first trained, and the fixed to perform RL with the learned agent models, or is the MOAP learned end-to-end during RL?\n\nPros:\n+ MAOP seems successful on the tested games in the experiments\n+ Demonstrates that, with a sufficiently engineered method, self-supervised learning can be used to discover different types of objects, and their dynamics.\n\nCons:\n- writing could be improved, as the methodology currently reads as a summation of facts, and some parts are written out of order, resulting in various forward references to components that only become clear later. Several times, the paper states that some novel algorithm is used, but then provides no further explanation in the text as all description of this novelty is deferred to an appendix. \n- method does not seem generic, hence it is unclear how relevant this architecture it is to other use cases\n- many hyperparameters for the individual components, algorithms. Unclear how these parameter setting affect the results\n\nBelow are more detailed comments and questions:\n\nGeneral comments:\n* The proposed MOAP method consists of many subalgorithms, resulting in various (hyper)parameters which may impact the results (e.g. see Appendix A, B). Appendix D lists several used hyperparameter settings, though various parameters for the algorithms are still missing (e.g. thresholds alpha, beta in Algo.2). Were the used parameters optimized? How are these hyperparameters set in practice? How does changing them impact your results?\n* Methods seems particularly designed for \'video games\', where the object and background structures have well defined sizes, appearance, etc. How will the MOAP fair in more realistic situations with noisy observations, occluded objects, changing appearances and lighting conditions, etc.?\n* How about changing appearance of an agent during an action, e.g. a \'walking animation\' ? Can your method learn the sequence of sprites to accurately predict the next image? Is that even part of the objective?\n* Appendix D has important implementation details, but is never mentioned in the text I believe! Didn\'t realize it existed on first read through.\n\n* Introduction:\n\t* What prediction horizon are you targeting? 1 step, T steps into the future, 1 to T steps in the future simultaneously?\n\tWhat are you trying to predict? Object motion? Future observations?\n\t* ""... which includes a CNN-based Relation Net to ... "", the names Relation Net, Inertia Net, etc.. are used as if the reader is expected to know what these are already. If these networks were introduced in related work already, please add citations. Otherwise please rephrase to clarify that these are networks themselves are part of your novel design.\n\n* Section 3.1\n\t* ""It takes multiple-frame video images ... and produce the predictions of raw visual observations."". As I understand from this, the self-supervised approach basically performs supervised learning to predict a future frame (target output) given past frames (input). I do not understand how this relates to Reinforcement Learning (RL) as mentioned in the introduction and Related Work. Is there still some reward function in play when learning the MAOP parameters? Or is the idea to first self-supervised learn the MAOP, and afterwards fix its parameters and use it in separate a RL framework? I believe RL is not mentioned anymore until Section 4.2. This connection between self-supervised and reinforcement learning should be clarified, or otherwise the related work should be adjusted to include other (self-supervised) work on predicting future image frames.\n\t* ""An object mask describes the spatial distribution of an object ..."" Does the distribution capture uncertainty on the object\'s location, or does it capture the spread of the object\'s extent (\'mass distribution\') ?\n\t* ""Note that Object Detector uses the same CNN architecture with OODP"". What does OODP stand for? Add citation here. (first mention of OODP is in Experiments section)\n\t* ""(similar with Section 3.2)"" → ""similar to"". Also, I find it a confusing to say something is similar to what will be done in a future section, which has not yet been introduced. Can you not explain the procedure here, and in Section 3.2 say that the procedure is ""similar to Section 3.1"" instead?\n\t* ""to show the detailed structure of the Effect Net module."" First time I see the name \'Effect Net\', what is it? This whole paragraph different nets are named, with a rough indication of their relation, such as ""Dynamic Net"", ""Relation Net"" and ""Inertia Net"". Is ""Effect Net"" a different name for any of the three previous nets? The paper requires the reader to puzzle from Fig.2 that Relation Net and Inertia Net are parts of Effect Net, which in turn is part of Dynamics Net. This wasn\'t clear from the text at all.\n\n* Section 3.2:\n\t* p7.: ""Since DISN leans"" → ""Since DISN learns"" ?\n\t* There are many losses throughout the paper, but I only see at the end of Section 3.1 some mentioning that multiple losses are combined. How is this done for the other components, .e.g is the total loss for DISN a weighted sum of L_foreground and L_instance ? Are the losses for all three three MAOP levels weighted for full end-to-end learning?\n\t* This section states various times ""we propose a novel [method]"", for which then no explanation is given, and all details are explained in the Appendix. While the Appendix can hold important implementation details, I would still expect that novelties of the paper are clearly explained in the paper itself. As it stands, the appendix is used as an extension of the methodological section of an already lengthy paper.\n\t* ""Conversely, the inverse function is ... "" M has a mask for each of the n_o ""object classes"", hence the ""Instance Localization Module"" earlier to split out instances from the class masks. So how can there be a single motion vector STN^-1(M,M\') if there are multiple instances for an object mask? How will STN^-1 deal with different amount of instances in M and M\' ?\n\n* Section 3.3:\n\t* What is the output of this level? I expect some mathematical formulation as in the previous sections, resulting in some symbol, that is then used in Section 3.2. E.g. is the output ""foreground masks F"" (found in Appendix A) ?  This paper is a bit of a puzzle through the pages for the reader.\n\n* Section 4: \n\t* ""We compare MAOP with state-of-the-art action-conditioned dynamics learning baselines, ..."" Please re-iterate how these methods differ in assumptions, what they model, with respect to your novel method? For instance, is the main difference your ""novel region proposal method"" and such? Is the overall architecture different? E.g. explain here already the AC Model uses ""pixel-level inference"", and that OODP has ""lacks knowledge on object-to-object relations"" to underline their difference to your approach, and provide context for your conclusions in Section 4.1.\n\n* Appendix A:\n\t* Algorithm 1, line 7: ""sample a pixel coordinate"" → is this non-deterministically sampling?\n', 'This paper proposes a novel architecture, coined Multi-Level Abstraction Object-Oriented Predictor, MAOP. This architeture is composed of 3 parts, a Dynamics model, an object segmentation model, and a motion detection module.\n\nWhile some parts of the model use handcrafted algorithms to extract data (e.g. the motion detection), most parts are learned and can be trained without much additional supervision, as the objectives are mostly unsupervised objectives.\n\nThe proposed model is interesting, and certainly ""solves"" the two tasks it is trained on. On the other hand, this model seems to be specifically tailored to solve these two tasks. It assumes a static background, very local newtonian-like physics, a very strong notion of object and object class. It is not clear to me if any of the improvements seen in this paper are valuable, reusable methods, or just good engineering work.\nAs such, I do not think that this paper fits ICLR. There has been a growing number of works that aim to find learning algorithms that learn to discover and disentangle object-like representations without having so much prior put into the model, but rather through some general purpose objective. The current paper seems like a decent applications paper, but it explores improvements orthogonal to this trend that IMO is what preoccupies the ICLR audience.\n\nThe writing of this paper makes it a bit hard to understand what the novel contributions of this paper are, and how the proposed method should go beyond the two problems that it solves. In general, there are many phrasings that would benefit from being rewritten more concisely; it would help with clarity, since the proposed model has a multitude of different parts with sometimes long names.\n\nExperimentally, there are many parts to the proposed model, and while it is clear what each of them achieves, it is unclear how necessary each of the parts are, and how sensitive the model is to any part being (possibly slightly) incorrect.\n\nThe proposed method is tested on, presumably, RL environments; yet, no RL experiments are performed, so there is no way of knowing if the proposed model is actually useful for planning (there are instances of model-based methods learning acceptable models that are just wrong enough to *not* be useful to actually do RL or e.g. MCTS planning).\n\nOverall, this paper tackles its tasks in an interesting but maybe too specific way; in addition, it could be improved in a variety of ways, both in terms of presentation and content. While the work is novel, I am not convinced that it is relevant to the interests of the ICLR audience.\n\n\nComments:\n- When running your experiments, do you report results averaged over multiple runs?\n- Figure 4+C7: why does the x-axis start at 2000?\n- I don\'t think Figure 5 is really necessary\n- All figures: your captions could be improved by giving more information about what their figure presents. E.g. in Figure C7 I have no idea what the curves correspond to. Sure it\'s accuracy, but for which task? How many runs? Is it a running average? Etc.\n- Where are the test curves? Or are all curves test curves?\n- Your usage of \\citep and \\citet, (Author, year) vs Author (year), is often inconsistent with how the citation is used.\n\n', 'This paper proposes a new architecture for learning dynamics models in 2D Atari-like game words. The architecture includes multiple layers of abstraction: a “motion detection” level, which looks at which pixels change over time in order to guess at which parts of the image are in the foreground or not; a “instance segmentation” level, which segments the foreground into regions and instances; and a “dynamics learning” level, which learns the dynamics of object instances using a interaction network-style approach.\n\nPros:\n- Impressive-looking dynamics predictions in Atari-like games.\n- An object-based prediction model, which could enable predictions about specific entities in the scene rather than holistic frame predictions.\n\nCons:\n- Very complicated and difficult-to-understand architecture.\n- No ablation studies to validate different components of the architecture.\n- No validation in a model-based RL or control setting.\n- Experiments are only done on one-step predictions, rather than long-term rollouts.\n\nQuality\n---------\n\nThe quality of the predictions seems quite high (based on Figure 6 and the results tables), though there are a number of opportunities to further strengthen the evaluation and analysis:\n\n- I wish that there were more than a single figure of qualitative results to go on. I highly recommend that a revision include a link to a video showing more predictions over time for each environment, ideally with comparisons to the other baselines as well.\n- The introduction of the paper motivates the learning of the model in terms of model-based RL, however, the model is not actually used in a model-based RL setting. It would be nice to see at least a simple validation that the model can be used with an off-the-shelf planner to solve one of the games which are evaluated in the paper. If it cannot, then that limits the significance of the model.\n- As far as I can tell, all the results reported in the tables are based on one-step predictions only. While it is great to show that even in this regime the other models struggle, it would be even better if results could be reported for longer rollouts (i.e., taking the model outputs and feeding it back in as input, and repeating this procedure say 50 steps into the future). Models are not particularly useful in a MBRL setting if they can only be used to predict a single timestep, so it is important to validate that longer-term predictions can be made as well.\n\nOverall the literature review is reasonably solid, but I am not sure the citations in the opening sentence are quite appropriate as model-based DRL has been around for longer than 2017 (see for example [1-3]). Moreover, Chiappa et al (2017) only learns a model and does not use it for planning, so I am not sure it is quite appropriate as a citation for MBRL. \n\n\nClarity\n--------\n\nUnfortunately, I had a very hard time understanding how exactly the architecture works and I felt like there were a lot of details missing. I am not confident that I would be able to reproduce the architecture from reading the paper alone. Below, I will list some of the specific points where I was confused, but I think overall the paper needs to be substantially reorganized in order to be clearer as to how the architecture actually works.\n\nMore broadly, I think some of my confusion stems from the fact that there are very similar computations occurring across the three levels of abstraction but the paper does not really make it clear how these computations relate to one another or how they are similar/different. For example, in the “dynamics learning” level there are modules for performing object detection and instance localization. But then in the “instance segmentation” level, there are similarly modules for detecting and masking out instances. It is not clear to me why this needs to be done twice? \n\nIn general, I would *strongly* recommend including at least in the appendix an algorithm box that sketches out the computational graph for the whole architecture (not in as much detail as the existing algorithm boxes, but in more detail than what is given in Figure 1).\n\nSpecific places where I was confused:\n\n- Where do the region proposals (P) come from?\n- If I’m understanding correctly, the variable M is used multiple times in multiple different ways. It seems to be produced from the “instance localization” module in the “dynamics learning” level, but also from the “dynamic instance segmentation network” in the “instance segmentation” level. Are these M different or the same?\n- Where does F_foreground^(t) come from?\n\n\nOriginality\n-------------\n\nOverall, the idea of learning object-based transition models is not really new (and there are a few citations missing regarding prior work in this regard, e.g. [4-6]). However, there is yet to be an accepted solution for actually learning object-based models robustly and the present work seems to result in the cleanest separation between dynamic objects and background that I have seen so far, and is therefore quite original in that regard.\n\nThis paper appears to be quite similar to Zhu & Zhang (2018), with the main difference being additional functionality to handle multiple dynamic objects in a scene rather than just a single dynamic object. This is a fairly significant difference and the improvement over Zhu & Zhang (2018) seems quite large, so even though the papers seem quite similar on the surface I think the difference is actually quite substantial.\n\nSignificance\n----------------\n\nIf it were clearer how to reproduce this paper, and if it could be shown to apply to a wider range of environments (e.g. the Atari suite, or even better the Sonic domains from the OpenAI Retro contest), then I believe this paper could be quite significant as it would open up new avenues for model-based learning in these domains. Unfortunately, however, it is not clear to me as the paper is currently written how well it would do on other 2D environments, thus limiting the significance. If the model only works on Monster Kong and Flappy Bird---neither of which are commonly used in the RL literature---then it has limited applicability to the rest of the model-based RL community. Similarly, as stated above, it is not clear how well the model will work with longer rollouts or in actual in MBRL settings, thus limiting its significance.\n\nReferences\n---------------\n\n[1] Heess, Wayne, Silver, Lillicrap, Tassa, & Erez (2015). Learning Continuous Control Policies by Stochastic Value Gradients. NIPS 2015.\n[2] Gu, Lillicrap, Sutskever, & Levine (2016). Continuous Deep Q-Learning with Model-based Acceleration. ICML 2016.\n[3] Schmidhuber (2015). On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models. arXiv 2015.\n[4] Wu, Yildirim, Lim, Freeman, & Tenenbaum (2015). Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning. NIPS 2015.\n[5] Fragkiadaki, Agrawal, Levine, & Malik (2016). Learning visual predictive models of physics for playing billiards. ICLR 2016.\n[6] Kansky, Silver, Mely, Eldawy, Lazaro-Gredilla, Lou, Dorfman, Sido, Phoenix, & George (2017). Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics. ICML 2017.']","[-20, -50, -20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper ('MAOP seems successful', 'demonstrates that...self-supervised learning can be used'), they also highlight significant weaknesses. These include the complexity of the method, lack of clarity in writing, and concerns about generalizability. The cons outweigh the pros in the review.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'I expect that' and 'I didn't fully understand' rather than making blunt criticisms. The reviewer also balances negative feedback with positive points and provides detailed suggestions for improvement, which is considerate. However, the score is not higher as the review is still quite critical overall, though expressed diplomatically."", ""The sentiment score is -50 because while the reviewer acknowledges some interesting aspects of the paper, they ultimately conclude it is not suitable for ICLR and list several significant criticisms. The overall tone is more negative than positive. The politeness score is 20 because the reviewer uses generally polite and professional language, offering constructive criticism and suggestions for improvement. However, they do not go out of their way to be overly polite or complimentary. The reviewer maintains a respectful tone while still being direct about the paper's shortcomings."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also list several significant 'Cons' and areas for improvement. The review highlights issues with the paper's clarity, lack of ablation studies, and limited experimental scope. However, it's not overwhelmingly negative as the reviewer sees potential in the work. The politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I wish', 'I recommend', and 'it would be nice to see', which are polite ways of suggesting improvements. The reviewer also balances criticism with positive feedback and provides detailed explanations for their concerns, demonstrating respect for the authors' work.""]"
"['The paper proposes a greedy-like algorithm for sparse recovery that uses nearest neighbors algorithms to efficiently identify candidates for the support estimates obtained at each iteration of a greedy algorithm. It assumes that the norms of the columns of the matrix A are one to be able to change the project-and-sort step into a nearest neighbors search.\n\nIt is not clear what the value of Fact 1 is, given that none of the sparse recovery algorithms discussed here actually performs ell0 norm minimization. Additionally, it is common in theoretical analysis of sparse recovery to assume that the columns of the matrix A have unit norm. In fact, the RIP implies that the columns of the matrix must have norm within delta of 1. Nonetheless, it would be useful to have a discussion of the effect that having non-unit column norms would have on the proposed approach.\n\nSimilarly, Fact 2 is almost self-evident; I suggest to discard the proof.\n\nThe equivalence of Definition 1 and the statement involving ps and qs needs to be shown more clearly. The statement in Definition 1 is given in terms of distances (ball radiuses), not counts of neighbors.\n\nI suggest swapping the use of CoSaMP and AIHT - the theoretical results of the paper refer to AIHT, so it is not clear why the algorithm itself is relegated to the supplementary material.\n\nIt is not clear how d0 is to be computed to implement Accelerated AIHT.\n\nFor Theorem 1, the authors should comment on when the assumption ""xtilde(t) converges linearly to a k-sparse signal with rate c"".\n\nIn Figures 1 and 2, does ""residual"" refer to the difference between x and xtilde, or b and Axtilde? \n\nMinor comments:\nTypo in page 5 ""¿""\nGrammar error in page 6 ""characterizing of the difficulty"".', 'The paper is very well-written, readable, with the ideas and derivations clearly explained. \n\nThe literature review is comprehensive and informative. I do feel however that the review could be improved, for example, by discussing the recent papers by Chinmay Hegde and Piotr Indyk on ""head"" and ""tail"" approximate projections to speed up recovery algorithms. The problem under study is indeed important and the contribution is interesting. \n\nMy biggest concern is that the technical contribution is too modest. Theorem 1 serves more as a decorative technical result (the assumption ""And for any vector v..."" seems out of the blue and too convenient) and the paper does not answer the many questions that come to mind here. For example, what is the intrinsic dimension of common random measurement matrices? Or how do any wrongly detected nearest neighbours propagate through the iterations of the algorithm? How does the measurement noise change the intrinsic dimension? We should intuitively lose stability in return for faster recovery. How would this be quantified in what you\'ve proposed.\n\n', ""Clarity: Paper is generally well written; however, certain theoretical statements (e.g. Theorem 1) are not very precise.\n\nOriginality: Contribution seems to be incremental; the proposed method seems to be a straightforward concatenation of well-known existing results in sparse recovery and nearest-neighbor search.\n\nSignificance: Unclear whether the techniques significantly advance the state of the art.\n\nQuality: Overall, I think this is a promising direction but the idea might not have fully fleshed out.\n\n----\nSummary: \nthe paper proposes a scheme to accelerate popular sparse recovery methods that rely on hard thresholding (specifically, CoSaMP and IHT, but presumably other similar methods can also be used here). The key idea is that if the measurement matrix is normalized, then the k-sparse thresholding of the gradient update can be viewed as solving a k-nearest neighbor problem. Therefore, one can presumably use fast k-NN methods instead of exact NN methods. Specifically the authors propose to use the prioritized DCI method of Li and Malik.\n\nPros: \nreasonable idea to use fast (sublinear) NN techniques in the k-sparse projection step.\n\nCons: \n* It appears that the running time improvement over the baseline IHT (which has Otilde(mn) complexity) heavily depends on the intrinsic dimensionality of A. However, the authors do not characterize this.\n* The authors neglect to mention in the paper that prioritized DCI has a pre-processing time of O(mn), so the final algorithm isn't really asymptotically faster.\n* I cannot parse Theorem 1 (especially, the second sentence). Is epsilon the failure probability of DCI?\n* Experimental results are far too synthetic. In real-life problems k itself is big, so there may be other bottlenecks (least squares, gradient updates, etc) and not necessarily the hard thresholding step.\n""]","[-20, 20, -30]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they raise several concerns and suggest multiple changes. The reviewer questions the value of certain facts, asks for clarifications, and suggests restructuring parts of the paper. However, it's not entirely negative as the reviewer also provides constructive feedback. The politeness score is moderately positive (50) because the reviewer uses neutral language and phrases suggestions politely (e.g., 'I suggest', 'it would be useful'). They avoid harsh criticism and frame their points as recommendations rather than demands. The reviewer maintains a professional tone throughout, even when pointing out errors or areas for improvement."", ""The sentiment score is 20 (slightly positive) because the reviewer starts with praise for the paper's writing and clarity, and acknowledges the importance of the topic. However, they express concerns about the technical contribution being modest and raise several questions, which tempers the overall positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They balance positive comments with areas for improvement, maintaining a professional and courteous tone. The use of phrases like 'I do feel however' and 'My biggest concern is' indicate a polite way of expressing criticism."", ""The sentiment score is -30 because the review is generally critical, pointing out several cons and limitations of the paper. However, it does acknowledge some positive aspects ('promising direction', 'reasonable idea'), preventing it from being extremely negative. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They present their points objectively, using phrases like 'It appears that' and 'The authors neglect to mention' rather than making accusatory statements. The reviewer also balances criticism with some positive remarks, which contributes to the polite tone.""]"
"[""- The authors study the problem of negative transfer in representation learning, and propose to use the formulation proposed by Ganin & Lempitsky '15 for domain adaptation to reduce negative transfer. Instead of defining the domain classification as the adversarial task to learn a domain-independent representation, they collect a set of classification problems irrelevant to the main task as the adversarial tasks, and aim to learn a representation that focuses only on the primary task. There are very little changes compared to the proposal by Ganin & Lempitsky '15, but the application to solve the problem of negative transfer is interesting.  \n\n- My main concern on the whole argument of the paper is whether the benefits we see in the experiments come from the elimination of negative transfer, or just come from having more training labels from different tasks available. In the main formulation of the approach (equation 7), the authors try to learn a feature representation that works well for the primary task but works poorly for the auxiliary(irrelevant) tasks. If we switch the sign for lambda, then it becomes very similar to traditional multi-task learning. I wonder how the multi-task formulation would compare against the adversarial formulation proposed by the authors. There are reasons to suspect the multi-task formulation will also work better than the logistic regression baseline, since more labels from different tasks are available to learn a better joint representation. It is not clear whether the improvements come from modeling the auxiliary tasks using negative transfer (where the adversarial approach should beat the baseline and multi-task approach), or just come from having more information (where both the adversarial approach and the multi-task approach beat the baseline, but have similar performance). \n\n- From a practical point of view, it is not easy to decide what prediction tasks are irrelevant. For example, in the birds dataset, I would expect the color and patterns in the body parts to have some correlations (primary_color, upperparts_color, underparts_color, wing_color, etc). In the case of occlusion of the relevant body parts, I could make a guess on the color based on the colors on other parts of the bird. In the ideal case for the current method, I would expect the adversarial approach proposed to learn a representation that mask out all the irrelevant parts of the animal or irrelevant contextual information. Apart from showing improved prediction performance, have the authors perform analysis on the image activation patterns similar to the motivation example in Figure 1 to see if the new approach actually focus on the relevant body parts of the animals? \n\n- The definition of auxiliary tasks are described in the second last paragraph of 3.3, but it would be clearer if it is also mentioned how they are defined in the experiments section. I went through the whole experiments section having trouble interpreting the results because I could not find the definition of adversarial tasks.  \n\n- Overall I like this paper since it attempts to solve an interesting problem in computer vision, but I would like to see the above question on comparison with multi-task learning answered, or some image activation pattern analysis to provide a more solid argument that the improvements come from elimination of negative transfer. \n\n"", 'Pros:\n- Provides illustration and math formulation for the problem of generalization beyond the correlation of labels and correlated but irrelevant attributes. Forming the issue as a domain adaptation problem (or specifically, a special kind of probability shift) is a clever idea.\n\n\nCons:\n- Lacks comparison to existing work. Making features invariant to attributes to improve generalization is not a new idea, cf. :\n(1) Xie, Qizhe, et al. ""Controllable invariance through adversarial feature learning."" Advances in Neural Information Processing Systems. 2017.\n(2) If you consider the domain difference between various domains to be similar to attribute, then this is also related: Li, Haoliang, et al. ""Domain generalization with adversarial feature learning."" Proc. IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR). 2018.\n(3) There are other works that, although do not aim at improving generalization, use very similar formulation to decouple attribute from features: e.g. (a) Lample, Guillaume, et al. ""Fader networks: Manipulating images by sliding attributes."" Advances in Neural Information Processing Systems. 2017.  (b) Mitigating Unwanted Biases with Adversarial Learning (which the authors cite, but do not offer any comparison or differentiation)\nTo improve the paper, these related work should be discussed in related work section, and (if applicable) compared to the proposed method in the experiments, rather than a very brief mention of one of them in Section 3.3 and no comparison.\n\n- Use of the term ""negative transfer"" is problematic. This is a more important shortcoming, but people may disagree with me. As far as I know, this term is used to describe a *source task* being used to help a *different target task* but result in a negative gain in performance (Torrey, Lisa, and Jude Shavlik. ""Transfer learning.""), which is inherently a multi-task learning setting. However, in this paper it refers to the effect of unrelated features being used in classifier, resulting in a worse generalization. The existence of this issue does not involve a second task at all. If this is not intended, please use another phrase. If the authors think that these are one and the same, I would strongly argue against this proposition.\nAlso, there is no ""negative transfer technique"" as implied by page 2, end of the first paragraph.\n\n- Section 3.2 and 3.3\'s analysis is somewhat disjoint from the method. The analysis boils down to ""given a different correlation between primary and aux tasks, you can compute the distribution of inputs, which will be different from the source, so let\'s make the aux task unpredictable to get domain invariance."" And the method goes on to remove auxiliary task information from the shared feature space. This is disjoint from either eq. (1) picking a target domain closest to source, and Theorem 1 the bound for domain adaptation. One way to improve the paper is to analyze how these analysis are affected by the adversarial training.\n\n- One of the selling points is that the method can adapt to trainable features in deep learning. However, in the experiment, fixed extracted features from pre-trained ResNet is used anyway. If so, a way to improve the paper is to compare to the traditional methods cited in page 2 paragraph 1, by applying them on fixed extracted ResNet features.\n\n', 'The term ""negative transfer"" is quite confusing, especially when it is used together with the term ""domain adaptation"". In domain adaptation, negative transfer means transferring knowledge from a source domain to a target domain in a brute-force manner may result in worse performance compared with that obtained by only using the target domain data.\nIn this paper, the negative transfer problem is different from that in domain adaptation. The authors just tried to model the proposed negative transfer learning problem as a domain adaptation problem. However, the defined problem setting of negative transfer is quite strange, where for the target dataset, neither instances nor labels are available expect for the probability of P_T(Y_p, Y_a), and there is relationship between Y_p and Y_a, which is different from that of the source dataset. It is not convincing that why the proposed problem setting is important in practice.\n\nThe proposed algorithm is designed based on two strong assumptions:\n1. D_T is drawn from a distribution that is nearest to that of D_S, and\n2. P_T(Y) is given in advance.\nRegarding the first assumption, it is not reasonable, and it is hard to be satisfied in practice. For the second assumption, it is also too strong to be satisfied in practice. Though the authors mentioned that when P_T(Y) is not given in advance, P_T(Y) can be further assumed to be of the uniform distribution or the classes are uncorrelated. However, these are just ad-hoc solutions. In practice, if P_T(Y) is unknown, and it is very different from the uniform distribution, or labels are highly correlated, the proposed algorithm may perform very poorly.\n\nRegarding the details of the algorithm, it just simply applies an existing model, DANN. In addition, the theoretical part is a well-known theorem.\n\nThere are some typos: on Page 3, Figure 3(a) --> Figure 2(a); on Page 4, Figure 3(b) --> Figure 2(b).']","[20, -20, -70]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because while the reviewer expresses interest in the paper's approach and finds it 'interesting', they also raise several concerns and questions. The overall tone is constructive but with reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits while politely expressing their concerns. They use phrases like 'I like this paper' and 'I would like to see', which are courteous ways of providing feedback. The reviewer also offers suggestions for improvement in a constructive manner, rather than being dismissive or harsh."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') that outweigh the positives. The reviewer points out several areas for improvement, including lack of comparison to existing work, problematic use of terminology, and disjoint analysis. However, the tone is not entirely negative, as the reviewer offers constructive suggestions for improvement. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'To improve the paper' and 'A way to improve the paper is to', which suggest a collaborative approach rather than harsh criticism. The reviewer also acknowledges that some points may be debatable ('people may disagree with me'), showing respect for differing opinions. The language is neither overly formal nor informal, striking a balance appropriate for academic peer review."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses confusion about terminology, questions the importance and practicality of the problem setting, criticizes the assumptions as unreasonable and too strong, and suggests that the algorithm is simply applying an existing model. The only positive aspect mentioned is that the theoretical part is well-known. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'It is not convincing' and 'it is not reasonable' rather than more harsh language. The reviewer also provides specific feedback and suggestions for improvement, which is a polite approach in academic reviews. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score.""]"
"[""This paper proposes a simple improvement to methods for unit pruning. After identifying a unit to remove (selected by the experimenter’s pruning heuristic of choice), the activation of that unit is approximately incorporated into the subsequent unit by “mean replacement”. The mean unit activation (computed on a small subset of the training set) is multiplied by each outgoing weight (or convolutional filter) and added to each corresponding bias instead. Experiments show this method is generally better than the typical method of zero-replacement before fine-tuning, though the advantage is smaller after several epochs of fine-tuning.\n\nWhile I find this paper intriguing and applaud the extensive experimentation and documentation, I have some concerns as well:\n\t1. There are unanswered questions about how this method relates to existing work. It is not clear from the paper how the “mean replacement” method differs from the two most related works (Ye, 2018) and (Morcos, 2018), which propose variations on replacing units with constant values or mean activations, respectively. Also, why does the method in this paper seem to yield good results, while the related method (Morcos, 2018) yields “inferior performance”?\n\t2. The results are stated to only apply to networks “without batch normalization”. The reason seems intuitive: any change that can be merely rolled into the bias will be lost after normalization (depending perhaps on the ordering of normalization and the non-linearities). This leaves an annually decreasing fraction of networks to which this method is applicable, given the widespread use of batch norm.\n\t3. Critically, it’s difficult to compare this work against other pruning works given the lack of results reported in terms of final test error and the lack of the ubiquitous “error vs. %-pruned” plot.\n\t\nOverall, this paper is lacking some clarity, may be limited in originality, may be helpful for some common networks and composable with other pruning methods (significance), but has a good quality evaluation (subject to the clarity issues). I’m rating this paper below the threshold given the limitations, but I’m willing to consider an upgrade to the score if these questions are addressed.\n\nOther notes:\n\t4. What is your definition of a convolutional “pruning unit”? (From context, I’d presume it corresponds to an output activation map.)\n\t5. In Section 3.1:  replace “in practice, people …” with  something like “in practice, it is common to”.\n\t6. In Equation 3, is the absolute value of the pruning penalty used in the evaluation?\n\t7. In the footnote in Section 3.2, how many training samples are needed for a good approximation? How many are used in the experiments?\n\t8. There are a couple typos in Section 3.2: “replacing -the- these units with zeroes” and “each of these output*s*”.\n\t9. Presumably the “\\Delta Loss after pruning” in Figures 2-6 is validation or test loss, not training loss? Is this the cross-entropy loss? Also, it would be much easier to compare to other papers if test accuracy were reported instead or in addition.\n\t10. In Figure 4, the cost to recover using fine-tuning seems to be only roughly 2% of the original training time. How much time is lost to the process of computing the average unit activation?\n\nUPDATE: I've raised the score slightly to 5 after the rebuttals and revisions."", '1. Pruning neurons in pre-trained CNNs is a very important issue in deep learning, and there are a number of related works have been investigated in Section 2. However, it is very strange that, I did not see any comparison experiments to these related works in this paper.\n\n2. The presentation of the experiment part is also wired, to report compression rates, speed-up rates, and accuracy might have a more explicit demonstration.\n\n3. \'\'This is often done by replacing the these units with zeroes"". However, in previous works, we can directly establish a compact network with fewer neurons after pruning some unimportant neurons. Thus, some considerations and motivations in Section 3.2 seem wrong. \n\n4. It seems that the neural network after using the proposed method has the same architecture as that of the original network, but some of it neurons are represented as mean replacement. Therefore, the compression and speed-up rates of the proposed method would be hard to implement in practice.\n\n5. The paper should be further proofread. There are considerable grammar mistakes and unclear sentences.', 'This paper presents a mean-replacement pruning strategy and utilizes the absolute-valued Taylor expansion as the scoring function for the pruning. Some computer vision problems are used as test beds to empirically show the effect of the employment of bias-propagation and different scoring functions. The empirical results validates the effectiveness of bias-propagation and absolute-valued Taylor expansion scoring functions.\n\nThe work is generally well-written and the results are promising, and the theoretical explanation in 3.3 is intriguing. However, I think the following issues need some further clarifications:\n1. What\'s the exact difference and connection between the mean-replacement pruning technique, and the bias-propagation technique in Ye et al., (2018) and the mean activation technique in Morcos et al. (2018)? The authors only mention that mean replacement pruning extends the idea in Ye et al. (2018) to the non-constrained training setting, but it is very unclear what ""constraints"" are talked about. Some more detailed and formal comparisons should be added, together with potential empirical comparisons.\n2. In the abstract, the authors claim that they ""adapt an existing score function ..."", but from the main text it seems that absolute-valued Taylor expansion score is exactly the same one in Molchanov et al. (2016). Is this a typo (or misleading claim) in the abstract?\n3. There are no comparisons of the approach proposed in this paper with some existing state-of-the-art, apart from some simple comparisons between whether bias-propagation is adopted and some inner comparisons among different scoring functions.\n\nIt would also be much better if some charts/tables with certain metrics for improvement apart from pruning penalties (e.g., compression rates, or inference speed, etc.) instead of simply illustrative figures are shown. \n\n### some smaller suggestions/typos ###\n1. The plot legends/labels are kind of inconsistent with the description before the figures. For example, in the main text the authors mainly use ""pruning penalty"", while in the figures the y-axes are typically labelled as ""\\Delta-loss after pruning"", and the plot tag at page 5 bottom is different from those used in the plots, which introduces some unnecessary confusion.\n2. It is very unclear how the authors arrive at the conclusion ""This results suggests ... the training process"" from the ""winning ticket"" hypothesis.\n3. Several typos that can be easily spell-checked (e.g., ""the effect or pruning"" -> ""the effect of pruning"", etc.).\n\nI hope the authors can address these issues. Thanks!']","[-30, -60, 20]","[60, -20, 80]","[""The sentiment score is -30 because while the reviewer finds the paper 'intriguing' and 'applauds the extensive experimentation', they express several concerns and ultimately rate the paper 'below the threshold'. The overall tone is more negative than positive, but not extremely negative. The politeness score is 60 because the reviewer uses polite language throughout, such as 'I find this paper intriguing' and 'I applaud the extensive experimentation'. They also phrase criticisms constructively, using phrases like 'I have some concerns' rather than direct attacks. The reviewer maintains a professional and respectful tone, even when pointing out limitations. However, it's not extremely polite, as it maintains a critical stance throughout."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, including lack of comparison experiments, strange presentation of results, potentially incorrect assumptions, and practical implementation concerns. The only somewhat positive aspect is the acknowledgment that the topic is important. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical. Phrases like 'very strange,' 'wired,' and 'seem wrong' come across as somewhat impolite. The final point about grammar mistakes and unclear sentences is particularly blunt. However, the reviewer does not use explicitly offensive language, which prevents the score from being lower."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the paper is 'generally well-written' and the results are 'promising'. However, they follow this with several critiques and requests for clarification, which tempers the positivity. The politeness score is high (80) as the reviewer uses respectful language throughout, such as 'I think', 'It would be much better if', and 'I hope the authors can address these issues. Thanks!'. They provide constructive criticism without being harsh or dismissive, and end on a polite note. The reviewer maintains a professional and courteous tone while clearly communicating their concerns and suggestions for improvement.""]"
"['Prons: \nThis paper provides a simple and economic technique to accelerate adaptive stochastic algorithms. The idea is novel and preliminary experiments are encouraging.\n\nCons: \n1.\tThe theoretical analysis for AAMSGrad is standard and inherits from AMSGrad directly. Meanwhile, the convergence rate of AAMSGrad merely holds for strongly convex online optimization, which does not match the presented experiments. Hence, the theoretical contribution is limited. \n2.\tThe current experiments are too weak to validate the efficacy of the proposed accelerated technique. We recommend the authors to conduct more experiments on various deep neural networks. ', 'The paper proposes an acceleration method that slightly changes the AMSGrad algorithm when successive stochastic gradients point in different directions.  I found the paper confusing to read because the critical points of Algorithm 1 are very unclear. For instance the \\phi function defined by Reddi et al. takes as argument all the past gradients g1...gt (see paper at the bottom of page 3) but is used inside Algorithm 1 with only the current gradient --\\phi_t(g_t)-- or an enigmatic ""max"" of two vectors --\\phi_t(max(g_t,pg_t))--  I have no idea what the actual calculation is supposed to be. The proof of the theorem (equation 6 in the appendix) suggests that this is a componentwise maximum and that the other gradients are still in.  But a componentwise maximum is a surprisingly assymetric construction. What if we reparametrize by changing the sign of one particular weight?  We get a different maximum?\n\nI finally looked into the empirical evaluation. I am not sure that the purported effect cannot be ascribed to other factors such as the choice of stepsize --they do not seem to have been looking for the best stepsize for each algorithm. The MNIST experiments are performed with a bizarre variant of CNN that seems to perform substantially worse than comparable system. They show the test loss but not the test accuracy though.\n\nIn conclusion I remain confused and unconvinced.', ""The paper considers a simplistic extension of first order methods typically used for neural network training. Apart from the basic idea the paper's actual algorithm is hard to read because it is full of lacking definitions. I have tried to piece together whatever I could by reading the proof. The algorithm box is very unclear. For instance the * operator is undefined. \n\nTo the best of my understanding which the paper changes the update by first checking whether the gradient has the same direction as the previous gradient if yes it uses the component wise maximum of the new gradient and the previous gradient in the update and otherwise it uses the new gradient. Now whether this if condition is checked component wise or an angle between the two vectors is completely unclear. \n\nI will really suggest the authors to at least write their algorithm with clarity. Further while stating the theorem there are undefined parameter and even the objective Regret has not been defined anywhere. Further the theorem which I could not verify due to similar unclarity shows I believe the same convergence result as AMSGrad and hence there is no theoretical advantage for the proposed algorithm. In terms of practice further I do not see a significant advantage and it could result be a step size issue . The authors do not say that they do a search over the hyper parameters. \n\nOn a philosophical level it is unclear what the motivation behind this particular change to any algorithm is. It would be good to discuss what additional advantage is added on top of acceleration. Note that the method feels very much like acceleration. \n""]","[20, -70, -70]","[50, -20, -20]","[""The sentiment score is slightly positive (20) because the review starts with positive aspects ('novel idea', 'encouraging experiments') but also includes significant criticisms. The overall tone is more constructive than negative. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers recommendations rather than harsh criticisms. They acknowledge the paper's strengths before presenting areas for improvement, which is a polite approach. The use of phrases like 'we recommend' instead of more directive language also contributes to the politeness."", ""The sentiment score is -70 because the reviewer expresses significant confusion and criticism throughout the review. They describe the paper as 'confusing to read', question the clarity of critical points, express doubt about the empirical evaluation, and conclude by stating they remain 'confused and unconvinced'. These are strong negative sentiments, though not entirely dismissive, hence not the lowest possible score. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is quite direct and critical. Phrases like 'I have no idea what the actual calculation is supposed to be' and 'I remain confused and unconvinced' are blunt and could be perceived as somewhat impolite in academic discourse. However, the reviewer does attempt to explain their concerns in detail, which prevents the score from being extremely negative."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper for lacking clarity, having undefined parameters, and not showing significant advantages over existing methods. They use phrases like 'simplistic extension', 'hard to read', 'very unclear', and 'no theoretical advantage', indicating strong dissatisfaction with the paper. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use phrases like 'I will really suggest' and 'it is unclear what the motivation behind this particular change to any algorithm is', which come across as somewhat blunt and dismissive. However, they do use some softening language like 'To the best of my understanding' and 'it would be good to discuss', which prevents the score from being even lower.""]"
"['Summary: This paper introduces a functional extension of the Bregman Lagrangian framework of Wibisono et al. 2016. The basic idea is to define accelerated gradient flows on the space of probability distribution. Because the defined flows include a term depending on the current distribution of the system, which is difficult to compute in general, the authors introduce an interacting particle approximation as a practical numerical approximation. The experiments are a proof-of-concept on simple illustrative toy examples.\n\nQuality: The ideas are generally of high quality, but I think there might some typos (or at least some notation I did not understand). In particular\n- tilde{F} is not defined for Table 1\n- the lyapunov function for the vector column of table one includes a term referring to the functional over rho. I think this is a typo and should be f(x) - f(xmin) instead.\n\nClarity: The paper is generally clear throughout.\n\nOriginality & Significance: The paper is original to my knowledge, and a valuable extension to the interesting literature on the Bregman Lagrangian. The problem of simulating from probability distributions is an important one and this is an interesting connection between that problem and optimization.\n\nPros:\n- An interesting extension that may fuel future study.\n\nCons:\n- This algorithm appears naively to have an O(n^2) complexity per iteration, which is very expensive in terms of the number of particles. Most MCMC algorithms would have only O(n) complexity in the number of particles. This limits its applicability.\n', 'The articles adapt the framework developed in Wibisono & al to the (infinite dimensional) setting consisting in carrying out  gradient descent in the space of probability distributions.\n\nPROS:\n- the text is well written, with clear references to the literature and a high-level description of the current state-of-the-art.\n- there is a good balance between mathematical details and high-level descriptions of the methods\n- although I have not been able to check all the details of the proofs, the results appear to be correct.\n\nCONS:\n- while I think that this type of article is interesting, I was really frustrated to discover at the end that the proposed methods either rely on strong Gaussian assumptions, or  ""density estimations"". In other words, no ""practical"" method is really proposed.\n- no comparison with other existing method is provided.\n\n\n', 'This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics).\n\nActually, I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary. One can get the same formula by deriving it from Wasserstein gradient flows. When considering the functional as relative entropy, one can derive the formula simply from the Fokker-Planck equation of 2nd order Langevin dynamics. As a result, the proposed methods seems to be a new way to derive the Wasserstein gradient flow (or Fokker-Planck equation), which does not make impact the algorithm, e.g., both ways result in the same algorithm.\n\nBesides, I found the writing needs to be improved. There are a lot of background missing, or the descriptions are not clear enough.  For example:\n1. Page 2: the divergence operator is not defined, though I think it is a standard concept, but would be better to define it.\n2. Page 2: the Wasserstein gradient and Gateaux derivative are not defined, what are the specific meanings of \\nabla_\\rho F(\\rho) and \\partial F / \\partial \\rho?\n3. 1st line in Section 2: convex function f of d real variables seems odd, I guess the author means argument of f is d-dimensional variable.\n4. Section 2, the authors directly start with the variational problem (3) without introducing the problem. Why do we need to variational problem? It would be hard to follow for some one who does not have such background.\n5. Similarly, what is the role of Lyapunov function here in (6)? Why do we need it?\n6. Why do you define the Lagrangian L in the form of (10)? What is the relation between (10) and (2)?\n7. It is not clear what ""The stochastic process (X_t, Y_t) is Gaussian"" means in Proposition 1? It might need to be rephrased.\n8. Second last line in page 5: I guess \\nabla \\log(\\rho) should be \\nabla\\log(\\rho_t).\n\nFor the theory, I think eq.15 only applies when the PDE, e.g. (13), is solved exactly, thus there is not too much practical impact, as it is well known from the Wasserstein gradient theory that the PDE decays exponentially, as stated in the theorem. When considering numerical solutions, I think this results is useless.\n\nFor the relation with SGHMC, let\'s look at eq.16. Actually, the derivative of the log term \\nabla \\log \\rho_t(X_t)) is equivalent to a brownian motion term. This can be seen by considering the Fokker-Planck equation for Brownian motion, which is exactly d \\rho_t = \\Delta \\rho_t. Consequently, instead of using the numerical approximations proposed later, one cane simply replacing this term with a Brownian motion term, which reduces to SGHMC (with some constant multipliers in front). \n\nThe authors then shows empirically that the proposed method is better than SGHMC, which I think only comes from the numerical methods.\n\nFor the kernel approximation, it makes the particles in the algorithm interactive. This resembles other particle optimization based algorithms such as SVGD, or the latest particle interactive SGLD proposed in [1] or [2[.  I think these methods need to be compared.\n\n[1] Chen et al (2018), A Unified Particle-Optimization Framework for Scalable Bayesian Sampling.\n[2] Liu et al (2018), https://arxiv.org/pdf/1807.01750.pdf\n\nTo sum up, though the derivation of accelerated gradient flow formula seems interesting, the resulting algorithm does not seem benefit from this derivation. The algorithm seems to be able to derived from a more direct way of using Wasserstein gradient flows, which results in a Wasserstein gradient flow for 2nd order Langevin dynamics, and is thus well known. The experiments are not convincing, and fail to show the advantage of the proposed method. The proposed method needs to be compared with other related methods.']","[50, 20, -50]","[75, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the high quality of ideas, originality, and potential significance of the paper. They mention pros like 'interesting extension' and 'valuable extension'. However, they also point out some cons and potential typos, which prevents the score from being higher. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'generally clear', 'interesting connection', and 'may fuel future study', which are polite ways to express positive aspects. Even when pointing out issues, the reviewer uses tentative language like 'I think there might be some typos' rather than making blunt criticisms."", ""The sentiment score is slightly positive (20) because the review starts with a neutral description of the article's content, followed by a balanced list of pros and cons. The pros highlight the well-written nature of the text, clear references, and good balance between mathematical details and high-level descriptions. However, the cons express frustration with the lack of practical methods and comparisons, which pulls the sentiment down from being strongly positive. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, even when expressing criticism. They acknowledge the article's strengths before presenting their concerns, which is a polite approach. The use of phrases like 'I think' and 'I was really frustrated' shows a personal, yet professional tone, avoiding harsh or rude language even when critiquing the work."", ""The sentiment score is -50 because the reviewer expresses several criticisms and doubts about the paper's novelty and practical impact. They suggest that the derivation is unnecessary and the results are not particularly advantageous over existing methods. However, they do acknowledge some interesting aspects, preventing the score from being more negative. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I think' and 'I found' to soften their critiques, and provide specific suggestions for improvement. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone.""]"
"[""Summary:\n\nThis work tackles few-shot (or meta) learning, providing an extension of the gradient-based MAML method to using a mixture over global hyperparameters. Each task stochastically picks a mixture component, giving rise to task clustering. Stochastic EM is used for end-to-end learning, an algorithm that is L times more expensive than MAML, where L is the number of mixture components. There is also a nonparametric version, based on Dirichlet process mixtures, but a large number of approximations render this somewhat heuristic.\n\nComparative results are presented on miniImageNet (5-way, 1-shot). These results are not near the state-of-the art anymore, and some of the state-of-art methods are simpler and faster than even MAML. If expensive gradient-based meta-learning methods are to be consider in the future, the authors have to provide compelling arguments why the additional computations pay off.\n\n- Quality: Paper is technically complex, but based on simple ideas. In the case of\n   infinite mixtures, it is not clear what is done in the end in the experiments.\n   Experimental results are rather poor, given state-of-the-art.\n- Clarity: The paper is not hard to understand. What is done, is done cleanly.\n- Originality: The idea of putting a mixture model on the global parameters is not\n   surprising. Important questions, such as how to make this faster, are not\n   addressed.\n- Significance: The only comparative results on miniImageNet are worse than the\n   state-of-the-art by quite a margin (admittedly, the field moves fast here, but it\n   is also likely these benchmarks are not all that hard). This is even though better\n   performing methods, like Versa, are much cheaper to run\n\nWhile the idea of task clustering is potentially useful, and may be important in practical use cases, I feel the proposed method is simply just too expensive to run in order to justify mild gains. The experiments do not show benefits of the idea.\n\nState of the art results on miniImageNet 5-way, 1-shot, the only experiments here which compare to others, show accuracies better than 53:\n- Versa: https://arxiv.org/abs/1805.09921.\n   Importantly, this method uses a simpler model (logistic regression head models)\n   and is quite a bit faster than MAML, so much faster than what is proposed here\n- BMAML: https://arxiv.org/abs/1806.03836.\n   This is also quite complex and expensive, compared to Versa, but provides good\n   results.\n\nOther points:\n- You use a set of size N+M per task update. In your 5-way, 1-shot experiments,\n   what is N and M? I'd guess N=5 (1 shot per class), but what is M? If N+M > 5,\n   then I wonder why results are branded as 5-way, 1-shot, which to mean means\n   that each update can use exactly 5 labeled points.\n   Please just be exact in the main paper about what you do, and what main\n   competitors do, in particular about the number of points to use in each task\n   update.\n- Nonparametric extension via Dirichlet process mixture. This is quite elaborate, and\n   uses further approximations (ICM, instead of Gibbs sampling).\n   Can be seen as a heuristic to evolve the number of components.\n   What is given in Algorithm 2, is not compatible with Section 4. How do you merge\n   your Section 4 algorithm with stochastic EM? In Algorithm 2, how do you avoid\n   that there is always one more (L -> L+1) components? Some threshold must be\n   applied somewhere.\n   An alternative would be to use split&merge heuristics for EM.\n- Results reported in Section 5 are potentially interesting, but entirely lack a\n   reference point. The first is artificial, and surely does not need an algorithm of this\n   complexity. The setup in Section 5.2 is potentially interesting, but needs more\n   work, in particular a proper comparison to related work.\n   This type of effort is needed to motivate an extension of MAML which makes\n   everything quite a bit more expensive, and lacks behind the state-of-art, which\n   uses amortized inference networks (Versa, neural processes) rather than\n   gradient-based.\n"", ""This paper proposes a mixture of MAMLs (Finn et al., 2017) by exploiting the interpretation of MAML as a hierarchical Bayesian model (Grant et al. 2018). They propose an EM algorithm for joint training of parameter initializations and assignment of tasks to initializations. They further propose a non-parametric approach to dynamically increase the capacity of the meta learner in continual learning problems. The proposed method is tested in a few-shot learning setup on miniImagenet, on a synthetic continual learning problem, and an evolutionary version of miniImagenet.\n\n[Strengths]\n\n+ Modeling the initialization space is an open research question and the authors make a sound proposal to tackle this.\n+ The extension to continual learning is particularly interesting, as current methods for avoiding catastrophic forgetting. inevitably saturate model parameters. By dynamically increasing the meta-learner's capacity, this approach can in principle bypass catastrophic forgetting.\n\n[Weaknesses]\n\n- There is nothing in the algorithm that prevents mode collapse, and the only thing breaking symmetry is random initialization. In fact, figure 5 and 6 suggest mode collapse occurs even in the non-parametric case. A closely related paper that may be of interest ( Kim et al., 2018, https://arxiv.org/abs/1806.03836 ) address this issue by using Stein Variational SGD.\n- Results on miniImagenet are not encouraging; the gains on MAML are small and similar methods that generalize MAML (Kim et al., 2018, Rusu et al., 2018) achieve significantly better performance.\n- Experiments on evolving tasks suggest the method is not able to capture task diversity. In the synthetic experiment (figure 5), the model suffers mode collapse when a sufficiently difficult task is introduced. Ultimately, it performs on par with MAML, despite having three times the capacity. Similarly, on the evolving miniImagenet dataset, figure 6 indicates there is no cluster differentiation across tasks.\n- The paper needs major polishing."", 'This paper presents a mixture of hierarchical Bayesian models for meta-learning to modulate transfer between various tasks to be learned. A non-parametric variant is also developed to capture the evolution of a task distribution over time. These are very fundamental and important problems for meta-learning. However, while the proposed model appears to be interesting, the evaluation is less convincing. \n\n1. The performance of few-shot classification on MiniImageNet is not comparable to the state of the art (Table 2, Table 1). Especially, by Table, the proposed model performs much worse than existing methods (50% vs 60%). More discussions and explanations on this experiment are clearly required.\n\n2. A more systematic and realistic evaluation is necessary to justify the proposed method. As a method that aims to cope with heterogeneous or even evolving task distributions, it is expected to work well in practice and outperform those baselines that are designed for a single task distribution. ']","[-50, -20, -30]","[20, 50, 50]","['The sentiment score is -50 because the reviewer expresses several criticisms of the paper, including that the results are not near the state-of-the-art, the method is too expensive to justify mild gains, and the experiments do not show benefits of the idea. However, the reviewer does acknowledge some positive aspects, such as the paper being technically complex and potentially useful, which prevents the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express criticisms. They provide specific suggestions and comparisons to other work, which is helpful. However, the review is not overly polite or complimentary, maintaining a mostly neutral tone with a slight lean towards politeness in how criticisms are framed.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they point out several significant weaknesses. The review starts positively but then lists more weaknesses than strengths, and the weaknesses seem more substantial. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout, acknowledging the paper's contributions while providing constructive criticism. They use phrases like 'sound proposal' and 'particularly interesting' when discussing strengths, and provide specific suggestions for improvement without using harsh language. The review maintains a balanced and objective tone, even when pointing out limitations."", ""The sentiment score is -30 because while the reviewer acknowledges the importance of the problem and the interesting nature of the proposed model, they express significant concerns about the evaluation, particularly the poor performance compared to state-of-the-art methods. The overall tone is more negative than positive, but not extremely negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the importance of the work and framing criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'more discussions and explanations are clearly required' and 'it is expected to work well' which maintain a professional and constructive tone.""]"
"['This paper proposes simple metrics for measuring the ""information density"" in learned representations. Overall, this is an interesting direction. However there are a few key weaknesses in my view, not least that the practical utility of these metrics is not obvious, since they require supervision in the target domain. And while there is an argument to be made for the inherent interestingness of exploring these questions, this angle would be more compelling if multiple encoder architectures were explored and compared. \n\n+ The overarching questions that the authors set out to answer: How task-specific information is stored and to what extent this transfers, is inherently interesting and important. \n\n+ The proposed metrics and simple and intuitive.\n\n+ It is interesting that a few units seem to capture most task specific information. \n\n- The envisioned scenario (and hence utility) of these metrics is a bit unclear to me here. As noted by the authors, transfer is most attractive in low-supervision regimes, w.r.t. the target task. Yet the metrics proposed depend on supervision in the target domain. If we already have this, then -- as the authors themselves note -- it is trivial to simply try out different source datasets empirically on a target dev set. It is argued that this is an issue because it requires training 2n networks, where n is the number of source tasks. I am unconvinced that one frequently enough has access to a sufficiently large set of candidate source tasks for this to be a real practical issue. \n\n- The metrics are tightly coupled to the encoder used, and no exploration of encoder architectures is performed. The LSTM architecture used is reasonable, but it would be nice to see how much results change (if at all) with alternative architectures.\n\n- The CFS metric depends on a hyperparameter (the ""retention ratio""), which here is arbitrarily set to 80% without any justification.\n\n- What is the motivation for the restriction to linear models? In the referenced probing paper, for example, MLPs were also used to explore whether attributes were coded for \'non-linearly\'. \n', 'MEASURING DENSITY AND SIMILARITY OF TASK RELEVANT INFORMATION IN NEURAL REPRESENTATIONS\n\nSummary:\n\nThis work attempts to define two kinds of metrics (metrics for information density and for information similarity) for the sake of automatically detecting similarity between tasks so that transfer learning can be done more efficiently. The concepts are clearly explained, and the metric for information density seems to match up with intuitions coming out of forward selections approaches. The metric for information transfer seems to be the commonplace metric that other works default to when they show that pre-trained representations are effective on downstream tasks. It is not clear that the notion of similarity through classifier weights makes sense, but see below for clarification questions. The problem addressed (automatic similarity scoring of tasks) is important for transfer learning, and thus the results have potential to be very impactful if they generalize to other kinds of tasks; as is, they seem to apply only to classification tasks, but that is a good step.\n\nPros:\n\nClearly written; experiments on the datasets chosen do seem to suggest that the proposed methods have potential. Brings in nice intuition from forward feature selection. An important problem with potential for high impact.\n\n\nCons:\n\nIt is not clear to me that the classifier difference metric is well-defined. Is there a constraint on the CFS and classifiers that ensure the difference between the weights really captures what is suggested? Is it not the case that classifier weights could come out quite different despite the tasks being quite similar if the linear classifiers learned to capitalize on dissimilar, yet equally fruitful patterns in the input features?\n\nDo you have thoughts on how this could be applied outside the context of sentence representations and further outside the context of classification? Those seem to be quite limiting features of these methods, which is not to say that they are not useful in that realm, but only to clarify my understanding of their possible scope of application.\n\nThese classification datasets are often so close, that I do wonder whether even simpler methods would work just as well. For example, clustering on bags-of-words might also show that SST, SST-fine, and IMDb are close/similar/transferable. The same could be said for SICK and SNLI. It would be nice to see a comparison to such baselines in order to get a sense of how the proposed methods give insights that other unsupervised or supervised methods might give just as well. Otherwise, it is hard to tell how significant these correlations are. Since the end goal is to determine transferability of tasks and not the methods, it does seem like there are simpler baselines that you could compare against.', 'This paper tries to quantify how ""dense"" representations we need for a specific task -- more specifically, how many dimensions are needed from a given representation (for a given task) to achieve a percentage of the performance of the entire representation. The second thing the paper tries to quantify is how well representations learned for one task can be fine tuned for another. Experiments are conducted with 4 different representation technique on a dozen or so tasks.\n\nQuick summary: While I liked aspects of this -- including the motivation of having a lightweight way of understanding how well representations transfer across tasks, overall my concerns surrounding the methodology and some missing analysis leads me to believe this needs more work before it is ready for publication.\n\nQuality: Below average\nI believe the proposed techniques have some flaws which hurt the eventual method. There are also concerns about the motivations behind parts of the technique.\n\nClarity: Fair\nThere were some experimental details that were poorly explained but in general the paper was readable.\n\nOriginality: Fair\nThere were some nice ideas in the work but I remain concerned about aspects of it.\n\nSignificance: Below average\nMy concern is that the flaws in the method do not make it conducive to use as is.\n\n\nStrengths / Things I liked:\n\n+ I really liked the motivating problem of being able to (hopefully cheaply / efficiently) estimate transfer potential to understand how well representations will perform on a different task.\n\n+ Multiple representations and tasks experimented with\n\nWeaknesses / Things that concerned me:\n(In no specific order)\n\n- (W1) Adversely affected by rotations: One of my big concerns with the work is the way the CFS is computed. While it seems ok to estimate these different metrics using only linear models, my concern with this is that the linear models are only given a subset of the **exact** dimensions of the original representations. This is very much unlike the learning objectives of most of these representation learning methods and hence is highly biased and dependent on the actual methods and the random seeds used and the rotations it performs. (In many cases the representations are used starting with a fully connected layer bottom layer on top of the representations and hence rotations of the representations do not affect performance)\n\nLet\'s take an example: Say there is a single dimension of the representation that is a perfect predictor of a task. Suppose we rotated these representations. Now the signal from the original dimension is split across multiple dimensions and hence the CFS may be deceivingly high.\n\nTo me this is a big concern as different runs of the same representation technique can likely have very different CFS scores based on initializations and random seeds.\n\n- (W2) Related to the last line: I did not see any experiments / analysis showing how stable these different numbers are across different runs of the representation technique. Nor did I see any error bars in the experiments. This again greatly concerned me as I am not certain how stable these metrics are.\n\n- (W3) Baselines for transfer learning: I felt this was another notable oversight. I would have liked to see results for both trivial baselines like random ranking as well as more informed baselines where we can estimate transfer potential using say k representation techniques, and then use that to help us understand how well it would do on the other representations. This latter baseline is a zero-cost baseline as it is not even dependent on the method.\n\n- (W4) Metrics for ranking of transfer don\'t make sense (and some are missing) : I also don\'t understand how ""precision"" and NDCG are used as metrics. Based on my understanding the authors rank (which itself is questionable) the different tasks in order of potential for transfer and then call this the ""gold"" set. How is precision and NDCG calculated from this?\n\nMore importantly I don\'t believe looking at rank alone is sufficient since that completely obscures the actual performance numbers obtained via transfer. In most cases I would care about how well my model would perform on transfer not just which tasks I should transfer from. I would have wanted to understand something like the correlation of these produced scores with the actual ground truth performance numbers.\n\n- (W5) Multi-task learning: I did not see any mention or experiments of what can be expected when the representations are themselves trained on multiple tasks. (This seems like something that could easily be done in the empirical analysis as well and would provide richer empirical signals as well)\n\n- (W6) Motivation for CFS: I still don\'t fully understand the need to understand the density of the representation (especially in the manner proposed in the paper). Why is this an important problem? Perhaps expanding on this would be helpful\n\n- (W7) Alternatives to CFS / Computational concerns: A big concern I had was the computational expense of the proposed approach. Unfortunately I did not see any discussion about this in the paper or empirically.\n\nI find this striking because I can easily come up with cheaper alternatives to get at this ""density"". For example using LASSO / LARS like methods you can perhaps figure out a good reduced dimension set more efficiently.\n\nIf I were to go through the computation of then why not just train a smaller version of that representation technique instead and **directly** see how well it can encode data in k dimensions via that technique / for that task?\n\nAlternatively why not try using a factorization technique to reduce the rank and then see how well the method does for different ranks?\n\n- (W7b) Likewise I wonder if we could just measure transfer more directly as well and why we need to go via these CFS sets\n\n- (W8) The proposed  CLF weight difference method has some concerning aspects as well. For example say we had two task with exact opposite labels. They would have a very low weight difference score though they are ideal representations for each other. Likewise looking at a difference of weight vectors seems arbitrary in other ways as well.\n']","[-20, 50, -60]","[60, 80, 40]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting direction and some positive aspects, they also point out several key weaknesses and areas for improvement. The overall tone suggests more concerns than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balancing criticism with positive comments, and phrases concerns as suggestions rather than harsh criticisms. They use phrases like 'it would be nice to see' and 'I am unconvinced' rather than more confrontational language. The reviewer also starts with positive points before moving to criticisms, which is a polite approach in academic reviews."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the problem addressed and the potential impact of the results. They mention several pros, including clear writing and promising experimental results. However, they also raise some concerns and questions, which balances out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions, and acknowledges the positive aspects of the work before discussing potential improvements. They use phrases like 'It is not clear to me' and 'Do you have thoughts on' which maintain a constructive and collegial tone."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the methodology and analysis, stating the paper 'needs more work before it is ready for publication'. They rate the quality and significance as 'Below average' and list numerous weaknesses. However, they do mention some positive aspects ('things I liked'), preventing an extremely negative score. The politeness score is 40 because the reviewer uses professional and respectful language throughout, acknowledging positive aspects and framing criticisms as 'concerns' rather than outright flaws. They use phrases like 'I liked aspects of this' and 'There were some nice ideas in the work' to soften their critique. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['This study explores the class hierarchy to solve many-class few-short learning problem in both traditional supervised learning and meta-learning. The model integrates both the coarse-class and fine-class label as the supervision information to train the DNN, which aims to leverage coarse-class label to assist fine-class prediction. The core part in the DNN is memory-augmented attention model that includes at KNN classifier and Memory Update mechanism. The re-writable memory slots in KNN classifier aim to maintain multiple prototypes used to describe the data sub-distribution within a class, which is insured by designing the memory utility rate, cache and clustering component in Memory Update mechanism. This study presents a relatively complex system that combines the idea of matching networks and prototypical networks.\n\nOne of the contributions is that the study puts forward a concept of the many-class few-short learning problem in both supervised learning and meta-learning scenarios, and uses a dataset to describe this problem.\n\nUsing the memory-augmented mechanism to maintain multiple prototypes is a good idea. It may be more interesting if its effectiveness can be proved or justified theoretically. Furthermore, it is better to offer some discussion about the learned memory slots in the view of “diverse and representative feature”.\n\nThe experiment results in Table 4 and Table 5 compare the MahiNet with Prototypical Net on the mcfsImageNet and mcfsOmniglot dataset. It is better to compare MahiNet with other state-of-the-art works, such as the Relation Network whose performance is higher than Prototypical Net. In addition, if more  challenging datasets  can be further evaluated in the experiments,  the paper  might be more convincing.\n\nIn my opinion, the hierarchy information provides the guidance to fine-gained classification, which not only can be added to MahiNet but also the other models. Therefore, to prove its effectiveness, it is better to add hierarchy information to other models for comparison. In addition, regarding the results on the column of 50-5 and 50-10 in Table 4, when the number of class increase to 50, the results are just slightly higher than prototypical network. Considering that the memory update mechanism is of the high resource consumption and complexity, it is better to provide more details about clustering, and training and testing time.\n', 'This paper try to formulate many-class-few-shot classification problem from 2 perspectives: supervised learning and meta-learning. Although solving this problem with class hierarchy is trivial,  combing MLP and KNN in these two ways seems interesting to me. I still have several questions:\n\n1) How the class hierarchy is got , manually set or automatically generate?  Whether the ideas still work if some coarse classes share same fine class?\n2) The so-called attention module is just classic KNN operations, please don\'t naming it attention just because the concept ""attention"" is hot.\n3) Why different ""attention"" operations are used for supervised learning and meta-learning?\n4) How to get the pre-trained models for supervised learning?\n5) What will happen if alternatively apply supervised learning and meta-learning?\n6) In Table 4, why MahiNet(Mem-2) w/o Attention and Hierarchy performs better than the one w/o attention?\n7) The authors just compare storing the average features and all features, I think results of different prototype number should be given, since one of their claim to apply KNN is to maintain a small memory.\n\n ', ""This paper presents methods for (1) adding inductive bias to a classifier through coarse-to-fine prediction along a class hierarchy and (2) learning a memory-based KNN classifier through an intuitive procedure that keeps track of mislabeled instances during learning. Further, the paper motivates focused work on the many class / few shot classification scenario and creates new benchmark datasets from subsets of imagenet and omniglot that match this scenario. Experimental results show gains over popular competing methods on these benchmarks.\nOverall, I like the motivation that this paper provides for many class / few shot and find some of the methods proposed interesting. Yet there are issues with clarity of presentation that made it somewhat difficult to fully understand the exact procedures that were implemented. The model figure is useful, but could be refined to add additional clarity -- particularly in the case of the KNN learning procedure. \nI'm not entirely familiar with recent work in this sub-field, so it is difficult for me to judge the novelty of the proposed procedure. Is it really true that class-hierarchies have never been used to perform coarse-to-fine inference in past work? If so, this should be state clearly. If not, related work should be mentioned and compared against. Finally, while the procedures are intuitive -- the takeaway of this paper could be substantially improved if even simple theoretical analysis were provided. For example, in the limit of infinite data, does the memory-based KNN learning procedure actually produce the right classifier? \nMisc comments questions:\n-The paper says at least twice that coarse classification will be performed with an MLP, while fine classification will use a KNN -- yet, the model section also state that both coarse and fine use both MLP and KNN. It is unclear to me which model setup was used in experiments. \n-Can anything theoretical be shown about the class hierarchy based classification technique? Intuitively, it does add inductive bias through a manually defined taxonomy, but can something more precise be said about how it restricts the hypothesis space? This procedure is simple enough that I would be surprised if similar techniques had not be studied thoroughly in the statistical learning theory literature. \n-The procedure for updating the KNN memory is intuitive, but can anything more be said about it? In isolation, is the KNN learning procedure at least consistent -- i.e. in the limit of large data does it converge to the correct classifier? Maybe this is trivial to prove, but is worth including. \n""]","[50, -20, 20]","[75, 30, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the study's contributions and innovative ideas, such as the memory-augmented mechanism and the concept of many-class few-shot learning. However, they also provide several suggestions for improvement, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism with phrases like 'it is better to' and 'it may be more interesting if'. They also acknowledge the positive aspects of the study before suggesting improvements, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer finds some aspects of the paper interesting, they raise several critical questions and point out issues with the methodology and terminology. The initial statement 'Although solving this problem with class hierarchy is trivial' also suggests some skepticism about the paper's approach. However, the reviewer does acknowledge that some aspects of the work seem interesting, which prevents the score from being more negative. The politeness score is moderately positive (30) as the reviewer maintains a professional tone throughout, using phrases like 'please don't' instead of more confrontational language. They also frame their criticisms as questions rather than direct accusations, which is a polite approach. The reviewer doesn't use overly complimentary language, which keeps the politeness score from being higher."", ""The sentiment score is slightly positive (20) because the reviewer expresses liking the motivation and finding some methods interesting, but also points out issues with clarity and suggests improvements. The overall tone is constructive rather than overtly negative or positive. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I like,' 'I'm not entirely familiar,' and phrases questions considerately. The reviewer offers critiques in a respectful manner, asking for clarification rather than making harsh judgments. The language is professional and courteous, avoiding any rudeness while maintaining a critical perspective.""]"
"['The idea of extending  Riemannian Langevin dynamics to functional spaces is elegant, however it is extremely hard to follow the proposed method as details are kept to a minimum. The finite approximation of the posterior distribution is a function of the parameters theta, however it displays parameters lambda. The couple of sentences: ""Then by sampling λ, we sample a functional f equivalently. The Riemannian Langevin dynamics on the functional space can thus be written as: (6)"" come without a single explanation.\n\nMinor comments\n* Max and Whye is the casual version for reference Welling and Teh.\n* proper nouns in References should be capitalized', 'This paper considers a new learning paradigm for Bayesian Neuron Networks (BNN): learning distribution in the functional space, instead of weight space. A new SG-MCMC variant is proposed in Algorithm 1, and applied to sampling in a \n""functional space"". The approach is demonstrated on various tasks.\n\nQuality: Low, due to the low clarity detailed below.\n\n\nClarity: I do not fully follow the core algorithm:  The posterior is U_D(\\theta) = \\sum_{i=1}^D  \\lambda_i * u_i, where  \\lambda_i is represented as MCMC samples,  what is u_i then? I guess u_i is defined in (2), which is approximated in (3) if weight sample is used. However, how is u_i represented in the functional approach? I guess it is similar to the weight-based approach. If this is true, how could we distinguish between a functional approach and weight-based approach?\n\nThe proposed SGFuncRLD is essentially Adam plus Gaussian noise, but performed in a so-called ""functional space""? It is therefore not surprise to me that SGFuncRLD performs better than pSGLD (RMSprop plus Gaussian noise), just as Adam performs better than RMSprop. If we only focus on the new SG-MCMC approach itself, the authors need to justify: (1) the smoothed gradient is an unbiased gradient estimator, how does it effect convergence? Does it guarantee to  true posterior? this should be done in theory. (2)  The SGFuncRLD  algorithm itself is the same with pSGLD except the smoothed gradient part.  This makes  the clear comparison even important. Does SGFuncRLD  perform better just because the proposed smoothed gradient, or because the sampling is done in the functional space?\n\nMy suggestions: Please disentangle the contributions clearly. There are two things: (1) smooth gradient, (2) sampling in a functional space. Which one really contributes the performance improvement?\n\nTo demonstrate (1),  the authors could at least conduct on a toy distribution, to demonstrate the difference with pSGLD, regardless it is to the functional space or the weight space. \nTo demonstrate (2), the authors  could apply the same SG-MCMC variant to the functional space and to the weight space, and see the difference. \n\nOriginality: To me, the idea of learning uncertainty of BNN in the functional space appeared in Prof.  Yee Whye Teh\'s NIPS 2017 presentation. The motivation in his presentation is very clear. However, how to implement this abstract idea in practice is unclear yet. This submission is the first attempt. However, I am concerned about the real contribution.\n\nSignificance: It is a very interesting research direction. The paper could have been significant if every part is clearly motivated and demonstrate. At this point, I am not fully convinced. ', ""The authors propose an approximate MCMC method for sampling a posterior distribution of weights in a Bayesian neural network.  They claim that existing MCMC methods are limited by poor scaling with dimensionality of the weights, and they propose a method inspired by HMC on finite-dimensional approximations of measures on an infinite-dimensional Hilbert space (Beskos et al, 2011).  In short, the idea is to use a low dimensional approximation to the parameters (i.e. weights) of the neural network, representing them instead as a weighted combination of basis functions in neural network parameter space.  Then the authors propose to use HMC on this lower dimensional representation.  While the idea is intriguing, there are a number of flaws in the presentation, notational inconsistencies, and missing experiments that prohibit acceptance in the current form.\n\nThe authors define a functional, f: \\theta -> [0, 1], that maps neural network parameters \\theta to the unit interval.  They claim that this function defines a probability distribution on \\theta, but this not warranted.  First, \\theta is a continuous random variable and its probability density need not be bounded above by one; second, the authors have made no constraints on f actually being normalized.  \n\nThe second flaw is that the authors equate a posterior on f given the data with a posterior on the parameters \\theta themselves.  Cf. Eq 4 and paragraph above.  There is a big difference between a posterior on parameters and a posterior on distributions over parameters.   Moreover, Eq. 5 doesn't make sense: there is only one posterior f; there are no samples of the posterior. \n\nThe third problem appears in the start of Section 3, where the authors now call the posterior U(theta) instead of f.  They make a finite approximation of posterior U(\\theta) = \\sum_i \\lambda_i u_i, which is inconsistent with Beskos et al.  I believe the authors intend to use a low dimensional approximation to \\theta rather than its posterior U(\\theta).  For example, if \\theta = \\sum_i \\lambda_i u_i for fixed basis functions u_i, then you can approximate a posterior on \\theta with a posterior on \\lambda.\n\nThe fourth, and most important problem, is that the basis functions u_i are never defined.  How are these chosen? Beskos et al use the eigenfunctions of the Gaussian base measure \\pi_0, but no such measure exists here.  Moreover, this choice will have a substantial impact on the approximation quality. \n\nThere are more inconsistencies and notational problems throughout the paper.  Section 4.1 begins with a mean field approximation that seems out of place.  Section 3 clearly states that the posterior on theta is approximated with a posterior on lambda, and this cannot factorize over the dimensions of theta.  Finally, the authors again confuse the posterior on weights with a posterior on distributions of weights in Eq 11.   \\tilde{U} is introduced as a function of lambda in Eq 14 and then called with f in line 4 of Alg. 1.  These two types are not interchangeable. \n\nThese inconsistencies cast doubt on the subsequent experiments.  Assuming the algorithm is correct, a fundamental experiment is still missing. \nTo justify this approach, the authors should show how the posterior approximation quality varies as a function of the size of the low dimensional approximation, D.\n\nI reiterate that the idea of approximating the posterior distribution over neural network weights with a posterior distribution over a lower dimensional representation of weights is interesting.  Unfortunately, the abundance of errors in presentation cloud the positive contributions of this paper.""]","[-50, -60, -70]","[20, 20, 20]","[""The sentiment score is -50 because the review expresses significant criticism about the paper's clarity and lack of detail, despite acknowledging the elegance of the idea. The reviewer states it's 'extremely hard to follow' and points out unexplained elements, indicating a negative sentiment. However, it's not entirely negative as the reviewer recognizes the idea as 'elegant'. The politeness score is 20 because the language is generally professional and constructive. The reviewer offers specific feedback and suggestions for improvement, which is helpful. The use of 'Minor comments' to separate less important issues is considerate. However, the directness of some criticisms ('come without a single explanation') prevents a higher politeness score. The reviewer maintains a respectful tone overall, avoiding harsh language or personal attacks."", ""The sentiment score is -60 because the review is generally negative, with the reviewer stating the quality is 'Low' and expressing several concerns about the clarity and contributions of the paper. However, it's not entirely negative as the reviewer acknowledges it's an 'interesting research direction'. The politeness score is 20 because while the reviewer is critical, they use professional language and offer constructive suggestions. They avoid personal attacks and use phrases like 'Please disentangle' and 'My suggestions', which are polite ways to give feedback. The reviewer also acknowledges potential positives, which adds to the politeness."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out multiple flaws, inconsistencies, and missing elements in the paper. Phrases like 'prohibit acceptance in the current form', 'abundance of errors', and 'cast doubt on the subsequent experiments' indicate a strong negative sentiment. However, the reviewer does acknowledge that the core idea is 'intriguing' and 'interesting', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I believe the authors intend to' and 'I reiterate that the idea... is interesting' which show a level of respect and consideration. The reviewer also provides detailed explanations for their criticisms, which is a polite way to give feedback. However, the directness of some criticisms and the lack of more positive language keeps the score from being higher.""]"
"['This paper describes multi-grained entity recognition. Experimental results show that the proposed Multi-Grained Proposal Network achieve better performance on NER tasks.\n\nMajor comments:\n\n- A major weakness of this paper is lack of citations to recent related studies. There are studies on nested NER published this June:\n\nA. Katiyar and C. Cardie, Nested Named Entity Recognition Revisited, NAACL/HLT 2018, June, 2018.\nM. Ju, et al., A neural layered model for nested named entity recognition, NAACL/HLT 2018, June 2018.\n\nYou need to compare these conventional methods to your proposed method.\n\n', '\n<Summary>\nAuthors propose the “Multi-grained NER (MGNER)  task” which aims at detecting entities at both coarse and fine-grained levels. Authors propose a Multi-grained Entity Proposal Network (MGEPN) which comprises (1) a Proposal Network that determines entity boundaries, and (2) a Classification network that classifies each proposed segment of an entity.\n\nThe task is primarily tested against the proposed method itself. The proposed method does outperform traditional sequence-labeling baseline model (LSTM-LSTM-CRF), validating the proposed approach. When the proposed model (trained with extra MG data) is evaluated on the traditional NER task (on test sets), however, no significant improvement is observed -- I believe this result is understandable though, because e.g. MG datasets have slightly different label distributions from original datasets, hence likely to result in lower recall, etc.\n\n<Comments>\nThe task studied is interesting, and can potentially benefit other downstream applications that consume NER results -- although it seems as though similar tasks have been studied prior to this study. The novelty of the proposed architecture is moderate - while each component of the model does not have too much technical novelty, the idea of separating the model into a proposal network and a classifier seems to be a new approach in the context of NER (that diverges from the traditional sequence labelling approaches), and is reasonably designed for the proposed task.\n\nThe details for creating the MG datasets is missing - are they labeled by human labelers, or bootstrapped? Experts or crowd-sourced? By how many people? Will the new datasets be released? Please provide clarifications.\n\nThe proposed approach does not or barely outperform base models when tested on the traditional NER task -- the proposed work thus can be strengthened by better illustrating the motivation of the MGNER task and/or validating its efficacy in other downstream tasks, etc. \x0c\n\nAuthors could provide better insights into the new proposed task by providing more in-depth error analysis - especially the cases when MG NER fails as well (e.g. when coarse-grained prediction predicts a false positive named-entity, etc.)\n', 'This paper proposed a entity proposal network for named entity recognition which can be effectively detect overlapped spans. The model obtain good performance on both Multi-grained NER task and traditional NER task. The paper is in general well written, the idea of proposal network break the traditional framework of sequence tagging formulation in NER task and thus can be effectively applied to detect overlapped named entities.\n\nHowever, I still have many concerns regarding the notation, the novelty of the paper, and the comparison with related literature, especially on previous overlapped span detection NER papers. The detailed concerns and questions are as follows:\nThe notations are very confusing. Many of the notations are not defined. For example, what does $T$ in $2D_sl*2T$ below Eq. 4 indicates?  What does $R$ scores means? I guess $R$ does not equal to number of entity types, but I’m not sure what $R$ exactly indicates. If $R$ is not number of entity types, why do you need R scores for being an entity and R scores for not being an entity? And what is $t$ in Eq 5? Is that entity type id or something else?\nI’m still confused how you select the entity spans from a large number of entity candidates. In Figure 5, if the max window length is 5, there may be more span candidates than the listed 5 examples, such as t_3 t_4 t_5. How do you prune it out?\nTable 5 is weird. There is not comparison with any baselines but just a report of the performance with this system. I don’t know what point this table is showing.\nThis is not the first paper that enumerates all possible spans for NER task.The idea of enumerating possible spans for NER task has appeared in [1] and can also effectively detect overlapped span. I would like to see the performance comparison between the two systems. The enumerating span ideas has been applied in many other tasks as well such as coreference resolution [2]and SRL[3], none of which is mentioned in related work.\nI feel that most of the gain is from ELMo but not the model architecture itself, since in Table 4, the improvement from the ELMo is only 0.06. The LSTM-LSTM-CRF is without adding ELMo, which is not a fair comparison. \nThe comparison of baselines is not adequate and is far from enough. The paper only compares with LSTM+CRF frameworks, which are not designed for detecting overlapped spans. There are many papers on detecting overlapping spans, such as [4], [5] and [6]. It’s important to compare with those paper since those methods are especially designed for overlapped span NER tasks.\n[1] Multi-Task Identification of Entities, Relations, and Coreferencefor Scientific Knowledge Graph Construction, EMNLP 2018\n[2] End-to-end neural coreference resolution, EMNLP 2017\n[3] Jointly predicting predicates and arguments in neural semantic role labeling, ACL 2018\n[4] Nested Named Entity Recognition Revisited, NAACL 2018\n[5] A Neural Layered Model for Nested Named Entity Recognition, NAACL 2018\n[6] Neural Segmental Hypergraphs for Overlapping Mention Recognition, EMNLP 2018']","[20, 20, -20]","[50, 50, 50]","[""The sentiment score is slightly positive (20) because the review starts with a neutral description of the paper and acknowledges that the proposed method achieves better performance. However, it then points out a 'major weakness', which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses professional language and offers constructive criticism. They directly state the paper's weakness but do so without harsh language, and provide specific suggestions for improvement. The use of 'You need to' is direct but not impolite in this context."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting nature of the task and the moderate novelty of the proposed architecture. However, they also point out several limitations and areas for improvement, balancing the positive aspects. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'please provide clarifications' and 'could provide better insights', which are polite ways of requesting improvements. The reviewer also acknowledges the understandable nature of some limitations, showing empathy towards the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper in the first paragraph ('good performance', 'well written', 'can be effectively applied'), the majority of the review consists of concerns and criticisms. These include issues with notation, novelty, comparison with related literature, and inadequate baselines. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing criticisms as 'concerns' and 'questions' rather than direct attacks. They also begin with positive comments before moving to criticisms. However, the tone is not overly deferential, maintaining a professional, matter-of-fact style appropriate for peer review.""]"
"['This paper proposes a network architecture inspired by the primate visual cortex. The architecture includes feedforward, feedback, and local recurrent connections, which together implement a predictive coding scheme. Some versions of the network are shown to outperform the similar PredNet and PredRNN architectures on two video prediction tasks: moving MNIST and KTH human actions. Finally, the authors provide neural data from monkeys and argue that their network shows similarities to the biological data.\n\nThe paper contains intriguing ideas about the benefits of sparse and predictive coding, and the direct comparison to biological data potentially broadens the impact of the work. However, major claims are unsubstantiated, and accuracy and clarity need to be improved to make the manuscript acceptable.\n\nMajor concerns:\n1. The authors claim that their architecture is more efficient because it uses sparse coding of residuals. Implementation details and some quantitative arguments, ideally benchmarks, need to be provided to show that their architecture is actually more efficient than PredRNN++ and PredNet.\n\n2. It is unclear whether the PredRNN++ should be compared to the C-C or C-F version of the network. Does the PredRNN++ have access to as many current and future frames as the C-C net? Is this a fair comparison? Please provide a clearer description of the different versions of your network and how they relate to the baseline models. That section in particular has many confusing typos (frame-by-chunk, chunk-by-frame abbreviations mixed up).\n\n3. In Figure 6, the authors claim that more layers lead to “better” representations. What does “better” mean? It is implied that the networks with more layers actually make the different motions more discriminable. Please quantify this. For example, a linear classifier could be trained on the neural activations. Also, how is this related to the rest of the paper? Do the authors claim that this result is unique to the proposed architecture? In that case, please provide a quantitative comparison to the PredNet or PredRNN++.\n\n4. In Figure 9, the presentation is highly confusing. Plots (c) to (h) are clearly made to look like the monkey data in (b) (nonlinear x-axes?), but show totally different timescales (training epochs vs. milliseconds). Please explain why it makes sense to compare these timescales. Also, what does it mean for a training epoch to have a negative value? \n\nMinor comments:\n1. I don’t understand the “tension” between hierarchical feature representations and residual representations brought up in Section 2. Do the PredNet and PredRNN++ not contain a hierarchy of representations?\n\n2. Figure 1 is not fully annotated and could be clearer. What does the asterisk mean? Why are there multiple arrows between the P’s? What do the small arrows next to the big arrows mean? Please expand the legend. Consider using colors to differentiate between components.\n\n3. I don’t understand Figure 4c. According to the text, this plot shows “effectiveness as a function of time”, but the x-axis is labeled “Layer Number”. What does “effectiveness over time” mean? What does the y-label mean (SSIM per day?)? What is “trunk prediction” (not mentioned anywhere in the text)?\n\n4. For Figure 9, it is pointed out that activity is expected to be lower for E neurons, but is also lower for R and P. This is interesting and also applies to Figure 8, so it would be good to see Figure 8 split up by E/R/P, too. \n\n5. The word “Figure” is missing before figure references.\n\n6. Please proof-read for typography, punctuation and grammar.', 'The authors propose a biologically inspired ANN to predict a video sequence, that performs better than previous biologically inspired video sequence predictors (>PredNet and >PredRNN+).  Their model also accounts for familiarity effects (i.e. decrease in neural activations when repeatedly presenting the same visual sequence) found in primate early visual system V1/V2 (data recorded for this article) and late visual system IT.\n\nThis work is interesting because it proposes a sequence prediction technique that accounts well for familiarity effects found in different regions of the visual system.\n\nHowever one of the claims does not seem supported by data:\n\n1. The authors claim repeatedly that using the prediction error framework is computationally more efficient than alternatives but they do not show this.\n\nFurthermore, the article would benefit from the following clarifications:\n\n2. It is unclear how their network performance compares to state-of-the-art NON neurally plausible models of sequence prediction.\n\n3. It is unclear from the introduction how they modified the network proposed by (Pan et al) to obtain their network. \n\n4. ""The SSIM index over time shows that the C-C method is more effective than C-F method, for C-F method performs better than C-C method in the short term perdiction when ground truth images are provided, but setting sliding window is too time-consuming, much more than the performance increase""\nPlease clarify this statement.\n\n5. Macaque experiments: Some experiments on macaques were performed for this article, but there is no mention of ethical guidelines and whether they were respected.\n\n6. Many typos are present in the text!\n\nI believe this work at the intersection of deep learning and neuroscience is an interesting contribution for both fields. However, the paper would benefit from these clarifications and a thorough proof-reading for the many typos present in the text. \n', 'Summary:\nThe paper presents a novel architecture for video prediction consisting of a feed-forward path with sparse convolutions and an LSTM generating predictions of chunks of video based on the sequence of input chunks. A feedback path links the LSTMs of the different sparse prediction modules. Experiments in video prediction are performed on moving-MNIST and the KTH action recognition dataset and the model achieves state-of-the-art performance on both. Interestingly, the model is exhibits prediction suppressions effects as have been observed during neurophysiological experiments in the inferotemporal cortex of macaque monkeys. The proposed method exhibits prediction suppression effects also in the lower layers, motivating a neurophysiological experiment in the earlier V1/V2 regions, which yielded an observation similar to the model’s prediction.\n\nStrengths:\nThe performance improvements over competing methods on Moving-MNIST and KTH presented in the experimental section are significant. The analysis seems fairly thorough.\n\nWeaknesses and requests for clarification:\n- The description of the sparse predictive module is difficult to follow, and I am not sure I understood it completely. I find it a bit unintuitive to start the description with the errors, instead of explaining what is computed from beginning to end. The section reads more like a loose description of isolated parts instead of an integrated whole. Maybe walking the reader step-by-step through one complete iteration of the computation helps to clarify this. Also, not every character in equations 1-5 and the algorithm has been defined. For example, what is L? \n- The text makes it sound like the idea of using 3d convolutions in a convLSTM is novel. 3D convLSTMs have been previously used in 3d vision, see \nChoy, C. B., Xu, D., Gwak, J., Chen, K., & Savarese, S. (2016, October). 3d-r2n2: A unified approach for single and multi-view 3d object reconstruction. In European conference on computer vision (pp. 628-644). Springer, Cham.\nThe application of 3d convLSTMs to video might be new, but the mentioned paper by Choy et al. (2016) should be cited.\n- You mention that padding is used for rows and columns. Are you using padding on the temporal axis as well?\n- The paper seems to be written in a rush, as it contains way too many typos and grammar mistakes, e.g. “a hierarchical of” (should be “a hierarchy of“ or just “hierarchical”), “feedforwad”, “Expriment” (section 4 heading), “achievedbetter”, “trained monkeys to image pairs”, “pervious”, “perserves”, “processure”, “sequnence” “viusal”. Many typos could have been caught by a spellcheck! This would improve readability a lot!\n- The citations are not properly formatted: (1) If the author names are used as part of the sentence, use e.g. Lotter et al. (2016), else (2) If the author names are not part of the sentence, use (Lotter et al., 2016). These two styles are mixed randomly in the current draft. This makes the manuscript, which already contains a lot of language mistakes, difficult to read.\n- Abbreviations that are used but not introduced: CNN, IT, PSTH, DCNN, LSTM.\n- The related work section could benefit from referring to some of the related work in neuroscience.\n- Adding a sentence explaining the intuition behind using SatLU in equation (1) might be helpful\n\nTo summarize my feedback: I think experimental results and analysis are strong, but the presentation is strongly lacking! The description of the approach definitely needs to be improved to make replication of the results easier. It might help to have someone who doesn’t know the model already read the description and explain it back to you while revising the draft. I hope I could provide some helpful suggestions. I would recommend the manuscript for acceptance, if the presentation is significantly improved!']","[-30, 20, 20]","[50, 60, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('intriguing ideas', 'potentially broadens the impact'), they express major concerns and state that 'major claims are unsubstantiated'. The overall tone suggests significant improvements are needed. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and specific suggestions for improvement. They avoid harsh or dismissive language, instead using phrases like 'please explain' and 'consider using'. However, the review is not overly effusive or deferential, maintaining a professional tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work as 'interesting' and a contribution to both deep learning and neuroscience fields. However, they also point out several issues and areas for improvement, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions for improvement rather than harsh criticisms. They use phrases like 'would benefit from' and 'please clarify' which maintain a polite tone. The reviewer also balances critique with positive remarks, showing consideration for the authors' work while providing necessary feedback."", 'The sentiment score is slightly positive (20) because while the reviewer points out several weaknesses and areas for improvement, they also highlight significant strengths and recommend the manuscript for acceptance if improvements are made. The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions for improvement, and frames criticisms as requests for clarification or areas to strengthen rather than outright faults. The reviewer also acknowledges the strong points of the work and expresses hope that their feedback is helpful. However, the score is not higher due to the direct nature of some criticisms, particularly regarding typos and formatting issues.']"
"['This paper presents a methodology to bring together independent subspace analysis and variational auto-encoders. Naturally, in order to do that, the authors propose a specific family of prior distributions that lead to subspace independence the Lp-nested distribution family. This prior distribution is then used to learn disentangled and interpretable representations. The mutual information gap is taken as the measure of disentanglement, while the reconstruction loss measures the quality of the representation. Experiments on the sPrites dataset are reported, and comparison with the state of the art shows some interesting results.\n\nI understand the limitations of current approaches for learning disentangled representations, and therefore agree with the motivation of the manuscript, and in particular the choice of the prior distribution. However, I did not find the answer to some important questions, and generally speaking I believe that the contribution is not completely and clearly described.\nP1) What is the shape of the posterior distribution?\nP2) How does the reparametrization trick work in your case?\nP3) How can one choose the layout of the subspaces, or this is also learned?\n\nMoreover, and this is crucial, the proposed method is not clearly explained. Different concepts are discussed, but there is no summary and discussion of the proposed method as a whole. The reader must infer how the method works from the different pieces. \n\nWhen discussing the performance of different methods, and even if in the text the four different alternatives are clearly explained, in figure captions and legens the terminology changes (ISA-VAE, ISA-beta-VAE, beta-VAE, beta-ISA-VAE, etc). This makes the discussion very difficult to follow, as we do not understand which figures are comparable to which, and in which respect.\n\nIn addition, there are other (secondary) questions that require an answer.\nS1) After (10) you mention the subspaces v_1,...v_l_o. What is the formal definition of these subspaces?\nS2) The definition of the distribution associated to ISA also implies that n_i,k = 1 for all i and k, right?\nS3) Could you please formally write the family of distributions, since applying this to a VAE is the main contribution of your manuscript?\nS4) Which parameters of this family are learned, and which of them are set in advance?\nS5) From Figure 4 and 5, I understand that the distributions used are of the type in (7) and not (10). Can you comment on this?\nS6) How is the Lp layout chosen?\nS7) Why the Lp layout for ISA-beta-VAE in Figure 5 is not the same as in Figure 4 for ISA-VAE?\nS8) What are the plots in Figure 4? They are difficult to interpret and not very well discussed.\n\nFinally, there are a number of minor corrections to be made.\nAbstract: latenT\nEquation (3) missig a sum over j\nFigure 1 has no caption\nIn (8), should be f(z) and not x.\nBefore (10), I understand you mean Lp-nested\nI did not find any reference to Figure 3\nIn 4.1, the standard prior and the proposed prior should be referred to with different notations.\n\nFor all these reasons I recommend to reject the paper, since in my opinion it is not mature enough for publication.', 'The authors point out several issues in current VAE approaches, including the rotational symmetric Gaussian prior commonly used. A new perspective on the tradeoff between reconstruction and orthogonalization is provided for VAE, beta-VAE, and beta-TCVAE. By introducing several non rotational-invariant priors, the latent variables\' dimensions are more interpretable and disentangled. Competitive quantitative experiment results and promising qualitative results are provided. Overall, I think this paper has proposed some new ideas for the VAE models, which is quite important and should be considered for publication.\n\nHere I have some suggestions and I think the authors should be able to resolve these issues in a revision before the final submission:\n1) The authors should describe how the new priors proposed work with the ""reparameterization trick"". \n2) The authors should at least provide the necessary implementation details in the appendix, the current manuscript doesn\'t seem to contain enough information on the models\' details.\n3) The description on the experiments and results should be more clear, currently some aspects of the figures may not be easily understood and need some imagination. \n4) There are some minor mistakes in both the text and the equations, and there are also some inconsistency in the notations.\n', 'The paper used the family of $L^p$-nested distributions as the prior for the code vector of VAE and demonstrate a higher MIG. The idea is adopted from independent component analysis that uses rotationally asymmetric distributions. The approach is a sort of general framework that can be combined with existing VAE models by replacing the prior. However, I think the paper can be much improved in terms of clarity and completeness.\n\n1. The authors used MIG throughout section 4. But I have no idea what it is. Does a better MIG necessarily imply a good reconstruction? I am not sure if we can quantify the model performance by the mere MIG, and suggest the authors provide results of image generations as other GAN or VAE papers do. \n2. Is the ""interpretation"" important for high dimensional code $z$? If yes, can the authors show an example of interpretable $z$?\n3. I had difficulty reading Section 4, since the authors didn\'t give many technical details; I don\'t know what the encoder, the decoder, and the specific prior are. \n4. The authors should have provided a detailed explanation of what the figures are doing and explain what the figures show. I was unable to understand the contribution without explanations.\n5. Can the authors compare the proposed prior with VampPrior [1]?\n\nThe paper should have been written more clearly before submission.\n[1] Tomczak, Jakub M., and Max Welling. ""VAE with a VampPrior."" arXiv preprint arXiv:1705.07120 (2017).']","[-70, 70, -30]","[20, 80, 20]","[""The sentiment score is -70 because the reviewer recommends rejecting the paper, stating it's 'not mature enough for publication'. They list numerous issues and unanswered questions, indicating a largely negative view. However, they do acknowledge some positive aspects ('interesting results', agreeing with the motivation), preventing the score from being extremely negative. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use polite phrases like 'Could you please' and 'I understand', and frame their criticisms as questions or areas needing clarification rather than outright attacks. However, the overall negative feedback and recommendation for rejection prevent the score from being higher."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it has 'proposed some new ideas' that are 'quite important' and recommending it 'should be considered for publication'. The tone is encouraging, though not overwhelmingly enthusiastic. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, framing their suggestions as 'I think' and 'should', rather than using demanding or harsh language. They acknowledge the paper's strengths before offering constructive feedback. The reviewer maintains a professional and courteous tone while providing specific, actionable recommendations for improvement."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('demonstrate a higher MIG', 'general framework that can be combined with existing VAE models'), the overall tone is critical. The reviewer states that the paper 'can be much improved' and lists several significant issues, concluding that it 'should have been written more clearly before submission'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 20 because the reviewer uses polite language throughout, framing criticisms as suggestions ('I suggest', 'Can the authors...') and avoiding harsh or accusatory language. However, the politeness is not overly effusive, maintaining a professional tone. The final statement is more direct but still not rude, keeping the score slightly positive.""]"
"[""The paper tries to describe SGD from the point of view of the distribution p(y',y) where y is (a possibly corrupted) true class-label and y' a model prediction. Assuming TV metric of probabilities, a trajectory is defined which fits to general learning behaviour of distributions.\n\nThe issue is that the paper abstracts the actual algorithm, model and data away and the only thing that remains are marginal distributions p(y) and conditional p(y'|y). At this point one can already argue that the result is either not describing real behavior, or is trivial. The proposed trajectory starts with a model that only predicts one-class (low entropy H(y') and high conditional entropy) and ends with the optimal model. the trajectory is linear in distribution space, therefore one obtains initially a stage where H(y') and H(y'|y) increase a lot followed by a stage where H(y'|y) decrease.\n\nThis is known to happen, because almost all models include a bias on the output, thus the easiest way to initially decrease the error is to obtain the correct marginal distribution by tuning the bias. Learning the actual class-label, depending on the observed image is much harder and thus takes longer. Therefore no matter what algorithm is used, one would expect this kind of trajectory with a model that has a bias.\n\nIt also means that the interesting part of an analysis only begins after the marginal distribution is learned sufficiently well. and here the experimental results deviate a lot from the theoretical prediction. while showing some parabola like shape, there are big differences in how the shapes are looking like.\n\nI don't see how this paper is improving the state of the art, most of the theoretical contributions are well known or easy to derive. There is no actual connection to SGD left, therefore it is even hard to argue that the predicted shape will be observed, independent of dataset or model(one could think about a model which can not model a bias and the inputs are mean-free thus it is hard to learn the marginal distribution, which might change the trajectory)\n\n Therefore, I vote for a strong reject."", ""This paper study the trajectory of H(\\hat{y}) versus H(\\hat{y}|y) on the information plane for stochastic gradient descent methods for training neural networks. This paper was inspired by (Ziv and Tishby 17'), but instead of measuring the mutual information I(X;T) and I(Y:T), this paper proposed to measure H(\\hat{y}) and H(\\hat{y}|y), which are much easier to compute but carries similar meaning as I(Y;T) and I(X;T).\n\nThe interesting part of this paper appears in Section 4, where the author makes a connection between the SGD training process and \\alpha-SMLC(strong Markov learning chain). SMLC is just simply linear combination of the initial distribution and the final stable distribution of the labels. The authors show that the trajectory of the real experiment is similar to that of SMLC.\n\nGenerally I think the paper is well-written and clearly present the ideas. Here are some pros and cons.\n\nPros 1: The trajectory presented in this paper is much more reliable than that in (Ziv and Tishby 17'), since measuring the entropy and conditional entropy of discrete random variables are much easier. Also it is easy for people to believe that the trajectory holds for various neural network structure and various activation functions.\n\nPros 2: The connection to SMLC is interesting and it may contain lot of insights.\n\nCons 1: One of my major concern is --- if you look at the trajectory of the experiment v.s. SMLC (Figure 3), they look similar at first glance. But if you look at it carefully, you will notice that the color of them are different! For SGD, the trajectory goes to the turning point very soon (usually no more than 10% of the training steps), whereas SMLC goes to the turning point much slower. How do the authors think about this phenomenon and what does this mean?\n\nCons 2: This paper is going to be more meaningful if the author can provide some discussions, especially about (1) what does the shape trajectory mean (2) what do the connection between the trajectory and Markov chain means (3) how can these connections be potentially useful to improve training algorithm? I understand that these questions may not be clearly answerable, but the authors should make this paper more inspiring such that other researchers can think deeper after reading this paper.\n\nCons 3: I suggest the authors using SGD instead of GD throughout the paper. Usually GD means true gradient descent, but the paper is talking about batched stochastic gradient descent. GD does not have Markovity.\n\nGenerally, I think the paper is on the borderline. I think the paper is acceptable if the author can provide more insights (against Cons 2)."", 'In summary, this paper does the following:\n- The initial problem is to analyze the trajectory of SGD in training ANNs in the space of  P of probability measures on Y \\times Y. This problem is interesting, but difficult. \n- the paper constructs a Markov chain that follows a shortest path in TV metric on P\n(the \\alpha SMLC)\n- through experiments, the paper shows that the trajectories of SGD and \\alpha-SMLC have  similar conditional entropy. \n\nMy issues with this paper are:\na/ The main result is a simulation. How general is this? Could it depend on the dataset? Could you provide some intuition or prove that for certain dataset, these two trajectories are the same (or very close)? \nb/ Meaning of this trajectory. This is not the trajectory in P, it is the trajectory of the entropies. In general, is there an intuitive explanation on why these trajectories are similar? And what does it mean -- for example, what would be a possible implication for training SGD? Could it be that all learning methods will have this characteristic parabolic trajectory for entropies? \nc/ The theoretical contribution is minor: both the techniques and results quoted are known. \n\nOverall, I think the paper lacks a take-away. It is an interesting observation that the trajectory of \\alpha-SMLC  is similar to that of SGD in these plots, but the authors have not made a sufficient effort to interpret this. \n']","[-80, 20, -50]","[-20, 60, 20]","[""The sentiment score is -80 because the review is highly critical and ends with a 'strong reject' recommendation. The reviewer points out multiple issues with the paper, stating that it doesn't improve the state of the art, its contributions are well-known or easy to derive, and there's no actual connection to SGD left. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite dismissive and blunt. Phrases like 'The issue is...', 'I don't see how this paper is improving...', and 'Therefore, I vote for a strong reject' contribute to a somewhat impolite tone. The reviewer doesn't offer any positive feedback or suggestions for improvement, which also contributes to the negative politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is 'well-written' and 'clearly present the ideas'. They also mention some pros, including the reliability of the trajectory and the interesting connection to SMLC. However, the score is not higher due to the 'cons' mentioned and the statement that the paper is 'on the borderline'. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers balanced feedback with both pros and cons, and phrases criticisms as suggestions or questions rather than direct attacks. The use of phrases like 'I think' and 'I suggest' also contribute to the polite tone. The reviewer maintains a professional and constructive approach, even when pointing out areas for improvement."", ""The sentiment score is -50 because the reviewer expresses several concerns about the paper's contributions and lack of interpretation, using phrases like 'issues with this paper,' 'lacks a take-away,' and 'not made a sufficient effort.' However, they do acknowledge that the observation is 'interesting,' which prevents the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language like 'Could you provide' and 'Overall, I think,' rather than harsh criticism. They also begin by summarizing the paper's contents objectively before presenting their concerns, which is a polite approach. The slightly positive score reflects this professional courtesy, although the review doesn't go out of its way to be overtly polite.""]"
"['This paper proposed an \n\n\n1. For me, the argument of the paper is ambitious. Data augmentation for DNN includes different perspective, including nonlinearity, adversarial etc. Generalization of  spatial and appearance models is not enough. The model formulate from a simple classification setting but does not involve too many for DNN models.  I put more references below. \n\n2. The experimental results are not strong. Not all strong baselines are included (I put some in the references). The improvements are marginal. Besides, I need more experimental setting information.\n\n3. The writing is not clear. For the related work part, it included many paragraph which are not related to the work, (e.g. GANs). In the introduction part, it did not mention the generalization of both spatial and appearance models, which is the main contribution.  \n\nReferences:\na. Good Semi-supervised Learning that Requires a Bad GAN\nb. Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference \nc. Temporal ensembling for semi-supervised learning', '[Summary]\n\nThis paper proposes a differentiable framework to learn to augment data for image classification. In particular, it uses spatial transformer and GANs as parametric data augmenters, and it formulates the validation set loss with respect to the data augmenter in a differentiable manner. \n\n[Pros]\n\n1.\tThe proposed method does not require many trials of model training under different training data, and it learns the data augmentation directly using the final classification objective.\n2.\tIt is inspiring to extend the differentiable form of influence function across the training and validation set and then across the original and augmented data. This paper also makes use of the most recent related advance to enable stochastic learning. The theory of the paper is nice.\n3.\tThe experimental results on MNIST (with less labeled data) and Cifar-10 are encouraging.\n\n[Cons]\n\n1.\tExperimental results can be stronger. Especially when compared to Ratner et al., this proposed method results in marginal performance gain. Given that Ratner et al.’s method trained the data augmentation module without supervision, the supervised learning in this paper does not show strong results. In addition, the paper did not report results on a more practical dataset (such ImageNet and Places). Even for Cifar-10, the reported numbers are away from the state-of-the-art. It is important to show the practical significance of the proposed method.\n2.\tData augmentation is naturally expected to be random, but the proposed method seems to learn a deterministic parameter for the augmenting transformation, which looks unnatural and limited. (Please clarify if I missed anything.) \n3.\tThe proposed method requires a parametric model (e.g, STN, GAN). However, differentiable parametric models are not always easy to design. This probably can be the biggest obstacle to apply the proposed method widely.\n\nOverall, the proposed method is very interesting. However, the experimental results are limited, and more discussions are needed. \n\n', 'This paper proposes an extension of the influence function study of Koh and Liang (2017) to data augmentation.  Influence of augmentation, carried out via a parameterized and differentiable model, on validation loss is approximated and the augmentation model is learned under this approximation.  Overall I think it is a valuable and publishable contribution.  I do find the paper to be unclear and perhaps could be improved in a few ways.  My main comments are:\n\n* The biggest question I have is it seems from Eq. 15 that authors are proposing an augmentation approach where the augmented samples replace the original samples and not co-exist with them in the training set.  I am not sure why Eq. 15 has to be set up like that, please elaborate.\n\n* In Section 3.4 it is stated that only top fully connected layer of F is considered to compute influence function for augmentation.  Does this also mean that when F is updated on augmented data only the top layer is updated?  Please clarify.\n\n* The paper is a bit difficult to follow due to lack of clarity and few errors:\n     - Section 2.1, Adversarial methods, “In these methods, a simple composition…adversarial examples” sentence is unclear\n     - Page 2 footnote “however, they are referred to as unsupervised due to learning is not involved” sentence is unclear\n     - Section 3.3 \\tilde{z} in first line should be \\tilde{z_i}\n     - Eq. 15 LHS should include \\tilde{z_i}\n     - Section 3.4 “adopts” -> “adopt”\n     - Section 3.4 “HVP” used without defining\n\n* Empirical evidence, while not extensive, is satisfactory.\n']","[-50, 20, 50]","[0, 60, 70]","[""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses in the paper, including an 'ambitious' but insufficient argument, 'not strong' experimental results, and unclear writing. However, it's not entirely negative as it acknowledges the paper's ambition and provides constructive feedback. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state their criticisms plainly (e.g., 'The writing is not clear') without using harsh language, but also without softening their critique with polite phrases."", ""The sentiment score is 20 (slightly positive) because the review acknowledges the paper's interesting and inspiring aspects, as well as its encouraging results. However, it also points out significant limitations and areas for improvement, balancing the positive aspects. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging both pros and cons objectively. The reviewer avoids harsh criticism and uses phrases like 'please clarify if I missed anything,' which shows consideration. The overall tone is constructive and professional, offering specific suggestions for improvement without being overly critical."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper is 'a valuable and publishable contribution,' indicating overall approval. However, they also mention several areas for improvement, which tempers the positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I think' and 'please elaborate,' and frames criticisms constructively. They also acknowledge the paper's value before offering suggestions. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, while providing specific, actionable feedback.""]"
"[""The paper performs model-based reinforcement learning. It makes two main contributions. First, it divides training into two phases: the unsupervised phase for learning transition dynamics and the second phase for solving a task which comes with a particular reward signal. The scope of the paper is a good fit for ICLR.\n\nThe paper is very incremental: the ideas of using an ensemble of models to quantify uncertainty, to perform unsupervised pre-training and to explore using an intrinsic reward signal have all been known for many years.\n\nThe contribution of the paper seems to be the combination of these ideas and the way in which they are applied to RL. I have the following observations / complaints about this.\n\n1. The paper is very sparse on details. There is no pseudocode for the main algorithm, and the quantity v^i_t (the epistemic variance on page 5) isn't defined anywhere. Without these things, it is difficult for me to say what the proposed algorithm is *exactly*.\n\n2. Sections 1 and 2 of the paper seem unreasonably bloated, especially given the fact that the space could have been more meaningfully used as per (1).\n\n3. The experimental section misses any kind of uncertainty estimates. If, as you say, you only had the computational resources for three runs, then you should report the results for all three. You should consider running at least one experiment for longer. This should be possible - a run of 50K steps of HalfCheetah takes about one hour on a modern 10-core PC, so this is something you should be able to do overnight.\n\n4. The exploration mechanism is a little bit of a  mystery - it isn't concretely defined anywhere except for the fact that it uses intrinsic rewards. Again, please provide pseudocode.\n\nAs the paper states now, the lack of details makes it difficult for me to accept. However, I encourage the authors to do the following:\n1. Provide pseudocode for the algorithm.\n2. Provide pseudocode for exploration mechanism (unless subsumed by (1)).\n3. Add uncertainty estimates to evaluation or at least report all runs.\n\nI am willing to re-consider my decision once these things have been done."", 'The authors built upon the PETS algorithm to develop a state uncertainty-driven exploration strategy, for which the main point is to construct a reward function. The proposed algorithm was then tested on a specific domain to show some improvement. \n\nThe contribution of this paper may be limited, as it needs a specific setting, as shown in Figure 1. Furthermore, this paper is a bit difficult to follow, e.g., it was not until the 5th page to describe their algorithm. I summarize the pros and cons as follows.\n\nPros:\n- The idea to include the exploration for PETS is somewhat interesting.\nCons:\n- The paper is a bit difficult to follow. Just to list a few places:\n  1. The term ""unsupervised exploration"" was mentioned a few times in this paper. I am not sure if this is an accurate term. Is there a corresponding ""supervised exploration"" used elsewhere? \n  2. When you introduced r_t in Section 3.3, how did you use it next? Was it used in Phase II?\n  3. For the PETS (oracle) in Figure 4, why are the settings different for forward and backward tasks?\n  4. What does ""random"" mean in Figure 4?\n- The novelty of this paper is somewhat limited, as it requires a specific setting and has been applied in only one domain.\n- There are a few grammar mistakes/typos in this paper. \n  1. What is ""k"" in the equation for r_t?\n  2.  ""...we three methods..."" in Page 6.', 'The authors address the problem of how to use unsupervised exploration in a first phase of reinforcement learning to gather knowledge that can be transferred to new tasks to improve performance in a second task when specific reward functions are available. The authors proposed a model-based approach which uses deep neural networks as a model for the environment. The model is PETS (probabilistic ensembles with trajectory sampling), an ensemble of neural networks whose outputs parametrize predictive distributions for the next state as a function of the current state and the action applied. To collect data during the unsupervised exploration phase, they use a metric of model uncertainty computed as follows: the average over all the particles assigned to each bootstrap is computed and the variance over these computed means is the\nmetric of uncertainty. The authors validate their method on the HalfCheetah OpenAI gym environment where they consider 4 different tasks related to running forward, backward, tumbling forward and tumbling backward. The results obtained show that they outperform random and count based exploration approaches.\n\nQuality:\n\nI am concerned about the quality of the experimental evaluation of the method. The authors only consider a single environment for their experiments and artificially construct 4 relatively similar tasks. I believe this is insufficient to quantify the usefulness of the proposed method.\n\nClarity:\n\nThe paper is clearly written and easy to read.\n\nNovelty:\n\nThe proposed approach seems incremental and lacks novelty. The described method for model-based exploration consists in looking at the mean of the prediction of each neural network in the ensemble and then computing the empirical average. This approach has been used before for active learning with neural networks ensembles:\n\nKrogh, Anders, and Jesper Vedelsby. ""Neural network ensembles, cross validation, and active learning."" Advances in neural information processing systems. 1995.\n\nThe used model, PETS, is also not novel and the proposed methodology for having first an unsupervised learning phase and then a new specific learning task is also not very innovative.\n\nSignificance:\n\nGiven the lack of a rigorous evaluation framework and the lack of novelty of the proposed methods, I believe the significance of the contribution is very low.']","[-50, -40, -60]","[20, 20, 20]","[""The sentiment score is -50 because the reviewer expresses several criticisms and concerns about the paper, describing it as 'very incremental' and 'sparse on details'. They also state that it's 'difficult for me to accept' in its current state. However, the score isn't lower because the reviewer does acknowledge some positive aspects (e.g., 'The scope of the paper is a good fit for ICLR') and offers constructive feedback for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I encourage the authors to' and 'I am willing to re-consider my decision', which show respect and openness. The language isn't overly polite, but it avoids rudeness and maintains a constructive approach."", ""The sentiment score is -40 because the review is generally critical, with more cons than pros listed. The reviewer states that the paper's contribution may be limited, it's difficult to follow, and has limited novelty. However, they do mention one positive aspect (the idea is 'somewhat interesting'), which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional manner. They use phrases like 'may be limited' instead of more harsh language, and provide specific examples to support their critiques. The reviewer also balances their critique by mentioning both pros and cons. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses concerns about the quality of the experimental evaluation, lack of novelty, and low significance of the contribution. While they acknowledge that the paper is clearly written, this positive aspect is outweighed by the critical comments. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I am concerned' and 'I believe' rather than harsh language. However, the criticism is direct and not particularly softened, preventing a higher politeness score. The reviewer also acknowledges some positive aspects, such as the clarity of writing, which contributes to the slightly positive politeness score.""]"
"[""The paper reports the results of testing several stepsize adjustment related methods including  vanilla SGD, SGD with Neserov momentum, and ADAM. Also, it compares those methods with hypergradient and without. The paper reports several interesting results. For instance, they found hypergradient method on common optimizers doesn't perform better that the fixed exponential decay method propose by Wilson et al. (2017). \n\nThough it is an interesting paper, but the main issue with this paper is that it lacks enough innovation with respect to theory or empirical study. It is not deep or extensive enough for publishing at a top conference. \n  \nOn page 3, it will be better to explain why use mu = 0.9, beta, etc. Why use CIFAR-10, MNIST?\n\nThe URL in References looks out of bound. \n\n\n"", 'Clarity: Below average\n- The introduction would be easier to follow if you named Baydin\'s approach and your own approach, because in the 2-4 bullet points you say ""this online scheme"", and ""the learning rate schedule"", without being perfectly clear what you are talking about\n- The last sentence of the introduction is meant to clearly state your hypothesis, so I was expecting ""emphasize the value of *"", i.e. either adaptive or non-adaptive methods, rather than just general \'tuning\', which is self-apparently important.\n\nQuality: Below average\nThis is a purely empirical study that does not go too deep. It is not quite a review paper, but only compares previous methods.\n\nPros:\nI especially appreciate the sensitivity analysis, ie Fig 6. If only all ML papers had something like this to suggest the difficulty of setting hyperparameters for their proposed methods.\n\nCons:\n- You should use mathematics to describe what you are talking about with adaptive stepsize in Sec 2.1. ""these methods multiply the gradient with a matrix"". Just giving one equation would be extremely helpful.\n- If I understand correctly, you are interpreting the inverse-Hessian as used in Newton\'s method and other non-diagonal \'gradient conditioners\' as types of stepsize. This is definitely interesting, but again it would be very simple to see what you are saying with an equation instead of starting with the phrase ""stepsize"" which is generally understood to be a scalar multiple on the gradient.\n- I\'m surprised you jump right into experiements after your background settings. It\'s apparent that this paper fundamentally relies on the Wilson (2017) hypergradient paper. Your paper should be more self-contained: \'hypergradient\' is not even defined in this paper, is it?...\n\nEspecially:\nHow do you know that if you change the model architecture, data, and loss, that a similar result will occur? I imagine that it heavily relies on the data and model-- in other words, that the sensitivity is dependent on ""how an algorithm reacts to a certain data/loss/model landscape"". I\'m trying to say that I\'m not convinced these results generalize to any other situation than the one presented here (so does it really say anything about the different stepsize selection rules?)\n\nRandom side note:\nSince your appendix is only a few lines, you could consider succinctly listing learning rates with set notation, for example {1e-n,5e-n : -5<n<1}.', ""General:\nIn general, this looks like a technical report rather than a research paper to me. Most parts of the paper are about the empirical analysis of adaptive algorithms and hyper-gradient methods. The contribution of the paper itself is not sufficient to be accepted.\n\nPossible Improvements:\n1. The study of such optimization problem should consider incorporating mathematics analysis with necessary proof. e.g. show the convergence rate under specific constraints. Even the paper is based on others' work, the author(s) could have extended their work by giving stronger theory analysis or experiment results.\n2. Since this is an experimental-based paper, besides CIFAR10 and MNIST data sets, the result would be more convincing if the experiments were also done on ImageNet(probably should also try deeper neural networks).\n3. The sensitivity study is interesting but the experiment results are not very meaningful to me. It would be better if the author(s) gave a more detailed analysis.\n4. The paper could be more consistent. i.e. emphasize the contribution of your own work and be more logical. I might miss something, but I feel quite confused about what is the main idea after reading the paper. \n\nConclusion:\nI believe the paper has not reached the standard of ICLR. Although we need such paper to provide analysis towards existing methods, the paper itself is not strong enough.""]","[-30, -50, -60]","[20, 20, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they express significant criticism about its lack of innovation and depth. The overall tone is more negative than positive, but not extremely negative. The politeness score is 20 because the reviewer uses polite language and constructive criticism, such as 'it will be better to explain' and 'interesting paper', but doesn't go out of their way to be overly polite. They maintain a professional tone throughout, balancing positive comments with critiques."", ""The sentiment score is -50 because the review is generally critical, with phrases like 'Below average' for both clarity and quality. The reviewer points out several cons and areas for improvement, which outweigh the few pros mentioned. However, it's not entirely negative as there are some positive comments and constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively polite language. They use phrases like 'I especially appreciate' and 'I'm surprised' rather than harsh or rude expressions. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. The tone is professional and constructive overall, even if critical."", ""The sentiment score is -60 because the review is generally negative. The reviewer states that the paper 'looks like a technical report rather than a research paper' and that 'the contribution of the paper itself is not sufficient to be accepted.' The conclusion also clearly states that the paper 'has not reached the standard of ICLR' and is 'not strong enough.' However, it's not entirely negative as the reviewer acknowledges some interesting aspects and provides constructive feedback, hence not scoring at the extreme negative end. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Possible Improvements' and offer specific suggestions for enhancement. The language is not overly polite or flattering, but it avoids rudeness or harsh criticism, striking a balance between honesty and courtesy.""]"
"['This work proposes a novel tree structure positional embedding by uniquely representing each path in a tree using a series of transformation, i.e., matmul for going up or down the edges. The tree encoding is used for transformer and shows gains over other strong baselines, e.g., RNNs, in synthetic data and a program translation task.\n\nPros:\n\n- An interesting approach for representing tree structure encoding using a series of transformation. The idea of transformation without learnable parameters is novel.\n\n- Better accuracy both on synthetic tasks and code translation tasks when compared with other strong baselines.\n\nCons:\n\n- Computation seems to be larger given that the encoding has to be recomputed in every decoding step. I\'d like to know the latencies incurred by the proposed method.\n\nOther comment:\n\n- I\'d like to see experimental results on natural language tasks, e.g., syntax parsing.\n\n- Section 2:  ""we see that is is not at all necessary"" -> that is\n\n- Section 3: Notation is a little bit hard to follow, "":"" for D and U, and "";"" in stacking.\n', 'The paper describes an interesting idea for using Vashwani\'s transformer with tree-structured data, where nodes\' positions in the tree are encoded using unique affine transformations. They test the idea in several program translation tasks, and find small-to-medium improvements in performance. \n\nOverall the idea is promising, but the work isn\'t ready for publication. The implementation details weren\'t easy to follow, the experiments were narrow, and there are key citations missing. I would recommend trying some more diverse tasks, and putting this approach against other graph neural network techniques.\n\n\nREVISED:\nI\'ve revised by review upwards by 1, though I still recommend rejection. The authors improved the scholarship by adding many more citations and related work. They also made the model details and implementation more clear. \n\nThe remaining problem I see is that the results are just not that compelling, and the experiments do not test any other graph neural network architectures.\n\nSpecifically, in Table 1 (synthetic experiments) the key result is that their tree-transformer outperforms seq-transformer on structured input. But seq-transformer is best on raw programs. I\'m not sure what to make of this. But I wouldn\'t use tree-transformer in this problem. I\'d use seq-transformer.\n\nIn Table 2 (CoffeeScript-JavaScript experiments), no seq-transformer results are presented. That seems... suspicious. Did the authors try those experiments? What were the results? I\'d definitely like to see them, or an explanation of why they\'re not shown. This paper tests whether tree-transformers are better than seq-transformer and other seq/tree models, but this experiment\'s results do not address that fully. Of the 8 tasks tested, tree-transformer is best on 5/8 while tree2tree is best on 3/8. \n\nIn Table 3, there\'s definitely a moderate advantage to using tree-transformer over seq-transformer, but in 5/6 of the tasks tree-transformer is worse than other approaches. The authors write, ""Transformer architectures in general, however, do not yet compete with state-of-the-art results."". \n\nFinally, no other graph neural network/message-passing/graph attention architectures are tested (eg. Li et al 2016 was cited but not tested, and Gilmer et al 2017 and Veličković et al 2017 weren\'t cited or tested), but there\'s a reasonable chance they\'d outperform the tree-transformer.\n\nSo overall the results are intriguing, and I believe there\'s something potentially valuable here. But I\'m not sure there\'s sufficient reason presented in the paper to use tree-transformer over seq-transformer or other seq/tree models. Also, while the basic idea is nice, as I understand it is restricted to trees, so other graphical structures wouldn\'t be handled.\n\n', 'The authors propose to change the positional encodings in the transformer model to allow processing of tree-structured data.\nThe tree positional encodings summarize the path between 2 nodes as a series of steps up or down along tree branches with the constraint that traveling up a branch negates traveling down any branch.\n\nThe experimental results are encouraging and the method notably outperforms the regular transformer as well as the tree2tree LSTM introduced by Chen et al on larger datasets. \n\nThe current draft lacks some clarity and is low on references. It would also be interesting to see experiments with arbitrary trees or at least regular trees with degree > 2 (rather than just binary trees). While the authors only consider binary trees in this paper, it represents a good first step towards generalizing attention-based models to nonlinear structures.\n\nComments:\n* Would it be possible to use the fact that D_kU = I for the correct branch k? (This happens frequently for binary trees)']","[60, -30, 60]","[70, 50, 70]","[""The sentiment score is 60 (positive) because the reviewer starts by highlighting the novelty of the approach and its better accuracy compared to strong baselines. They use phrases like 'interesting approach' and 'novel', indicating a positive view. However, they also mention some cons and requests for additional information, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as requests for information ('I'd like to know...', 'I'd like to see...') rather than direct criticisms. They also balance positive and negative feedback, and point out minor errors in a neutral way. The tone is professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's interesting idea and potential value, they ultimately recommend rejection due to insufficient compelling results and lack of comparison with other relevant techniques. The reviewer points out several weaknesses and expresses skepticism about the paper's readiness for publication. However, the score is not extremely negative as the reviewer does see some promise in the work. The politeness score is 50 because the reviewer uses respectful and constructive language throughout, acknowledging improvements made by the authors and explaining their concerns in detail. They offer specific suggestions for improvement and frame their criticisms in a professional manner, avoiding harsh or dismissive language. The tone is generally courteous while still being critical where necessary."", ""The sentiment score is 60 (positive) because the reviewer describes the experimental results as 'encouraging' and notes that the method 'notably outperforms' other approaches on larger datasets. They also mention it's a 'good first step' towards generalizing attention-based models. However, they do point out some limitations, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'it would be interesting' and frame suggestions as questions, which is a polite way to provide feedback. The reviewer maintains a professional tone without using overly formal or informal language.""]"
"['PRO’s:\n+well-written\n+nice overall system: GAN framework for super-sampling audio incorporating features from an autoencoder\n+some good-sounding examples\n\nCON’s:\n-some confusing/weakly-presented parts (admittedly covering lots of material in short space)\n-I am confused about the evaluation; would like additional qualitative/observational understanding of what works, including more on how the results differ from baseline\n\nSUMMARY: The task addressed in this work is: given a low-resolution audio signal, generate corresponding high-quality audio. The approach is a generative neural network that operates on raw audio and train within a GAN framework. \nWorking in raw sample-space (e.g. pixels) is known to be challenging, so a stabilizing solution is to incorporate a feature loss. Feature loss, however, usually requires a network trained on a related task, and if such a net one does not already exist, then building one can have its own (possibly significant) challenges. In this work, the authors avoid this auxiliary challenge by using unsupervised feature losses, taking advantage of the fact that any audio signal can be downsampled, and therefore one has the corresponding upsampled signal as well.\n\nThe training framework is basically that of a GAN, but where, rather than providing the generator with a low-dimensional noise signal input, they provide the generator with the subsampled audio signal. The architecture includes a generator ( G(lo-fidelity)=high-fidelity ), a discriminator ( D(high-fidelity) = real or by super-sampled ? ), and an autoencoder ( \\phi( signal x) = features of signal x at AE’s bottleneck). \n\nCOMMENTS:\n\nThe generator network appears to be nearly identical to that of Kuleshov et al (2017)-- which becomes the baseline-- and so the primary contribution differentiating this work is the insertion of that network into a GAN framework along with the additional feature-based loss term. This is overall a nice problem and a nice approach! In that light, I believe that there is a new focus in this work on the perceptual quality of the outputs, as compared to (Kuleshov et al 2017). I would therefore ideally like to see (a) some attempts at perceptually evaluating the resulting output (beyond PESQ, e.g. with human subjects and with the understanding that, e.g. not all AMT workers have the same aural discriminative abilities themselves), and/or (b) more detailed associated qualitative descriptions/visualization of the super-sampled signal, perhaps with a few more samples if that would help. That said, I understand that there are page/space limitations. (more on this next)\n\nGiven the similarity of the U-net architectures to (Kuleshov et al 2017), why not move some of those descriptions to the appendix? \n\nFor example, I found the description and figure illustrating the “superpixel layers” to be fairly uninformative: I see that the figure shows interleaving and de-interleaving, resulting in trading-off dimensionalities/ranks/etc, and we are told that this helps with well-known checkerboard artifacts, but I was confused about what the white elements represent, and the caption just reiterated that resolution was being increased and decreased. Overall, I didn’t really understand exactly the role that this plays in the system; I wondered if it either needed a lot more clarification (in an appendix?), or just less space spent on it, but keeping the pointers to the relevant references.  It seems that the subpixel layer was already implemented in Kuleshov 2017, with some explanation, yet in the present work a large table (Table 1(b)) is presented showing that there is no difference in quality metrics, and the text also mentions that there is no significant perceptual difference in audio. If the subpixel layer were explained in detail, and with justification, then I would potentially be OK with the negative results, but in this case it’s not clear why spend this time on it here. It’s possible that there is something simple about it that I am not understanding. I’m open to being convinced. Otherwise, why not just write: “Following (Kuleshov et al 2017), we use subpixel layers (Shi et al) [instead of ...] to speed up training, although we found that they make no significant perceptual effects.” or something along those lines, and leave it at that? \n\nI did appreciate the descriptions of models’ sensitivity to size/structure of the conv filters, importance of the res connections, etc.\n\nMy biggest confusion was with the evaluation & results:\n\nSince the most directly related work was (Kuleshov 2017), I compared the super resolution (U-net) samples on that website (https://kuleshov.github.io/audio-super-res/ ) to the samples provided for the present work ( https://sites.google.com/view/unsupervised-audiosr/home ) and I was a bit confused, because the quality of the U-net samples in (Kuleshov 2017) seemed to be perceptually significantly better than the quality of the Deep CNN (U-net) baseline in the present work. Perhaps I am in error about this, but as far as I can tell, the superresolution in (Kuleshov et al 2017) is significantly better than the Deep CNN examples here. Is this a result of careful selection of examples? I do believe what I hear, e.g. that the MU-GAN8 is clearly better on some examples than the U-net8. But then for non-identical samples, how come U-net4 actually generally sounds better than U-net8? That doesn’t make immediate sense either (assuming no overfitting etc). Is the benefit in moving from U-net4 to U-net8 within a GAN context but then stabilizing  it with the feature-based loss? If so, then how does MU-GAN8 compare to U-net4? Would there be any info for the reader by doing an ablation removing the feature loss from the GAN framework? etc. I guess I would like to get a better understanding of what is actually going on, even if qualitative. Is there any qualitative or anecdotal observation about which “types” of samples one system works better on than another? For example, in the provided examples for the present paper, it seemed to be the case that perhaps the MU-GAN8 was more helpful for supersampling female voices, which might have more high-frequency components that seem to get lost when downsampling, but maybe I’m overgeneralizing from the few examples I heard. \n\nSome spectrograms might be helpful, since they do after all convey some useful information despite not telling much of the perceptual story. For example, are there visible but inaudible artifacts? Are such artifacts systematic?\n\nWere individual audio samples represented as a one-hot encoding, or as floats? (I assume floats since there was no mention of sampling from a distribution to select the value).\n\nA couple of typos:\n\ndescriminator → discriminator \n\npg 6 “Impact of superpixel layers” -- last sentence of 2nd par is actually not a sentence. “the reduction in convolutional kernels prior to the superpixel operation.”\n\nOverall, interesting work, and I enjoyed reading it. If some of my questions around evaluation could be addressed-- either in a revision, or in a rebuttal (e.g. if I completely misunderstood something)-- I would gladly consider revising my rating (which is currently somewhere between 6 and 7).\n', ""This paper presents a GAN-based method to perform audio super-resolution. In contrast to previous work, this work uses auto-encoder to obtain feature losses derived from unlabeled data. \n\nComments:\n(1) Redundant comma: “filters with very large receptive fields are required to create high quality, raw audio”.\n\n(2) There are some state-of-the-art non-autoregressive generative models for audio waveform e.g., parallel wavenet, clarinet. One may properly discuss them in related work section. Although GAN performs very well for images, it hasn't obtained any compelling results for raw audios. Still, it’s very interesting to explore that. Any nontrivial insight would be highly appreciated.\n\n(3) In multiscale convolutional layers, it seems only larger filter plays a significant role. What if we omit small filter, e.g., 3X1?\n\n(4) It seems the proposed MU-GAN introduces noticeable noise in the upsampled audios. \n\nPros:\n- Interesting idea and fascinating problem. \nCons:\n- The results are fair. I didn’t see big improvement over previous work (Kuleshov et al., 2017).\n\nI'd like to reconsider my rating after the rebuttal.\n"", '\nThe paper presents a model to perform audio super resolution. The proposed model trains a neural network to produce a high-resolution audio sample given a low resolution input. It uses three losses: sample reconstructon, adversarialy loss and feature matching on a representation learned on an unsupervised way.\n\nFrom a technical perspective, I do not find the proposed approach very novel. It uses architectures following closely what has been done for Image supre-resolution. I am not aware of an effective use of GANs in the audio processing domain. This would be a good point for the paper. However, the evidence presented does not seem very convincing in my view. While this is an audio processing paper, it lacks domain insights (even the terminology feels borrowed from the image domain). Again, most of the modeling decisions seem to follow what has been done for images. The empirical results seem good, but the generated audio does not match the quality of the state-of-the-art.\n\nThe presentation of the paper is correct. It would be good to list or summarize the contributions of this work.\n\nRecent works have shown the amazing power of auto-regressive generative models (WaveNet)  in producing audio signals. This is, as far as I know, the state-of-the-art in audio generation. The authors should motivate why the proposed model is better or worth studying in light of those approaches. In particular, a recent work [A] has shown very high quality results in the problem of speech conversion (which seems harder than bandwidth extension). It would seem to me that applying such models to the bandwith extension task should also lead to very high quality results as well. What is the advantage of the proposed approach? Would a WaveNet decoder also be improved by including these auxiliary losses?\n\nWhile the audio samples seem to be good, they are also a bit noisy even compared with the baseline. This is not the case in the samples generated by [A] (which is of course a different problem). \n\nThe qualitative results are evaluated using PESQ. While this is a good proxy it is much better to perform blind tests with listeners. That would certainly improve the paper. \n\nFeature spaces are used in super resolution to provide a space in which the an L2 loss is perceptually more relevant. There are many such representations for audio signals. Specifically the magnitude of time-frequency representations (like spectrograms) or more sophisticated features such as scattering coefficients. In my view, the paper would be much stronger if these features would be evaluated as alternative to the features provided by the proposed autoencoder. \n\nOne of the motivations for defining the loss in the feature space is the lack (or difficulty to train) auxiliary classifiers on large amounts of data.  However, speech recognition models using neural networks are quite common. It would be good to also test features obtained from an off-the-shelf speech recognition system. How would this compare to the proposed model?\n\nThe L2 ""pixel"" loss seems a bit strange in my view. Particularly in audio processing, the recovered high frequency components can be synthesized with an arbitrary phase. This means that imposing an exact match seems like a constraint as the phase cannot be predicted from the low resolution signal (which is what a GAN loss could achieve). \n\nThe paper should present ablations on the use of the different losses. In particular, one of the main contributions is the inclusion of the loss measured in the learned feature space. The authors mention that not including it leads to audible artifacts. I think that more studies should be presented (including quantitative evaluations and audio samples).\n\nHow where the hyper parameters chosen? is there a lot of sensitivity to their values?\n\n\n[A] van den Oord, Aaron, and Oriol Vinyals. ""Neural discrete representation learning."" Advances in Neural Information Processing Systems. 2017.\n']","[50, -20, -30]","[70, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by listing both pros and cons, indicating a balanced view. They describe the work as 'interesting' and 'nice overall', but also point out several areas for improvement. The tone is generally constructive rather than overly critical. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges space limitations, and expresses openness to revising their rating. They phrase criticisms as suggestions or questions rather than harsh judgments. The reviewer also compliments aspects of the work and expresses enjoyment in reading it. However, they don't use overtly formal or deferential language, keeping the tone professional but not excessively polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'interesting idea and fascinating problem', they also point out several cons and areas for improvement. The reviewer states that the results are 'fair' and they 'didn't see big improvement over previous work', indicating a somewhat negative sentiment. However, they are open to reconsidering their rating after a rebuttal, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the positive aspects of the work. They use phrases like 'One may properly discuss' and 'Any nontrivial insight would be highly appreciated', which are polite ways of suggesting improvements. The reviewer also ends on a courteous note by being open to reconsidering their rating."", ""The sentiment score is -30 because the reviewer expresses several criticisms and doubts about the paper's novelty, methodology, and results. They state that the approach is not very novel, lacks domain insights, and doesn't match the quality of state-of-the-art methods. However, they do acknowledge some positive aspects, such as the potential novelty of using GANs in audio processing and the correct presentation of the paper, which prevents the score from being more negative. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It would be good to...' and 'The paper should...' when making suggestions, and they acknowledge positive aspects alongside criticisms. The reviewer also provides specific recommendations for improvement and references to relevant work, which is helpful and courteous. While not overly warm, the language is respectful and aimed at improving the paper.""]"
"[""The submission describes a sort of hybrid between reinforcement learning and imitation learning, where an auxiliary imitation learning objective helps to guide the RL policy given expert demonstrations.  The method consists of concurrently maximizing an RL objective--augmented with the GAIL discriminator as a reward—and minimizing the GAIL objective, which optimizes the discriminator between expert and policy-generated states.  Only expert states (not actions) are required, which allows the method to work given only videos of the expert demonstrations.  Experiments show that adding the visual imitation learning component allows RL to work with sparse rewards for complex tasks, in situations where RL without the imitation learning component fails.\n\nPros:\n+ It is an interesting result that adding a weak visual imitation loss dramatically improves RL with sparse rewards \n+ The idea of a visual imitation signal is well-motivated and could be used to solve practical problems\n+ The method enables an ‘early termination’ heuristic based on the imitation loss, which seems like a nice heuristic to speed up RL in practice\n\nCons:\n+ It seems possible that imitation only helps RL where imitation alone works pretty well already\n+ Some contributions are a bit muddled: e.g., the “learning with no task reward” section is a little confusing, because it seems to describe what is essentially a variant of normal GAIL\n+ The presentation borders on hand-wavy at parts and may benefit from a clean, formal description\n\nThe submission tackles a real, well-motivated problem that would appeal to many in the ICLR community.  The setting is attractive because expert demonstrations are available for many problems, so it seems obvious that they should be leveraged to solve RL problems—especially the hardest problems, which feature very sparse reward signals.  It is an interesting observation that an imitation loss can be used as  a dense reward signal to supplement the sparse RL reward.  The experimental results also seem very promising, as the imitation loss seems to mean the difference between sparse-reward RL completely failing and succeeding.  Some architectural / feature selection details developed here seem to also be a meaningful contribution, as these factors also seem to determine the success or failure of the method.\n\nMy biggest doubt about the method is whether it really only works where imitation learning works pretty well already.  If we don’t have enough expert examples for imitation learning to work, or if the expert is not optimizing the given reward function, then it is possible that adding the imitation loss is detrimental, because it induces an undesirable bias.  If, on the other hand, we do have enough training examples for imitation learning to succeed and the expert is optimizing the given reward function, then perhaps we should just do imitation learning instead of RL.  So, it is possible that there is some sweet spot where this method makes sense, but the extent of that sweet spot is unclear to me.\n\nThe experiments are unclear on this issue for a few reasons.  First, figure 4 is confusing, as it is titled ‘comparison to standard GAIL', which makes it sound like a comparison to standard imitation learning.  However, I believe this figure is actually showing the performance of different variants of GAIL used as a subroutine in the hybrid RL-IL method.  I would like to know how much reward vanilla GAIL (without sparse rewards) achieves in this setting.  Second, figure 8 seems to confirm that some variant of vanilla imitation learning (without sparse rewards) actually does work most of the time, achieving results that are as good as some variants of the hybrid RL-IL method.  I think it would be useful to know, essentially, how much gain the hybrid method achieves over vanilla IL in different situations.\n\nAnother disappointing aspect of the paper is the ‘learning with no task reward’ section, which is a bit confusing.  The concept seems reasonable at a first glance, except that once we replace the sparse task reward with another discriminator, aren’t we firmly back in the imitation learning setting again?  So, the motivation for this section just seems a bit unclear to me.  This seems to be describing a variant of GAIL with D4PG for the outer optimization instead of TRPO, which seems like a tangent from the main idea of the paper.  I don’t think it is necessarily a bad idea to have another discriminator for the goal, but this part seems somewhat out of place.\n\nOn presentation: I think the presentation is a bit overly hand-wavy in parts.  I think the manuscript could benefit from having a concise, formal description.  Currently, the paper feels like a series of disjoint equations with unclear connections among them.  The paper is still intelligible, but not without knowing a lot of context relating to RL/IL methods that are trendy right now.  I feel that this is an unfortunate trend recently that should be corrected.  Also, I’m not sure it is really necessary to invoke “GAIL” to describe the IL component, since the discriminator is in fact linear, and the entropy component is dropped.  I think “apprenticeship learning” may be a more apt analogy.\n\nOn originality: as far as I can tell, the main idea of the work is novel.  The work consists mainly of combining existing methods (D4PG, GAIL) in a novel way.  However, some minor novel variations of GAIL are also proposed, as well as novel architectural considerations.\n\nOverall, this is a nice idea applied to a well-motivated problem with promising results, although the exact regime in which the method succeeds could be better characterized."", 'This paper aims at solving the problem of estimating sparse rewards in a high-dimensional input setting. The authors provide a simplified version by learning the states from demonstrations. This idea is simple and straightforward, but the evaluation is not convincing. \n\nI am wondering if this approach still works in more general applications, e.g., when state distributions vary dramatically or visual perturbations arise in the evaluation phase.  \n\nIn addition, it is weird to use adversary scheme to estimate rewards. Namely, the agent is trying to maximize the rewards, but the discriminator is improved so as to reduce rewards. \n\nIn section 3, the authors mention an early termination of the episode, this is quite strange in real applications, because even the discriminator score is low the robot still needs to accomplish the task.\n\nFinally, robots are subject to certain physical constraints, this issue can not be addressed by merely learning demonstrated states.', '---\nUpdate: I think the experiments are interesting and worthy of publication, but the exposition could be significantly improved. For example:\n\n- Not sure if Figure 1 is needed given the context.\n- Ablation study over the proposed method without sparse reward and hyperarameter \\alpha\n- Move section 7.3 into the main text and maybe cut some in the introduction\n- More detailed comparison with closely related work (second to last paragraph in related work section), and maybe reduce exposition on behavior cloning.\n\nI like the work, but I would keep the score as is.\n---\n\n\nThe paper proposes to use a ""minimal adversary"" in generative adversarial imitation learning under high-dimensional visual spaces. While the experiments are interesting, and some parts of the method has not been proposed (using CPC features / random projection features etc.), I fear that some of the contributions presented in the paper have appeared in recent literature, such as InfoGAIL (Li et al.).\n\n- Use of image features to facilitate training: InfoGAIL used pretrained ResNet features to deal with high-dimensional inputs, only training a small neural network at the end.\n- Tracking and warm restarts: InfoGAIL does not seem to require tracking a single expert trajectory, since it only classifies (s, a) pairs and is agnostic to the sequence.\n- Reward augmentation: also used in InfoGAIL, although they did not use sparse rewards for augmentation.\n\nAnother contribution claimed by this paper is that we could do GAIL without action information. Since we can shape the rewards for most of our environments that do not depend on actions, it is unsurprising that this could work when D only takes in state information. However, it is interesting that behavior cloning pretraining is not required in the high-dimensional cases; I am interested to see a comparison between with or w/o behavior cloning in terms of sample complexity. \n\nOne setting that could potentially be useful is where the expert and policy learner do not operate within the same environment dynamics (so actions could not be same) but we would still want to imitate the behavior visually (same state space). \n\nThe paper could also benefit from clearer descriptions, such as pointers to which part of the paper discusses ""special initialization, tracking, or warm starting"", etc., from the introduction.']","[60, -50, -20]","[70, 20, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, including 'interesting result', 'well-motivated', 'promising results', and 'nice idea'. However, they also mention some concerns and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting criticisms. They use phrases like 'It is an interesting observation' and 'I think it would be useful to know', which maintain a polite tone. The reviewer also balances positive and negative feedback, showing consideration for the authors' work while providing honest critique."", ""The sentiment score is -50 because the reviewer expresses skepticism about the paper's approach and evaluation. They use phrases like 'not convincing' and raise several concerns, indicating a generally negative view. However, it's not entirely negative as they acknowledge the idea as 'simple and straightforward'. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I am wondering' instead of direct criticism. They raise concerns as questions or observations rather than harsh judgments. However, the language is not overtly polite, maintaining a neutral to slightly positive tone in terms of courtesy."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the experiments are interesting and worthy of publication, they express several concerns about the paper's contributions and clarity. The reviewer points out that some of the claimed contributions have appeared in recent literature and requests clearer descriptions and comparisons. However, the score is not deeply negative as the reviewer still finds value in the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think,' 'I like the work,' and 'I am interested to see,' which show respect for the authors' efforts. The reviewer also offers specific suggestions for improvement without using harsh or dismissive language. However, the score is not extremely high as the review is primarily focused on critiquing the paper rather than offering extensive praise.""]"
"[""This paper proposes a definition for interpretability which is indeed the same as model simplicity using the MDL principle. It has several issues:\n\n1) Interpretability is not the same as simplicity or number of model parameters. For example, an MLP is thought to be more interpretable than an RNN with the same number of parameters.\n\n2) The definition of explainability in Eq. (5) is flawed. It should not have the second term L(M(X)|M^o, X) which is the goodness of M^o's fit. You should estimate M^o using that equation and then report L(M^o|M^p) as the complexity of the best estimate of the model (subject to e.g. linear class). Mixing accuracy of estimation of a model and its simplicity does not give you a valid explainability score. \n\n3) In Section 2.4.2, the softmax operator will shrink the large negative coefficients to almost zero (reduces the degrees of freedom of a vector by 1). Thus, using softmax will result in loss of information. In the linear observer case, I am not sure why the authors cannot come up with a simple solution without any transformation.\n\n4) Several references in the text are missing which hinders understanding of the paper."", 'Summary:\nThe authors propose a framework for training an external observer that tries explain the behavior of a prediction function using the minimal description principle. They extend this idea by considering how a human with domain knowledge might have different expectations for the observer. The authors test this framework on a multi-variate time series medical data (MIMIC-III) to show that, under their formulation, the external observer can learn interpretable embeddings.\n\nPros:\n- Interesting approach: Trying to develop an external observer based on information theoretic perspective. \n- Considering the domain knowledge of the human subject can potentially be an important element when we want to use interpretable models in practice.\n\nIssues:\n(1) In 2.4: So between M and M^O, which one is a member of M_reg? \n(2) On a related note to issue (1): In 2.4.1, ""Clearly, for each i, (M(X))_i | M^O(X) follows also a Gaussian distribution: First of all, I\'m not sure if that expression is supposed to be  p(M(X)_i | M^O(X)) or if that was intended. But either way, I don\'t understand why that would follow a normal distribution. Can you clarify this along with issue (1)?\n(3) In 2.4.2: The rationale behind using attention & compactness to estimate the complexity of M^O is weak. Can you elaborate this in the future version?\n(4) What do each figure in Figure 4 represent?\n(5) More of a philosophical question: the authors train M and M^O together, but it seems more appropriate to train an external observer separately. If we are going to propose a framework to train an agent that tries to explain a black box function, then training the black-box function together with the observer can be seen as cheating. It can potentially make the job of the observer easier by training the black box function to be easily explainable. It would have been okay if this was discussed in the paper, but I can\'t find such discussion.\n(6) The experiments can be made much stronger by applying this approach to a specific prediction task such as mortality prediction. The current auto-encoding task doesn\'t seem very interesting to apply interpretation.\n(7) Most importantly: I like the idea very much, but the paper clearly needs more work. There are broken citations and typos everywhere. I strongly suggest polishing this paper as it could be an important work in the model interpretability field.', 'This paper is motivated in an interesting application, namely ""explainable representations"" of patient physiology, phrased as a more general problem of patient condition monitoring. Explainability is formulated as a communication problem in line with classical expert systems (http://people.dbmi.columbia.edu/~ehs7001/Buchanan-Shortliffe-1984/MYCIN%20Book.htm). \nInformation theoretical concepts are applied, and performance is quantified within the minimum description length (MDL) concept.\n\nQuality & clarity \nWhile the patient dynamics representation problem and the communication theoretical framing is interesting , the analyses and experiments are not state of the art. \nWhile the writing overall  is clear and the motivation well-written, there are many issues with the modeling and experimental work.\nThe choice of MDL over more  probabilistic approaches  (as e.g. Hsu et al 2017 for sequences) could have been better motivated. The attention mechanism could have been better explained (attention of whom and to what?) and also the prior (\\beta). How is the prior established - e.g. in the MIMIC case study   \nThe experimental work is carried out within a open source data set - not allowing the possibility of testing explanations against experts/users. \n\nOriginality \nThe main originality is in the problem formulation. \n\nSignificance \nThe importance of this work is limited as the case is not clearly defined. How are the representations to be used and what type of users is it intended to serve (expert/patients etc) \n\nPros and cons\n+ interesting problem\n\n-modeling could be better motivated\n-experimental platform is limited for interpretability studies\n\n== \nHsu, W.N., Zhang, Y. and Glass, J., 2017. Unsupervised learning of disentangled and interpretable representations from sequential data. In Advances in neural information processing systems (pp. 1878-1889).\n\n']","[-70, -20, -20]","[0, 60, 50]","[""The sentiment score is -70 because the review is predominantly critical, pointing out several significant issues with the paper. The reviewer uses phrases like 'has several issues', 'is flawed', and 'will result in loss of information', indicating a negative sentiment towards the paper's content and methodology. However, it's not entirely negative as the reviewer acknowledges the paper's attempt to propose a definition for interpretability.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite or rude language. The criticism is direct and factual, without personal attacks or overly harsh language, but also without any particularly courteous or softening phrases. The reviewer simply states the issues and recommendations in a straightforward manner typical of academic peer reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Interesting approach', 'potentially be an important element'), they list several issues and state that 'the paper clearly needs more work'. The overall tone suggests that significant improvements are needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions ('Can you clarify this?', 'I strongly suggest'), and includes positive feedback alongside the critiques. The reviewer also expresses interest in the idea ('I like the idea very much') which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting application', 'well-written motivation'), they also point out several significant issues with the modeling and experimental work. The overall tone suggests that the paper has potential but falls short in key areas. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, balancing criticism with praise and using phrases like 'could have been better motivated' rather than harsh language. They also provide constructive feedback and suggestions for improvement, which contributes to the polite tone.""]"
"['The paper introduces a new twist to the activation of a particular neuron. They use a modulator which looks at the input and performs a matrix multiplication to produce a vector. That vector is then used to scale the original input before passing it through an activation function. Since this modulating scalar can look across neurons to apply a per-neuron scalar, it overcomes the problem that otherwise neurons cannot incorporate their relative activation within a layer. They apply this new addition to several different kinds of neural network architectures and several different applications and show that it can achieve better performance than some models with more parameters.\n\n\nStrengths:\n- This is a simple, easy-to-implement idea that could easily be incorporated into existing models and frameworks.\n- As the authors state, adding more width to a vanilla layer stops increasing performance at a certain point. Adding more complex connections to a given layer, like this, is a good way forward to increase capacity of layers.\n- They achieve better performance than existing baselines in a wide variety of applications.\n- The reasons this should perform better are intuitive and the introduction is well written.\n\nWeaknesses:\n- After identifying the problem with just summing inputs to a neuron, they evaluate the modulator value by just summing inputs in a layer. So while doing it twice computes a more complicated function, it is still a fundamentally simple computation.\n- It is not clear from reading this whether the modulator weights are tied to the normal layer weights or not. The modulator nets have more parameters than their counterparts, so they would have to be separate, I imagine.\n- The authors repeatedly emphasize that this is incorporating ""run-time"" information into the activation. This is true only in the sense that feedforward nets compute their output from their input, by definition at run-time. This information is no different from the tradition input to a network in any other regard, though.\n- The p-values in the experiment section add no value to the conclusions drawn there and are not convincing.\n\nSuggested Revisions:\n- In the abstract: ""A biological neuron change[s]""\n- The conclusion is too long and adds little to the paper\n\n', 'This paper proposes a scalar modulator adding to hidden nodes before an activation function. The authors claim that it controls the sensitivity of the hidden nodes by changing the slope of activation function. The modulator is combined with a simple CNN, DesneNet, and a LSTM model, and they provided the performance improvement over the classic models. \n\nThe paper is clear and easy to understand. The idea is interesting. However, the experimental results are not enough and convincing to justify it. \n\n1) The authors cited the relevant literature, but there is no comparison with any of these related works. \n\n2) Does this modulator actually help for CNN and LSTM architectures? and How? Recently, there are many advanced CNN and LSTM architectures. The experiments the authors showed were with only 2 layer CNNs and 1 layer LSTM. There should be at least some comparison with an architecture that contains more layers/units and performs well. There is a DenseNet comparison, but it seems to have an error. See 4) for more details.\n\n3) The authors mentioned that the modulator can be used as a complement to the attention and gate mechanisms. Indeed, they are very similar. However, the benefit is unclear. More experiments need to be demonstrated among the models with the proposed modulator, attention, and gates, especially learning behavior and performance differences. \n\n4) The comparison in Table 2 is not convincing. \n- The baseline is too simple. For instance on CIFAR10, a simple CNN architecture introduced much earlier (like LeNet5 or AlexNet) performs better than Vanilla CNNs or modulated CNNs.\n- DenseNet accuracy reported in Table 2 is different from to the original paper: DenseNet (Huang et al. 2017) CIFAR10 # parameters 1.0M, accuracy 93%, but in this paper 88.9%. Even the accuracy of modulated DenseNet is 90.2% which is still far from the original DenseNet.\nFurthermore, there are many variations of DenseNet recently e.g., SparsenNet: sparsified DenseNet with attention layer (Liu et al. 2018), # parameters 0.86M, accuracy 95.75%. Authors should check their experiments and related papers more carefully.\n\nSide note: page 4, Section 3.1 ""The vanilla DenseNet used the structure (40 in depth and 12 in growth-rate) reported in the original DenseNet paper (Iandola et al., 2014)"". This DenseNet structure is from Huang et al. 2017 not from Iandola et al. 2014.\n', 'Summary: this submission proposes a modification of neural network architectures that allows the modulation of activation functions of a given layer as a function of the activations in the previous layer. The author provide different version of their approach adapted to CNN, DenseNets and LSTM, and show it outperforms a vanilla version of these algorithms.\nEvaluation: In the classical context of supervised learning tasks investigated in this submission, it is unclear to me what could be the benefit of introducing such “modulators”, as vanilla ANNs already have the capability of modulating the excitability of their neurons. Although the results show significant, but quite limited, improvements with respect to the chosen baseline, more extensive baseline comparisons are needed.\n\nDetails comments:\n1.\tUnderlying principles of the approach\nIt is unclear to me why the proposed approach should bring a significant improvement to the existing architectures. First, from a neuroscientific perspective, neuromodulators allow the brain to go through different states, including arousal, sleep, and different levels of stress. While it is relatively clear that state modulation has some benefits to a living system, it is less so for an ANN focused on a supervised learning task. Why should the state change instead of focusing on the optimal way to perform the task? If the authors want to use a neuroscientific argument, I would suggest to elaborate based on the precise context of the tasks they propose to solve. \nIn addition, as mentioned several times in the paper, neuromodulation is frequently associated to changes in cell excitability. While excitability is a concept that can be associated to multiple mechanisms, a simple way to model changes in excitability is to modify the threshold that must be reached by the membrane potential of a given neuron in order for the cell to fire. Such simple change in excitability can be easily implemented in ANNs architectures by affecting one afferent neuron in the previous layer to the modification of this firing threshold (simply adding a bias term). As a consequence, if there is any benefit to the proposed architecture, it is very likely to originate specifically from the multiplicative interactions used to implement modulation in this paper. However, approximation of such multiplicative interactions can also be implemented using multiple layers network equipped with non-linear activations. Overall, it would be good to discuss these aspects in great detail in the introduction and/or discussion of the paper, and possibly find a more convincing justification for the approach.\n\n2.\tWeak baseline comparison results\nIn the CNN experiments, modulated networks are only compared with a single vanilla counterpart equipped with ReLu. There are at least two obvious additional baseline comparison that would be useful: what if the Re-Lu activations are replaced with fixed sigmoids? And what if batch-normalization is switched on/off (I could not find whether it was used at all). Indeed it, we should exclude benefits that are simply due to the non-linearity of the sigmoid, and batch normalization also implements a form of modulation at training that may provide benefits equivalent to modulation (or on the contrary, batch norm could implement a modulation in the wrong way). It would be better to look at all possible combinations of these architecture choices.\nDue to lack of details in the paper and my personal lack of expertise in LSTMs, I will not comment on baselines for that part but I assume similar modifications can be done.\nOverall, given the weak improvements in performance, it is questionable whether this extra degree of complexity should be added to the architecture. Additionally, I could not find the precise description of the statistical tests performed. Ideally, the test, the number of samples, the exact p-value, and whether the method of correction for multiple comparison should be included each time a p-value is mentioned.\n\n\n\n\n\n \n', 'Summary: \nThis paper introduces an architectural change for basic neurons in neural network. Assuming a ""neuron"" consists of a linear combination of the input, followed by a non-linear activation function, the idea is to multiply the output of the linear combination by a ""modulator"", prior to feeding it into the activation function. The modulator is itself a non-linear function of the input. Furthermore, in the paper\'s implementation, the modulators share weights across the same layer. The idea is demonstrated on basic vision and NLP tasks, showing improvements over the baselines. \n\nI - On the substance:\n1. Related concepts and biological inspirations\nThe idea is analogous to attention and gating mechanisms, as the authors point out, with the clear distinction that the modulation happens _before_ the activation function. It would have been interesting to experiment a combination of modulation and attention since they do not act on the same levels. \nAlso, the authors claim inspiration from the biological neurons, however, they do not elaborate in depth on the connections to the neuronal concepts mentioned in the introduction. \n\n2. The performance of the proposed approach\nIn the first experiment, the modulated CNN at 150 epochs seems to have comparable performance with the vanilla CNN at 60 (the latter CNN starts overfitting afterwards). Why not extending the learning curve to more epochs since the modulated CNN seems on a positive slope? \nThe other experiments show some improvements over the baselines, however more experiments are necessary for claiming generality. Especially, the baselines remain too simple and there are some well-known well-performing architectures, for both image and text processing, that the authors could compare to (cf winning architectures for imagenet for instance). They could also take these same architectures and augment them with the modulation proposed in the paper. \nFurthermore, an ablation study is clearly missing, what about different activation functions, combination with other optimization techniques etc.?\n\nII - On the form:\n1. the paper is sometimes unclear, even though the overall narrative is sound,\n2. wiggly red lines are still present in the caption of Figure 1 right.\n3. Figure 6 could be greatly simplified by putting its content in the form of a table, I don\'t find that the rectangles and forms bring much benefit here.\n4. Table 5 (should it not be Figure?): it is not fully clear what the lines represent and based on which input. \n5. some typos: \n - abstract: a biological neuron change[s]\n - abstract: accordingly to -> according to \n - introduction > paragraph 2 > line 11: Each target node multipl[i]es \n\nIII - Conclusion: \nThe idea is interesting and some of the experiments show nice results (eg. modulated densenet-lite outperforming densenet) but the overall paper needs further improvements. In particular, the writing needs to be reworked, the experiments to be consolidated, and the link to neuronal modulation to be further investigated. ', 'Paper summary:\n\nThis paper proposes a method to scale the activations of a layer of neurons in an ANN depending on the inputs to that layer. The scaling factor, called modulation, is computed using a separate weight matrix and activation function. It is multiplied with each neuron\'s activation before applying its non-linearity. The weight matrix of the modulator is learned alongside the other weights of the network by backpropagation. The authors evaluate this modulated neural unit in convolutional neural networks, densely connected CNNs and recurrent networks consisting of LSTM units. Reported improvements above the baselines are between 1% - 3%.\n\nPro:\n\n+ With some minor exceptions the paper is clearly written and comprehensible.\n+ Experiments seem to have been performed with due diligence.\n+ The proposed modulator is easy to implement and applicable to (almost) all network architectures.\n\nContra:\n\n- Lin et. al. (2014) proposed a network in network architecture. In this architecture the output of each neural unit is computed using a small neural network contained in it and thus arbitrary, input-dependent activation functions can be realized and learned by each neuron. The proposed neural modulation mechanism in the paper at hand is in fact a more restricted version of the network-in-network model and the authors should discuss the relationship of their proposal to this prior work.\n\n- When comparing the test accuracy of CNNs in Fig. 4 the result is questionable. If training of the vanilla CNN was stopped at its best validation loss (early stopping), the difference in accuracies would have been marginal. Also the choice of hyper-parameters may significantly affect the outcome of the comparison experiments. More experiments would be necessary to prove the advantage of this model over a wide range of hyper-parameters.\n\nMinor points:\n\n- It is unclear whether the modulator weights are shared along the depth of a CNN layer, i.e. between feature maps.\n\n- Page 9: ""Our modification enables a network to use previous activity to determine its current sensitivity to input [...]"" => A vanilla LSTM is already capable of doing that using its input gate.\n\n- Page 9: ""[...] the ability to adjust the slope of an Activation Function has an immediate benefit in making the back-propagation gradient dynamic."" => In fact ReLUs do not suffer from the vanishing gradient problem. Furthermore DenseNets already provide a short-path for the gradient flow by introducing skip connections.\n\n- The discussion at the end adds little value and rather seems to be a motivation of the model than a discussion of the results.\n\nRating:\n\nMy main concern is that the proposed modulator is a version of the network in network model restricted to providing a scaling factor. Although the authors motivate this model biologically, I do not see sufficient empirical evidence to believe that it is advantageous over the full network in network model by Lin et. al. I would recommend to add a direct comparison to that model to a future version of this paper.\n']","[60, -30, -50, -20, -20]","[70, 50, 50, 60, 60]","[""The sentiment score is 60 (positive) because the review begins by highlighting the paper's novel approach and its potential benefits. The reviewer lists several strengths, including the simplicity and wide applicability of the idea, as well as improved performance across various applications. While there are some weaknesses mentioned, they are presented as areas for improvement rather than fundamental flaws. The politeness score is 70 (polite) because the reviewer uses neutral, professional language throughout. They provide a balanced view, acknowledging both strengths and weaknesses without using harsh or critical language. The suggestions for revision are presented constructively, and the overall tone is respectful and aimed at improving the paper rather than dismissing it."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is clear and the idea is interesting, they express significant concerns about the experimental results and their convincingness. The reviewer points out several major issues, including lack of comparison with related works, insufficient experiments with more complex architectures, and discrepancies in reported results. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The paper is clear and easy to understand' and 'The idea is interesting' before presenting their criticisms. The reviewer also provides specific suggestions for improvement and uses polite language such as 'Authors should check' rather than making accusatory statements. However, the review doesn't go out of its way to be overly polite or complimentary, keeping it at a moderate positive score."", ""The sentiment score is -50 because the reviewer expresses significant skepticism about the proposed approach and its benefits. They state that it's 'unclear' why the approach should bring improvement, question the justification, and point out weak baseline comparisons. However, it's not entirely negative as they do acknowledge some improvements, albeit limited ones. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It is unclear to me' and 'I would suggest' rather than making blunt criticisms. They also offer constructive feedback and suggestions for improvement, which is polite. The language is not overly formal or deferential, hence not scoring higher on politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and some positive results, they also point out several areas needing improvement. The review highlights issues with clarity, lack of depth in experiments, missing comparisons, and the need for further investigation. The overall tone suggests the paper needs significant work before it can be considered acceptable.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and balance criticism with acknowledgment of the paper's strengths. The language used is respectful and focuses on the work rather than the authors. Phrases like 'it would have been interesting' and 'the idea is interesting' soften the critique. However, the score is not higher as the review is direct in its criticism and doesn't use overly polite language or excessive praise."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pro' section), they express significant concerns and criticisms in the 'Contra' section. The reviewer questions the novelty of the proposed method and the strength of the empirical evidence. The final recommendation suggests major revisions are needed. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths before presenting criticisms, use phrases like 'My main concern is...' instead of harsh statements, and offer constructive suggestions for improvement. The tone remains objective and focused on the scientific content rather than personal attacks.""]"
"['This paper proposes a model-based value-centric (MVC) framework for transfer learning in continuous RL problems, and an algorithm within that framework. The paper attempts to answer two questions: (1) ""why are current RL algorithms so inefficient in transfer learning"" and (2) ""what kind of RL algorithms could be friendly to transfer learning by nature""? I think these are very interesting questions to investigate, and researchers that work on transfer learning could benefit from insights on them. However, I am not yet convinced that this paper answers these questions satisfyingly. It would be great to hear the author\'s thoughts on my questions below. \n\nThe main insight I take away from the paper is that policy gradient methods are not suitable for transfer learning compared to model-based and value-centric methods for some assumptions (the reward function not changing and the transition dynamics being deterministic). This insight and the experiments in the paper are interesting, but I am unsure if the paper as it is presented now passes the bar for ICLR.\n\nIn general the paper has two contributions:\nA) analysis of value-centric vs policy-centric methods\nB) an algorithm that is more useful for transfer learning.\n\nRegarding A)\nThe authors argue that policy-centric algorithms are less useful for transfer learning than value-centric methods. \n\nThey first illustrate this with an example in Section 3. Since this is just one example, as a reader I wonder if it would not be possible to construct an example that shows the exact opposite, where value iteration fails but policy gradient doesn\'t. It feels like there are many assumptions that play into the given example (the reward function not changing; the transition dynamics being deterministic; the choice of using policy gradients and value iteration). \n\nIn addition, the authors provide a theoretical justification in the Appendix (which I have briefly scanned) and the intuition behind it in Section 5. From what I understand, the main problem arises from the policy\'s output space being a Gaussian distribution, which causes the policy being able to get stuck in a local optimum. Further, the authors show (in the Appendix) that under some assumtions the value function always converges. Are there any guarantees on this when we don\'t have access to the true reward and transition functions (which themselves could get stuck in a local optimum)?\n\nWould the authors say that the phenomenon is more a problem with the algorithm (policy gradient vs value iteration) than policy-centric and value-centric methods in general? Are there other methods that would be able to transfer policies better than policy gradient methods?\n\nRegarding B)\nThe author\'s proposed method (MVC) has three components: the value function, the dynamics model and the reward model, all of which are learned by neural networks. It seems like the main advantage comes from using a model (since that\'s the aspect which changes when having to transfer to an altered MDP). Does the advantage of this method over DDPG and TRPO come from the fact that the dynamics model changes smoothly, and we have an approximation to it? Then it is not surprising that this outperforms a policy gradient method. \n\nOther comments:\n\n- Could you explain what is meant by ""precise"" and ""imprecise"" when speaking about policies or value functions?\n- Could you explain what is meant by the algorithm being ""accessible"" (e.g., Definition 1)?\n\n- Section 2.1: In Property 1, what is f? Could you make explicit why we are interested in the two properties listed? By ""not rigorously"", do you mean that those properties are based on intuition? These properties are used later in the paper and the appendix, so I wonder how strong of an assumption this is.\n- Section 2.2: Could you explain what is meant by ""task""? You say that within the MDP, the transition dynamics and reward functions change, but the task stays the same. However, earlier (in the introduction) you state that only the environment dynamics change. I find it confusing that ""the task"" is something hand-wavy and not part of the formal definition of the MDP. In what exact ways can the reward function be influenced by the change in the transition dynamics? \n- Section 3: Replace ""obviously"" with ""hence""; remove ""it is not hard to find that"". This might not be so trivial for some readers.\n- Appendix B: Refer to Table 1 in the text.\n\nClarity: The paper is written well, but I think some assumptions and their affects should be stated more clearly and put into context. The paper misses a discussion / conclusion section. It would be great to see a discussion on some of the assumptions; e.g., what if the low dimensional assumtion breaks down? What if we assume that also the reward function can change? The authors are in a unique position to give insight into these things (even if the results from the paper do not hold after dropping some assumptions) and it would be very helpful to share these with the reader in a discussion section.', 'The paper considers the problem of transfer in continuous-action deep RL. In particular, the authors consider the setting where the dynamics of the task change slightly, but the effect on the policy is significant. They suggest that values are better suited for transfer and suggest learning a model to obtain these values.\n\nOverall, there are interesting ideas here, but I am concerned about whether the proposed approach actually solves the problem the authors consider and its general applicability.\n\nThe point about value functions being better suited for transfer than policies is indeed true for greedy policies: it is well-known that they are discontinuous, and small differences in value can result in large differences in policy. This point is hence relevant in continuous control, where deterministic policies are considered.\n\nBut I am a bit confused as to why the proposed approach is better though. Eq. (4) still takes a max w.r.t. the estimated dynamics, etc. So even if the value function is continuous, by taking the max, we get a deterministic policy which has the same problem! That is probably why the performance is quite similar to DDPG. Considering a softer policy parameterization (a continuous softmax analogue) would be more in line with the authors’ motivation.\n\nThe proposed method itself doesn’t seem generally practical unfortunately, as it is suggested to learn the *model* of the environment for with a high-dimensional state space and a continuous action space, and do value iteration. In other words, if Property 2 was easy to satisfy, we wouldn’t be struggling with model-based methods as much as we are! However, I do appreciate that the authors illustrate the model loss curves in their considered domains. This raises a question of when are dynamics “easy”.\n\nThe theoretical justification is quite weak, since the bound in Proposition 2 is too loose to be meaningful (as the authors themselves acknowledge). One way to mitigate this would be to support it empirically, by considering a range of disturbances of the specified form, and showing the shape of the bound on a small domain. The same thing can be done for the parametric modifications considered in the experiments -- instead of considering a set of instances, consider the performance as a function of the range of disturbances to the same dynamics parameter.\n\nMinor comments:\n* The italicization of certain keywords in the intro is confusing, in particular precise, imprecise -- these aren’t well-defined terms, and don’t make sense to me in the mentioned context. The policy function isn’t more “precise” than the value.\n* I suggest including the statements of the propositions in the main text', 'The paper proposes a model-based value-centric (MVC) deep RL algorithm for transfer learning. The algorithm optimizes neural networks to estimate the deterministic transitions and rewards, and uses the these models to learn a value function by minimizing the Bellman residual. Policy is represented implicitly as the action that greedily maximizes the return, expressed in terms of the learned models. The experiments show some improvement on transferability over DDPG and TRPO policies.\n\nThe paper has two relatively independent stories: The title and the introduction motivates the work by discussing the transferability of policies and value functions. However, instead of rigorously evaluating transferability, the paper proposes a model-based algorithm (MVC) for learning policies for continuous actions. Novelty of the new algorithm is quite limited, as it simply uses a learned dynamics model and reward function to learn a value function. Regarding transferability, introducing MVC seem quite orthogonal, and instead, it would be better to have a clear comparison of transferability using existing methods (e.g., DDPG). If having an explicit policy network hurts transferability, then existing algorithms can be modified by replacing the actor with greedy maximization, or alternatively other value based methods that do not involve actor network (NAF, SQL, QT-Opt) could be used.\n\nRegarding the intuition why values transfer better, the examples given in the introduction and Section 3 are good and intuitive. However, from my experience, the limited information content of a policy is only a partial reason for poor transferability, and in practice I have seen policies to transfer, in fact, better than values. The chosen viewpoint based on information content is nice as it can be proven mathematically, but might not be the most insightful and important in practice. The experimental evaluation is not rigorous enough to allow drawing further conclusions. For example, one could compare the two approaches using a wider set of RL algorithms, include more realistic environments (ideally transfer to real-world), or have a heat map illustrating transferability w.r.t. selected parameters. Also, no comparison to the  state-of-the-art methods is provided (PPO, TD3, SAC).\n\nMinor points:\n- Please include the theorems in Section 5 (and proofs in the appendix). The intuition provided in the body is not very clear.\n- Why is it necessary to assume a deterministic dynamics model? Why only the dynamics model can vary between the domains and not also the reward (second paragraph in Section 1)?\n']","[-20, -30, -30]","[80, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting questions and insights of the paper, they express significant doubts about whether the paper satisfactorily answers these questions or meets the standards for ICLR. The reviewer raises several concerns and questions about the paper's assumptions, methodology, and conclusions. However, the tone is not entirely negative, as the reviewer shows interest in the topic and invites the authors to respond to their questions.\n\nThe politeness score is quite high (80) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'It would be great to hear the author's thoughts,' 'Could you explain,' and 'I think these are very interesting questions to investigate.' The reviewer also acknowledges the potential benefits of the research and frames their criticisms as questions or areas for clarification rather than outright dismissals. The language is professional and courteous throughout, even when expressing doubts or concerns."", ""The sentiment score is -30 because while the reviewer acknowledges 'interesting ideas,' they express significant concerns about the approach's effectiveness and general applicability. The overall tone is more critical than positive, but not entirely negative. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging positive aspects ('I do appreciate...') and framing criticisms as concerns rather than direct attacks. They also offer constructive suggestions for improvement. The language is professional and courteous, avoiding harsh or rude expressions, but it's not excessively polite either."", ""The sentiment score is -30 because the review is generally critical of the paper, pointing out limitations in novelty, experimental rigor, and relevance of the proposed method to the stated goal of transferability. However, it's not entirely negative as it acknowledges some positive aspects like good intuitive examples. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement without being harsh or dismissive. The reviewer uses phrases like 'Please include' and offers alternative approaches, which contributes to the polite tone.""]"
"['This is an interesting paper, trying to find the adversarial cases in reinforcement learning agents. The paper discusses several different settings to investigate how generalizable the worst-case environment is across different models and conjectured that it comes from the bias in training the agents. Overall the paper is well-written and the experiments seem convincing. I have two questions regarding the presented result.\n\n1. The search algorithm depicted in section 2 is only able to find a local optimum in the environment space. How robust is the result given different initializations?\n\n2. It is briefly discussed in the paper that the failure in certain mazes might come from the structural bias in the training and the “complex” mazes are under-represented in the training dataset. It is hence natural to ask, if the procedure described in this paper can be incorporated to enhance the performance by some simple heuristics like re-weighting the training samples. I think some discussion on this would be beneficial for verifying the conjecture made here.\n\n3. The authors compared the “hardness” of the mazes based on the number of walls in the maze. But it is arguably a good metric as the authors also mentioned visibility and other factors in measuring the complexity of the task. I would like to see more exploration in different factors that accounts for the complexity and maybe compare different agents to see if they are sensitive in the same set of factors. \n\nTo summarize, I like the idea of the paper and I think the result can be illuminating and worth some more follow-up work to understand the RL training in general.\n', 'Update:\n\nI appreciate the clarifications and the extension of the paper in response to the reviews. I think it made the work stronger. The results in the newly added section are interesting and actually suggest that by putting more effort into training set design/augmentation, one could further robustify the agents, possibly up to the point where they do not break at all in unnatural ways. It is a pity the authors have not pushed the work to this point (and therefore the paper is not as great as it could be), but still I think it is a good paper that can be published.\n\n-----\n\nThe paper analyzes the performance of modern reinforcement-learning-based navigation agents by searching for “adversarial” maze layouts in which the agents do not perform well. It turns out that such mazes  exist, and moreover, one can find even relatively simple maze configurations that are easily solved by humans, but very challenging for the algorithms.\n\nPros:\n1) Interesting and relevant topic: it is important not only to push for best results on benchmarks, but also understand the limitations of existing approaches.\n2) The paper is well written\n3) The experiments are quite thorough and convincing. I especially appreciate that it is demonstrated that there exist simple mazes that can be easily solved by humans, but not by algorithms. The analysis of transferability of “adversarial” mazes between different agents is also a plus.\n\nCons:\n1) I am not convinced worst-case performance is the most informative way to evaluate models. Almost no machine learning model is perfect, and therefore almost for any model it would be possible to find training or validation samples on which it does not perform well. Why is it so surprising that this is also the case for navigation models? Why would one assume they should be perfect? Especially given that the generated “adversarial” mazed lie outside of the training data distribution, seemingly quite far outside. Are machine learning models ever expected to perfectly generalize outside of the training data distribution? Very roughly speaking, the key finding of the paper can be summarized as “several recent navigation agents have problems finding and entering small rooms of the type they never saw during training” - is this all that significant?\n\nTo me, the most interesting part of the paper is that the models generalize as well as they do. I would therefore like to see if it is possible to modify the training distribution - by adding “adversarial” mazes, potentially in an iterative fashion, or just by hand-designing a wider distribution of mazes - so that generalization becomes nearly perfect and the proposed search method is not anymore able to find “adversarial” mazes that are difficult for the algorithm, but easy for humans.\n\n2) On a related note, to me the largest difference between the mazes generated in this paper and the classical adversarial images is that the modification of the maze is not constrained to be small or imperceptible. In fact, it is quite huge - the generated mazes are far from the training distribution. This is a completely different regime. This is like training a model to classify cartoon images and then asking it to generalize to real images (or perhaps other way round). Noone would expect existing image classification models to do this. This major difference with classical adversarial examples should be clearly acknowledged.\n\n3) It would be interesting to know the computational requirements of the search method. I guess it can be estimated from the information in the paper, but would be great to mention it explicitly. (I am sorry if it is already mentioned and I missed it)\n\nTo conclude, I think the paper is interesting and well executed, but the presented results are very much to be expected. To me the most interesting aspect of the work is that the navigation agents generalize surprisingly well. Therefore, I believe the work would be much more useful if it focused more on how to make the agents generalize even better, especially since there is a very straightforward way to try this - by extending the training set. I am currently in the borderline mode, but would be very happy to change my evaluation if the focus of the paper is somewhat changed and additional experiments on improving generalization (or some other experiments, but making the results a bit more useful/surprising) are added.', 'The authors present a simple technique for finding ""worst-case"" maze environments that result in bad performance. The adversarial optimization procedure is a greedy procedure, which alternately perturbs maze environments and selects the maze on which the trained agent performs worst for the next iteration. The authors highlight three properties of these mazes, which show how this adversarial optimization procedure can negatively impact performance.\n\nHigh-level comments:\n- I am unconvinced that many of the observed behaviors are ""surprising"". The procedure for adversarially optimizing the maps is creating out-of-distribution map samples (this is confirmed by the authors). The function for creating maps built-in to DeepMind Lab (the tool used to generate the random maps used in this paper) has a set of rules it uses to ensure that the map follows certain criteria. Visual inspection of the \'Iteration 20\' maps in Figure 2 finds that the resulting adversarial map looks fundamentally different from the \'Initial Candidate\' maps. As a result, many of the features present in the adversarial maps may not exist in the initial distribution, and the lack of generalizability of Deep RL has become a relatively common talking point within the community. That being said, I agree with the authors\' claims about how this sort of analysis is important (I discuss this more in my second point).\n- In my mind, the \'discovery\' of the performance on these optimized out-of-distribution samples is, in my mind, not particularly impactful on its own. The Deep RL community is already rather aware of the lack of generalization ability for agents, but are in need of tools to make the agents more robust to these sorts of examples. For comparison, there is a community which researches techniques to robustify supervised learning systems to adversarial examples (this is also mentioned by the authors in the paper). I feel that this paper is only partially complete without an investigation of how these out-of-distribution samples can be used to improve the performance of the agents. The addition of such an investigation has the potential to greatly strengthen the paper. This lack of ""significance"" is the biggest factor in my decision.\n- The first two results sections outlining the properties of the adversarially optimized mazes were all well-written and interesting. While generally interesting, that the less-complex A2CV agent shows better generalization performance than the more-complex MERLIN agent is also not overly surprising. Yet, it remains a good study of a phenomenon I would not have thought to investigate.\n\nMinor comments:\n- The paper is very clear in general. It was a pleasure to read, so thank you! The introduction is particularly engaging, and I found myself nodding along while\n- Figures are generally excellent; your figure titles are also extremely informative, so good work here.\n- Fig 4. It might be clearer to say ""adversarially optimized"" instead of simplly ""optimized"" in the (b) caption to be clearer that it the map that is being changed here, rather than the agent. Also, ""Human Trajectories"" -> ""Human Trajectory"", since there is only one.\n- I am not a fan of saying ""3D navigation tasks"" for 2.5D environments (but this has become standard, so feel free to leave this unchanged).\n\nThis paper is a well-written investigation of adversarially chosen out-of-distribution samples. However, the the high-quality of this narrow investigation still only paints a partial picture of the problem the authors set out to address. At the moment, I am hesitant to recommend this paper for acceptance, due to its relatively low ""significance""; a more thorough investigation of how these out-of-distribution samples can be used.']","[70, 50, -30]","[80, 80, 70]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and 'well-written' with 'convincing' experiments. They also mention liking the idea and finding the results illuminating. The overall tone is supportive, though not overwhelmingly enthusiastic. The politeness score is 80 (polite) due to the reviewer's constructive and respectful language. They frame their points as questions or suggestions rather than criticisms, and use phrases like 'I would like to see' and 'I think' to soften their recommendations. The reviewer also concludes with a positive summary, reinforcing the polite tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges improvements made to the paper and finds the work interesting, stating it's 'a good paper that can be published.' However, they also express some disappointment that the authors didn't push the work further. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, appreciating the authors' efforts ('I appreciate the clarifications'), offering constructive criticism, and using phrases like 'I think' and 'To me' to soften their opinions. They also balance critiques with positive comments, demonstrating professional courtesy."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (e.g., 'well-written', 'interesting', 'excellent figures'), they express significant reservations about the paper's impact and significance. The reviewer is 'unconvinced' by some claims, finds some results unsurprising, and is 'hesitant to recommend this paper for acceptance'. However, it's not entirely negative, as they see potential value in the work with further investigation.\n\nThe politeness score is 70 because the reviewer uses respectful and constructive language throughout. They begin with positive comments, use phrases like 'thank you' and 'good work', and frame criticisms as suggestions for improvement rather than harsh judgments. The tone is professional and courteous, even when expressing concerns. The reviewer also acknowledges the clarity and readability of the paper, which adds to the overall polite tone.""]"
"['The paper theoretically analyzes the sparsity property of the stationary point of layerwise l1-regularized network trimming. Experiments are conducted to show that reaching a stationary point of the optimization can help to deliver good performance. Specific comments follow.\n\n1. While the paper analyzes the properties of the stationary point of the layerwise objective (5), the experiments seem to be conducted based on the different joint objective (8). Experimental results of optimizing (5) seem missing. While the reviewer understands that (5) and (8)  are closely related, and the theoretical insights for (5) can potentially translate to the scenario in (8), the reviewer is not sure whether the theory for (5)  is rigorously justified by the experiments.\n\n2. It is also unclear how tight the bound provided by Theorem 1 is.  Is the bound vacuous? Relevant statistics in the experiments might need to be reported to elucidate this point.\n\n3. It is also unclear how the trade-off in point (b) of the abstract is justified in the experiments.\n\nMinor Points:\npage 2, the definition of $X^{(j)}$, the index of $l$ and $j$ seem to be typos.\npage 2, definition 1, the definition of the bracket need to be specified. \npage 4, the concept of stationary point and general position can be introduced before presenting Theorem 1 to improve readability.\npage 4, Corollary 1, should it be $nnz(\\hat{W})\\le JN k_{\\mathcal{S}}$?\npage 7, Table 2, FLOPS should be FLOP? \npage 8, is FLOP related to the time/speed needed for compression? If so, it should be specified. If not, compression runtime should also be reported.\n\n\n\n\n', 'This paper discusses the effect of L1 penalization for deep neural network. In particular it shows the stationary point of an l1 regularized layer has bounded non-zero elements. \n\nThe perspective of the proof is interesting: By chain rule, the stationary point satisfies nnz(W^j) linear equations, but the subgradients of the loss function w.r.t. the logits have at most N\\times ks variables. If the coefficients of the linear equation are distributed in general positions, then the number of variables should not be larger than the number of equations. \n\nWhile I mostly like the paper, I would like to point out some possible issues:\n\nmain concerns: \n\n1. the columns of V may not be independent during the optimization(training) process. In this situation, I am not quite sure if the assumption of “general position” still holds. I understand that in literatures of Lasso and sparse coding it is common to assume “general position”. But in those problems the coefficient matrix is not Jacobian from a learning procedure. \n\n2. the claim is a little bit counter intuitive: Theorem 1 claims the sparse inequality holds for any \\lambda. It is against the empirical observation that when lambda is extremely small, effect of the regularizer tends to be almost zero. Can authors also show this effects empirically, i.e., when the regularization coefficients decrease, the nnz does not vary much? (Maybe there is some optimization details or approximations I missed?)\n\nSome minor notation issues:\n1. in theorem 1: dim(W^{(j)})=d should be dim(vec(W^{(j)}))=d\n2. in theorem 1: Even though I understand what you are trying to say, I would suggest we describe the jacobian matrix V in details. Especially it is confusing to stack vec(X^J) (vec(W^j)) in the description.\n3. the notations of subgradient and gradient are used without claim\n', 'The main concerns come from the following parts:\n\n\n(1) Repeating the old story from other papers:\nA large part of math is from previous works, which seems not enough for the ICLR conference.\nIt is very surprising that the authors totally ignore the latest improvements in neural network compression. Their approach is extremely far away from the state of the art in terms of both methodological excellence and experimental results. The authors should read through at least some of the papers I list below, differentiate their approach from these pioneer works, and properly justify their position within the literature. They also need to show a clear improvement on all these existing pieces of work. \n\n(2) quite limited novelty:\nIn my opinion, the core contribution is replacing SGD with Adam.\nFor network compression, it is common to add L1 Penalty to loss function. The main difference of this paper is change SGD to Adam, which seems not enough. \n\n(3) lacking solid experiments:\nIn section Experiment, the authors claim ""Finally, we show the trade-off for pruning Resnet-50 on the ILSVRC dataset."", but I cannot find the results. \n\nIs the ResNet-32 too complex for cifar-10? Of course, it can be easily pruned if the model is too much capacity for a simple dataset.  Why not try the Resnet-20 first?\n\n[1] C. Louizos et al., Bayesian Compression for Deep Learning, NIPS, 2017\n[2] J. Achterhold et al., Variational Network Quantization, ICLR, 2018']","[-20, 50, -80]","[60, 75, -20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's theoretical analysis and experiments, they express several concerns and uncertainties about the methodology and results. The reviewer points out mismatches between theory and experiments, questions the tightness of bounds, and notes unclear justifications. These critiques suggest a somewhat skeptical view of the paper's contributions. However, the tone is not entirely negative, as the reviewer also recognizes the potential value of the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'the reviewer understands' and 'it is unclear' rather than making accusatory statements. The review is structured and specific, offering constructive feedback and even including minor points for improvement. The language is neither overly formal nor casual, striking a balance that is appropriate for academic peer review. While not excessively polite, the reviewer's tone is consistently courteous and focused on improving the paper rather than criticizing the authors."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the interesting perspective of the proof and stating that they 'mostly like the paper'. However, they also raise some concerns, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases their concerns as questions or suggestions rather than criticisms (e.g., 'Can authors also show...?', 'I would suggest...'), and acknowledges their own potential misunderstanding ('Maybe there is some optimization details or approximations I missed?'). The reviewer also separates their main concerns from minor notation issues, which is a considerate way to structure feedback."", ""The sentiment score is -80 because the review is highly critical, pointing out major flaws in the paper such as lack of novelty, insufficient experiments, and ignoring recent advancements in the field. The reviewer expresses surprise at the authors' oversight and suggests the work is far from state-of-the-art. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. Phrases like 'extremely far away from the state of the art' and 'totally ignore the latest improvements' come across as blunt and somewhat impolite. The reviewer does offer some constructive feedback and suggestions for improvement, which prevents the politeness score from being even lower.""]"
"[""The paper proposes an imitation learning model able to generate trajectories based on some expert trajectories. The assumption is that observed trajectories contain multi-modal (i.e. style) information that is not naturally captured by existing methods. The authors proposed a VAE based architecture that uses a prior distribution P(z) to simultaneously generate (state-action) pairs based on a LSTM decoder (actually, one LSTM for the states and one interleaved LSTM for the actions). This decoder is learned using a classical VAE auto-encoding loss, observed trajectories being encoder through a bi-LSTM. Experiments are made on three toy examples: a simple 2d Navigation case exhibiting 3 different 'styles', a 2D circle example with also 3 different styles, and a zombie attack scenario with two different styles. The results show that the model is able to capture different clusters of trajectories. \n\nFirst of all, the paper does not propose a new model, but an instantiation of an existing model to a particular case. The main difference with SoTA is that the authors propose to both decode states and actions without using a simulator. The contribution of the paper is thus quite light. Moreover, it is unclear how the model can be used to get a policy corresponding to a particular mode. Can we use the learned decoders to generate actions on-the-fly in a real/simulated environment? Right now (section 3.3), actions are generated on generated states, but not on observed ones.  The paper has to clarify this point since just generating trajectories seems to be a little bit useless. In general Section 3.3 lacks of details (e.g the rolling window is also unclear). Also, the model could be described a little bit more in term of architecture, particularly on the critical point about how the two decoding LSTMs are interacting. \n\nFrom the experimental point of view, the paper attacks very simple cases, without any comparison with state-of-the-art, and without almost any quantitative results. If Section 4.1 and 4.2 are useful to explore the ability of the model on simple cases, I would recommend the authors to merge these two sections in one smaller one, and then to focus on more realistic experiments. For example, it seems to me that the experimental setting proposed for example in [Li et al.] on driving styles could be interesting, and would allow a comparison with existing methods. Also the model proposed in [Co-Reyes et al.] could be an interesting comparison (at least, keeping the principle of this paper, without the hierarchical structure), particularly because this model is based on the use of a simulator while the proposed one is not. If a performance close to this baseline can be obtained with your model, it would be interesting for the community.\n\nRight now, the experimental part and the too small contribution of the paper are not enough for acceptance. I would suggest the authors to:\n* better describe their contribution i.e model architecture and how the model can be used to obtain a real policy\n* use 'stronger' use cases for the experiments, and particularly existing use cases\n* provide a deep quantitative and qualitative comparison with SoTA\n\nPro:\n* simple method, no need of a simulator\n\nCons:\n* not clear how to move from trajectory generation to a real policy\n* small contribution\n* too light experimental study without comparison with baselines and state of the art\n"", '\nThis paper proposes a VAE for modelling state-action sequences using a single latent variable rather than one per timestep. The authors empirically demonstrate that this model works on toy 2D examples and a simplified 2D Minecraft-like environment. Although I am unaware of other works that use a VAE in this setting, the model is still quite generic, thus requires further application to justify its significance. This paper is clear and well written. \n\nThe current contribution of this paper is limited, however it could be improved in a number of ways. The main component lacking from this paper is a meaningful comparison to other related works. Its unclear what the advantage of this model is over other models and so a thorough comparison to other sequence models would really help this paper. As mentioned in the conclusion, another direction for this work would be to bootstrap reinforcement learning. If this bootrapping was demonstrated then it would make this paper’s contribution stronger. Finally, another important direction for improvement for this paper would be to demonstrate its usefulness on more complex environments, instead of only 2D examples. \n\nPros:\n- clear and well written\n- model works on toy examples\nCons:\n- lack of baseline comparisons\n- lack of contributions\n\n\n', 'This paper presents an approach to multi-modal imitation learning by using a variational auto-encoder to embed demonstrated trajectories into a structured latent space that captures the multi-modal structure. This is done through a stochastic neural network with a bi-directional LSTM and mean pooling architecture that predicts the mean and log-variance of the latent state. This is followed by a state and action/policy decoder (both LSTMs) that recursively generate trajectories from latent space samples. The entire model is trained by optimising the ELBO on a set of pre-specified expert demonstrations. At test time, samples are generated from the latent space and recursively decoded to generate state and action trajectories. The method is tested on three low-dimensional continuous control tasks and is able to learn structured latent spaces capturing the modes in the training data as well as generating good trajectory reconstructions.\n\nLearning from multi-modal demonstration data is an important sub-area in imitation learning. As the paper pointed out, there has been a lot of recent work in this area. A lot of the ideas in this paper are similar to those proposed in prior work -- the network for embedding the trajectory is similar to the ones from Wang et al & Co-Reyes et al with the major difference being in the structure of the action decoder (and what inputs to encoder). Also, prior work has dealt with problems that are high-dimensional (Wang et al) and has shown results when operating directly on visual data (InfoGAIL). Comparatively, the results in this paper are on toy problems. \n\nAs there is no direct comparison to prior work provided in the paper, it is hard to quantify how much better the proposed approach is in comparison to prior work. For example, the ""2D Circle Example"" was taken from the InfoGAIL paper. It would have been good to use that as a baseline example to compare those two methods and highlight the advantages of the proposed approach -- did it require less data? fewer environment interactions? etc. \n\nThe results on the Zombie Attack Scenario seem poor. Specifically, in the avoid scenario, the approach seems to fail almost half the time. It would be good if the authors spend more time on this -- again, a comparison to prior work would establish some baselines and give us a good idea of the expected performance on this scenario. The videos show a single representative example for the ""Attack"" and ""Avoid"" scenarios. More examples including failures need to be included so that the distribution of results can be captured. \n\nThere is little in terms of generalisation or ablation studies in the paper. For example, in the Zombie Attack Scenario one could generate data with different zombie behaviours and measure performance on held out behaviours. Similarly, as an ablation, the authors could look at directly predicting actions instead of states & actions (states could be generated through a pre-trained dynamics model).\n\nFigure 6. is hard to parse and could be explained better. No details are provided on the network architecture (number/size of the LSTM/fully connected layers), number of demonstrations used, training algorithm, hyper-parameters etc. \n\nFew typos in the paper: \n  Page 6 - between the animation links \'avoiding\' \'region\'\n  Fig 7 caption - the zombie but are not in attacking range -> but the zombies are not in the attacking range,\n\nRelevant citations that can be added:\n1) Hausman, K., Chebotar, Y., Schaal, S., Sukhatme, G., & Lim, J. J. (2017). Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets. In Advances in Neural Information Processing Systems (pp. 1235-1245).\n2) Tamar, A., Rohanimanesh, K., Chow, Y., Vigorito, C., Goodrich, B., Kahane, M., & Pridmore, D. (2018). Imitation Learning from Visual Data with Multiple Intentions.\n\nOverall, I find the paper to be incremental and lacking good experimental results and comparisons. The strengths of the paper are not clear and need to be explained and evaluated well. Substantial work is needed to significantly improve the paper before it can be accepted.']","[-50, -20, -60]","[20, 60, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several significant weaknesses in the paper such as 'light contribution', 'unclear' aspects, and 'too simple' experiments. However, it's not entirely negative as it acknowledges some positive aspects ('simple method, no need of a simulator') and provides constructive suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer specific, constructive feedback. Phrases like 'I would suggest' and 'it would be interesting' indicate a polite tone, even while delivering criticism. The reviewer also balances negative points with positive ones, which contributes to a more polite overall tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clear and well written', 'model works on toy examples'), they emphasize that the paper's contribution is 'limited' and list several areas for improvement. The overall tone suggests that significant work is needed to make the paper more impactful. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement rather than harsh criticisms. The reviewer maintains a professional tone, using phrases like 'could be improved' and 'would really help this paper', which contribute to the polite nature of the review."", ""The sentiment score is -60 because the review is generally negative, pointing out several shortcomings of the paper. The reviewer states that the paper is 'incremental and lacking good experimental results and comparisons' and that 'substantial work is needed to significantly improve the paper before it can be accepted.' However, it's not entirely negative as the reviewer acknowledges some strengths and provides constructive feedback, hence not scoring at the extreme negative end. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They offer specific suggestions for improvement and point out both strengths and weaknesses. The language used is not rude, but rather constructive and academic in nature. However, it's not overly polite either, maintaining a neutral to slightly positive tone in terms of politeness.""]"
"['The authors study in this paper the approximation capabilities of neural networks for real valued functions on probability measure spaces (and on tree structured domains). \n\nThe first step of the paper consists in extending standard NN results to probability measure spaces, that is rather than having finite dimensional vectors as inputs, the NN considered here have probability measures as inputs. The extension to this case is straightforward and closely related to older extension on infinite dimensional spaces (see for instance the seminal paper of Stinchcombe https://doi.org/10.1016/S0893-6080(98)00108-7 and e.g. http://dx.doi.org/10.1016/j.neunet.2004.07.001 for an application to NN with functional inputs). Nothing quite new here.\n\nIn addition, and exactly as in the case of functional inputs, the real world neural networks do not implement what is covered by the theorem but only an approximation of it. This is acknowledged by the authors at the end of Section 2 but in a way that is close to hand waving. Indeed while the probability distribution point is valuable and gives interesting tools in the MIL context, the truth is that we have no reason to assume the bag sizes will grow to infinite or even will be under our control. In fact there are many situations were the bag sizes are part of the data (for instance when a text is embedded in a vector space word by word and then represented as a bag of vectors). Thus proving some form of universal approximation in the multiple instance learning context would need to take this fact into account, something that is not done at all here. \n\nTherefore I believe the contribution of this paper to be somewhat limited. ', 'This paper generalizes the universal approximation theorem (usually stated for real functions on some Euclidean space) to real functions on the space of measures (at least a compact set of proba. measures).\n\nThis result might be interesting but not really surprising and the paper does not put any new theoretical ideas or proof techniques. The proof is actually almost identical than in the original paper of Hornik, Stinchcombe and White (89) [and not the 91 paper of Hornik as indicated in the paper], the only difference being a trick on the density of f\\circ h instead of just considering cos() function.\n\nAll in all, the contributions is interesting but really incremental', 'The paper investigates the approximation properties of a family of neural networks designed to address multi-instance learning (MIL) problems. The authors show that results well-known for standard one layer architectures extend to the MIL models considered. The authors focus on tree-structured domains showing that their analysis applies to these relevant settings. \n\nThe paper is well written and easy to follow. In particular the theoretical analysis is clear and pleasant to read. \n\nThe main concern is related to the relevance of the result to ICLR. As the authors themselves state, the result is not surprising given the standard universality result of one-layer neural networks (and indeed Thm. 2 heavily relies on this fact to prove the universality of MIL architectures). In this sense the current work might be more suited to a journal venue. \n\n']","[-50, -20, 20]","[20, 0, 80]","[""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper's contribution, stating it is 'somewhat limited' and that there is 'Nothing quite new here.' However, it's not entirely negative as the reviewer acknowledges some valuable points. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout, using phrases like 'I believe' to soften criticism. They also acknowledge the authors' work and provide constructive feedback, which is more polite than purely negative criticism. The language is not overtly polite, but it avoids rudeness, hence a slightly positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the result 'might be interesting', they also state that it's 'not really surprising' and describe the contribution as 'really incremental'. The reviewer points out that the paper doesn't introduce new theoretical ideas or proof techniques, which further contributes to the negative sentiment. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states their opinions directly without using overly harsh language, but also without any notably courteous phrasing. They present their critique in a matter-of-fact manner, focusing on the content rather than using emotional or personal language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and easy to follow, with clear theoretical analysis. However, they express a concern about the relevance of the result to ICLR, suggesting it might be more suited for a journal venue, which tempers the overall positive sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, offering praise for the writing and clarity, and framing their concern in a constructive manner without harsh criticism. The phrases 'well written', 'easy to follow', and 'clear and pleasant to read' contribute to both the positive sentiment and polite tone.""]"
"['Pros:\n+ Improving joint training of non-differentiable pipelines is a meaningful and relevant problem\n+ Using the stochastic computation graph structure to smooth a pipeline in a structured way is a plausible idea\n\nCons:\n+ The main result of the paper concerning sufficient conditions for optimality of the method seems dubious\n+ It is not obvious why this method would outperform simple baselines, and baselines for joint training were tried\n+ The notation seems unnecessarily bloated and overly formal\n+ The exposition spends too much time on prior work, too little on the contribution, and the description of the contribution is confusing\n\nThe submission describes a method for smoothing a non-differentiable machine learning pipeline (such as the Faster-RCNN detector), so that gradient-based methods may be applied to jointly train all the parameters of the pipeline.  In particular, the proposal involves recasting the pipeline as a stochastic computation graph (SCG), adding stochastic nodes to this graph, and then using REINFORCE-style policy gradients to perform parameter learning on the SCG.  It is claimed that under certain conditions, the optimal parameters of the resulting SCG are also optimal for the original pipeline.  The method is applied to optimizing the parameters of Faster-RCNN.\n\nI think making non-differentiable pipelines differentiable is an intuitively appealing concept.  A lot of important, practical machine learning systems fall into this category, so devising a nice way to do global parameter optimization for such systems could potentially have significant impact.  In general, we can’t hope to make much meaningful progress on the problem of optimizing general nonlinear, differentiable functions, but it is plausible that a method that targets key non-differentiable components for smoothing—such as this paper—could outperform a generic black-box optimizer.  So, I think the basic idea here is plausible and addresses an important problem.\n\nUnfortunately, I think this work loses sight of that high-level goal: to me, the key question is whether the proposed approach outperforms any other simple method for global parameter optimization in the presence of nonlinearities and nondifferentiability.  The paper fails to answer this question because no baselines for global parameter optimization were tried.  We can just treat the pipeline as a black box mapping parameters to training set performance, and so any black-box optimization method can be applied to this problem.  It is not clear that the proposed method would outperform an arbitrary black box optimization method such as simulated annealing, Nelder-Mead, cross-entropy method, etc.\n\nI think there are also much simpler methods in a similar vein to the proposed method that might also perform just as well as the proposal.  One key conceptual issue here is that reducing the problem to a reinforcement learning problem, as the submission does, is not much of a reduction at all.  First, if the goal is to do global parameter optimization, then we don’t really have to smooth the pipeline itself: we can just smooth the black box mapping parameters to performance, and then optimize that with SGD.  There are many ways to do this--if we want to use policy gradient, we can just express the problem as something in this form:\n\nmin_\\phi E_{\\theta ~ q_\\phi} C(\\theta)\n\nwhere C is the black-box mapping parameters \\theta to a performance index (such as mean AP), q_\\phi is a distribution over parameters (e.g., Gaussian), and \\phi are the distribution parameters (e.g., mean, covariance of the Gaussian).  We can then optimize this using REINFORCE policy gradients.\n\nIf we want to really smooth the pipeline itself, then it is also easy to do this by devising a suitable MDP and then applying REINFORCE with the usual MDP structure.  We simply identify the state s_t at time t with the output of the t’th pipeline stage, introduce a new ‘action’ variable a_t representing a ’stochastified output’, and trivial dynamics (P(s_{t+1} | s_t, a_t) = \\delta(s_{t+1} - a_t)).  If the policy is a Gaussian (P(a_t | s_t) = N(a_t; s_t, \\Sigma)), then this is similar to relaxing the constraint that one stage’s output is equal to the input of the next stage, and somehow quadratically penalizing their difference.  In fact, there is a neural network training method based explicitly on this penalization view [A], and it would make yet another great baseline to try.\n\nIn fact, the proposed method is essentially similar to what I have just described, but it is unfortunately described in an overcomplicated way that obscures the true nature of the method.  I think the whole SCG framework is overkill here.  Too much of the paper is spent just rehashing the SCG framework, and the very heavy notation again just obscures the essential character of the method.\n\nIf there were, as the paper claims, some interesting condition under which the method produces solutions that are optimal under the original pipeline, that would be remarkable and interesting.  However, I have serious doubts about this part of the paper.  The key problem is the statement that “It follows that c(k_c, DEPS_c - k_c) = c(…) + z_c”.  The paper seems to be claiming that if E z = 0, then c(k + z) = c(k) + z, which can’t possibly be true in general.  \n\nThe heavy and opaque notation makes it very difficult to understand this section.  Perhaps it would help to consider a very simple example.  Suppose we want to minimize E_{x ~ q} c(y(x)) (where x ~ q means x is distributed as q).  We can introduce only one new stochastic node (k = y + z), between y and c.  Clearly c(y + z) is not generally equal to c(y) + z, even if E z = 0.\n\nIn summary, I think the submission needs a lot of work on multiple axes before it can make a significant impact.  The most important issues are a complete lack of relevant baselines and the dubious claims about sufficient conditions for optimality.  The idea could have merit, but it needs to be carefully compared and motivated with respect to existing work (such as [A]) as well as the simple baselines I have mentioned.  The presentation also needs to be revised to find the simplest expression of the method and to focus on the interesting parts.\n\n[A] Taylor, Gavin, et al. ""Training neural networks without gradients: A scalable admm approach."" International Conference on Machine Learning. 2016.', 'The paper proposes a method for converting a non-differentiable machine learning pipeline into a stochastic, differentiable, pipeline that can be trained end-to-end with gradient descent approaches.\n\n* Clarity: The language in the paper is very clear and easy to follow. The paper is lacking in clarity only when discussing some results/concepts from previous work (see detailed comments below).\n* Quality: Overall the paper is in good shape, aside from some concerns which I will describe further.\n* Originality: The originality is not very clear because it seems that a lot of ideas are borrowed from Schulman et al. (2015) (i.e. the concept of stochastic computation graph and how to compute the gradient) and from Rao et, al (2018) (i.e. sampling bounding boxes in some stages of the pipeline). To be fair to the authors, I am not very familiar with the two papers mentioned above, which makes this hard to judge. However, I think this paper could have explained more clearly which part exactly is a novelty of this paper, and where it separates from the rest.\n* Significance: The concept of converting a non-differentiable pipeline to a differentiable version is indeed very useful and widely applicable, but the experimental section did not convince me that this particular method indeed works: the results show a very small improvement (0.7-2%) on a single system (Faster R-CNN), that has already been pretrained (so not clear if this method can learn from scratch).\n\nPros:\n1)\tOverall the paper is well written.\n2)\tThe algorithm shown in Figure 4 nicely summarizes the whole algorithm.\n3)\tI particularly liked the part of Section 3 where it is shown the equivalence between the optimal parameters for the non-differentiable pipeline and the optimal parameters for the differentiable version.\n4)\tFigure 5 with detailed results is useful.\n\nCons:\n5)\tThe way the paper is written, it is not clear where the contribution of this paper separates from existing work, mainly Schulman et al. (2015). I believe the idea of going around non-differentiability via minimizing a surrogate loss (i.e. your equation (2) introduced by Schulman et al. (2015)) is already known. I’m not sure exactly where this work diverges from that.\n6)\tThe contribution of this paper is posed as a general framework for turning an arbitrary non-differentiable pipeline into a similar differentiable and stochastic version. However, the experimental section does not convince me that: \n    a)\tit is general – because it is applied only on the Faster R-CNN problem. \n    b)\tthat it can learn from scratch – it is only applied after the base method has been pre-trained. There are no experiments where you train a network from scratch with this new differentiable pipeline. If the reason is that ResNets are hard to train from scratch, then you can always try your pipeline on a smaller problem, even a synthetic dataset, just to prove that it works.\n     c)\tthat the improvement is significant from the baseline method – the results section show only a 1-2% increase in mAP, and only for the smaller networks (on larger ResNet models the gain is less than 1%, and the standard deviation is getting larger). \n\nDetailed comments:\n7)\tYou only cite the work of Schulman et al. (2015) at the beginning of section 2.1. While moving to section 2.2, I initially got the wrong impression that this us your contribution. Please state clearly where this comes from.\n8)\tIt is not explained well why the new gradient can be estimated as in equation (2). I spent quite some time trying to figure out where that comes from (particularly the log part), only to realize that the explanation is probably in the original work (at the time when I thought this is your contribution). Please point the readers to it. \n\nFinal remarks: \nOverall this paper introduces some interesting ideas. My main concerns were: (1) the originality, and (2) the results are not convincing. Perhaps concern (1) can be easily clarified by the authors, but for concern (2) it might be useful to show new results (training from scratch, other architectures to prove generality), as well as give arguments as to why the 1-2% gain in mAP is significant. \n', 'The authors use RPO (Shulman et al, 2015) to transform non-differentiable operations in Faster R-CNN such as NNS, RoIPool, mAP to stochastic but differentiable operations. They cast Faster R-CNN as a SCG which can be trained end-to-end. They show results on VOC 2007.\n\nPros:\n(+) The idea of casting a non-differentiable pipeline into a stochastic one is very reasonable\n(+) This idea is showcased for a hard task, rather than toy examples, thus making it more realistic and exciting\nCons:\n(-) Results are rather underwhelming\n(-) Important properties of the final approach, such as complexity (time, memory, FLOPs) are not mentioned at all\n\nWhile the idea the authors present seems reasonable and is showcased for a hard problem, such as object detection and on a well-designed system such as Faster R-CNN, the results are rather underwhelming. The proposed approach does not show any significant gains on top of the original pipeline (for ResNet101 the reported gains are < 0.2%). These small gains come at the expense of a more complicated definition and training procedure. The added complexity is not mentioned by the authors, such as time, memory requirements and FLOPs. In addition, the VOC2007 benchmark is rather outdated and much smaller than others. It would be nice to see similar results on COCO, which is larger and more challenging. \n\nSimilar efforts in this direction, namely making various modules of the Faster R-CNN pipeline differentiable, have shown little gains as well. For example, Dai at al., CVPR 2016, convert RoIPool into RoIWarp (following STN, Jaderberg et al) that allows for differentiation with respect to the box coordinates. ']","[-60, -20, -20]","[20, 60, 50]","[""The sentiment score is -60 because the review is predominantly negative. While it acknowledges the importance of the problem and the plausibility of the basic idea, it criticizes the paper's main results, lack of baselines, overcomplicated notation, and dubious claims. The reviewer states that the submission 'needs a lot of work on multiple axes' and has 'serious doubts' about key parts of the paper. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'Unfortunately' to soften criticisms. They also acknowledge some positive aspects before delving into the negatives. However, the criticism is direct and extensive, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'nicely summarizes', 'useful'), they express significant concerns about originality and the convincingness of the results. The cons outweigh the pros, and the final remarks emphasize these concerns. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively ('Please state clearly', 'it might be useful to show'). They also use phrases like 'To be fair to the authors' and 'I particularly liked', which contribute to a polite tone. However, it's not extremely high as the review is still direct in its criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros') of the work, they express disappointment with the results ('rather underwhelming') and point out several limitations. The overall tone suggests that the reviewer is not fully convinced by the work's contribution. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticism with acknowledgment of the work's merits. They use neutral language to express concerns ('It would be nice to see...') rather than harsh criticism, and provide constructive feedback for improvement.""]"
"['Overall, this is a thorough attempt at a system for evaluating various generative models on synthetic problems vaguely representative of the kinds of problems claimed to be covered by GANs. I think the approach and the conclusions drawn are mostly reasonable, with one major caveat discussed shortly.\n\nI also think it would help in a revision to add evaluations of more recent successors to RealNVP, such as MAF (NIPS 2017, https://arxiv.org/abs/1705.07057 ), Glow ( https://arxiv.org/abs/1807.03039 ), and (although of course this paper came out concurrently with your submission) the promising FFJORD ( https://openreview.net/forum?id=rJxgknCcK7 ). The scale of comparison of GAN variants is also much smaller than that of Lucic et al. or their followup, Kurach et al. ( https://arxiv.org/abs/1807.04720 ), which is not cited here (and should be).\n\nBut primarily, I think there are some serious concerns with your choice of metrics that make the results as they are difficult to interpret.\n\n\n""Note that OT is not a distance in the standard mathematical sense, as for instance the \'distance\' between two sets of points sampled from the same distribution is not zero."" -- You\'ve confused some notions here. The Wasserstein-1 distance, which is a scalar times the variant of OT you use here, absolutely is a proper distance metric between distributions: W(P, Q) is a metric. But when you compute the OT distance between *samples*, OT(S, T) with S ~ P and T ~ Q, you\'re equivalently computing the distance W(\\hat{P}, \\hat{Q}) between the empirical distributions of the samples, \\hat{P} = 1/N \\sum_i \\delta_{S_i} and the similar \\hat{Q}, which of course are not the same thing as the source distributions themselves. You can, though, view OT(S, T) as an *estimator* of W(P, Q); the distance between *distributions* is what we actually care about.\n\nIt is well-known that these empirical distributions of samples \\hat{P} converge to the true distribution P (in the Wasserstein sense, W(P, \\hat{P})) exponentially slowly in the dimension, which is what your example about high-dimensional distributions demonstrates. Incidentally, this is exactly the example used in Arora et al. (ICML 2017, https://arxiv.org/abs/1703.00573 ). This means that, viewed as an estimator of the true distance between distributions, the empirical-distribution OT estimator is strongly biased. Thus it becomes very difficult to tell what the true OT value is at any sample size, and moreover this amount of bias might differ for different distribution pairs even at the same sample size, so *comparing* OT estimates at a fixed sample size is a tricky business. For example, in your Figure 2, when the ""oracle"" score is significantly more than zero, you know that all of your estimates are very strongly biased. There is not, as far as I know, any strong reason to suspect that this amount of bias should be comparable for different distribution pairs, making any conclusions drawn from these numbers suspect.\n\n\nYour scheme you call ""Two-Sample Test,"" first, should have a more specific name. Two-sample testing is an extremely broad field, with instances including the classical Kolmogorov-Smirnov test and t tests, the popular-in-ML kernel MMD-based tests, and even Wasserstein-based tests (e.g. https://arxiv.org/abs/1509.02237 ). Previous applications of these tests in GANs and generative models include Bounliphone et al. (ICLR 2016, https://arxiv.org/abs/1511.04581 ), Lopez-Paz and Oquab (2016 - which you cite without a venue but which was at ICLR 2017), Sutherland et al. (ICLR 2017, https://arxiv.org/abs/1611.04488 ), Huang et al. (2018), and more, using a variety of schemes. Your name for this should include ""nearest neighbor"" or something along those lines to avoid confusion.\n\nAlso, you call this an ""extension of the original formulation,"" but in the common case where n(x) is more often right than wrong, your v is exactly \\hat t - 1 of Lopez-Paz and Oquab; see their (2). If it\'s usually wrong, then v = 1 - \\hat t; only when the signs differ per class does it significantly differ from theirs, and in any case I don\'t see a real motivation to put the absolute values for each class separately rather than just taking |\\hat t - 1/2|.\n\nMoreover, it\'s kind of crazy to term your v statistic a two-sample *test* -- you have nothing in there about its sampling distribution, which is key to hypothesis testing to obtain e.g. a p-value. (Maybe the variance of v is very different between different distributions; this is likely the case. In any case the variance will probably become extremely large as the dimension increases.) Comparing this score is thus difficult, but in any case calling it a ""test"" is potentially very misleading. You could, though, estimate the variance as described by Lopez-Paz and Oquab to construct a test.\n\nAlso: you can imagine the statistic v(S, T) as an estimator of the distance between distributions given as\n  D(P, Q) = |1/2 - \\int ( 1 if p(x) > q(x), 0 o.w.) p(x) dx|\n          + |1/2 - \\int (-1 if p(x) > q(x), 0 o.w.) q(x) dx|.\nBut v(S, T) is, like for the OT distance, a biased estimator of this distance, whose bias will get worse with the dimension. Thus, like with the OT, it\'s hard to meaningfully compare v(S, T) as an attempt to compare *distributions* based on D, which is what we actually care about. Here the oracle score does not show strong bias: assuming a reasonable number of samples, when P = Q the v estimator is always going be approximately 0. But this doesn\'t mean that other estimators aren\'t strongly biased, and indeed this is exactly what your Appendix C shows. The strong change in performance for KDE is somewhat hard to interpret, but maybe has something to do with the connection between KDE and NN-based methods?\n\n\nYour log-likelihood score is an unbiased and asymptotically normal estimate of the true distribution score (the cross-entropy), so it\'s easy to compare. But it accounts only for a very small portion of comparing distributions.\n\n\nThere is at least one score in common use for this kind of evaluation with easy-to-compare estimators: the squared MMD. It has an easy-to-compute unbiased and asymptotically normal estimator, so it\'s easy to get confidence intervals for the true value between distributions at any sample size, making comparing the numbers based on a reasonable number of samples easy. There\'s also a well-devolped theory for how to construct p-values for a test if you want those; Bounliphone et al. above even developed a relative test to compare the MMDs of two models accounting for the correlations due to using the same ""target"" set, though if you use separate target sets (because you can easily sample more points from your synthetic distribution) then it\'s simpler. The choice of kernel does matter, but I think the median-heuristic Gaussian kernel would be a very reasonable score to add to your repertoire, and for particular distributions you also might be able to pick a better kernel (e.g. based on the causal factors when those exist). See also Binkowski et al. (ICLR 2018, https://arxiv.org/abs/1801.01401 ) for a detailed discussion of these issues in comparison to the FID score.\n\nUsing a metric whose estimation can be understood, and whose estimators can be reliably compared, is I think vital to any evaluation process. This also prevents issues like when RealNVP outperforms the oracle, which should be impossible with any proper evaluation metric.\n\n\n\nMinor points:\n\n- Why is Pedregosa et al. (2011) cited for fitting multivariate Gaussians by maximum likelihood? This is something that doesn\'t need a citation, especially not to scikit-learn, which doesn\'t even (I don\'t think) contain an implementation of fitting Gaussians beyond (np.mean(X, axis=0), np.cov(X, rowvar=False)).\n\n- Mode coverage and related scores: this is based on assigning sample points to their single most likely clusters? I\'d imagine that sometimes a model will output points far from any cluster, in which case the cluster that happens to be closest might happen to be the most likely, but it\'s strange to really count that point as part of that cluster for these scores. Or similarly, a point might be relatively evenly spaced between two clusters, in which case the assignment could be fairly arbitrary, again making these scores a little strange.', 'This work aims at addressing the generative model evaluation problem by introducing a new benchmark evaluation suite which hosts a large array of distributions capturing different properties. The authors evaluated different generative models including VAE and various variants of the GANs on the benchmark, but the current presentation leaves the details in the dark.\n\nThe proposed benchmark and the accompanied metrics should provide additional insights about those generative models that are not well known and help drive improvement to model design, similar to [1] and [2]. But the presentation of the work, especially the experiment section, only gives abundant number of results without detailed explanation regarding the pros and cons of the existing models, the efficacy of the proposed metrics, or the reason behind some nice generative properties of GANs that are not able to learn the distribution well.\n\nOther issues:\n- In Section 1, the authors argued that ""we deliberately avoid convolutional networks on images with the aim of decoupling the benefits of various modeling paradigms from domain specific neural architectures"". Then in footnote 4, they mentioned that ""constructed by hand neural generators that well approximate these distributions"" which suggests the importance of the domain specific neural architectures. It would be nicer to see how much the ""specific"" neural architectures help and how different metrics favor different architectures.\n- The authors only used 10K training points and 1K test samples, which seems small especially for multivariate distributions. This could have impacts on the quality of the learned models, especially the neural ones.\n\n[1] M. Zaheer, C.-L. Li, B. Poczos, and R. Salakhutdinov. GAN connoisseur: can GANs learn simple 1D parametric distributions? NIPS Workshop on Deep Learning: Bridging Theory and Practice 2017.\n[2] S. Arora, and Y. Zhang. Do GANs actually learn the distributions? An empirical study. arXiv:1706.08224.\n', ""Updated to reflect author response:\n\nThis paper proposes a series of metrics to use with  a collection of generative models to evaluate different approximate inference frameworks. The generative models are designed to be synthetic and not specialized to a particular task. The paper is clearly written and the motivation is very clear.\n\nWhile there has been work like Forestdb to maintain a collection of generative models, I don't believe\nthere has been work to evaluate how they perform on a series of metrics. There would be great utility\nin having a less ad-hoc way to evaluate inference algorithms.\n\nWhile the idea is sound, the work still feels a bit incomplete. The only distributions used in the experimental section seem to be Gaussians and Mixture of Gaussians. Many more families of distributions are mentioned in Section 3, and it would have been nice to show some evaluation of them considering the code is already there. In addition to distributions mentioned in Section 3, it would help if there were a few larger dimensional distributions. Often for evaluation now, many papers\nuse a Deep Gaussian model trained to model MNIST digits. I worry that insights drawn from\nthe synthetic examples won't transfer when the models are applied to real-world tasks.\n\nI would like to see described a wider variety of models, including possibly more models with\ndiscrete latent variables as much recent literature is currently exploring.\n\nThe paper is a bit confusing in how it discusses distributions and models. Distributions form the ground truth we compare different trained models to.  It would been more clear for me if the explanation with supplemented with some notation to describe who will compare draws from the true data distributions to samples from each of the trained generative models.\n\n""]","[-20, -20, 50]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as a 'thorough attempt' and finds the approach 'mostly reasonable', they express 'serious concerns' about the choice of metrics and highlight several issues that make the results 'difficult to interpret'. This indicates more criticism than praise overall. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms diplomatically (e.g. 'I think there are some serious concerns' rather than stating issues as definitive facts). They also provide helpful suggestions for improvement and additional references to consider. The tone remains professional and courteous even when pointing out flaws."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential value of the proposed benchmark, they express several concerns about the presentation and methodology. The review points out multiple issues and suggests that the work lacks detailed explanations and insights. However, it's not entirely negative as the reviewer recognizes the potential benefits of the benchmark. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'It would be nicer to see' and 'The authors only used' instead of more direct criticisms. The reviewer also provides constructive feedback and references to support their points, which contributes to the polite tone. The language is not overly formal or deferential, but it remains respectful and focused on the work rather than personal attacks."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear writing, clear motivation, and potential utility of the work. However, they also point out that the work feels incomplete and suggest areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh critiques. Phrases like 'it would have been nice' and 'I would like to see' maintain a constructive tone. The reviewer also acknowledges the authors' response, indicating a respectful dialogue.""]"
"['Summary\nThe authors propose a relatively simple approach to mine noisy parallel sentences which are useful to greatly improve performance of purely unsupervised MT algorithms.\nThe method consists of a) mining documents that refer to the same topic, b) extracting from these documents parallel sentences, c) training the usual unsup MT pipeline with two additional losses, one that encourages good translation of the extracted parallel sentences and another one forcing the distribution of words to match at the document level.\n\nNovelty: the approach is novel.\n\nClarity: the paper is clearly written.\n\nEmpirical validation: The empirical validation is solid but limited. The authors could further strengthen it by testing on low-resource language pairs (En-Ro, En-Ur).\nIt would also be useful to report more stats about the retrieved sentences in tab. 1 (average length compared to ground truth, BLEU using as reference the translation of a SoA supervised MT method, etc.)\n\nQuestions\n1) Sec. 3.2 is the least clear of the paper. The notation of eq. 7 is quite unclear because of the overloading (e.g., P refers to both the model and the empirical distribution).\nI am also unclear about this constraint about matching the topic distribution: as far as I understood, the model gets only one gradient signal for the whole document. I find then surprising that the authors managed to get any significant improvement by adding this term.\nRelated to this term, how is it computed? Are documents translated on the fly as training proceeds? Could the authors provide more details?\n\n2) Have the authors considered matching sentences to any other sentence in the monolingual corpus as opposed to sentences in the comparable document?\n ', 'The major issue in this paper is that the ""new direction"" in this paper has been explored before [1]. Therefore the introduction needs to be rewritten with arguing the difference between existing methods. \n\nThe proposed method highly relies on the percentage of implicitly aligned data. I suggest the author do more experiments on different data set with a significant difference in this ""percentage"". Otherwise, we have no idea about the performance\'s sensitivity to the different datasets. \n\nMore detailed explanations are needed. For example, what do you mean by ""p(w)  as the estimated frequency""? Why do we need to remove the first principal components?\n\nSection 3.2 title is "" aligning topic distribution"" but actually it is doing word distribution alignment.\n\nDo you do normalization for P(w^Y;d_i^X,\\theta) in eq.6 which is defined on the entire vocab\'s distribution?\n\nI think the measurement of the alignment accuracy and more experiments with different settings of \\alpha and \\beta are needed.\n\nCitation needed for ""Second, many previous works suggest  that the word distribution ...""\n\n[1] Munteanu et al, ""Improving Machine Translation Performance by Exploiting Non-Parallel Corpora"", 2006', ""This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1, and the similarity between this sentence pair is c2 greater than any other pair in the documents, under sentence representations formed from word embeddings trained with MUSE. The neural translation model learns to translate from language X to Y, and from Y to X using the same encoder and decoder parameters, but the decoder is aware of the intended target language given an embedding of the intended language. The model is also trained to minimise the KL divergence between the distribution of terms in the target language document and the distribution of terms in the current model output. The model also uses the denoising autoencoding and reconstruction objectives of Lample et al. (2017). The results show improvements over the Lample et al. (2017) and that performance is heavily dependent on the number of sentences extracted from the weakly aligned documents.\n\nPositives\n- Large improvement over previous attempts at unsupervised MT for the En-De language pair.\n- Informative ablation study in Section 4.4 of the relative contribution of each part of the overall objective function (Eq 9).\n\nNegatives\n- The introduction gave the impression that this method would be applied to low-resource language pairs but it was applied to two high-resource language pairs. Because you have not evaluated on a low-resource language pair, it's not clear how your proposed method would generalise to a low-resource setting.\n\nQuestions\n- Can you give some intuition for why you remove the first principal component from the word embeddings in Equations 1 - 3?\n- Are the Supervised results in Table 2 actually a fair reflection of a reasonable NMT model trained with sub-word representations and back translated data?\n- What is the total number of sentences in the weakly paired documents in Table 1? It would be useful to know the proportion of sentences you managed to extract to train your models.\n\nComments\n- Koehn et al. (2003) is not an example of any kind of neural network architecture.""]","[60, -50, 50]","[70, 20, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its novelty, clarity, and solid empirical validation. They describe the approach as 'novel' and the paper as 'clearly written'. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement in a helpful manner, using phrases like 'The authors could further strengthen it by...' and 'It would also be useful to...'. The reviewer also poses questions in a polite way, showing engagement with the work. The language is professional and courteous, without any harsh criticism or rudeness."", ""The sentiment score is -50 because the review points out several major issues with the paper, including that the 'new direction' has been explored before, which undermines the paper's novelty claim. The reviewer also requests significant revisions and additional experiments, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer provides constructive feedback for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'I suggest' and 'More detailed explanations are needed' rather than using harsh or rude phrasing. The reviewer also provides specific recommendations for improvement, which is a courteous approach in academic reviews."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's method, followed by a balanced list of positives and negatives. The reviewer acknowledges improvements over previous attempts but also points out limitations. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions, and maintains a professional tone. The reviewer provides constructive feedback and asks clarifying questions without using harsh or dismissive language.""]"
"['This paper proposes a sequence to sequence model augmented with a multinomial latent variable. This variable can be used to generate multiple candidate translations during decoding. This approach is simpler than previous work using continuous latent variables or modifying beam search to encourage diversity, obtaining more diverse translations with a smaller drop in translation accuracy.   \n\nStrengths:\n- Simple model that succeeds in achieving its goal of generating diverse translations.\n- Provides insights into training models with categorical latent variables. \nWeaknesses:\n- More insight into what the latent variable is learning to represent would strengthen the paper. \n\nWhile the model is simple, its simplicity has significant strengths: In contrast to more complex latent space, the latent variable assignments can be enumerated explicitly, which enables it to be used to control the generation and compare outputs. The simplicity of the model will force the latent variable towards capturing diversity - modelling uncertainty in how to express the output rather than uncertainty in the content. \n\nOne question about the model architecture is just whether it is sufficient to feed the latent variable embedding only once, as it effect might be diluted across long output sequences (as opposed to, say, feeding the latent variable at each time step). \n\nThe paper provides some interesting insights, such as the need to do hard EM-style training and turning off dropout when inferring the best latent variable assignment during training, to avoid mode collapse. \n\nWhat is the effect of initialization? This often has a large impact in EM-style training, and could also lead to mode collapse, though in this case the restricted parameterization might prevent that. \n\nWhat is the training time and computational resource requirements? Are multiple DGX-1s running in parallel required to train the model?\n\nWhat is not clear enough from the paper is what kind of structure the latent variables learn to capture. In particular this model is not biassed towards any explicit notion of the kind of diversity one would like to learn. While there is some qualitative analysis, further analysis would strengthen the paper. \n\nOverall this is a very interesting contributions that offer useful insights into designing controllable sequence generation models.', 'This paper studies the diverse text generation problem, specifically on machine translation problem. The authors use a simple method, which just using a single multinomial latent variable compared with previous approaches that using multi latent variables. They named the approach: Hard-MoE. They use parallel greedy decoding to generate the diverse translations and the experiments on three WMT datasets show the approach make a trade-off between diversity and quality.\nIn general, I think generating the diverse translations for machine translation problem may not so important and piratically in actual scenarios. In fact, how to generate fluent and correct translations is more important. \n\nFor the details, there are some problems. 1) The only modification for this work is to make the soft probability of p(z|x) to be 1/K. The others are several experimental studies. To be an formal ICLR paper, this may not be interesting enough to draw my attention. 2) In case of the results, though the authors claimed they achieved better trade-off between diversity and quality, in my opinion, the beam original beam search is good enough from the results in Table 1. 3) In table 2, what means k=0 for the BLEU score? 4) I want to indicate that the purpose of VAE approach related to this work is to increase the model performance w.r.t. the BLEU score instead of the diversity, same as the original MoE method. 5) There are some related works to this work, but their methods are also very effective in terms of the BLEU score, e.g., the author can check this one in EMNLP this year: “Sequence to Sequence Mixture Model for Diverse Machine Translation”. Authors may need a more discussion between those works and this work.\n', 'The authors aim to increase diversity in machine translation using a multinomial latent variable that captures uncertainty in the target sentence. Modeling uncertainty with latent variables is of course relatively common in ML, and this work has similarities with latent variables models for MT [Zhang et al., 2016] and for other generation tasks such as dialogue [Serban et al., 2017; etc.]. The key difference is that the authors here use a Mixture of Expert (MoE) approach while most relevant prior works use variational approaches. Experiments show improvements in diversity over variational NMT [Zhang et al., 2016] and decoding-time approaches (e.g., diversity constraints [Vijayakumar et al., 2016]).\n\nOverall, the proposed approach (hard-MoE) is well motivated and the experimental results are relatively promising. I think the authors did a good job analyzing and justifying their approach against the soft version of their model (i.e., soft-MoE causes experts to “die” during training) and variational alternatives (i.e., variational approaches often have failure modes where the latent variable is effectively ignored.) \n\nHowever, I find related work a bit weak because the problem of producing diverse output has been a much bigger focus in tasks other than MT, such as dialogue and image captioning. The paper glosses over related approaches on these tasks, but the need to model uncertainty for these other tasks is much bigger since source and target are usually not semantically equivalent. So it would have been nice to see argumentative (or even empirical) comparisons with popular models such as VHRED for dialogue [Serban et al., 2017], as many of these models are not intrinsic to either MT or dialogue (the only aspect specific to dialogue in VHRED is context, but it can be set to empty and thus VHRED could have been used as a baseline in the paper.) It would be interesting to compare the work against Serban et al. [2017]’s justification for using a latent variable, which is quite different (see their bit on “shallow generation”, and the idea that their latent variable encapsulates “the high-level semantic content of of the output”).  \n\nOne technical caveat is that there appears to be some inconsistency in the comparison between human and systems in Table 1. If N is the number of references, then systems are evaluated on N references while the human “system” on only N-1 because of leave-one-out. While this difference might have less of an impact on “average oracle BLEU” than standard BLEU, having one less reference might still penalize the human “system”, and this might partially explain why “beam search’s average oracle BLEU is fairly close to human’s average oracle BLEU”. The right thing to do would be to evaluate both human and all systems in a leave-one-out approach (i.e., let references [r1 … rN] and systems [s1 … sM], then evaluate each element of [s1 … sM r1] on references [r2 … rN], etc.). In that manner, all the “systems” including human are consistently evaluated on *exactly* the same references. \n\nMinor comments: \n\n “By putting the model in evaluation mode during minimization we also speed up training and reduce memory consumption, since the K forward passes have no gradient computation or storage.” In other words, does this mean the algorithm is easy to *parallelize* because sharing parameters is often what kills the effectiveness of parallelized SGD and variants? If so, “parallelizing” is key word to mention here otherwise I don’t see how we can speed that up by increasing K.\n\nFigure 2: performance drops with K approaching 20. What happens with K=50 or 100 or more? This is a bit of a concern because (1) larger K could require a massive amount parallelization and (2) competing approaches such as VHRED can handle latent variables with higher capacities.\n\nPractical considerations subsection is too vague: parameter sharing is not formally/mathematically explained and the work could be hard to reproduce exactly (as there are often different ways to share parameters). \n\nWhy no “#ref covered” for human in Table 1, and why no comparison with Variational NMT? Zhang et al [2016] is the most talked about competing model, so it should probably be evaluated on both settings.\n\nMissed reference: Mutual Information and Diverse Decoding Improve Neural Machine Translation.\nJiwei Li, Dan Jurafsky. https://arxiv.org/abs/1601.00372', '# Summary of model \n\nThe paper proposes a mixture model formulation of NMT where the mixing coefficients are uniform and fixed. The authors then proceed to derive a lowerbound on the marginal likelihood \n\np(y|x) = \\sum_z p(z)p(y|x,z) > 1/K \\max_z p(y|x,z)\n\nby picking the component z for which the joint likelihood is maximised. With a uniform p(z) this clearly selects the z for which the conditional p(y|x,z) is maximum. I use strictly greater here because p(z) > 0 and p(y|x,z) > 0 for every z.\n\nThe loss L(\\theta|x,y) for an observation (x,y) is \\min_z - \\log p(y|z,x; \\theta)\nwhose gradient with respect to NN parameters (theta) is \\grad_theta \\log p(y|z,x; \\theta) for the component z that minimises the negative log-conditional and 0 for every other component, thus while this requires K forward passes (to solve \\min_z), it only takes 1 backwards pass.\n\n# Discussion\n\nI appreciate model-based (as opposed to search-based) attempts to improve diversity for generation tasks such as MT. Latent variable modelling aims at a more explicit account of the generative procedure, namely, the joint distribution, which can potentially disentangle and explain different modes of the marginal. Thus from that point of view, this paper points to an exciting direction. That said, in my view, the assumptions behind the proposed approach are not justifiable and some of the claims are simply not appropriate. Below I try to support this view.\n\nA stepping stone of this model is that p(y|x,z) must be ""large for only one value of z"" (as authors put it), and authors *assume* that will be the case. \n\nWhile the bound in equation (2) holds, whether or not p(y|z,x) turns out to be ""large for only one value of z"", it will be a very loose bound unless that happens. \n\nThe key point is that one cannot *assume* it to be the case. One could perhaps *promote* it to be the case, but there\'s no aspect of the model formulation (or objective) that promotes such behaviour.\n\nBackpropagating through whichever component happens to assign the largest likelihood does not guarantee (nor encourages) the other conditionals to *independently* end up going to zero. \n\nGiven the level of parameter sharing, I\'d even consider the possibility that the exact opposite happens. As authors put it themselves \n\n""Instead, by sharing parameters, even unpopular experts receive some gradients throughout training.""\n\nIt\'s true they do, but they are being updated on the basis of the unilateral opinion of the selected component about the likelihood of the data.\n\nNote that the true posterior p(z|x,y) is exactly proportional to the likelihood, as the prior is *uniform and fixed*:\n  p(z|x,y) \\propto 1/K p(y|x,z) \\propto p(y|x,z)\nThis means that the authors expect the likelihood to do component allocation on its own. That is, the conditionals p(y|x,z=1), ..., p(y|x,z=K) must somehow coordinate themselves in making good use of the latent components. Without any mechanism to promote ""competition"" (in the parlance of Jacobs et al 1991), I don\'t see how this can work.\n\nAlso, the paper claims to model uncertainty, if I take the posterior to fulfil this claim, then I\'m just left with a likelihood (again, due to uniform prior). In any case, a notion of uncertainty here would be conditioned on a point estimate of the network\'s parameters and should thus be worded carefully.\n\n# Clarifications\n\n1. ""we aim to explicitly model uncertainty during training"" can you make a case for where that happens in your model?\n\n2. ""prevents the gating from training well and the latent variable embeddings from specializing"" which gating?\n\n3. ""While they showed improvements due to the regularization effect of the Monte Carlo gradient estimate”. I find it strange to talk about the “regularisation effect” of a gradient estimate, perhaps you can be a bit more precise here? Or perhaps you are referring to some specific component of the objective function whose gradient we are estimating via MC and perhaps that component may have some regularisation effect.\n\n4. if you aim to have p(y|x,z) high for a single latent variable at a time, you are implicitly saying that every x has at most (or rather exactly) K translations with non-negligible probability. Is that sensible? \n\n# Pros/Cons\n\nPros\n\n* simple: the approach presented here requires no significant changes to otherwise standard architectures, it instead concentrates in a change of objective and training algorithm.\n* assessment of variability in translation: this paper proposes to use BLEU and a corpus of multiple references in an interesting (potentially novel) way. \n\nCons\n\n* problematic assumptions: e.g. posterior will turn out sparse without any explicit way to promote such behaviour\n* unrealistic claims: e.g. modelling uncertainty\n* imprecise use of technical language: some technical terms are not used in their strictly technical sense (e.g. uncertainty, degeneracy), some explanations employ loosely defined jargons (e.g. regularisation effect of the gradient estimate) \n']","[70, -50, 50, -50]","[80, 20, 75, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses an overall positive view of the paper, calling it a 'very interesting contribution' and highlighting several strengths. They note that the model succeeds in its goal and provides useful insights. While some weaknesses and questions are raised, these are presented constructively as opportunities for improvement rather than major flaws. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths before discussing potential improvements, and phrase their suggestions as questions or areas for further exploration rather than criticisms. The tone is collegial and supportive, aiming to improve the work rather than tear it down."", ""The sentiment score is -50 because the reviewer expresses several criticisms and doubts about the paper's importance and contributions. They state that generating diverse translations may not be very important in practical scenarios and that the paper's modifications are not interesting enough for an ICLR paper. However, it's not entirely negative as they acknowledge some positive aspects of the work.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout and uses phrases like 'I think' and 'in my opinion' to soften their criticisms. They also provide specific, constructive feedback and suggestions for improvement. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer states the approach is 'well motivated' and results are 'relatively promising', but also points out some weaknesses in related work and technical issues. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the authors' good work, and frames criticisms constructively as suggestions for improvement. The reviewer balances positive feedback with areas for enhancement, maintaining a professional and courteous tone throughout."", ""The sentiment score is -50 because while the reviewer appreciates the model-based approach and sees potential in the direction, they express significant concerns about the assumptions and claims made in the paper. The reviewer states that 'the assumptions behind the proposed approach are not justifiable and some of the claims are simply not appropriate.' They also list several cons, including 'problematic assumptions' and 'unrealistic claims.' However, the review is not entirely negative, as they do mention some pros and interesting aspects of the paper, which is why the score is not lower.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciate' and 'In my view' to soften criticism. The reviewer also provides detailed explanations for their concerns and offers specific questions for clarification, which is constructive. While the criticism is direct, it is presented in a way that focuses on the work rather than attacking the authors personally. The language used is formal and appropriate for academic discourse, avoiding any rudeness or harsh language.""]"
"['\n\nReview Summary\n--------------\nThe paper presents a combination of rule lists, prototypes, and deep representation learning to fit classifiers that are said to be simultaneously ""accurate"" and ""interpretable"". While the topic is interesting and the direction seems novel, I don\'t think the work is quite polished or competitive enough to be accepted without significant revision. The major issues include non-competitive evaluation of what ""interpretability"" means, ROC AUC numbers that are indistinguishable from standard deep learning (RCNN) pipelines that use many fewer parameters, and many unjustified choices inside the method itself. The paper itself could also benefit from revision to improve flow and introduce technical ideas to be more accessible to readers.\n\n\nPaper Summary\n-------------\nThe paper presents a new method called ""PEARL"" (Prototype Learning via Rule Lists), which produces a rule list, a set of prototypes, and a deep feed-forward neural network that can embed any input data into a low-dimensional feature space. The primary intended application is classifying subjects into a finite set of possible disorders given longitudinal electronic health records with categorical features observed at T irregular time intervals. \n\nThe paper suggests learning a representation for each subject\'s data by feeding the EHR time series into a recurrent convolutional NN. The input data is a 2 x T array, with one row representing observed data and second row giving time delay between successive observations. The vector output of an initial convolutional RNN is then fed into a highway network to produce a final vector denoted ""h"". \n\nGiven an encoder to produce feature vectors, and a fixed rule list learned from data itself, the paper suggests obtaining a prototype for each rule by computing the average vector of all data that matches the given rule. The quality of these prototypes and related neural networks (for computing features and predicting labels from features) is then assessed via their loss function in Eq. 1: a weighted combination of how well the prototypes match the learned embeddings (distance to closest prototype) and how well the classifier predicts labels.  The core idea is that the embedding is learned to classify well while creating a latent space that looks like the prototypes of the rule list.\n\nAfter training an embedding and NN classifier on a fixed rule list, it seems the data is reweighted according to some heuristic procedure to obtain better properties, then a new rule list is trained and the process repeats again. (I admit the reweight procedure\'s purpose was never clear to me).\n\nExperiments are done on a proprietary heart failure EHR dataset and on a subset of MIMIC data. \n\nStrengths\n---------\n* Seems original: I\'m unaware of any other method connecting rule lists AND prototypes AND NNs\n* Neat applications to healthcare\n\nLimitations\n-----------\n* Interpretability evaluation seems weak: no human subject experiments, no quantiative metrics, unclear if rule-lists shown is an apples-to-apples comparison\n* Prototypes themselves never evaluated \n* Many design choices inside method not justified with experiments -- why highway networks + RCNNs?\n\nMajor Issues with Method\n------------------------\n\n## M1: Not clear that AUC difference between PEARL and baselines is significant\n\nThe major issue is that the presented approach does not seem significantly different in predictive performance than the baseline Recurrent CNN. Comparing ROC AUC, we have PEARL\'s 0.688 to RCNN\'S 0.682 with stddev of 0.009 on the proprietary heart failure dataset, and PEARL\'s 0.769 to RCNN\'s 0.766 with stddev of 0.009. When AUCs match this closely, I struggle to believe one model is definitively better, especially given that the RCNN has 2x *fewer* parameters (8.4k to 18.4k). \n\nIf the counterargument is that the resulting ""deep model"" is not ""interpretable"", one should at least compare to a post-processing step where the decision boundary of the RCNN is the reference to which a rule list or decision tree is trained.\n\n## M2: Interpretability evaluation not clear.\n\nIsn\'t the maximum number of rules set in advance? \n\nAdditionally, prototypes are a key part of this work, but the learned prototypes are not evaluated at all in any figure (except to track avg. distance from prototype while training). If prototypes are so central to this work, I would like to see a formal evaluation of whether the learned prototypes are indeed better (in terms of distance, or inspection of values by an expert, or something else) than alternatives like Li et al.\n\n## M3: Missing a good synthetic/small dataset experiment\n\nNeither of the presented data tasks is particularly easy to understand for non-experts. I\'d suggest creating an additional experiment where the audience of ML readers is likely to easily grasp whether a set of rule lists is ""good"" for the problem at hand... maybe create your own synthetic task or a UCI dataset or something, or even use the stop-and-frisk crime dataset from the Angelino et al. 2018 paper. Then you can compare against just a few relevant baselines (rule lists only or prototypes only). I think a better illustrative experiment will help readers grasp differences between methods. \n\n## M4: How crucial is feature selection?\n\nIn each iteration, Algo. 1 performs feature selection before learning rules. Are any other baselines (trees, rule lists) allowed feature selection before the classifier is learned? What would happen to PEARL without feature selection? What method is used for selection? (A search of the document only has \'feature selection\' occur once, in the Alg. itself, so it seems explanation is missing).\n\n## M5: Why are multiple algorithm iterations needed?\n\nWon\'t steps 3 and 4 of Alg. 1 result in the same rules every time? It\'s not clear then why on subsequent iterations the algorithm would improve. Perhaps it\'s just the reweighting of data that causes these steps to change?\n\nMinor issues\n------------\n\n## Loss function notation confusing\n\nDoesn\'t the rule list classifier s_R take the data itself X? Not the learned embedding h(X)? Please fix or clarify Eq. 1. I think you might clarify notation by just writing yhat(h(X)) if you mean the predicted label of some example as done by your NNs. Using ""R"" makes folks think the rule list is involved.\n\n## Not clear why per-example reweighting is required\n\nNone of the experiments assess why per-example reweighting (lines 6-9 of Algo. 1) is required. Readers would like to see a comparison of performance with and without this step.\n\n## Not clear or justified when ""averaged"" prototypes are acceptable\n\nAre your ""averaged"" prototypes guaranteed to satisfy the rule they represent? Is taking the average of vectors that match a rule always guaranteed to also match the rule? I don\'t think this is necessarily true. Consider a rule that says ""if x[0] == 0 or x[1] == 0, then ___"".  Suppose the only matching vectors are x_A = [0 1] and x_B = [1 0]. The average vector is [0.5 0.5] which doesn\'t work.\n\n## Several different measures of distance used without careful justification \n\nWhy use two different distances -- Euclidean distance to assess distance to prototypes for prototype assignment, and then cosine similarity when deciding which examples to upweight or downweight? Why not just use Euclidean distance for both (appropriately transformed to a similarity)?\n\nComments on Presentation\n------------------------\nOverall I think every section of the paper needs significant revision to improve a reader\'s ability to understand main ideas. Notation could be introduced slowly (explain purpose and dimension of every variable), assumptions could be clearly stated (e.g. each individual rule can have ANDs but not ORs), and design choices justified. You might try the test of giving the paper to a colleague and having them explain back the ideas of each section to you... currently I do not believe this version passes this test.\n\nThe introduction claims that ""clinicians are often unwilling to accept algorithm recommendations without clarity as to the underlying reasoning"", but I would be careful in blindly asserting this without evidence. For a nice argument about avoiding blind assumptions about what doctor\'s will and won\'t accept, see Lipton\'s 2017 paper ""The Doctor Just Won\'t Accept That"" (https://arxiv.org/abs/1711.08037)\n\nAdditionally, the authors should clarify more precisely what definition of interpretability is needed for their applications. Is it simplicity? Is it conceptual alignment with known medical facts? Is it the ability to transparently list the rules in plain English?\n\nLine-by-line details\n--------------------\n\n## Sec. 2\n\nWhen introducing p_j, should clarify this this is one prototype vector of many.\n\nWhen defining p_j = f_j(X), can you clarify what dimensionality p_j has? Is it always the same size as each example\'s data vector x_i?\n\n\n## Sec. 3\n\nFig. 2: I don\'t find this figure very easy-to-understand. It\'s clear that after embedding raw features to a new space, the learned rules are *different*, but it\'s not clear they are *better*.  None of the illustrated rules perfectly segments the different colors, for example. I guess the point is all the red dots are within one rule? But they aren\'t alone (there are blue and orange dots too), so it\'s still not clear this would be a better classifier.\n\nFor EHR datasets, are you assuming that events are always categorical? And that outcomes ""y"" are always discrete (one-of-L) variables? Or could y be real-valued?\n\nEq. 1: You should make notation clearly indicate which terms depend on \\theta. Currently it seems that nothing is a function of \\theta.\n\nEq. 1: Do you also find the prototype set P that minimizes this objective? Or is there another way to obtain P given parameters \\theta? This is confusing just from reading the eqn.\n\nWhat size is the learned representation h(X)? Is it a vector?\n\nEq. 6: Do you really need a ""network"" to compute the distance to each of the K prototypes? Can\'t you just compute these distances directly?\n\n## Sec 4\n\n""Mac OS 1.4"" : Do you mean Mac OS version 10.4? Not clear this is relevant.\n\n4.3 Case Study: How do I read these rules? Is this rule applied only if ALL conditions are true? or if any individual one is true (""or"")? This is unclear.', 'This paper aims at tackling the lack of interpretability of deep learning models, which is especially problematic in a healthcare setting --the focus of this research paper. Specifically, the authors propose Prototype lEArning via Rule Lists (PEARL), which combines rule learning and prototype learning to achieve more accurate classification and better predictive power than either method independently and which the authors claim makes the task of interpretability simpler.  \nThe authors present an interesting and novel architecture in PEARL. Combining the two approaches of rule lists and prototype learning. However, my main concern with the paper and with the architecture in general is the lack of clarity upfront regarding what the authors perceive as the criteria for interpretability. This seems to be one of the chief aims of the paper, however, the authors don’t reach this point until Section 4 of the paper. Given that this is one of the main strengths of the paper as proposed by the authors, this needs to be given more prominence and also needs to be made more explicit what the authors mean by this. The authors define interpretability as measured by the number of rules and number of protoypes identified by a particular model, without, providing an argument, justification, or a citation of previous work which justifies these criterion. Especially since this is one of the main points of the paper, this needs to be better argued and the authors should either elaborate on this point, or restrain on making claims that these models are more interpretable.\nThe model architecture of Section 3.1 was quite obscure both from the intuitive and implementation level. It’s not clear how the different modules (prototype learning, rule lists) link together in practice, nor how these come together to create an interpretable model.\nGenerally, the paper is quite poorly structured and there were several grammatical errors which made the paper quite hard to follow. Although the problems articulated are important, the paper did not do sufficient justice to addressing these problems. \n', 'Summary: \nThis paper presents a new interpretable prediction framework which combines rule based learning, prototype learning, and NNs. The method is particularly applicable to longitudinal data. While the idea of bringing together rules, prototypes, and NNs is definitely novel, the method itself has some unclear design choices. Furthermore, the experiments seem pretty rudimentary and the presentation can be significantly improved. \n\nDetailed Comments: \n1. In Section 2, the authors seem to define rule list as a set of independent if-then rules. Please note that rule lists have an ""else if"" clause which creates a dependency between the rules. Please refer to ""Interpretable decision sets"" by Lakkaraju et. al. for understanding the differences between rule lists and rule sets. \n2. Section 3.1 is quite confusing. It would be good to give an intuition as to how the various pieces are being combined and in why it makes sense to combine them in this way. The data reweighting process seems a bit adhoc to me. What other choices for reweighting were considered?\n3. I would strongly encourage the authors to carry out at least a simple user study before claiming that the proposed method is more interpretable than existing rule lists. Adding both prototypes and rules, in fact, adds to the cognitive burden of an end user - it would be interesting to see when and how having both prototypes and rules will help an end user. \n\nPros:\n1. First approach to combine NNs, rule learning, prototype learning\n2. Provides an interpretable method for predictions on longitudinal medical data\n3. Experimental results seem to suggest that the proposed approach is resulting in accurate and interpretable models.\n\nCons:\n1. The various pieces in the method (rule learning, prototype, NNs, data reweighting) seem to be somewhat haphazardly connected. Section 3.1 does not give me a good idea about how the different pieces are resulting in an accurate and interpretable model\n2. The paper makes claims such as ""Experimental results also show the resulting interpretation\nof PEARL is simpler than the standard rule learning."" without actually doing any significant user studies. Furthermore, any other synthetic data experiments which could demonstrate the various facets of accuracy-interpretability tradeoffs are missing\n3. The presentation of the paper is quite unclear. See detailed comments above. \n']","[-50, -40, -30]","[50, 20, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, stating it is not 'polished or competitive enough to be accepted without significant revision'. They list several major issues and limitations. However, the score is not lower because the reviewer does acknowledge some strengths and the potential of the work. The politeness score is 50 because the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. They use phrases like 'I don't think' and 'I would suggest' which maintain a respectful tone. The reviewer also highlights positives like 'neat applications' and 'seems original' before diving into critiques, which is a polite approach."", ""The sentiment score is -40 because while the reviewer acknowledges the paper's interesting and novel approach, they express significant concerns about the lack of clarity, poor structure, and insufficient addressing of the main problems. The reviewer's criticisms outweigh the initial positive remarks. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'my main concern' and 'needs to be better argued' rather than harsh language. However, the critique is direct and doesn't use overly polite language, keeping the score relatively low on the positive side."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('novel idea', 'accurate and interpretable models'), they express significant concerns about the method's design, experimental rigor, and presentation clarity. The overall tone suggests more criticism than praise. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and balancing criticisms with positive points. They use polite language like 'would be good to' and 'I would strongly encourage' rather than harsh directives. The reviewer also acknowledges the paper's strengths in the 'Pros' section, demonstrating a balanced approach.""]"
"['This paper proposes a new framework for topic modeling, which consists of two main steps: generating bag of words for topics and then using RNN to decode a sequence text. \n\nPros:\nThe author draws lessons from the infoGAN and designed a creative object function with reconstruction loss and categorical loss. As a result, this paper achieved impressive outcome for topic modeling tasks.\n\nComments:\n1. High-level language is used to describe how to train two parts of the model, which is not technically clear. It would be better describe the algorithms in more details by listing steps for your algorithm in the section 3.3.\n\n2. For text generation experiments, why didn’t you compare your model with any other related model such as SeqGAN or TextGAN? It is not so convincing to just use VAE+Wgan-gp as a baseline model.\n\n3. For qualitative analysis part, you just listed some of your generated sentences for proving the fluency and relevance. Why didn’t you use some standard metrics for evaluating the quality of the text? I cannot judge the quality of your model through these randomly selected sentences.\n\n4. As you mentioned in this paper “your model can be easily combined with any current text generation models”, have you done any experiments for demonstrating the original text generation model will get better performance after applying your framework? \n\nMinor comments:\n1. On page 2 and page 4, you mentioned “the third term in (2)”. According to my understanding, this should be equation 1 instead. \n', 'This paper presents a topic model based on adversarial training. Specifically, the paper adopts the framework of InfoGAN to generates the bag-of-words of a document and the latent codes in InfoGAN correspond to the latent topics in topic modelling. In addition to the above framework, to make the model work better, several add-ons are also proposed, combining autoencoder, loss clipping, and a generative model to generate text sequences based on the bag-of-words.\n\nMy comments are as follows:\n\n1. There are several issues of this paper on clarity:\n\n(1) The first major one for me is that the authors did not give any details on how to interpret the latent code (i.e. the topics here) with the top words. In conventional topic models, usually a topic is a distribution of words, so that top words can be selected by their weights. But I did not see something similar in the proposed model.\n\n(2) Another major one is why the word sequence generator is introduced in the proposed model. I did not see the contribution of this part to the whole model as a topic model, although the joint training shows the marginal performance gain on text generation.\n\n(3) Some of the experiment settings are not provided, for example, the number of topics, the value of \\alpha and \\lambda in the proposed model, the hyperparameters of LDA, which are crucial for the results.\n\n(4) Why is the size of the bag-of-words vocabulary set to be 3K whereas that of the word generation vocabulary set to be 15K?\n\nMinor issues:\n\n(5) In the related work of InfoGAN, there are a lot of cross-references to the following sections, before they are properly introduced.\n\n(6) Typo of ""Accurcay"" in Table 4(a).\n\n2. Using adversarial training for topic models seems to be an interesting idea. There is not much work in this line and this paper proposes a model that seems to be working. But it seems to be that the proposed model has several issues as follows:\n\n(1) Each document seems to have only one topic, which can be an impractical setting for long documents.\n\n(2) The proposed model ignores the word counts, which can be important for topic modelling.\n\n(3) I did not see a major improvement of the proposed model over others, given that the only numerical result reported is classification accuracy and the state-of-the-art conventional topic models are not compared. This also leads to my concern about the experiments. I would expect more comparisons than classification accuracy, such as topic coherence and perplexity (for topic modelling) and with more advanced conventional models. From the low values of the accuracy on 20NG, I am wondering if LDA is working properly.  \n\n', 'This paper proposes TopicGAN, a generative adversarial approach to topic modeling and text generation. The model basically combines two steps: first to generate words (bag-of-words) for a topic, then second to generate the sequence of the words.\n\nWhile the idea is interesting, there are several important limitations. First, the paper is difficult to understand, and some of the explanations are not convincing. For example, in section 4.1.1, it says ""... our method assumes that the documents are produced from a single topic ... Our assumption aligns well with human intuition that most documents are generated from a single main topic."" This goes very much against the common assumption of a generative topic model, such as LDA, which the model compares against. I don\'t mean to argue either way, but if the paper presents a viewpoint which is quite different from the commonly accepted viewpoint (within the specific research field), then there needs to be a much deeper explanation, ideally with concrete evidence to support it. Another sentence from the same paragraph states that their ""model outperforms LDA because LDA is a statistical model, while our generator is a deep generative model."" This argument also seems flawed and without concrete evidence. There are other parts in the paper where the logic seems strange and without evidence, and they make it difficult to understand and accept the major claims of the paper.\n\nSecond, the model does not offer much novelty. It seems that the two-stage model simply puts the two pieces, a GAN-style generator and an LSTM sequence model together. Perhaps I am not understanding the model, but the model description was also not clear nor easy to understand with respect to its novelty.\n\nThird, the evaluation is somewhat weak. There are two main evaluations tasks: text classification and text generation. For the first task, classification is not the main purpose of topic models, and while text classification _is_ used in many topic modeling papers, it is almost always accompanied by other evaluation metrics such as held-out perplexity and topic coherence. This is because the main purpose of topic modeling is to actually infer the topics (per-topic word distribution and per-document topic distribution) and model the corpus. Thus I feel it is not a fair evaluation to just compare the models using text classification tasks. The second evaluation task of text generation is not explained enough. For the human evaluation, who were the annotators, and how were they trained? How many people annotated each output, and what was the inter-rater agreement? How many sentences were evaluated, and how were they chosen? Without these details, it is difficult to judge whether this evaluation was valid.\n\nLastly, the results are mediocre. Besides the classification task, the others do not show significant improvements over the baseline models. Perplexity (table 3) shows similar results for DBPedia and worse results (than WGAN-gp) for Gigaword. Table 4 shows slightly better results for ""Preference"" for TopicGAN with joint training, but ""Accuracy"" is measured only for the proposed model and not the baseline model. ']","[20, -40, -70]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'impressive outcome' and 'creative object function', but also provides several critical comments and suggestions for improvement. The overall tone is constructive rather than overtly negative or enthusiastic. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions ('It would be better...') and questions ('Why didn't you...?') rather than direct accusations. The reviewer also begins with positive points before moving to critiques, which is a polite approach. The language is professional and objective, avoiding personal attacks or overly harsh criticism."", ""The sentiment score is -40 because the review is generally critical, pointing out several issues with clarity and the proposed model. However, it does acknowledge some positive aspects, such as the interesting idea of using adversarial training for topic models. The politeness score is 60 because the reviewer uses respectful language throughout, framing criticisms as 'comments' and 'concerns' rather than direct attacks. The reviewer also uses phrases like 'I would expect' and 'I am wondering' which soften the critique. The review maintains a professional tone without using overly harsh language, even when pointing out significant issues."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several important limitations of the paper, including difficulty in understanding, lack of novelty, weak evaluation, and mediocre results. While the reviewer acknowledges that the idea is interesting, this is outweighed by the numerous criticisms. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'While the idea is interesting' and 'Perhaps I am not understanding the model,' which soften the criticism. However, the reviewer is also direct in their critique, which prevents the score from being higher. The reviewer provides specific examples and explanations for their criticisms, which is constructive but not overly polite.""]"
"['This paper proposes GASI to disambiguate different sense identities and learn sense representations given contextual information. \nThe main idea is to use scaled Gumbel softmax as the sense selection method instead of soft or hard attention, which is the novelty and contribution of this paper.\nIn addition, the authors proposed a new evaluation task, contextual word sense selection, which can be used to quantitatively evaluate the semantic meaningfulness of sense embeddings.\nThe proposed model achieves comparable performance on traditional word/sense intrinsic evaluation and word intrusion test as previous models, while it outperforms baselines on the proposed contextual word sense selection task.\n\nWhile the scaled Gumbel softmax is the claimed novelty, it is more like an extension of the original MUSE model (Lee and Chen, 2017), which proposed the sense selection and representation learning modules for learning sense-level embeddings.\nThe only difference between the proposed one and Lee and Chen (2017) is Gumbel softmax instead of reinforcement learning between sense selection and representation learning modules.\nTherefore, the idea from the proposed model is similar to Li and Jurafsky (2015), because the sense selection is not one-hot but a distribution.\nThe novelty of this paper is limited because the model is relatively incremental.\n\nFrom my perspective, the more influential contribution is that this paper points out the importance of evaluating sense selection capability, which is ignored by most prior work.\nTherefore, I expect to see more detailed evaluation on the selection module of the model. \nAlso, because the task of this paper is multi-sense embeddings, the traditional word similarity (without contexts) task seems unnecessary. \nMoreover, there is no error analysis about the result on the proposed contextual word sense selection task, which may shed more light on the strength and weakness of the model. \nFinally, I suggest the authors remove the word-level similarity task and try the recently released Word in Context (WiC) dataset, which is a binary classification task that determines whether the meaning of a word is different given two contexts.\nIt would be better to see that GASI performs well on this task given its better sense selection module.\n\nOverall, the contribution is somewhat incremental and the evaluation/discussion should focus more on the sense selection module. \nConsidering the issues mentioned above, I will expect better quality for an ICLR paper.', ""* Summary\n\n  This paper extends the skipgram model using one vector per sense of a word. Based on this, the paper proposes two models for training sense embeddings: One where the word senses are marginalized out with attention over the senses, and the second where only the sense with highest value of attention contributes to the loss. For the latter case, the paper uses a variant of Gumbel softmax for training. The paper shows evaluations on benchmark datasets that shows that the Gumbel softmax based method is competitive or better than other methods. Via a crowdsourced evaluation, the paper shows that the method also produces human interpretable clusters.\n\n* Review\n  This paper is generally well written and presents a plausible solution for the problem of discovering senses in an unsupervised fashion.\n  \n  If \\beta=0, then we get SASI, right? How well does this perform on the non-contextual word similarity task? Also, on the crowd sourced evaluation? The motivation for the hard attention/Gumbel softmax is to learn sense representations that are distinguishable. But do the experiments test this? \n\n  There's something strange about Eq 6. If I understand this correctly, \\tilde{c_i} is the context and c_j^i is the j^th context word. Then P(c_j^i | w, \\tilde{c_i}) should be 1 because the context is given, right? While the motivation for the right hand side makes sense, the notation could use work.\n  \n  The description of how the number of senses is pruned in section 3.1 seems to be a bit of a non sequitur. It is not clear whether this is used in the experiments and if so, how it compares. The appendix gives more details, but it seems a bit out of place even then because the evaluations don't seem to use it.\n\n\n* Minor comments\n  There are some places where the writing could be cleaned up.\n  - Eq 16 changes the notation for the sense embeddings and the context words from earlier, say Eq 12.\n  - Parenthetical citations would be more appropriate in some places Eg: above Eq 3, in footnote 3\n  - Page 6, above 6.2: Figure-Figure?\n  - Page 9, Agreement paragraph: hight -> highest\n"", 'The paper presents a method for deriving multi sense word embeddings. The key idea behind this method is to learn a sense embedding tensor using a skip-gram style training objective. The objective defines the probability of contexts marginalised over latent sense embeddings. The paper uses Gumbel-softmax reparametrization trick to approximate sampling from the discrete sense distributions. The method also uses a separate hyperparameter to help scale the dot product appropriately. \n\nStrengths:\n\n1. The technique is a well-motivated solution for a hard problem that builds on the skip-gram model for learning word embeddings.\n2. A new manual evaluation approach for comparing sense induction approaches.\n3. The empirical advance while relatively modest appears to be significant since the technique seems to yield better results than multiple baselines across a range of tasks. \n\nSuggestions:\n\n1. The number of senses is fixed to three. This is a bit arbitrary, even though it is following some precedence. I like the information in the appendix that shows how to handle cases when there are duplicate senses induced for words that dont have many senses. It would be useful to know how to handle the cases where a word can have more than three senses. Given that the authors have a way of pruning duplicate senses, it would have been interesting to try a few basic methods that select the number of senses per word dynamically. \n\n2. The evaluation includes word similarity task and crowdsourcing for sense intrusion and sense selection. These provide a measure of intrinsic quality of the sense based embeddings. However, as Li and Jurafsky (2015) point out, typically applications use more powerful models that use a wide context. It is not clear how these improvements to sense embeddings will translate in these settings. It would have been useful to have at least one or two end applications to illustrate this. \n\n\n3. Given that the empirical gains are not quite consistent, I would encourage the authors to specifically argue why this particular method should be favoured over other existing methods. The related work discussion merely highlights methodological differences. For example, the contrast with Lee and Chen (2017) seems to be only that of differentiability. Is the claim that differentiability is desirable because this allows for fine tuning in applications? If this is the case then it will be nice to have this verified. \n\n4. The lower bound on the log likelihood objective is good but what are we supposed to take away from it? Is it that there is an interpretation that allows us to get away with negative sampling? \n\nOverall I like the paper. It presents an application of the Gumbel-softmax trick for sense embeddings induction and shows some empirical evidence for the usefulness of this idea, including some manual evaluation. \n\nI think the evaluation could be strengthened with some end applications and much crisper arguments on why the method is preferable over other methods that achieve comparable performance.\n\nReferences:\n\n[Li and Jurafsky., EMNLP 2015] Do Multi-Sense Embeddings Improve Natural Language Understanding?\n\n\n']","[-30, 50, 60]","[20, 70, 80]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., proposing a new evaluation task and achieving comparable performance on traditional evaluations), they express significant concerns about the novelty and contribution of the work. The reviewer states that the contribution is 'somewhat incremental' and that they 'expect better quality for an ICLR paper.' These criticisms outweigh the positive elements, resulting in a slightly negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and acknowledging the paper's strengths. However, the criticism is direct and unambiguous, which prevents the score from being higher. The reviewer uses phrases like 'I suggest' and 'It would be better to see,' which contribute to the polite tone while still clearly communicating the paper's shortcomings."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating the paper is 'generally well written and presents a plausible solution,' which indicates a positive view. However, they also raise several questions and point out areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions or questions rather than harsh criticisms. They also acknowledge the paper's strengths before diving into areas for improvement. The use of phrases like 'could use work' and 'could be cleaned up' instead of more negative alternatives contributes to the polite tone. The reviewer also provides specific, helpful feedback for improvement, which is a polite way to critique."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, noting its strengths and stating 'Overall I like the paper.' However, it's not extremely positive as the reviewer also provides several suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'suggestions' rather than demands. The reviewer also uses phrases like 'I would encourage' and 'It would be useful,' which are polite ways of offering feedback. The tone is consistently professional and constructive, without any rudeness or harsh criticism.""]"
"['This work proposes to train an RL-based agent to simultaneously learn Embodied Question Answering and Semantic Goal Navigation on the ViZDoom dataset. The proposed model incorporates visual attention over the input frames, and also further supervises the attention mechanism by incorporating an auxiliary task for detecting objects and attributes.\n\nPros:\n-Paper was easy to follow and well motivated\n-Design choices were extensively tested via ablation\n-Results demonstrate successful transfer between SGN, EQA, and the auxiliary detection task\n\nCons:\n-With the exception of the 2nd round of feature gating in equation (3), I fail to see how the proposed gating -> spatial attention scheme is any different from the common inner-product based spatial attention used in a large number of prior works, including  [1], [2], and [3] and many more.\n-The use of attribute and object recognition as an auxiliary task for zero-shot transfer has been previously explored in [3]\n\n\nOverall, while I like the results demonstrating successful inductive transfer across tasks, I did not find the ideas presented in this work to be sufficiently novel or new.\n\n[1] Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering, Huijuan Xu, Kate Saenko\n[2] Drew A. Hudson, Christopher D. Manning, Compositional Attention Networks for Machine Reasoning\n[3] Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks, Tanmay Gupta, Kevin Shih, Saurabh Singh, Derek Hoiem', 'The authors propose a multitask model using a novel “dual-attention” unit for embodied question answering (EQA) and semantic goal navigation (SGN) in the virtual game environment ViZDoom. They outperform a number of baseline models originally developed for EQA and SGN (but trained and evaluated in this multitask paradigm).\n\nComments and questions on the model and evaluation follow.\n\n1. Zero-shot transfer claim:\n1a. This is not really zero-shot transfer, is it? You need to derive object detectors for the meanings of the novel words (“red” and “pillar” from the example in the paper). It seems like this behavior is supported directly in the structure of the model, which is great — but I don’t think it can be called “zero-shot” inference. Let me know if I’ve misunderstood!\n1b. Why is this evaluated only for SGN and not for EQA?\n\n2. Dual attention module:\n2a. The gated attention model only makes sense for inputs in which objects or properties (the things picked out by convolutional filters) are cued by single words. Are there examples in the dataset where this constraint hold (e.g. negated properties like “not red”)? How does the model do? (How do you expect to scale this model to more naturalistic datasets with this strong constraint?)\n2b. A critical claim of the paper is that the model learns to “align the words in both the tasks and transfer knowledge across tasks.” (Earlier in the paper, the claim is that “This forces the convolutional network to encode all the information required with respect to a certain word in the corresponding output channel.”) I was expecting you would show some gated-attention visualizations (not spatial-attention visualizations, which are downstream) to back up this claim. Can you show me visualizations of the gated-attention weights (especially when trained on the No-Aux task) which demonstrate that words and objects/properties in the images have been properly aligned? Show that e.g. the filter at index i only picks out objects/properties cued by word i?\n\n3. Auxiliary objective: it seems like this objective solves most of the language understanding problem relevant in this task. Can you motivate why it is necessary? What is missing in the No-Aux condition, exactly? Is it just an issue with PPO optimization? Can you do error analysis on No-Aux to motivate the use of the Aux task?\n\n4. Minor notes:\n4a. In appendix A, the action is labeled “Turn Left” but the frames seem to suggest that the agent is turning right.\n4b. How are the shaded regions estimated in figs. 7, 8? They are barely visible — are your models indeed that consistent across training runs? (This isn’t what I’d expect from an RL model! This is true even for No-Aux..?)\n4c. Can you make it clear (via bolding or coloring, perhaps) which words are out-of-vocabulary in Table 3? (I assume “largest” and “smallest” aren’t OOV, for example?)\n', 'The system is explained thoroughly, and with the help of nice looking graphics the network architecture and its function is clearly described. The paper validates the results against baselines and shows clearly the benefit of double  domain learning. The paper is carefully written and  follows the steps required for good scientific work.\n\nPersonally, I do not find this particularly original, even with the addition of the zero-shot learning component. \n\nAs a side note, the task here does not seem to need a multitask solution. Adding the text input as subtitles to the video gives essentially the same information that is used in the setup. The resulting inclusion of text could utilise the image attention models in a similar manner as the GRU is used in the manuscript for the text. In this case the problem stated in the could be mapped  to a ""DeepMind Atari"" type of RL solution, with text as a natural component, but added as visual clue to the game play. Hence, I am not convinced that the dual attention unit is essential to the performance the system.\n\nIn addition, there are studies (https://arxiv.org/abs/1804.03160) where sound and video are , in unsupervised manner, correlated together. This contains analogous dual attention structure as the manuscript describes, but without reinforcement learning component.\n\nI would recommend this as a poster.\n']","[-20, 20, -20]","[60, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they ultimately conclude that the work lacks sufficient novelty. The final statement 'I did not find the ideas presented in this work to be sufficiently novel or new' indicates an overall negative assessment. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, acknowledging positive aspects before critiquing, and frames criticisms constructively (e.g. 'I fail to see how...' rather than stating the authors are wrong). The reviewer also provides specific references to support their critiques, which is a polite and professional approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' novel approach and its performance improvements over baselines. However, the bulk of the review consists of critical questions and suggestions for improvement, indicating a mixed but generally constructive sentiment. The politeness score is high (80) due to the reviewer's use of respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'Let me know if I've misunderstood!' and 'Can you show me...' demonstrate a polite and collaborative tone. The reviewer also uses hedging language like 'it seems like' to soften potential criticisms. Overall, the review maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the thorough explanation and clear description of the system, they express doubts about its originality and necessity. The reviewer states 'Personally, I do not find this particularly original' and questions the essential nature of the dual attention unit. However, the score is not deeply negative as the reviewer does recognize some positive aspects of the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'The paper validates the results' and 'The paper is carefully written', showing respect for the authors' work. Even when expressing doubts, the language remains professional and constructive, avoiding harsh or rude phrasing.""]"
"['This paper formulates a new deep method called deep abstaining classifer. Their main idea is to introduce a new modified loss function that utilizes an absention output allowing the DNN to learn when abstention is a better option. The core idea resemble KWIK framework [1], which has been theoretical justified.\n\nPros:\n\n1. The authors find a new direction for learning with noisy labels. Based on Eq. (1) (the modified loss), the propose \\alpha auto-tuning algorithm, which is relatively novel. \n\n2. The authors perform numerical experiments to demonstrate the efficacy of their framework. And their experimental result support their previous claims.\nFor example, they conduct experiments on CIFAR-10 and CIFAR-100. Besides, they conduct experiments on open-world detection dataset.\n\nCons:\n\nWe have three questions in the following.\n\n1. Clarity: in Section 3, the author claim real-world data is corrupted in some non-arbitrary manner. However, in practice, it is really hard to reason the corrpution procedure for agnostic noisy dataset like Clothing1M [2]. The authors are encouraged to explain this point more.\n\n2. Related works: In deep learning with noisy labels, there are three main directions, including small-loss trick [3], estimating noise transition matrix [4,5], and explicit and implicit regularization [6]. I would appreciate if the authors can survey and compare more baselines in their paper.\n\n3. Experiment: \n3.1 Baselines: For noisy labels, the author should compare with [7] directly, which is highly related to your work. Namely, designing new loss function can overcome the issue of noisy labels. Without this comparison, the reported result has less impact. Moreover, the authors should add MentorNet [2] as a baseline https://github.com/google/mentornet\n\n3.2 Datasets: For datasets, I think the author should first compare their methods on symmetric and aysmmetric noisy data. Besides, the authors are encouraged to conduct 1 NLP dataset.\n\nReferences:\n\n[1] L. Li, M. Littman, and T. Walsh. Knows what it knows: a framework for self-aware learning. In ICML, 2008.\n\n[2] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning from massive noisy labeled data for image classification. In CVPR, 2015.\n\n[3] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n\n[4] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n\n[5] J. Goldberger and E. Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In ICLR, 2017.\n\n[6] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n\n[7] Z. Zhang and M. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In NIPS, 2018.', 'This manuscript introduces deep abstaining classifiers (DAC) which modifies the multiclass cross-entropy loss with an abstention loss, which is then applied to perturbed image classification tasks.  The authors report improved classification performance at a number of tasks.\n\nQuality\n+ The formulation, while simple, appears justified, and the authors provide guidance on setting/auto-tuning the hyperparameter.\n+ Several different settings were used to demonstrate their modification.\n- There are no comparisons against other rejection/abstention classifiers or approaches.  Post-learning calibration and abstaining on scores that represent uncertainty are mentioned and it would strengthen the argument of the paper since this is probably the most straightforward altnerative approach, i.e., learn a NN, calibrate predictions, have it abstain where uncertain.\n- The comparison against the baseline NN should also include the performance of the baseline NN on the samples where DAC chose not to abstain, so that accuracies between NN and DAC are comparable. E.g. in Table 1, (74.81, coverage 1.000) and (80.09, coverage 0.895) have accuracies based on different test sets (partially overlapping).\n- The last set of experiments adds smudging to the out-of-set (open set) classification tasks.  It is somewhat unclear why smudging needs to be combined with this task.\n\nClarity\n- The paper could be better organized with additional signposting to guide the reader. \n\nOriginality\n+ Material is original to my knowledge.\n\nSignificance\n+ The method does appear to work reasonably and the authors provide detail in several use cases.\n- However, there are no direct comparison against other abstainers and the perturbations are somewhat artificial.', 'The paper introduces a new loss function for training a deep neural network which can abstain.\nThe paper was easy to read, and they had thorough experiments and looked at their model performance in different angles (in existence of structured noise, in existence of unstructured noise and open world detection).  However, I think this paper has some issues which are listed below:\n\n\n1)  Although there are very few works regarding abstaining in DNN, I would like to see what the paper offers that is not addressed by the existing literature. Right now, in the experiment, there is no comparison to the previous work, and in the introduction, the difference is not clear. I think having an extra related work section regarding comparison would be useful.\n\n2) The experiment section was thorough, and the authors look at the performance of DAC at different angles; however, as far as I understand one of the significant contributions of the paper is to define abstain class during training instead of post-processing (e.g., abstaining on all examples where the network has low confidence). Therefore, I would like to see a better comparison to a network that has soft-max score cut-off rather than plain DNN. In figure 1-d the comparison is not clear since you did not report the coverage. I think it would be great if you can compare either with related work or tune a softmax-score on a validation set and then compare with your method. \n\n3) There are some typos, misuse of \\citet instead of \\citep spacing between parenthesis; especially in figures, texts overlap, the spacing is not correct, some figures don’t have a caption, etc.\n']","[50, 20, 20]","[70, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty and experimental support for its claims, but also raises several questions and suggests improvements. This indicates a balanced view with a slight positive lean. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions (e.g., 'The authors are encouraged to...'), and acknowledges the paper's strengths before discussing areas for improvement. The reviewer also provides helpful references, which is a courteous gesture. However, it's not extremely polite as it maintains a professional, somewhat detached tone rather than being overtly praising or deferential."", 'The sentiment score is slightly positive (20) because the review acknowledges several positive aspects of the manuscript, such as the justified formulation, demonstration in different settings, and originality. However, it also points out significant limitations, like lack of comparisons with other approaches and unclear organization. The overall tone suggests cautious approval with room for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout, balancing positive and negative points without using harsh language. They offer constructive criticism and suggestions for improvement rather than outright dismissal of the work.', ""The sentiment score is slightly positive (20) because the reviewer starts with positive comments about the paper being easy to read and having thorough experiments. However, they also mention 'some issues' which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I would like to see' and 'I think it would be great if' which maintain a polite tone while providing feedback. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to giving feedback.""]"
"['This paper analyzes the limitation of probability density distillation with reverse KL divergence, and proposes two practical methods for probability distillation.\n\nDetailed comments:\n\n1) Typo: should be WaveNet, not Wavenet.\n\n2) In Proposition 1. $c_i$ should be $\\rho_i$.\n\n3) One may explain “path derivative” with more details. Also, I am really confused by Proposition 1 and its underlying implication. Given p_s and p_t are centered at the origin, isn’t p_s(x) already the optimal if it’s just a unit Gaussian. Why do we need a derivative pointing away from the origin? At least, one need parameterize p_s as N(0, \\phi)?\n\n4) In section 3.2, “set $\\mu = [2, 2]^T$”? Isn’t $\\mu$ a T dimensional vector?\n\n5) A lot of important details are missing in neural vocoder experiment. For x-reconstruction, do you use L1 or L2 loss?  For student model, do you use Gaussian IAF with WaveNet architecture as in ClariNet, or Logistic IAF as in Parallel WaveNet? Following this question, do you compute KLD in closed-form? Do you use the regularization term introduced in ClariNet? Student with KL loss and power loss outperforms x-reconstruction. Did you try x-reconstruction along with power loss?\n\nPros:\nCertainly, there are some interesting ideas in this paper. \n\nCons:\nThe experiment results are not good enough. The paper is poorly written. A lot of important details are missing.  \n\nHowever, I would like to raise my rating to 6, if these comments can be properly addressed.\n', 'The paper studies the problem of distilling a student probabilistic model (that\nis easy to sample from) from a complex teacher model (for which sampling is\nslow).  The authors identify a technical issue with a recent distillation\ntechnique, namely that positive gradient signals become increasingly unlikely\nas the dimensionality of the teacher model increases.  They then propose two\nalternative technique that sidestep this issue.\n\nThe topic is definitely relevant.  The paper focus on a single method for\nprobability distillation, which limits the significance of the contribution.\n\nThe paper is very well written and well structured.  Section 4 is may be a bit\ntoo dense for the uninitiated; it may make sense to clarify that calT and calS\nrefer to the teacher and student models---it is only obvious while reading this\nsection for the second time around.\n\nAll contributions seem novel.  The fact that the (reverse) KL can lead to bad\nmodels is known; the issue identified in this paper, however, seems novel.\n\nI could not spot any major flaws with the paper.\n\nThe evaluation is satisfactory.  The issue of KL-based training is very clear,\nas is the advantage of the encoder-decoder alternatives.\n\nI especially appreciated the link between distillation and encoder-decoder\narchitectures.\n\nDetailed comments:\n\n1 - How widespread is the issue identified in this paper?  In other words, is\nreverse KL realistically used in applications other than probability\ndistillation?\n\n2 - It is unclear to me why Proposition 2 is important.  This should be\nexplicitly stated.\n\n3 - It would make sense to add a forward pointer to Figure 3c in Section 3.1,\nto provide another example of mode-seeking.', 'This paper proposes new methods for distilling a feed-forward generative model (student) from an autoregressive generative model (teacher) as an alternative to the reverse-KL divergence. The first part of the paper analyses optimization issues with the reverse KL divergence while in the second part of the paper alternatives are proposed (x-reconstruction and z-reconstruction).\n\nDetailed comments:\n\n1.\nIn abstract and other places: ""sparse gradient signal from the teacher"".\nSparsity implies that many of the values are exactly zero, while Section 3.1 seems to imply that some of the values might be small (or pointing towards the origin).\n\n2.\nIn Section 3.1 and 3.2 the authors discuss a potential failure mode of the reverse KL:\n\nBut, proposition 1 boils down to the fact that if the student\'s mass is more spread out than the teacher is some direction, that it should shrink that mass closer to zero as well.\n\nIn the example of the paper: if an eigenvalue of T is smaller than 1, it would mean that the student which is spherical Gaussian, would adjust its probability mass to also be smaller in that eigenvector\'s direction.\n\nAs training progresses, the students mass would be much closer to the teacher and the probability of \'pointing away\' from the origin would be about as likely as pointing towards.\n\nSo it\'s not clear at all that the described property is problematic for optimization, as it could as well be interpreted as the student trying to fit the teacher\'s distribution better.\n\n3.\nWas the KL between P_S(x_i | z_<i) and P_T(x_i | x_<i) computed analytically? If these conditional distributions are Gaussian (which they are in many of the examples) this should be trivial.\n\n4.\nSection 4 about the neural vocoder needs to be expanded: many details are missing here and although it\'s one of the more important experiments in the paper it\'s relatively neglected compared to the other parts of the paper.\n\n5.\nIn the Section 4: the experiment with reverse-KL is a straw man comparison: For audio the reverse KL was only proposed in combination with the power loss (Oord et al). Two additional experiments would make the result a lot stronger: KL+power-loss and X-recon+power-loss. Because if the x-recon method does not work well together with the power-loss, its practical applicability seems limited.\n\n\nThe proposed methods are interesting, because they are elegant and seems to work reasonably well on the tasks tried. The first part of the paper about gradient sparsity/orientation needs to be addressed. Section 4 should be expanded and an additional comparison should be made.\n\nI would change my rating if these issues were addressed.\n']","[-20, 60, -20]","[40, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges 'some interesting ideas' in the paper, they also point out several issues such as missing details, poor writing, and unsatisfactory experimental results. The overall tone suggests more criticism than praise, but it's not entirely negative as the reviewer offers to raise their rating if concerns are addressed. The politeness score is moderately positive (40) as the reviewer uses professional language throughout, offers constructive criticism, and even suggests a way for the authors to improve their rating. The reviewer points out issues directly but without harsh language, maintaining a respectful tone while providing detailed feedback."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the relevance of the topic, praises the paper's writing and structure, and appreciates certain aspects of the work. They state that they 'could not spot any major flaws' and find the evaluation 'satisfactory.' However, they also mention that the focus on a single method limits the significance of the contribution, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'I especially appreciated' and offer specific, helpful suggestions for improvement without harsh criticism. The reviewer also balances positive comments with areas for clarification, maintaining a professional and courteous approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed methods as 'interesting' and 'elegant', they also point out several issues that need to be addressed. The reviewer states they would change their rating if these issues were addressed, implying the current rating is not positive. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the strengths of the paper. They provide detailed comments and suggestions for improvement without using harsh or dismissive language. The tone is professional and aimed at helping the authors improve their work.""]"
"['The paper proposes a feature smoothing technique, which generates virtual data points by interpolating the input space of two randomly sampled examples. The aim is to generate virtual training data points that are close to adversarial examples. Experimental results on both MNIST and Cifar10 datasets show that the proposed method augmented with other regularization techniques are robust to adversarial attacks and obtain higher accuracy when comparing with some testing baselines. Also, the paper presents some theoretical analyses showing that label smoothing, logit squeezing, weight decay, Mixup and feature smoothing all produce small estimated variance of the decision boundary when regularizing the networks. \n\nThe paper is generally well written, and the experiments show promising results. Nevertheless, the proposed method is not very novel, and the method is not comprehensively evaluated with experiments.\n\nMajor remarks:\n\n1.\tThe experiments show that feature smoothing has to combine with other regularizers in order to outperform other testing methods. In this sense the contribution of the feature smoothing along is not clear. For example, without integrating other regularizers, Mixup and feature smoothing obtain very close results for BlackBox-PGD, BlackBoxcw and Clean, as shown in Table 1. In addition, in the paper, the feature smoothing along is only validated on the MNIST (not even tested on Cifar10 in Table2). Consequently, it is difficult to evaluate the contribution of the proposed smoothing technique. \n2.\tExperiments are conducted on datasets MNIST and Cifar10 with small number of target classes. Empirically, it would be useful to see how it performs on more complex data set such as Cifar100 or ImageNet.\n3.\tThe argument for why the proposed feature smoothing method works is presented in Theorem4.3 in Section 4.2, but the theorem seems to rely on the assumption that one can add data around the true decision boundary. However, how we can generate samples near the true decision boundary and how we should chose the mixing ratio to attain this goal is not clear to me in the paper. In addition, how we can sure that the adding synthetic data from one class does not collide with manifolds of other classes as suggested in AdaMixup (Guo et al., MixUp as Locally Linear Out-Of-Manifold Regularization)? This is particular relevant if the proposed feature smoothing strategy prefers to create virtual samples close to the true decision boundary.\n4.\tAt the end of page4, the authors claim that both feature smoothing and Mixup generate new data points that are closer to the true boundary. I wonder if the authors could further justify or show that either theoretically or experimentally. \n5.\tThe proposed method is similar to SMOTE (Chawla et al., SMOTE: Synthetic Minority Over-sampling Technique). In this sense, comparison with SMOTE would be very beneficial.\n\nMinor remarks:\n\n1.\tIn the paper Mixup, value 1 was carefully chosen as the mixing policy Alpha for Cifar10 (otherwise, underfitting can easily occur as shown in AdaMixUp), and it seems in the paper the authors used a very large value of 8 for Mixup’s Beta distribution, and I did not see the justification for that number in the paper.\n2.\tTypo in the second paragraph of page2: SHNV should be SVHN\n', 'The authors proposed a feature smoothing method without adding any computational burden for defensing against adversarial examples. The idea is that both feature smoothing and Gaussian noise can help extend the range of data. Moreover, the authors combined these methods together to gain a better test and adversarial accuracy. They further proved 3 theorems to try to analyze the biases and variances of decision boundary based on the fisher information and delta method.  \n\nIn my opinion, the main contribution of this paper is to prove that the boundary variance will decrease due to adding one additional regularization term to the loss function. \n\nMain comments:\n1.\tThe proposed feature smoothing method seems less novel to me. In contrast to the mixup method, the proposed method appears to remove the label smoothing part, so it is better to explain or justify why this could be better theoretically.  Moreover, in the PGD and PGD-cw results, the performance is not as good as the Gaussian random noise method. Can the authors offer any discussion or comments on the possible reasons?\n2.\tSome details of the proof of Theorem 4.1 seemed to be omitted. I am a bit confused about this. \na.\t“Without loss of generality, we further assume b = 0 and w > 0.”  With smaller magnitude, b=0 is reasonable, but why to assume w>0?\nb.\tCould you present the derivation details or the backing theory of the approximation of var(b), when one more regularization term are added?  \n3.\tIn addition, a method of modifying the network is proposed to adapt to the feature smoothing method. However, no experimental results are reported to support its effectiveness. I would believe some empirical evaluations may further strengthen the paper.\n', 'In this paper the authors introduce a novel method to defend against adversarial attacks that they call feature smoothing. The authors then discuss feature smoothing and related “cheap” data augmentation-based defenses against adversarial attacks in a nice general discussion. Next, the authors present empirical data comparing and contrasting the different methods they introduce as a means of constructing models that are robust to adversarial examples on MNIST and CIFAR10. The authors close by attempting to theoretically motivate their strategy in terms of reducing variance of the decision boundary.\n\nOverall, I found this paper pleasant to read. However, it is unclear to me exactly how novel its contributions are. As discussed by the authors, there are strong similarities between feature smoothing and mixup although I did enjoy the unifying exposition presented in the text. It also seems as though the paper suffers from some simplifying assumptions considered by the authors. For example, in sec. 2 the authors claim that \\tilde x will be closer to the decision boundary than x. However, this is only true if the decision boundary is convex. \n\nI appreciated the extensive experiments run by the authors. However, I wish they had included results from adversarial training. It seems (looking at Madry’s paper) that the defense offered by these cheap methods is still significantly worse than adversarial training. I feel that some discussion of this is warranted even if the goal is to reduce computational complexity.\n\nFinally, I am not sure what to make of the theory presented. While it is nice to see that the variance of the decision boundary is reduced by regularization in the case of 1-dimensional linear regression, I am not at all convinced by the authors generalization to neural networks. In particular, their discussion seems to only hold for one-hidden-layer networks. Although the authors don’t offer much clarity here. For example eq. 2 is literally just a statement that ReLU is a convex function. However, it is clearly the case that multiple layers of the network will violate this hypothesis. Overall, I did not find this discussion particularly compelling. ']","[-20, -20, -20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'promising results'), they express several major concerns about the novelty, comprehensiveness of evaluation, and clarity of the method's contribution. The overall tone suggests that significant improvements are needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before critiques, and phrases concerns as suggestions or questions rather than direct criticisms. They use polite phrases like 'I wonder if the authors could' and 'it would be useful to see', maintaining a constructive tone even when pointing out issues."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some contributions of the paper, they express several concerns and criticisms. The reviewer points out that the proposed method seems 'less novel' and performs worse than existing methods in some cases. They also note omissions in the proof and lack of experimental results for a proposed modification. These criticisms outweigh the initial positive remarks about the paper's contributions.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They frame their criticisms as questions or suggestions rather than direct attacks. Phrases like 'In my opinion,' 'Can the authors offer any discussion,' and 'I would believe' soften the critique. The reviewer also acknowledges the paper's contributions before diving into criticisms, which is a polite approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer found the paper 'pleasant to read' and appreciated certain aspects, they expressed several concerns about the novelty of contributions, simplifying assumptions, and the theoretical discussion. The reviewer also pointed out that the defense offered is 'significantly worse than adversarial training'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects ('I found this paper pleasant to read', 'I appreciated the extensive experiments') while offering constructive criticism. The reviewer maintains a professional tone, avoiding harsh language even when expressing concerns, which contributes to the polite nature of the review.""]"
"['The authors propose to use k-DPP to select a set of diverse parameters and use them to search for a good a hyperparameter setting. \n\nThis paper covers the related work nicely, with details on both closed loop and open loop methods. The rest of the paper are also clearly written. However, I have some concerns about the proposed method.\n- It is not clear how to define the kernel, the feature function and the quality function for the proposed method. The choices of those seem to have a huge impact on the performance. How was those functions decided and how sensitive is the result to hyperparameters of those functions?\n- If the search space is continuous, what is the mixing rate of Alg. 2? In practice, how is ""mixed"" decided? What exactly is the space and time complexity? I\'m not sure where k log(N) comes from in page 7.  \n- Alg. 2 is a straight forward extension of Alg. 1, just with L not explicitly computed. I think it would have more novelty if some theoretical analyses can be shown on the mixing rate and how good this optimization algorithm is. \n\nOther small things:\n- citation format problems in, for example, Sec. 4.1. It should be \\citep instead of \\cite. \n- it would be good to mention Figure 2 in the text first before showing it. \n\n[Post rebuttal]\nI would like to thank the authors for their clarifications. However, I am still concerned with the novelty. The absence of provable mixing rate is also a potential weakness. I think a clearer emphasis on the novelty, e.g. current algorithm with mixing rate analyses or more thorough empirical comparisons will make the paper stronger for resubmission.', '- This paper proposes an approach to get samples with high dispersion for hyperparameter optimisation. \n- It theoretically motivates the use of Determinantal Point Processes in yielding such samples.\n- Further, an iterative mixing algorithm is proposed to handle continuous and discrete sample space.\n- Experiments on finding hyperparameter for sentence classification are presented. In terms of accuracy, it performs better than other open-loop methods. In comparison to closed-loop methods, it yields parameter settings with comparable performance but with gains in wall clock time.\n- The distinction from close-loop approaches makes it easy to parallelise.\n\n\nThis paper is novel in its modelling of hyperparameter optimisation with DPP and the theoretical justification and experiments have been clearly presented. It would be interesting to explore the practicability of the method on more large-scale experiments on image related tasks.\n\n', 'I reviewed the same paper last year. I am appending a few lines based on the changes made by authors.\n\nThe authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al. (2011). The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new, so the main contribution here is the empirical study. \n\nThe first experiment by the authors shows that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner (Fig. 1).\n\nThe second experiment shows surprisingly that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Fig. 2, column 1).\n\nThe third experiment shows that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.\n\nI have a few reservations. First, I do not find these outcomes very surprising or informative, except for the second experiment (Fig. 2, column 1). Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20. The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al. (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al. (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study.\n\nCOMMENTS ON THE CHANGES SINCE THE LAST YEAR\n\nI am not convinced by the comparison with Spearmint added by the authors since the previous version. It is unclear to me if the comparison of wall clock time and accuracy holds for larger number of hyperparameters or against Spearmint with more parallelization.\n\nIn addition the authors do not compare against more recent work, e.g., \n\n@INPROCEEDINGS{falkner-bayesopt17,\n author    = {S. Falkner and A. Klein and F. Hutter},\n title     = {Combining Hyperband and Bayesian Optimization},\n booktitle = {NIPS 2017 Bayesian Optimization Workshop},\n year      = {2017},\n month     = dec,\n}\n\n@InProceedings{falkner-icml-18,\n  title =        {{BOHB}: Robust and Efficient Hyperparameter Optimization at Scale},\n  author =       {Falkner, Stefan and Klein, Aaron and Hutter, Frank},\n  booktitle =    {Proceedings of the 35th International Conference on Machine Learning (ICML 2018)},\n  pages =        {1436--1445},\n  year =         {2018},\n  month =        jul,\n}']","[-20, 80, -30]","[60, 70, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('covers the related work nicely', 'clearly written'), they express several concerns about the proposed method and its novelty. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and thanks the authors for their clarifications. They provide specific suggestions for improvement without using harsh or dismissive language. The reviewer maintains a professional tone while clearly communicating their concerns."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, noting its novelty, clear presentation, and good performance. The reviewer states that the paper is 'novel in its modelling' and that the 'theoretical justification and experiments have been clearly presented.' The only slight criticism is a suggestion for future work, which is framed positively as an interesting exploration. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths without using overly effusive praise. The suggestion for future work is presented as an interesting possibility rather than a demand or criticism. The overall tone is constructive and encouraging, maintaining a polite and professional demeanor typical of academic peer reviews."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'k-DPP-RBF performs better than uniform random search'), they express several reservations and criticisms. The reviewer points out limitations in the study's scope, lack of comparison with recent relevant work, and skepticism about the added comparison with Spearmint. The overall tone suggests the reviewer is not fully convinced by the paper's contributions. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I have a few reservations' and 'I am not convinced' rather than harsh or dismissive language. However, the critique is direct and doesn't include many softening phrases or compliments, keeping the score only moderately positive.""]"
"['Summary: The paper considers so-called kernel neural networks where the non-linear activation function at each neuron is replaced by a kernelized linear operation, and analyses a layer-wise training scheme to train such networks. The theoretical claims are that (i) the optimal representation at each hidden layer can be determined by getting the similarity between two kernel matrices and (ii) this procedure gives a more interpretable training procedure and can avoid the vanishing gradient problems. Some small-scale experiments are provided.\n\nEvaluation: I have a mixed feeling about this paper: the theoretical contributions seem interesting but its interpretation and practicality are somewhat non-intuitive and philosophically troubling, in my opinion. I did not check the proofs in the appendix so I might have missed some critical info or have not fully understood the experimental set-up.\n\n- interpretability: it\'s not clear to me if this training scheme is any more interpretable than backprop training (not to mention it\'s not clear to me how to define interpretability for neural networks). Whether BP or any layer-wise training schemes is used, isn\'t the goal is to get S_{l-1} to the state where S_{l-1}s for examples of different classes are far away from each other as this is easier for the classifier?\n- function representation: in section 2, fj^i(x) is parameterized as a sum of kernel values evaluated at x and the training points. It\'s unclear to me what is x here -- input to the network or output of the previous layer? This also has a sum over all training points, so is training kMLPs in a layer-wise fashion more efficient than traditional kernel methods? \n- training scheme: what is the order of layers being trained? input to output or output to input? I\'m slightly hazy on how to obtain F^{(l-1)}(S) to compute G_{l-1}. \n- the intuition of layer-wise optimality: on page 4, the paper states that ""the global min of R_l wrt S_{l-1} can be explicitly identified prior to any training"" but intuitively this must condition on some known function/function class F^(l). Could you please enlighten me on this?\n- the experiments are of small-scale and, as the paper pointed out, only demonstrating the concepts. What are the main practical difficulties preventing this from being applied to bigger networks/bigger datasets?\n- vanishing gradients: I\'m not clear how layer-wise training can avoid this issue - could you please explain this?\n- some typos: p1 emplying -> employing, p4 supress -> suppress, p5 represnetation -> representation', '****Reply to authors\' rebuttal****\n\nDear Authors,\n\nThank you very much for all the effort you have put into the rebuttal. Based on the improved theoretical and experimental results, I have decided to increase my score from 5 to 6.\n\nBest wishes,\nRev 1\n\n\n****Original review****\n\n\nThis paper explores integration of kernel machines with neural networks based on replacing the non-linear function represented by each neuron with a function living in some pre-defined RKHS. From the theoretical standpoint, this work is a clear improvement upon the work of Zhang et al. (2017). Authors further propose a layer-wise training algorithm based on optimisation of a particular similarity measure between embeddings based on their class assignments at each layer, which eliminates necessity of gradient-based training. However, the experimental performance of the proposed algorithm is somewhat lacking in comparison, perhaps because the authors focus on kernelised equivalents of MLPs instead of CNNs as Zhang et al.\n\nMy rating of the paper is mainly due to the lack of experimental evidence for usefulness of the layer-wise training, and absence of experimental comparison with several baselines (see details below). It is also unclear whether the structure of KNs is significantly better than that of NNs in terms of interpretability. Apart from the comments below, I would like to ask the authors to discuss relation to the following related papers:\n\n\t1) Kulkarni & Karande, 2017: ""Layer-wise training of deep networks using kernel similarity"" https://arxiv.org/pdf/1703.07115.pdf\n\n\t2) Scardapanea et al., 2017: ""Kafnets: kernel-based non-parametric activation functions for neural networks"" https://arxiv.org/pdf/1707.04035.pdf\n\n\nDetailed comments:\n\nTheory\n\n- (Sec 4.1) Backpropagation (BP) is being criticised: BP is only a particular implementation of gradient calculation. It seems to me that your criticisms are thus more related to use of iterative gradient-based optimisation algorithms, rather than to obtaining gradients through BP?! Regarding the criticism that BP forces intermediate layers to correct for ""mistakes"" made by layers higher up: it seems your layer-wise algorithm attempts to learn the best possible representation in first layer, and then progresses to the next layer where it tries to correct for the potential error of the first layer and so on. In other words it seems that the errors of layers are propagated from first to last, instead of last to first as in BP, but are still being propagated in a sense. I do not immediately see why propagation forward should be preferable. Can you please further explain this point?\n\n- It is proven in the appendix (Lemma B.3) that under certain conditions stacking additional layers never leads to degradation of training loss. Can you please clarify whether additional layers can be helpful even in the case where previous layers already succeeded in learning the optimal representation?\n\n- (Sec 4.1) Layer-wise vs. network-wise optimality: I find the claim that BP-based learner is not aware of the network-wise optimality confusing. BP explicitly optimises for network-wise optimality and the relative contribution to the network-wise error of each weight is propagated accordingly. I suppose my confusion stems from lack of a clear description of what defines a learner ""aware"" or ""blind"" to network-wise optimality. In general, I am not convinced layer-wise optimality is a useful criterion when what we want to achieve is network-wise optimality. As you show in the appendix, if layer-wise optimality is achieved then it implies network-wise optimality; however, layer-wise optimality is only a sufficient condition and likely not a necessary one (except for the simplified scenario studied in B.3). It is thus not clear to me why layer-wise training would always be preferable to network-wise training (e.g. using BP) especially because its greedy nature might intuitively prevent learning of hierarchical representations which are commonly claimed to be key to the success of neural networks. Can you please clarify?\n\n- (Sec 4.2) I think it would be beneficial to state in the introduction that the ""risk"" is with respect to the hinge loss which is common in the SVM/kernel literature but much less in the deep learning literature and thus could surprise a few people when they reach this point. \nFuther questions:\n\t- From Lemma 4.3, it seems that the derived representation is only optimal with respect to the **upper bound** on the empirical risk (which for \\tau >= 2 will be an upper bound on the population risk). I got slightly confused at this point as my interpretation of the previous text was that the representation is optimal with respect to the population risk itself. Does the upper bound have the same set of optima? Please clarify.\n\n\t- (p.5) There are two assumptions that I find somewhat restrictive. Just before Lemma 4.3 you assume that the number of points in each class must be the same. Can you comment on whether you expect the same representation to be optimal for classification problems with significantly imbalanced number of samples per class? The second assumption is after Lemma 4.4 where you state that the stationary kernel k^{l-1} should attain its infinum for all x, y s.t. || x - y || greater than some threshold. This does not hold for many of the popular kernels like RBF, Matern, or inverse multiquadric. Do you think this assumption can be relaxed?\n\n\t- (p.5) Choice of the dissimilarity measure for G: Can you provide more intuition about why you selected L^1 distance and whether you would expect different results with L^2 or other common metrics?\n\n- (Sec 4.3) Can you please provide more detaild about the relation of the proposed objective (\\hat(R)(F) + \\tau max_j ||f_j||_H) to Lemmas 4.3 and 4.5 where the optimal representation was derived for functions that optimise an upper bound in terms of Gaussian complexity (e.g. is the representation that minimises risk w.r.t. the Gaussian bound also optimal with respect to functions that optimise this objective)?\n\n\nExperiments\n\n- I would appreciate addition of some standard baselines, like MLP combined with dropout or batch normalisation, and optimised with RMSProp (or similar). These would greatly help with assessing competitiveness with current SOTA results.\n\n- It would be nice to see the relative contribution of the two main components of the paper. Specifically, an experiment which would evaluate empirical performance of KNs optimised by some form of gradient descent vs. by your layer-wise training rule would be very insightful.\n\n\nOther\n\n- (p.2, 1st par in Sec 2) [minor] You state ""a kernel machine is a universal function approximator"". I suppose that might be true for a certain class of kernels but not in general?! Please clarify.\n\n- (p.2, 3rd par in Sec 2) [minor] Are you using a particular version of the representer theorem in the representation of f_j^{(i)} as linear combination of feature maps? Please clarify.\n\n- (p.2, end of 1st par in Sec 3) L^{(i)} is defined as sup over X_i. It is not clear to me that this constant is necessarily finite and I suspect it will not be in general (it will for the RBF kernel (and most stationary kernels) used in experiments though). Finiteness of L^{(i)} is necessary for the bound in Eq. (2) to be non-vacuous. Please clarify.\n\n- (p.3, after 1st display in Sec 4.2.1) [minor] Missing dot after ""that we wish to minimise"". Next sentence states ""**the** optimal F"" (emphasis mine) -- I am sorry if I overlooked it, but I did not notice a proof that a solution exists and is unique, and am not familiar enough with the literature to immediately see the answer. Perhaps a footnote clarifying the statement would help.\n\n- (p.4, 1st par in Sec 4) You say ""A generalisation to regression is reserved for future work"". I did not expect that based on the first few pages. On high-level, it seems that generalisation to regression need not be trivial as, for example, the optimal representation derived in Lemma 4.3 and Lemma 4.5 explicitly relies on the classification nature of the problem. Can you comment on expected difficulty of extension to regression? Possibly state in the introduction that only classification is considered in this paper.\n\t- (p.7, 1st par in Sec 6) [related] ""However they did not extend the idea to any **arbitrary** NN"" (emphasis mine). Can you please be more specific here?\n\n- (p.5-6) [minor] Last sentence in Lemmas 4.3 and 4.5 is slightly confusing. Can you rephrase please?\n\n- (p.6) [minor] You say ""the learned decision boundary would generalise better to unseen data"". Can you please clarify the last sentence (e.g. being more precise about the meaning of the word ""simple"" in the same sentence) and provide reference for why this is necessarily the case?', 'This paper attempts to learn layers of NNs greedily one at a time by using kernel machines as nodes instead of standard nonlinearities. The paper is well-written and was an interesting read, despite being notation heavy. \n\nI think the interpretability claims have some merits but are over-stated. Furthermore, the expressive power of universal approximation through kernels holds only asymptotically. So I am not sure if the authors can claim equivalence in expressive powers to more traditional NNs theoretically. I have some additional questions about the paper, and I am reserving my recommendation on this paper till the authors answer them. \n\n1) Since individual node is simply a hyperplane in the induced kernel space, why not just specify the cost function as the risk + \\tau * norm(weights) ?  What is the benefit of explicitly talking about gaussian complexities and delineating Theorem 4.2 when the same can be achieved by writing a much simpler form? Lemmas 4.4 and 4.5 should be straightforward extensions too if just used in this form since Lemma C.1 follows easily, and again could be simplified a lot by just using the regularized cost function. Am I missing something here?\n\n\n2) Lemma 4.3 assumes separability (since c should be > a for \\tau to be positive) of classes, and also balanced classes (since number of positives = number of negatives). Why are these assumptions reasonable ? I understand that the empirical evaluation presented do justify the methodology, but I am wondering if based on these assumptions the theoretical results are of any use in the way they are currently presented. \n\nMinor :\nBelow Def 4.1  ""to a standard normal distribution "" should be ""according to P"".\nSome typos, please proof read e.g. spelling error ""represnetation "". ']","[-20, 20, -20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because the reviewer expresses 'mixed feelings' about the paper, pointing out several concerns and areas needing clarification. While they acknowledge some interesting theoretical contributions, they also highlight issues with interpretability, practicality, and experimental scale. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing criticisms as questions or requests for clarification rather than direct criticisms. They also acknowledge their own potential misunderstandings and the possibility of missing critical information. The use of phrases like 'please enlighten me' and 'could you please explain' further contribute to the polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer increased their score from 5 to 6 based on the authors' rebuttal, they still express concerns about experimental performance and lack of comparisons. The overall tone is constructive but critical. The politeness score is moderately high (60) due to the reviewer's use of polite language throughout, such as 'Thank you very much for all the effort', 'I would appreciate', and 'Can you please clarify?'. The reviewer maintains a professional and respectful tone while providing detailed critical feedback and suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-written and interesting, they express significant reservations about the claims made and have several questions that need to be addressed before they can recommend the paper. The reviewer states that interpretability claims are 'over-stated' and questions the theoretical equivalence to traditional NNs. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects of the paper, and frames criticisms as questions or areas for clarification rather than direct attacks. They use phrases like 'I think', 'I am not sure', and 'Am I missing something here?' which maintain a polite tone while expressing concerns.""]"
"['This paper proposes a model-based object-oriented algorithm, SOORL. \nIt assumes access to an object detector which returns a list of objects with their attributes, an interaction function which detects interactions between objects, and a set of high-level macro actions. Using a simplified state representation obtained through the object detector, it performs optimistic MCTS while simultaneously learning transition and reward models. The method is evaluated on two toy domains, PongPrime and miniPitfall, as well as the Atari game Pitfall. It achieves positive rewards on Pitfall, which previous methods have not been able to do. \n\nDespite good experimental results on a notoriously hard Atari game, I believe this work has limited significance due to the high amount of prior knowledge/engineering it requires (the authors note that this is why they only evaluate on one Atari game). I think this would make a good workshop paper, but it\'s not clear that the contributions are fundamental or generally applicable to other domains. Also, the paper is difficult to follow (see below). \n\nPros:\n- good performance on a difficult Atari game requiring exploration\n- sample efficient method\n\nCons:\n- paper is hard to follow\n- approach is evaluated on few environments\n- heavily engineered approach\n- unclear whether gains are due to algorithm or prior knowledge\n\n\nSpecific Comments:\n\n- Section 3 is hard to follow. The authors say that they are proposing a new optimistic MCTS algorithm to support deep exploration guided by models, but this algorithm is not described or written down explicitly anywhere. Is this the same as Algorithm 3 from Section 5? They say that at each step and optimistic reward bonus is given, but it\'s unclear which bonus this is (they mention several possibilities) or how it relates to standard MCTS.\nIn Section 3.1, it is unclear what the representation of the environment is. I\'m guessing it is not pixels, but it is discrete states? A set of features? \nThe authors say ""we provided the right model class for both experiments"" - what is this model class? \n\n- Concerning the general organization of the paper, it would be clearer to first present the algorithm (i.e. Section 5), go over the different components (model learning, learning macro actions, and planning), and then group all the experiments together in the same section. \nThe first set of experiments in Sections 3.1 and 3.2 can be presented within the experiments section as ablations.  \n\n- Although the performance on Pitfall is good, it\'s unclear how much gains are due to the algorithm and how much are due to the extra prior knowledge. It would be helpful to include comparisons with other methods which have access to the same prior knowledge, for example with DQN/A3C and  pseudo-count exploration bonuses using the same feature set and macro actions as SOORL uses. \n\n\nMinor:\n- Page 2: ""Since the model...the new model estimates"": should this be part of the previous sentence?\n- Page 5: ""There are reasonable evidence"" -> ""There is reasonable evidence""\n- Page 5: "". we define a set of..."" -> "". We define a set of...""\n- Page 8: ""any function approximation methods"" -> ""method""', '-- Summary --\n\nThe paper proposes to learn (transition) models (for MDPs) in terms of objects and their interactions. These models are effectively deterministic and are compatible with algorithms for planning with count-based exploration. The paper demonstrates the performance of one such planning method in toy tasks and in Pitfall, as well as a comparison with other planning methods in the toy tasks. The proposed model-based method, called SOORL, yields agents that perform better on Pitfall with a small amount of data.\n\n-- Assessment --\n\nAs a positive, the results of the paper are favorable compared to previous work, with good sample efficiency, and they demonstrate the viability of the proposed approach. The most negative point is that SOORL relies on limiting domain-specific biases that are hard to remove or circumvent.\n\n-- Clarity --\n\nThe paper is somewhat clear. There are many typos and mistakes in writing, and at parts (for example, the second paragraph of Section 4.2) the explanations are not clear.\n\n-- Originality --\n\nI believe the work is original. The paper explores a natural idea and the claims/results are not surprising, but as far as I am aware it has not been tried before.\n\n-- Support --\n\nThe paper provides support for some of the claims made. The comparison to related work contains unsupported claims (""we studied how imperfect planning can affect exploration"") and could be more upfront about the weaknesses of the proposed method. The claims in the introduction are sufficiently supported.\n\n-- Significance --\n\nIt would be hard to scale SOORL to other tasks, so it is unlikely to be adopted where end-to-end learning is wanted. Therefore I believe the impact of the paper to be limited.\n\nThere is also the question of whether the paper will attract interest and people will work on addressing the limitations of SOORL. I would like to hear more from the authors on this point.\n\n-- For the rebuttal --\n\nMy greatest doubt is whether the paper will attract enough interest if published, and it would be helpful to hear from the authors on why they think future work will build on the paper. Why is the proposed approach a step in the right direction?\n\n-- Comments --\n\nSample efficiency: The paper should be more clear about this point. It seems that 50 episodes were used for getting the positive reward in Pitfall, which is great.\n\nObject detection: I am happy with the motivation about how we can remove the hand-made object detection. It is important the other strong assumptions (object interaction matrix, for example) can be removed as well. My opinion on simplifications is this: They are ok if they are being used to make experiments viable and they can be removed when scaling up; but they are not ok if there is no clear way to remove them.\n\nKnown interaction matrix: It may be possible to remove this requirement using the tools in [1]\n\nDeterministic model: The use of no-ops to make the model deterministic seems right if the ultimate goal is to make the model deterministic, but it seems unsuited if the model is to be used for control. Maybe the model needs to be temporally extended as I thought the paper was proposing in Section 4.2 but Section 4.3 suggests that this temporal extension was not a good idea. Is my understanding correct?\n\nExploration: I was a bit confused about how the text discusses exploration. UCT uses OFU, but the text suggests that it does not. What are the components for exploration? Both a bonus on unseen transitions and the confidence interval bonus? Also, the paper would have to provide support for the claim that ""with limited number of rollouts, the agent might not observe the optimistic part of the model, in contrast to optimistic MCTS where optimism is build into every node of the tree"". However, it is fair to say that in the to domains MCTS seemed has performed better, and for that reason it has been chosen instead of Thompson Sampling for the later experiments.\n\nWriting: The paper has a number of typos and mistakes that need to be fixed. To point out a few:\n* I would suggest more careful use of ""much"" and ""very""\n* For citations, ""Diuk et al. (2008) also proposed..."" and ""(UCT, Kocsis & Szepesvari, 2006)""\n\nClaims: I think the claims made in the introduction could be stated more clearly in the conclusion. (Intro) ""We show how to do approximate planning"" --> (Conclusion) ""Our model learning produces effectively deterministic models that can then be used by usual planning algorithms"".\n\n-- References --\n\n[1] Santoro et al., 2017. ""A simple neural network module for relational reasoning""']","[-20, 20]","[50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good experimental results', 'good performance', 'sample efficient method'), they express significant reservations about the paper's overall significance and applicability. The reviewer states that the work has 'limited significance' and suggests it would be more suitable as a workshop paper rather than a full conference paper. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticism with praise, and using phrases like 'I believe' and 'I think' to soften direct criticisms. They also provide a structured review with clear pros and cons, and offer specific, constructive feedback for improvement, which is a polite approach to reviewing."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as favorable results compared to previous work and good sample efficiency. However, they also point out significant limitations and express doubts about the paper's potential impact, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering balanced feedback and suggestions for improvement without using harsh language. They phrase criticisms diplomatically (e.g., 'The paper is somewhat clear') and use polite language when requesting more information from the authors (e.g., 'I would like to hear more from the authors on this point'). The reviewer also acknowledges the paper's originality and provides specific, helpful comments for improvement, which contributes to the polite tone.""]"
"['This paper studies a very simple and intuitive method to boost the training speed of deep neural networks. The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model. Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.\n\nIn general, I think the authors did a decent job in showing that such a simple idea could surprisingly work well to boost NN training. I believe it will inspire future works on speeding up NN training. However, to form a solid ICLR publication, plenty of future works need to be done.\n\n1)\tI will not be fully convinced if an idea aiming to speed up, is only verified on small scale dataset (e.g., CIFAR10). It will be much better if there are large scale experiments conducted such as on ImageNet and WMT neural machine translation. \n\n2)\tPlease well position some related works. First, it would be more interesting and informative if some baselines in section 2 (especially those in “Optimization and Importance Sampling’), are compared with. Second, there are important related works omitted such as L2T [1], which also talks/shows the possibly of using partial training data to achieve speed up.\n\n3)\tSome writing issues: it would be better to *clearly* demonstrate the final accuracy of different models (i.e. ResNet 164 trained on whole data and selected subset), such as putting them into a table, but not merely showing them vaguely in the curves and text. I’m also note sure about the meaning of `epoch’ in Table 1: does it mean how many epochs the proxy model is trained? If so, I can hardly get the intuition of why smaller epochs works better. I noted a conjecture raised by the authors in the last sentence of paragraph “comparing different proxies”. However, I cannot catch the exact meaning. \n\n[1] Fan, Y., Tian, F., Qin, T., Li, X. Y., & Liu, T. Y. Learning to Teach. ICLR 2018\n', '# Summary\nThe paper presents a method for identifying and selecting the most informative subset of the training dataset in order to reduce training time while maintaining test accuracy. The method consists of training a proxy model that is smaller and has been trained for fewer epochs, and which can optionally be ensembled. Experiments show promising results, indicating that some datasets can be reduced to half the size without impacting model performance.\n\n# Quality\nThe paper appears sound and of good quality. Background literature is cited and the proposed method is discussed in sufficient detail.\n\nI would, however, like to see some additional comparative experiments. All experiments are constructed to show that the method can indeed achieve accuracy comparable to the full model but with a smaller training set. I would like to see how it compares to existing strategies -- are there any reason to pick this method over existing ones?\nSince the last sentence in section 2 states that the proposed method is orthogonal to previous subsampling techniques, and therefore can be combined with any of them, it would be interesting to see how SVP compares to these and whether a combination of, say, SVP and importance sampling will in fact achieve better performance than the importance sampling on its own.\nAdditionally, given the model\'s high resemblance to active learning, it would be interesting to see it compared to some prominent active learning methods.\n\n# Clarity\nThe paper reads quite well. I particularly like the paragraph headlines, which makes it easy to get an overview of the paper.\n\nThe figures are generally nice and readable, except for figure 3, which I don\'t understand. Maybe I am missing it, but I can\'t find an explanation for what the rows and columns indicate, and the labels themselves should also be increased in size.\n\n# Originality\nI do not find the paper particularly novel. To me, the proposed method seems to be a variant of active learning, not orthogonal to this as it is claimed in section 2. The choice of surrogate model and uncertainty metric might be new, but the method itself boils down to uncertainty sampling, a well-known strategy in active learning.\nHowever, I am happy to change my mind if the authors can explain to me exactly how their method differs from active learning.\n\n# Significance\nWhile techniques for speeding up training without sacrificing performance are, of course, always interesting, I find the proposed method to be rather incremental and not significant enough for ICLR. It would be better suited as a workshop paper.\n\n# Other notes\nIn the last paragraph of section 1, you write that ""Our proposed framework is robust to the choice of proxy model architecture."" I am not sure what you mean by this. Do you mean that one can choose any model as the proxy (which is clearly correct) or do you mean that the method is ""proxy agnostic"" in the sense that any proxy model will work better than no proxy? If the latter is the case, I would like some arguments for this. Also, if the method is indeed proxy agnostic, it should be possible to remove the proxy completely and select the data in some other way.\n', ""General:\nThe paper proposed an algorithm named Select Via Proxy(SVP), which can be used for data sampling. The idea is simple and straightforward: 1) use a proxy model to get decision boundary 2) train the large target model on the data points close to the decision boundary.\n\nStrength:\n1. Roughly this is a well-written paper. The main idea is quite clear to me.\n2. Empirical validation of the experiments looks good. The results show that SVP help reduce the training time with ResNet. The author(s) also showed the influence of different quantifying uncertainty methods.\n\nPossible Improvements:\n1. In Related Work, several previous works were mentioned. Although the author(s) claimed that SVP can be combined with them, it's better to show the performance of SVP compared with them. This would show the significance of the work.\n2. In the experiments, I was hoping to see how well SVP works on ImageNet. The problem is that: For ResNet152 and ResNet164, they are relatively too deep on such small data sets. Since the dimension of the data points(images) is not high, SVP can easily catch a reasonable decision boundary with a smaller model. I am almost sure ResNet20 is good enough to do this. I am more concerned about the situation where the capacity of the model is challenged by the size of the dataset. e.g. The data sets of autonomous driving are usually extremely large and even very deep models cannot be fully trained on that. \n3. The data points close to the decision boundary can be considered as tough data points, whose features might be hard to be caught by the model. If training model only on these data points, the trained model may just memorize tough data points and not learn the other data points from the data set. One solution is that, while training on tough data points, the model should also be trained on a small portion of well-learned data points. I don't think training only on the points close to the decision boundary is enough and was more expecting to see some discussion about this in the paper.\n\nConclusion:\nMy two biggest concerns are: 1) The algorithm is not tested on large data seta 2) The algorithm is not tested with the models of limited capacity. As a conclusion, I tend to vote for rejection.""]","[50, -20, -60]","[70, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's decent job and potential to inspire future work, but also points out several areas for improvement. The first paragraph is generally positive, while the subsequent paragraphs highlight necessary improvements. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. Phrases like 'I think the authors did a decent job' and 'I believe it will inspire future works' demonstrate a polite tone. The suggestions for improvement are framed as recommendations rather than demands, using phrases like 'It will be much better if' and 'Please well position some related works', which maintains a courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The paper appears sound and of good quality'), they also express significant criticisms. The reviewer questions the novelty and significance of the work, suggesting it's more suitable as a workshop paper. They also request additional comparative experiments and clarifications.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like to see' and 'I am happy to change my mind if the authors can explain', which are polite ways of requesting more information or expressing disagreement. The reviewer also compliments aspects of the paper, such as its readability and the use of paragraph headlines.\n\nOverall, while the review is critical in parts, it's presented in a constructive and courteous manner, balancing negative feedback with positive observations and suggestions for improvement."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper and concludes with a recommendation for rejection. While they acknowledge some strengths, the overall tone is critical, especially in the 'Possible Improvements' and 'Conclusion' sections. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths and providing constructive feedback. They use phrases like 'Possible Improvements' instead of direct criticisms, and maintain a professional tone even when recommending rejection. The reviewer also uses hedging language like 'I was hoping to see' and 'I tend to vote for' which softens the critique.""]"
"['\nSummary: This paper tries to tackle the option discovery problem, by building on recent work on successor representation and eigenoptions. Although this is an extreme important problem, I feel the paper fails to deliver on its promise. The authors propose a way of clustering states via their SR/SF representation and they argue that this would lead to the discovery of subgoals that are fundamentally different from the popular choices in literature, like bottleneck states. They argue that this discovery procedure would lead to states “better for exploration”, “provide greater accessibility to a larger number of states”. Both of which sound promising, but I felt the actual evaluation fails to show or even assess either of these rigorously. Overall, after going through the paper, it is not clear what are the properties of these discovered subgoal states and why they would be better for exploration and/or control.\n\nClarity: Can be improved significantly! It requires several reads to get some of the important details. See detailed comments.\n\nOriginality and Significance: Very limited, at least in this version. The quantitative, and in some cases qualitative, evaluation lacks considerably. The comparison with the, probably most related, method (eigenoption) yield some slight improvement. But unfortunately, I was not conceived that this grain of empirical evidence would transfer to other scenarios. I can’t see why that would that be the case, or in which scenarios this might happen. At least those insights seem to be missing from the discussion of the results. \n\n\nDetailed comments and questions:\n\n1) Section 3.1: Latent Learning. There are a couple of design choices here that should have been more well explained or motivated:\ni) The SR were built under the uniformly random policy. This is a design choice that might work well for gridworld/navigation type of domains but there are MDP where the evaluation under this particular policy can yield uninformative evaluations. Nevertheless this is an interesting choice that I think deserved more discussion, especially the connection to previous work on proto-value functions and eigenoptions. For instance, if both of these representations -- eigenoptions and the proposed successor option model -- aim to represent the SR under the uniform policy, why does know do (slightly) better than the other? Moreover, how would these compare under a different policy (non-uniform). \nii) The choice of reward. The notation is a bit confusing here, as it’s somewhat inconsistent with the definitions (2-4). Also, more generally, It is not clear throughout if we are using the discounted or undiscounted version of SR/SFs -- (2-3) introduce the discounted version, (4) seems to be undiscounted. Not clear if (5) refers to the discounted or undiscounted version. Nevertheless, I am guessing this was meant as a shaping reward, thus \\gamma=1 for (5). But if that’s the case, according to eq. (2), most of the time I would expect \\psi_s(s_{t+1}) and \\psi_s(s_{t}) to have the same value. Could you explain why that is not true (at least in your examples)?\niii) Termination set: Q(s,a)<=0. This again seems a bit of an arbitrary choice and it’s not clear which reward this value function takes into account. \n\n2) Figure 2: The first 2 figures representing the SRs for the two room domain: the values for one of the rooms seems to be zero, although one would expect a smoother transition around the ‘doorway’, otherwise the shaping won’t point in the right direction for progression. Again, this might suggest that more informative(control) policy might give you more signal.  \n\n3) Section 3.2: ‘The policy used for learning the SR is augmented with the previously learnt options‘. Can you be more precise about how this is done? Which options used? How many of them? And in which way are they used? This seems like a very important detail. Also is this augmented policy used only for exploration? \n\n4) SRmin < \\sum_{s’} ψ(s, :) < SRmax. Is this meant to be an expectation over all reachable next states or all states in the environment? How is this determined or translated in a non-tabular setting. Not sure why this is a proxy to how ‘developed’ this learning problem or approximation is. Can you please expand on your intuition here?\n\n5) Section 3.3. The reward definition seems to represent how much the progress between \\phi(s_t+1) - \\phi(s) aligns with the direction of the goal. This is very reminest of FuN [2] -- probably a connect worth mentioning and exploring.\n\n6) Figure 4: Can you explain what rho is? It seems to be an intermediate representation for shared representation \\phi. Where is this used?\n\n7) Experiments:\n“a uniformly random policy among the options and actions (typically used in exploration) will result in the agent spending a large fraction of it’s time near these sub-goals”. Surely this is closely linked to the termination condition of the option and the option policy. How is this assessed?\n\n“in order to effectively explore the environment using the exploration policy, it is important to sample actions and options non-uniformly”. It would be good to include such a comparison, or give a reason why this is the case. It’s also not clear how many of the options we are considering in this policy and how extensive their horizons will be. This comes back to the termination condition in Section 3.1 which could use an interpretation. \n\n“In all our experiments, we fix the ratio of sampling an option to an action as 1:19.” This seems to be somewhat contradictory to the assumption that primitive actions are not enough to explore effectively this environment. \n\nFigure 8. I think this experiment could use some a lot more details. Also it would be good to guide the reader through the t-SNE plot in Figure 8a. What’s the observed pattern? How does this compare to the eigenoption counterpart.\n\n8) General comment on the experiments: There seems to be several stages in learning, with non-trivial dependencies. I think the exposition would improve a lot if you were more explicit about these: for instance, if the representation continually refined throughout the process; when the new cluster centers are inferred are the option policies learnt from scratch? Or do they build on the previous ones? Does this procedure converge -- aka do the clusters stabilize?\n\n9) Quantitative performance evaluation was done only for the gridworld scenarios and felt somewhat weak. The proposed tasks (navigation to a goal location) is exactly what SFs are trained to approximate. No composition of (sub)tasks, nor tradeoff-s of goals were studied [1,3] -- although they seem natural scenario of option planning and have been studied in previous SFs work. Moreover, if the SFs are built properly, in these gridworlds acting greedily with respect to the SFs (under the uniformly random policy) should be enough to get you to the goal. Also, probably this should be a baseline to begin with.\n\nReferences:\n[1] Andre Barreto, Will Dabney, Remi Munos, Jonathan J Hunt, Tom Schaul, Hado P van Hasselt, and ´ David Silver. Successor features for transfer in reinforcement learning. In Advances in Neural Information Processing Systems, pp. 4055–4065, 2017.\n\n[2] Vezhnevets, A.S., Osindero, S., Schaul, T., Heess, N., Jaderberg, M., Silver, D. and Kavukcuoglu, K., 2017, July. FeUdal Networks for Hierarchical Reinforcement Learning. In International Conference on Machine Learning (pp. 3540-3549).\n\n[3] Barreto, A., Borsa, D., Quan, J., Schaul, T., Silver, D., Hessel, M., Mankowitz, D., Zidek, A. and Munos, R., 2018, July. Transfer in deep reinforcement learning using successor features and generalised policy improvement. In International Conference on Machine Learning (pp. 510-519).\n', 'This paper studies of the problem of HRL. It proposed an option discovery algorithm based on successor representations (SR). It considers both tabular and function approximation settings. The main idea is to first learn SR representation, and then based on the leant SR representation to clusters states using kmeans++ to identify subgoals. It iterate between this two steps to incrementally learn the SR options. The technique is sound, but incremental comparing to previous methods learning eigenoption and learning bottleneck states based on SRs. \n\nHere are the comments for this manuscript:\n \nHow sensitive is the performance to the number of subgoals? How is the number of option determined?\n\nIt is unclear to me why the termination set of every option is the set of all states satisfying Q(s, a)\\leq 0. Such a definition seems very adhoc.\n\nRegarding the comparison to eigenoptions, arethey learned from SR as well? It seems that the cited paper for eigenoptions is based on the graph laplacian. If that is true, a more recent paper learns eigenoptions based on SR should be discussed and included for the comparison.\n\nMachado et al., Eigenoption Discovery through the Deep Successor Representation, ICLR2018\n', 'The authors propose a method based on successor representations to discover options in a reward-agnostic fashion.  The method suggests to accumulate a set of options by (1) collecting experience according to a random policy, (2) approximating successor representation of or states, (3) clustering the successor representations to yield “proto-typical” cluster centers, and (4) defining new options which are the result of policies learned to “climb” the successor representation of the proto-typical state.  The authors provide a few qualitative and quantitative evaluations of the discovered options.\n\nI found the method for discovering options reasonable and interesting.  The authors largely motivate the method by appealing to intuition rather than mathematical theory, although I understand that many of the related works on option discovery also largely appeal to intuition.  The visualizations in Figure 5 (left) and Figure 7 are quite convincing.\n\nMy concerns focus on the remaining evaluations:\n\n-- Figure 5 (right) is difficult to understand.  How exactly do you convert eigenoptions to sub-goals?  Is there a better way to visualize this?\n\n-- The evaluation method in Figure 6 seems highly non-standard; the acronym AUC is usually not used in this setting.  Why not just plot the line plots themselves?\n\n-- Figure 8 is very difficult to interpret.  For (a), what exactly is being plotted? SR of all tasks or just cluster centers?  What should the reader notice in this visualization?  For (b), I don’t understand the options presented.  Is there a better way to visualize the goal or option policy?\n\n-- Overall, the evaluation is heavy on qualitative results (many of them on simple gridworld tasks) and light on quantitative results (the only quantitative result being on a simple gridworld which is poorly explained).  I would like to see more quantitative results showing the the discovered options actually help solve difficult tasks.\n', 'The paper proposes to use successor features for the purpose of option discovery.  The idea is to start by constructing successor features based on a random policy, cluster them to discover subgoals, learn options that reach these subgoals, then iterate this process.  This could be an interesting proposal, but there are several conceptual problems with the paper, and then many more minor issues, which put it below the threshold at the moment.\n\nBigger comments:\n1. The reward used to train the options (eq 5) could be either positive or negative.  Hence, it is not clear how or why this is related to getting options that go to a goal.\n2. Computing SRs only for a random policy seems like it will waste potentially a lot of data. Why not do off-policy learning of the SR while performing  the option?\n3. The candidate states formula seems very heuristic. It does not favour reaching many places necessarily (eg going to one next state would give a 1/(1-gamma) SR value)\n4. Fig 5 is very confusing. There are large regions of all subgoals and then subgoals that are very spread out.  If so many subgoals are close by, why would an agent explore? It could  just jump randomly in that region for a while. It would have been useful to plot the trajectory distribution of the agent when using the learned options to see what exactly the agent is doing\n5. There are some hacks that detract from the clarity of the results and the merits of the proposed method. For example, options are supposed to be good for exploration, so sampling them less would defeat the purpose of constructing them, but that is exactly what the authors end up doing. This is very strange and seems like a hack. Similarly, the use of auxiliary tasks makes it unclear what is the relative merit of the proposed method. It would have been very useful to avoid using all these bells and whistles and stick as closely as possible to the stated idea.\n6. The experiments need to be described much better. For example, in the grid worlds are action effects deterministic or stochastic? Are start state and goal state drawn at random but maintained fixed across the learning, or each run has a different pair? Are parameters optimized for each algorithm?  In the plots for the DM Lab experiments, what are we looking at? Policies? End states? How do options compare to Q-learning only in this case? Do you still do the non-unit exploration? The network used seems gigantic, was this optimized or was  this the first choice that came to mind? Would this not overfit? What is the nonlinearity?\n\nSmall comments:\n- This synergy enables the rapid learning Successor representations by improving sample efficiency. \n- Argmax a’ before eq 1\n- Inconsistent notation for the transition probability p\n- Eq 3 and 4 are incorrect (you seem to be one-off in the feature vectors used)\n- Figure 2 is unclear, it requires more explanation\n- Eq 6 does not correspond to eq 5\n- In Fig 6 are the 4 panes corresponding top the 4 envs.? Please explain. Also this figure needs error bars \n- It would be useful to plot not just AUC, but actual learning curves, in order to see their shape (eg rising faster and asymptoting lower may give a better AUC). \n- Does primitive Q-learning get the same number of time steps as *all* stages of the proposed algorithm? If not, it is not a fair comparison\n- It would be nice to also have quantitative results corresponding to the experiments in Fig 7.']","[-60, -20, 20, -70]","[20, 50, 60, 20]","[""The sentiment score is -60 because the reviewer expresses significant disappointment with the paper, stating it 'fails to deliver on its promise' and has 'very limited' originality and significance. They criticize the evaluation as lacking and unconvincing. However, it's not entirely negative as they acknowledge the importance of the problem and some slight improvements over related methods. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I feel' and 'I was not convinced' rather than making blunt accusations. They also provide detailed feedback and suggestions for improvement, which is constructive and helpful. The language is not overly formal or polite, but it avoids rudeness while delivering criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the technique is 'sound', they also describe it as 'incremental comparing to previous methods'. This suggests that the reviewer sees the work as only a small step forward. The review also includes several critical questions and points for improvement, which contributes to the slightly negative sentiment. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They phrase their criticisms as questions or suggestions rather than direct criticisms (e.g., 'How sensitive is the performance...', 'It is unclear to me why...'). The reviewer also acknowledges the soundness of the technique, which is a polite gesture. However, the review doesn't include explicitly positive or encouraging language, which prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer finds the method 'reasonable and interesting' and mentions some aspects as 'quite convincing'. However, they also express several concerns about the evaluations, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as 'concerns' and using phrases like 'I would like to see' rather than making demands. They also acknowledge the merits of the work before presenting their critiques. The review maintains a professional and constructive tone, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states there are 'several conceptual problems' and 'many more minor issues' that put the paper 'below the threshold'. The reviewer lists numerous criticisms and areas for improvement, indicating a generally unfavorable view of the paper. However, it's not entirely negative as the reviewer acknowledges that the proposal 'could be an interesting' idea, hence not scoring at the extreme negative end. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'it would have been useful' and 'please explain' which are polite ways of requesting improvements. The reviewer also offers constructive suggestions and asks clarifying questions rather than making harsh judgments. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"[""Summary\n\nThe authors consider RL with safety constraints, which is framed as a multi-reward problem. At a high-level, this involves finding the Pareto front, which optimally trades off objectives. The paper primarily introduces and discusses a discretization scheme and methods to model the Q-value function as a NIPWC (non-increasing piecewise constant function). NIPWC are stored as values over discrete partitions of state-action spaces. To do so, the authors introduce two data structures DecRect and ContDecRect to store Q function values over geometric combinations of subsets of state-action space.\n\nThe authors discuss how to execute elementary operations on these data structures, such as computing max(f(x), g(x)), weighted sums, etc. The goal is to use these operations to compute Bellman-type updates to compute optimal value/policy functions for multi-reward problems. The authors also present complexity analysis for these operations. \n\nPro\n- Extensive discussion and analysis of discrete representations of Q-functions as NIPWCs. \n\nCon\n- A major issue with this work is that it is very densely written and spends a lot of time on developing the discretization framework and operations on NIPWC. However: \n- There is no clear practical algorithm to solve (simple) multi-reward RL problems with the authors' approach.\n- No experiments to demonstrate a simple implementation of these techniques.\n- Even though multi-reward settings are the stated problem of interest, authors don't discuss Pareto front computations in much detail, e.g., section 4.3 computing non-dominated actions is too short to be useful.\n- The discussion around complexity upper bounds is too dense and uninsightful. For instance, the bounds in section 5 all concern bounds on the Q-value as a function of the action, which results in upper bounds as a function of |A|. But in practice, the action is space is often small, but the state space is high-dimensional. Hence, these considerations seem less relevant. \n\nOverall, this work seems to present an interesting computational scheme, but it is hard to see how this is a scalable alternative. Practical demonstrations would benefit this work significantly.\n\nReproducibility\nN/A \n"", ""The authors provide an algorithm that aims to compute optimal value functions and policies as a function of a set of constraints.  The ideas used for designing the algorithm seem reasonable.  However, I don't fully understand the motivation here.  Given a set of constraints, one can simply carry out value iteration with what the authors call the scalarized reward in order to generate an optimal policy.  Why go through the effort to compute things in a manner parameterized by the constraints?  Perhaps the intention is to use this for sensitivity analysis, though the authors do not discuss that?\n\n"", 'I generally like the paper. The paper discussed a constrained value iteration setting where the safety contraints must be greater some threshold, and thresholds \\delta are parameters. The paper attempts to develop an value iteration algorithm to compute a class of optimal polices with such a parameter. The algorithm is mainly based on a special design of representation/data structure of PWC function, which can be used to store value functions and allows to efficiently compute several relevant operations in bellman equation. A graph-based data structure is developed for continuous state domains and hence value iteration can be extended to such cases. \n\nIn general, the paper presents an interesting direction which can potentially help solve RL problems with the proposed constraint setting. However, the paper spends lots of effort explaining representations, but only a few sentences explaining about how the proposed representations/data structures can help find a somehow generic value iteration solution, which allows to efficiently compute/retrieve a particular solution once a \\delta vector is specified. The paper should show in detail (or at least give some intuitive explanations) that using the proposed method can be more efficient than solving a value iteration for each individual constraint given that the constraints are independent. Specifically, the author uses the patient case to motivate the paper, saying that different patients may have different preferred thresholds and it is good to find class of policies so that any one of those policies can be retrieved once a threshold is specified. However, in this case, when dealing with only one patient, the dimension of reward is reduced to 1 (d = 1), while the computation of the algorithm is exponential in d, plus that the retrieval time is not intuitive to be better, so it is unsure whether computing such a class of policies worth.\n\nIn terms of novelty, the scalarization method of the vector-valued reward seems intuitive, since breaking a constraint means a infeasible solution. Furthermore, it is also unclear why the representation of PWC in discrete case is novel. A partial order on a high-dimensional space is naturally to be based on dominance relation, as a result, it seems natural to store value function by using right-top coordinates of a (hyper)rectangle.\n\nAs for the clarity, though the author made the effort to explain clearly by using examples after almost every definition/notation, some important explanations are missing. I would think the really interesting things are the operations based on those representations. For example, the part of computing summation of two PWC function representation is not justified. Why the summation can be calculated in that way? Though the maximum operation is intuitive, however, the summation should have some justification. I think a better way to explain those things is to redefine a new bellman operator, which can operate on those defined representations of PWC function. \n\nI think it could be a nice work if the author can improve the motivation and presentation. Experiments on some simple domains can be also helpful. ']","[-50, -20, 20]","[20, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pro' section), they express significant concerns and criticisms in the 'Con' section. The review highlights major issues with the work, such as lack of practical algorithms, no experiments, and dense, uninsightful discussions. The overall tone suggests the work needs substantial improvements.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They present both pros and cons, and use neutral language to express criticisms (e.g., 'A major issue with this work is...' rather than using harsh or dismissive language). The reviewer also offers constructive suggestions for improvement, which adds to the politeness. However, the score is not higher as the review doesn't include many explicitly polite phrases or soften the criticisms significantly."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the ideas seem reasonable, they express confusion about the motivation and question the necessity of the approach. The phrase 'I don't fully understand the motivation here' indicates a lack of clarity in the paper's purpose. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, such as 'The ideas used for designing the algorithm seem reasonable' and phrases questions politely, like 'Perhaps the intention is to use this for sensitivity analysis, though the authors do not discuss that?' The reviewer maintains a professional tone without using harsh or dismissive language, even when expressing concerns."", ""The sentiment score is 20 (slightly positive) because the reviewer starts by saying they 'generally like the paper' and find it an 'interesting direction', but then express several concerns and areas for improvement. The overall tone is more positive than negative, but with significant reservations. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'the paper presents an interesting direction' and 'I think it could be a nice work if...' which maintain a polite tone while still conveying their concerns. The reviewer also offers suggestions for improvement rather than just criticizing, which contributes to the polite tone.""]"
"['This paper provides a new method that approximates the confidence distribution of classification probability, which is useful for novelty detection. The variational inference with Dirichlet family is a natural choice.\n\nThough it is principally insightful to introduce the “higher-order” uncertainty, I do see the fundamental difference from the previous research on out-of-distribution detection (Liang, Lee, etc.). They are aimed at the same level of uncertainty.  Consider a binary classier, the only possible distribution of output y is Bernoulli- a mixture of Bernoulli is still Bernoulli.   \n\nIn ODIN paper,  the detector contains both the measurement of the extent to which the largest unnormalized output of the neural network deviates from the remaining outputs (U1 in their notation) and another measurement of the extent to which the remaining smaller outputs deviate from each other (U2 in their notation).  In this paper, the entropy term has the same flavor as U2 part?\n\nI am a little bit concerned with the VI approach, which introduces extra uncertainty.  I do not understand why there is another balancing factor eta in equation 6, which makes it no longer a valid elbo. Is the ultimate goal to estimate the exact posterior distribution of p(z) through VI, or purely some weak regularization that enforces uniformity?  Could you take advantage of some recent development on VI diagnostics and quantify how good the variational approximation is?\n\nIn general, the paper is clear and well-motivated, but I find the notation sometimes confusing and inconsistent. For example, the dependency on x and D is included somewhere but depressed somewhere else.  alpha_0 appears in equation 4 but it is defined in equation 7. \n\nI am impressed by the experiment result that the new method almost always dominates best known methods, previously published in ICLR 2018. But I am not fully convinced why it works theoretically.  I would recommend a weak accept.  \n', 'This paper proposes a new framework for out-of-distribution detection, based on variational inference and a prior Dirichlet distribution. The Dirichlet distribution is presented, and the way it is used withing the method is discussed (i.e. clipping, scaling, etc). Experiments on several datasets and comparison with the state of the art is reported and extensively discussed.\n\nThe motivation of the proposed approach is clear, and I agree with the attempt to regularize the network output. The choice of the Dirichlet distribution is quite natural, as each of its samples are the prior weights of a multinomial distribution. However, some other choices are less clear (clipping, scaling, decision, and the use of a non-informative prior). The overall inference procedure appears to be advantageous in the many experiments that the authors report (several datasets, and several baselines).\n\nThe first thought that came to my mind, is that out-of-distribution detection is to classification what outlier detection is to regression. Therefore, relevant and recent work on the topic deserves to be cited, for instance:\nS. Lathuiliere, P. Mesejo, X. Alameda-Pineda and R. Horaud, DeepGUM: Learning Deep Robust Regression with a Gaussian-Uniform Mixture Model, In ECCV, 2018.\n\nOne thing that I found quite strange at first sight is the choice of clipping the parameters of the Dirichlet distribution. It is said that this is done in order to choose an appropriate prior distribution. However, the choice is not very well motivated, because what ""appropriate"" means is not discussed. So why do you clip to 1? What would happen if some of the alpha\'s go over 1? Is it a numerical problem, a modeling problem, a convergence issue?\n\nI would also like the authors to comment on the use of a non-informative Dirichlet distribution within the KL-divergence. The KL divergence measures the deviation between the approximate a posteriori distribution and the true one. If one selects the non-informative Dirichlet distribution, this is not only a brutal approximation of the true posterior, but most importantly a distribution that does not depend on x, and that therefore cannot be truly called posterior.\n\nIt is also strange to take a decision based on the maximum alpha. On the contrary, the smallest alpha should be taken, since it is the one that concentrates more probability mass to the associated corner in the simplex.\n\nRegarding the scaling function, it is difficult to grasp its motivation and effects. It is annouced that the aim of the smoothing function is to smooth the concentration parameters alpha. But in what sense? Why do they need to be smoothed? Is this done to avoid numerical/convergence problems? Is this a key part of the model? The same stands, by the way, for the form of the input perturbation.\n\nThe experiments are plenty, and I appreciated the sanity check done after introducing the datasets. However, I did not manage to understand why some methods appear in some tables and not in other (for example ""Semantic""). I also have the feeling that the authors could have chosen CIFAR-100 in Table 2, since most of the metrics reported are quite high (the problems are not much challenging).\n\nRegarding the parameter eta, I would say that its discussion right after Table 3 is not long enough. Specially, given the high sensitivity of this parameter, as reported in the Table of Figure 4. What is the overall interpretation of this sensitivity?\n\nFrom a quantitative perspective, the results are impressive, since the propose methods systematically outperforms the baselines (at least the ones reported). However, since these baselines are not the same in all experiments, CIFAR-100 is not used, and the discussion of the results could be richer, I conclude that the experimental section is not too strong.\n\nIn addition to all my comments, I would say that the authors chose to exceed the standard limit of 8 pages. Even if this is allowed, the extra pages should be justified. I am affraid that there are many choices not well motivated, and that the discussion of the results is not informative enough. I am therefore not inclined to accept the paper as it is.', 'Summary\n=========\nThe paper describes a probabilistic approach to quantifying uncertainty in DNN classification tasks.\nTo this end, the author formulate a DNN with a probabilistic output layer that outputs a multinomial over the\npossible classes and is equipped with a Dirichlet prior distribution.\nThey show that their approach outperforms other SOTA methods in the task of out-of-distribution detection.\n\nReview\n=========\nOverall, I find the idea compelling to treat the network outputs as samples from a probability distribution and\nconsequently reason about network uncertainty by analyzing it.\nAs the authors tackle a discrete classification problem, it is natural to view training outcomes as samples from\na multinomial distribution that is then equipped with its conjugate prior, a Dirichlet.\n\nHowever, the model definition needs clarification. In the classical NN setting, I find it misleading\nto speak of output distributions (here called p(x)). As the authors point out, NNs are deterministic function approximators\nand thus produce deterministic output, i.e. rather a function f(x) that is not necessarily a distribution (although can be interpreted as a probability).\nOne could then go on to define a latent multinomial distribution over classes p(z|phi) instead that is parameterized by a NN, i.e. phi = f_theta(x).\nThe prior on p(phi) would then be a Dirichlet and consequently the posterior is Dirichlet as well.\nThe prior distribution should not be dependent on data x (as is defined below Eq. 1).\n\nThe whole model description does not always follow the usual nomenclature, which made it at times hard for me to grasp the idea.\nFor instance, the space that is modeled by the Dirichlet is called a simplex. The generative procedure, i.e. how does data y constructed from data x and the probabilistic procedure, is missing.\nThe inference procedure of minimizing the KL between approximation and posterior is just briefly described and could be a hurdle to understand, how the approach works when someone is unfamiliar with variational inference.\nThis includes a proper definition of prior, likelihood and resulting posterior (e.g. with a full derivation in an appendix).\n\nAlthough the authors stress the importance of the approach to clip the Dirichlet parameters, I am still a bit confused on what the implications of this step are.\nAs I understood it, they clip parameters to a value of one as soon as they are greater than one.\nThis would always degrade an informative distribution to a uniform distribution on the simplex, regardless whether the parameters favor a dense or sparse multinomial.\nI find this an odd behavior and would suggest, the authors comment on what they mean with an ""appropriate prior"". Usually, the parameters of the prior are fixed (e.g. with values lower one if one expects a sparse multinomial).\nThe prior then gets updated through the data/likelihood (here, a parameterized NN) into the posterior.\n\nClipping would also lead to the KL term in Eq. 3 to be 0 often times, as the Dir(z|\\alpha_c) often degrades to Dir(z|U).\n\nThe experiments are useful to demonstrate the application and usefulness of the approach. \nOutcome in table 3 could maybe be better depicted using bar charts, results from table 4 can be reported as text only, which would free up space for a more thorough model definition.']","[20, -50, 20]","[60, 50, 60]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and is 'impressed' by the experimental results, they also express some concerns and recommend only a 'weak accept'. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, asks questions rather than making blunt criticisms, and acknowledges the paper's strengths. They use phrases like 'I am impressed' and 'the paper is clear and well-motivated', which contribute to a polite tone. However, the review is not overly effusive, maintaining a professional, slightly reserved tone, which is why it's not scored higher on politeness."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (clear motivation, advantageous inference procedure, impressive quantitative results), they express significant concerns and are 'not inclined to accept the paper as it is'. The reviewer points out several issues with the methodology, lack of clarity in certain choices, and limitations in the experimental section. This indicates a generally negative sentiment, though not extremely so.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like the authors to comment on...' and 'I appreciated the sanity check...', which are polite ways of expressing their thoughts. The reviewer also acknowledges positive aspects of the work before presenting criticisms. However, the score is not higher because the review is direct in its criticisms and does not use overly deferential language."", ""The sentiment score is slightly positive (20) because the reviewer finds the idea 'compelling' and acknowledges the usefulness of the experiments. However, they also express several concerns and suggest areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I find' and 'I am still a bit confused' which maintain a polite tone while expressing their thoughts. The reviewer also balances critique with positive comments, acknowledging the paper's strengths alongside areas for improvement.""]"
"['Summary:  This paper studies deep multi-task learning. Prior papers have studied various knowledge sharing approaches for deep multi-task learning including hard and soft sharing schemes. And some soft sharing schemes have used tensor decompositions (including TT, and Tucker). This paper fuses this line of work with the recently proposed Tensor-Ring decomposition in order to obtain Tensor Ring (TR)-based soft sharing for multi-task learning. The results show some improvement over prior deep MTL methods based on other tensor factorisation methods.\n\nStrengths:\n+ Nice extension of existing line of work tensor-factorisation based MTL.\n+ More flexibility for controlling shared/unshared portions of weights compared to DMTRL. \n+ Improves on previous methods results.\n+ Experiments evaluate how MTL methods relate with various amounts of training data on each task.\n\nWeaknesses:\n- Novelty/significance is limited. \n- Writing. Many things are not clearly and intuitively explained. Some claims are not adequately justified. \n- Introduces more hyper parameters to tune.\n- Results may rely on hyper parameter tuning. \n\nComments:\n1. Novelty.  Existing studies already established the template of different tensor factorisation methods (TT, Tucker) being possible to plug into deep networks for different kinds of soft-sharing MTL. Meanwhile, TR decomposition is taken off the shelf; (and as it’s been applied for compression before, this is not the first time TR decomposition has been used in a CNN context either). Therefore this is an A+B paper and a high bar should be met for the additional analysis, insight, or performance improvements that should provided.\n2. Lots of writing issues:\n2.1 Many things are not explained transparently enough at best (or major over-claim at worst). For example: \n2.1.1 Paper claims the benefit that each task can have its own I/O dimensionality. However if TR-decomp is “circularly connected” TT-decomp (Fig 1), then this seems not to happen automatically. So it should be unpacked more clearly how this is achieved. \n2.1.2 Paper claims favourable ability to use more private cores than TT, where only one core is private. However circular TT would also seem to have one private core by default (the core with a task axis). So I suspect something else is going on, but this is completely unclear and should be explained more transparently. Furthermore it should be justified if whatever modifications do enable these properties are definitely a unique property of TR-decomp, or could also be applied to TT-decomp. \n2.1.3 Statement “TRMTL generalizes to allow the layer-wise weight to be represented by a relatively lager number of latent cores” unclear: generalises what? larger number of cores than what? Than TT? The previous presentation suggests TT and TR should have same number of cores.  \n2.1.4 Statements like “TR enjoys the property of circular dimensional permutation invariance” are made without any explanation about what is the implication of this for neural networks and multi-task learning.  \n2.2 Many claims are inaccurate or not adequately backed up by theory or experiment. EG: (i) Paper claims to include DMTRL as a special case. But it only subsumes DMTRL-TT, not DMTRL-Tucker. Because TR-decomp does not include Tucker-decomp as an exact special case.  (ii) Sentences “TR-ranks are usually smaller than TT-ranks” are assertions without verification. \n2.3 Sentences are taken verbatim from other papers, plagiarism. For example: “TR model is more flexible than TT, because TR-ranks can be equally distributed in the cores, but TT-ranks have a relatively fixed pattern”  is verbatim from Zhao’16 TR-decomp paper. \n3. Hyperparameters: This paper apparently gains some practical benefit due to the notion of shared/unshared cores. However, this also introduces  additional hyper parameters (E.g., each layers private proportion “c”) to tune besides the ranks. Unlike the rank that can be pre-estimated by reconstruction error, this one seems to require tuning by cross-validation. This is not scalable. \n4. Hyperparameters+Tuning: Hyperparameters Private proportion, “sharing pattern”, IO dimension seem to be tuned by accuracy.( “We test different sharing patterns and report the ones with the best accuracies”). This is even less scalable, and additional tuning makes it unsurprising it surpasses other models performance.\n5. Insight & Analysis. All the core selection & public/private core selection are treated as black box optimisation. No insight is given about what turns out to be useful to share or not, and how consistent this is, etc.\n', 'The novelty and experiments are somewhat limited. Thus I am lowering my score.\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nThe authors proposed a variant of tensor ring formulation for multi-task learning. They achieved that by sharing some of the TT cores for learning ""common task"" while learning individual TT cores for each separate tasks.\n\nPros:\n1) Overall nice but simple extension of TT/ TR framework\n2) Nice set of experiments which have shown improvement over standard TT/ TR framework for MTL.\n\nCons (and suggestions):\n1) As to my knowledge TT/ TR have not been used for MTL before, I wonder if someone wanted to the proposed method is the only way to achieve it, so in that sense, it\'s a very ""simple"" extension.\n2) Though authors called something called ""TRL"", I think it is just an indexing scheme so essentially the same idea of TR.\n3) I wonder why authors suddenly mentioned about convolution in the end of section 3.1., looks very out of the place discussion.\n4) I suggest in Section 3.2., make the shareable cores not adjacent in Eq. (4) as they claimed.\n5) The experiments are somewhat ""````````simplistic"" and I believe the power of this sharing should have experimented on Taskonomy data (https://arxiv.org/pdf/1804.08328.pdf). Right now, the experimental setup is very much simplistic, which is one of the main points the authors should address.\n6) Can the authors comment on the number of parameters used?\n7) I wonder if the author can show some RNN/ LSTM experiment because some of the datasets used like OMLIGLOT/ MNIST are too simple to count as an experiment. Challenge will be to see the performance in challenging MTL. \n8) I believe the authors should comment on the choice of c and the location of the shareable cores.', 'Summary: The authors propose tensor ring nets for multi-task learning\n\nCons: This is a poorly organized paper and poorly motivated. \nThis paper discusses relevant mathematics with no motivation in section 2, while the  prior work is in section 4. Seems backward.\n\nPlease reference the first papers to employ tensor decompositions for imaging.\n\nM. A. O. Vasilescu, D. Terzopoulos, ""Multilinear Analysis of Image Ensembles: TensorFaces,""  Proc. 7th European Conference on Computer Vision (ECCV\'02), Copenhagen, Denmark, May, 2002, in Computer Vision -- ECCV 2002, Lecture Notes in Computer Science, Vol. 2350, A. Heyden et al. (Eds.), Springer-Verlag, Berlin, 2002, 447-460. \n\n M. A. O. Vasilescu, D. Terzopoulos, ""Multilinear Subspace Analysis for Image Ensembles,\'\' Proc. Computer Vision and Pattern Recognition Conf. (CVPR \'03), Vol.2, Madison, WI, June, 2003, 93-99. \n\nM.A.O. Vasilescu, ""Multilinear Projection for Face Recognition via Canonical Decomposition "",  In Proc. Face and Gesture Conf. (FG\'11), 476-483.']","[-40, -30, -70]","[20, 20, -30]","[""The sentiment score is -40 because the review is overall critical, highlighting several weaknesses and issues with the paper. While it acknowledges some strengths, the majority of the review focuses on limitations, lack of novelty, and writing problems. The politeness score is 20 because the reviewer maintains a professional tone and uses neutral language, even when being critical. They provide specific examples and suggestions for improvement rather than harsh dismissals. The reviewer balances criticism with recognition of the paper's strengths, which contributes to the slightly positive politeness score. However, the review doesn't go out of its way to be overly polite or encouraging, keeping the score relatively low on the positive scale."", ""The sentiment score is slightly negative (-30) because the review starts with 'The novelty and experiments are somewhat limited' and mentions lowering the score. The reviewer lists both pros and cons, but the cons outweigh the pros in number and detail. The politeness score is slightly positive (20) as the reviewer uses neutral language and offers constructive suggestions. They use phrases like 'I wonder' and 'Can the authors comment' which are polite ways of asking for clarification or improvements. The review maintains a professional tone throughout, avoiding harsh criticism while still pointing out areas for improvement."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer describes the paper as 'poorly organized' and 'poorly motivated', which are strong criticisms. There are no positive comments to balance these negative ones. The politeness score is -30 because while the language isn't overtly rude, it's quite blunt and lacks any softening phrases or positive reinforcement. The reviewer directly states the paper's flaws without cushioning the criticism. The use of 'Seems backward' comes across as somewhat dismissive. However, the reviewer does provide specific recommendations for improvement, which prevents the score from being even lower.""]"
"['This paper proposed to improve the system resource efficiency for super resolution networks. \n\nFirst, I am afraid all the techniques considered in this paper have been investigated in previous works. Thus no new idea is proposed in this work. Also, it is also not clear why these improvement is particularly suitable for the task of super resolution. In my viewpoint, these techniques actually can be used to improve a variety of network architectures in both high-level and low-level vision tasks.\n\nSecond, the experimental results are also weak. As this work is aiming to address the super resolution tasks, at least visual comparisons between the proposed methods and other state-of-the-art approaches should be included in the experimental part. But unfortunately, no such qualitative results are presented in the manuscript. \n\nFinally, the presentation of the paper should also be carefully proofread and revised.\n', '\nThe paper proposes a detailed empirical evaluation of the trade-offs achieved by various convolutional neural networks on the super resolution problem. The paper provides an extensive evaluation of different architectural changes and the trade-off between savings in terms of memory and computational cost and performance, measured in terms of PSNR and SSIM.\n\nThis is an empirical paper, thus it does not provide technical contributions. I do think that the insights obtained from such an empirical evaluation could be of interest for practitioners and researchers working on the problem. My main concern is the method only evaluates the trade-offs between model efficiency (in terms of memory and/or computation) and performance measured using metrics that are known to not be well correlated with perceptual quality. Thus it is not obvious to me that the insights obtained in this work would translate to the other case.\n\nIt is well known that PSNR favors blurry solutions over perceptually more appealing solutions. This comes from the fact that there is no information in the low resolution image to produce the missing high resolution details. Filling up plausible details in a way that is different from the original image would lead to high PSNR. Models that treat the super resolution problem as a regression task using similarity in pixel space, tend to produce blurry solutions and require very large models to improve the score.  \n\nIn recent years, many works have been studying the use of perceptual losses to mitigate this issue or simply treating the super resolution problem as conditional generative modeling.  For instance, models using L2 losses in a perceptually more relevant (or learned) feature spaces [A, B], or including GAN losses [C, D] (to list a few). To my knowledge, these models are the current state of the art in terms of perceptual quality. This has been evaluated empirically via perceptual tests [D].  \n\nThis line of work needs to be cited. In my view, the paper needs to provide a detailed justification on why models using these losses are not considered. Would the conclusions drawn on this work transfer to that setting? Furthermore, it would be good to perform perceptual tests to perform this evaluation. It would be good to provide some canonical examples in the appendix.\n\nThe overall writing of the paper could be improved. Several sentences are difficult to read, due to typos or the construction of the sentences. The paper evaluates many architectural modifications proposed by other works. It would be good to add an appendix with a small description of what these are. This would make the paper self-contained an easier to read (I had too look up a few of them).\n\nThe authors mentioned that they first train models for scaling factor of x2 and then use them for training settings higher magnification. How is this exactly done? Please provide details.\n\nI am curious of weather using some for of distillation techniques would be useful here.\n\nDid you try scaling factors larger than x4? Scaling factors of x2 does not seem very relevant, as simpler methods can achieve already quite competitive results (such as simple interpolation methods)\n\nThe authors seem to be citing Zhang et al (2018) as a reference to attention mechanisms. To my knowledge the paper that proposed these mechanisms is [E].\n\nThe citation style is not used properly throughout the manuscript. As an example:\n\n“… proposed in StrassenNets Tschannen et al (2017).” Should be “… proposed in StrassenNets (Tschannen et al, 2017).” Or “… proposed in StrassenNets proposed by Tschannen et al (2017).”\n\n[A] Johnson, J. et al. ""Perceptual losses for real-time style transfer and super-resolution.""\xa0ECCV, 2016.\n[B] Bruna, J. et al ""Super-resolution with deep convolutional sufficient statistics.""\xa0ICLR 2016.\n[C] Ledig, C. et al. ""Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.""\xa0CVPR. Vol. 2. No. 3. 2017.\n[D] Sønderby, C. K., et al. ""Amortised map inference for image super-resolution.""\xa0arXiv preprint arXiv:1610.04490(2016).\n[E] Bahdanau, D. et al ""Neural machine translation by jointly learning to align and translate.""\xa0arXiv (2014).', 'The authors target single-image super-resolution (SR) task and study the efficiency (runtime, memory) of the current neural networks.\n\nOn the positive side, the paper is a good effort of bringing together works and insights related to efficient designs and efficient SR solutions.\n\nIf we report to the baseline architecture (RCAN) then the proposed efficient variants achieves large reductions in number of parameters or multiplications-additions, at the cost of lower accuracy. However, when the newly proposed trade-offs are compared with the existing literature, we see other methods that do a comparable or better job in the same range.\n\nOn the negative side, from my point of view, the study is far from being thorough and does not lead to or bring new insights or ideas. The experimental results does not reveal new operating points (trade-off between complexity/operations and performance accuracy).\n\nI would suggest to the authors to expand their study, to make some novel observations, and to propose some designs that can stand out in the literature.\n\nI am pointing out also to some recent papers that are related to the topic and can be or are applied to SR:\nGu et al, ""Multi-bin Trainable Linear Unit for Fast Image Restoration Networks"", arxiv 2018\nIgnatov et al, ""Pirm challenge on perceptual image enhancement on smartphones: Report"", arxiv 2018\nand some works proposed for that challenge:\nVu et al, ""Fast and efficient image quality enhancement via desubpixel convolutional neural networks"", ECCVW 2018\nLi et al, ""CARN: Convolutional Anchored Regression Network for Fast and Accurate Single Image Super-Resolution"", ECCVW 2018\nPengfei et al, ""Range scaling global u-net for perceptual image enhancement on mobile devices"", ECCVW 2018\n\n']","[-70, -20, -20]","[-20, 60, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that no new ideas are proposed, the experimental results are weak, and the paper needs careful proofreading. There are no positive comments about the paper's content or contributions. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any softening phrases or positive reinforcement. Phrases like 'I am afraid,' 'no new idea is proposed,' and 'the experimental results are also weak' contribute to a somewhat blunt and critical tone. The reviewer does not use particularly polite language or offer encouragement, which results in a slightly negative politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential value of the empirical evaluation, they express significant concerns about the paper's methodology and scope. The reviewer points out several limitations, such as the focus on metrics not well-correlated with perceptual quality and the omission of important recent work in the field. However, the tone is not entirely negative, as the reviewer suggests ways to improve the paper. The politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and frame criticisms as concerns or questions rather than harsh judgments. The language used is respectful and academic, avoiding any rudeness or personal attacks. The reviewer also acknowledges potential value in the work, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good effort', 'bringing together works and insights'), they also express significant criticisms. The reviewer states that the study is 'far from being thorough' and 'does not lead to or bring new insights or ideas'. They suggest that the authors need to expand their study and make novel observations, indicating that the current work is not sufficiently impactful. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offers constructive criticism, and provides helpful suggestions for improvement. They use phrases like 'I would suggest' and 'On the positive side', which maintain a professional and courteous tone. The reviewer also provides additional resources, which is a helpful and considerate gesture.""]"
"['This paper proposed a combination of graph neural networks and conditional random field to model the correlation between node labels in the output.  In typical graph neural nets the predictions for nodes are conditionally independent given the node representations.  This paper proposes to use a CRF to compensate for that.  In terms of the approach, the authors used GCNs to produce unary potentials for the CRF, and have the pairwise potentials on each edge to model the correlation of labels of neighboring nodes.  Learning is done by optimizing pseudo-likelihood and the energy loss, while inference is performed through a couple heuristic processes.\n\nCombining neural nets with CRFs is not a new idea, in particular this has been tried before on image and sequence CRFs.  It is therefore not surprising to see an attempt to also try it for graph predictions.  The main argument for using a CRF is its ability to model the correlations of output labels which was typically treated as independent.  However this is not the case for deep neural networks, as it already fuses information from all over the input, and therefore for most prediction problems it is fine to be conditionally independent for the output, as the dependence is already modeled in the representations.  This is true for graph neural networks as well, if we have a deep graph neural net, then the GNN itself will take care of most of the dependencies between nodes and produce node representations that are suitable for conditionally independent output predictions.  Therefore I’m not convinced that CRFs are really necessary for solving the prediction tasks tried in this paper.\n\nThe learning and inference algorithms proposed in this paper are also not very convincing.  CRFs has been studied for a long time, and there are many mature algorithms for learning them.  We could do proper maximum conditional likelihood learning, and use belief propagation to estimate the marginals to compute the gradients.  Zheng et al. (2015) did this for convnets, we could also do this for graph CRFs as belief propagation can be easily converted into message passing steps in the graph neural network.  Pseudo-likelihood training makes some sense, but energy loss minimization doesn’t really make sense and has serious known issues.\n\nOn the other hand, the proposed inference algorithms does not have good justifications.  Why not use something standard, like belief propagation for inference again?  Our community has studied graphical models a lot in the last decade and we have better algorithms than the ones proposed in this paper.\n\nLastly, the experiments are done on some standard but small benchmarks, and my personal experience with these datasets are that it is very easy to overfit, and most of the effort will be put in to prevent overfitting.  Therefore more powerful models typically cannot be separated from overly simple models.  I personally don’t care a lot about the results reported on these datasets.  Besides, there are a lot of questions about the proposed model, but all we get from the experiment section are a few numbers on the benchmarks.  I expect studies about this model from more angles.  One more minor thing about the experiment results: the numbers for GraphSAGE are definitely wrong.\n\nOverall I think this paper tackles a potentially interesting problem, but it isn’t yet enough to be published at ICLR due to its problems mentioned above.', ""The authors combine graph convolutional neural network and conditional random fields to get a new model, named conditional graph neural fields. The idea of the paper is interesting, but the work is not solid enough. Detailed comments come as follows,\n\n1. In the proposed model, the authors treat the pairwise energy as prior and they do not depend on any features. Unlike the usual graph model in Eq (4), the authors further use the normalized \\hat A as a scale factor in the pairwise term. What is the intuition for this?\n\n2. The loss (10), which the authors claim that they are using, may not work. In fact, the loss cannot be used to use for training most architectures: ``while this loss will push down on the energy of the desired answer, it will not pull up on any other energy.''(LeCun et. al. 2006, A tutorial on energy-based learning). For deep structured model learning, please using piecewise learning, or joint training using some common CRF loss, such as log-loss. In fact, the authors are not using the energy-based loss as they have constraints on unary and pairwise terms. In fact, if we ignore the pairwise term in (11), the loss becomes log-loss for GCN. With the pairwise term, the loss is somehow like the loss for piecewise learning but the constraints on U is wrong (for piecewise learning, U should sum to 1).\n\n3. The inference procedure is too simple that it can hardly find the near-optimal solutions. In fact, there exists an efficient mean-field based inference algorithm (Shuai Zheng et. al., 2015). Why did the authors choose a simple but poor inference procedure?\n\nComments After rebuttal\n==========\nThank you for adress my concerns.\n\nThe response and the revision resolved my concern (1). However, the most important part, the possibly problematic loss is not resolved. It is true that sometimes (10) can achieve good results with good regularizers or a good set of hyperparameters. However, theoretically, the loss is ]only pushed down the desired answer, which may make the training procedure quite unstable. Thus I still think that a different loss should be used here."", ""This paper proposes a conditional graph neural network to explore the label correlation. In fact, this method combines graph convolutional neural network and CRF together. The novelty is incremental. No new insight is provided toward this topic. \n\nFor experiments, how did you train DeepWalk (Node2vec)? By using all nodes or the selected training set? It should be clarified in the paper. \n\nAdditionally, Table 3 says the result of semi-supervised methods. But how did you conduct semi-supervised learning for DeepWalk or Node2vec?\n\n===================\nAfter feedback:\nThanks for authors' feedback. Some of my concerns have been addressed. But the novelty is still not significant. On the other hand, the dataset used in this paper is simple. Specifically, at least the first 3 datasets are single-label and the number of classes is not large. They are too simple to support the claim. It's better to use multi-label datasets to show that the proposed method can really capture the correlation of labels. \n""]","[-60, -40, -50]","[20, 20, 20]","[""The sentiment score is -60 because the reviewer expresses significant skepticism about the paper's approach and contributions. They state they are 'not convinced' by the necessity of the proposed method, criticize the learning and inference algorithms as 'not very convincing', and question the experimental results. However, they do acknowledge it tackles a 'potentially interesting problem', preventing an extremely negative score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I'm not convinced' and 'I expect' rather than harsh language. They also acknowledge some positive aspects, like the potential interest of the problem. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is -40 because the reviewer states the work is 'not solid enough' and raises several significant concerns about the methodology and approach. However, it's not entirely negative as they acknowledge the idea is 'interesting'. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism, thanking the authors for addressing concerns. However, they maintain a formal tone without being overly polite. The reasoning is based on the critical nature of the comments balanced with professional language and acknowledgment of the authors' efforts."", ""The sentiment score is -50 because the reviewer expresses that the paper's novelty is incremental and no new insight is provided, which are negative comments. However, they do acknowledge that some concerns were addressed after feedback, slightly mitigating the negativity. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and thank the authors for their feedback. They also provide specific suggestions for improvement, which is constructive. The reviewer maintains a respectful tone throughout, even when expressing dissatisfaction with aspects of the work.""]"
"[""REVISION: thanks for the clarification. I have slightly increased my rating (to 4).\n\nThis paper tackles a very interesting subject but lacks sufficient clarity of presentation to allow me to do a proper review.\n\nFirst, there are many sentences which are not well-formed or are ambiguous (in pretty much all the sections). Then there are terms which are introduced without being first clearly explained or defined. Finally, there are issues with the mathematical clarity as well, with many notations which are used without being explained or defined. Sometimes one can figure out the missing information later (e.g., fig 1 talks about mutual information objectives without stating if we want to maximize or minimize it, but later in the text we figure that out) but it makes reading very difficult.\n\nWhat is a 'transformed one' (on page 2)\nWhat is a 'geometric intrinsic reward'?\nWhere are the intrinsic rewards defined?\nWhat is a 'non-parametric classifier'? A neural net? an kernel SVM?\n\nThere are also some mathematical problems:\n- if f (page 3) has a discrete output, then it will probably lose information, so it cannot be inverted (contrary to the stated assumption that f(x)!=f(y) for x!=y)\n- what are the differences between the different Q functions being defined? do the correspond to different action spaces? What is Q_task? What is pi_meta?\n- in eqn 2, I do not think that the log q_c term maximizes the mutual information between actions and (G(t),G(t+1)), i.e. it would be missing an entropy term\n- what is Z_c in eqn 2?\n\n"", 'This paper proposed an algorithm for structured exploration in deep reinforcement learning via learning the visual abstractions from pixels. The proposed method learns discrete visual abstractions and derives intrinsic reward functions from them so as to help the agent to optimize the policy. \n\nThe proposed method is interesting in that learning the visual abstractions together with the policy may assist in computing an optimal policy. The method is learning a meta Q function and (E * M+1) other Q functions. The authors mentioned that their work is most similar to hierarchical-DQN (Kulkarni et al., 2016) but this work required hand-crafted instance segmentation and the agent architecture do not learn about many intrinsic rewards learners. However, I am concerned if the proposed method solved the problem with the need of hand-crafted instance segmentation since, as shown in the Algorithm 1 and the caption of Figure 2, Q_{meta} acts every T steps. I do not understand why the meta Q function is used to propose actions for every fixed number of steps. Besides that, though the proposed method does have many intrinsic reward functions (in fact, there are E * M additional intrinsic reward functions). However, the authors did not show in the experiments if having too many intrinsic reward functions helps a lot. It will be better if the authors can show that, larger values for E or M can make the performances better.\n\nAnother concern I have is on some of the experiment results. For the experiment results in Figure 5 and 6, only in the left figures can the results of the proposed methods outperform the baselines. Besides that, the authors may need to describe the baseline methods in the experiments in more details.\n\nAlso, it will be better if the authors can improve the paper a little bit with the writing. For example, it will be better if the authors can explain the variables X, Y and the distribution q when mentioning Equation 1 so that it is easier to understand the paper. Also, there are some typos, such as the section reference on line 10 of Algorithm 1, the definition of the g function on the last line of page 3 (I guess the authors want to write ""{0...E}"" instead of ""{0, E}"") and the second sentence of the experiment section (at least I did not see the supplementary sections, but the authors mentioned that). It is better if these typos can be fixed. \n \n\nReferences:\n\nTejas D Kulkarni, Karthik Narasimhan, Ardavan Saeedi, and Josh Tenenbaum. Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation. In Advances in neural information processing systems, pp. 3675–3683, 2016.', 'The appproach introduces visual abstractions that are used for reinforcement learning. The abstractions are learned using a lower bound on the mutual information and options are created to generate different measurements for each abstraction. The algorithm hence learns to ""control"" each abstraction as well as to select the options to achieve the overall task. The algorithm is tested on a 3D navigation task and a few Atari tasks which are known for difficult exploration.\n\nThe paper might contain some interesting ideas, however, I am quite confused about the paper due to lack of clarity in writing. The approach is not properly motivated, many equations are not really eplained and important information is missing, so it is really hard to evaluate the contribution of the approach. Please see below for more comments:\n- It is unclear how the intrinsic reward is defined (which is critical to understand the approach).\n- It is unclear what the M different measurements are or for what they are used for. \n- It is unclear qhy equation 1 defines a classification loss. Distribution q is not defined in Eq (1).\n- I do not understand the description of Q-meta in caption of Figure 2, ""Qmeta acts every T steps, which is the fixed temporal\ncommitment window, and outputs an action to select and execute either: (1) composition over Q\nfunction from the option bank indexed by a particular entity and an intrinsic reward function or (2)\nthe Qtask policy which outputs raw actions."" How can an action be a composition over Q-function and a intrinisic reward function? Please clarify what Qmeta and Qtask do in the text right in the beginning. \n\nI have to say that the paper confused me too much that it is likely I missed the point of the paper. On the positive side, I think the learning of the abstractions using lower bounds of the mutual information is very interesting. The authors should work on their presentation and this could be a very nice paper.  \n\n']","[-50, -20, -20]","[20, 60, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the clarity and presentation of the paper. They mention issues with sentence structure, undefined terms, and mathematical clarity. The reviewer states that these problems make it difficult to conduct a proper review, which indicates a negative sentiment. However, they do acknowledge that the paper tackles 'a very interesting subject', which prevents the score from being even lower. The politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding harsh language or personal attacks. They use phrases like 'thanks for the clarification' and frame their criticisms as observations rather than accusations. However, the directness of the criticisms and the lack of positive reinforcement keep the politeness score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method as 'interesting', they express several concerns and criticisms. They question aspects of the method, point out limitations in the experimental results, and suggest areas for improvement. However, the tone is not entirely negative, as they also recognize potential merits of the approach.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It will be better if...' and 'I am concerned if...' rather than making blunt criticisms. The reviewer also offers constructive suggestions for improvement, which is a polite way to address shortcomings. The language is not overly formal or deferential, but it avoids any rudeness or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas, they express significant confusion about the paper's clarity and presentation. The reviewer states that 'The paper might contain some interesting ideas, however, I am quite confused about the paper due to lack of clarity in writing.' They list several unclear aspects and missing information, indicating overall dissatisfaction with the current state of the paper. However, the score is not extremely negative because the reviewer ends on a positive note, suggesting that with improved presentation, 'this could be a very nice paper.'\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Please see below for more comments' and 'Please clarify,' which are polite ways of requesting improvements. The reviewer also acknowledges potential positives, such as 'the learning of the abstractions using lower bounds of the mutual information is very interesting,' showing respect for the authors' work. The language is not overly formal or exceptionally polite, but it avoids any rudeness or harsh criticism, maintaining a balanced and respectful tone.""]"
"['This paper studies extrapolation error in off-policy batch reinforcement learning (RL), where the extrapolation error refers to the overestimation of the value for the state-action pairs that are not in the training data.\n\nThe authors propose batch-constrained RL, where the policy is optimize under the constraint that, at each state, only those actions that have been taken in that state in the training data are allowed.  This is then extended to continuous space, where it allows only the state-action pairs that are close to a state-action pair in the training data.  When there is no such action for a given state, the action that is closet to a feasible action at that state is selected.\n\nIt makes intuitive sense that the proposed approach works well as long as we only encounter state-action pairs that are closed to one of the state-action pairs in the batch.  However, I do not expect that this is always the case.  The proposed method is to simply choose the closest action in the batch.  Then why does the proposed approach perform well?  Is it because the experiments are performed under rather deterministic settings?  How often are no state-action pairs found in the neighbor?  Is there any mechanism for recovering from ""not in the batch""?\n\nThe paper would be much stronger if it study this challenge of ""not in the batch"" more in depth.  Technical contributions in the present paper are rather limited.\n\nA key assumption in the discrete case is that whole episodes are in the batch.  This is rather restricting, because in many applications, it is infeasible to collect a whole episode, and parts of many episodes are collected from many agents.  Although this assumption is stated, it would be nice to emphasize by also stating that the theorems do not hold when this assumption does not hold.  The assumption becomes less important for continuous case, because of approximation.  It might be interesting to study the performance of the proposed approach when the assumption does not hold in the continuous case.\n', 'Authors consider a problem of off-policy reinforcement learning in a setting explicitly constrained to a fixed batch of transitions. \nThe argument is that popular RL methods underperform significantly in this setting because they fail to account for extrapolation error caused by inevitably sparse sampling of the possible action-state space.\nTo address this problem, authors introduce the notion of batch-constrained RL which studies policies and associated value functions only on the state-space covered by the available training data.\nFor practical applications a deep RL method is introduced which enables generalisation to the unseen states and actions by the means of function approximation.\n\nI find the problem studied in the paper very important. It is indeed strongly connected to the idea of imitation learning which has been studied previously, but I like the explicit point from which authors see the problem.\nThe experimental results seem quite appealing to justify use of the proposed approach.\n\nHowever, on the clarity side the paper should be improved before publication.\n\nThe interplay between action generating VAE G_w(s) and \\pi is unclear to me.\nFirst, what does it mean that G(s) is trained to minimise the distance D_A?\n\nIf G(s) is a VAE, then it is trained to minimise the corresponding variational lower bound, how is minimisation of the distance over actions is incorporated here? And what exactly is this distance?\nSimilarly, what does “D_S will be defined by the implicit distance induced by the function approximation” exactly mean?\n\nOther comments / questions:\n\nPage 6: “Theorem 1 implies with access to only\na subset of state-action pairs in the MDP, the value function… This suggests batch-constrained policies\nare a necessary tool for combating extrapolation bias.”\nThis might be true, but it does not follow from the Theorem 1 as it only applies to the batch Bellman operator and not the standard one used in most methods.\n\nCorollary 1 and 2: What is Q^* here?\n\nPage 7, first sentence: should there be if A_s, e != \\emptyset? \n\nEpsion-Batch-constrained policy iteration: would the beam search actually maximize Q function? This needs to be proven or at least discussed.\n\nI don’t see how is epsilon used in the iteration scheme.  This needs to be clarified.\n\nEquation 11: the subscript of the max operator looks weird, should there be just a_i?\n\nFigure 4: where is “True value” curve on the plots?\n\nThe notation \\pi(s, a; \\Phi) used throughout the paper is confusing and can be interpreted as a joint distribution over states and actions.\n\nAs I said, currently the paper does not appear to be easy to follow to me and even if it does contain important ideas, I believe they must be communicated in a clearer way.\nI am eager to revise my evaluation if authors make substantial effort to improve the paper.', 'Summary:\nProposes BCRL for learning from a fixed collection of off-policy experience (I\'ll call this the ""training data""). BCRL attempts to avoid backing up values from states that are not present in the training data, on the assumption that the current estimates of these values are likely to be inaccurate. In the continuous state-action case, this is accomplished by training a generative model to propose, given a state `s`, an action `a` such that a transition similar to `(s, a)` is in the training data. A secondary policy is then trained to perturb the proposed action within a constrained region to maximize value. BCRL outperforms DDPG and DQN when learning from fixed data, but BCRL is slightly worse than behavior cloning at learning to reproduce an expert policy that does not take exploration actions.\n\nReview:\nThe overall approach is sound. The problem of extrapolation is intuitively obvious, but not something I had thought about before. I think typically exploration would correct the problem since states with over-estimated values would become more likely to be reached, giving an opportunity to get a better estimate. \n\nThe learning setting is closer to imitation learning than to what I would call RL, since the BCRL approach essentially avoids extrapolation error by ignoring the parts of the problem that are not represented in the training data. The well-known problem with behavior cloning is compounding errors once the agent strays into areas of the state space that are far from the training data. To me ""off-policy RL"" implies that the goal is to learn a complete policy from off-policy data. I think the ""competitors"" to which BCRL should be compared are imitation learning algorithms address noisy demonstrations, and not so much off-policy RL algorithms. It would also be interesting to see the generalization performance of BCRL outside of its training data.\n\nThe BCRL idea might be applicable in a conventional RL setting as well, since the initial stages of learning could be subject to a similar extrapolation error until there has been enough exploration. A comparison to something like TRPO in this setting would be interesting.\n\nThe paper is well-written with good coverage of related literature. There are a few points where the technical content is imprecise, which I note below. \n\nComments / Questions:\n* Could one obtain a similar effect to BCRL by simply initializing the value estimates pessimistically?\n* Sec 4.1: Since B is a set of (s, a, s\', r) tuples, what does it mean for a state s\' to be ""in B""? Similar question for state-action tuples (s, a).\n* As you note in the appendix, the construction in Sec 4.1 is essentially creating a new MDP that contains only the transitions that occur in the training data. I\'d suggest stating as much in the main paper for intuition.\n* Sec 4.2 / 5: The perturbation constraint \\Phi is set to 0.05 in the experiments. Since the actions in these control problems are vectors, what does a scalar constraint correspond to? How is the constraint enforced during learning?\n* What are the distance functions D_S and D_A?\n\nPros:\n* A good approach to applying RL methods in the ""imitation-like"" setting. I\'ve seen similar things attempted before, but this method makes more sense. \n\nCons:\n* The learning setting is more like ""fuzzy"" behavior cloning from noisy data than off-policy RL. Experimental comparison against more-sophisticated imitation learning approaches is missing.']","[-20, -20, 50]","[60, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the intuitive sense of the approach and its performance in certain conditions, they express significant concerns about the paper's limitations. The reviewer points out that the technical contributions are 'rather limited' and suggests that the paper would be 'much stronger' if it addressed certain challenges more in-depth. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They phrase their criticisms as suggestions or questions rather than direct attacks, using phrases like 'It would be nice to...' and 'It might be interesting to...'. The reviewer also acknowledges the strengths of the paper before presenting their concerns, which is a polite approach to criticism.\n\nThe language is professional and objective, without any personal attacks or overly harsh wording, which contributes to the positive politeness score. However, it's not extremely high as the review is still direct in its criticism and doesn't use overtly polite language or excessive praise."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the problem studied in the paper 'very important' and the experimental results 'quite appealing', they also state that 'the paper should be improved before publication' and that it's 'not easy to follow'. They express eagerness to revise their evaluation if improvements are made, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the importance of the work, and offers constructive criticism. They use phrases like 'I find', 'I like', and 'I believe' to soften their critiques, and end on a encouraging note about being willing to revise their evaluation. However, the directness of some criticisms prevents the score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the approach as 'sound' and notes that the paper is 'well-written with good coverage of related literature'. They also mention 'pros' of the approach. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions or questions rather than demands. They acknowledge the strengths of the paper while also providing detailed, thoughtful feedback for improvement. The reviewer maintains a professional and courteous tone throughout the review.""]"
"['This paper proposes a hierarchical variational autoencoder for modeling paragraphs. The model creates two levels of latent variables; one level of sentence-level latent variables and another single global latent. This avoids posterior collapse issues and the authors show convincing results on a few different applications to two datasets.\n\nOverall, it is an impressive result to be able to convincingly model paragraphs with a useful global latent variable. Apart from some issues with confusing/incomplete notation (see below), my main criticism is that the authors fail to compare their approach to ""A Hierarchical Latent Structure for Variational Conversation Modeling"" by Park et al. As far as I can tell, the approaches are extremely similar, except that Park et al. may not learn the prior parameters and also use a hierarchical RNN encoder rather than a CNN (which may be irrelevant). They also are primarily interested in dialog generation, so the lower-level of their hierarchy models utterances in a conversation rather than sentences in general, but I don\'t see this as a major difference. I\'d encourage the authors to compare to this and potentially use it as a baseline. More generally, it would have been nice to see more ablation experiments (e.g. convolutional vs. LSTM encoder). Finally, I know that space is tight, but other papers on global-latent-variable models tend to include more demonstrations that teh global variable is capturing meaningful information, e.g. with attribute vector arithmetic. The authors could include results of manipulating review sentiment via attribute vector arithmetic, for example.\n\n\nSpecific comments:\n\n- ""The Kullback-Leibler (KL) divergence term ... which can be written in closed-form (Kingma & Welling, 2013), encourages the approximate posterior distribution qφ(z|x) to be close to the multivariate Gaussian prior p(z)."" The prior is not always taken to be a multivariate Gaussian. You should add a sentence stating that the VAE prior is often taken to be a diagonal-covariance Gaussian for convenience.\n- 3.2 has a few things which are unclear. In the second paragraph, you define z as the sampled latent code which is fed through an MLP ""to obtain the starting state of the sentence-level LSTM decoder"". But then LSTM^{sent} appears to be fed z at every timestep. LSTM^{sent} is also not defined - am I to assume that its arguments are the previous state and current input, so that z is the input at every timestep? Also, you write ""where h^s_0 is a vector of zeros"" which makes it sound like the starting state of the sentence-level LSTM decoder is a vector of zeros, not the output of the MLP which takes z as input. In contrast, LSTM^{word} takes three arguments as input. Which are the ""state"" and which are the ""input"" to the LSTM?\n- I don\'t see any description of your CNN encoder (only the LSTM decoder in section 3.2, 3.3 only covers the hierarchy of latent variables, not the CNN architecture). What is its structure? Figure 1 shows a CNN encoder generating lower-level sentence embeddings and a high-level global embedding. How are those computed? It is briefly mentioned in 4.1 under ""Datasets"" but this seems insufficient.\n- p_\\theta(x | z) is defined as the generating distribution, but also as a joint distribution of z_1 and z_2. Unless I am missing something I think you are overloading the notation for p_\\theta.\n- I don\'t think enough information is given about the AAE and ARAE baselines. Are they the same as the flat-VAE, except with the KL term replaced by the an adversarial divergence between the prior and approximate posterior?', 'This paper proposes using a hierarchical VAE to text generation to solve the two problems of long text generation and mode collapse where diversity in generated text is lost.\n\nThe paper does this by decoding the latent variable into sentence level latent codes that are then decoded into each sentence. The paper shows convincing results on perplexity, N-gram based and human qualitative evaluation.\n\nThe paper is well written though some parts are confusing. For example, equation 4 refers to q as the prior distribution but this seems like it\'s the posterior distribution as it is described just below equation 5. p(z_1|z_2) is also not well defined. It would be clearer to specify the full algorithm in the paper.\n\nThe work also mentions that words are generated for each sentence until the _END token is generated. Is this token always generated? What happens to a sentence if that token is not generated?\n\nThe novelty of this paper is questionable given the significant amount of existing work in hierarchical VAEs. It\'s also unclear why a more direct comparison can\'t be made with Serban et. al in terms of language generation quality and perplexity. If a downstream model is only able to make use of one latent variable, can\'t multiple variables simply be averaged?\n\nIt\'s also unclear how this work is novel with regards to the works below.\n\nHierarchical Variational Autoencoders for Music\nRoberts, et. al\nNIPS 2017 creativity workshop\nThis seems to have a similar hierarchical structure where there is an initial 16 step decoder that decodes the latent code for the lower level note level LSTMs to use during generation.\n\nUnsupervised Learning of Disentangled and Interpretable Representations from Sequential Data\nHsu, et. al\nNIPS 2017\nThis proposes a factorized hierarchical variational autoencoder which also has a double latent variable hierarchical structure, one that is conditional on the other.\n\nMinor comments\n- Typo in page 3 under Hierarchical structures in NLP: characters ""from"" a word\n- Typo above section 4.3: hierarhical\n\n=== After rebuttal ===\nThanks for the response.\n\nI believe that Reviewer2\'s criticism about the similarity to Park et. al isn\'t sufficiently addressed by the authors. Even if the hierarchical structure is different it\'s unclear whether this alternative structure is superior to Park et. al. There appears to be no evidence that the latent variables contain more global information relative to VHCR (Park et. al). These claims aren\'t tested and the results in the paper aren\'t comparable since the authors don\'t evaluate on the same datasets as Park et. al.\n\nIn general, I think the claims of a superior hierarchical structure to models such as the factorized hierarchical VAE paper needed to be tested to show evidence of a more powerful representation for hier-VAE.\n\nI will keep my score.', 'This paper proposed a hierarchical generative model for generating long text. The authors use a hierarchical LSTM decoder to first generate sentence-level representations; then based on the representation of each sentence, a word-level LSTM decoder is utilized to generate a sequence of words in this sentence. In addition, they use multiple layers of latent variables to address the posterior collapse issue.\nThe paper studies an important problem and the authors performed extensive experiments.\n\n\nMy major concern is about the novelty of this paper.\nHierarchical LSTM for generating long txt has been widely studied. For example, in the following works:\nLi, Jiwei, Minh-Thang Luong, and Dan Jurafsky. ""A hierarchical neural autoencoder for paragraphs and documents."" arXiv preprint arXiv:1506.01057 (2015).\nHierarchical LSTM for Sign Language Translation, AAAI, 2018.\n\nPlacing hierarchical latent variables in VAE  is also investigated before.\nFor example, in \nZhao, Shengjia, Jiaming Song, and Stefano Ermon. ""Infovae: Information maximizing variational autoencoders."" arXiv preprint arXiv:1706.02262 (2017).  With some adaption from image domain to text domain\nSerban, Iulian Vlad, et al. ""A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues."" AAAI. 2017.\n\nThe author combines this two ideas together, which is incremental in terms of novelty.\n\n\nIn the writing of section 3.2, the authors should clearly cite the previous works on hierarchical LSTM and acknowledge that this is not the contributions of this paper. Under the current writing, for unfamiliarized readers, it sounds like this is proposed by the authors of this paper, which is not the case.\n\nThe notations of this paper is confusing, which hinders its readbility.\nFor example, in equation 5, the distribution is parameterized by theta.\nIn equation 6, p(x|z) is also parametrized by theta.\n\nIn the experiments, I\'d like to see a comparison with the following works.\nI suggest the authors to compare with the following works.\n\nFan, Angela, Mike Lewis, and Yann Dauphin. ""Hierarchical Neural Story Generation."" ACL (2018).\n\nGhosh, S., Vinyals, O., Strope, B., Roy, S., Dean, T., & Heck, L. (2016). Contextual LSTM: A Step towards Hierarchical Language Modeling.\n\nZhao, Shengjia, Jiaming Song, and Stefano Ermon. ""Infovae: Information maximizing variational autoencoders."" arXiv preprint arXiv:1706.02262 (2017).  With some adaption from image domain to text domain']","[50, -30, -30]","[75, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'impressive result' and 'convincing' modeling, but also raises several criticisms and suggestions for improvement. The overall tone is balanced, recognizing both strengths and areas for enhancement. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. Phrases like 'I'd encourage the authors' and 'it would have been nice to see' maintain a collegial tone. The reviewer also provides detailed, helpful feedback, which is a polite way of engaging with the authors' work."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('convincing results', 'well written'), they express significant concerns about novelty, comparisons to existing work, and unclear aspects of the paper. The overall tone is more critical than positive. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and phrases criticisms as questions or suggestions rather than harsh statements. They also thank the authors for their response in the rebuttal section. However, the review maintains a professional tone rather than being overly polite, hence the moderate positive score."", ""The sentiment score is -30 because while the reviewer acknowledges the importance of the problem and the extensive experiments, they express major concerns about the novelty of the paper. They point out that key components of the proposed model have been studied before, suggesting the work is incremental rather than novel. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They use phrases like 'I suggest' and 'I'd like to see' which are polite ways of making recommendations. However, they don't use overly deferential language, maintaining a professional tone throughout. The review balances critique with acknowledgment of the paper's strengths, which contributes to its overall polite tone.""]"
"['This paper presents a novel deep learning module for recurrent processes. The general idea and motivation are generally appealing but the experimental validation is a mess. Architectures and hyper-parameters are casually changed from experiment to experiment (please refer to Do CIFAR-10 Classifiers Generalize to CIFAR-10? By Recht et al 2018 to understand why this is a serious problem.) Some key evaluations are missing (see below). Key controls are also lacking. This study is not the first to look into recurrent / feedback processes. Indeed some (but not all) prior work is cited in the introduction. Some of these should be used as baselines as opposed to just feedforward networks. TBut with all that said, even addressing these concerns would not be sufficient for this paper to pass threshold since overall the improvements are relatively modest (e.g., see Fig. 4 right panel where the improvements are a fraction of a % or left panel with a couple % fooling rates improvements) for a module that adds significant computational cost to an architecture runtime. As a side note, I would advise to tone down some of the claims such as ""our network could outperform baseline feedforward networks by a large margin”...\n\n****\nAdditional comments:\n\nThe experiments are all over the place. What is the SOA on CIFAR-10 and CIFAR-100? If different from VGG please provide a strong rationale for testing the circuit on VGG and not SOA. In general, the experimental validation would be much stronger if consistent improvements were shown across architectures.\n\nAccuracy is reported for CIFAR-10 and CIFAR-100 for 1 and 2 feedback iterations and presumably with the architecture shown in Fig. 1. Then robustness to noise and adversarial attacks tested on ImageNet and with a modification of the architecture. According to the caption of Fig. 4, this is done with 5 timesteps this time! Accuracy on ImageNet needs to be reported ** especially ** if classification accuracy is not improved (as I expect). \n\nThen experiments on fine-grained with ResNet-34! What architecture is this? Is this yet another number of loops and feedback iterations? When reporting that ""Our model can get a top-1 error of 25.1, while that of the ResNet-34 model is 26.5.” Please provide published accuracy for the baseline algorithm.\n\nFor the experiment on occlusions, the authors report using “a multi-recurrent model which is similar to the model mentioned in the Imagenet task”. Sorry but this is not good enough.\n\nTable 4 has literally no explanation. What is FF? What are unroll times?\n\nAs a side note, VGG-GAP does not seem to be defined anywhere.\n\nWhen stating ""We investigated VGG16 (Simonyan & Zisserman, 2014), a standard CNN that closely approximate the ventral visual hierarchical stream, and its recurrent variants for comparison.”, the authors probably meant “coarsely” not “closely"".', 'The paper proposes to add ""recurrent"" connections inside a convolution network with gating mechanism. The basic idea is to have higher layers to modulate the information in the lower layers in a convolution network. The way it is done is through upsampling the features from higher layers, concatenating them with lower layers and imposing a gate to control the information flow. Experiments show that the model is achieving better accuracy, especially in the case of noisy inputs or adversarial attacks. \n\n- I think there are lot of related literature that shares a similar motivation to the current work. Just list a few that I know of:\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. ""U-net: Convolutional networks for biomedical image segmentation."" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015.\nLin, Tsung-Yi, et al. ""Feature Pyramid Networks for Object Detection."" CVPR. Vol. 1. No. 2. 2017.\nNewell, Alejandro, Kaiyu Yang, and Jia Deng. ""Stacked hourglass networks for human pose estimation."" European Conference on Computer Vision. Springer, Cham, 2016.\nYu, Fisher, et al. ""Deep layer aggregation."" arXiv preprint arXiv:1707.06484 (2017).\nThe current work is very similar to such works, in the sense that it tries to combine the higher-level features with the lower-level features. Compared to such works, it lacks both novelty and insights about what works and why it works.\n\n- The performance gain is pretty marginal, especially given that the proposed network has an iterative nature and can incur a lot of FLOPs. It would be great to show the FLOPs when comparing models to previous works.\n\n- It is interesting observation that the recurrent network has a better tolerance to noise and adversarial attacks, but I am not convinced giving the sparse set of experiments done in the paper.\n\nOverall I think the current work lacks novelty, significance and solid experiments to be accepted to ICLR.\n\n', 'This paper introduces feedback connection to enhance feature learning through incorporating context information. \n\nA similar idea has been explored by (Li, et al. 2018). Compared with that work, the novelty of this work is weaken and seems limited. The difference from Li is not very clear. The authors need to give more discussion. Furthermore, experimental comparison with Li et al. 2018 is also necessary. \n\nThe performance gain is limited. The authors mainly evaluate their method for noisy image classification. Such application is very narrow and deviates a bit from realistic scenarios. ']","[-70, -70, -50]","[-20, -20, 0]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous issues with the paper, including problems with experimental validation, lack of key evaluations and controls, and modest improvements. The phrase 'the experimental validation is a mess' is particularly critical. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism ('the experimental validation is a mess') and sarcastic remarks ('Sorry but this is not good enough'). The reviewer also advises to 'tone down some of the claims', which could be perceived as slightly condescending. However, the review is not overtly rude, maintaining some level of professional courtesy."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the work 'lacks both novelty and insights', the performance gain is 'pretty marginal', and concludes that the work 'lacks novelty, significance and solid experiments to be accepted'. However, it's not entirely negative as the reviewer acknowledges some interesting observations. The politeness score is -20 because while the language is not overtly rude, it's quite direct and critical without much attempt to soften the criticism. Phrases like 'lacks novelty' and 'I am not convinced' come across as somewhat blunt. The reviewer does not use particularly polite language or offer much encouragement, which contributes to the slightly negative politeness score."", ""The sentiment score is -50 because the review is generally negative, pointing out limitations in novelty, comparison with previous work, and narrow application. However, it's not entirely dismissive, acknowledging the introduction of a new idea. The politeness score is 0 (neutral) as the language is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly ('novelty of this work is weaken', 'performance gain is limited') but doesn't use harsh or insulting language. The tone is matter-of-fact, focusing on the paper's content rather than personal comments.""]"
"['The authors propose a review-style overview of memory systems within neural networks, from simple RNNs to stack-based memory architectures and NTM / MemNet-style architectures. They propose some reductions to imply how one model can be used (or modify) to simulate another. They then make predictions about which type of models should be best on different types of tasks.\n\nUnfortunately I did not find the paper particularly well written and the taxonomy was not illuminating for me. I actually felt, in the endeavor of creating a simple taxonomy the authors have created confusing simplifications, e.g.\n\n""LSTM: state memory and memory of a single external event""\n\nto me is mis-leading as we know an LSTM can compress many external events into its hidden units. Furthermore the taxonomy did not provide me with any new insights or display a prediction that was actually clairvoyant. I.e. it was clear from the outset that a memory network (say) will be much better at bAbI than a stack-augmented neural network. It would be more interesting to me, for example, if the paper could thus formalize why NTMs & DNCs (say) do not outperform LSTMs at language modeling, for example. I found the reductions somewhat shady, e.g. the RAM simulation of a stack is possible, however the model could only learn the proposed reduction if the number of write heads was equal to the number of memory slots --- or unless it had O(N) thinking steps per time step, where N is the number of memory slots, so it\'s not a very realistic reduction. You would never see a memory network, for example, simulating a stack due to the fixed write-one-slot-per-timestep interface. \n\nNit: I\'m not sure the authors should be saying they \'developed\' four synthetic tasks, when many of these tasks have previously been proposed and published (counting, copy, reverse copy). ', 'Summary\n=========\nThe paper analyses the taxonomy over memory-based neural networks, in the decreasing order of capacity: Neural RAM to Neural Stack, Neural Stack to LSTM and LSTM to vanilla RNN. The experiments with synthetic and NLP datasets demonstrate the benefits of using models that fit with task types.  \n\nComment\n========\nOverall, the paper is well written and presents interesting analysis of different memory architectures. However, the contribution is rather limited. The proposed taxonomy is not new. It is a little bit obvious and mentioned before in [1] (Unfortunately, this was not cited in the manuscript). The theorems on inclusion relationship are also obvious and the main contribution of the paper is to formally show that in mathematical forms.  The experiments on synthetic tasks give some insights into the models’ operations, yet similar analyses can be found in [2, 3]. To verify the models really learn the task, the authors should include tests on unseen sequence lengths.  There remains questions unexplained in NLP tasks such as why multi-slot memory did not show more advantages in Movie Review and why Neural Stack performed worse than LSTM in bAbI data.  \n\nMinor potential errors: \n\nIn Eq. (6), r_{t-1} should be r_t   \n\nThe LSTM presented in Section 3.2 is not the common one. Normally, there should be x_t term in Eq. (3) and h_t=g_{o,t}*\\tanh(r_t) in Eq. (6). The author should follow the common LSTM formulas (which may lead to different proofs) or include reference to their LSTM version.  \n\n[1] Yogatama et al. Memory Architectures in Recurrent Neural Network Language Models. ICLR’18 \n\n[2] Joulin et al. Inferring algorithmic patterns with stack-augmented recurrent nets. NIPS’15 \n\n[3] Graves et al. Neural Turing Machines. arXiv preprint arXiv:1410.5401 (2014). ', 'I really liked this paper and believe it could be useful to many practitioners of NLP, conversational ML and sequential learning who may find themselves somewhat lost in the ever-expanding field of dynamic neural networks.\n\nAlthough the format of the paper is seemingly unusual (it may feel like reading a survey at first), the authors propose a concise and pedagogical presentation of Jordan Networks, LSTM, Neural Stacks and Neural RAMs while drawing connections between these different model families.\n\nThe cornerstone of the analysis of the paper resides in the taxonomy presented in Figure 5 which, I believe, should be presented on the front page of the paper. The taxonomy is justified by a thorough theoretical analysis which may be found in appendix.\n\nThe authors put the taxonomy to use on synthetic and real data sets. Although the data set taxonomy is less novel it is indeed insightful to go back to a classification of grammatical complexity and structure so as to enable a clearer thinking about sequential learning tasks. \n\nAn analysis of sentiment analysis and question answering task is conducted which relates the properties of sequences in those datasets to the neural network taxonomy the authors devised. In each experiment, the choice of NN recommended by the taxonomy gives the best performance among the other elements presented in the taxonomy.\n\nStrength:\no) The paper is thorough and the appendix presents all experiments in detail. \no) The taxonomy is clearly a novel valuable contribution. \no) The survey aspect of the paper is also a strength as it consolidates the reader\'s understanding of the families of dynamic NNs under consideration.\n\nWeaknesses:\no) The taxonomy presented in the paper relies on an analysis of what the architectures can do, not what they can learn. I believe the authors should acknowledge that the presence of Long Range Dependence in sequences is still hard to capture by dynamic neural networks (in particular RNNs) and that alternate analysis have been proposed to understand the impact of the presence of such Long Range Dependence in the data on sequential learning. I believe that mentioning this issue along with older (http://ai.dinfo.unifi.it/paolo/ps/tnn-94-gradient.pdf) and more recent (e.g. http://proceedings.mlr.press/v84/belletti18a/belletti18a.pdf and https://arxiv.org/pdf/1803.00144.pdf) papers on the topic is necessary for the paper to present a holistic view of the matter at hand.\no) The arguments given in 5.2 are not most convincing and could benefit from a more thorough exposition, in particular for the sentiment analysis task. It is not clear enough in my view that it is true that ""since the goal is to classify the emotional tone as either 1 or 0, the specific contents of the text are not very important here"". One could argue that a single word in a sentence can change its meaning and sentiment.\no) The written could be more polished.\n\nAs a practitioner using RNNs daily I find this paper exciting as an attempt to conceptualize both data set properties and dynamic neural network families. I believe that the authors should address the shortcomings I think hinder the paper\'s arguments and exposition of pre-existing work on the analysis of dynamic neural networks.']","[-70, -20, 80]","[-20, 50, 70]","[""The sentiment score is -70 because the reviewer expresses significant dissatisfaction with the paper. They state that they 'did not find the paper particularly well written' and that the taxonomy was 'not illuminating'. They also criticize the authors' simplifications as 'confusing' and 'misleading'. The reviewer finds little value in the paper's predictions and reductions, describing them as 'shady' and not 'realistic'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. Phrases like 'Unfortunately I did not find...' and 'I actually felt...' are direct but not overtly rude. However, the use of words like 'shady' and the final 'Nit' comment about the authors claiming to have 'developed' tasks they didn't create, come across as somewhat impolite and accusatory."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'interesting analysis'), they also point out several limitations and criticisms ('contribution is rather limited', 'taxonomy is not new', 'obvious', 'remains questions unexplained'). The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positives before criticisms, and phrases critiques constructively ('should include', 'The author should follow'). They avoid harsh language and maintain a professional tone, even when pointing out flaws."", ""The sentiment score is 80 because the reviewer expresses a very positive overall view of the paper, using phrases like 'I really liked this paper' and 'exciting'. They highlight several strengths and believe it could be useful to many practitioners. The few weaknesses mentioned are presented constructively and don't significantly detract from the overall positive sentiment. The politeness score is 70 because the reviewer uses respectful and professional language throughout, offering constructive criticism and suggestions for improvement. They acknowledge the paper's strengths and frame their criticisms as areas for potential enhancement rather than outright flaws. The tone is consistently courteous, though not excessively formal or deferential, hence the score of 70 rather than higher.""]"
"['I raised my rating. After the rebuttal.\n\n- the authors address most of my concerns.\n- it\'s better to show time v.s. testing accuracy as well. the per-epoch time for each method is different.\n- anyway, the theory part acts still more like a decoration. as the author mentioned, the assumption is not realistic.\n\n-------------------------------------------------------------\nThis paper presents a method to update hyper-parameters (e.g. learning rate) before updating of model parameters. The idea is simple but intuitive. I am conservative about my rating now, I will consider raising it after the rebuttal.\n\n1. The focus of this paper is the hyper-parameter, please focus and explain more on the usage with hyper-parameters. \n- no need to write so much in section 2.1, the surrogate is simple and common in optimization for parameters. After all, newton method and natural gradients method are not used in experiments.\n- in section 2.2, please explain more how gradients w.r.t hyper-parameters are computed. \n\n2. No need to write so much decorated bounds in section 3. The convergence analysis is on Z, not on parameters x and hyper-parameters theta. So, bounds here can not be used to explain empirical observations in Section 5. \n\n3. Could authors explain the time complexity of inner loop in Algorithm 1? Does it take more time than that of updating model parameters?\n\n4. Authors have done a good comparison in the context of deep nets.  However,\n- could the authors compare with changing step-size? In most of experiments, the baseline methods, i.e. RMSProp are used with fixed rates. Is it better to decay learning rates for toy data sets? It is known that SGD with fixed step-size can not find the optimal for convex (perhaps, also simple) problems. \n- how to tune lambda? it is an important hyper-parameter, but it is set without a good principle, e.g., ""For SGD-APO, we used lambda = 0.001, while for SGDm-APO, we used lambda = 0.01"", ""while for RMSprop-APO, the best lambda was 0.0001"". What are reasons for these?\n- In Section 5.2, it is said lambda is tuned by grid-search. Tuning a good lambda v.s. tuning a good step-size, which one costs more?\n', 'The paper proposes an approach to adapt hyperparameters online. \nWhen learning rates are in focus, a convincing message would be to show that adaptation of learning rates is more efficient and simpler than their scheduling when tested on state-of-the-art architectures. \nA. You demonstrate the results on CIFAR-10 for 10% error rates which corresponds to networks which are far from what is currently used in deep learning. Thus, it is hard to say whether the results are applicable in practice. \nB. You don\'t schedule learning rates for your baseline methods except for a single experiment for some initial learning rate. \nC. Your method involves a hyperparameter to be tuned which affects the shape of the schedule. This hyperparameter itself benefits from (requires?) some scheduling. \n\nIt would be interesting to see if the proposed method is competitive for training contemporary networks and w.r.t. simple schedule schemes. Online tuning of  hyperparameters is an important functionality and I hope your paper will make it more straightforward to use it in practice. \n\n\n* Minor notes:\n\nYou mention that ""APO converges quickly from different starting points on the Rosenbrock surface"" but 10000 iterations is not quick at all for the 2-dimensional Rosenbrock, it is extremely slow compared to 100-200 function evaluations needed for Nelder-Mead to solve it. I guess you mean w.r.t. the original RMSprop. ', 'Summary:\nThis paper introduces Amortized Proximal Optimization (APO) that optimizes a proximal objective at each optimization step. The optimization hyperparameters are optimized to best minimize the proximal objective. \n\nThe objective is represented using a regularization style parameter lambda and a distance metric D that, depending on its definition, reduces the optimization procedure to Gauss-Newton, General Gauss Newton or Natural Gradient Descent.\n\nThere are two key convergence results which are dependent on the meta-objective being optimized directly which, while not practical, gives some insight into the inner workings of the algorithm. The first result indicates strong convergence when using the Euclidean distance as the distance measure D. The second result shows strong convergence when D is set as the Bregman divergence. \n\nThe algorithm optimizes the base optimizer on a number of domains and shows state-of-the-art results over a grid search of the hyperparameters on the same optimizer.\n\n\nClarity and Quality: The paper is well written. \n\nOriginality: It appears to be a novel application of meta-learning. I wonder why the authors didn’t compare or mention optimizers such as ADAM and ADAGRAD which adapt their parameters on-the-fly as well. Also how does this compare to adaptive hyperparameter training techniques such as population based training?\n\nSignificance:\nOverall it appears to be a novel and interesting contribution. I am concerned though why the authors didn’t compare to adaptive optimizers such as ADAM and ADAGRAD and how the performance compares with population based training techniques. Also, your convergence results appear to rely on strong convexity of the loss. How is this a reasonable assumption? These are my major concerns. \n\nQuestion: In your experiments, you set the learning rate to be really low. What happens if you set it to be arbitrarily high? Can you algorithm recover good learning rates?\n']","[20, -20, 50]","[50, 50, 75]","[""The sentiment score is slightly positive (20) because the reviewer mentions raising their rating and that the authors addressed most of their concerns. However, they still have some reservations about the theory part. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive feedback and suggestions without harsh criticism. They acknowledge improvements and use phrases like 'please explain' and 'could authors explain', which are polite ways of requesting more information. The reviewer also balances critique with positive observations, maintaining a courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic, they express several significant concerns about the paper's methodology and results. The reviewer points out limitations in the experimental setup (points A, B, C) that make it difficult to assess the practical applicability of the proposed method. However, the reviewer also expresses hope for the paper's potential impact, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and express encouragement for the research direction, despite their criticisms. The language used is respectful and focuses on the work rather than personal attacks. The use of phrases like 'It would be interesting to see' and 'I hope your paper will make it more straightforward' contribute to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'well written' and a 'novel and interesting contribution'. However, they also express concerns and questions, which temper the positivity. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or concerns rather than direct attacks, and offers constructive feedback. They use phrases like 'I wonder why' and 'I am concerned' instead of more aggressive language. The reviewer also balances critique with praise, which contributes to the polite tone.""]"
"['This paper proposes a new approach to enforcing disentanglement in VAEs using a term that penalizes the synergistic mutual information between the latent variables, encouraging representations where any given piece of information about a datapoint can be garnered from a single latent.  In other words, representations where there is no information conveyed by combinations of latents that is not conveyed by considering each latent in isolation.  As the resultant target is intractable to evaluate, a number of approximations are employed for practical training.\n\nThe high-level idea is quite interesting, but the paper itself is quite a long way of convincing me that this is actually a good approach.  Moreover, the paper is a long way of the level of completeness, rigor, clarity, and polish that is required to seriously consider it for publication.  In short, the work is still at a relatively early stage and a lot more would need to be done for it to attain various minimum standards for acceptance.  A non-exhaustive list of specific examples of its shortfalls are given below.\n\n1. The paper is over a page and a half under length, despite wasting large amounts of space (e.g. figures 3 and 4 should be two lines on the same plot)\n\n2. The experimental evaluation is woefully inadequate.  The only quantitative assessment is to compare to a single different approach on a single toy dataset, and even then the metric being used is the one the new method uses to train for making it somewhat meaningless.\n\n3. The introduction is completely generic and says nothing about the method itself, just providing a (not especially compelling) motivation for disentanglement in general.  In fact, the motivation of the introduction is somewhat at odds with the work -- correctly talking about the need for hierarchical representations which the approach actually actively discourages.\n\n4. There are insufficient details on the algorithm itself in terms of the approximations that are made to estimate the synergistic mutual information.  These are mostly glossed over with only a very short explanation in the paragraph after equation 15.  Yes there are algorithm blocks, but these are pretty incomprehensible and lack accompanying text.  In particular, I cannot understand what A_w is supposed to be.  This is very important as I suspect the behavior of the approximation is very different to the true target.  Similarly, it would be good to provide more insight into the desired target (i.e. Eq 15).  For example, I suspect that it will encourage a mismatch between the aggregate posterior and prior by encouraging higher entropy on the former, in turn causing samples from the generative model to provide a poor match to the data.\n\n5. The repeated claims of the approach and results being ""state-of-the-art"" are cringe-worthy bordering on amusing.  Writing like this serves no purpose even when it justified, and it certainly is not here.\n\n6. There are a lot of typos throughout and the production values are rather poor.  For example, the algorithm blocks which are extremely messy to the point where they are difficult to follow, citep/citet mistakes occur almost every other citation, there is a sign error in Equation 16.\n\n\nThis is a piece of work in an exciting research area that,  with substantial extra work, could potentially result in a decent paper due to fact that the core idea is simple and original.  However, it is a long way short of this in its current state.  Along with addressing the specific issues above and improving the clarity of the work more generally, one thing in particular that would need to address in a resubmission is a more careful motivation for the method (ideally in the form of a proper introduction).  \n\nThough I appreciate this is a somewhat subjective opinion, for me, penalizing the synergistic information is probably actually a bad thing to do when taking a more long-term view on disentanglement.  Forcing simplistic representations where no information is conveyed through the composition of latents beyond that they provide in isolation is all well and good for highly artificial and simplistic datasets like dsprites, but is clearly not a generalizable approach for larger datasets where no such simplistic representation exists.  As you say in the first line of your own introduction, hierarchy and composition are key parts of learning effective and interpretable representations and this is exactly what you are discouraging.  A lot of the issue here is one of the disentanglement literature at large rather than this paper (though I do find it to be a particularly egregious offender) and it is fine to have different opinions.  However, it is necessary to at least make a sensible case for why your approach is actually useful.  \n\nNamely, is there actually any real applications where such a simplistic disentanglement is actually useful?  Is there are anyway the current works helps in the longer vision of achieving interpretable representations?  When and why is the synergistic information a better regularizer than, for example, the total correlation?  The experiments you have do not make any inroads to answering these questions and there are no written arguments of note to address them.  I am not trying to argue here that there isn\'t a good case to be made for the suggested approach in the context of these questions (though I am suspicious), just that if the work is going to have any lasting impact on the community then it needs to at least consider them.', 'The authors aim at training a VAE that has disentangled latent representations in a ""synergistically"" maximal way.\nFor this they  use one (of several possible) versions of synergy defintions and create a straight forward penalization term for a VAE objective (roughly the whole mutual information minus the maximum mutual information of its parts).\nThey train this VAE on one dataset, namely dsprites, and compare it to a VAE with total correlation penalization. \n\nThe paper is well written and readable. The idea of using synergy is an important step forward in understanding complex models. The concept of synergy has great potential in machine learning and is highly relevant.\n\nThe main concepts of synergy are not developed in this paper and the used penalization term is straight forward.\nThe number of experiments conducted and comparisons done is quite limited. Also the potential of synergy is not really demonstrated, e.g. for representation learning, causality, etc., and appears here ad hoc. \nAlso why one should use the authors\' suggested penalization term instead of total correlation is not discussed, nor demonstrated as they perform similarly on both disentanglement and synergy loss.\n\nI hope the authors find more relevant applications or data sets in the future to demonstrate the importance of synergy.\n\n', 'The paper proposes a new objective function for learning disentangled representations in a variational framework, building on the beta-VAE work by Higgins et al, 2017. The approach attempts to minimise the synergy of the information provided by the independent latent dimensions of the model. Unfortunately, the authors do not properly evaluate their newly proposed Non-Syn VAE, only providing a single experiment on a toy dataset and no quantitative metric results. Furthermore, even qualitatively the proposed model is shown to perform no better than the existing factor-VAE baseline.\n\nI commend the authors for taking a multi-disciplinary perspective and bringing the information synergy ideas to the area of unsupervised disentangled representation learning. However, the resulting Non-Syn VAE objective function is effectively a different derivation of the original beta-VAE objective. If the authors want to continue with the synergy minimisation approach, I would recommend that they attempt to use it as a novel interpretation of the existing disentangling techniques, and maybe try to develop a more robust disentanglement metric by following this line of reasoning. Unfortunately, in the current form the paper is not suitable for publication.\n\n']","[-70, 20, -60]","[-20, 60, 20]","[""The sentiment score is -70 because the reviewer expresses significant criticism and skepticism about the paper. They state that the paper is 'quite a long way of convincing me that this is actually a good approach' and that it's 'a long way of the level of completeness, rigor, clarity, and polish that is required to seriously consider it for publication.' The reviewer lists numerous shortcomings and suggests that substantial extra work is needed. However, it's not entirely negative as they acknowledge the 'core idea is simple and original' and that it 'could potentially result in a decent paper' with more work.\n\nThe politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt and somewhat harsh language. For example, they describe the experimental evaluation as 'woefully inadequate' and call the claims of being 'state-of-the-art' as 'cringe-worthy bordering on amusing.' The reviewer also uses phrases like 'a long way short of this' and 'particularly egregious offender,' which come across as rather critical. However, they do soften some criticisms with phrases like 'I appreciate this is a somewhat subjective opinion' and provide constructive feedback, which prevents the score from being lower."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and readable, and recognizes the importance and potential of the concept of synergy in machine learning. However, they also point out limitations in the experiments and comparisons, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and ends with an encouraging note for future work. The reviewer maintains a professional tone without using overly negative language, even when discussing the paper's shortcomings."", ""The sentiment score is -60 because the review is largely negative. The reviewer states that the authors 'do not properly evaluate their newly proposed Non-Syn VAE,' and that the model performs 'no better than the existing factor-VAE baseline.' The reviewer also concludes that 'in the current form the paper is not suitable for publication.' However, it's not entirely negative as the reviewer commends the authors for their multi-disciplinary perspective and offers suggestions for improvement. The politeness score is 20 because while the reviewer is critical, they use polite language such as 'I commend the authors' and offer constructive suggestions. The tone is professional and respectful, even when delivering negative feedback. The reviewer also uses softening language like 'Unfortunately' when delivering criticism, which adds to the politeness.""]"
"['The paper studies approximation and estimation properties of CNNs with residual blocks in the context\nof non-parametric regression, by constructing equivalent fully-connected architectures (with a block-sparse structure),\nand leveraging previous approximation results for such functions.\nExplicit risk bounds are obtained for regression functions in Barron and Holder classes.\n\nThe main contribution of the paper is Theorem 1, which shows that a class of ResNet-type CNNs\ncontains a class of ""block-sparse"" fully-connected networks, with appropriate constraints on various size quantities.\nThis result allows the authors to obtain a general risk bound for the ResNet CNN that minimizes empirical risk\n(Theorem 2, which mostly follows Schmidt-Hieber (2017)),\nas well as adaptations of the bound for the Barron and Holder classes, by relying on existing approximation results.\n\nThe construction of Theorem 1 is interesting, and shows that ResNet CNNs can be quite powerful function approximators,\neven with a filter size that is arbitrarily fixed.\nHowever, the obtained CNN approximating architectures look quite unrealistic compared to most practical use-cases of CNNs,\nsince they specifically try to reproduce a fully-connected architecture, leading to residual blocks of depth ~= D/K,\nwhich is very deep compared to usual CNNs/ResNets (considering, e.g. K=3 and D in the hundreds for images).\nIn particular, CNNs are typically used when there is some relevant inductive bias such as equivariance\nto translations (and invariance with pooling operations) to take advantage of,\nso removing this inductive bias by approximating fully-connected architectures seems a bit twisted.\nThe approach of reducing the function class to be approximated would seem more relevant here,\nas in the cited papers Petersen & Voigtlaender (2018) and Yarotsky (2018), and perhaps the results of\nthe present paper can be useful in such a scenario as well.\n\nSeparately, the presentation of the paper could be significantly improved,\nfor instance by introducing relevant notions more clearly in the introduction and related work sections,\nand by providing more insight and discussion of the obtained results in the main paper.\n\nMore specific comments:\n- Section 1, p.2: define M? define D? M seems to be used for different things in different paragraphs\n- Section 2: Explain what is ""s"" in the Barron class, or at least point to the relevant definition in the paper\n- Section 3.1:\n  * \'estimation error\' is usually called \'(expected) risk\' in the statistical literature (also in the introduction). estimation error would have to do with relating R and R^hat\n  * why is the estimator ""regularized""?\n- Definition 2: shouldn\'t it be D_m^(0) = D instead of 1?\n- Theorem 1: What is L? Also, it would be helpful to sketch the construction in the main paper given that this is the main result.\n- Section 4.2: M_1 is the Lipschitz constant of what function?\n- Section 5.1: ""M = 1"" this is confusing, maybe use a different letter for the ridge expansion? The discussion on \'relative scale\' could be made clearer.\n- Section 5.2, \'if we carefully look at their proofs\': more details on this should be provided.\n', 'The authors demonstrate the function expression properties for the Residual type convolutional neural networks to approximate the block sparse fully connected neural networks. Then it is shown that such Res-CNNs can approximate any function as long as it can be expressed by the block-sparse FNNs, including the Barron class and Holder class functions. The price to pay is that the number of parameters is larger than that of the FNNs by a constant factor. \n\nThe idea for connecting the expressive ability of CNNs with FNNs is interesting, which can fully take advantage of the power of FNNs to understand CNNs. However, it is not very clear how the convolutional structure of CNNs help in the analysis of approximating FNNs. For example, in the analysis of C.1 and C.2, it will help better understand why CNNs may work from a high-level intuition when the authors construct the filters. \n\nMoreover, it will also help better understand the expressive power of CNNs if the authors can provide some extended discussion on why approximating the block-sparse FNNs rather than arbitrary feed-forward networks. Is there any fundamental reason (or a counterexample) this cannot be realized, or is there to some extent a technical barrier in the analysis? \n\nMinor issue\n\nOn page 20, “Bounds residual blocks” -> “Bounds for residual blocks”\n', 'This manuscript shows the statistical error of the ERM for nonparametric regression using the family of a Resnet-type of CNNs. Specifically, two results are showed. First, the authors show that any block-sparse fully connected neural network can be embedded in CNNs. Second, they show the covering number of the family of CNNs. Combining with the existing results of the approximation error of neural nets (Klusowski&Barron 2016, Yarotsky 2017, Schmidt-Hieber 2017), they show the L2 statistical risk. \n\nDetailed comments:\n\n1. The intuition of using block-sparse FNN seems unclear. It seems that when $M=1$, it reduces to the sparse NN considered in [Schmidt-Hieber 2017]. In the proof of Corollary 5, the authors directly use the error of approximating Holder smooth function by sparse FNN and show that the construction in [Schmidt-Hieber 2017] is actually block-sparse. Thus, it seems unclear why we should consider such block-sparse family. Can any sparse NN be embedded in the family of CNNs?\n\n2. In the Related Work, the authors only compare with 2 previous work on the approximation error of CNN. Actually, this work is more related to [Schmidt-Hieber 2017] due to borrowing the results. It would be better to see what the novelties are compared with that work, especially in terms of the proof techniques.\n\n3. The authors claim that the construction of approximator for Holder functions in [Schmidt-Hieber 2017] is block sparse. It would be nice to give more details of the construction since this is not claimed in [Schmidt-Hieber 2017].']","[-20, 50, 20]","[50, 75, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting contributions, they express several concerns about the practical relevance of the approach and the need for improved presentation. The reviewer points out that the obtained CNN architectures seem 'quite unrealistic compared to most practical use-cases of CNNs' and suggests that the approach of reducing the function class to be approximated would be more relevant. They also mention that 'the presentation of the paper could be significantly improved.' However, the review is not entirely negative, as it recognizes the main contribution and the interesting construction in Theorem 1. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The construction of Theorem 1 is interesting' and provide constructive feedback. The reviewer also offers specific suggestions for improvement without using harsh or dismissive language. The use of phrases like 'could be significantly improved' and 'it would be helpful to' indicate a polite approach to criticism."", 'The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting idea of connecting CNNs with FNNs and the potential benefits of this approach. However, they also express some concerns and suggest areas for improvement, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their suggestions as ways to improve understanding rather than as criticisms. They also point out a minor issue politely. The reviewer maintains a professional and courteous tone while providing substantive feedback.', ""The sentiment score is slightly positive (20) because the reviewer acknowledges the manuscript's contributions and provides a neutral summary of the work. However, they also raise several questions and suggest areas for improvement, indicating a mixed but generally positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases their comments as suggestions ('It would be better', 'It would be nice'), and avoids harsh criticism. The reviewer maintains a professional tone while providing constructive feedback, which contributes to the polite nature of the review.""]"
"['The paper presents an approach for an approach to addressing multi-goal reinforcement learning, based on what they call ""one-step path rewards"" as an alternative to the use of goal conditioned value function. \nThe idea builds on an extension of a prior work on FWRL. \nThe paper presents empirical comparison of the proposed method with two baselines, FWRL and HER. \nThe experimental results are mixed, and do not convincingly demonstrate the effectiveness/superiority of the proposed method. \nThe idea of the proposed method is relatively simple, and is not theoretically justified. \n\nBased on these observations, the paper falls short of the conference standard. ', 'This paper aims to improve on Hindsight Experience Replay by removing the need to compute rewards for reaching a goal. The idea is to frame goal-reaching as a shortest path problem where all rewards are -1 until the goal is reached, removing the need to compute rewards. While similar ideas were explored in a recent arxiv tech report, this paper claims to build on these ideas with new loss functions. The experimental results do not seem to be any better compared to baselines when measured in terms of data efficiency, but the proposed method requires fewer “reward computations”.\n\nClarity:\nWhile the ideas in the paper were easy to follow, there are a number of problems with the writing. The biggest problem is that it wasn’t clear exactly what algorithms were evaluated in the experiments. There is an algorithm box for the proposed method in the appendix, but it’s not clear how the method differs from the FWRL baseline.\n\nAnother major problem is that the paper does a poor job of citing earlier related work on RL. DQN is introduced without mentioning or citing Q-learning. Experience replay is mentioned without citing the work of Long-Ji Lin. There’s no mention of earlier work on shortest-path RL from LP Kaelbling from 1993. \n\nNovelty and Significance:\nAfter reading the paper I am not convinced that there’s anything substantially new in this paper. Here are my main concerns:\n\n1) The shortest path perspective for goal-reaching was introduced in “Learning to Achieve Goals” by LP Kaelbling [1]. This paper should be cited and discussed.\n\n2) I am not convinced that the proposed formulation is any different than what is in Hindsight Experience Replay (HER) paper. Section 3.2 of the HER paper defines the reward function as -1 if the current state is not the same as the goal and 0 if the current state is the same as the goal. Isn’t this exactly the cost-to-go/shortest path reward structure that is used in this paper?\n\n3) This paper claims that the one-step loss (Equation 8) is new, but it is actually the definition of the Q-learning update for transitioning to a terminal state. Since goal states are absorbing/terminal, any transition to a goal state must use the reward as the target without bootstrapping. So the one-step loss is just Q-learning and is not new. This is exactly how it is described in Section 3 of [1].\n\n4) The argument that the proposed method requires fewer reward evaluations than FWRL or HER seems flawed. HER defines the reward to be -1 if the current state and the goal are different and 0 if they are the same. As far as I can tell this paper uses the same reward structure, so how is it saving any computation?\n\nCan the authors comment on these points and clarify what they see as the novelty of this work?\n\nOverall quality:\nUnless the authors can convince me that the method is not equivalent to existing work I don’t see enough novelty or significance for an ICLR paper.\n\n[1] “Learning to Achieve Goals” LP Kaelbling, 1993.\n', 'This paper presents a reinterpretation of hindsight experience replay (HER) that avoids recomputing the reward function on resampled hindsight goals in favor of simply forcing the terminal state flag for goal-achieving transitions, referred to by the authors as a ""step loss"".\nThe new proposal is evaluated on two goal-conditioned tasks from low-dimensional observations, and show modest improvements over HER and a function-approximation version of Floyd-Warshall RL, mostly as measured against the number of times the reward function needs to be recomputed.\n\nPros:\n- minor improvement in computational cost\n- investigation of classical FWRL technique in context of deep RL\n\nCons:\n- computational improvement seems very minor\n- sparse-reward implementations of HER already do essentially what this paper proposes\n\nComments:\n\nThe main contribution of the paper appears to be the addition of what the authors refer to as a ""step loss"", which in this case enforces the Q function to correctly incorporate the termination condition when goals are achieved. I.E. the discounted sum of future rewards for states that achieve termination should be exactly equal to the reward at that timestep.\n\nIt\'s not clear to me how this is fundamentally different than HER. One possible ""sparse reward"" implementation of HER involves no reward function recomputation at all, instead simply replacing the scalar reward and termination flag for resampled transitions with the indicator function for whether the transition achieves the resampled goal.\nIs this not essentially identical to the proposal in this paper? I would consider this a task-dependent implementation detail for an application of HER rather than a research contribution that deserves an entire paper.\n\nThe authors claim the main advantage here is avoiding recomputation of the reward function for resampled goals.\nI do not find this particularly compelling, given that all of the evaluations are done in low-dimensional state space: reward recomputation here is just a low-dimensional euclidean distance computation followed by a simple threshold.\nIn a world where we\'re doing millions of forward and backward passes of large matrix multiplications, is this a savings that really requires investigation?\nIt is somewhat telling that the results are compared primarily in terms of ""# of reward function evaluations"" rather than wall time. If the savings were significant, I expect a wall time comparison would be more compelling.\nMaybe the authors can come up with a situation in which reward recomputation is truly expensive and worth avoiding?\n\nAll of the experiments in this paper use a somewhat unusual task setup where every timestep has a reward of -1. Have the authors considered other reward structures, such as the indicator function R=(1 if s==g else 0) or a distance-based dense reward?\nWould this proposal work in these cases? If not, how significant is a small change to HER if it can only work for one specific reward function?\n\nConclusion:\n\nIn my view, the main contribution is incremental at best, and potentially identical to many existing implementations of HER.\nThe reconsideration of Floyd-Warshall RL in the context of deep neural networks is a refreshing idea and seems worth investigating, but I would need to see much more careful analysis before I could recommend this for publication.']","[-60, -70, -60]","[0, 20, 20]","[""The sentiment score is -60 because the review is generally negative. The reviewer states that the paper 'falls short of the conference standard' and that the experimental results are 'mixed, and do not convincingly demonstrate the effectiveness/superiority of the proposed method.' They also mention that the idea is 'not theoretically justified.' However, it's not entirely negative as they do acknowledge that the paper presents an approach and builds on prior work, which is why the score isn't lower. The politeness score is 0 (neutral) because the language used is professional and objective, without being particularly polite or rude. The reviewer states their observations directly without using overly harsh language or personal attacks, but also without any notably courteous phrases."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's novelty and significance. They state they are 'not convinced that there's anything substantially new in this paper' and list several major concerns about the claimed contributions. The reviewer also mentions problems with clarity and citations, concluding that they 'don't see enough novelty or significance for an ICLR paper'. However, it's not entirely negative as they acknowledge some aspects were 'easy to follow'.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Can the authors comment on these points' and 'Unless the authors can convince me', which invite dialogue rather than outright dismissal. The reviewer also provides specific feedback and references to help improve the paper. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses skepticism about the paper's main contribution, stating it's 'incremental at best' and potentially not different from existing implementations. They question the significance of the computational improvement and the applicability of the method to different reward structures. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They acknowledge some pros of the paper and use phrases like 'It's not clear to me' and 'I would need to see' rather than making outright dismissive statements. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['This paper presents an instruction-following model consisting of two modules: a\ngoal-prediction model that maps commands to goal representations, and an\nexecution model that maps goal representations to policies. The second module is\ntrained without command supervision via a goal exploration process, while the\nfirst module is trained supervisedly in a metric learning framework.\n\nThis paper contains an important core insight---much of what\'s hard about\ninstruction following is generic planning behavior that doesn\'t depend on the\nsemantics of instructions, and pre-learning this behavior makes it possible to\nuse natural language supervision more effectively. However, the paper also\ncontains a number of serious evaluation and presentation issues. It is obviously\nnot ready to publish (uncaptioned figures, paragraphs interrupted mid-sentence,\netc.) and should not have been submitted to ICLR in its present form.\n\nSUPERVISION AND COMPARISONS\n\nI found comparisons between supervision conditions in this paper difficult to\nunderstand. It is claimed that the natural language instruction following\napproaches described in the first paragraph ""require a large amount of human\nsupervision"" in the form of action sequences. This is not exactly true, as some\napproaches (e.g. Artzi 2013), can be trained with only task completion signals.\nMore problematically, all these approaches are contrasted with reinforcement and\nimitation learning approaches, which are claimed to use ""little human\nsupervision"". In fact, most of the approaches listed in this section use exactly\nthe same supervision---either action sequences (imitation learning) or task\ncompletion signals (reinforcement learning). Indeed, the primary distinction is\nthat the ""NLP-style"" approaches are typically evaluated on their ability to\ngeneralize to new instructions, while the ""RL-style"" approaches are evaluated on\nthe (easier) problem of fitting the complete instruction distribution as quickly\nas possible.\n\nThis confusion carries into the evaluation of the approach proposed in this\npaper, which is compared to RL and IL baselines. It\'s hard to tell from the\ntext, but it appears that this is an ""RL-style"" evaluation setting, where we\nonly care about rapid convergence rather than generalization. But the baselines\nare inadequately described, and it\'s not clear to me that they condition on the\ncommands at all. More significantly, it\'s not clear what an evaluation based on\n""timesteps"" means for a behavior-cloning approach---is this the number of\ndistinct trajectories observed? The number of gradient steps taken? Without\nthese explanations it is impossible to interpret the experimental results.\n\nGENERALITY OF PROPOSED APPROACH\n\nDespite the advantages of the high-level two-phase model proposed, the specific\nimplementation in this paper has two significant shortcomings:\n\n- No evidence that it works with real language: despite numerous claims\n  throughout the paper that the model is designed to interpret ""human\n  instructions"", it is revealed on p7 that these instructions consist of one or two\n  5-way indicator features. This is an extremely impoverished instruction space,\n  especially compared to the numerous papers cited in the introduction that make\n  use of large datasets of complex natural-language strings generated by human\n  annotators. The present experiments do not support the use of the word ""human""\n  anywhere in the paper.\n\n- No support for combinatorial action spaces. Even if we set aside the\n  distinctions between human-generated instructions and synthetic command\n  languages like used in Hermann Hill & al., the goal -> policy module is\n  defined by a buffer of cached trajectories and goal representations. While\n  this works for the simple environments considered in this paper, it cannot\n  generalize to real-world instruction-following scenarios where the number of\n  distinct goal configurations is too large to tractably enumerate. Again, this\n  is a shortcoming that existing approaches do not suffer from (given\n  appropriate assumptions about the structure of goal space), so the lack of\n  comparisons is problematic.\n\nCLARITY\n\nThe whole paper would benefit from copy-editing by an experienced English\nspeaker, but a few sections are particularly problematic:\n\n- The first paragraph of 4.1.1 is extremely difficult to understand What does\n  the fingertip do? What exactly is the action space?\n\n- The end of the second paragraph is also difficult to understand; after reading\n  it I still don\'t know what the extra ""position"" targets do.\n\n- 4.1.4 is cut off mid-way through a sentence.\n\n- last sentence of 4.2\n\nThe figures are also impossible to interpret: three of the four are captioned\n""overview of the proposed framework"", and none are titled.', 'This submission proposes a method for learning to follow instructions by splitting the policy into two stages: human instructions to robot-interpretable goals and goals to actions. The authors claim to achieve better data efficiency, adaptability, and generalization as compared to the baselines.\n\nHere are some comments/questions:\n- One of the biggest limitations of the proposed method is that it can only work for one-to-one or many-to-one mapping of instructions to goals. As I understand (please correct me if I am wrong), the method can not work for contextual instructions where the goal depends on the environment and the same instruction can map to different goals, such as \'Go to the largest/farthest object\'.\n- Another limitation of the method is that it requires a set of goals G, which is not trivial to obtain especially in partially observable environments such as embodied navigation in 3D space.\n- The experimental setup is unclear and several crucial details are missing:\n\t- ""An instruction for approaching one of the five targets in the arena is generated and passed to the agent at first."" -> how is the instruction generated?\n\t- There\'s no example of the environment or the instruction in the submission\n\t- ""Within the instruction become approaching more than one targets, one of two added targets is selected as internal targets pair with one of the remaining targets."" I do not understand this sentence. How are the targets generated in the trajectory-oriented task? How are the instructions generated in this task?\n- Experimental results are not convincing:\n\t- The introduction motivates the need for understanding human instructions and the abstract says \'Given a human instruction\', but I believe experiments do not have any human instructions.\n\t- All the environments seem to be fully-observable, it is not clear whether the method would work in partially-observable environments.\n\t- Only vanilla PPO and BC cloning are used as baselines. There are several competing methods for following instructions which the authors cite such as Hermann et al. 2017, Chaplot et al. 2017, Misra et al. 2017, etc. Why weren\'t any of these approaches used as a baseline?\n- The submission requires proof-reading, there are several typos in the manuscript (some are listed below), some of them make it very difficult to understand the setting.\n\n- Typos:\n- Sec 3.1 on Pg 4 mentions \'CEM\' multiple times, it\'s not defined until 3.3.2 on Pg 6.\n- Pg 3 Theses sets -> These sets\n- Pg 7 where the Reacher pointing at -> where the Reacher is pointing at\n- Pg 7 What reacher observes the word is its fingertip’s position, coordinates in two dimension. -> something is wrong in this sentence.\n- Pg 7 Then comes to the trajectory-oriented task, there are only a few differences from above -> something is wrong in this sentence.\n- Pg 7 Within the instruction become approaching more than one targets -> something is wrong here', 'The paper proposes a modular approach to the problem of mapping instructions to robot actions. The first of two modules is responsible for learning a goal embedding of a given instruction using a learned distance function. The second module is responsible for mapping goals from this embedding space to control policies. Such a modular approach has the advantage that the instruction-to-goal and goal-to-policy mappings can be trained separately and, in principle, allow for swapping in different modules. The paper evaluates the method in various simulated domains and compares against RL and IL baselines.\n\nSTRENGTHS\n\n+ Decoupling instruction-to-action mapping by introducing goals as a learned intermediate representation has advantages, particularly for goal-directed instructions. Notably, these together with the ability to train the components separately will generally increase the efficiency of learning.\n\n\nWEAKNESSES\n\n- The algorithmic contribution is relatively minor, while the technical merits of the approach are questionable.\n\n- The goal-policy mapping approach would presumably restrict the robot to goals experienced during training, preventing generalization to new goals. This is in contrast to semantic parsing and symbol grounding models, which exploit the compositionality of language to generalize to new instructions.\n\n- The trajectory encoder operates differently for goal-oriented vs. trajectory-oriented instructions, however it is not clear how a given instruction is identified as being goal- vs. trajectory-oriented.\n\n- While there are advantages to training the modules separately, there is a risk that they are reasoning over different portions of the goal space.\n\n- A contrastive loss would seemingly be more appropriate for learning the instruction-goal distance function.\n\n- The goal search process relies on a number of user-defined parameters\n\n- The nature of the instructions used for experimental evaluations is unclear. Are they free-form instructions? How many are there? Where do they come from? How different are the familiar and unfamiliar instructions?\n\n- Similarly, what is the nature of the different action spaces?\n\n- The domains considered for experimental evaluation are particularly simple. It would be better to evaluate on one of the few common benchmarks for robot language understanding, e.g., the SAIL corpus, which considers trajectory-oriented instructions.\n\n- The paper provides insufficient details regarding the RL and IL baselines, making it impossible to judge their merits.\n\n- The paper initially states that this distance function is computed from learned embeddings of human demonstrations, however these are presumably instructions rather than demonstrations.\n\n- I wouldn\'t consider the results reported in Section 4.5 to be ablative studies.\n\n- The paper incorrectly references Mei et al. 2016 when stating that methods require a large amount of human supervision (data annotation) and/or linguistic knowledge. In fact Mei et al. 2016 requires no human annotation or linguistic knowledge.\n\n- Relevant to the discussion of learning from demonstration for language understanding is the following paper by Duvallet et al.\n\nDuvalet, Kollar, and Stentz, ""Imitation learning for natural language direction following through unknown environments,"" ICRA 2014\n\n- The paper is overly verbose and redundant in places.\n\n- There are several grammatical errors\n\n- The captions for Figures 3 and 4 are copied from Figure 1.']","[-60, -50, -50]","[20, 20, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, including 'serious evaluation and presentation issues', stating it is 'obviously not ready to publish', and pointing out multiple shortcomings. However, they do acknowledge an 'important core insight', preventing the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I found... difficult to understand' rather than more accusatory language, and provide specific, constructive feedback. The reviewer also acknowledges positive aspects before delving into criticisms, which is a polite approach. However, some statements like 'should not have been submitted to ICLR in its present form' are quite blunt, preventing a higher politeness score."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several limitations and issues with the submission. The reviewer expresses concerns about the method's applicability, experimental setup, and results. However, it's not entirely negative as the reviewer asks for clarification on some points, suggesting room for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'please correct me if I am wrong' and phrase their comments as questions or suggestions rather than harsh statements. The reviewer also provides constructive feedback by pointing out specific areas for improvement and typos. The tone is professional and objective, avoiding personal attacks or overly harsh language."", ""The sentiment score is -50 because while the review acknowledges some strengths of the paper, it lists significantly more weaknesses than strengths. The reviewer points out several major issues with the methodology, experimental setup, and claims made in the paper. However, it's not entirely negative as it does recognize some positive aspects.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use neutral language to describe the weaknesses without being overly harsh or personal. The reviewer also starts by highlighting the strengths before moving on to the weaknesses, which is a polite approach. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many softening phrases or particularly polite language.""]"
"[""Summary: The authors present a network which facilitates cross-domain\nlearning for SLU tasks where the the goal is to resolve intents and\nslots given input utterances. At a high level, the authors argue that\nby fine-tuning a pre-trained version of the network on a small set of\nexamples from a target-domain they can more effectively learn the\ntarget domain than without transfer learning.\n\nFeedback:\n\n* An overall difficulty with the paper is that it is hard to\ndistinguish the authors' contributions from previous works. For\nexample, in Section 3.1, the authors take the model of Goyal et al. as\na starting point but explain only briefly one difference\n(contatenating hidden layers). In Section 3.2 the contributions\nbecomes even harder to disentangle. For example, how does this section\nrelate to other word-embeddings papers cited in this section? Is the\nproposed method a combination of previous works, and if not, what are\nthe core new ideas?\n\n* Some sections are ad-hoc and should be justified/explained\nbetter. For example, the objective, which ultimately determines the\ntrained model behaviour uses a product of experts formulation, yet the\nauthors do not discuss this. Similarly, the overarching message, that\nby fine-tuning a suitable model initialisation using small amounts of\ndata from the target domain is fairly weak as the authors do not\ndetail exactly how the model is fine-tuned. Presumably, given only a\nsmall number of examples, this fine-tuning runs the risk of\noverfitting, unless some form of regularisation is applied, but this\nis not discussed.\n\n* Lastly, there are some curious dips in the plots (e.g., Figure 2 bottom left, Figure 3 top left, bottom left), which deserve more explanation. Additionally, the evaluation section could be improved if the scores were to show error-bars. \n\nMinor: All plots should be modified so they are readable in grey-scale."", 'In this paper, an efficient SLU model, called as TSSM, is proposed to tackle the problem of insufficient training data for the task of spoken language understanding. TSSM considers the intent and slot detection as a unified multi-objective optimization problem which is addressed by a meta-learning scheme. The model is pre-trained on a large dataset and then fine-tuned on a small target dataset. Thus, the proposed TSSM can improve the model performance on a small datatset in new domains.\n\nPros:\n1)\tThe transfer learning of spoken language understanding is very interesting.\n2)\tThe proposed TSSM can integrate the task of intents and slots and take the relationship between intents and slots into consideration.\n3)\tFive datasets are used to evaluate the performance of the method.\n\nCons:\nOverall, the novelty of this paper is incremental and some points are not clear. My main concerns are listed as follows.\n1)\tThe authors state that the knowledge transfer is the main contribution of this paper. However, as introduced in 3.5, the transfer scheme in which the model is first pre-trained on a large dataset and then fine-tuned on a small target dataset is very straightforward. For example, currently, almost all methods in the area of object recognition are pre-trained on ImageNet and then fine-tuned on a small dataset for particular tasks.\n2)\tAuthors also state that improvements for transferring from Restaurant, Laptop, TV, Atis to Hotel is not obvious. I think the results also need to be reported and the reasons why the improvement is not obvious should be provided and discussed.\n3)\tThe paper needs more proofreading and is not ready to be published, such as “A survey fnor transfer” and “a structured multi-objective optimization problems”.\n', 'This paper focuses on dealing with a scenario where there are ""unseen"" intents or slots, which is very important in terms of the application perspective.\n\nThe proposed approach, TSSM, tries to form the embeddings for such unseen intents or slots with little training data in order to detect a new intent or slot in the current input.\nThe basic idea in the model is to learn the representations of utterances and intents/slots such that utterances with the same intents/slots are close to each other in the learned semantic space.\nThe experiments demonstrate the effectiveness of TSSM in the few-shot learning scenarios.\nThe idea about intent embeddings for zero-shot learning is not fully original (Chen, et al., 2016), but this paper extends to both intent classification and slot filling. \n\nThe paper tests the performance in different experimental settings, but the baselines used in the experiments are concerned.\nThis paper only compares with simple baselines (MaxEntropy, CRF, and basic DNN), but there should be more prior work or similar work that can be used for comparison in order to better justify the contributions of the model.\nIn addition, this paper only shows the curves and numbers in the experiments, but it is better to discuss some cases in the qualitative analysis, which may highlight the contributions of the paper.\nAlso, in some figures of Fig. 2, the proposed TSSM is not better than DNN, so adding explanation and discussion may be better.\n']","[-50, -20, 20]","[50, 50, 50]","[""The sentiment score is -50 because the review is generally critical, pointing out several areas for improvement, but not entirely negative. The reviewer acknowledges the authors' work and provides constructive feedback. The politeness score is 50 because the language used is professional and respectful, offering suggestions rather than harsh criticisms. The reviewer uses phrases like 'could be improved' and 'should be justified/explained better', which are polite ways of pointing out weaknesses. The review maintains a balanced tone, discussing both the paper's content and areas for improvement without being overly negative or confrontational."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros') of the paper, they express more significant concerns ('cons') about the novelty and clarity of the work. The reviewer states that 'the novelty of this paper is incremental and some points are not clear,' which indicates a generally negative sentiment towards the paper's contribution. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present their critique in a constructive manner, using phrases like 'My main concerns are' rather than harsh or dismissive language. The reviewer also balances their critique by acknowledging the positive aspects of the paper before presenting their concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the paper's focus and the effectiveness of the proposed approach in experiments. However, they also point out some concerns and areas for improvement, which tempers the overall positivity. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and offers constructive criticism without harsh or rude phrasing. They acknowledge the paper's strengths before suggesting improvements, which is a polite approach to reviewing. The reviewer also uses phrases like 'it is better to' and 'may be better' when making suggestions, which maintains a respectful tone.""]"
"[""This paper presents a framework to train an end-to-end multi-lingual multi-speaker speech recognition system. Overall, the paper is quite clear written.\n- Strengthens:\n+ Experimental results show consistent improvements in speech recognition performance and language identification performance.\n\n- Weakness:\n+ I'm not sure whether the framework is novel. The authors have just mixed training data from several languages to train an end-to-end multi-speaker speech recognition system.\n+ I don't see the real motivation why the authors want to make the task harder than needed. The example provided in figure 1 is very rare in reality.\n+ The authors claimed that their system can recognise code-switching but actually randomly mixing data from different languages are not code-switching.\n+ In general, it would be better to have some more analyses showing what the system can do and why."", ""The authors propose to build a speech recognition system that has been trained to recognize a recording that has been produced by mixing multiple recordings from different languages together, and allowing for some code switching (also done artificially by concatenating different recordings).\n\nWhile this sounds fancy and like a hard problem, it is in fact easier than recognizing two speakers that have been mixed together speaking the same language, which has already been solved in (Seki, 2018a), from what I can tell. I don't see any contribution in this paper, other than explaining how to create an artificial (un-realistic) database of mixed speech in multiple languages, and then training a multi-speaker end-to-end speech recognition system on that database.\n"", 'This paper presents an end-to-end system that can recognize single-channel multiple-speaker speech with multiple languages.\n\nPros:\n- The paper is well written.\n- It shows the existing end-to-end multi-lingual ASR (Seki et al., 2018b) and end-to-end multi-speaker ASR (Seki et al., 2018a) techniques can be combined without any change to achieve reasonable performance.\n- It demonstrates the challenge of single-channel multi-lingual multiple-speaker speech recognition, and compares the performance of the multiple-speaker system on the mixed speech and the single-speaker system on the isolated speech.\n\nCons:\n- It lacks novelty: the proposed framework just simply combines the two existing techniques as mentioned above.\n- The training and evaluation data are both artificially created by randomly concatenating utterances with different languages from different speakers with different context. I am not sure of how useful the evaluation is, since this situation is not realistic. Also, currently it cannot test the real code-switching since the utterances are not related and not from the same speaker.\n- There are not enough analyses. E.g. it would be good to analyze what contributes to the gap between the single-speaker ASR system performance on the isolated speech and the multi-lingual multi-speaker ASR system on the mixed speech. How well does the proposed end-to-end framework perform compared to a two-step framework with speaker separation followed by multi-lingual single-speaker ASR?']","[-20, -70, -20]","[50, -20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths (experimental results showing improvements), they express several concerns about the novelty, motivation, and depth of analysis in the paper. The overall tone suggests more weaknesses than strengths. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases criticisms as observations or questions rather than direct attacks. They begin with a positive comment about the paper being 'quite clear written' and use phrases like 'I'm not sure' and 'It would be better' instead of more confrontational language."", ""The sentiment score is -70 because the reviewer expresses a strongly negative opinion about the paper's contribution. They state that the problem addressed is 'in fact easier' than existing solved problems and that they 'don't see any contribution in this paper.' This indicates a significant lack of perceived value in the work. The politeness score is -20 because while the language isn't overtly rude, it's quite dismissive. Phrases like 'While this sounds fancy' and 'I don't see any contribution' come across as somewhat condescending and blunt, lacking the constructive tone typically expected in peer reviews. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or extremely harsh language, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'reasonable performance'), they also highlight significant cons such as lack of novelty and concerns about the usefulness of the evaluation. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses neutral, professional language throughout. They present both pros and cons in a balanced manner, and phrase criticisms as suggestions for improvement rather than harsh judgments. The use of phrases like 'It would be good to...' indicates a constructive approach.""]"
"['The paper proposes W2GAN, a GAN where the objective function relies on a W2 distance. Authors state that the discriminator approximate the W2 distance, and that the generator follows an OT map. \nWhile I did not see any flaws in the development, the paper is quite bushy and hard to follow. Some questions are still open, for instance in the end of the experiments, authors state that the model has ""a strong theoretical advantages"": can you provide more details about those advantages?\nThe experiments do not show any clear advantages of the method regarding competitors. Regarding Table 1, why are there some points with no arrows? W2-OT seems not to perform better: are there some other advantages (computational?) to use the method? In Figure 1, it is quite difficult to evaluate the results on a single image with no comparisons. Again, providing a strong evaluation of the method would help to strengthen the paper. \n\nThere are some weird statements and typos mistakes that should be corrected. For example in the first 2 pages: (abstract) ""other GANs also approximately following the Optimal Transport"", (Introduction) ""An optimal map has many important implications such as computing barycenters"", ""high-dimenisonal"", ""generator designed"", ""consideral"", ""although the theoretical arguments do not scale immediately"".\nThe layout of the bibliography should be deeply reviewed.\n\n', ""The paper W2GAN describes a method for training GAN and computing an optimal transport (OT) map\nbetween distributions. As far as I can tell, it is difficult to identify the original contributions\nof the paper. Most results are known from the OT community. The differences with the work of Seguy, 2018\nis also not obvious. I encourage the authors to establish more clearly the differences of their work\nwith this last reference. Most of the theoretical considerations of Section 3 is either based on \nunrealistic assumptions (case 1) or make vague assumptions 'if we ignore the possibly significant effect ...'\nthat seem unjustified so far. Experimental results do not show evidences of superiority wrt. existing works.  \nAll in all I would recommend the authors to better focus on the original contribution of their works wrt.  \nstate-of-the-art and explain why the theoretical analysis on convergence following a geodesic path in a \nWasserstein space is valuable from a practical view. Finally, I did not understand the final claim of the \nAbstract : 'Perhaps surprisingly, we also provide empirical evidence that other GANs also approximately following\nthe Optimal Transport.'. What are those empirical evidences ? It seems that this claim is not supported somewhere \nelse in the paper.\n\nMinor remarks:\n - regarding the penalization in eq. (5), the expectation is not for all x and y \\in R^2, but for x drawn from \\mu and y from \\nu.\n   Same for L_2 regularization\n - Proposition 1 is mainly due to Brenier\nBrenier, Y. (1991). Polar factorization and monotone rearrangement of vector‐valued functions. Communications on pure and applied mathematics, 44(4), 375-417.\n - from Eq (7), you should give precisely over what the expectations are taken.\n - Eq (10) : how do you inverse sup and inf ? \n - when comparing to Seguy 2018, are you using an entropic or a L_2 regularization ? How do you set the regularization strength ?\n - where is Figure 2.a described in section 4.2 ? \n\nRelated works :\n - what is reference (Alexandre, 2018) ?  \n - regarding applications of OT to domain adaptation, there are several references on the subject. \n   See for instance \nCourty, N., Flamary, R., Tuia, D., & Rakotomamonjy, A. (2017). Optimal transport for domain adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9), 1853-1865.\nor \nDamodaran, B. B., Kellenberger, B., Flamary, R., Tuia, D., & Courty, N. (2018). DeepJDOT: Deep Joint distribution optimal transport for unsupervised domain adaptation. ECCV \nfor a deep variant.\n - Reference Seguy 2017 and 2018 are the same and should be fused. The corresponding paper\n   was published at ICLR 2018\n   Regarding this last reference, the claim 'As far as we know, it is the first demonstration of a GAN achieving reasonable generative modeling results and an approximation of the optimal transport map between two continuous distributions.' should maybe be lowered ? "", '\npros\n\n- formal approach to the problem and a clear understanding of what is missing (Section 6.6); I appreciated Section 3 at large in particular.\n\n- I like Theorem 1 and Corollary 1. Is it is possible to reason about an imperfect generator class and undertrained discriminator, and get sufficient conditions for convergence (not necessarily exponential) ?\n\n\ncons\n\n- In Proposition 1, I suspect that p > 2 (see below), which makes the p=2 choice a limit case of the proposition.\n\n- The paper should have cited the paper https://arxiv.org/pdf/1710.05488.pdf which goes along similar lines in its Section 3 and make proper comparisons.\n\n - experimental results do not do a great favour to the technique proposed: in Table 1, W2-OT is not better than Barycentric-OT (see spiral); in Table 2, W2GAN is not better than WGAN-LP; Figure 1-a is maybe the only Figure with a clearcut advantage. However, the CIFAR examples in Figure 1b look quite bad after zooming. Do the authors have more experiments and comparisons on images ?\n\nDetail:\n\n* In proposition 1, (6), use the Holder conjugate of p: ||\\nabla||^{1(p-1)-1} =1/||\\nabla||^{2-q}. Also better to understand as $q\\leq 2$. \n\n* looking at the proof of proposition 1, I do not know how you derive the inverse gradient, but I suspect you need in fact $p>2$, which also implies $q<2$ above.\n\n* Sentence after (10) grammatically incorrect\n\n* In the interpretation of the equation after (16), isn’t is possible to interpret the Jacobian terms as a geometric tweak for the update of G ?\n\n* Lots of mistakes in references: Mistake in the first ref in references, many @JOURNAL/CONF titles do not appear.\n']","[-20, -60, -20]","[20, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer doesn't see any flaws in the development, they express concerns about the paper being 'bushy and hard to follow', lack of clear advantages over competitors, and the need for stronger evaluation. The reviewer also points out several typos and weird statements that need correction. However, the tone is not entirely negative, as they ask for clarifications and suggest improvements rather than outright rejecting the work. The politeness score is slightly positive (20) because the reviewer uses relatively neutral language and phrases criticisms as questions or suggestions ('can you provide more details', 'providing a strong evaluation... would help'). They also acknowledge the absence of major flaws. However, the review doesn't go out of its way to be overtly polite or complimentary, maintaining a professional tone throughout."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that it's difficult to identify original contributions, questions the theoretical considerations, and notes that experimental results don't show superiority over existing work. They also express skepticism about claims made in the abstract. However, it's not entirely negative as they do provide suggestions for improvement.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone. They use phrases like 'I encourage the authors' and 'I would recommend the authors' which are constructive rather than dismissive. The reviewer also provides specific feedback and suggestions for improvement, which is helpful and courteous. However, the overall tone is more neutral than overtly polite, hence the modest positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some positive aspects ('pros' section, appreciation for certain parts), there are more critical points raised in the 'cons' section and details. The reviewer points out issues with experimental results, missing citations, and potential errors in proofs. The politeness score is moderately positive (50) as the reviewer uses professional language, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I appreciated', 'I like', and provide specific suggestions for improvement rather than harsh criticism. The review maintains a balanced and respectful tone throughout, even when pointing out flaws.""]"
"['The paper applies graph convolutional networks to Penn Treebank language modeling and provides analysis on the attention weight patterns it uses.\n\nClarity: the paper is very clearly written!\n\nThe introduction states that existing CNN language models are ""not easily interpretable in that they do not explicitly learn the structures of sentences"". Why is this? The model in this paper computes attention values which is interpreted by the authors as corresponding to the structure of the sentence but there are equivalent means to trace back feature computation in other network topologies as well.\n\nMy biggest criticism is that the evaluation is done on a very small language modeling benchmark which is clearly out of date. Penn Treebank is the CIFAR10 of language modeling and any claims on this dataset about language modeling are highly doubtful. Models today have tens and hundreds of millions of parameters and training them on 1M words is simply a regularization exercise that does not enable a meaningful comparison of architectures.\n\nThe claims in the paper could be significantly strengthened by reporting results on at least a mid-size dataset such as WikiText-103, or better even, the One Billion Word benchmark.', ""This work proposes a CNN based language model based on graph neural networks. Basic idea is to compute adjacency matrix for an entire sentence in parallel for faster computation. Empirical results show probably the best performance among CNN approaches but still lags behind the best RNNs.\n\nPros:\n\n- A new network based on graph neural networks.\n\nCons:\n\n- The proposed model needs to recompute attention probabilities for each step and it might incur latencies. I'd like to know how slow it is when compared with other CNN approaches and how fast it is when compared with other RNNs.\n\n- Lacking experiments. This paper shows only a single table comparing other approaches, and does not present any ablation studies. Note that section 4.4 mentions some details, but does not show any numbers to justify the claim, e.g., why choosing the window size of 10, 20, 30, 40.\n\n- This paper claims that the learned model captures the ground truth parse tree in section 4.3. However, this work simply picks a single example in section 5.3 to justify the claim. I'd recommend the author to run a parser to see if the proposed attention mechanism actually capture the ground truth parse trees or not."", ""This paper draws inspiration from recent works on graph convolutional networks and proposes GTCN, a convolutional architecture for language modeling. The key intuition is to treat sentences as (potentially densely-connected) graphs over tokens, instead of sequences as in many RNN-based language models. The model then, when predicting a token, summarizes previous tokens using attention mechanism as context. Empirical evaluation on word-level language modeling on Penn Treebank shows competitive performance.\n\nThe idea of this work appears reasonable and well-motivated to me. But the connections to previous works, especially those based on self-attention, should be clearly addressed. Further, writing can be improved, and I would encourage a thorough revision since there are typos making the paper a bit hard to follow.\nLast but not least, I find several of the claims not very-well supported. Please see details below.\n\nPros:\n- Well-motivated intuition treating language as structured.\n\nCons:\n- Writing can be improved.\n- Missing discussion of existing works. \n\nDetails:\n\n- Based on my understanding of Eqs. 6--11, the proposed GTCN seems to be a gated version (also equipped with window-2 convolutions) of the self-attention mechanism. Could the authors comment on how GTCN relates to Vaswani et al. (2017), Salton et al. (2017), among others? Also, empirical comparisons to self-attention based language models might be necessary.\n\n- I was confused by Eqs. 13--14 and the text around it. Doesn't one need some kind of classifier (e.g., an MLP) to predict x_{t+1}? Why are these two equations predicting word embedding?\n\n- The start of Section 4.1. There seems to be a typo here. I'm assuming the two vectors are `$\\mathbf{v}$ and $\\mathbf{q}$` here, as in Eqs. 6 and 7.\n\n- More clarification on Eq. 9 might be necessary. Is \\mathbf{W}^p part of the parameters? I'm guessing \\mathbf{W}_{i-j}^p selects a row from the matrix, since there is a dot product outside.\n\n- Can the authors clarify Eq. 5? I'm not sure how to interpret it, and it seems not used anywhere else.\n\n- Eq. 2 is a bit misleading: it might give the impression that f_{t+1} does not depend on f_t (and so forth), which is not the case for LSTM.\n\n- It would be interesting to be how GTCN compare to other models in efficiency, since the paper mentions parallel computation many times.\n\n- Contribution.2: GTCN is not really the state-of-the-art model on LM.\n\n- Comparison to RNNG: RNNG treats each sentence as a separate sequence, in contrast to most cited works in Table 1, where the whole training (eval) set is treated as a single sequence, and truncate the length when applying BPTT. And according to the second paragraph of Section 5.1, this work follows the latter. To the best of my knowledge, such a difference does have an effect on the perplexity metric. In this sense, RNNG is not comparable to the rest in Table 1. It is perhaps fine to still put it in the table, but please clarify it in the text.\n\nMinors:\n\n- Why is the margins above equations seem larger. Can the authors make sure the template is right?\n\n- Around Eq.5: why is \\mathbf{X} is capitalized in the eq, but not in the text? Are they the same thing?\n\n- Section 4.3: the dependence of attention weights $a$ is not reflected in the notation.\n\n- Section 5.1: I think what it means here is a `10K` vocabulary, instead of a 10K word tiny corpora.\n\n\nReferences\n\nVaswani et al.. 2017. Attention is All You Need. In Proc. of NIPS.\n\nSalton et al.. 2017. Attentive Language Models.""]","[-20, -20, -20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very clearly written'), they express significant criticism about the evaluation methodology and dataset choice. The reviewer suggests that the claims could be 'significantly strengthened' by using more up-to-date and larger datasets, indicating that the current work has notable limitations. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'My biggest criticism is...' and 'The claims could be significantly strengthened by...' which maintain a professional and courteous tone while providing feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('probably the best performance among CNN approaches'), they also list several significant concerns and areas for improvement. The cons outweigh the pros, indicating a somewhat negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions for improvement rather than harsh criticism. Phrases like 'I'd like to know' and 'I'd recommend' contribute to the polite tone. The reviewer also acknowledges the positive aspects of the work before diving into the criticisms, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-motivated intuition'), they express several concerns and areas for improvement. The review lists more cons than pros and points out multiple issues with the paper's content and presentation. However, it's not overwhelmingly negative, as the reviewer sees potential in the work. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, often phrasing criticisms as suggestions or questions ('Could the authors comment on...', 'It would be interesting to see...'). They also balance criticism with positive remarks. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, which contributes to the politeness score.""]"
"['\n-------------\nSummary\n-------------\nThe authors propose to train a policy while concurrently learning a dynamics model. In particular, the policy is updated using both the RL loss (rewards from the environment) and the ""consistency constraint"", which the authors introduce. This consistency constraint is a supervised learning signal, which compares trajectories in the environment with trajectories in the imagined world (produced with the dynamics model). \n\n---------------------\nMain Feedback\n---------------------\nI feel like there might be some interesting ideas in this work, and the results suggest that this approach performs well. However, I had a difficult time understanding how exactly the method works, and what its advantages are. These are my main questions:\n\n1) At the beginning of Section 4 the authors write ""The learning agent has two pathways for improving its behaviour: (...) (ii) the open loop path, where it imagines taking actions and hallucinates the state transitions that could happen"". Do you actually do this? This is not mentioned in anywhere. And as far as I understand, the reward function is not learned - hence there will be no training signal in the open loop path. Does the reward signal always come from the true environment?\n2) Is the dynamics model used for anything else than action-selection during training? Planning? If not, I don\'t really understand the results and why this works at all (k=20 being better than k=5, for example).\n3) Is the dynamics model pre-trained in any way? I find it surprising that the model-free method and the proposed method perform similar at the beginning (Figure 3). If the agent chooses its actions based on the state that is predicted by the dynamics model, this should throw off the learning of the policy at the beginning (when the dynamics model hasn\'t learned anything sensible yet).\n\n-----------------------\nOther Questions\n-----------------------\n4) How exactly does training without the consistency constraint look? Is this the same as k=1?\n5) Could the authors comment on the evaluation protocol in the experimental section? Are the results averages over multiple runs? If so, it would help to see confidence intervals to make a fair assessment of the results. \n6) For the swimmer in Figure 2, the two lines (with consistency and without consistency) start at different initial returns, why is that so? If the same architecture and seed was used, shouldn\'t this be the same (or can you just not see it in the graph)?\n\n---------\nClarity\n---------\nThe title and introduction initially gave me a slightly wrong impression on what the paper is going to be about, and several things were not followed up on later in the paper.\nTitle:\n8) ""generative models"" reminds of things like a VAE or GAN; however, I believe the authors mean ""dynamics models"" instead\n9) ""by interaction"" is a bit vague as to what the contribution is (aren\'t policies and dynamic models in general trained by interacting with the environment?); the main idea of the paper is the consistency constraint\nAbstract / Introduction:\n10) The authors talk about humans carrying out ""experiments via interaction"" to help uncover ""true causal relationships"". This idea is not brought up again in the methods section, and I don\'t see evidence that with the proposed approach, the policy does targeted experiments to uncover causal relationships. It is not clear to me why this is the intuition that motivates the consistency constraint. \n11) As the authors state in the introduction, the hope of model-based RL is better sample complexity. This is usually achieved by using the model in some way, for example by planning several steps ahead when choosing the current action. Could the authors comment on where they would place their proposed method - how does it address sample complexity?\n12) In the introduction, the authors discuss the problem of compounding errors. These must be a problem in the proposed method as well, especially as k grows. Could the authors comment on that? How come that the performance is so good for k=20?\n13) The authors write that in most model-based approaches, the dynamics model is ""learned with supervised learning techniques, i.e., just by observing the data"" and not via interaction. There\'s two things I don\'t understand: (1) in the existing model-based approaches the authors refer to, the policy also interacts with the world to get the data to do supervised learning - what exactly is the difference? (2) The auxiliary loss ""which explicitly seeks to match the generative behaviour to the observed behaviour"" is just a supervised learning loss as well, so how is this different?\n\nFor me, it would help the readability and understanding of the paper if some concepts were introduced more formally.\n14) In Section 2, it would help me to see a formal definition of the MDP and what exactly is optimised. The authors write ""optimise a reward signal"" and ""maximise its expected reward"", however I believe it should be the expected cumulative reward (i.e., return). \n15) The loss function for the dynamics model is not explicitly stated. From the text I assume that it is the mean squared error for the per-step loss, and a GAN loss for the trajectory-wise loss.\n16) Could the authors explicitly state what the overall loss function is, and how the RL and supervised objective are combined? Is the dynamics model f trained only on the supervised loss, and the policy pi only on the RL loss?\n17) In 2.3 the variable z_t is not formally introduced. What does it represent?\n\n------------------------\nOther Comments\n------------------------\n18) I find it problematic to use words such as ""hallucination"" and ""imagination"" when talking about learning algorithms. I would much prefer to see formal/factual language (like saying that the dynamics model is used to do make predictions / do planning, rather than that the agent is hallucinating). \n\n-- edit (19.11.) ---\n- updated score to 5\n- corrected summary', '---Below is based on the original paper---\nThis paper presents a framework that allows the agent to learn from its observations, but never follows through on the motivation of experimentation---taking actions mainly for the purpose of learning an improved dynamics model. All of their experiments merely take actions that are best according to the usual model-based or model-free methods, and show that their consistency constraint allows them to learn a better dynamics model, which is not at all surprising. They do not even allow for the type of experimentation that has been done in reinforcement learning for as long as it has been around, which is to allow exploration by artificially increasing the reward for the first few times that each state is visited. That would be a good baseline against which to compare their method.\n\nOverall:\nPros:\n1. Clear writing\n2. Good motivation description.\n\nCons:\n1. Failed to connect presented work with the motivation.\n2. No comparison against known methods for exploration.\n\n\n----Below is based on the revision---\n\nThanks to the reviewers for making the paper much clearer. I have no particular issues on the items that are in the paper. However, subsections 7.2.1 and 7.2.2 are missing.', '\nSummary:\n\nThis paper presents a simple auxiliary loss term for model-based RL that attempts to enforce consistency between observed experience trajectories and hallucinated rollouts.  Simple experiments demonstrate that the constraint slightly improves performance.\n\nQuality:\n\nWhile I think the idea of a consistency constraint is probably reasonable, I consider this a poorly executed exploration of the idea.  The paper makes no serious effort to compare and contrast this idea with other efforts at model-based RL.  The most glaring omission is comparison to very old ideas (such as dyna) and new ideas (such as imagination agents), both of which they cite.\n\nClarity:\n\nThe paper is reasonably clear, although there are some holes.  For example, in the experimental section, it is unclear what model-based RL algorithm is being used, and how it was modified to support the consistency constraint.  (I did not read the appendix).\n\nOriginality:\n\nIt is not clear how novel the central idea is.\n\nSignificance:\n\nThis idea is not significant.\n\nPros:\n+ A simple, straightforward idea\n+ A good topic - progress in model-based RL is always welcome\n\nCons:\n- Unclear how this is significantly different from other related work (such as imagination agents)\n- Experimental setup is poorly executed.\n  - Statistical significance of improvements is unclear\n  - No attempt to relate to any other method in the field\n  - No explanation of what algorithms are being used\n']","[-30, -50, -60]","[50, 20, -20]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting ideas and good results, they express significant confusion about the method and its advantages. They have many questions and concerns, indicating a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'Could the authors comment on...' and 'It would help me to see...', which are polite ways of requesting clarification or changes. However, the review isn't overly deferential, maintaining a professional tone, so it's not at the highest end of politeness."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out significant shortcomings in the methodology and lack of comparison with existing methods. However, it's not entirely negative as it acknowledges some positive aspects like clear writing and good motivation description. The politeness score is 20 because while the reviewer's tone is professional and not overtly rude, it's also quite direct in its criticism. The reviewer does use polite phrases like 'Thanks to the reviewers' in the revision section, which slightly elevates the politeness score. The reasoning behind these scores is based on the critical nature of the comments balanced against the few positive remarks and the professional, albeit direct, language used throughout the review."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that it's a 'poorly executed exploration of the idea', makes 'no serious effort to compare and contrast', has 'glaring omissions', and is 'not significant'. The few positive comments ('simple, straightforward idea', 'good topic') are outweighed by the criticisms. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and critical without much attempt to soften the feedback. Phrases like 'poorly executed' and 'not significant' are particularly harsh. The reviewer does not use polite language or offer encouragement, which contributes to the slightly negative politeness score.""]"
"[""This paper considers reinforcement learning tasks that have high-dimensional space, long-horizon time, sparse-rewards. In this setting, current reinforcement learning algorithms struggle to train agents so that they can achieve high rewards. To address this problem, the authors propose an abstract MDP algorithm. The algorithm consists of three parts: manager, worker, and discoverer. The manager controls the exploration scheduling, the worker updates the policy, and the discoverer purely explores the abstract states. Since there are too many state, the abstract MDP utilize the RAM state as the corresponding abstract state for each situation. \n\nThe main strong point of this paper is the experiment section. The proposed algorithm outperforms all previous state of the art algorithms for Montezuma’s revenge, Pitfall!, and Private eye over a factor of 2. \n\nIt is a minor weak point that the algorithm can work only when the abstract state is obtained by the RAM state. In some RL tasks, it is not allowed to access the RAM state. \n\n================================\nI've read all other reviewers' comments and the response from authors, and decreased the score. Although this paper contains interesting idea and results, as other reviewers pointed out, it is very hard to compare with other algorithm. I agree to other reviewers. The algorithm assumptions are strong. "", 'This paper considers how to effectively perform exploration in the setting where a difficult, high-dimensional MDP can be mapped to a simpler, lower-dimensional MDP. They propose a hierarchical approach where a model of the abstract MDP is incrementally learned, and then used to train sub-policies to transition between abstract states. These sub-policies are trained using intrinsic rewards for transitioning to the correct state, and the transition probabilities in the abstract MDP reflect how well a sub-policy can perform the transition. \n\nThe approach is evaluated on three difficult Atari games, which all require difficult exploration: Montezuma\'s Revenge, Pitfall and Private Eye, and is shown to achieve good performance in all of them. Furthermore, the model can be used to generalize to new tasks by changing the rewards associated with different transitions. \n\nThe main downside with this paper is that the mapping from original state (i.e. pixels) to the abstract state is assumed to be known beforehand, which requires prior knowledge. The authors hardcode this mapping for each of the games by fetching the relevant bits of information from RAM. This prevents fair comparison to many other methods which only use pixels, and makes this paper borderline rather than strong accept. \n\n\nQuality: the method is evaluated on difficult problems and shown to perform well. The experiments are thorough and explore a variety of dimensions such as robustness to stochasticity, granularity of the abstract state and generalization to new tasks. The approach does strike me as rather complicated though - it requires 19 (!) different hyperparameters as shown in table 2. The authors do mention that many of these did not require much tuning and they intend on making their code public. Still, this suggests that re-implementation or extensions by others may be challenging. Are all of these moving parts necessary?\n\nClarity: the paper is well-written, for the most part clear, and the details are thoroughly described in the appendix. \n\nOriginality: this approach in the context of modern deep learning is to my knowledge novel.\n\nSignificance: This paper provides a general approach for hierarchical model-based planning when the mapping from the hard MDP to the easy one is known, and in this sense is significant. It is limited by the assumption that the mapping to abstract states is known. I suspect the complexity of the approach may also be a limiting factor. \n\nPros:\n+ good results on 3 challenging problems\n+ effective demonstration of hierachical model-based planning\n\nCons:\n- requires significant prior knowledge for state encoding\n- complicated method\n\nMinor:\n- in the intro, last paragraph: ""Our approach significantly outperforms previous non-demonstration SOTA approaches in all 3 domains"". Please specify that you use extra knowledge extracted from RAM, otherwise this is misleading. \n- Algorithm 1: nagivate -> navigate\n- Section 4, last sentence: broken appendix link. \n- Bottom of page 6: ""Recent work on contextual MDPs...as we do here"" is not a sentence. \n- In related work, it would be nice to mention some relevant early work by Schmidhuber on subgoal generation: http://people.idsia.ch/~juergen/subgoals.html\n\n\n\n*** Updated ***\n\nAfter reading the updated paper, responses, other reviews, and looking at related works more closely, I have changed my score to a 5. This is due to several factors. \n\nAlthough the paper\'s core idea is definitely interesting, the fact that they use hardcoded features, rather the standard setup which uses pixels, makes comparison to other methods much more complicated. In particular, I think that the comparison to DQN-PixelCNN is unfair, as this other method makes very few assumptions about the inputs (only that they are pixels). The authors sort of point this out in the main text, but this is somewhat misleading. They say ""PixelCNN uses less prior knowledge than our approach"". In fact, it uses as much prior knowledge as any RL method which operates on pixels. Granted, this is nonzero, but it\'s vastly less than what this paper\'s method assumes. The other comparison is to SOORL (which uses a different state encoding altogether). The comparison to SmartHash is fairer, although the variant of SmartHash they compare against is not the main method the paper proposes (a generic autoencoder-based state encoding which makes minimal assumptions about the input). It would have been better if the authors included experiments for their method using such a learned state encoding.\n\nReporting SOTA results on very hard tasks using extra hardcoded features or other domain knowledge is potentially misleading to the community as to how far along we are in solving these tasks, and extra care should be taken to put these results in context. Otherwise, for those not familiar with the subtleties, this makes it seem like these tasks are being solved when in fact they are not. My concern is that other works may then be asked to be compared against these artificially high results. Having many different task setups also makes comparison between different published works confusing in general. Other works (such as Ostrovski et al) have been able to make progress on these tasks while staying within the standard pixel-based framework.\n\nThese concerns would have been partially mitigated had the authors made it *very* clear that they were assuming substantial prior knowledge, which makes their method non-comparable to others which do not make this assumption. This could have been done in the introduction (which was one of my comments, but this was not included in the updated draft). I.e., something to the effect of ""We emphasize that our approach assumes substantially more prior knowledge than other approaches which operate only on pixels, and as such is not directly comparable with these approaches"". In addition, I would have liked if the authors had followed the suggestion of Reviewer 1 to include results in pixel space, even if negative, but this was not done either (using a simple autoencoder-based representation, like the one in the SmartHash paper, would have also been fine). As it is, statements such as ""Our approach achieves more than 2x the reward of prior non-demonstration SOTA approaches"" and ""our approach relies on some prior knowledge in the state abstraction function, although we compare against SOTA methods using a similar amount of prior knowledge in our experiments"" are quite misleading and unfair to other methods which do not assume access to prior knowledge (the second statement is untrue for the case of DQN-PixelCNN). \n\nAnother point which I had not noticed previously is the very high sample complexity (2 billion). One of the motivations behind model-based approaches is that they are supposed to be more sample efficient, but that does not seem to be the case here. \n', 'This paper deal with learning abstract MDPs for planning in tasks that require long-horizon due to sparse rewards.\nThis is an extremely important and timely topic in the RL community.\n\nThe paper is generally clear and well written.\n\nThe proposed algorithm seems reasonable and it is conceptually simple to understand. In the current experimental results presented it also seems to outperform the alternative baselines.\n\nNonetheless, the paper has few flaws that significantly impact the stated contributions and reduced my rating.\n1) a stated contribution are theoretical guarantees about the performance of the algorithm. this analysis is not currently included in the main body of the manuscript, but rather in the appendix, which I find rather annoying. Moreover, said the analysis is in my opinion not sufficiently rigorous, with hand-wavy arguments, no formal proof and unclear terms (e.g. how do you define near-optimal?). Moreover, as observed by the authors this analysis currently rely on strong assumptions that might make it rather unrealistic. Overall, if you want to claim theoretical guarantees you will have to significantly improve the manuscript.\n2) Related work, although extensive in terms of the number of references, do not help to place this work in the literature. Listing related work is no the same as describing similarities and differences compared to previous methods. For example, a paper that obviously comes to mind is ""FeUdal Networks for Hierarchical Reinforcement Learning"". What are the differences to your approach? Also, please place the related work earlier on in the paper. Otherwise, it is impossible for a reader to correctly and objectively relate your proposed approach to previous literature.\n3) In its current form, the experimental results are extremely cherry-picked, with a very small number of tasks evaluated, and for each task a single selected baseline used. This needs to be changed: a) you should run all the baselines for each of the current tasks b) you should also expand the experiments evaluated to include tasks where it is not obvious that a hierarchy would help/is necessary c) you should include more baselines. feudal RL should be one, Roderick et al 2017 should be another one (especially considering your discussion in Sec 8)\n\nAdditional feedback:\n- The paper is currently oriented towards discrete states. What can you say about continuous spaces?\n- The use of random exploration for the discoverer is underwhelming. Have you tried different approaches? Would more advanced exploration techniques work or improve the performance?\n- Using only 4 seeds seems too little to provide accurate standard deviations. Please run at least 10 experiments.\n- The use of RAM is a fairly serious limitation of your experimental setting in my view. You should include results also for the pixel space, even if negative. Otherwise, this choice is incomprehensible.\n ']","[-50, -60, -20]","[20, 50, 50]","[""The sentiment score is -50 because the review starts positively, highlighting the strong experimental results, but then shifts to a more negative tone. The reviewer mentions a weak point and ultimately decreases their score after reading other reviews, indicating overall dissatisfaction. The final paragraph expresses agreement with other reviewers' criticisms, suggesting the paper has significant limitations. The politeness score is 20 because the language used is generally professional and respectful. The reviewer acknowledges both strengths and weaknesses of the paper without using harsh language. However, the tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is -60 because the review starts positively but becomes increasingly critical, especially in the updated section. The reviewer downgrades their score and expresses significant concerns about the paper's methodology and comparisons. Key phrases like 'borderline rather than strong accept', 'misleading', and 'unfair to other methods' indicate a negative sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'please specify' and 'it would be nice to mention', even while expressing criticisms. They also acknowledge positive aspects of the paper before detailing concerns. The language is consistently polite and constructive, avoiding harsh or personal criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the clarity of the paper, they also point out several significant flaws that impact the stated contributions. The reviewer uses phrases like 'the paper has few flaws that significantly impact the stated contributions' and 'reduced my rating', indicating an overall negative sentiment despite some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments and use polite language even when criticizing, such as 'Nonetheless, the paper has few flaws' and 'please place the related work earlier'. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism.\n\nHowever, the score is not higher because there are some direct criticisms that, while not impolite, are quite frank, such as calling the experimental results 'extremely cherry-picked' and describing the use of random exploration as 'underwhelming'.""]"
"['As a paper on how to prioritize the use of neurons in a memory this is an excellent paper with important results. \n\nI am confused by the second part of the paper an attached GAN of unlimited size. It may start out small but there is nothing to limit its size over increased learning. It seems to me in the end it becomes the dominate structure. You start the abstract with ""able to learn from a stream of data over an undefined period of time"". I think it would be an improvement if you can move this from an undefined time/memory size to a limited size for the GAN and then see how far that takes you. ', 'This paper attempts to mitigate catastrophic problem in continual learning. Different from the previous works where episodic memory is used, this work adopts the generative replay strategy and improve the work in (Serra et al., 2018) by extending the output neurons of generative network when facing the significant domain shift between tasks.\n \nHere are my detailed comments:\nCatastrophic problem is the most severe problem in continual learning since when learning more and more new tasks, the classifier will forget what they learned before, which will be no longer an effective continual learning model. Considering that episodic memory will cost too much space, this work adopts the generative replay strategy where old representative data are generated by a generative model. Thus, at every time step, the model will receive data from every task so that its performance on old tasks will retain. However, if the differences between tasks are significant, the generator cannot reserve vacant neurons for new tasks or in other words, the generator will forget the old information from old tasks when overwritten by information from new tasks. Therefore, this work tries to tackle this problem by extending the output neurons of the generator to keep vacant neurons to retain receive new information. As far as I am concerned, this is the main contribution of this work.\n \nNevertheless, I think there are some deficiencies in this work.\n \nFirst, this paper is not easy to follow. The main reason is that from the narration, I cannot figure out what is the idea or technique of other works and what is the contribution of this paper. For example, in Section 4.1, I am not sure the equation (3), (4), (5), (6) are the contributions of this paper or not since a large number of citations appear.\n \nSecond, the authors mention that to avoid storing previous data, they adopt generative replay and continuously enlarge the generator to tackle the significant domain shift between tasks. However, in this way, when more and more tasks come, the generator will become larger and larger. The storing problem still exists. Generative replay also brings the time complexity problem since it is time consuming to generate previous data. Thus, I suggest the authors could show the space and time comparisons with the baseline methods to show effectiveness of the proposed method.\n \nThird, the datasets used in this paper are rather limited. Three datasets cannot make the experiments convincing. In addition, I observe that in Table 1, the proposed method does not outperform the Joint Training in SVHN with A_10. I hope the author could explain this phenomenon. Furthermore, I do not see legend in Figure 3 and thus I cannot figure out what the curves represent.\n \nFourth, there are some grammar mistakes and typos. For example, there are two ""the"" in the end of the third paragraph in Related Work. In the last paragraph in Related Work, ""provide"" should be ""provides"". In page 8, the double quotation marks of ""short-term"" are not correct.\n \nFinally yet importantly, though a large number of works have been proposed to try to solve this problem especially the catastrophic forgetting, most of these works are heuristic and lack mathematical proof, and thus have no guarantee on new tasks or scenarios. The proposed method is also heuristic and lacks promising guarantee.', '\nThe proposed method tackles class-incremental continual learning, where new categories are incrementally exposed to the network but a classifier across all categories must be learned. The proposed method seems to be essentially a combination of generative replay (e.g. Deep Generative Replay) with AC-GAN as the model and attention (HAT), along with a growing mechanism to support saturating capacity. Quantitative results are shown on MNIST and SVHN while some analysis is provided on CIFAR.\n\nPros\n\n + The method combines the existing works in a way that makes sense, specifically AC-GAN to support a single generator network with attention-based methods to prevent forgetting in the generator.\n\n + The method results in good performance, although see caveats below. \n\n + Analysis of the evolution of mask values over time is interesting.\n\nCons\n \n - The method is very confusingly presented and requires both knowledge of HAT as well as more than one reading to understand. The fact that HAT-like masks are used for a generative replay approach is clear, but the actual mechanism of ""growing capacity"" is not made clear at all especially in the beginning of the paper. Further the contributions are not clear at all, since a large part of the detailed approach/equations relate to the masking which was taken from previous work. The authors should on the claimed contributions. Is it a combination of DGR and HAT with some capacity expansion?\n\n - It is not clear whether pushing the catastrophic forgetting problem into the generator is the best approach. Clearly, replaying data accurately from all tasks will work well, but why is it harder to guard against the generative forgetting problem than the discriminative one?\n\n - The approach also seems to add a lot of complexity and heuristics/hyper-parameters. It also adds capacity and it is not at all made clear whether the comparison is fair since no analysis on number of parameters are shown.\n\n - Relatedly, better baselines should be used; for example, if the memory used by the generative model is merely put to storing randomly chosen instances from the tasks, how will the results compare? Clearly storing instances bypasses the forgetting problem completely (as memory size approaches the dataset size it turns into the joint problem) and it\'s not clear how many instances are really needed per task, especially for these simpler problems. As such, I find it surprising that simply storing instances would do as poorly as stated in this paper which says cannot provide enough diversity.\n\n It also seems strange to say that storing instances ""violates the strictly incremental setup"" while generative models do not. Obviously there is a tradeoff in terms of memory usage, privacy, performance, etc. but since none of these methods currently achieve the best across all of these there is no reason to rule out any of the methods. Otherwise you are just defining the problem in a way that excludes other simple approaches which work.\n\n - There are several methodological issues: Why are CIFAR results not shown in a table as is done for the other dataset? How many times were the experiments run and what were the variances? How many parameters are used (since capacity can increase?) It is for example not clear that the comparison to joint training is fair, when stating: ""Interestingly, DGM outperforms joint training on the MNIST dataset using the same architecture. This suggests that the strictly incremental training methodology indeed forced the network to learn better generalizations compared to what it would learn given all the data."" Doesn\'t DGM grow the capacity, and therefore this isn\'t that surprising? This is true throughout; as stated before it is not clear how many parameters and how much memory these methods need, which makes it impossible to compare.\n\n Some other minor issues in the writing includes: \n   1) The introduction makes it seem the generative replay is new, without citing approaches such as DGR (which are cited in the related work). The initial narrative mixes prior works\' contributions and this paper\'s contributions; the contributions of the paper itself should be made clear, \n\n   2) Using the word ""task"" in describing ""joint training"" of the generative, discriminative, and classification networks is very confusing (since ""task"" is used for the continual learning description too, \n\n   3) There is no legend for CIFAR; what do the colors represent?\n\n   4) There are several typos/grammar issues e.g. ""believed to occurs"", ""important parameters sections"", ""capacity that if efficiently allocated"", etc.).\n\n In summary, the paper presents what seems like an effective strategy for continual learning, by combining some existing methods together, but does not make it precise what the contributions are and the methodology/analysis make it hard to determine if the comparisons are fair or not. More rigorous experiments and analysis is needed to make this a good ICLR paper. ']","[70, -30, -30]","[50, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer starts by calling it an 'excellent paper with important results,' which is a strong positive statement. However, it's not 100 because the reviewer expresses confusion about the second part of the paper and suggests an improvement. The politeness score is 50 (slightly polite) because the language is generally respectful and constructive. The reviewer uses phrases like 'I am confused' and 'I think it would be an improvement,' which are polite ways to express criticism. However, it's not extremely polite as it doesn't use overtly courteous language or praise beyond the initial compliment."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's attempt to address an important problem and its main contribution, they list several significant deficiencies and criticisms. These include difficulty in following the paper, concerns about space and time complexity, limited datasets, grammar mistakes, and lack of mathematical proof. However, the score is not extremely negative as the reviewer does recognize the paper's efforts and contribution. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I think', 'I suggest', and 'I hope', which softens the criticisms. They also begin with positive aspects before moving to critiques. However, the score is not extremely high as the review is direct in its criticisms without excessive hedging or praise."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros' section), there are more extensive and significant criticisms ('Cons' section). The reviewer points out several methodological issues, lack of clarity in presentation, and concerns about the novelty and fairness of comparisons. However, the tone isn't entirely negative, as the reviewer does recognize some merits of the work. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'The proposed method seems to be' and 'It is not clear whether' rather than making blunt criticisms. The reviewer also balances negative points with positive ones and provides specific suggestions for improvement, which is a polite approach in academic reviewing.""]"
"['The paper proposes using structured matrices, specifically circulant and diagonal matrices, to speed up computation and reduce memory requirements in NNs. The idea has been previously explored by a number of papers, as described in the introduction and related work.  The main contribution of the paper is to do some theoretical analysis, which is interesting but of uncertain impact.\n\nThe experiments compare performance against DeepBagOf`Fframes (DBOF) and MixturesOfExperts (MOE). However, there are other algorithms that are both more competitive and more closely related. I would like to see head-to-head comparisons with tensor-based algorithms such as Novikov et al: https://papers.nips.cc/paper/5787-tensorizing-neural-networks, which achieves huge compression ratios (~200 000x), and other linear-algebra based approaches. \n\nAFTER READING REBUTTAL\nI\'ve increased my score because the authors point out previous work comparing their decomposition and tensortrains (although note the comparisons in Moczulski are on different networks and thus hard to interpret) and make a reasonable case that their work contributes to improve understanding of why circulant networks are effective. \n\nI strongly agree with authors when they state: ""We also believe that this paper brings results with a larger scope than the specific problem of designing compact neural networks. Circulant matrices deserve a particular attention in deep learning because of their strong ties with convolutions: a circulant matrix operator is equivalent to the convolution operator with circular paddings"".  I would broaden the topic to structured linear algebra more generally. I hope to someday see a comprehensive investigation of the topic.', 'In this paper, the authors prove that bounded width diagonal-circulant ReLU networks (I will call them DC-ReLU henceforth) are universal approximators (this was shown previously without the bounded width condition). They also show that bounded width and small depth DC-ReLUs can approximate deep ReLU nets with row rank parameters matrices. This explains the observed success of such networks. The authors also provide experiments to demonstrate the compression one can achieve without sacrificing accuracy.\n\nPros: The authors provide strong approximation results that explain the observed success of DC-ReLUs.\n\nCons: Too many grammatical errors (mainly improper pluralization of verbs and punctuation errors), typos, stylistic inconsistencies seriously affect the readability of the paper. The authors should pay more attention to these.', 'The experiments in the paper are similar to those explored in previous work! The main contribution claimed in the paper is the theoretical formulation for compact design of neural networks using circulant matrices instead of fully connected matrices. \n\nI do not think the claim is sufficiently justified by the theoretical results provided. \n\nEarlier result already shows how any matrix fully connected matrices can be approximated by 2n-1 circulant matrices. As the authors themselves point out, this theoretical result does not necessarily imply reduction in number of parameters since the for a depth l network, the equivalent diagonal-circulant-ReLU network will now require (2n-1)l depth, or 2n(2n-1)l parameters. \n\nThe main results (Proposition 3, 4) show that if the fully connected networks of depth l network are parameterized by (approximately) rank k matrices, then the resultant depth of diagonal-circulant network required to approximate the original network is (4k+1)l, which results in a total of 8n(4k+1)l parameters. Similar to the case of full rank fully connected networks (proposition 2), this result does not necessarily indicate a compression of number of parameters either. In particular, if fully connected networks are indeed rank k, then we only need nkl parameters parameters to represent the matrix, which is lower than the number of parameters required by the diagonal-circulant network. \n\nSo I do not see how the result can be seen as a justification for using diagonal-circulant networks as compact representations. \n\nWriting:\nTheorem 1: The statement about approximability with B_1B_2…B_{2n-1} is independent of p and S. \nProposition 3: The expression for depth should be \\sum_{i=1}^l (4k_i+1)  — sum should go from i=1 to l and there should be no multiplicative factor l \n\nOther non-critical comments: Multiplication by circulant matrices amounts to circular convolution with full dimensional kernel. In this sense, replacing a fully connected layers by circulant matrices is similar to replacing it with convolutional layers.  May be this connection can be explicitly stated in the paper.\n\n']","[20, 50, -60]","[50, 20, 20]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and interesting theoretical analysis, they also express some reservations about its impact and comparisons. The reviewer's tone becomes more positive after reading the rebuttal, increasing their score and expressing strong agreement with some points. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and shows willingness to adjust their opinion based on the authors' rebuttal. They also express hope for future research in the field, which adds a collegial tone to the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strong approximation results and the paper's contribution to explaining the success of DC-ReLUs. However, they also point out significant issues with grammar and readability, which balances out the positive aspects. The politeness score is 20 (slightly polite) because the reviewer maintains a professional tone and provides both pros and cons. They don't use harsh language, but they do directly state that the authors should pay more attention to grammatical errors. The use of 'Too many' and 'seriously affect' in the criticism slightly reduces the politeness, but overall, the review remains respectful and constructive."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's main claims and contributions. They state that the theoretical results do not sufficiently justify the claimed benefits of using circulant matrices, and they don't see how the results can be seen as justification for the proposed approach. The review is predominantly critical, though not entirely negative.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I do not think' and 'I do not see how' rather than more aggressive language. They also offer constructive feedback, including suggestions for improving the writing and pointing out potential connections to other work. The reviewer's language is slightly more polite than neutral, hence the slightly positive score.""]"
"['In this paper, a framework for lifelong learning based on Bayesian neural network is proposed. The key idea is to combine iterative pruning for multi-task learning along with the weight regularization. The idea of iterative pruning was first considered by Mallya et al., 2018 and weight regularization was considered for Bayesian neural network by Nguyen et al., 2018.\n\nPros: \n- Combination of two idea seems novel. I like the idea of considering the weight parameter as the ""global"" random variables and the mask parameters as the task-specific random variables. \n\nCons: \n- In general, there is lack of explanation/justification on the combination of two ideas. Especially, there is lack of explanation on how to apply the whole algorithm (e.g., text states that complete algorithm is in Algorithm 3., but there is no Algorithm 3. in the paper). \n\n- I do not understand how equation (6) is developed, and why hyper-parameters are need for ""regularization of weights"", comparing with the Variational Continual Learning (VCL, Nguyen et al., 2018). More explanation seems necessary for justification of the algorithm.\n\n- More stronger baselines need to be considered for the experiments. Why is there no comparison with the existing continual learning algorithms? At the very least, comparison with the VCL or Elastic Weight Consolidation (EWC, Kirkpatrick et al., 2017) seems necessary since one of the key idea is about regularization for weights.\n\n\nIn general, I think it is a nice idea to combine two existing approaches. However, the algorithm lacks justification in general and experimental results are not very persuasive.   ', 'The paper addresses the problem of lifelong learning of neural networks - a setting where learning is performed on a continuously arriving new tasks without having access to previously encountered data.\nAuthors propose a method that prevents catastrophic forgetting typical for naive application of stochastic gradient descent by preventing supposedly important weights to change (in either soft of hard manner), where the weight importance is assessed by its signal to noise ratio estimated from the corresponding (approximate) posterior distribution.\nAuthors evaluate their approach on a set of image classification datasets and find it superior to the PackNet baseline as well as few simpler ones.\n\nThe idea of using uncertainty estimates obtained from Bayesian training to adjust weight updates is natural and potentially very promising. \nHowever, to me this paper does not seem to investigate the idea sufficiently deep.\n\nThe weight pruning or hard masking variant of the method depends on a very important hyperparameter p (size of the mask) which is unclear how to set beforehand. \n\nI also struggle with understanding the weight regularisation or soft masking variant. \nAuthors seem to get their inspiration in the idea of assumed density filtering, where the posterior for 1:T-1 is approximated and used a prior for task T (last sentence on page 5).\nAt the same time, in Algorithm 2, line 6 the prior is defined as the standard BBB mixture prior and not the approximate posterior from the previous task.\nQuite oddly, parameters of the _approximate posterior_ are being quadratically regularalized to not deviate from parameters of the _approximate posterior_ from the previous task. \nThis deviates from the original idea and requires additional justification.\nBesides that, I find the way this regularisation is applied potentially problematic for the variance parameter (last term in eq. 6).\nHere authors apply the regularisation to the parameter of the softplus transformation they use, but scale it with the inverse std deviation which is the “classical” parametrisation. The choice of parametrisation was not discussed, however, clearly different parametrizations may lead to very different results. \n\nOn the experimental side, I have two major issues:\n1. The datasets considered are very small, authors could consider using ImageNet, especially given that they already work with 224x224 images.\n2. The only prior work used as a baseline is PackNet, while there is no reason why other established methods such as EWC are not applicable.\n\nMinor comments:\nThe middle expression in eq. 5 seems to miss the -log p(D_T | D_{1:T-1}) term which does not change the latter expression (since it does not depend on parameters theta).\nPage 3: “citestochastic methods”, a citation seems to be missing.', 'Motivated from leveraging the uncertainty information in Bayesian learning, the authors propose two algorithms to prevent forgetting: Pruning and Regularization. Experiments on several sequential learning tasks show the improved performance.\n\nQuality:  The description on the related work is comprehensive. The proposed algorithms seem easy to follow. \n \nClarity: Low \n\nThe contributions in terms of algorithms are clearly presented. However, the writing can be largely improved.\n\n(1) Some claims are improper:  I don\'t think it\'s accurate to say that most of lifelong learning is non-Bayesian (In introduction), and EWC is derived from a Bayesian perspective, and Variational Conditional Learning is a very Bayesian approach.\n\n(2) Please proofread the submission: \nTypos: e.g.,  ""Beysian"", ""citestochastic methods"";  \nStyle: x is not bold occasionally, but has the meaning given the context. \n\nOriginality: It seems to be the first work that leverages the variance in Bayesian Neural Nets (BNN) to prevent forgetting. My understanding that EWC also consider the variance, but in a different way. \n\nSignificance: \nIt is good to consider variance/uncertainty for lifelong learning, and should be encouraged.\nHowever, the comparison to the representative algorithms or state-of-the-art is missing in this submission. For example, EWC/IS, or method in [*].  Is it possible to run the experiments on more standard datasets, such as [*].\n\n[*] Overcoming Catastrophic Forgetting with Hard Attention to the Task, ICML 2018\n\n\nQuestions:\n1. In (6), there are three terms on the right side, it seems the 2nd term include the 3rd term, why do we need to add the 3rd term again?\n\n2. ""Once a task is learned, an associated binary mask is saved which will be used at inference to recover key parameters to the desired task. The overhead memory caused by saving the binary mask (less than 20MB for ResNet18), is negligible given the fact it completely eliminates the forgetting""\n\nTo me, saving a binary mask means saving ""partial"" model. First, this is additional parameter saving. Second, in the inference stage, one can recover the corresponding best model using the mask, how close is it to cheating? (Perhaps I am not an expert in lifelong learning). \nCan you put the model size of ResNet18, so that the readers can understand 20MB is small/negligible compared to the full model. \n\n\n\n']","[-20, -30, 20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express more concerns ('Cons') and conclude that the algorithm lacks justification and the experimental results are not very persuasive. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, acknowledging the novelty of the idea and providing constructive criticism without harsh or rude comments. They use phrases like 'I like the idea' and 'I think it is a nice idea' which contribute to a polite tone, while also clearly stating areas that need improvement."", ""The sentiment score is -30 because while the reviewer acknowledges the potential of the idea ('potentially very promising'), they express several significant concerns and criticisms about the paper's methodology and experimental design. The overall tone suggests the paper needs substantial improvements. The politeness score is 20 because the reviewer uses respectful language throughout, framing criticisms as personal observations ('to me', 'I struggle with understanding') rather than direct attacks. They also acknowledge positive aspects before presenting criticisms. However, the language remains professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the contributions and potential of the work, noting its originality and significance in leveraging uncertainty for lifelong learning. However, they also point out several areas for improvement, including clarity issues and missing comparisons, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They acknowledge the paper's strengths before discussing its weaknesses, and phrase their concerns as questions or suggestions rather than direct criticisms. The reviewer also uses polite phrases like 'Please proofread' and 'Is it possible to...' which contribute to the overall courteous tone.""]"
"['The authors propose to use importance resampling (IR) in place of importance sampling (IS) for policy evaluation tasks. The method proposed by the authors definitely seems valid, but it isn’t quite clear when this is applicable.\n\nIR is often used in the case of particle filters and other SMC is often used to combat the so-called “degeneracy problem” where a collection of particles (or trajectories) comes to degenerate such that all the mass is concentrated onto a single particle. This does not seem to be the case here, as the set of data (the replay buffer) does not seem to be changing over time. In particular, since the target policy and the behavior policy are fixed, the bigger issue seems to be that the distribution itself will not change over time.\n\nFinally, the results are given for somewhat simple problems. The first two settings show that the difference between IR/IS can be very stark, but it seems like this is the case when the distributions are very different and hence the ESS is very low. The IR methods seem like they can eliminate this deficiency by only sampling from this limited subset, but it is also unclear how to extend this to the policy optimization setting.\n\nOverall I have questions about where these results are applicable. And finally, as stated a moment ago, it is unclear how these results could be extended to the setting of off-policy policy optimization, where now the resulting policies are changing over time. This would necessitate updating the requisite sampling distributions as the policies change, which does seem like it would be difficult or computationally expensive (unless I am missing something). Note that this is not an issue with IS-based methods, because they can still be sampled and re-weighted upon sampling.\n', 'This paper introduces the concept of Sampling Importance Resampling (SIR) and give a simple method to adjust the off-policyness in the TD update rule of (general) value function learning, as an alternative of importance sampling. The authors argue that this resampling technique has several advantages over IS, especially on the stability with respect to step-size if we are doing optimization based the reweighted/resampled samples. In experiment section they show the sensitivity to learning rate of IR TD learning is closer to the on-policy TD learning, comparing with using IS or WIS.\n\nMain comments: \nThe proposed IR technique is simple and definitely interesting in RL settings. The advantage about sensitivity of step-size choice in optimization algorithm looks appealing to me, since that is a very common practical issue with IS weighted objective. However I feel both the theoretical analysis and empirical results will be more convinced to me if a more complete analysis is presented. Especially considering that the importance resampling itself is well known in another field, in my point of view, the main contribution/duty of this paper would be introducing it to RL, comparing the pros/cons with popular OPPE methods in RL, and characterize what is the best suitable scenario for this method. I think the paper could potentially do a better job. See detailed comments:\n\n1. The assumption of Thm 3.2 in main body looks a little bit unnatural to me. Why can we assume that the variance is bounded instead of prove what is the upper bound of variance in terms of MDP parameters? I believe there exists an upper bound so that result would be correct, but I’m just saying that this should be part of the proof to make the theorem to be complete.\n2. If my understanding to section 3.3 is correct, the variance of IR here is variance of IR just for one minibatch. Then this variance analysis also seems a little bit weird to me. Since IR/IR-BC is computed online (actually in minibatch), I think a more fair comparison with IS/WIS might be giving them the same number of computations over samples. E.g. I would like to see the result of averaged IR/IR-BC estimator (over n/k minibatch’s) in either slicing window (changed every time) or fully offline buffer, where n is the number of samples used in IS/WIS and k the size of minibatch. I think it would be more informative than just viewing WIS as an (upper bound) benchmark since it uses more samples than.\n3. From a higher level, this paper considers the problem of learning policy-value function with off-policy data. I think in addition to TD learning with IS adjustment, fitted Q iteration might be a natural baseline to compare with. It is also pretty widely-used and simple. Unlink TD, FQI does not need off-policy adjustment since it learns values for each action. I think that can be a fair and necessary baseline to compare to, at least in experiment section.\n4. A relatively minor issue: I’m glad to see the author shows how sensitive each method is to the change of learning rate. I think it would be better to show some results to directly support the argument in introduction -- “the magnitude of the updates will vary less”, and maybe some more visualizable results on how stable the optimization is using IS and IR. I really think that is the most appealing point of IR to me.\n\nMinor comments:\n5. The authors suggest that the second part of Var(IR), stated in the fifth line from the bottom in page 5, is some variability not related to IS ratio but just about the update value it self. I think that seems not the case since the k samples (\\delta_ij’s, j=1 to k) actually (heavily) depend on IS raios, unless I missed something here. E.g. in two extreme case where IS weights are all ones or IS weights are all zero except for one (s,a) in the buffer, the variance is very different and that is because of IS ratio but not the variance of updates themselves. \n6. Similar with (5), in two variance expressions on the top of page 6, it would be better to point out that the distribution of k samples are actually different in two equations. One of them is sampled uniformly from buffer and the other is proportional to IS ratios.\n7. I think it is a little bit confused to readers when sometimes both off-policy learning and off-policy policy evaluation are used to describe the same setting. I would personally prefer use off-policy (policy) learning only in the “control” setting: learning the optimal policy or the optimal value function, and use the term off-policy policy evaluation referring to estimating a given policy’s value function. Though I understand that sometimes we may say “learning a policy value function for a given policy”, I think it might be better to clarify the setting and later use the same term in the whole paper.\n\nOverall, I think there are certainly some interesting points about the IR idea in this paper. However the issues above weakens my confidence about the clarity and completeness of the analysis (in both theory and experiment) in this paper.', ""In this work, the authors studied the technique of importance re-sampling (IR) for off-policy evaluation in RL, which tends to have low-biased (and it's unbiased in the bias-correction version) and low-variance. Different than existing methods such as importance sampling (IS) and weighted importance sampling (WIS) which correct the distribution over policy/transitions by an importance sampling ratio, in IR one stores the offline data in a buffer and re-samples the experience data (in form of state, action, & next-state) for on-policy RL updates. This approach avoids using importance sampling ratios directly, which potentially alleviate the variance issue in TD estimates. The authors further analyze the bias and consistency of IR, discuss about the variance of IR, and demonstrate the effectiveness of IR by comparing it with IS/WIS on several benchmark domains.\n\nOn the overall I think this paper presents an interesting idea of IR for off-policy learning. In particular it hinges on designing the sampling strategy in replay buffer to handle the distribution discrepancy problem in off-policy RL. Through this simple off-policy estimator, the authors are able to show improvements when compared with other state-of-the-art off-policy methods such as IS and WIS, which are both known to have high-variance issues. The authors also provided bias and consistency analysis of these estimators, which are reasonable theoretical contributions. The major theoretical question/concern that I have is in terms the variance comparisons between IR and IS/WIS. While I see some discussions in Sec 3.3, is there a concrete result showing that IR estimator has lower variance when compared to IS and WIS (even under certain technical assumptions)? This is an important missing piece for IR, as the original motivation of not using IS/WIS estimators is because of their issues on variance. \n\nIn terms of experiment, while the authors have done a reasonably good job evaluating IR on several domains based on the MSE of policy evaluation, to make it more complete can the authors also show the efficiency of IR when compared to state-of-the-art algorithms such as V-trace, ABQ or Re-Trace (which are cited in the introduction section)? ""]","[-20, -20, 60]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the validity of the proposed method, they express several concerns and questions about its applicability and extensibility. The review points out limitations and unclear aspects of the work, which contributes to the overall negative sentiment. However, it's not extremely negative as the reviewer does recognize some merits of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The method proposed by the authors definitely seems valid' and frame their concerns as questions or observations rather than harsh criticisms. The language is constructive and focuses on the work rather than making personal comments about the authors. While not overly effusive, the tone is consistently polite and appropriate for academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns and suggest that the paper could 'potentially do a better job.' The reviewer points out multiple areas where they feel the analysis is incomplete or unconvincing, which contributes to the overall negative sentiment. However, the score is not deeply negative because the reviewer does recognize some value in the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I feel,' 'I think,' and 'I would like to see,' which soften their criticisms. The reviewer also acknowledges positive aspects of the work, such as calling the proposed technique 'simple and definitely interesting.' While they do express criticisms, they do so in a constructive manner, offering specific suggestions for improvement rather than harsh dismissals. The language is consistently polite and academic, avoiding any personal attacks or overly negative language."", ""The sentiment score is 60 (positive) because the reviewer expresses an overall positive view of the paper, describing it as presenting 'an interesting idea' and acknowledging its 'reasonable theoretical contributions'. The reviewer also notes improvements compared to other methods. However, it's not extremely positive as the reviewer raises some concerns and suggests additional comparisons. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively, and framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'I think', 'can the authors', and 'to make it more complete' indicate a polite and constructive tone. The reviewer maintains a professional and courteous demeanor while providing both praise and constructive feedback.""]"
"['Summary: The paper considers federate learning of neural networks, i.e. data are distributed on multiple machines and the allocation of data points is potentially inhomogenous and unbalanced. The paper proposes a method to combine multiple networks trained locally on different data shards and form a global neural network. The key idea is to identify and reuse neurons that can be used for all shards and add new neurons to the global network if necessary. The matching and combination process is done via MAP inference of a model using a Beta-Bernoulli process. Some experiments on federated learning demonstrate the performance of the proposed method.\n\nGeneral evaluation (+ pro/ - con, more specific comments/questions below):\n+ the paper is very well-written -- the BBP presentation is light but very accessible. The experimental set up seems sound.\n+ the matching procedure is novel for federated training of neural networks, as far as I know, but might not be if you are a Bayesian nonparametric person, as the paper pointed out similar techniques have been used for topic models.\n- the results seem to back up the claim that the proposed is a good candidate for combining networks at the end of training, but the performance is very similar or inferior to naive combination methods and that the global network is way larger than individual local network and nearly as large as simply aggregating all neurons together.\n- the comparison to recent federated learning methods is lacking (e.g. McMahan et al, 2017) (perhaps less communication efficient than the proposed method, but more accurate).\n\nSpecific comments/questions/suggestions:\n- the MAP update for the weights given the assignment matrix is interesting and resembles exactly how the Bayesian committee machine algorithm of Tresp (2000) works, except that the variances are not learnt for each parameter but fixed for each neuron. On this, there are several hyperparameters for the model, e.g. variance sigma_j -- how are these tuned/selected?\n- the local neural networks are very mall (only 50 neurons per layer). How do they perform on the test set on the homogeneous case? Is there a performance loss by combining these networks together?\n- the compression rate is not that fantastic, i.e. the global network tends to add new neuron for each local neuron considered. Is this because it is in general very hard to identify similar neuron and group them together? In the homogeneous case, surely there are some neurons that might be similar. Or is it because of the MAP inference procedure/local optima?', 'The paper develops a novel solution for federated learning under three constraints, i.e. no data pooling (which distillation violates), infrequent communication (which iterative distributed learning violates), and modest-sized global model (which ensemble model violates). This is acknowledgedly a kind of unique setting, and the proposed solution does fit it well.\n\nHowever, I have the following two main concerns\n1. The major attack on distillation from an ensemble is that it needs to pool data across all sources which has cost and privacy concerns. However I\'m not entirely convinced this ""data pooling"" is really necessary. One could argue distillation might as well be performed with simply an extra dataset that could be collected (sampled) elsewhere.\nPlus, even though the proposed solution doesn\'t need to do ""data pooling"", it is effectively doing ""model pooling"" which may has its own costs and issues, e.g. the assumptions that one has access to all the parameters of the local models, and that all those local models should more or less be homogeneous to allow such pooling to happen, might not hold.\n\n2. The idea of applying Beta-Bernoulli Process to uncover the underlying global model from a pool of local models is interesting. But I would very much like to see comparisons to some other simpler baselines, e.g. using dictionary learning to extract the common set of basis shared among the local models, or perhaps the slightly fancier DP-means (Kulis & Jordan, 2012)? Especially the lack of a meaningful improvement over the compared baselines from the empirical studies makes me wonder whether the BBP is indeed fit for purpose or even necessary for this task.\n\nSome other questions/comments,\n1. I\'d be interested to see what the authors think about the connection between their proposed PFNM to Hinton\'s dropout, which could also be interpreted as performing an implicit ""model pooling"" over an ensemble of local models sharing weights among each other.\n\n2. After introducing the notation for ""-j"", I\'d suggest not to abuse ""j"" to keep denoting (dummy) indices in summations (e.g. Eq.(7), (8), etc.) - I might prefer swapping it with e.g. ""j\'"" in $B^{j\'}_{i,l}$, $v_{j\'l}$ and $\\sigma^2_{j\'}$ to avoid confusions.\n\n3. When the number of batches J gets larger, which means a smaller batch size and therefore also a larger variance among the local models, would it be beneficial to also increase the noise variances $\\sigma_j$ accordingly to allow a better fit?', ""The paper uses the beta process to do federated neural matching. The brief experimental results show worse performance than the other techniques compared with. Also, the motivation for the hierarchical beta process isn't clear, since each group has a single Bernoulli process. This makes learning each second level beta process a meaningless task. Why not have a single beta-Bernoulli process?""]","[20, -20, -50]","[80, 60, 0]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges several positive aspects of the paper, such as it being well-written and presenting a novel approach. However, they also point out significant limitations, which balances out the positive aspects. The politeness score is high (80) as the reviewer uses respectful language throughout, presenting both positive and negative points in a constructive manner. They use phrases like 'the paper is very well-written' and frame criticisms as suggestions or questions, which maintains a polite tone. The reviewer also provides specific, detailed feedback, which is helpful and courteous in academic contexts."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the paper's approach, they express two main concerns and several additional questions/comments. The overall tone suggests that the reviewer is not fully convinced by the paper's arguments and methods. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms as 'concerns' and 'questions/comments'. They also use phrases like 'I'd be interested to see' and 'I'd suggest', which are polite ways of offering feedback. The reviewer maintains a professional and constructive tone, even when pointing out potential weaknesses in the paper."", ""The sentiment score is -50 because the review is generally negative, pointing out worse performance and questioning the motivation behind the approach. However, it's not entirely dismissive, acknowledging the experimental results and asking a constructive question. The politeness score is 0 (neutral) because the language is direct and matter-of-fact without being overtly polite or rude. The reviewer states observations and criticisms plainly without using particularly courteous language or harsh words. The tone is professional and objective, focusing on the content rather than being personally critical or overly deferential.""]"
"['The contributions of this paper are in the field of LSTM, where the authors explore the interpretability of LSTM with multivariate data obtained from various and disparate applications. To this end, the authors endow their approach with tensorized hidden states and an update process in order to learn the hidden states. Furthermore, the authors develop a mixture attention mechanism and a summarization methods to quantify the temporal and variable importance in the data. They validate the forecasting  and interpretability performance of their approach with experiments. \n\nThe parer is interesting, well structured and and clearly written. Also, the addressed topic of interpretability is pertinent. However, I have several concerns.\n\n1. In the related work the authors state that “In time series analysis, prediction with exogenous variables is formulated as an auto-regressive exogenous model ” . This is not always right - it is not imperative to add the auto-regressive terms, this is optional and depends on the way we want to formulate our time series forecasting approach and the known constraints.  \n2. In section 3 — Interpretable Multi-Variable LSTM, by stacking exogenous time series and target series, the authors implicitly formulate their algorithms in a way to consider auto-regression. And I have several concerns with this for time series forecasting. Because, the past is not always a predictor of the future even - particularly in time series context and in industrial settings. And in the occasions where the past allows to predict the future we do not necessarily need to use LSTM to forecast (the notion of persistency in forecasting is enough).  Therefore, the power of LSTM in forecasting would have been convincing if you omit the target series in your multi-variable input.\n3. In Network Architecture section the authors develop tensorized hidden state and an update scheme. This idea is interesting, I think it would also be good to know what is the algorithmic complexity of this approach? \n4.  In section 3.3 the authors state that ""In the present paper, we choose the simple normalized summation function eq.(9). "" Could the authors justify the reason behind this choice? I am not convinced of the reason behind this, especially the authors mention, right after,  that ""It is flexible to choose alternative functions for f_{agg}""\n\n5. In the experiment section, concerning the prediction performance the authors present a table showing their results, I believe it would have been more compelling to present the prediction results with graphs showing the normalized cumulative errors, as an example.\n\n6. With regard to the interpretation of the results, the authors show the variable importance as a function of the epoch number, it would be equally important to correlate the same figure with the associated prediction results/normalized cumulative errors as a function of the epoch number - this will allow to assess the importance of the interpretability.\n\nI think it would be important to further justify the pertinence of this work in terms of interpretability (the statement in the introduction ""the interpretability of prediction models is essential for deployment and\nknowledge extraction"" seems to be limited) for example what does it bring knowing the variance importance  as a function of the epoch number. As an example, the Pearson correlation coefficient can help select relevant features to a model, and restrict the number of inputs to the relevant ones - can we draw inspiration from this and explain what the authors are proposing in terms of interpretability... Here the idea is to have a motivation presenting the merits of this work, which I think is missing - particularly with the experiments presented here.', 'This paper describes a recurrent model (LSTM specifically, but generalizable) which can produce variable-wise hidden states that can be further used for two types of attentions: 1) variable importance for the importance of each variable (not accounting for time), and 2) temporal importance of each variable for the importance of each variable over time. The proposed NN model (IMV-LSTM) does not seem to directly provide such importance. Rather, the outputs are “decomposed” for each variable/time that allows probabilistic inference on top of this.\n\nOne of my main concerns (described in Cons/Comments below) is how it is not straightforward to grasp the quality of variable importance and temporal variable importance results despite this is the key strength of this paper. If this comes from my lack of understanding, I would appreciate if the authors could provide a little more explanation.\n\nPros:\n1.\tThe overall quality of the paper is decent and mostly clear.\n2.\tThe experiments are quite extensive.\n3.\tThe fact that each variable should have different level of importance is interesting and practical.\n\nCons/Comments:\n1.\tThe term “tensor” is used throughout the paper to describe the stacked matrices. While this is not technically wrong to describe 2>-dimensional structures, this term could potentially imply (and make the readers to expect) tensor-based schemes such as tensor decomposition. This is not necessarily bad, but to me, “tensor” and “variable-wise correspondence” do not seems to be associated too deeply since the “tensor” used in IMV-LSTM is a stack of matrices that are also independently used with respect to each other.\n\n2.\tThe variable importance experiments seem quite extensive and thorough, especially the lists of variable-wise temporal importance matrices provided in the appendix. However, the authors could provide some significance or relevance of the findings with respect to any domain knowledge or literature, it may help further appreciate and interpret the quality of the variable importance which is quite subjective to non-experts. Such information may not even need to be in the main paper; including a short description in the appendix.\n\n3.\tRelated to comments (2), the difference between IMV-Full and IMV-Tensor is hard to interpret since neither one is always better than the other (i.e., IMV-Full > IMV-Tensor in some experiments, vice versa). While the key difference is speculated to be from how the LSTM handles the variables, I am curious how this related to the differences in the results and how the differences variable importance results (i.e., Fig.3) can be in at least speculated.\n\nQuestions:\n1.\tShould \\tilde{h}_t in Figure 1 (a) be \\tilde{h}__{t-1} since this hidden state is from t-1? The figure itself currently implies that the hidden state for t is used, but this is computed from x_t using U_j. With \\tilde{h}__{t-1}, it follows Eq.(1).\n\n2.\tIn Equation set 2 for IMV-Tensor, are W and U (not W_j and U_j) also in tensor forms so each variable and hidden state get transformed correspondingly (i.e., W_1 for h^1_{t-1}, U_1 for x^1_t).\n\n3.\tThe IMV-Tensor version of IMV-LSTM (related to the question above) can be considered as a set of parallel LSTMs, one for each variable. Such independence could also be inferred from Figure 1. If that’s the case, where do the variables “interact” with each other? Is this happening in the later stage where the hidden states across variable/time are aggregated in the attention stage (Eq.(8) and on)?\n\n4.\tUp until Eq.(8), n was used for the variable index where n = 1,…,N. In Eq.(8), it seems to be still used as the variable index (i.e., h_T^n and g^n), but it is also a set of possible values for a random variable z_{T+1}. Is n used the same way for z_{T+1} as well? I am slightly confused on how z is used. Also, (just to clarify), if we use N variables, we are using y_t as well (i.e., [x_t^1,…,x_t^{N-1}, y_t])?\n\n5.\tf_agg: Is this for aggregating over instances? For \\bar{\\alpha}^n, I’m guessing this is aggregated over instances for variable n for t=1,…,T_1.\n\n6.\tI am not too familiar with the notion of “time-lag” in the experiments. If the authors could explain this a little bit, I would appreciate it.', 'Summary:\nThe authors propose IMV-LSTM, which can handle multi-variate time series data in a manner that enables accurate forecasting, and interpretation (importance of variables across time, and importance of each variable). The authors use one LSTM per variable, and propose two implementations: IMV-Full explicitly tries to capture the interaction between the variables before mixing the LSTM hidden layers with attention. IMV-Tensor uses separate LSTMs for each variable that remain separate, and mixes the hidden layers of the LSTMs using attention. The propose model outperforms popular interpretable models on three different datasets, and the experiments regarding the variable importance is convincing.\n\nPros:\n- The paper is clearly written, easy to understand.\n- IMV-LSTM outperforms many baselines including popular interpretable models on three different datasets, and the interpretation part is not super rigorous, but convincing enough.\n- Multi-variate time-series data are very common, therefore an interpretable, accurate models such as IMV-LSTM have a big practical impact.\n- I like the idea of using the important variables to train another model for testing how accurately the models can choose important variables\n\nIssues:\n- In the introduction: claim that attention mechanism can unveil the effect of variable to the target is tricky, potentially dangerous: Attention is attention. It is no causal, let alone correlation. Coefficients in logistic regression are correlated with the prediction target. Variables with high attention has ""some relationship"" with the prediction target. \n- The methodological novelty of IMV-LSTM is limited. Using attention mechanism on RNN to provide interpretation has been explored quite often. This paper is not so different from other works [1,2,3]\n- Claim that this is the first work to derive temporal-level & variable-level importance is not convincing: The importance calculation of this paper boils down to averaging the attention values. This can be easily done in the previous works [1,2,3], or any model that uses attention on each input channel and on the temporal axis.\n- Can\'t follow Eq.10. How is this justified?\n\n\n[1] Choi, E., Bahadori, M.T., Sun, J., Kulas, J., Schuetz, A. and Stewart, W., 2016. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems (pp. 3504-3512).\n[2] Zhang, J., Kowsari, K., Harrison, J.H., Lobo, J.M. and Barnes, L.E., 2018. Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record. IEEE Access.\n[3] Xu, Y., Biswal, S., Deshpande, S.R., Maher, K.O. and Sun, J., 2018, July. RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2565-2573). ACM.\n']","[-20, 50, 50]","[60, 80, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting, well structured and clearly written', they express 'several concerns' and provide multiple critiques and suggestions for improvement. This indicates a generally critical stance, albeit with some positive aspects. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects of the paper and framing criticisms as suggestions or questions (e.g., 'Could the authors justify...', 'I think it would be important...'). The reviewer maintains a professional tone, avoiding harsh or dismissive language, even when expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's decent quality, extensive experiments, and interesting concept. However, they also express concerns and ask for clarifications, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms constructively, and expresses appreciation for potential explanations. They use phrases like 'I would appreciate' and 'If this comes from my lack of understanding,' showing consideration for the authors. The review is structured professionally with clear pros, cons, and questions, maintaining a courteous tone throughout."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary, highlighting both pros and issues. The reviewer acknowledges the paper's clarity, the model's performance, and its practical impact, which are positive aspects. However, they also point out several limitations and concerns, balancing the overall sentiment. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They use phrases like 'I like the idea' and frame criticisms as 'Issues' rather than using harsh language. The reviewer also provides constructive feedback and references to support their points, which is a polite way to offer criticism in academic contexts.""]"
"['This paper proposes to learn a dynamics model (state to pixels using Generative Adversarial Networks), use this model in conjunction with Monte Carlo Tree Search, model-free reinforcement learning (Q-learning) and a reward prediction network essentially combining model-free with model-based learning. The proposed approach is empirically evaluated on a small subset of the Atari games and theoretical analysis for the bias-variance tradeoff are presented.\n\nIt is highly appreciated that this paper presents an idea and discusses why the proposed approach does not result in high performance. This is very valuable and useful for the community. On a high level it would be very useful if Figure 1 would be show less examples but present them much larger since it is almost impossible to see anything in a printout. Further, the caption does not lend itself to understand the figure. Similarly Figure 2 would benefit from a better caption. \n\nThe first part of the discussion (7), the individual building blocks, should be mentioned much earlier in the paper. It would be further useful to add more related work on that abstraction level. This would help to communicate the main contribution of this paper very precisely.\n\nOn the discussion of negative results: It is very interesting that Dyna-Q does not improve the performance and the hypothesis for why this is the case seems reasonable. Yet, it would be very useful to actually perform an experiment in a better controlled environment for which e.g. the dynamics model is based on the oracle and assess the empirical effect of different MCTS horizons and rollout estimates. Further, this scenario would allow to further quantify the importance and the required “quality” of the different learning blocks.\n\nIn its current form the paper has theoretical contributions and experimental results which cannot be presented in the main paper due to space constraints. Albeit the appendix is already very extensive it would be very useful to structure it into the theoretical derivation and then one section per experiment with even more detail on the different aspects of the experiment. The story of the main paper would benefit from referencing the negative results more briefly and better analyzing the different hypothesis on toy like examples. Further, the introduction could be condensed in order to allow for more in detail explanations and discussions without repetition later on.\n\nAs argued in the paper it is clear that image generation is a very expensive simulation mechanism which for games like pong which depend on accurate modeling of small aspects of the image are in itself difficult. Therefore, again although really appreciated, the negative results should be summarized in the main paper and the hypothesis concluded better analyzed. The extensive discussion of hyper parameters and approaches for individual components could be in the appendix and the main paper focuses on the hypothesis analysis.\n', 'This paper presents Generative Adversarial Tree Search (GATS) that simulates trajectories for the Monte-Carlo Tree Search up to a certain depth. The GATS functions as a model that can simulate the dynamics of the system and predict rewards, effectively removing the need for a real simulator in the MCTS search.\n\nThey prove some favourable theoretical properties regarding the bias variance trade-off.  Specifically, they propose the model based model free trade-off which illustrates the trade-off between selecting longer rollouts, which increases the upper performance bound, and getting a more accurate Q estimate, which decreases the upper performance bound.\n\nThey also propose a pseudo count exploration bonus based on the inverse Wasserstein metric as the exploration strategy for GATS.\n \nThey observe that when tree-search rollouts are short, GATS fails to outperform DQN on 4 different games.\n\nQuality:\nIt is unclear to me how you arrive at the result in Equation (9) of Appendix D. You have assumed in the second equation that the optimal action max_a Q(s,a) and max_a \\hat{Q}(s,a) are the same action a. How do you arrive at this conclusion? Since \\hat{Q} is an approximation of Q, why would the action a be the same?\n\nClarity:\nThe paper is fairly well written. There are many grammatical mistakes, but the overall message is more or less conveyed.\n\nOriginality:\nIt is original in the sense that a generative adversarial network is used as the model for doing the tree search. It is disappointing that this model does not yield better performance than the baseline and the theoretical results are questionable. I would like the authors to specifically address the theory in the rebuttal. \n\nSignificance:\n\nWhile I appreciate negative results and there should be more papers like this,  I do think that this paper falls short in a couple of areas that I think the authors need to address. (1) As mentioned in quality, it is unclear to me that the theoretical derivation is correct. (2) The exploration bonus based on the inverse Wasserstein metric would add much value to the paper if it had an accompanying regret analysis (similar to UCB, for example, but adapted to the sequential MDP setting). \n\nIt appears in your transfer experiments that you do indeed train the GDM faster to adapt to the model dynamics, but it doesn’t appear to help your GATS algorithm actually converge to a good level of performance. Perhaps this paper should be re-written as a paper that focuses specifically on learning models that can easily transfer between domains with low sample complexity?\n\nFor the exploration bonus: If the authors added a regret analysis of the exploration count and can derive a bound of the number of times a sub-optimal action is chosen, then this could definitely strengthen the paper. This analysis could provide theoretical grounding and understanding for why their new exploration account makes sense, rather than basing it on empirical findings.', 'The submitted paper proposes GATS, a RL model combining model-free and model-bases reinforcement learning. Estimated models of rewards and dynamics are used to perform rollouts in MTCS without actually interacting with the true environment. The authors theoretically and empirically evaluate their approach for low depths rollouts. Empirically they show improved sample complexity on the Atari game Pong.\n\nI think publishing negative research results is very important and should be done more often if we can learn from those results. But that is an aspect I feel this paper falls short at. I understand that the authors performed a great deal of effort trying to tune their model and evaluated many possible design choices, but they do not a provide a thorough investigation of the causes which make GATS ""fail"". I suggest that the authors try to understand the problems of MCTS with inaccurate models better with synthetic examples first. This could give insights into what the main sources of the problem are and how they might be circumvented. This would make the negative results much more insightful to the reader as each source of error is fully understood (e.g., beyond an error reate for predicting rewards which does not tell us about the distribution of errors which for example could have a big effect on the author\'s observations).\n\nAnother issue that needs further investigation is the author\'s ""hypothesis on negative results"". It would be great to experimentally underline the author\'s arguments. It is not trivial (at least to me) to fully see the ""expected"" interaction of learning dynamics and depths of rollouts. While MCTS should be optimal with any depths of rollouts given the true Q-function, the learning process seems more difficult to understand.\n\nI would also like the authors to clarify one aspect of their theoretical analysis. e_Q is defined as the error in the Q-estimate for any single state and action in the main text. This appears to be inconsistent with the proof in the appendix, making the bound miss a factor which is exponential in H (all possible x_H that can be reached within H steps). This would change the properties of the bound quite significantly. Maybe I missed something, so please clarify.\n\nOriginality mainly comes from the use of GANs in MCTS and the theoretical analysis.\n\nStrengths:\n- Interesting research at the intersection of model-free and model-based research\n- Lots of effort went into properly evaluating a wide range of possible design choices\n- Mainly well written\n\nWeaknesses:\n- Missing depths in providing a deep understanding of why the author\'s expectations and empirical findings are inconsistent\n- The authors use many tweaks and ideas to tune each component of their model making it difficult to draw conclusions about the exact contribution of each of these\n- Error in the theoretical analysis (?)\n\nMinor comment:\n* The paper would benefit from improved and more self-contained figure captions.\n']","[-20, -20, -30]","[80, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer appreciates the paper's discussion of negative results, they also point out several areas for improvement. The reviewer suggests restructuring the paper, condensing the introduction, and providing more detailed analysis of hypotheses. They also mention that some figures are difficult to understand and could be improved.\n\nThe politeness score is high (80) because the reviewer uses respectful and constructive language throughout. They begin by stating that the paper is 'highly appreciated' and 'very valuable and useful for the community.' The reviewer offers suggestions for improvement in a polite manner, using phrases like 'it would be very useful' and 'would benefit from.' Even when discussing negative aspects, the reviewer maintains a professional and courteous tone, focusing on how the paper could be enhanced rather than criticizing it harshly."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., originality of using a generative adversarial network for tree search), they express disappointment with the performance and question the theoretical results. The reviewer also points out several areas where the paper falls short and needs improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I appreciate' and 'I would like the authors to' which indicate respect. However, the review is not overly effusive in its politeness, maintaining a balanced and objective tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the importance of publishing negative results and the effort put into the research, they express several significant concerns about the paper's shortcomings. The reviewer points out that the paper lacks a thorough investigation of why their approach fails, suggests improvements, and mentions potential errors in the theoretical analysis. However, the tone is not entirely negative, as the reviewer also notes some strengths of the paper.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They phrase criticisms as suggestions (e.g., 'I suggest that the authors try to understand...') and acknowledge the authors' efforts. The reviewer also balances criticism with positive remarks about the paper's strengths. The language is professional and avoids harsh or dismissive statements, maintaining a collegial tone even when pointing out weaknesses.""]"
"['Summary: \nThe paper considers finding the most adversarial random noise given multiple classifiers. They formulate the problem as the standard min-max game and apply the multiplicative weight updates. The technical contribution is to clarify the computational complexity of implementing/approximating the response oracle. The authors show experimental results.\n\nComments: \nI am afraid that the main technical result is already known:\n\nYoav Freund Robert E. Schapire: Adaptive game playing using multiplicative weights, Games and Economic Behavior, 29:79-103, 1999.\n\nThe paper shows that a multiplicative update algorithm can approximately solve the min-max game. If you use the result, you can readily obtain the main results of the present paper. \n\nAfter rebuttal:\nI read the authors comments and I understood the technical contribution more and raised my score.  Implementing/appriximating the response oracle is non-trivial. For MWU, I still think that the above paper should be cited (citing the Adaboost paper is not enough) since the paper shows MWU solves the min-max game.  \n', 'This paper is concerned with the problem of finding adversarial examples for an ensemble of classifiers. This is formulated as the task of finding noise vectors that can be added to a set of examples in such a way that, for each example, the best ensemble element performs as badly as possible (i.e. it’s a maximin problem).\n\nThis is formulated as a two-player game (Equation 1), in which the above description has been relaxed slightly: Equation 1 seeks a *distribution* over noise vectors, instead of only one. This linearizes the game, so that we can seek a mixed Nash equilibrium. Given access to a best response oracle, Algorithm 1 results in such a mixed Nash equilibrium. This is pretty standard stuff (see e.g. “Robust Optimization for Non-Convex Objectives” in NIPS’17, or “A Reductions Approach to Fair Classification” in ICML’18), but the application of this approach to this problem is novel and interesting.\n\nIn Section 2.1, the authors seek to show that they can get provable guarantees for *linear* classifiers, provided that there exists a “pure strategy Nash equilibrium”, which is a set of noise vectors for which *every* classifier misclassifies *every* example. These conditions seem to me to be so strong that I’m not sure that this section is really pulling its weight.\n\nOn the subject of Section 2.1, the authors might consider whether an analysis based on “Two-Player Games for Efficient Non-Convex Constrained Optimization” (on arXiv) could be used here: convert Equation 1 into a constrained optimization problem by adding a slack variable, then reformulate it as a non-zero-sum game, in which one player uses the zero-one loss, and the other uses e.g. the hinge loss.\n\nWhile Algorithm 1 makes an unrealistic oracle assumptions, and I didn’t find Section 2.1 fully satisfying, I think that overall the theoretical portion of the paper is sufficiently convincing that one should be surprised if their experiments don’t show good performance (which they do--extremely good performance, in fact). Overall, this is an interesting and important problem, and a well-motivated approach that seems to work well in practice. I think Section 2.1 is a bit weak, but this is a relatively minor issue.', ""Summary: The authors provide a method to attack multiple classifiers, with the key insight that it is insufficient to attack a simple average of the multiple classifier outputs; creating adversarial examples which can fool each classifier independently leads to more success in attacking any defenses that has access to multiple classifiers. Note that white-box access to all the classifiers is assumed. \n\nClarity: Paper is well written and claims are clear and substantiated. \n\nOriginaility: The paper's technical contribution seems limited. They suggest performing PGD to estimate the best response, which is similar to previous work. However, the authors do multiple rounds of this, with different weights on the multiple classifiers at each step. \n\nConcerns: \n(1) Ensembles have mostly been proposed for black-box attacks. The setting where there are multiple classifiers and all of these weights are accessible to the attacker seems unrealistic. What's the advantage for a defense to commit to a set of trained classifiers before hand? \n\n(2) Security concerns aside; it is not surprising that it's possible to find an attack that works for multiple classifiers at the same time, and I believe this has been done in prior work. The theoretical contribution is limited and the technique proposed is just a small modification of existing gradient based algorithms.\n\n(3) The experimental evaluation is against previous work which tried to solve a different problem (black box based attacks).  Hence, they are not convincing. \n\n\n"", 'The paper studies the problem of adversarial examples generation. The authors phrase the following problem: given a set of models  C, we want to find an adversarial perturbation that maximizes the loss on an ensemble of models. However, the ensemble weights are chosen by the learner. In the case that we have one example, this is equivalent to asking that the same adversarial perturbation (or distribution over perturbations) fools all the individual models in my collection. This is a reasonable phrasing of the problem, though it seems different from versions studied in literature. In particular, previous works used uniform ensembles.\nMore generally, the authors consider a set of m examples, and the adversarial player now looks for a (distribution over) perturbations for each of the n examples. The learner player selects mixing weights to minimize the error rate. This is an interesting formulation of the problem: in particular, tying the mixing weights used for all examples is a non-intuitive change and does not have the clean interpretation above any more.\nThis notion of allowing mixing weights on the learner is a change from previous work. The authors would do well to explain why this formulation is chosen and what the interpretation is. It corresponds to a specific attack model where the learner and the adversary make choices in a very specific order, and could use further explanation on when this a reasonable attack model. Note that previous work looked at the setting of all weights being equal, and one natural variant is to allow a set of mixing weights per example, which would correspond to finding a perturbation (or distribution over perturbations) for this example that fool all models in the set C. The version studied here is left unexplained in the current work.\n\nThe authors then argue that we can solve this game by playing MW vs. best response. They propose using best response on the adversarial player. This player is then trying to find the perturbation that maximizes the p-weighted sum of the 0-1 (or rather surrogate) losses, where p represents the mixing weights on C. The authors show that in the convex case, if there is a pure NE, then the best response can be found: in this case we get a convex problem. They study the convex case a bit more, showing that there is at most an exponential number of values for the 0-1 loss, since a {0,1} vector defining which side of each classifier in C x falls in fully defines the loss at x. \n\nFinally, the authors move to the non-convex case where the experiments are done. The authors report interesting results on imagenet and for mnist for the convex case. I had some trouble understanding the imagenet results. For one, it seems fishy that their Madry et al. attack is worse than the FGM for many of the models and suggests strongly that the parameters for the Madry attack were not properly tuned. It is hard to know since the paper does not report on various parameters for these attacks. Second, these attacks are designed for l_infty and modifying them for l_2 would be necessary for a fair comparison. Finally, I am not sure why the authors do not compare to the Carlini and Wagner attacks on Imagenet, which is actually an l2 attack and makes the accuracy 0 at a slightly larger perturbation radius. Also, the authors would do well to emphasize that for larger perturbation radii, there are attacks which make the accuracy zero, and the contribution here seems to be look at smaller radii.\n\nMy primary concern with the work is that it is not clear to me how the specific two player game is motivated. The authors do not justify why it makes sense to allow weights on the ensemble, and also why these weights need to be tied together across examples. For a paper that makes strong claims about its approach being principled, this is a serious shortcoming in my view. Secondarily, the experiments section leaves me worried that the comparison is with improperly tuned versions of previous work. I would therefore not be in favor of accepting this paper.\n\nComments:\npg 1 : ""One of the most pressing ..."" : that is perhaps an unnecessary exaggeration.\npg 2: The name ""NSFW"" is an unfortunate choice, is completely non-informative about the contribution and I strongly recommend the authors reconsider it.\n- As far as I can tell, Tramer et al. do not build an ensemble model at all; the ensemble word there refers to an ensemble of adversarial perturbations.\n- The hinge loss is actually not smooth. However, I don\'t quite see why you need smoothness there.']","[-20, 60, -50, -60]","[20, 70, 50, 20]","[""The sentiment score is slightly negative (-20) because the reviewer initially expresses concern that the main technical result is already known, which is a significant criticism. However, after the rebuttal, the reviewer acknowledges a better understanding of the technical contribution and raises their score, which mitigates the negativity somewhat. The politeness score is slightly positive (20) because the reviewer uses polite language throughout, such as 'I am afraid that...' and 'I read the authors comments and I understood...'. They also provide constructive feedback and suggestions for improvement, which is a polite approach to reviewing. The reviewer maintains a professional tone, even when expressing criticism, and shows willingness to reconsider their initial assessment based on the authors' rebuttal."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper. They describe the approach as 'novel and interesting' and state that the paper addresses 'an interesting and important problem' with a 'well-motivated approach that seems to work well in practice.' The reviewer does point out some weaknesses, particularly in Section 2.1, but overall considers these 'relatively minor.' The positive language outweighs the criticisms, resulting in a moderately positive score.\n\nThe politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer acknowledges the paper's strengths and frames their criticisms in a balanced way, using phrases like 'I think' and 'might consider' which soften the impact of the critique. The overall tone is collegial and supportive, indicative of a polite academic discourse."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., 'Paper is well written and claims are clear and substantiated'), they express significant concerns and limitations of the work. The reviewer states that the technical contribution seems limited, the setting is unrealistic, and the experimental evaluation is not convincing. These criticisms outweigh the positive comments, resulting in a moderately negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude expressions. They present their concerns objectively and provide specific reasons for their criticisms, maintaining a constructive tone. The reviewer also acknowledges positive aspects of the paper, which contributes to the overall politeness of the review."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's approach and experimental comparisons, ultimately recommending against acceptance. The reviewer states, 'I would therefore not be in favor of accepting this paper,' which is a clear negative sentiment. However, the reviewer does acknowledge some positive aspects, such as 'interesting results' and 'interesting formulation,' which prevents the score from being even lower. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'The authors would do well to' and 'I had some trouble understanding,' which are polite ways of expressing criticism. The reviewer also provides specific, constructive feedback. However, some phrases like 'it seems fishy' and the strong recommendation against the paper's name choice slightly reduce the politeness score.""]"
"['This paper is poorly written, and looks like it was not proof-read. \nPresentation of the problem at hand is presented over so many times that it becomes confusing.\nAuthors ought to better define the image description space of the objects and the haptic space. \nMore interesting would have been a good explanation of the different sensors used in the anthropomorphic hand  and the vector built to represent the different sensed objects.\nThe most expected contribution of this work is barely explained: how the haptic sensors\' values/object labels vectors were built and fed to the predictor network, what their values looked like for the various objects, how these vectors clustered for the various objects etc.\n\nAmong the many evident weaknesses:\n- Domain specific concepts and procedures of most importance to this work are not explained: ""... measure various physical properties of objects using the bio-tac sensor using five different exploration procedures (EP)"".  Page 3, Paragraph 1. Bio-tac sensor and most importantly exploration procedures (EP) should be presented more clearly.\n- Incomplete and out of nowhere sentences are common: ""The SHAP procedure\nwas established for evaluating prosthetic hands and arms. With this idea in mind, prior work (?)\nbuilt a prosthetic arm which could ..."" Page 4, Paragraph 1.\n- Many references are not well introduced and justified: ""We then trained the network using\nADAM (Kingma & Ba (2014)) with an initial learning rate set to 1e-4."" Page 4, Paragraph 6. In the same paragraph,  authors explain using ""The groundtruth predictions were per-channel averaged haptic forces"" without having defined those channels (that one can guess but shouldn\'t). Concepts have to be clearly defined prior to their use.\n\n\n', 'The authors propose a task of classifying objects from tactile signals. To do this, the image and haptic data are collected for each object. Then, image-to-haptic and haptic-to-label predictors are trained by supervised learning. In the experiment, prediction accuracy on unseen object class is studied. \n\nThe paper is clearly written although it contains several typos. The proposed task of cross-modal inference is an interesting task. I however hardly find any significance of the proposed method. The proposed method is simple non-end-to-end predictors trained by supervised learning. So, the proposed model seems more like a naive baseline. It is not clear what scientific challenge the paper is solving and what is the contribution. Also, the performance seems not impressive. I’m not sure why the authors average the haptic features. Lots of information will be lost during the averaging, why not RNNs. Overall, the paper seems to require a significant improvement.\n', 'This is an exciting research problem, and could be of broad interest in robotics.  The problem posed, and associated data sets and simulation code, if shared, could be an interesting and novel source of challenge to machine learning researchers. \n\nHowever, the paper appears to be a fairly early work in progress, with missing detail in many areas, and making some odd approximations. One concern is the use of averaged haptic readings over a series of explorations, rather than the haptic reading for a specific pose. The approach of averaging seems certain to blur and confound things unnecessarily, making it harder for the system to learn the relationship between pose, object form and sensation.\n\nThe paper itself has weaknesses, e.g. on p5 you say ""When employing the predicted means, this accuracy was a bit lower."" when you actually have a drop from 99% to 54%! You do not specify which objects are used for this experiment. and in Section 4.2, you do not specify the exploration strategy used. \n\nCan you clarify the explanation of the images in Figure 3 - you say that the image is as in Figure 3, but are you really giving the image of the object AND hand, or just the object itself (if so, you need to change the explanation). \n\n']","[-80, -50, -20]","[-20, 20, 50]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper is 'poorly written,' 'confusing,' and lists many 'evident weaknesses.' There are no positive comments, only criticisms and suggestions for improvement. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and critical. The reviewer uses phrases like 'poorly written,' 'barely explained,' and 'incomplete and out of nowhere sentences are common,' which are direct and somewhat harsh criticisms. However, the reviewer does offer specific recommendations for improvement, which prevents the score from being even lower on the politeness scale."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('clearly written', 'interesting task'), they express significant concerns about the paper's contribution, methodology, and results. Phrases like 'hardly find any significance', 'seems more like a naive baseline', and 'requires a significant improvement' indicate a predominantly negative sentiment. The politeness score is 20 because the reviewer uses relatively neutral language and offers some positive comments, but doesn't use overtly polite phrasing. They present criticisms directly but not rudely, maintaining a professional tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the research problem as 'exciting' and 'of broad interest', they express several concerns and point out weaknesses in the paper. The reviewer uses phrases like 'fairly early work in progress', 'missing detail in many areas', and 'odd approximations', indicating overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using polite language such as 'Can you clarify' and acknowledging positive aspects before critiquing. They offer constructive criticism and specific suggestions for improvement, which is considerate. The reviewer avoids harsh language, even when pointing out significant issues (e.g., 'a bit lower' for a large drop in accuracy), further indicating a polite approach to the review.""]"
"[""This paper propose an extension of the Neural Theorem Provers (NTP) system that addresses the main issues of this method. The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. \n\nPro:\n\nThe paper is clear and well written and the contribution is relevant to ICLR. NTP systems by combining the advantages of neural models and symbolic reasoning are a promising research direction. Even though the results presented are lower than previous studies, they present the advantage of being interpretable.\n\nCons:\n\nI'm not convinced by the model used to integrate textual mentions. The evaluation proposed in section 6.3 proposes to replace training triples by textual mention in order to evaluate the encoding module. However, it seems to me that, in this particular case, these mentions are very short sentences.  This could explained why such a simplistic model that simply average word embeddings is sufficient. I wonder if this would still work for more realistic (and thus longer) sentences.\n\nMinor issues:\n\n-Page 1: In particular [...] (NLU) and [...] (MR) in particular, ...\n"", ""The authors propose several techniques to speed up the previously proposed Neural Theorem Prover approach. The techniques are evaluated via empirical results on several benchmark datasets.\n\nLearning interpretable models is an important topic and the results here are interesting and valuable to the community. However, I feel that the paper in its current form is not yet ready for publication in ICLR, for the following reasons:\n\n1) The authors propose three improvements. The first is a speed-up through nearest neighbor search instead of a brute-force search. This is the most elaborated section out of the three, yet seems like the most trivial -- unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size. It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). The attention mechanism (essentially reducing the model capacity) is also well-known but its effect in this particular framework is not properly elaborated. The same can be said for the use of mentions.\n\n2) The section on experiment results seems a bit rushed -- the authors did mention some last-minute discovery that may affect some of the presented results. The section can be a little hard to parse. In particular, it would be useful for the authors to focus on providing more insights on how the proposed techniques improve the results, and in what ways.\n\n3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). For a reader that has done so, the section feels redundant.\n\n"", '[Summary]\nThis paper scales NTPs by using approximate nearest neighbour search over facts and rules during unification. Additionally, the paper incorporates mentions as additional facts where the predicate is the text that the entities of the mention are contained in. The paper also suggests parameterizing predicates using attention over known predicates. The increments presented are reasonable and justified, but the experimental results, specifically on the larger datasets, warrant further investigation.\n\n[Pros]\n- Reasonable and interesting increments on top of NTP.\n- Scaling the approach to larger datasets is well motivated.\n- Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion.\n\n[Cons]\n- Empirical performance on larger datasets needs further investigation.\n- No ablation study is performed so the effect of incorporating mentions and attention are unclear.\n- Baseline performance on FB15k-237 seems weak compared to the original papers as well as more recent papers re-examining baselines for KG completion (http://aclweb.org/anthology/W17-2609). Is this due to the d=100 restriction, or were pretrained embeddings not used? Without further explanation, the claim that scores are competitive with SOTA seems unjustified, at least for FB15k-237 since the model performs significantly worse than the baselines which seem to be worse than previously reported.\n\n[Comments]\n- For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset.\n\n[Overall]\nIt’s great that NTP was scaled up to handle larger datasets, however further analysis is needed. The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well.\n']","[50, -20, -20]","[75, 60, 60]","[""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's contributions, followed by a 'Pro' section that praises the paper's clarity and relevance. However, this is balanced by a 'Cons' section that expresses skepticism about one aspect of the model. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The criticisms are framed as personal opinions ('I'm not convinced') rather than harsh judgments. The reviewer also offers constructive feedback and points out minor issues, which is a polite way to help improve the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the value of the results, they state that the paper is 'not yet ready for publication' and list several criticisms. The overall tone suggests room for improvement rather than outright rejection. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits before presenting criticisms. They use phrases like 'I feel that' and 'it would be useful' which soften the critique. The reviewer also provides specific, constructive feedback rather than harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('reasonable and interesting increments', 'well motivated'), they express significant concerns about the experimental results and lack of ablation studies. The overall tone suggests that the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balancing criticism with praise, and phrases concerns as suggestions for improvement rather than harsh criticisms. They use phrases like 'needs further investigation' and 'further analysis is needed' instead of more negative phrasing. The reviewer also acknowledges the positive aspects of the work before diving into criticisms, which is a polite approach in academic reviews.""]"
"['This paper introduces a new way of interpreting the VQ-VAE, \nand proposes a new training algorithm based on the soft EM clustering. \n\nI think the technical aspect of this paper is written concisely. \nIntroducing the interpretation as hard EM seems natural for me, and the extension\nto the soft EM training is sound reasonable. \nMathematical complication is limited, this is also a plus for many non-expert readers. \n\nI\'m feeling difficulties in understanding the experimental part.\nTo be honest, I think the experimental section is highly unorganized, not a quality for ICLR submission. \nI\'m just wondering why this happens, given clean and organized technical sections...\n\nFirst, I\'m confusing what is the main competent in the Table 1. \nIn the last paragraph of the page 6, it reads; \n""Our implementation of VQ-VAE achieves a significantly better BLEU score and faster decoding speed compared to (10).""\nHowever, Ref. (10) is not mentioned in the Table 1. Which BLEU is the score of Ref. (10)? \n\nSecond, terms ""VQ-VAE"", (soft?)""EM"" and ""our {model, approach}"" are used in a confusing manner. \nFor example, in Table 1, below the row ""Our Results"", there are:\n- VQ-VAE\n- VQ-VAE with EM\n- VQ-VAE + distillation\n- VQ-VAE with EM + distillation\n\nThe ""VQ-VAE"" is not the proposed model, correct? \nMy understanding is that the proposal is a VQ-VAE solved via soft EM, which corresponds to ""VQ-VAE with EM"". \n\nThird, a paragraph ""Robustness of EM to Hyperparameters"" is mis-leading. \nThe figure 3 does not show the robustness against a hyperparameter. \nIt shows the BLEU against the number of ""samples"" (in fact, there is no explanation about what the ""samples"" means). \nI think hyperparameters are model constants such as the learning rate of the SGD, alpha-beta params for Adam, dimension of hidden units, number of layers, etc. The number of samples are not considered as a model hyperparameter; it\'s a dataset property. \nThe figure 5 shows the reconstructed images of the original VQ-VAE and the proposed VQ-VAE with EM. \nHowever, there is no explanation which hyperparameter is tested to assess ""the robustness to hyperparameters"". \n\nFourth, there is no experimental report on the image reconstructions (with CIFAR and SVHN) in the main manuscript. \nIn fact, there is a short paragraph that mentions about the SVHN results, \nbut it only refers to the appendix. \nI think appendix is basically used for additional results or proofs, that are not essential for the main message of the paper. \nHowever, performance in the image reconstruction is one of the main claims written in the abstract, the intro, etc. \nSo, the authors should include the image reconstruction results in the main body of the paper. \nOtherwise, claims about the image reconstructions should be removed from the abstract, etc. \n\n\n+ Insightful understanding of the VQ-VAE as hard EM clustering\n+ Natural and reasonable extension to soft-EM based training of the VQ-VAE\n-- Unorganized experiment section. This simply ruins the quality of the technical part. \n\n\n## after feedback\n\nSome of my concerns are addressed the feedback. \nConsidering the interesting technical parts, I raise the score upward, to the positive side. ', 'Summary: \n\nThis paper presents a new training algorithm for vector-quantized autoencoders (VQVAE), a discrete latent variable model akin to continuous variational autoencoders.\nThe authors propose a soft-EM training algorithm for this model, that replaces hard assignment of latent codes to datapoints with a weighted soft-assignment.\n\nOverall the technical writing in the paper is sloppy, and the presentation of the generative model takes the form of an algorithmic description of the training algorithm, rather than being a clear definition of the generative model itself.\n\nThe technical presentation of the work by the authors starts only at page 5 (taking less than a full page), after several pages of imprecise presentation of previous and related work. The paper could be significantly improved by making this preceding material more concise and rigorous. \n\nQuantitative experimental evaluation is limited to a machine translation task, which is rather uncommon in the literature on generative latent variable models. I would expect evaluation in terms of held-out data log-likelihood (ie bits-per-dimension) used in probabilistic generative models, and possibly also using measures from the GAN literature such as inception scores. Datasets that are common include CIFAR-10 and resized variants of the imagenet dataset. \t \n\n\nSpecific comments:\n\n- Please adhere to the ICLR template bibliography style, which is far more readable than the style that you used. \n\n- Figure 1 does not seem to be referenced in the text. \n\n- The last paragraph of section 2.1 is unclear. It mentions a sampling a sequence of latent codes. The notion of sequentiality has not been mentioned before, and it is not clear what it refers to in the context of the model defined so far up to that point. \n\n- The technical notation is very sloppy. \n* In numerous places the paper refers to the joint distribution P(x1,…,x_n, z1, …, zn) without defining that the distribution factorizes across the samples (xi,zi), and without specifying the forms of p(zi) and p(xi|zi). \n* This makes that claims such as “computing the expectation in the M step (Equation 11) is computationally infeasible” are not verifiable. \n\n- Please be clear about how much is gained by replacing the exact M-step with a the one based on the samples from the posterior computed in the E-step. \n\n- What is the reason to decode the weighted average of the embedding vectors, rather than decoding all of them, and updating the decoder in a weighted manner?\n\n- reference 14 for Variational autoencoders is incorrect, please use the following citation instead: \n@InProceedings{kingma14iclr,\n  Title                    = {Auto-Encoding Variational {B}ayes},\n  Author                   = {D. Kingma and M. Welling},\n  Booktitle                = {{ICLR}},\n  Year                     = {2014}\n}\n\n- The related work section (4) provides a rather limited overview of relevant related work. \nHalf of it is dedicated to recent advances in machine translation, which does not bear a direct connection to the technical material presented in section 3.\n\n- There is no justification of using *causal* self-attention on the source embedding, is this a typo?\n\n- As for the experimental evaluation results: it seems that distillation is a much more critical factor to achieve good performance than the proposed EM training of the VQ-VAE model. Unfortunately, this fact goes unmentioned when discussing the experimental results. \n\n- What is the significance of the observed differences in BLEU scores? Please report average performance and standard deviations over several runs with randomized parameter initialization and batch scheduling. \n\n- It seems that the tuning of the number of discrete latent codes (table 2 in appendix) and other hyper-parameters (table 3 in appendix) was done on the test set, which is also used to compare to related work. A separate validation set should be used for hyper parameter tuning in machine learning experiments.\n\n- It seems that all curves in figure 3 collapse from about 45 BLEU to values around 17 BLEU, why is this? The figure is hard to read since poor quality, and curves that are superposed. \n', 'General:\nThe paper presents an alternative view on the training procedure for the VQ-VAE. The authors have noticed that there is a close connection between the original training algorithm and the well-known EM algorithm. Then, they proposed to use the soft EM algorithm. In the experiments the authors showed that the soft EM allows to obtain significantly better results than the standard learning procedure on both image and text datasets.\n\nIn general, the paper shows a neat link between the well-known EM algorithm and the learning method for the VQ-VAE. I like the manner the idea is presented. Additionally, the results are convincing. I believe that the paper will be interesting for the ICLR audience.\n\nPros:\n+ The connection between the EM algorithms and the training procedure for the VQ-VAE is neat.\n+ The paper is very well written, all concepts are clear and properly outlined.\n+ The experiments are properly performed and all results are convincing.\n\nCons:\n- The paper is rather incremental, however, still interesting.\n- The quality of Figure 1, 2 and 3 (especially Figure 3) is unacceptable.\n- There is a typo in Table 6 (row 5: V-VAE → VQ-VAE).\n- I miss two references in the related work on training with discrete variables: REBAR (Tucker et al., 2017) and RELAX (Grathwohl et al., 2018).\n- The paper style is not compliant with the ICLR style.\n\n--REVISION--\nI would like to thank authors for their effort to improve quality of images. In my opinion the paper is nice and I sustain my initial score.', 'This paper discusses VQ-VAE for learning discrete latent variables, and its application to NMT with a non-autoregressive decoder to reduce latency (obtained by producing a number of latent variables that is much smaller than the number of target words, and then producing all target words in parallel conditioned on the latent variables and the source text). The authors show the connection between the existing EMA technique for learning the discrete latent states and hard EM, and introduce a Monte-Carlo EM algorithm as a new learning technique. They show strong empirical results on EN-DE NMT with a latent Transformer (Kaiser et al. (2018)).\n\nThe paper is clearly written (excepting the overloaded appendix), and the individual parts of the paper are interesting, including the link between VQ-VAE training and hard EM, the Monte-Carlo EM, and strong empirical results. I\'m less convinced that the paper as a whole delivers on what it promises/claims.\n\nThe first contribution of the paper is that it shows a simple VQ-VAE to work well on the EN-DE NMT task, in contrast to the results by Kaiser et al. (2018). The paper attributes this to tuning of the code-book, but the results (table 3) seem to contradict this, with a code-book size of 2^16 even slightly better than the 2^12 that is used subsequently. The reason for the performance difference to Kaiser et al. (2018) remains opaque. While interesting, the empirical effectiveness of Monte-Carlo EM is a bit disappointing, achieving +0.3 BLEU over the best configuration for EN-DE (after extensive hyperparameter tuning, seen in table 4), and -0.1 BLEU on EN-FR. Monte-Carlo EM also seems very sensitive to hyperparameters, namely the sample size (tables 4,5), contradicting the later claim that EM is robust to hyperparameters. The last claimed contribution (using denoising techniques) is hidden in the appendix, an application of an existing technique, and not compared to knowledge distillation (another existing technique).\n\nI\'d like to see some of the results in the paper published eventually. However, the claims need to better match the empirical evidence, and for a paper that has ""better understanding"" in the title, I\'d like to gain a better understanding of the differences to Kaiser et al. (2018) that make VQ-VAE fail for them, but not in the present case.\n\n+ clearly written paper\n+ interesting, novel EM algorithm for VQ-VAE\n+ strong empirical results on non-autoregressive NMT\n\n- the strong performance of the VQ-VAE baseline remains unexplained, and the claimed explanation contradicts empirical results.\n- the new EM algorithm gives relatively small improvements, with hyperparameters that were likely selected based on test set scores .\n- most of the empirical gain is attributable to knowledge distillation, which is not a novel contribution']","[20, -60, 80, -20]","[50, -20, 70, 50]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's technical merits and interesting aspects, they also express significant concerns about the experimental section. The initial critique is quite negative, but the reviewer raises their score 'to the positive side' after feedback. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, balancing criticism with praise. They use phrases like 'I think' and 'I'm feeling difficulties' to soften critiques, and explicitly list positive aspects. However, some direct criticisms (e.g., 'highly unorganized, not a quality for ICLR submission') prevent a higher politeness score."", ""The sentiment score is -60 because the review is predominantly negative, highlighting numerous issues with the paper such as 'sloppy' technical writing, limited experimental evaluation, and unclear presentation. However, it's not entirely negative as it does suggest ways to improve. The politeness score is -20 because while the reviewer uses some polite language ('please'), the overall tone is quite direct and critical, using words like 'sloppy' and 'unclear'. The reviewer doesn't soften criticisms and directly points out flaws, which comes across as somewhat impolite in academic discourse. However, it's not overtly rude, hence the score is not extremely negative."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its strengths and potential interest to the ICLR audience. They use phrases like 'neat link', 'well written', and 'convincing results'. The cons mentioned are relatively minor and presented constructively. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and expressing gratitude in the revision section. They present criticisms diplomatically, using phrases like 'I miss' instead of more direct accusations. The reviewer maintains a professional tone, balancing praise with constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'interesting', 'strong empirical results'), they express significant doubts about the paper's overall contribution and claims. The reviewer states they are 'less convinced that the paper as a whole delivers on what it promises/claims' and points out several shortcomings. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I'd like to see' and 'I'd like to gain a better understanding', which are polite ways of suggesting improvements. The reviewer also balances positive and negative points, listing both strengths and weaknesses of the paper.""]"
"['This paper tries to draw connections between rate distortion theory and DNNs and use some intuitions from that domain to draw conclusions about robustness and generalization of the DNNs. \n\nThe paper is mostly written in a storytelling narrative with very little rigor. In my opinion, this lack of rigor is problematic for a conference paper that has to be concise and rigorous. Moreover, the story is not told in a cohesive way. In most parts of the paper, there is not much relationship between the consecutive paragraphs. And even within most of the paragraphs, I was lost in understanding what the authors meant. I wish the paper would have been self-contained and made concrete definitions and statements instead of very high-level ideas that are difficult to judge. In the current state, it is very difficult for me to say what exactly is the contribution of the paper in terms of the story other than some loosely related high-level ideas. I feel like most parts the story that the authors are telling is already told by many other papers in other forms(papers that authors have cited and many other ones).\n\n\n', 'This paper considers the trade-off between the prediction accuracy of deep neural networks (DNNs) and sensitivity to adversarial examples.\nReviewing the (Gaussian) channel capacity and rate-distortion theory, i.e., the information bottleneck, the authors discuss their implications on the generalization performance of DNNs. The experiments demonstrate the SNR of gradients, information plane, the generalization gap, and fault tolerance against adversarial examples.\n\nWhile the interpretations of DNN learning by the information theoretic concepts are interesting, most of them are already known results, and hence provide little novel theoretical knowledge.\n\nThe discussions in Section 3 are superficial. It is not clear how they are related to the main arguments of this paper.\n\nWhile the experiment of fault tolerance is interesting, the implications obtained from experiments are somewhat trivial.\n\nminor comments:\np.2, l.15: h, w, and c are undefined.   \nSection 2: Rate-distortion theory is usually explained by the sphere covering argument instead of sphere packing. \nSection 4.3.1: It is not explained what zero and one-shot transfer learning is.\n\nPros:\nThe experiment of fault tolerance is interesting. \nCons:\nTheoretical parts are basic results of information theory.\nThe implications of experiments are somewhat trivial. \n\n\n', 'The paper discusses on a rate distortion interpretation of adversarial examples by building the equivalence of DNN and a noisy channel. The proposed topic is very interesting. However, it is quite disappointing after reading the paper, that it does not deliver. In a sense, the reader has an impression that the paper is a collection of fractions of small thoughts and empirical observation pieces that are yet to be stringed up coherently.\n*To start with, the contributions are not clear. The major equations (1-4) are all pre-existing. The main Figure (fig.1) is also not new. Sec.3 is on implications, while it is more a discussion section centered on existing works about capacity and adversarial examples. Although it is claimed in the beginning of the paper 3 theoretical and empirical contributions, they are not clearly presented in the follow-up text.\n*Empirical evaluation, in Fig.2, a legend should be in place to introduce the colored curves. Currently it is unclear what it is for each of the curves. \n*Fig.3: it is unclear why the MI plots are of piecewise straight lines. Does it imply that the two MIs are linearly related?\n*Table 1&2: Not clear how this observation has to do with the RD theory.\n\nSeems no response from the authors. ']","[-70, -30, -70]","[-20, 20, -20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses significant concerns about the paper's lack of rigor, cohesiveness, and clarity. They state that it's 'difficult to judge' the paper's contributions and suggest that much of the content may not be novel. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticism is direct and unmitigated. Phrases like 'very little rigor', 'problematic', and 'very difficult for me to say what exactly is the contribution' convey a harsh assessment without softening language. The reviewer does attempt some politeness by using phrases like 'In my opinion' and 'I wish', but overall the tone is more critical than polite."", ""The sentiment score is -30 because the review is generally critical, pointing out that most of the interpretations are already known results and provide little novel theoretical knowledge. The reviewer also mentions that some discussions are superficial and implications are trivial. However, it's not entirely negative as the reviewer acknowledges that some aspects, like the experiment on fault tolerance, are interesting. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and respectful manner. They use phrases like 'While the interpretations... are interesting' and provide a balanced view by mentioning both pros and cons. The language is not overly harsh or rude, maintaining a polite academic tone throughout the review."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses disappointment and states that the paper 'does not deliver.' They describe it as a 'collection of fractions of small thoughts' that are not coherently connected. The reviewer also points out several unclear aspects and missing information. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism. Phrases like 'quite disappointing' and the overall tone of dissatisfaction contribute to a somewhat impolite impression. However, the reviewer does acknowledge that the proposed topic is 'very interesting' at the beginning, which prevents the politeness score from being even lower.""]"
"['Revised Review:\n\nThe authors of this work has taken my concerns, and concerns of other reviewers, and revised their paper during the rebuttal period. They have increased the quality of the writing / clarity, restructured the presentation (i.e. put many details in the Appendix section), and committed to open-sourcing the platform post publication. For these reasons I believe this work is now at a state that should be published at ICLR, and I revised my score from 5 to 7. I hope other reviewers can reread the work and post their updated comments.\n\nI\'m excited about the work, because it incorporates good ideas from A-Life / evolution / open-endedness communities, to introduce new paradigms and new ways of thinking to the RL community. I look forward to using this environment in my own research going forward, regardless of whether this work gets accepted or not. Good luck!\n\nMinor comment: On page 4, the section 5 Experiments, I think ""Technical details"" should be in bold font before the sentence ""We run each experiment using 100 worlds."" so it is distinguished from being part of that sentence.\n\nOriginal Review:\n\nThe authors present a new game environment inspired by MMORPGs. The environment supports a ""massive"" number of agents, each have different neural net brains (*) and have some foraging and combat skills. They use distributed RL to train the policies (using REINFORCE) and over time can observe the dynamics of the population of these artificial life agents interact with each other, where the only reward is survival. There are many interesting insights, such as looking at how multi-agent cooperative (and deceptive) strategies emerge, and how some agents with different niche skills co-evolve with agents with other niche skills. They also plan to open source the platform and I have high hopes that this will be a fantastic research environment. While I\'m very optimistic about this work and direction, there are issues with this particular paper, and I feel it is not ready for publication in its current form. While I have no doubt that the software project will be great, as a reviewer I\'m evaluating this particular paper, and I want to highlight flaws about the paper and what can be done to fix it during the rebuttal/review period.\n\nMy recommendations to improve the article:\n\n(1) Writing - I really enjoyed this work, but frankly, the writing is horrible. It took me days of effort to decipher every paragraph and understand all the terms and what is going on. The article reads like it is written by the person who programmed the game, and played MMORPGs almost every day of his childhood and adult life, so someone who is not reading the article thru the lens of the author might have an incredibly tough time digesting the content. For instance, there are sentences like ""It adds melee, ranged, and magic-based combat""... ""Melee, ranged, and magic combat have maximum Manhattan distance of effect of 1, 2, and 3 cells respectively. They do 10, 2, and 1 damage respectively""... ""This prevents uninteresting \'spawn killing\' and is a common technique in human games"". These are only a small selection of samples. There are also terminology like ""#ent and #pop"" which I feel should be replaced by $N_{ent}$ and $N_{pop}$ for a paper. In contrast, older works related to population-based RL training like [2], or RL in games like [3] are examples of clear and understandable writing. I highly recommend you give the draft to someone outside of your team, who is sufficiently isolated from this project (or perhaps to a professional writer if your lab has one), to go over each paragraph, and make the writing more clear. This would benefit the work in the long term as people refer back to the paper when they run your code.\n\n(2) Diagrams - While the diagrams look interesting, IMO they are poorly made. When I look at Figure 1, 4, and 9, it is really difficult to understand what is going on. I recommend redoing the diagrams, perhaps get some inspiration from distill.pub or OpenAI blog posts. There are things that are not clear, like what the inputs are into each agent, and how the training works. I recommend having some pseudocode snippets (like the Gym framework) to explain parts of the overall picture in more detail as figures.\n\nGiven a work of this magnitude, I\'m personally okay that they went over 8 pages, as long as it is properly used for clarity.\n\nDiscussion:\n\nConcepts from Artificial Life and Evolution has been introduced in this work. There is some confusion between what is ""learning"" and what has been ""evolved"" in your setup. Some readers coming from the evolution, or biology fields (who I bet will find your paper interesting to read and experiment with) might interpret ""learning"" to be weight changes during a life time, while ""evolution"" would be changes to the weight parameters from one generation to the next, but I think in policy-gradient RL, ""learning"" means weight changes after an agent dies and is reborn. Should consider clarifying in the introduction, the definition of learning, and whether it is inter-life or intra-life.\n\nYou cited some of Stanley\'s talks on open-endedness, but I wonder if you considered their work [1] where they proposed that having a minimum criteria condition might encourage diversity of solutions. For instance, perhaps in your environment, an agent doesn\'t have to be the very best, but only manage to survive, to move on to the next generation, which might cause very interesting multi-agent population dynamics. A parallel to modern life is that people (at least those in wealthy nations) live with such a good social safety net that people don\'t really have to be the best ""agent"" to reproduce and survive, and this might explain the large diverse cultures and ideas we end up with as human species, compared to other animals (where the current game is probably a suitable model of). An experiment to explore an experiment where only the very weakest agents die, but leaving agents with mediocre foraging and combat skills still live on (and pursue their own interests, whatever they may be) will be super interesting, and I encourage you to explore these ideas of open-endedness.\n\nBugs: In the appendix, the citation for OpenAI Five needs fixing.\n\nCurrently it pains me that I can only assign a score of 5 of this work (NOTE: this has been since revised upwards to 7 upon reading revision after rebuttal period), since I don\'t think the current writing is up to standards. In my opinion, it deserves a score of 7-8. If you work on points (1) and (2) and submit a revised draft with much better writing, visualization, figures to explain the work, I\'ll happily revise my score and improve it by 1-3 points depending on how much improvement is made.\n\n[1] Brand and Stanley. ""Minimal Criterion Coevolution: A New Approach to Open-Ended Search"" (GECCO 2017) http://eplex.cs.ucf.edu/papers/brant_gecco17.pdf\n[2] https://arxiv.org/abs/1703.03864\n[3] https://arxiv.org/abs/1804.03720\n\n(*) well, sort of, due to compute limits they are clustered to some extent to their species, so agents within a species have identical brains, unlike the real world.\n', ""The paper presents a new evaluation platform based on massive multiplayer games, allowing for a huge number of neural agents in persistent environments.\nThe justification evolves from MMO as a source of complex behaviours arguing that these settings have some characteristics of life on earth, being a “competitive game of life”. However, there are many combinations with completely different insights and implications. The key characteristics for the setting in this paper seem to be:\n1.\tCognitive evolution with learning, rather than physical or just genetic evolution (all bodies and architectures are equal)\n2.\tChanging environments (tasks), between parameter updates\n3.\tSurvival-oriented rewards\nAnd for some experiments some agents share policy parameters to simulate “species”.\nFrom the introduction and the rest of the paper, it’s not clear whether the same platform can be used with agents that are not neural, or even agents that are hardcoded (for the sake of diversity or to analyse specific behaviours). This is an important issue, as other platforms allow for the definition of some baseline agents, including random agents, agents with simple policies, etc.\nThe background and related work section covers MMO and artificial life, but has some important omissions, especially those ideas in the recent literature that are closest to this proposal.\nFirst, why can’t Yang et al., 2018 be extended with further tasks? \nSecond, conceptually, the whole setting is very similar to the Darwin-Wallace setting proposed in Orello et al. 2011:\n@inproceedings{hernandez2011more,\n  title={On more realistic environment distributions for defining, evaluating and developing intelligence},\n  author={Hern{\\'a}ndez-Orallo, Jos{\\'e} and Dowe, David L and Espa{\\~n}a-Cubillo, Sergio and Hern{\\'a}ndez-Lloreda, M Victoria and Insa-Cabrera, Javier},\n  booktitle={International Conference on Artificial General Intelligence},\n  pages={82--91},\n  year={2011},\n  organization={Springer}\n}\n\nThe three characteristics mentioned before are the key elements of this evaluation setting, which changes environments between generations. Also, the setting is presented in the context of evaluation and experimentation, as this manuscript.\n\nThird, regarding multi-agent evaluation setting, Marlo over Minecraft (Malmo) is covering this niche as well. \n\nhttps://marlo-ai.github.io/\n\nAlthough it is episodic and the number of agents is limited, this should be compared too.\n\nNevertheless, the authors should make a more convincing argument about why we need *massively* multiplayer settings. Why is it the case that some behaviours and skills appear with thousands of agents but cannot appear with dozens of examples? In evolutionary game theory, for instance, some complex situations emerge from very few agents.\n\nFinally, the use of agents that have to survive with “health, food and water” and its use as experimental setting can be found in Strannegård et al. 2018.   \nhttps://www.degruyter.com/downloadpdf/j/jagi.2018.9.issue-1/jagi-2018-0002/jagi-2018-0002.pdf\nFigures are not very helpful. Especially the captions do not really explain what we see in the figures. For instance, Figure 2 doesn’t show much. Figure 3 left and middle show some weird dots and patterns, but they are not explained. Also, the one on the right tries to show “ghosting”, but colours and their meaning are not explained. Similarly, it is not clear what the agents see and process. I assume it is a local grid as the one seen in figure 4. But this is quite an aerial view, and other grid options might do the job as well.\nSimilarly, some actions are mentioned (it seems that N, S, E, W and “Pass”? plus some attack options, but they are not described). In the end, I understand many choices have to be made for any evaluating setting, but many choices are very arbitrary (end of section 3 and especially experiments) and there is a lot of tuning, so it’s unclear whether some of the observations happen just in a particular combination of choices, but are more general. The authors end up with many inconclusive observations and doubts (“perhaps”) about small changes, at the end of section 5.\nOther things such as the “spawn cap” and the “server merge” are poorly explained, with clear definitions and proper justification of their role. Similarly, I’m not sure about how reproduction takes place or not, and if so, whether weights are inherited or reinitialised. Something related is said about species.\nI found the statement about multiagent competition being a curriculum magnifier, not a curriculum itself, very interesting, but is this really shown in the paper or elsewhere?\nIn general, I miss many details and justifications for the whole architecture and mechanism of this neural MMO.\nPros:\n-\tDesigned to be scalable\n-\tGoes in the right direction of benchmarks that can capture generally variable (social) behaviour.\nCons:\n-\tPoor comparison with existing platforms and similar ideas.\n-\tToo many arbitrary decisions for the setting and the experiments to make it work or show complex behaviours\n-\tThe paper needs extensive rewriting, clarifying many details, with the figures really helping for the understanding.\nTypos and minor things: \n-\t“Susan Zhang 2018” is named a couple of times, but the reference is missing. Also, it is quite unusual to use the given name for this researcher while this is not done for any other of the references.\n-\t“as show in Figure 2” -> shown\n-\t“impassible” -> “impassable”\n\n****************************\nI've read the new comments from the authors and the new version of the paper. I think that the paper has improved significantly in terms of presentations, coverage of related work. I still see that the contribution is somewhat limited, but I'm updating the score to better account with this new version of the paper."", 'This paper proposes a multi agent life simulators as an environment for RL. The environment is procedurally generated, with possibly many different game dynamics including foraging, and combat. They train deep RL agents in this environment and show various emergent behaviors such as exploration, and niche development. Additionally, they propose a tournament competition scheme to evaluate different populations of agents against each other.\n\nThis paper has a number of interesting findings, but overall lacks polish and coherence. The writing is verbose and informal in many places. There are many details not included -- for example specifics on combat targeting, how RL agents are trained, and information how to parse figures (what do colors mean?).\n\nPro\n+ Interesting idea, and demonstration of a system. From the intro, I believe an environment such as this is will be fruitful to study.\n+ Results seem preliminary but are interesting. In particular, the finding that agents generalize and thus perform better on tournament selection when trained in larger population is intriguing as well as the exploration results with population count!\n+ Reproducibility: authors claim they will release environment simulator code.\n\nCon\n- Paper can be considerably tightened. It is currently quite long (9.5 pages vs the suggested 8 page). There are also a lot of details included that don\'t seem core to the message. For example -- the multiple types of API / IPC communication, much of the RPGs section.\n- Some areas of writing could be improved, either too casual, or sloppy. For example -- various names are not capitalized in bibliography.\n- Examples of imprecise / casual writing: ""good performance without discounting, but training was less stable."" What does ""less stable"" actually mean? ""postprocess trajectories using a discount factor"" this is part of the REINFORCE algorithm -- postprocessing, to me, implies modifying the observations. The term ""numerical collapse"" is not a term I am aware of.\n- It is unclear what is shown in many of the figures. What are the colors in figures 8,9,10 for example? \n- Lots of details and ongoing work put in which distracts from a clear message. For example, why was ""entity targeting"" included? It doesn\'t appear to be described and the results shown in figure 10 are confusing. I would consider stepping back, and figuring out what one thing you want to show the reader, then drop all detail not around that point.\n- Lacking a conclusion of somesort. Ideally there would be something to pull the whole paper together.\n- use of terminology -- unclear why neural mmo is name of this environment. This is not a MMO, nor does the environment have anything ""neural"" related -- one can train reinforcement learning agents without neural network function approximators on it for example. I would consider renaming.\n\nIn its current form, I do not recommend accepting this paper but I do encourage the authors to continue working on it to both tighten the writing and presentation as well as continue to show interesting results via RL experiments.\n\n\n\nEDIT: See bellow, raised score from 4 --> 6.\n']","[50, 20, -40]","[75, 50, 20]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses excitement about the work and its potential, while also noting significant areas for improvement. They revised their score upwards from 5 to 7, indicating a positive shift in opinion after the authors addressed concerns. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and expresses enthusiasm for the work's potential. They provide detailed suggestions for improvement in a helpful manner, rather than being harshly critical. The reviewer also acknowledges the authors' efforts to address concerns and improve the paper. The language is professional and courteous, even when pointing out flaws in the writing and presentation."", ""The sentiment score is slightly positive (20) because while the reviewer points out several issues and areas for improvement, they also acknowledge the paper's strengths and note significant improvements in the revised version. The reviewer mentions pros like the platform being scalable and moving in the right direction for benchmarks. The final paragraph indicates an improved opinion of the revised paper. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement without using harsh language, and acknowledge the authors' efforts in addressing previous comments. The reviewer balances critique with positive remarks, which is a polite approach in academic reviewing."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects ('interesting findings', 'interesting idea'), the overall tone is critical. The reviewer lists more cons than pros and concludes by not recommending acceptance of the paper. However, it's not entirely negative as they encourage further work. The politeness score is 20 because the reviewer uses polite language and constructive criticism. They balance negative feedback with positive points and use phrases like 'I encourage the authors to continue working on it'. The tone is professional and not personally attacking, but also not overly deferential or excessively polite.""]"
"['Strengths:\n\nWell written paper, covers most of the relevant related work\nTechnique is conceptually easy to understand (~ adversarial training)\n\nWeaknesses:\n\nUnclear set of desiderata properties for a watermarking technique\nNo formal guarantees are verified, the mechanism is only tested\nAttacks tested are not tailored to the technique proposed\n\nFeedback and rebuttal questions:\n\nThis submission is easy to read and follow, and motivates the problem of watermarking well in light of intellectual property concerns. The technique proposed exploits unused capacity in the model to train it to associate specific inputs (computed adversarially) to specific outputs (the keys). Watermarking succeeds when the bit error rate between the predicted signature and the expected one is zero. This approach is conceptually easy to understand. \n\nThe experimental setup used to evaluate the approach is however limited. First, it is unclear why desiderata stated in Section 3.1 and summarized in Table 1 are necessary and sufficient. Would you be able to justify their choice in your rebuttal? For instance, the “security” requirement in Table 1 overlaps with “fidelity”. Similarly, the property named “integrity” really refers to only a subset of what one would typically describe as integrity. It basically calls for a low false positive or high precision. \n\nThe attack model described in Section 3.2 only considers three existing attacks: model fine-tuning, parameter pruning and watermark overwriting. These attacks do not consider how the adversary could adapt and they are not optimal strategies for attacking the specific defensive mechanism put in place here. For instance, could you explain in your rebuttal why pruning the smallest weights in the architecture in the final architecture would help with removing adversarial examples injected to watermark the model? Similarly, given that adversarial subspaces have large volumes, it makes sense that multiple watermarks could be inserted simultaneously and thus watermark overwriting attacks would fail.\n\nIf the approach is based on exploring unused capacity in the model, the adversary could in fact attempt to use a compression technique to preserve the model’s behavior on the task and remove the watermarking logic. For instance, the adversary could use an unlabeled set of inputs and have them labeled by the watermarked model. Because these inputs will not be “adversarial”, the watermarked model’s decision surface used to encode the signatures will remain unexplored during knowledge transfer and the resulted compressed or distilled model would solve the original task without being watermarked. Is this an attack you have considered in your experiments and if not could you elaborate why one may exclude it in your rebuttal?\n\nMinor comments: \n\nP3: Typo “Verifiabiity”\nP5: Could you add a reference or additional experimental results that justify why transferable keys would be located near the decision boundaries? \n', 'summary:\n\nThe paper proposes an approach for model watermarking (i.e., watermarking a trained neural neteowrk). The watermark is a bit string, which is embedded in the model as part of a fine-tuning procedure, and can be decoded from the network from the model\'s specific predictions for a specific set of inputs (called keys) chosen during the fine-tuning step. The process generates a watermark when we can be confident that a model that didn\'t go through the exact same fine-tuning procedure gives significantly different predictions on the set of keys. The application scenario is when a company A wants to deploy a model for which A has IP ownership, and A wants to assess whether a competitor is (illegaly) re-using A\'s model. The approach presented in the paper works in the black-box setting, meaning that whether a model posesses the watermark can be assessed only by querying the model (i.e., without access to the internals of the model).\n\nThe overall approach closely follows Merrer et al. (2017), but extends this previous work to multi-bit watermarking. The similarity with Merrer et al. is that keys are generated with a procesdure to generate adversarial examples, watermarking is performed by specifically training the network to give the source label (i.e., the label of the image from which the adversarial example has been generated). The differences with Merrer et al. lie in the fact that each key encoded a specific bit (0 or 1), and the multi-bit watermark is encoded in the predictions for all keys (in case of a multi-class classifier, the labels are first partitionned into two clusters to map each class to either 0 or 1). In contrast, Merrer et al. focused on ""zero-bit"" watermarking, meaning that all keys together are only used to perform a test of whether the model has been watermarked (not encode the watermark). Another noticeable difference with Merrer et al. is in step 4 of the algorithm, in which several unmarked models are generated to select better key images.\n\ncomments:\n\nWhile overall the approach makes sense and most of the design decisions seem appropriate, many questions are only partly addressed. My main concerns are:\n1- the watermarks are encoded in adversarial examples for which the trained model gives the ""true"" label (i.e., the watermark is embedded in adversarial examples on which the model is robust). The evaluation does not address the concerns of false alarms on models trained to be robust to adversarial examples. Previous work (e.g., Merrer et al.) study at least the effect of fine-tuning with adversarial examples..\n\n2- A watermark of length K is encoded in K images, and the test for watermarking is ""The owner can prove the authorship of the model if the BER is zero."". This leaves little room to model manipulation. For instance, the competitor could randomize its predictions once in a while (typically output a random label for one out of K inputs), with very small decrease in accuracy and yet would have a non-negligible probability of having a non-zero BER.\n\nother comments:\n1- overhead section: in step 4 of the algorithm, there is a mention of ""construct T unmarked models"": why aren\'t they considered in the overhead? This seems to be an extremely significant part of the cost (the overall cost seems to be more T times the cost of building a single unmarked model rather than a few percent)\n\n2- step 2 page 4: ""The intuition here is that we want to filter out the highly transferable WM keys"": I must have misunderstood something here. Why are highly transferable adversarial examples a problem? That would be the opposite: if we want the key to generate few false alarms (i.e., we do not want to claim ownership of a non-watermarked model), then we need the adversarial examples to ""transfer"" (i.e., be adversarial for non-watermarked models), since the watermarked model predicts the source class for the key. Merrer et al. (2017) on the contrary claim "" As such adversaries seem to generalize across models [...] , this frontier tweaking should resist model manipulation and yield only few false positives (wrong identification of non marked model)."", which means that transferability of adversarial examples is a fundamental assumption underlying the approach.\n\n3- under Eq. 1: ""Note that without the additional regularization loss (LWM), this retraining procedure resembles ‘adversarial training’ (Kurakin et al., 2016)."": I do not understand that sentence. Without L_{WM}, the loss is the usual classification loss (L_0), and has nothing to do with adversarial training.\n\n4- more generally, the contribution of the paper is on multi-bit watermarking, but there is no clear application scenario/experiment  where the multi-bit is more useful than the zero-bit watermarking.\n', 'A method for multi-bit watermarking of neural networks in a black-box setting is proposed. In particular, the authors demonstrate that the predictions of existing models can carry a multi-bit string that can later be used to verify ownership.\nExperiments on MNIST, CIFAR-10 and ImageNet are presented in addition to a robustness assessment w.r.t. different WM removal attacks.\n\nQuestions/Comments:\n\nRegarding the encoding scheme, a question that came up is whether one needs to perform clustering on the last layer before the softmax? In principle, this could be done at any point, right?\n\nAnother question is how the method scales with the key length. Did you experiment with large/small values of K (e.g., 100,200,...)? It would be interesting, e.g., to see a plot that shows key length vs. accuracy of the marked model, or, key\nlength vs. detection success (or BER).\n\nApart from these comments, how does the proposed model compare to zero-bit WM schemes? I am missing a clear comparison to other, related work, as part of the experiments. While there might not exist other ""black-box multi-bit""\nschemes in the literature, one could still compare against non-multi-bit schemes. \n\nIn light of a missing comparison, my assessment is ""Marginally below acceptance threshold"", but I am willing to vote\nthis up, given an appropriate response.\n\n\n\n\n\n']","[20, -20, -20]","[80, 50, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges strengths such as the paper being well-written and the technique being conceptually easy to understand. However, they also point out several weaknesses and areas for improvement, which tempers the overall positive sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, asks questions politely, and frames criticisms constructively. They use phrases like 'Would you be able to justify...?' and 'Could you explain...?' which maintain a courteous tone. The reviewer also balances critique with positive feedback, demonstrating professional courtesy. The minor comments at the end are presented neutrally and helpfully, further contributing to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that 'the overall approach makes sense and most of the design decisions seem appropriate', they express 'main concerns' and list several issues with the paper. The reviewer points out gaps in the evaluation, potential vulnerabilities in the watermarking method, and misunderstandings or inconsistencies in the paper's explanations. These criticisms outweigh the initial positive acknowledgment, resulting in a slightly negative overall sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language like 'My main concerns are...' and 'I must have misunderstood something here' rather than harsh or accusatory statements. The reviewer also acknowledges positive aspects of the work before presenting criticisms. However, the score is not higher because the review is primarily focused on pointing out issues and doesn't include many explicitly polite phrases or compliments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method and experiments, they express concerns about missing comparisons and state that the paper is 'Marginally below acceptance threshold'. However, they are open to changing their assessment given an appropriate response, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, poses questions politely, and offers constructive feedback. They also express willingness to reconsider their assessment, which is a courteous gesture. The review maintains a professional tone without any rude or overly critical remarks.""]"
"['This paper presents a generalization of TransE to Riemannian manifolds. While this work falls into the class of interesting recent approaches for using non-Euclidean spaces for knowledge graph embeddings, I found it very hard to digest (e.g. the first paragraph in Section 3.3). Figure 3 and 4 confused me more than helping me to understand the method. Furthermore, current neural link prediction methods are usually evaluated on FB15k and WN18. In fact, often on the harder variants FB15k-237 and WN18RR. For FB15k and WN18, Riemannian TransE seems to underperform compared to baselines -- even for low embedding dimensions, so I have doubts how useful this method will be to the community and believe further experiments on FB15k-237 and WN18RR need to be carried out and the clarity of the paper, particularly the figures, needs to be improved. Lastly, I would be curious about how the different Riemannian TransE variants compare to TransE in terms of speed?\n\nUpdate: I thank the authors for their response and revision of the paper. To me, results on WN18RR and FB15k-237 are inconclusive w.r.t. to the choice of using Riemannian as opposed to Euclidean space. I therefore still believe this paper needs more work before acceptance.', 'In this paper, authors focus on the problem of efficiently embedding Knowledge Graphs in low-dimensional embedding spaces, a task where models are commonly evaluated via downstream link prediction and triple classification tasks. The proposed model - Riemannian TransE, based on TransE [Bordes et al. 2013] - maps entities to points in a non-Euclidean space, by minimising a loss based on the geodesic distance in such space. This paper is especially interesting, since extends previous approaches - such as Poincare embeddings - to the multi-relational setting. Results look promising on WN11 and FB13, but authors mention results on the more commonly used WN18 and FB15k are less accurate than those obtained by the baselines (without reporting them). It is worth mentioning that WN18 and FB15k were found to be solvable by very simple baselines (e.g. see [1]). Furthermore, authors do not report any finding on the geometry of the learned spaces.\n\nIntroduction - Wording is a bit weird sometimes, e.g. what does ""evaluating dense matrices or tensors"" mean?\nRelated Work - Likewise, this section was a bit hard to follow. I do not fully get why authors had to use terms like ""planet"", ""launcher"", ""satellite"" etc. for describing mappings between entities and points in a manifold, relations and points in another manifold, and the manifold where the geodesic distances between representations are calculated.\nWhat is the intuition behind this?\nTab. 1 does a great job at summarising existing scoring functions and their space complexity. However, it may be worth noticing that e.g. the inner product used by DistMult is not really a ""dissimilarity"" between two representations (but rather the opposite). Is the number of parameters the same for Riemannian TransE as for the other methods (including the extra ""l"" parameters)? If it isn\'t the comparison may be slightly unfair.\n\n[1] https://arxiv.org/abs/1707.01476', 'The paper proposes a new approach to compute embeddings of multi-relational data such as knowledge graphs. For this purpose, the paper introduces a variant of TransE that operates on Riemannian manifolds, in particular, Euclidean, Spherical, and Hyperbolic space. This approach is motivated by the results of Nickel & Kiela (2017), who showed tha  Hyperbolic space can provide important advantages for embedding graphs with hierarchical structure.\n\nHyperbolic and Riemannian embeddings are a promising research area that fits well into ICLR. Extending hyperbolic, and more general, Riemannian embeddings to multi-relational data is an important aspect in this context, as it allows to extend such methods to new applications such as Knowledge Graph Completion. Overall, the paper is written well and mostly good to understand. However, I am concerned about multiple aspects in the current version:\n\n- What is the motivation for using this particular form of translation? In Riemannian manifolds, the analogue of vector addition and subtraction is typically taken as the exponential or logarithmic map (as expm and logm in Euclidean space are exactly vector addition and subtraction). For the spherical and hyperbolic manifold both maps have closed form expressions and are differentiable. It is therefore not clear to me what the advantage of the proposed approach is compared to these standard methods. In any case, it would be important to include them in the experimental results.\n\n- It is also not clear to me whether the benefits of hyperbolic embeddings translate into the setting that is proposed here. The advantage of hyperbolic embeddings is that they impose a hierarchical structure in the latent space. The method proposed in this paper uses then a single (hyperbolic) embedding of entities across all relation types. This implies that there should be a single consistent hierarchy that explains all the links in all relations. This seems unlikely and might explain some of the hyperbolic results. A more detailed discussion and motivation would be important here.\n\n- Regarding the experimental results: Why are the results for HolE and ComplEx so different? As [1,2] showed, both models are identical, and for that reason should get close to identical results. The large differences seem inconsistent with these results. Furthermore it seems that the results reported in this paper do not match previously reported results. What is the reason for these discrepancies?\n\n[1] Hayashi, K., and Shimbo, M. ""On the equivalence of holographic and complex embeddings for link prediction"", 2017.\n[2] Trouillon, T, and Nickel, M. ""Complex and Holographic Embeddings of Knowledge Graphs: A Comparison"", 2017.']","[-50, 50, -20]","[20, 70, 60]","[""The sentiment score is -50 because the reviewer expresses several concerns and doubts about the paper's clarity, usefulness, and experimental results. They mention finding it 'very hard to digest', being confused by figures, and noting that the method underperforms compared to baselines. The update also indicates that the results are 'inconclusive' and the paper 'needs more work'. However, it's not entirely negative as they acknowledge it as an 'interesting recent approach'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'I would be curious about' and 'I thank the authors for their response', which show respect. However, the criticism is direct without much softening language, keeping the score only slightly positive."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'especially interesting' and notes that the results look 'promising' on some datasets. However, they also point out limitations, such as less accurate results on other datasets and some unclear explanations. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'it may be worth noticing' and 'this section was a bit hard to follow' rather than harsh or dismissive language. The reviewer also provides specific suggestions for improvement and references to support their points, which is a polite and professional approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's potential and relevance ('Hyperbolic and Riemannian embeddings are a promising research area that fits well into ICLR'), they express several significant concerns about the current version. These concerns include questioning the motivation for the proposed approach, doubting whether the benefits of hyperbolic embeddings translate to this setting, and pointing out inconsistencies in the experimental results. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'It is not clear to me' and 'A more detailed discussion and motivation would be important here', which present concerns in a constructive manner rather than dismissively. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"['Summary\n\nThe paper presents a novel approach for learning a generative model where different factors of variations can be independently manipulated. The method is build upon  the GAN framework where the latent variables are divided into different subsets (chunks) which are expected to encode information about high-level factors of variation. To this end, a Siamese Network for each chunk is trained with a contrastive loss minimizing the distance between generated images sharing the same factor (the latent variables in the chunk are equal), and maximizing the distance between pairs where the latent variables differ. Given that the proposed model fails in this fully-unsupervised setting, the authors propose to add weak-supervision into the model by forcing the Siamese networks to  focus only on particular aspects of generated images (e.g, color, edges, etc..). This is achieved by applying  a basic transformation  over the input images in order to remove specific information. The evaluation of the  proposed model is carried out using the MS-Celeb dataset where the authors provide qualitative results.\n\n\nMethodology\n\n*Disentangling generative factors without explicit labels is a challenging and interesting problem. The idea of dividing the latent representation in different subsets and using a proxy task involving triplets of images has been already explored in [3]. However, the use of Siamese networks in this context is novel and sound.\n\n*As shown in the reported results, the proposed method fails to learn meaningful factors in the unsupervised setting. However, the authors do not provide an in-depth discussion of this phenomena. Given that previous works [1,2,3] have successfully addressed this problem using a completely unsupervised approach, it would be necessary to give more insights about: (i) why the proposed method is failing (ii) why this negative result is interesting and (iii) if the method could be useful in other potential scenarios. \n\n*The strategy proposed to introduce weak-supervision is too ad-hoc. I agree that using cues such as the average color of an image can be useful if we want to model basic factors of variation. However, it is unclear how a similar strategy could be applied if we are interested in learning variables with higher-level semantics such as the expression of a face or its pose.\n\n*As far as I understand, the transformations applied to the input images (e.g, edge detection) must be differentiable (given that it is necessary to backpropagate the gradient of the contrastive loss through the generator network). If this is the case, this should be properly discussed in the paper. Moreover, given that the amount of differentiable transformations is reduced, this also limits the application of the proposed method for more interesting scenarios. \n\n*It is not clear why the latent variables modelling the generative factors are defined using a Gaussian prior. How the case where two images have a very similar latent factor is avoided while generating pairs of images for the Siamese network?  Have the authors considered to use categorical or binary variables? The use of the contrastive loss sounds more appropriate in this case.\n\n\nExperimental results\n\n*The experimental section is too limited. First of all, only a small number of qualitative results are reported and, therefore, it is very difficult to assess the proposed method and draw any conclusion. For example, when the edge extractor is used, what kind of information is modeled by the latent variables? Is it consistent across different samples?\n\nMoreover, it is not clear why the authors have limited the evaluation to the case where only two “chunks” are used. In principle, the method could be applied with many more subsets of latent variables and then manually inspect them to check it they are semantically meaningful (see [2]) \n\n*As previously mentioned, there are many recent works addressing the same problem from a fully-unsupervised perspective [1,2,3]. All these works provide quantitative results evaluating the learned representations by using them to predict real labels (e.g, attributes in the CelebA data-set). The authors could provide a similar evaluation for their method by using the feature representations learned by the siamese networks in order to evaluate how much information they convey about real factors of variation. This could clarify the advantages of the weakly-supervised strategy compared to unsupervised approaches.\n\nReview summary\n\n+The addressed problem (learning disentangled representations without explicit labeling) is challenging and interesting.\n\n+The idea of using a proxy task (contrastive loss with triplets of generated images) is somewhat novel and promising.\n\n- The authors report only negative results for the fully-unsupervised version of UD-GAN The paper lacks and in-depth discussion about why this negative result is interesting.\n\n-The strategy proposed to provide weak-supervision to the model is too ad-hoc and it is not clear how to apply it in general applications\n\n-The experimental section do not clarify the benefits of the proposed approach. In particular, the qualitative results are too limited and no quantitative evaluations is provided.\n\n\n[1] Variational Inference of Disentangled Latent Concepts from Unlabelled Observations (Kumar et al, ICLR 2018)\n\n[2] Beta-vae: Learning basic visual concepts with a constrained variational framework. (Higgins et. al, ICLR 2017)\n\n[3] Disentangling Factors of Variation by Mixing Them. (Hu et. al, CVPR  2018)\n', 'The paper proposes a framework for learning interpretable latent representations for GANs. The key idea is to use siamese networks with contrastive loss. Specifically, it decomposes the latent code to a set of knobs (sub part of the latent code). Each time it renders different images with different configurations of the knobs. For example, 1) as changing one knob while keeping the others, it expects it would only result in change of one attribute in the image, and 2) as keeping one knob while changing all the others, it expects it would result in large change of image appearances. The relative magnitude of change for 1) and 2) justifies the use of a Siamese network in addition to the image discriminator in the standard GAN framework. The paper further talks about how to use inductive bias to design the Siamese network so that it can control the semantic meaning of a particular knob. \n\nWhile I do like the idea, I think the paper is still in the early stage. First of all, the paper does not include any numerical evaluation. It only shows a couple of examples. It is unclear how well the proposed method works in general. In addition, the InfoGAN work is designed  for the same functionality. The paper should compare the proposed work to the InfoGAN work both quantitatively and qualitatively to justify its novelty. ', '[EDIT]: I have updated my score after the author response and paper revision.\n=============================\n\n[I was asked to step in as a reviewer last minute. I did not look at the other reviews].\n\n-------------------------------\nSummary\n-------------------------------\nThis paper proposes to learn disentangled latent states under the GAN framework. The core idea is to partition the latent states into N partitions, and correspondly have N Siamese networks that pull the generated images with the same latent partition towards each other, along with a contrastive loss which ensures generated images with different latent partitions to be different. The authors experiment with two setups: in the ""unguided setup"" training is completely unsupervised, while in the ""guided"" setup, there is some weak supervision to encourage different partitions to learn different factors.\n\n-------------------------------\nEvaluation\n-------------------------------\nWhile the motivation is nice, I find the results (especially in the unguided setup) underwhelming. This does not seem surprising to me, as in the unguided case, the constrative loss seems not strong enough to encourage the latent partitions to be different. Results with weak supervision (their method for injecting weak supervision was very nice) are more impressive. However, there is no comparison against existing work. Learning disentangled representations with deep generative models is very much an active area. Here are some recent papers:\n\nhttps://openreview.net/references/pdf?id=Sy2fzU9gl\nhttps://arxiv.org/abs/1802.05822\nhttps://arxiv.org/abs/1802.05983\nhttps://arxiv.org/abs/1802.04942\n\nImportantly, there are no quantitative metrics. I do not think this work is ready for publication.\n\n\n', '[Edit] I changed my rating from 4 to 5 based on the author responses.\n=======\nThis paper proposed a GAN that learns a disentangled factors of variations in unsupervised (or weakly-supervised) manner. To this end, the proposed method incorporates a contrastive loss together with Siamese network, which encourages the generator to output smaller variations in samples if they are drawn by varying the same latent factors. The proposed idea is evaluated on simple datasets such as MNIST and centered faces, and show that it is able to learn disentangled latent codes by incorporating some heuristics. \n\nAlthough the paper presents an interesting and reasonable idea, I think the paper is incomplete and in the proof-of-concept stage. In terms of method, the guidance for learning Siamese networks are designed heuristically (e.g. edges, colors, etc.) which limits its applicability over various datasets; I think that designing more principled approach to build such guidances from data should be one of the key contributions of the paper. In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing. \n\nIn conclusion, I suggest a reject of this paper due to the lacks of comprehensive study and evaluation.\n']","[-30, -20, -60, -60]","[50, 50, 20, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'challenging and interesting problem', 'novel and promising idea'), they express significant concerns about the methodology, experimental results, and lack of in-depth discussion. The review lists more negative points than positive ones, indicating an overall negative sentiment. However, it's not extremely negative, as the reviewer still sees some value in the work.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms (e.g., 'it is not clear', 'the experimental section is too limited') rather than harsh or dismissive language. The reviewer also acknowledges positive aspects of the work before presenting criticisms. However, the score is not higher because the review doesn't include explicitly polite phrases or go out of its way to soften criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges liking the idea, they express significant concerns about the paper being in an early stage, lacking numerical evaluation, and not comparing to similar existing work (InfoGAN). The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with a positive note ('I do like the idea') and providing constructive criticism without harsh or dismissive language. They offer specific suggestions for improvement rather than outright rejection, maintaining a professional and courteous tone."", ""The sentiment score is -60 because the reviewer finds the results 'underwhelming', states there is 'no comparison against existing work', and concludes that the work is 'not ready for publication'. These are significant criticisms, though the reviewer does acknowledge some positive aspects like the 'nice' motivation and 'impressive' results with weak supervision. The politeness score is 20 because the reviewer uses generally neutral language and offers some positive comments, but is also quite direct in their criticisms. They provide constructive feedback by suggesting relevant papers and pointing out specific areas for improvement, which adds to the politeness, but the overall tone remains critical."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, calling it 'incomplete and in the proof-of-concept stage', criticizing its limited applicability and lack of comprehensive evaluation, and ultimately suggesting rejection. However, they do acknowledge the idea as 'interesting and reasonable', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I think' and 'I suggest' rather than making blunt statements, and they acknowledge positive aspects before presenting criticisms. The language is not overtly polite, but it avoids rudeness and maintains a constructive tone despite the negative overall assessment.""]"
"['This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches.\n\nStrength:\n- important problem\n\nWeakness:\n- the novelty of the proposed method is very marginal\n- the experiments are quite weak\n\nDetails:\n- the novelty of the proposed method seems to be very marginal, which simply applies the GCN for link prediction. The existing GCN based method for recommendation shares similar ideas (e.g., Yin et al. 2018, PinSage), though dual hypergraph is not used. But the essential idea is very similar. \n- the data sets used in the experiments are too small\n- the node embedding based methods should be compared for link prediction, e.g., DeepWalk, LINE, and node2vec.\n', 'This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails.\n\nThe problem of link prediction in hypergraph is important and interesting, especially in the chemistry domain. However from the technical point of view, this work is somewhat incremental since prior work has done link prediction using GCN (Zhang and Chen, 2018). The idea of performing hyperlink prediction in the dual hypergraph is not new, either (Lugo-Martinez and Radivojac, 2017). As for the directed hypergraph setting, it seems to be a straightforward extension once one knows how to do in the undirected setting (adding an extra term to classify head/tail).\n\nIn terms of experiments, given the similarity between Lugo-Martinez and Radivojac, 2017 and NHP (both operates in the dual hypergraph), it would be better if the former could also be used as a baseline, as least in the undirected setting.\n\nIt is reasonable to have a subset of links as candidate reactions in the metoboli network datasets. For CORA and DBLP, it is not clear where the ‘actual papers’ and ‘candidate papers’ come from. For example in CORA there are 1072 authors; yet there are only 5416 candidate papers.\n\nIt seems the joint learning of NHP-D does not improve the accuracy in the directed setting as claimed in Sec. 5.2. Besides, there is no baseline in the directed setting. It is difficult to appreciate the performance in Sec. 6. One thing one can do is to use previous methods in the undirected setting, e.g., CMM, with the extra term L_d in Eq. (4).\n\nMinor comments:\nTypo: \nP5: atleast -> at least\nP5: What is GCN 2?\nSec. 5: ‘p = 32 in 1’ and ‘shown in 2’\n\nMissing references on link prediction and/or deep learning:\nDiscriminative relational topic models. PAMI 2014.\nRelational deep learning: A deep latent variable model for link prediction. AAAI 2017\nNeural relational topic models for scientific article analysis. CIKM 2018.', '[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? somewhat\n\n[Novelty] Are the problems or approaches novel? rather incremental\n\n[Soundness] Is the paper technically sound? yes\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal\n\n[Clarity] Is the paper well-organized and clearly written? okay\n\nConfidence: 2/5\n\nSeen submission posted elsewhere: No\n\nDetailed comments:\n\nIn this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches.\n\n=== Major comments\n\nI found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion.\n\nIt is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the “10 trials” mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why “fake papers” are needed for the citation networks; it is clear that “fake author lists” are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen.\n\nI appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work.\n\n=== Minor comments\n\nThis work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here.\n\nAccording to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP’s performance and the size/density of the graph? or is there some other explanation for this behavior?\n\nRelated to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes?\n\nThe described strategy for negative sampling seems as though it selects “easy” negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more “difficult” (or just uniformly random) negative samples are chosen?\n\nI believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable.\n\n=== Typos, etc.\n\nIn Equation (4), the “k” index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}.\n\n“table 2” -> “Table 2”, and many other similar examples throughout the paper.\n\n“higher-order etc.” -> “higher-order, etc.”\n“GCN based” -> “GCN-based”, and similar in several places in the paper\n“a incomplete” -> “an incomplete”\n']","[-50, -20, -20]","[20, 50, 60]","[""The sentiment score is -50 because the review highlights significant weaknesses, including 'very marginal' novelty and 'quite weak' experiments, while only briefly mentioning one strength. The overall tone suggests the reviewer is not impressed with the paper. The politeness score is 20 because the language is professional and objective, avoiding harsh criticism, but also not overly polite. The reviewer uses neutral phrases like 'the novelty seems to be very marginal' rather than more direct criticism. The structured format with 'Strength' and 'Weakness' sections also contributes to a professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem, they criticize the work as 'somewhat incremental' and point out several limitations. They also suggest additional comparisons and experiments that should have been included. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, offers constructive criticism, and provides specific suggestions for improvement. They avoid harsh language and frame their critiques as opportunities for enhancement rather than outright flaws."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'the paper is technically sound', 'code is available'), they express significant concerns about novelty ('rather incremental', 'novelty... rather limited') and the strength of experimental results ('marginal', 'difficult to interpret'). The overall tone suggests the reviewer is not fully convinced of the paper's merits. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciate that...', 'I found...', and 'I believe...' which soften criticism. They also provide constructive feedback and specific suggestions for improvement, which is considerate. The reviewer avoids harsh language or personal attacks, contributing to the polite tone.""]"
"[""The paper ‘Generative model based on minimizing exact empirical Wasserstein distance' proposes\na variant of Wasserstein GAN based on a primal version of the Wasserstein loss rather than the relying\non the classical Kantorovich-Rubinstein duality as first proposed by Arjovsky in the GAN context.\nComparisons with other variants of Wasserstein GAN is proposed on MNIST.\n\nI see little novelty in the paper. The derivation of the primal version of the problem is already \ngiven in  \nCuturi, M., & Doucet, A. (2014, January). Fast computation of Wasserstein barycenters. In ICML (pp. 685-693).\n\nUsing optimal transport computed on batches rather the on the whole dataset is already used in (among\nothers)\n Genevay, A., Peyré, G., & Cuturi, M. (2017). Learning generative models with sinkhorn divergences. AISTATS\n Damodaran, B. B., Kellenberger, B., Flamary, R., Tuia, D., & Courty, N. (2018). DeepJDOT: Deep Joint distribution optimal transport for unsupervised domain adaptation. ECCV  \n\nAlso, the claim that the exact empirical Wasserstein distance is optimized is not true. The gradients, evaluated on \nbatches, are biased. Unfortunately, the Wasserstein distance does not enjoy similar U-statistics as MMD. It is very \nwell described in the paper (Section 3): \nhttps://openreview.net/pdf?id=S1m6h21Cb\n\nComputing the gradients of Wasserstein on batches might be seen a kind of regularization, but it remains to be\nproved and discussed.\n\nFinally, the experimental validation appears insufficient to me (as only MNIST or toy datasets are considered).\n\n\nTypos:\n Eq (1) and (2): when taken over the set of all Lipschitz-1 functions, the max should be a sup "", ""The authors propose to estimate and minimize the empirical Wasserstein distance between batches of samples of real and fake data, then calculate a (sub) gradient of it with respect to the generator's parameters and use it to train generative models.\n\nThis is an approach that has been tried[1,2] (even with the addition of entropy regularization) and studied [1-5] extensively. It doesn't scale, and for extremely well understood reasons[2,3]. The bias of the empirical Wasserstein estimate requires an exponential number of samples as the number of dimensions increases to reach a certain amount of error [2-6]. Indeed, it requires an exponential number of samples to even differentiate between two batches of the same Gaussian[4]. On top of these arguments, the results do not suggest any new finding or that these theoretical limitations would not be relevant in practice. If the authors have results and design choices making this method work in a high dimensional problem such as LSUN, I will revise my review.\n\n[1]: https://arxiv.org/abs/1706.00292\n[2]: https://arxiv.org/abs/1708.02511\n[3]: https://arxiv.org/abs/1712.07822\n[4]: https://arxiv.org/abs/1703.00573\n[5]: http://www.gatsby.ucl.ac.uk/~gretton/papers/SriFukGreSchetal12.pdf\n[6]: https://www.sciencedirect.com/science/article/pii/0377042794900337"", 'The paper proposed to use the exact empirical Wasserstein distance to supervise the training of generative model. To this end, the authors formulated the optimal transport cost as a linear programming problem. The quantitative results-- empirical Wasserstein distance show the superiority of the proposed methods.\n \nMy concerns come from both theoretical and experimental aspects:\nThe linear-programming problem Eq.(4)-Eq.(7) has been studied in existing literature.\nThe contribution is about combining this existing method to supervise a standard neural network parametrized generator, so I am not quite sure if this contribution is sufficient for the ICLR submission.\nIn such a case, further experimental or theoretical study about the convergence of Algorithm 1 seems important to me.\n \nAs to the experiments, firstly, EWD seems to be a little bit biased since EWD is literally used to supervise the training of the proposed method.\nOther quantitative metric studies can help justifying the improvement.\nAlso, given that the paper brings the WGAN family into comparison, the large scale image dataset should be included since WGAN have already demonstrated their success.\n \nLast things, missing parentheses in step 8 of Algorithm 1 and overlength of url in references.\n']","[-70, -80, -20]","[-20, -20, 60]","[""The sentiment score is -70 because the reviewer expresses significant criticism and sees 'little novelty' in the paper. They point out multiple issues, including lack of originality, incorrect claims, and insufficient experimental validation. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the feedback or provide positive comments. The reviewer bluntly states issues and doesn't use polite phrases or acknowledgments of the authors' efforts. The slightly negative politeness score reflects this lack of courtesy rather than outright rudeness."", ""The sentiment score is -80 because the reviewer is highly critical of the proposed approach, stating that it has been tried before, doesn't scale, and has well-understood limitations. The reviewer also mentions that the results don't suggest any new findings or practical relevance. The politeness score is -20 because while the reviewer isn't overtly rude, the tone is quite dismissive and blunt. The reviewer directly states that the approach 'doesn't scale' and uses phrases like 'extremely well understood reasons' which can come across as somewhat condescending. However, the reviewer does offer to revise their review if the authors can provide evidence of the method working in high-dimensional problems, which slightly mitigates the overall negative tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'show the superiority of the proposed methods'), they express several concerns and suggest that the contribution may not be sufficient for the submission. The overall tone indicates more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as 'concerns' rather than direct attacks, and uses polite language like 'seems important to me' when making suggestions. The reviewer also provides constructive feedback and specific recommendations for improvement, which contributes to the polite tone.""]"
"['This paper proposes some new angles to the problem of imitation learning from state only observations (not state-action pairs which are more expensive). \nSpecifically, the paper proposes ""self exploration"", in which it mixes the imitation reward with environment reward from the MDP itself in a gradual manner, guided by the rate of learning.\nIt also proposes a couple of variants of imitation rewards, RTGD and ATD inparticular, which formulate the imitation rewards for random or exhaustive pairs of states in the observation data, as opposed to the rewards proposed in existing works (CSD, SSD), which are based on either consecutive or single states, which constitute the baseline methods for comparison.\nThe authors then perform a systematic experiment using a particular navigation problem on a grid world, and inspect under what scenarios (e.g. when the action spaces of the expert and learner are the same, disjoint or in a containment relationship) which of the methods perform well relative to the baselines. \nSome moderately interesting observations are reported, which largely confirm one\'s intuition about when these methods may perform relatively well. \nThere is not very much theoretical support for the proposed methods per se, the paper is mostly an empirical study on these competing reward schemes for imitation learning.\nThe empirical evaluation is done in a single domain/problem, and in that sense it is questionable how far the observed trends on the relative performance of the competing methods generalizes to other problems and domains. \nAlso the proposed ideas are all reasonable but relatively simple and unsurprising, casting some doubt as to the extent to which the paper contributes to the state of understanding of this area of research. ', ""The paper proposes to combine expert demonstration together with reinforcement learning to speed up learning of control policies. To do so, the authors modify the GAIL algorithm and create a composite reward function as a linear combination of the extrinsic reward and the imitation reward. They test their approach on several toy problems (small grid worlds). \n\nThe idea of combining GAIL reward and extrinsic reward is not really new and quite straight forward so I wouldn't consider this as a contribution. Also, using state only demonstration in the framework of GAIL is not new as the authors also acknowledge in the paper. Finally, I don't think the experiments are convincing since the chosen problems are rather simple. \n\nBut my main concern is that the major claim of the authors is that they don't use expert actions as input to their algorithm, but only sequences of states. Yet they test their algorithm on deterministic environments. In such a case, two consecutive states kind of encode the action and all the information is there. Even if the action sets are different in some of the experiments, they are still very close to each other and the encoding of the expert actions in the state sequence is probably helping a lot. So I would like to see how this method works in stochastic environments. "", 'The draft proposes a heuristic combining environment rewards with an IRL-style rewards recovered from expert demonstrations, seeking to extend the GAIL approach to IRL to the case of mismatching action spaces between the expert and the learner. The interesting contribution is, in my opinion, the self-exploration parameter that reduces the reliance of learning on demonstrations once they have been learned sufficiently well.\n\nQuestions:\n\n- In general, it\'s known that behavioral cloning, of which this work seem to be an example in so much it learns state distributions that are indistinguishable from the expert ones, can fail spectacularly because of the distribution shift (Kaariainen@ALW06, Ross&Bagnell@AISTATS10, Ross&Bagnell@AISTATS11). Can you comment if GAN-based methods are immune or susceptible to this?\n   \n- Would this work for tasks where the state-space has to be learned together with the policy? E.g. image captioning tasks or Atari games.\n\n- Is it possible to quantify the ease of learning or the frequency of use of the ""new"" actions, i.e. $A^l \\setminus A^e$?. Won\'t learning these actions effectively be as difficult as RL with sparse rewards? Say, in a grid world where 4-way diagonal moves allow reaching the goal faster, learner is king 8-way, demonstrations come from a 4-way expert, rewards are sparse and each step receives a -1 reward and the final goal is large positive -- does the learner\'s final policy actually use the diagonals and when?\n\nRelated work:\n   \n- Is it possible to make a connection to (data or policy) aggregation methods in IL. Such methods (e.g. Chang et al.@ICML15) can also sometimes learn policies better than the expert.\n\nExperiments:\n- why GAIL wasn\'t evaluated in Fig. 3 and Fig. 4?\n\nMinor:\n- what\'s BCE in algorithm 1?    \n- Fig.1: ""the the""\n- sec 3.2: but avoid -> but avoids\n- sec 3.2: be to considers -> be to consider\n- sec 3.2: any hyperparameter -> any hyperparameters\n- colors in Fig 2 are indistinguishable\n- Table 1: headers saying which method is prior work and which is contribution would be helpful\n- Fig. 3: if possible try to find a way of communicating the relation of action spaces between expert and learner (e.g. a subset of/superset of). Using the same figure to depict self-exploration make it complicated to analyse.\n- sec 3.2: wording in the last paragraph on p.4 (positive scaling won\'t _make_ anything positive if it wasn\'t before)']","[-20, -60, 50]","[50, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('moderately interesting observations', 'reasonable' ideas), they express several criticisms. These include questioning the generalizability of the results, doubting the extent of the paper's contribution, and noting the lack of theoretical support. The overall tone suggests skepticism about the paper's significance.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They use neutral language to express their criticisms, avoiding harsh or dismissive phrasing. The reviewer acknowledges positive aspects of the work and provides specific, constructive feedback. However, the score is not higher because the review lacks overtly polite or encouraging language, maintaining a somewhat detached tone."", ""The sentiment score is -60 because the reviewer expresses several significant concerns about the paper's contributions and experiments. They state that the main idea is 'not really new,' the experiments are 'not convincing,' and they have a 'main concern' about the paper's major claim. However, it's not entirely negative as they do acknowledge some aspects of the work. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and relatively polite manner. They use phrases like 'I wouldn't consider' and 'I don't think' rather than making blunt statements. They also use 'But my main concern is...' to introduce their primary criticism, which is a polite way to express a significant issue. The language is generally neutral and academic, avoiding any rudeness or overly harsh criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the 'interesting contribution' of the work, which indicates a positive view. However, the rest of the review consists of questions and suggestions for improvement, which balances out the initial positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and provides detailed, constructive feedback. The use of phrases like 'Can you comment' and 'Is it possible' shows a polite approach to requesting clarifications. The reviewer also offers helpful suggestions for improvements in a courteous manner, such as 'headers saying which method is prior work and which is contribution would be helpful'.""]"
"['Overview:\n\nThis paper proposed an approach for zero-shot phoneme recognition, where it is possible to recognise phonemes in a target language which has never been seen before. Rather than just training a phoneme recogniser directly on background data and then applying it to unseen data, phonetic features are first predicted, allowing phonemes not in the source language set to be predicted.\n\nMain strengths:\n\nThe paper\'s main strength lies in that this is a very unexplored area that could assist in the development of speech technology where it is currently not possible. The proposed model (Section 2) has also not been considered in prior work.\n\nMain weaknesses:\n\nThe paper\'s main weakness is in some of its claims and that it misses some very relevant literature. Detailed comments together with a minimal list of references are given below (but I would encourage the authors to also read a bit more broadly). But in short I do not think it is that easy to claim that this is the first paper to do zero-shot learning on speech; many of the zero-resource studies where unlabelled audio is used could be seen as doing some for of zero-shot matching. Specifically [5] is able to predict unseen phoneme targets.  Multilingual bottleneck features can be applied to languages that have never been seen before [2], and the output of phoneme recognisers trained on one language have long been applied to get output on another unseen language. The first one-shot learning speech paper [4] (to my knowledge) is also not mentioned at all. The approach in the paper also still relies on some text data from the target language; if this then can be described as ""zero-shot"" learning, then I think many of these previous studies c also make this claim.\n\nOverall feedback:\n\nThere is definitely value in this work, but it should be much better situated within the broader literature. Below I give some editorial suggestions and also outline some suggestions for further experiments.\n\nDetailed comments, suggestions and questions:\n\n- Abstract: It would be useful to have some details of the ""baseline model"" here already, especially since it is such a new task.\n- Introduction: ""... but they can hardly predict phones or words directly due to their unsupervised nature."" This is a strong statement that maybe requires more justification. On the one hand, the statement is true, and the high word error rates in e.g. [3] can be cited. On the other hand, it has been shown that at the phone-distinction level, these models perform quite well and sometimes outperform supervised models [1]. Since this paper also considers phone error rate as a metric, I think care should be taken with such statements.\n- Introduction: ""While zero-shot learning has attracted a lot of attention in *the* computer vision community, this setup has hardly been studied in speech recognition research especially in acoustic modeling."" Definitely look at some of the studies mentioned below, and also [4] specifically.\n- ""However, we note that our model can be combined with a well-resourced language model to recognize words."" How would this be done, since I think this is actually quite a challenging task.\n- Section 2: ""... useful the original ESZSL architecture ..."" -> ""... useful in the original ESZSL architecture ...""\n- Section 2.2: I assume the small text corpus is at the phone level (and not characters directly)? This should be clarified, and it could raise the question of whether this approach is truly ""zero-shot"".\n- Section 3.2: ""We used EESEN framework ..."" -> ""We used the EESEN framework ...""\n- Section 4: You could look at the recent work in [2], which uses multilingual bottleneck features trained on 10 languages and applied to multiple unseen languages. It would be interesting to also train your approach on multiple languages instead of only English.\n\nMissing references:\n\n1. M. Heck, S. Sakti, and S. Nakamura, ""Feature Optimized DPGMM Clustering for Unsupervised Subword Modeling: A Contribution to Zerospeech 2017,"" in Proc. ASRU, 2017.\n2. E. Hermann and S. J. Goldwater, ""Multilingual bottleneck features for subword modeling in zero-resource languages,"" in Proc. Interspeech, 2018.\n3. H. Kamper, K. Livescu, and S. Goldwater, An embedded segmental k-means model for unsupervised segmentation and clustering of speech,"" in Proc. ASRU, 2017.\n4. B. M. Lake, C.-Y. Lee, J. R. Glass, and J. B. Tenenbaum, ""One-shot learning of generative speech concepts,"" in Proc. CogSci, 2014.\n5. O. Scharenborg, F. Ciannella, S. Palaskar, A. Black, F. Metze, L. Ondel, and M. Hasegawa-Johnson, ""Building an ASR system for a low-resource language through the adaptation of a high-resource language asr system: Preliminary results,""in Proc. ICNLSSP, 2017.\n\nEdit: Based on the rebuttal I\'ve changed my rating from 4 to 5.', 'This paper proposes to train a Universal Phonetic Model for building speech recognition for new languages without any training data. It suggests to use X-SAMPA to map phones from all the languages into a single phonetic space. The prediction models are designed to first predict the phonetic features and then the phones depending on the target language.\nOverall , the paper is quite clear written. \n- Strengthens:\n+ It observed overall improvements for all the target languages.\n\n- Weaknesses:\n+ The idea and the proposed model are not novel. \n+ All the baseline systems have relative high phone error rates.\n+ The authors claimed to have a universal phonetic model but actually the model was trained only with English data. Therefore, experimental setup could be improved. In my opinion, it makes more sense to define a bunch of resource-rich languages as source and then train a real universal phonetic model. \n+ Overall, this paper lacks an analysis what are exactly improved and why the improvements for some target languages are larger than for the others.\n ', ""This paper presents an approach to address the task on zero-shot learning for speech recognition, which consist of learning an acoustic model without any resources for a given language. The universal phonetic model is proposed, which learns phone attributes (instead of phone label), which allows to do prediction on any phone set, i.e. on any language. The model is evaluated on 20 languages and is shown to improve over a baseline trained only on English.\n\nThe proposed UPM approach is novel and significant: being able to learn a more abstract representation for phones which is language-independent is a very promising lead to handle the problem of ASR on languages with low or no resources available. \n\nHowever, the results are the weak point of the paper. While the results demonstrate the viability of the approach, the gain between the baseline performance and the UPM model is quite small, and it's still far from being usable in practice. \n\nTo improve the paper, the authors should discuss the future work, i.e. what are the next steps to improve the model.\n\nOverall, the paper is significant and can pave the way for a new category of approaches to tackle zero-shot learning for speech recognition. Even if the results are not great, as a first step they are completely acceptable, so I recommend to accept the paper.\n\nRevision:\nThe approach of using robust features is interesting and promising, as well as the idea of training on multiple languages. Overall, the authors response addressed most of the issues, therefore I am not changing my rating.""]","[50, -20, 70]","[75, 50, 80]","[""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's strengths and potential value, they also point out significant weaknesses and missing literature. The overall tone is constructive, suggesting improvements rather than outright rejection. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides detailed suggestions for improvement. They use phrases like 'I would encourage the authors' and 'There is definitely value in this work,' which maintain a positive and supportive tone even while critiquing. The reviewer also acknowledges the authors' rebuttal by changing their rating, showing openness to dialogue."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths ('observed overall improvements'), they list more weaknesses than strengths. The criticisms are substantial, pointing out lack of novelty, high error rates in baselines, and issues with the experimental setup and analysis. However, the tone isn't entirely negative, as they do mention positive aspects and the overall clarity of the paper. The politeness score is moderately positive (50) because the language used is professional and constructive. The reviewer uses phrases like 'Overall, the paper is quite clear written' and presents criticisms as observations rather than harsh judgments. They also use polite language like 'In my opinion' when suggesting improvements. The review maintains a respectful tone throughout, even when pointing out weaknesses."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper is 'novel and significant', 'very promising', and recommends acceptance despite some limitations. They view it as an important first step in a new approach. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively (e.g., 'To improve the paper, the authors should...'). The reviewer also maintains a positive tone even when discussing weaknesses, using phrases like 'Even if the results are not great, as a first step they are completely acceptable'.""]"
"['\nSummary:\n========\nTheis paper proposes a method for learning decomposable representations in the context of a language modeling task. Using holographic reduced representations (HRR), a word embedding is composed of a role and a filler. The embedding is then fed to an LSTM language model. There is also an extension to chunk-level representations. Experimentally, the model achieves perplexity comparable to a (weak) baseline LSTM model. The analysis of the learned representations shows a separation into syntactic and semantic roles. \n\nThe paper targets an important problem, that of learning decomposable representations. As far as I know, it introduces a novel perspective using HRR and does so in the context of language modeling, which is a core NLP task. The analysis of the learned representations is quite interesting. I do have some concerns with regards to the quality of the language model, the clarity of some of the model description, and the validity of using HRR in this scenario. Please see detailed comments below. \n\nComments:\n=========\n1. Section 2 refers to Plate (1995) for the conditions when the approximate decoding via correlation holds. I think it\'s important to mention these conditions and discuss whether they apply to the language modeling case. In particular, Plate mentions that the elements of each vector need to be iid with mean zero and variance 1/n (where n is the length of the vector). Is this true for the present case? Typically, word embeddings and LSTM states are do not exhibit this distribution. Are there other conditions that are (not) met?\n2. Learning separate bases for different role-filler bindings is said to encourage the model to learn a decomposition of word representation. On the other hand, if I understand correctly, this means that word embeddings are not shared between roles, because s^w_i is also a role-specific vector (not just a word-specific vector). Is that a cause of concern? \n3. It\'s not clear to me where in the overall model the next word is predicted. Figure 1b has an LSTM that predicts filler embeddings. Does this replace predicting the next word in a vanilla LSTM? Equation 5 still computes a word score. Is this used to compute the probability of the next word as in equation 2?  \n4. Comparison to other methods for composing words. Since much of the paper is concerned with composing words, it seem natural to compare the methods (and maybe some of the results) to methods for composing words. Some examples include [2] and the line of work on recursive neural networks by Socher et al., but there are many others. \n5. Perplexity results:\n- The baseline results (100.5 ppl on PTB) are very weak for an LSTM. There are multiple papers showing that a simple LSTM can do much better. The heavily tuned LSTM of [1] gets 59.6 but even less tuned LSTMs go under 80 or 80 ppl. See some results in [1]. This raises a concern that the improvements from the HRR model may not be significant. Would they hold in a more competitive model? \n- Can you speculate or analyze in more detail why the chunk-level model doesn\'t perform well, and why adding more fillers doesn\'t help in this case? \n6. Motivation: \n- The introduction claims that the dominant encoder-decoder paradigm learns ""transformations from many smaller comprising units to one complex emedding, and vice versa"". This claim should be qualified by the use of attention, where there is not a single complex embedding, rather a distribution over multiple embeddings. \n- Introduction, first paragraph, claims that ""such crude way of representing the structure is unsatisfactory, due to a lack of transparency, interpretability or transferability"" - what do you mean by these concepts and how exactly is the current approach limited with respect to them? Giving a bit more details about this point here or elsewhere in the paper would help motivate the work. \n7. Section 3.3 was not so clear to me:\n- In step 1, what are these r_i^{chunk}? Should we assume that all chunks have the same role embeddings, despite them potentially being syntactically different? How do you determine where to split output vectors from the RNN to two parts? What is the motivation for doing this?\n- In prediction, how do you predict the next chunk embedding? Is there a different loss function for this? \n- Please provide more details on decoding, such as the mentioned annealing and regularization. \n- Finally, the reliance on a chunker is quite limiting. These may not be always available or of high quality. \n8. The analysis in section 4.3 is very interesting and compelling. Figure 2 makes a good point. I would have liked to see more analysis along these lines. For example, more discussion of the word analogy results, including categories where HRR does not do better than the baseline. Also consider other analogy datasets that capture different aspects. \n9. While I agree that automatic evaluation at chunk-level is challenging, I think more can be done. For instance, annotations in PTB can be used to automatically assign roles such as those in table 4, or others (there are plenty of annotations on PTB), and then to evaluate clustering along different annotations at a larger scale. \n10. The introduction mentions a subset of the one billion word LM dataset (why a subset?), but then the rest of the papers evaluates only on PTB. Is this additional dataset used or not? \n11. Introduction, first paragraph, last sentence: ""much previous work"" - please cite such relevant work on inducing disentangled representations.\n12. Please improve the visibility of Figure 1. Some symbols are hard to see when printed. \n13. More details on the regularization on basis embeddings (page 4) would be useful. \n14. Section 3.3 says that each unique word token is assigned a vectorial parameter. Should this be word type? \n15. Why not initialize the hidden state with the last state from the last batch? I understand that this is done to assure that the chunk-level models only consider intra-sentential information, but why is this desired? \n16. Have you considered using more than two roles? I wonder how figure 2 would look in this case. \n\n\nWriting, grammar, etc.:\n====================== \n- End of section 1: Our papers -> Our paper\n- Section 2: such approach -> such an approach; HRR use -> HRR uses; three operations -> three operations*:*\n- Section 3.1: ""the next token w_t"" - should this be w_{t+1)? \n- Section 3.2, decoding: remain -> remains \n- Section 3.3: work token -> word token \n- Section 4.1: word analogy task -> a word analogy task; number basis -> numbers of basis\n- Section 4.2: that the increasing -> that increasing \n- Section 4.3: no space before comma (first paragraph); on word analogy task -> on a word analogy task; belong -> belongs\n- Section 4.4: performed similar -> performed a similar; luster -> cluster \n- Section 5: these work -> these works/papers/studies; share common goal -> share a common goal; we makes -> we make; has been -> have been  \n\nReferences\n==========\n[1] Melis et al., On the State of the Art of Evaluation in Neural Language Models\n[2] Mitchell and Lapata, Vector-based Models of Semantic Composition\n', 'This paper is very interesting as it seems to bring the clock back to Holographic Reduced Representations (HRRs) and their role in Deep Learning. It is an important paper as it is always important to learn from the past. HRRs have been introduced as a form of representation that is invertible. There are two important aspects of this compositional representation: base vectors are generally drawn from a multivariate gaussian distribution and the vector composition operation is the circular convolution. In this paper, it is not clear why random vectors have not been used. It seems that everything is based on the fact that orthonormality is impose with a regularization function. But, how can this regularization function can preserve the properties of the vectors such that when these vectors are composed the properties are preserved.\n\nMoreover, the sentence ""this is computationally infeasible due to the vast number of unique chunks"" is not completely true as HRR have been used to represent trees in ""Distributed Tree Kernels"" by modifying the composition operation in a shuffled circular convolution. ', 'The paper proposes a new approach for neural language models based on holographic reduced representations (HRRs). The goal of the approach is to learn disentangled representations that separate different aspects of a term, such as its semantic and its syntax. For this purpose the paper proposes models both on the word and chunk level. These models aim disentangle the latent space by structuring the latent space into different aspects via role-filler bindings.\n\nLearning disentangled representations is a promising research direction that fits well into ICLR. The paper proposes interesting ideas to achieve this goal\nin neural language models via HRRs. Compositional models like HRRs make a lot of sense for disentangling structure in the embedding space. Some of the experimental results seem to indicate that the proposed approach is indeed capable to discover rough linguistic roles. However, I am currently concerned about different aspects of the paper:\n\n- From a modeling perspective, the paper seems to conflate two points: a) language modeling vie role-filler/variable-binding models and b) holographic models as specific instance of variable bindings. The benefits of HRRs (compared e.g., to tensor-product based models) are likely in terms of parameter efficiency. However, the benefits from a variable-binding approach for disentanglement should remain across the different binding operators. It would be good to separate these aspects and also evaluate other binding operators like tensors products in the experiments.\n\n- It is also not clear to me in what way we can interpret the different filler embeddings. The paper seems to argue that the two spaces correspond to semantics and syntax. However, this seems in no way guaranteed or enforced in the current model. For instance, on a different dataset, it could entirely be possible that the embedding spaces capture different aspects of polysemy.  However, this is a central point of the paper and would require a more thorough analysis, either by a theoretical motivation or a more comprehensive evaluation across multiple datasets.\n\n- In its current form, I found the experimental evaluation not convincing. The qualitative analysis of filler embeddings is indeed interesting and promising. However, the comparisons to baseline models is currently lacking. For instance, perplexity results are far from state of the art and more importantly below serious baselines. For instance, the RNN+LDA baseline from Mikolov (2012) achieves already a perplexity of 92.0 on PTB (best model in the paper is 92.4). State-of-the-art models acheive perplexities around 50 on PTB. Without an evaluation against proper baselines I find it difficult to accurately assess the benefits of these models. While language modeling in terms of perplexity is not necessarily a focus of this paper, my concern translates also to the remaining experiments as they use the same weak baseline.\n\n- Related to my point above, the experimental section would benefit significantly if the paper also included evaluations on downstream tasks and/or evaluated against existing methods to incorporate structure in language models.\n\nOverall, I found that the paper pursues interesting and promising ideas, but is currently not fully satisfying in terms of evaluation and discussion.']","[-20, 50, -20]","[60, 70, 60]","[""Sentiment score: The review starts with a neutral summary of the paper, acknowledging its novelty and importance. However, it then expresses 'some concerns' about the quality of the language model, clarity of description, and validity of using HRR. The detailed comments list several issues and suggestions for improvement, indicating a somewhat negative sentiment. While the reviewer finds some aspects 'interesting' and 'compelling', the overall tone suggests more criticism than praise, hence a slightly negative score of -20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use polite phrases like 'Please see detailed comments below' and 'I would have liked to see'. Even when pointing out issues, the language is constructive rather than harsh, often phrasing criticisms as questions or suggestions. The reviewer also acknowledges positive aspects of the paper. However, the review is not overly effusive in its praise, maintaining a balanced tone. Therefore, a politeness score of 60 seems appropriate, indicating a polite but not excessively deferential review."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'very interesting' and 'important', acknowledging its value in learning from the past. However, they also raise some questions and point out potential issues, which balances the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their concerns as questions or observations rather than direct criticisms. They acknowledge the paper's merits before discussing potential issues, which is a polite approach. The reviewer also uses phrases like 'it is not clear' instead of more accusatory language, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting ideas and promising direction, they express several significant concerns about the modeling approach, interpretation of results, and experimental evaluation. The reviewer states they found the paper 'not fully satisfying' overall. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as areas for improvement rather than outright flaws. They use phrases like 'I am currently concerned about' and 'It would be good to' which maintain a collegial tone while providing feedback.""]"
"[""The paper proposes to integrate sequential information into imitation learning techniques.  The assumption is that mostly all the IL techniques are learning a policy which depends on state at time t, while the information contained in this state may be not sufficient to choose the right action (actually, this is the POMDP setting, the notion of POMDP not appearing in the paper....). The authors thus propose to use a recurrent neural network to encode the state by aggregating past information, instead of just using the features of the state at time t. They thus instantiate this idea on different methods and show that, on some problems, this approach can increase the quality of the final policy.\n\nActually, the contribution of the paper is a simple extension of existing methods: using a RNN instead of a simple NN in imitation learning models. First of all, when dealing with classical environments such as Atari, many papers propose to use the last N frames as a state encoding (instead of the last frame), following the same intuition. The studied setting thus corresponds to the PO-MDP case and using a RNN in POMDP is for example what is done in  [Merel etal. 2017]. Moreover, the problem of imitation learning (and particularly inverse RL) in POMDP has been of the interest of many papers like [Choi et al. 2008] for instance and many more, and it is unclear what is the positioning of this paper w.r.t existing works. Since the paper proposes just to encode history with a RNN, the proposed solution lacks of originality, and the contribution of the paper in term of model is quite low.  But the authors explain how this can be instantiated in three different settings (IRL, GAIL and BC) -- note that the section concerning the use of Adaboost is not clear and could be better described -- which can be of the interest of the community. \nConcerning the experiments, I don't understand what is the split between training and testing data. Is it pairs of state-action coming from the experts ? or trajectories ? Moreover, I don't understand why these environments correspond to POMDP cases and the authors have to give details on that. For instance, mountain-car is clearly not a POMDP problem in its classical shape, nor Acrobot. As if, it makes the experiments very difficult to reproduce. The interest of using the RNN to encode history does not seem clear for each of the cases since it often degrades the final performance, so I don't know exactly what insights I can extract from the paper.\n\nPro:\n* The approach is proposed for IRL, GAIL and BC\n\nCons:\n* Lack of positionning w.r.t POMDP litterature\n* Lack of details in the experiments, and lack of good experimental results\n* Low contribution in term of model\n\n\n[Merel et al. 2017]  Learning human behaviors from motion capture\nby adversarial imitation\n[Choi et al.] Inverse Reinforcement Learning in Partially Observable\nEnvironments"", 'The paper puts forward the idea of using a recurrent neural network in algorithms for learning from demonstration in order to take into account sequential information. The authors test it in the inverse reinforcement learning setting and the behavioral cloning setting on different control problems.\n\nI feel the basic idea is really straightforward. Although some promising results are obtained in the experimental setting, I believe the contribution may not be sufficient for a publication at ICLR. Moreover, there are some issues in the writing, e.g., \n\n- classically, as far as I know, RL is not considered to be a metaheuristic, although I understand that someone could make the case for it.\n\n- although there’s not really a consensus on terminology, I think using imitation learning to define the whole class of problems encompassing IRL and behavioral cloning is not the best. Generally, imitation learning is equated to behavioral cloning. I think a better term for this general class is learning from demonstration. For instance, there are some IRL approaches that don’t try to mimic a demonstrated policy, but aim at learning an even better policy.\n\n- the issue described in the paper about the missing sequential information is due to the fact the authors consider POMDPs and not MDPs. This should be made clearer. I think the authors should also cite the following paper:\n\n@article{ChoiKim11,\n\tAuthor = {Jaedeug Choi and Kee-Eung Kim},\n\tJournal = {JMLR},\n\tPages = {691--730},\n\tTitle = {Inverse Reinforcement Learning in Partially Observable Environments},\n\tVolume = {12},\n\tYear = {2011}}\n\n- the related work has to be reworked. Kuderer et al. (2013) is not about urban route planning, but deals with learning driving style; Mnih et al. (2015) is not about training multi-agent systems, but introduces DQN; Silver et al. (2016) is about go, not chess. Are TRPO or PPO really off-policy or asynchronous?\n\n- the last section of Sec.3.4 sounds strange. It’s not MC that assumes that the impact of an action decays with time. The discount factor comes from the choice of the total discounted reward criterion.\n\nOther comments:\n\n- in abstract: BL -> BC\n- notations issues in (2-5)\n- l.6-7, Algo 1: t = T_m?\n- The text should be checked for typos.', 'This paper introduces the use of sequential information (state-action pairs) for enhancing imitation learning, and using recurrent networks (LSTM) in that process.  The authors motivate this by pointing out that while the state information, if Markovian, should contain all information necessary for decision making, with incomplete learners redundant information in the sequential state-action information leading to the current state can be helpful, citing some concrete examples. \nAfter describing a number of variants of this idea, in the context of IRL, BC, etc., the authors conduct a systematic empirical evaluation to assess the effectiveness of the proposal, over the baselines, using a number of RL benchmark problems. \nThe results are favorable and convincingly show that the proposed sequential enhancement can bring significant improvement in terms of attained rewards, convergence speed and stability in many of the tested cases. \nOne suggestion I have is that it would be interesting to investigate into the question of how the addition of sequential information adds value is related to the validity of Markovian assumption in each of the problem being considered. \nIt is a good empirical paper demonstrating the practical use of an idea that is simple but reasonable, and in a way that is substantiated using proper cutting edge framework and baselines. \n']","[-50, -30, 80]","[20, 20, 70]","[""The sentiment score is -50 because the review is predominantly critical. While it acknowledges some positive aspects ('can be of the interest of the community'), it highlights several significant shortcomings ('lack of originality', 'low contribution', 'lack of details', 'lack of good experimental results'). The reviewer also expresses confusion about certain aspects of the paper. The politeness score is 20 because the language used is professional and constructive, avoiding harsh or personal criticism. The reviewer uses phrases like 'I don't understand' instead of directly criticizing the authors, and provides specific suggestions for improvement. However, the tone is not overly polite or praising, maintaining a neutral, academic style."", ""The sentiment score is -30 because the reviewer expresses several criticisms and doubts about the paper's contribution, stating it 'may not be sufficient for a publication at ICLR.' They also point out multiple issues with writing and terminology. However, they do acknowledge some 'promising results,' which prevents the score from being more negative. The politeness score is 20 because the reviewer uses generally polite language, such as 'I feel' and 'I believe,' softening their criticisms. They also provide constructive feedback and specific suggestions for improvement, which is courteous. The reviewer avoids harsh or rude language, maintaining a professional tone throughout."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, describing it as 'good' and noting that the results are 'favorable and convincingly show' the effectiveness of the proposed method. The reviewer also praises the paper for demonstrating a 'simple but reasonable' idea in a way that is 'substantiated using proper cutting edge framework and baselines'. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, offering constructive feedback and a suggestion for improvement without any harsh criticism. The tone is consistently positive and supportive, acknowledging the authors' contributions and the value of their work.""]"
"['Here the authors convert the GRU equations into continuous time and use theory and experiments to study 1- and 2-dimensional GRU networks. The authors showcase every variety of dynamical topology available in these systems and point out that the desirable line and ring attractors are not achievable, except in gross approximation.  The paper is extremely well written.\n\nI am deeply conflicted about this paper.  Is the analysis of 1 or 2 dimensional GRUs interesting or significant? That’s a main question of this paper.  There is no question of quality, or clarity, and I am reasonably certain nobody has analyzed the GRU in this way before.\n\nOn the one hand, the authors bring a rigor and language to the discussion of recurrent networks that is both revealing (for these examples) and may to bear fruit in the future.  On the other hand, the paper is exclusively focused on 1- and 2-dimensional examples which have precisely no relevance to the recurrent neural networks as used and studied by machine learning practitioners and researchers, respectively. If the authors have proved something more general for higher dimensional (>2) cases, they should make it as clear as possible.\n \nA second, lesser question of relevance is studying a continuous time version.  It is my understanding that discrete time dynamics may exhibit significantly more complex dynamical phenomenon and again practitioners primarily deploy discrete time GRUs.  I understand that theoretical progress often requires retreating to lower dimensionality and (e.g. linearization, etc.) but in this case it is not clear to me that the end justifies the means.  On the other hand, a publication such as this will not only help to change the language of RNNs in the deep learning community, but also potentially bring in more dynamical systems specialists into the deep learning field, which I thoroughly endorse.\n\nModerate concern\n\n“In order to show this major limitation of GRUs …” but then a 2-gru is used, which means that it’s not a general problem for GRUs with higher dim, right?  Also, won’t approximate slow points would also be fine here? I think this language needs to be more heavily qualified.\n\nMinor\n\nGRU almost always refers to the network, even though it is Gated Recurrrent Unit, this means that when you write ‘two GRUs’, the naive interpretation (to me) is that you are speaking about two networks and not a GRU network with two units.\n\nSide note requiring no response: It might be interesting to study dynamical portrait as a function of training for the two-d GRU.\n', 'The authors analyse GRUs with hidden sizes of one and two as continuous-time dynamical systems, claiming that the expressive power of the hidden state representation can provide prior knowledge on how well a GRU will perform on a given dataset. Their analysis shows what kind of hidden state dynamics the GRU can approximate in one and two dimensions. In the experimental part, they show how a GRU with two hidden states trained on a multistep prediction task can learn such dynamics.\n\nAlthough RNNs are important for Machine Learning, the paper seems to contain flaws in the theoretical part, which seem to invalidate some of the claimed results. But we may change our rating in case of a convincing rebuttal.\n\nThe Proof of Lemma 2 claims that h(t) achieves all values on the real set, which is false (h(t) assumes values in (-1,1)). Nevertheless, the theorem should hold since there is always at least one intersection between h and tanh(f(h)).\n\nLemma 1 claims that for any choice of parameters, there exist only finitely many fixed points. However, in the proof the authors only show that the number of fixed points cannot be uncountable, without taking into consideration the possibility that there are countably many fixed points. The proof also omits steps concerning the Taylor expansion which would make the proof clearer: We suggest adding those steps in the appendix. Furthermore, when equation (12) is Taylor-expanded, the authors do not consider the case where the GRU parameters are such that the argument of function “sech” is outside its convergence radius. These might be parameters for which there are infinitely many fixed points, even if we are unable to provide a Taylor expansion. The Lemma may still be correct, but this does not seem to be a complete proof.\n\nThe authors claim that an arbitrarily close approximation of a line attractor can be created using two GRUs, but no proof is provided.\n\nThe experimental part is difficult to evaluate since there are no learning curves for the three tasks. For instance, it is difficult to judge whether the GRUs are unable to learn the dynamics of a ring attractor because of theoretical limitations or because the model has not been properly trained for the specific task.\n\nThe paper is easy to read, except for certain parts where it is not clear if some of the statements are true in general or just have not been proven false by the authors. It is not clear why Figure 3 is representing all possible simple fixed points and bifurcation fixed points: is there a theoretical result stating that these are the only possible topologies, or are these the only ones found? The same question applies for the 36 images in figure 9. The range of the parameters used for finding these configurations is not specified.\n\nSince the hidden state assumes values in (-1,1)^2, why is its range in most of the images (-1.5,1.5)?\n\nWe are not familiar with related work on transformations from discrete to continuous dynamical systems: are the dynamics of the discrete time GRU model preserved in the transformation? If so, is there a reference for this? Are the phase portraits in the middle row of figure 8 generated by letting the discrete GRU system evolve, or is the continuous system used with the parameters of the trained GRU?\n\nWe would like to see more explanations of why various topologies are useful for the applications mentioned in the paper. Given a generic dataset, how can these results help to understand how well a GRU will perform?\n\nWhat is the reason behind the belief that the analysis extends to higher dimensions? The effects of a 1D -> 2D extension are far from trivial - why should that be different for higher dimensions?\n\nThe problem the authors want to solve seems important, and some of the theoretical results are promising, but we think that this paper has to be further polished before acceptance.\n\nIt is possible that we will increase the score if the authors can provide clarifications on the above questions.\n\nAdditional comments:\n\nIntroduction\n\n-The vanishing gradient problem was not discovered in 1994, but in 1991 by Hochreiter: \n\nSepp Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, TU Munich, 1991. Advisor J. Schmidhuber.\n\n- Make clear that GRU is a variant of vanilla LSTM with forget gates (where one gate is missing):\n\nGers et al. “Learning to Forget: Continual Prediction with LSTM.“ Neural Computation, 12(10):2451-2471, 2000. \n\n- The intro says that GRU has become widely popular and cites Britz et al 2017, but Britz et al actually show that LSTM consistently outperforms its variant GRU in Neural Machine Translation. Please clarify this. \n\n- Also mention Weiss et al (“On the Practical Computational Power of Finite Precision RNNs for Language Recognition”) who exhibited basic limitations of GRU when compared to LSTM. \n\n- Is the result by Weiss et al actually related to the result of the authors who found that 2 GRUS cannot accurately a line attractor without near zero constant curvature in the phase space?\n\n\nSection 2\n\n-Wrong brackets in equation (4)\n-Missing bracket before citing Laurent & Brecht\n\nSection 4\n\n-”We conjecture that the system depicted in figure 2A..” Should be figure 3A\n- Lemma1: UZ has capital Z subscript\n\nSection 5.2\n\n-”The added affine transformation allows for a sufficiently long subinterval”: “sufficiently long” is too vague\n\nSection 5.3\n\n“A manifold with without near zero constant curvature”: should be “a manifold without near zero constant curvature”\n\nAppendix A\n\n-Wrong brackets in equation (20)\n\nAppendix B\n\n- In the proof of Theorem 1, the derivative is of (29), not of (12)\n\nAppendix C\n\nFigure 9: “who’s initial conditions” should be “whose initial conditions”\n\nAfter rebuttal:\n\nIt\'s better now. However, the revised introduction still says:  ""GRU has become wildly popular in the machine learning community thanks to its performance in machine translation (Britz et al., 2017) ... LSTM has been shown to outperform GRU on neural machine translation (Britz et al., 2017).... specifically unbounded counting, come easy to LSTM networks but not to GRU networks (Weiss et al., 2018)."" \n\nSo better remove the first statement on Britz et al: ""GRU has become wildly popular ... in machine translation (Britz et al., 2017)"" because they actually show why GRU is NOT wildly popular in machine translation, as correctly justified later in the same paragraph.\n\nPending the above revision, we\'d like to increase our evaluation by 2 points, up to 6!\n', ""This paper analyzes GRUs from a dynamical systems perspective, i.e. phase diagrams, fixed points, and bifurcations. The abstract and intro are well written and motivate the need for more theoretical framework to understand RNNs, especially how well they are able to represent and express temporal features in the training data. The dynamical systems analysis is well presented and visualized nicely. \n\nMost of the paper concentrates on the 1d (one single GRU) and 2d (two GRU's) case.  They show that 2d GRUs can be trained to adopt a variety of fixed points, can approximate a line attractors (an important feature for short-term memory), but cannot mimic a ring attractor.\n\nMy concerns are:\n\n- The derivation of the continuous time dynamical system (Appendix A) is confusing to me. Unless I'm not following the derivation correctly, should there be another \\Delta t in the denominator of the right-hand side of (23), from (22)? It's confusing to me that the continuous-time version in (26) has essentially the same form as the discrete-time version in (22).\n\n- The applicability of this analysis to RNNs of even modest size is unclear. Generically, there's no reason to believe the intuitions from 2d should necessarily generalize to higher dimensions, and rigorous analysis of higher dimensional systems of this kind can be fairly challenging, even if one starts from a continuation analysis.\n\n- Small typo: top of Page 4, figure should refer to 3A, not 2A.\n\n""]","[-20, -20, 60]","[60, 60, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's quality and clarity, they express deep conflict about its significance and relevance. They question the usefulness of analyzing 1- or 2-dimensional GRUs and the continuous time version, which are not directly applicable to practical machine learning. However, they also recognize potential positive impacts, such as changing the language of RNNs and attracting dynamical systems specialists to deep learning. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and expressing concerns in a constructive manner. They use phrases like 'extremely well written' and offer balanced perspectives, even when critiquing. The reviewer also provides specific suggestions and notes areas requiring clarification, which is helpful and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and some promising theoretical results, they point out several flaws in the theoretical part and express concerns about the experimental section. The review suggests that the paper needs further work before acceptance. However, the reviewer does leave room for improvement, stating they may change their rating based on the authors' response. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offers constructive criticism, and provides detailed suggestions for improvement. They use phrases like 'we suggest,' 'we would like to see,' and 'it is possible that we will increase the score,' which maintain a polite and collaborative tone. The reviewer also acknowledges the potential importance of the work, which adds to the politeness."", ""The sentiment score is 60 (positive) because the reviewer starts with positive comments about the paper's analysis, presentation, and visualization. They mention that the abstract and intro are well-written and that the dynamical systems analysis is well-presented. However, the score is not higher due to the concerns raised in the latter part of the review. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They phrase their criticisms as 'concerns' rather than outright flaws, and even suggest that their confusion might be due to their own misunderstanding ('Unless I'm not following the derivation correctly'). The reviewer also points out a small typo in a neutral manner. The overall tone is constructive and professional, maintaining politeness while providing critical feedback.""]"
"['This paper proposes that models for different tasks in multi-task learning cannot only share hidden variables but also gradients.\n\nPros:\n- The overall framework is theoretically motivated and intuitive. The idea of passing gradients for multi-task learning is interesting and the execution using fast weights is plausible.\n- The experiments are extensive and cover three different task combinations in different domains.\n- The results are convincing and the additional analyses are compelling.\n\nCons:\n- I would have liked to see a toy example or at least a bit more justification for the ""pretend-to-share"" problem that models ""collect all the features together into a common space, instead of learning shared rules across different tasks"". As it is, evidence for this seems to be mostly anecdotal, even though this forms the central thesis of the paper.\n- I found the use of Read and Write ops confusing, as similar terminology is widely used in memory-based networks (e.g. [1]). I would have preferred something that makes it clearer that updates are constrained in some way as ""writing"" implies that the location is constrained, rather than the update minimizing a loss.\n\nQuestions:\n- How is the weight list of task similarities \\beta learned when the tasks don\'t share the same output space? How useful is the \\beta?\n- Could you elaborate on what is the difference between pair-wise gradient passing (PGP) and list-wise gradient passing (LGP)\n\n[1] Graves, A., Wayne, G., & Danihelka, I. (2014). Neural turing machines. arXiv preprint arXiv:1410.5401.', 'This paper tries to address the""pretend-to-share"" problem by designing the gradient passing schemes in which the gradient updates to specific parameters of tasks are passed to the shared parameters. Besides, the authors summarize existing multitask learning algorithms in a framework called Parameters Read-Write Networks (PRAWN). \n\nPros:\n- The view of putting existing multi-task learning algorithms in a read-write framework is quite intriguing and inspiring.\n\nCons:\n- Motivation: The whole paper is assumed to address the ""pretend-to-share"" problem, while the authors never provide any evidence that such problem really exists for any other algorithm. It seems to be an assumption without any support.\n- Method:  \n   - Though the read-write framework is very interesting, the authors do not clearly present it, so that the readers can be totally get lost. For example, what do you mean by writing {\\Theta^{*r}_k - \\theta^{swr}_k}? In the line of structural read-op, where are \\theta_3 and \\theta_4  in the column of the constituent para. ? What do you mean by writing the equation (4)? How do you define g() in equation (8)? This is a research paper which should be as clear as possible for the readers to reproduce the results, rather than a proposal only with such abstract and general functions defined. \n   - In the list-wise communication scheme, you define the task relationship in equation (11). The problem is how do you evaluate the effectiveness of such definition, since massive works in multitask learning pursue to learn the task relationship automatically to guarantee the effectiveness instead of such heuristic definition. \n- Related works: The authors do not clearly and correctly illustrate the connections between this work and meta-learning/domain adaptation. To my best knowledge, meta-learning, including MAML (Finn et al. 2017), can obviously solve both in-task setting and out-task setting. In some sense, I think this work is almost equivalent to MAML. \n- Experiments: \n   - First, several state-of-the-art baselines including MAML and cross-stitch networks should be compared. Specifically, for the text classification dataset, there have been a lot of domain adaptation works discovering the transferable pivots (shared features) and non-pivots (specific features), which the authors should be aware of and compare in Table 3.  \n   - The Figure 5 is not clear to me, and so is the discussion. The authors try to explain that the updating direction of shared parameters for PGP-SR is an integration of two private updating directions. I tried hard to understand, but still think that Figure 5(a) is even better than Figure 5(b). The updating direction of the shared parameters is almost the same as the cyan line.\n- Presentation: there are so many grammatical errors and typos. For example,\n   - In the introduction, ""...datasets, range from natural"" -> ""...datasets, ranging from natural""\n  - In the related work, ""and they propose address it with adversarial"" -> ""and they propose to address it with adversarial""\n - In the beginning of Section 4, "" an general"" -> ""a general""', 'Paper summary: \nIn this paper, the authors propose a general framework for multi-task learning (MTL) in neural models. The framework is general for including some of the current neural models for MTL. Under the framework, the author propose a new method that could allow tasks to communicate each other with explicit gradients. Based on the gradients being communicated, the system could adjust the updates of one task based on the gradient information of the other task. Also, prior task relatedness information could be incorporated to the system. \n\nThe idea of incorporating passing gradients among tasks seems very interesting, which is new as far as I am aware of. Although the idea is simple, but it seems intuitive since purely aggregating gradient updates might have undesired cancelling effects on each other.  \n\nThere are some questions I have about this method. \n1.\tI’m curious about how the sequential update in pairwise task communication affects the performance. \n2.\tAlso, how does sequential update nature of the method affect the training speed, as for now, the parameter update consists of two sequential steps which also involve changes to the traditional update rule. \n3.\tWhat is fast weight for and how it is used in (9)? It would be better if there are more details on how the update is carried out during the gradient communication.\n4.\tRegarding the relatedness for List-wise communication, is it possible to update the relatedness dynamically? Since the pre-computed relatedness might not always make sense. During the learning of the representations, the task relatedness could change in the process.\nThe system framework for MTL introduced by the authors seem to be kind of isolated to the method proposed. I feel that the framework is not quite easy to understand from the way it is presented.  From my perspective, the effectiveness of analyzing MTL methods using the framework seems a bit limited to me, as it serves more like a way of abstracting MTL models instead of analyzing it. Therefore, I feel the content devoted to that part might be too much.\n\nOverall, I think the paper is interesting although the method itself is relatively simple. And the direction of utilizing gradient communication among tasks seem interesting and could be further explored. But I do feel the organization of the paper is a bit too heavy on the framework instead of the methodology proposed. And more details of the algorithm proposed could be provided.\n\nOn a side note, I think the paper exceeds the required length limit of 10 pages if appendices are counted towards it.\n']","[70, -60, 20]","[80, 20, 60]","[""The sentiment score is 70 (positive) because the review starts with a clear statement of the paper's proposal and lists several pros, including the 'theoretically motivated and intuitive' framework, 'extensive' experiments, and 'convincing' results. The cons are presented as constructive feedback rather than severe criticisms. The politeness score is 80 (polite) due to the balanced and professional tone throughout. The reviewer uses respectful language, acknowledging the paper's strengths while offering suggestions for improvement. The use of phrases like 'I would have liked to see' and 'I found... confusing' express personal opinions without being harsh. The inclusion of questions at the end demonstrates engagement with the work and invites further discussion, which is a polite way to address potential issues."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges one pro ('intriguing and inspiring' framework), it lists numerous cons including issues with motivation, methodology, related work, experiments, and presentation. The tone suggests significant revisions are needed. The politeness score is 20 because the reviewer uses relatively neutral language and frames criticisms as observations rather than attacks. They use phrases like 'I tried hard to understand' which shows effort on their part. However, the review is direct in its criticisms without much softening language, keeping it from being highly polite."", ""The sentiment score is slightly positive (20) because the reviewer finds the paper interesting and acknowledges the novelty of the proposed method. However, they also express several concerns and suggest areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and balances negative points with positive ones. They use phrases like 'I'm curious about' and 'I feel that' to soften their critiques, and acknowledge the interesting aspects of the work. The review maintains a professional and constructive tone throughout, even when pointing out potential issues or areas needing clarification.""]"
"['This paper introduces an approach to pruning the parameters of a trained neural network. The idea is inspired by the Optimal Brain Surgeon method, which relies on second derivatives of the loss w.r.t. the network parameters. Here, the corresponding Hessian matrix is approximated using the Fisher information to make the algorithm scalable to very deep networks.\n\nStrengths:\n- The method does not require hyper-parameter tuning.\n- The results show the good behavior of the approach.\n\nWeaknesses:\n\nNovelty:\n- In essence, this method relies on the work of Marten & Grosse to approximate the Hessian matrix used in the Optimal Brain Surgeon strategy. This is fine, but not of great novelty.\n\nMethod:\n- It is not clear to me why the notion of binary parameters gamma is necessary. Instead of varying the gammas from 1 to 0, why not directly zero out the corresponding network parameters w?\n- In essence, the objective function in Eq. 5 adds an L_1 penalty on the gamma parameters, which would be related to an L_1 penalty on the ws. Note that this strategy has been employed in the past, e.g., Collins & Kohli, 2014, ""Memory Bounded Deep Convolutional Networks"".\n- It is not clear to me how zeroing out individual parameters will truly allows one to reduce the model afterwards. In fact, one would rather want to remove entire rows or columns of the matrix W_l, which would truly correspond to a smaller model. This was what was proposed by Wen et al., NIPS 2016 and Alvarez & Salzmann, NIPS 2016, ""Learning the Number of Neurons..."".\n- In the past, when dealing with the Hessian matrix, people have used the so-called Pearlmutter trick (Pearlmutter, Neural Computation 2014, ""Fast exact multiplication by the Hessian"". In fact, in this paper, the author mentions the application to the Optimal Brain Surgeon strategy. Is there a benefit of the proposed approach over this alternative strategy?\n\nExperiments:\n- While the reported compression rates are good, it is not clear to me what they mean in practice, because the proposed algorithm zeroes out individual parameters in the matrix W_l of each layer.  This does not guarantee entire channels to be removed. As such, I would not know how to make the model actually smaller in practice. It would seem relevant to show the true gains in memory usage and in inference speed (both measured on the computer, not theoretically).\n\nSummary:\nI do appreciate the fact that the proposed method does not require hyper-parameters and that it seems to yield higher compression rates than other pruning strategies that act on individual parameters. However, novelty of the approach is limited, and I am not convinced of its actual benefits in practice.\n', 'The paper proposes a multi-layer pruning method called MLPrune for neural networks, which can automatically decide appropriate compression ratios for all the layers. It firstly pre-trains a network. Then it utilizes K-FAC to approximate the Fisher matrix, which in turn approximates the exact Hessian matrix of training loss w.r.t model weights. The approximated Hessian matrix is then used to estimate the increment of loss after pruning a connection. The connections from all layers with the smallest loss increments are pruned and the network is re-trained to the final model.\n\nStrength:\n1. The paper is well-written and clear. \n2. The method is theoretically sound and outperforms state-of-the-art by a large margin in terms of compression ratio. \n3. The analysis of the pruning is interesting.\n\nWeakness:\n*Method complexity and efficiency are missing, either theoretically or empirically.* \nThe main contribution claimed in the paper is that they avoid the time-consuming search for the compression ratio for each layers. However, there are no evidences that the proposed method can save time. As the authors mention, AlexNet contains roughly 61M parameters. On the other hand, the two matrices A_{l-1} and DS_l needed in the method for a fully-connected layer already have size 81M and 16M respectively. Is this only a minor overhead, especially when the model goes deeper?\n\nOverall, it is a good paper. I am inclined to accept, and I hope that the authors can show the complexity and efficiency of their method.\n', ""This paper proposes a multi-layer pruning technique based on the Hessian. The main claims are performing better than other second order pruning methods and be principled. \n\n\nMain concerns / comments are:\n-\tPart of the novelty relays on computing the Hessian, and the algorithm goes for very large networks (parameter wise), why? Modern networks do have much fewer parameters and do perform better. How does it behave on those? Would be interesting to see impact on modern networks (e.g., ResNet). \n\n\n-\tPaper claims to be principled (as many others) and being able to address multiple layers at the same time. I do believe first order methods do that as well. Why not compared to them? \n-\tPaper claims little overhead (compared to training and re-training). There is not much on that. Also, following the pipeline [train-prune-retrain] can be substituted by pruning while training with little overhead as in recent papers: (such as Learning with structured sparsity or Learning the number of neurons in DNN both at NIPS2016 or encouraging low-rank at compression aware training of DNN, nips 2017). Compared to those newer methods, this proposal has a drop-in accuracy while those do not. Would be nice to have a discussion related to that. Would be possible to include this into the original training process? \n-\tExperiments are shown in small datasets and non-current networks with millions of parameters which do not reflect current state of the art. I would be interested to see limitations in networks not having fully connected layers with the large majority of (redundant) parameters.\n-\tCompute time is not provided. Please comment on that\n-\tI am not sure if I understand the statement on 'pruning methods can not handle multiple layers'. To the best of my understanding, current pruning methods as those mentioned above do\n\n-\tDifferent to others, the proposed method, given a desired compression ratio can adjust the relevance of each layer. That is interesting, however, what is the motivation behind? Would be interesting to be able to control specifically each layer to make sure, for instance, the latency of each layer is maintained. \n\n\n-\tI am confused with \\lambda, how does this go from percentage to per parameter? Is that guaranteed?\n""]","[-30, 60, -30]","[50, 80, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper (e.g., no hyper-parameter tuning required, good results), they express significant concerns about the novelty, methodology, and practical benefits of the approach. The overall tone is more negative than positive, but not extremely negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms as personal opinions (e.g., 'It is not clear to me...', 'I am not convinced...'). They also use phrases like 'I do appreciate...' which adds to the politeness. However, the review is not overly effusive or extremely polite, maintaining a professional tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its strengths and stating it's 'a good paper' and they are 'inclined to accept'. However, it's not extremely positive due to the mentioned weakness and request for additional information. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames the weakness as a suggestion for improvement rather than a harsh criticism. The phrase 'I hope that the authors can show...' is particularly polite and constructive."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some interesting aspects of the paper, they raise several significant concerns and criticisms. These include questioning the relevance of the method for modern networks, the lack of comparison with first-order methods, and the limited experimental scope. The reviewer also expresses confusion about some claims and asks for clarification on multiple points.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use phrases like 'Would be interesting to see' and 'Please comment on that' which are polite ways of requesting additional information or suggesting improvements. The reviewer also acknowledges potentially interesting aspects of the work. However, the overall tone is more neutral than overtly polite, hence the moderate positive score.""]"
"['I do not understand the denomination of nonlinearity coefficient provided in definition 1: although the quantity indeed does equal to 1 under whitened data distribution or orthogonal matrix, the conjecture that it should be close to 1 does not seem to be close at all just under any data distribution. Using a similar construction that section 6, we can rescale a whitened input data with a diagonal matrix D with components all equal to one except for a very large one \\lambda and also multiply the input weights by D^{-1} to compensate (and have a similar function). If you look at such construction for the linear case with identity initialization of A, the NLC is sqrt((\\lambda^2 + n - 1) (\\lambda^{-2} + n - 1)) / n which can grow arbitrarily large with \\lambda *for a linear model*. However, because of its low capacity, we would expect a linear model to have reasonable generalization. This seems to compromise the initial NLC being low as a necessary condition for reasonable generalization. \nConversely, it’s possible to initialize arbitrarily large residual networks such that the resulting initial function is linear (by initializing the output weight of the incrementing block to 0). This initialization may also be done such that the initial NLC becomes close to 1. I would not think this wouldn’t necessarily result in good generalization, which seems to agree with the experimental observation. \nNow given that this initial NLC is neither sufficient nor necessary to predict generalization, one can wonder what is correlating generalization and NLC together in the experiment section. Same remark applies to the correlation between nonlinearity and NLC. This is especially concerning since in the linear case, the NLC can vary whether we chose to whiten the data or not for example, so the other influencing factors need to be discovered. What were the architecture that resulted in small/high NLC?\nThe experiment section still contains interesting bits, such as successful training of very deep architecture that are very sensitive to input perturbations but they are not part of the main thread of the paper.', 'This paper proposes a metric to measure the ""nonlinearity"" of neural network, and presents evidence that the value of this metric at initialization time is predictive of generalization performance.\n\nApart from a few problems I think this paper is well written and thorough. The contribution is solid, although not earth shattering given previous work on such metrics.  There seems to be a basic error in some of the early math, although I don\'t think this will qualitatively affect the results in any significant way.\n\n\n-----------------\nDetailed comments by section:\n------------------\n\nSection 3:\n\nIt seems like a 1/sqrt(d) factor is missing from these Q_i(S_x x(i)) and Q_j(S_x f(x,j)) formulas.  As far as I can tell this doesn\'t affect Def 1 because you seemed to use the correct formula there. \n\nHowever, the rewritten version with the traces doesn\'t seem to be correct. There should be a d_in factor in the denominator (inside the square root). This error seems unrelated to the other one.  Assuming I\'m correct and that this is an error, does this affect your results in the various figures?  And what is the actual final definition of NLC that you used?\n\nIn general, it\'s annoying for the reader to verify that all of these forms are equivalent.  And it\'s fiddly enough with the sqrt(d) terms constantly disappearing and reappearing in the numerator and denominators that even you made multiple errors (as far as I can tell).  I would suggest making this section more rigorous and writing out everything carefully. And you probably don\'t need to rewrite it in so many equivalent forms with different notation unless they are useful somehow. \n\nThe use of the Q and S symbols feels superfluous and counterproductive. Standard notation with expectations and squares wouldn\'t take much more space and would be a lot clearer.\n\n\nSection 4:\n\n""we plot the relative diameter of the linearly approximable regions of the network as defined in section 3"": but you don\'t seem to define ""relative diameter"" there. As far as I can tell it\'s only defined in Appendix E, and this is only mentioned in the caption of figure 1.  It\'s impossible to interpret this result without knowing precisely what ""relative diameter"" is.  If you can\'t afford to describe this in the main paper you should at least mention that it\'s a different (more expensive) way of estimating the same thing that the NLC estimates.\n\nIn Figure 2, are the higher test errors due to the optimizer failing to lower the training error, or due to a greater generalization gap?  I guess the Figure 3 results suggest the latter possibility, which is surprising to me. \n\n\nWhat does it mean to have a ""very biased output"".  What does that inequality mean intuitively?  Should there be an absolute value on the RHS?  It would be much easier to parse it if it were written in plain notation without these S and Q symbols.\n\n\nSection 6:\n\n""metric also an"" -> ""metric also has an""\n\nCan you generate a failure case for ""correlation information"" that doesn\'t involve Batch Norm layers?  I don\'t think the authors of those works meant for their results to deal with that.\n\nNote that there are actually a lot of papers going back to the 90s that discussed and proved representational benefits of depth in neural networks.', 'In this paper the authors introduce a new quantity, the nonlinearity coefficient, and argue that its value at initialization is a useful predictor of test time performance for neural networks. The authors conduct a wide range of experiments over many different network architectures and activation functions to corroborate these results. The authors then extend their method to compute the local nonlinearity of activation functions instead.\n\nI am a bit torn on this paper. I appreciate the direction that the authors have chosen to pursue. The topic of identifying parameters that are predictive of trainability is certainly interesting and has the potential to be quite impactful. Moreover, the breadth of the experiments conducted by the authors is novel and significant. Finally, I find the the overall manner in which the authors have chosen to present their data refreshingly transparent. Together, this leads me to believe that the quantity proposed by the authors might be useful to researchers.\n\nHaving said that, I am concerned by the author’s exposition of the nonlinearity coefficient itself. Fundamentally, my concern stems from the fact that it seems a lot of relatively ad-hoc decisions were made in the construction of the nonlinearity coefficient and an insufficiently good job was done to compare it to other measures of nonlinearity.\n\nSpecifically, it feels like an extremely weak definition of nonlinearity to say that the linear approximation of a function fails when it produces values that lie outside of the co-domain of the function. Moreover, I feel as though there is already a well defined notion of nonlinearity at a point that could be constructed by reference to the Hessian (or generally by the approximation error induced by truncating the Taylor series after the linear term). I would like to see some comparison between these two methods. \n\nThis is made more troubling given that the correlation found by the authors is present but does not seem especially strong. For example, in fig. 2A it seems like the nonlinearity coefficient varies by at least two orders of magnitude in the inset of the figure where the test accuracy really does not seem sensitive to its value. Prior work (for example, [1] from last years ICLR) has shown strong correlations between the Frobenius norm of the Jacobian and test error (see fig. 5 and fig. 6). Since the definition of the nonlinearity coefficient seems somewhat ad-hoc I would love to see a comparison between it and just looking at the Jacobian norm in terms of predicting test accuracy.\n\n[1] - SENSITIVITY AND GENERALIZATION IN NEURAL NETWORKS: AN EMPIRICAL STUDY\nRoman Novak, Yasaman Bahri, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein\n']","[-50, 50, -20]","[20, 60, 70]","[""The sentiment score is -50 because the reviewer expresses significant concerns and disagreements with the paper's main arguments. They question the validity of the nonlinearity coefficient (NLC) definition and its relationship to generalization, providing counterexamples that challenge the paper's claims. However, the score is not extremely negative as the reviewer acknowledges some 'interesting bits' in the experiment section.\n\nThe politeness score is 20 because the reviewer maintains a professional and academic tone throughout, avoiding personal attacks or harsh language. They present their criticisms as observations and questions rather than direct accusations. The use of phrases like 'I do not understand' and 'one can wonder' softens the critique. However, the score is only slightly positive as the review doesn't include explicitly polite language or praise, focusing primarily on technical concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper is 'well written and thorough' and the contribution is 'solid', despite mentioning 'a few problems' and a 'basic error'. The overall tone is constructive and appreciative of the work. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offering suggestions for improvement rather than harsh criticisms. They acknowledge the paper's strengths before pointing out areas for improvement. The use of phrases like 'I think', 'I would suggest', and 'it's annoying for the reader' maintain a polite tone while providing feedback. The reviewer also offers helpful suggestions and asks clarifying questions, showing engagement with the work."", ""The sentiment score is slightly negative (-20) because while the reviewer appreciates certain aspects of the paper (e.g., the direction, breadth of experiments, and transparent presentation), they express significant concerns about the definition and comparison of the nonlinearity coefficient. The reviewer is 'torn' and 'concerned,' which indicates a mixed but overall slightly negative sentiment. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and uses phrases like 'I appreciate' and 'I would like to see' instead of making demands. The reviewer also offers constructive feedback and suggestions for improvement, maintaining a professional and courteous tone.""]"
"['The paper presents an empirical study of how accuracy and robustness vary with increasing training data for four different data sets and CNN architectures. The main conclusion of the study is that while training accuracy generally increases with increasing training data, provided sufficient training data is available for training the network in the first place, the robustness on the other hand does not necessarily increase, and may even decrease.\n\nSimilar findings were presented previously in Su et al., 2018. Hence, the current paper contains incremental and marginal new findings versus the existing literature. The paper would also have been a lot stronger and significantly advanced our scientific understanding of the problem if the authors had made some attempt at trying to explain their findings theoretically. In its current form the paper does not contain sufficient contributions for acceptance.', 'This paper empirically evaluates the effect of the training dataset size on accuracy and robustness against adversarial attacks. The methodology of the paper is generally easy to assess and the overall idea well communicated.\n\nFor the motivation example I assume the following assessment holds true. Several linear functions are sampled and compose S_1, S_2, and T. A single linear regression model is used to fit all the data, either S_1 or (S_1 and S_2). If that is the case the experiment is not clear to me since the single linear model can only fit the data mean, mean slope (a) and constant (mu). Since the joint dataset better captures the mean of T the error for the joint training should be lower indeed. However, to actually compare both values the same threshold theta should be used for both and not a percentage of their performance. I would argue that this very simple model does not provide any valuable insight into the problem due to its construction.\n\nThe experimental setup presented in Section 4 only considers examples which are classified correctly by all data subsets. However, it is crucial to also consider the mistakes of these subsequent sets. For example, the learned model for the most restrictive dataset is most likely not exposed to a complex decision boundary, therefore it will exhibit a much smoother prediction at the cost that it will simply classify many more examples as the target class. In this case using data perturbations is not even the problem since completely different examples might be classified wrongly. Although not entirely clear, it would be very useful to consider the nearest negative neighbor in the dataset in the embedding space of the classifier to capture this problem at least partially. In general if the test accuracy is lower the learned classifier exhibits less performance, thus, adversary examples, distorted examples are not the main issue since it simply makes mistakes on visually different examples. Therefore, the overall analysis should be much more focused on models which achieve the same test performance but use require less data to achieve this performance.', 'This paper conducts an empirical analysis of the effect of training data size on the model robustness to adversarial examples. The authors compared four different NN architectures using four different datasets for the task of image classification. Overall, the paper is easy to follow and clearly written. \n\nHowever, since Su et al., 2018, already presented similar findings, I do not see any major contribution in this paper. Additionally, I would expect the authors to conduct some more analysis of their results besides acc. and distortion levels. For examples, investigate the type of mistakes the models have made, compare models with the same test acc. but different amount of training data used to get there, some analysis/experiments to explain these findings (monitor models parameters/grads during training, etc.) \n\n']","[-50, -20, -20]","[0, 50, 50]","[""The sentiment score is -50 because the reviewer acknowledges the paper's empirical study but criticizes it for containing 'incremental and marginal new findings' and not having 'sufficient contributions for acceptance'. This indicates a negative sentiment, though not extremely harsh. The politeness score is 0 (neutral) because the reviewer uses professional language without being particularly polite or rude. They state their criticisms directly but without using inflammatory language. The reviewer acknowledges the work done ('The paper presents an empirical study...') before providing critique, which is a standard, neutral approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('generally easy to assess and the overall idea well communicated'), they express significant concerns about the methodology and the value of the experiments. The reviewer points out several issues with the motivation example and the experimental setup, suggesting that the paper's approach may not provide valuable insights.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'not clear to me' and 'it would be very useful to consider', rather than using harsh or dismissive language. The reviewer also offers constructive suggestions for improvement, which is a polite way to address shortcomings in the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'easy to follow and clearly written', they express concerns about the lack of major contribution and the need for more in-depth analysis. The reviewer states 'I do not see any major contribution in this paper' and suggests additional analyses that should have been included, indicating disappointment with the current state of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with positive comments and using phrases like 'I would expect' rather than making harsh demands. The critique is presented as suggestions rather than direct criticisms, maintaining a professional and courteous tone.""]"
"['This paper proposed another GAN-based PU learning method. The mathematics in this paper is not easy to follow, and there are many other critical issues.\n\n*****\n\nThe clarity is really an issue. First of all, I cannot easily follow the meanings behind the equations. I guess the authors first came up with some concrete implementation and then formalize it into an algorithm. Given the current version of the paper, I am not sure whether this clarity of equations can be fixed without an additional round of review or not.\n\nMoreover, the logic in the story line is unclear to me, especially the 3rd paragraph that seems to be mostly important in the introduction. There are two different binary classification problems, of separating the positive and negative classes, and of separating the given and generated data. I cannot see why the generated data can serve as negative data. This paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me.\n\n*****\n\nThe paper classified PU learning methods into two categories, one-stage methods and two-stage methods. This is interesting. However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning. The former problem setting was proposed very early and formalized in ""learning classifiers from only positive and unlabeled data"", KDD 2008; the latter problem setting was proposed in ""presence-only data and the EM algorithm"", Biometrics 2009 and formalized in ""analysis of learning from positive and unlabeled data"", NIPS 2014. Surprisingly, none of these 3 papers was cited. By definition, GAN-based PU learning belongs to the latter problem setting while Rank Prune can only be applied to the former but was included as a baseline method.\n\nThe huge difference between these two settings and their connections to learning with noisy labels are known for long time. To be short, class-conditional noise model corrupts P(Y|X) and covers censoring PU, mutual contamination distribution framework corrupts P(X|Y) and covers case-control PU, and mathematically mutual contamination distribution framework is more general than class-conditional noise model and so is case-control PU than censoring PU. See ""learning from corrupted binary labels via class-probability estimation"", ICML 2015 for more information where the above theoretical result has been proven. An arXiv paper entitled ""on the minimal supervision for training any binary classifier from only unlabeled data"" has some experimental results showing that methods for class-conditional noise model cannot handle mutual contamination distributions. The situation is similar when applying censoring PU methods to case-control PU problem setting.\n\nFurthermore, the class-prior probability pi is well-defined and easy to estimate in censoring PU, see ""learning classifiers from only positive and unlabeled data"" mentioned above. However, it is not well-defined in case-control PU due to an identifiability issue described in ""presence-only data and the EM algorithm"" mentioned above. Thus, the target to be estimated is defined as the maximal theta such that theta*P(X|Y)<=P(X) following ""estimating the class prior and posterior from noisy positives and unlabeled data"", NIPS 2016. BTW, ""mixture proportion estimation via kernel embedding of distributions"" is SOTA in class-prior estimation; the previous NIPS paper was written earlier and accepted later.\n\nIn summary, as claimed in the paper and shown in Table 1 in the introduction, all discriminative PU methods and GenPU require to know pi for learning. This is true, but this is because they are designed for a more difficult problem setting---learning classifiers and estimating pi are both more difficult. Lacking some basic knowledge of PU learning is another big issue.\n\n*****\n\nThe novelty is to be honest incremental and thus below the bar of ICLR. The significance is similarly poor, due to that the experiments mixed up methods for censoring PU and those for case-control PU. What is more, F1-score is a performance measure for information retrieval rather than binary classification. We all know GANs are pretty good at MNIST but not CIFAR-10. In fact, GenPU has a critical issue of mode collapse, and this is why GenPU reports 1-vs-1 rather than 5-vs-5 on MNIST. Even though, I still think GenPU makes much more sense than PGAN and D-GAN.', 'The motivation of the work is not clear but the novelty seems to be present.\n\nThe paper is very hard to follow as the problem description and intuition of the D-GAN is not clearly written.\n\nBased on the experiments, the proposed method achieves marginal improvement in terms of F1 score but sometimes also slightly lower performance than other GAN based such as PGAN, so the impact of this work to solve positive unlabelled data problem is not evident. \n\nI am personally not as familiar with the PU problem and existing frameworks so my confidence in the assessment is low; my main experience is in the computer vision for autonomous driving and sparse coding.\n\nBut my feeling is this paper is marginally below the threshold of acceptance.', '[Summary]\nPU learning is the problem of learning a binary classifier given labelled data from the positive class and unlabelled data from both the classes. The authors propose a new  GAN architecture in this paper called the Divergent Gan (DGAN) which they claim has the benefits of two previous GAN architectures proposed for PU learning: The GenPU method and the Positive-Gan architecture. The key-equation of the paper is (5) which essentially adds an additional loss term to the GAN objective to encourage the generator to generate samples from the negative class and not from the positive class. The proposed method is validated through experiments on CIFAR and MNIST.\n\n[Pros]\n1. The problem of PU learning is interesting.\n2. The experimental results on CIFAR/MNIST suggest that some method that the authors coded worked at par with existing methods.\n\n[Cons]\n1. The quality of the writeup is quite bad and a large number of critical sentences are unclear. E.g.\na. [From Abstract] It keeps the light adversarial architecture of the PGAN method, with **a better robustness counter the varying images complexity**, while simultaneously allowing the same functionalities as the GenPU method, like the generation of relevant counter-examples.\nb. Equation (3) and (4) which are unclear in defining R_{PN}(D, δ)\nc. Equation (6) which says log[1 - D(Xp)] = Yp log[D(Xp)] + (1-Yp) log[1-D(Xp)] which does not make any sense.\nd. The distinction between the true data distribution and the distribution hallucinated by the the generator is not maintained in the paper. In key places the authors mix one with the other such as the statement that supp(Pp (Xp )) ∩ supp(Pn (Xn )) → ∅\nIn short even after a careful reading it is not clear exactly what is the method that the authors are proposing.\n\n2. Section 2.2 on noisy-label learning is only tangentially related to the paper and seems more like  a space filler.\n\n3. The experimental results in Table 4 and Table 3 do not compare to GenPU. Although the authors claim several times that the GenPU method is *onerous*, it is not clear why GenPU is so much more onerous in comparison to other GAN based methods which all require careful hyper-parameter tuning and expensive training. Furthermore the reference PN method performs worse than other PU learning methods which does not make sense. Because of this I am not quite convinced by the experiments.']","[-80, -40, -60]","[-20, 20, 20]","[""The sentiment score is -80 because the review is highly critical, pointing out numerous issues with the paper including lack of clarity, poor logic, missing important citations, and fundamental misunderstandings of PU learning. The reviewer states the paper has 'incremental' novelty and 'poor' significance, indicating strong negative sentiment. The politeness score is -20 because while the reviewer uses some polite phrases like 'I guess' and 'I am not sure', the overall tone is quite blunt and critical. The reviewer directly states issues without much softening language, using phrases like 'clarity is really an issue' and 'lacking some basic knowledge of PU learning is another big issue'. While not overtly rude, the language is more direct and critical than would be considered polite in academic discourse."", ""The sentiment score is -40 because the review is generally negative, pointing out several issues with the paper such as unclear motivation, difficulty in following the problem description, and marginal improvements in results. The reviewer also states that the paper is 'marginally below the threshold of acceptance'. However, it's not extremely negative as the reviewer acknowledges some novelty and admits to low confidence in their assessment. The politeness score is 20 because while the reviewer is critical, they use relatively neutral language and acknowledge their own limitations ('my confidence in the assessment is low'). They also use phrases like 'my feeling is' which softens the criticism. The review doesn't use overtly polite language, but it avoids rudeness and maintains a professional tone."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges some positive aspects ('Pros'), the 'Cons' section is much more extensive and critical. The reviewer points out significant issues with the paper's clarity, methodology, and experimental results. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'The quality of the writeup is quite bad' which is honest but not overly harsh. The reviewer also provides specific examples to support their critiques, which is a constructive approach. The language is not particularly warm or polite, but it avoids rudeness, maintaining a neutral to slightly polite professional tone.""]"
"[""\nMuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions\n\nThis paper proposed multi-modal MAML, which alleviates the single initialization limitation of MAML by modulating task prior with MAML. Below are some comments.\n\nPros:\n1. Overall, the paper is clear written. \n2. By using modulation, there is no need to explicitly control/know the number of modes in advance.\n3. The multi-MAML baseline is good for an ablation study, though it is only on a synthetic regression task.\n4. MUMOMAML combines the strength of both gradient-based and model-based meta-learners.\n\nCons.\n1. The novelty of the paper seems to be the combinations of MAML and FiLM, which seems a bit limited.\n2. I wonder whether the proposed method is mostly useful when there is a clear mode difference as in the synthetic regression/RL tasks of the paper. Moreover, the paper only shows tasks with only two-three modes, what happen when there is a large number of modes?\n3. What's the results on the mini-Imagenet? The Omniglot seems to be saturated already.\n4. Why tau is not updated in the inner loop of Algorithm 1?\n\nMinor:\n1. page 4, 'in to' -> 'into'\n2. In page 5, in 'based on the input data samples and then\ninfers the parameter to modulate the prior model', what does the `input data samples' refers to? Is it the training data of a meta-learning task?\n3. Do you stop gradient to the learner in MUMOMAML?"", 'This paper presents an interesting meta-learning algorithm that can learn from multimodal task distributions, by combining model-based and gradient-based meta-learning. It first represents a task with a latent feature vector produced by a recurrent network, and then modulates the meta-learned prior with this task-specific latent feature vector before applying gradient-based adaptation. Experimental results are shown to validate the proposed algorithm. While the idea appears to be quite novel for meta-learning, further efforts are needed to improve this work.\n\n1. The experiment on few-shot image classification is less convincing, with results only on the Omniglot dataset, which are only comparable to those of existing methods that are designed for a single task distribution. Why not show results on MiniImageNet or other more realistic datasets which are more likely to be multimodal?  \n\n2. It is not clear how the idea of modulation works for multimodal meta-learning. More discussions and insights can be helpful.\n\n3. The encoding of a task relies on the order of examples, which seems undesirable for a classification or regression problem. ', 'Strengths:\n+ The paper identifies a valid limitation of the MAML algorithm: With a limited number of gradient descent steps from a single initialization, there is a limit to the ability of a fixed-size neural network to adapt to tasks sampled from a diverse dataset.\n+ The tSNE plots show some preliminary interesting structure for the simple regression and RL tasks, but not for the classification task.\n\nWeaknesses:\n- The motivation of uncovering latent modes of a task distribution does not align with the proposed method. The algorithm computes a continuous representation of the data from a task (which is fixed during gradient-based fast adaptation). The mode identity, on the other hand, should be a discrete variable.  Such a discrete variable is never explicitly computed in the proposed method.\n- The technical writing is unclear and jargon is often used without definition. Importantly, one of the central motivators of the paper, ""task modulation"", is never given a precise definition.\n- The standard few-shot classification task (Omniglot) does not clearly consist of a task distribution that is multimodal, so the method is not well-motivated in this setting.\n- Experimental conclusions are weak.\n\nMajor comments:\n- The paper neglects to discuss how the proposed method could be used in the context of other methods for ""gradient-based meta-learning"" such as Ravi & Larochelle (2016). I believe the attention-based modulation and the FiLM modulation could be easily adapted to that setting. Why was this not discussed or evaluated?\n- Conditioning has been used in the context of few-shot learning before, but this is not discussed (https://arxiv.org/abs/1805.10123, https://arxiv.org/abs/1806.07528).\n- The paper often confounds task representation with neural network parameter values. For example, Figure 1 depicts the adaptation of parameter values with gradients (\\nabla L), yet the caption describes ""task modes."" More careful writing would disentangle these two components.\n- The motivation for the particular form of the task embedding computation is not given. What were the other options? Why not, for example, an order-invariant function instead of a bidirectional GRU?\n- In all of the experiments, there is no appropriate baseline that keeps the parameter dimensionality constant, so it is unclear whether the (marginal) improvement in performance is due to added expressivity by adding more parameters rather than an algorithmic improvement. I suggest an ensembling baseline with an appropriate number of ensemble members.\n- There is no evaluation on a standard benchmark for few-shot classification (miniImageNet), and the Omniglot improvement is small.\n- The reinforcement learning comparison at some point compares MUMOMAML with modulation applied (therefore with access to task-specific data) to MAML with no adaptation (and therefore no access to task-specific data). This is not entirely fair.\n- tSNE results can be misleading (e.g., see https://distill.pub/2016/misread-tsne/), and the task delineation is not extremely clean. I would be more convinced if a clustering algorithm were applied.\n\nMinor comments:\n- The paper needs to be checked over for English grammar and style.\n- everywhere: The ""prior"" referred to in this paper is not a prior in the Bayesian sense. I suggest a more careful use of terminology.\n- abstract: ""augment existing gradient-based meta-learners"" You augment a specific variant of gradient-based meta-learning, MAML.\n- pg. 1: ""carve on a snowboard"" don\'t know what this means\n- The terminology of ""task distribution"" and ""modes"" thereof is used without introduction in the introduction section. The terminology ""model-based meta-learning/adaptation"" and ""gradient-based meta-learning/adaptation"" is also used without introduction here. This makes the introduction unnecessarily opaque. Consider the reader who is not familiar with meta-learning papers; they would have a very hard time parsing, for example, the phrase ""...this not only requires additional identity information about the modes, which is not always available or is ambiguous when the modes are not clearly disjoint..."" (pg. 1).\n- Further, the terminology ""model-based"" seems non-standard, and is aliased with the term model-based reinforcement learning (which specifically refers to the set of RL algorithms that make use of a ""model"" of transition dynamics). Since the paper tackles a reinforcement learning benchmark, this may lead to some confusion.\n- pg. 3; ""our model does not maintain an internal state"" Is the task representation/embedding not an internal state?\n- pg. 3: ""relevant but vaguely related skills"" this is imprecise\n- pg. 3: The episodic training setup, which is standard to meta-learning setups, could be much better described. The MAML algorithm could be given better intuition.\n- everywhere: ""task specific"" -> task-specific\n- Algorithm 1: ""infer"" is a misuse of terminology that usually refers to an operation in latent variable probabilistic modelling. Since the computation of \\tau is purely feedforward, I recommend writing ""compute.""\n- \\tau should be used in some places where v is used instead']","[20, -20, -60]","[50, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer begins by listing several pros of the paper, including clear writing, good methodology, and combining strengths of different approaches. However, they also list several cons and areas for improvement, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They present both pros and cons in a balanced manner, and phrase their criticisms as questions or suggestions rather than harsh criticisms. The use of 'I wonder' and phrasing criticisms as questions (e.g., 'Why is tau not updated...?') contributes to the polite tone. The reviewer also acknowledges the paper's strengths before presenting criticisms, which is a polite approach in academic reviewing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and 'novel', they also state that 'further efforts are needed to improve this work'. The review points out several limitations and areas for improvement, which contributes to the overall negative sentiment. However, it's not strongly negative as the reviewer does recognize the potential of the work.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful language throughout. They begin with positive acknowledgments of the paper's contributions before moving on to constructive criticism. The suggestions are phrased as questions or statements rather than direct commands, which maintains a polite tone. Phrases like 'It is not clear' and 'More discussions and insights can be helpful' are diplomatic ways of pointing out areas for improvement."", ""The sentiment score is -60 because the review lists significantly more weaknesses than strengths, and the major comments section is extensive with critical points. The reviewer identifies several substantial issues with the paper's methodology, motivation, and experimental conclusions. However, it's not entirely negative as the reviewer acknowledges some strengths and provides constructive feedback. The politeness score is 20 because while the reviewer is direct and critical, the language used is professional and constructive. The reviewer uses phrases like 'I suggest' and 'I would be more convinced if' which are polite ways of offering improvements. The review also balances criticism with acknowledgment of the paper's strengths. However, some phrases like 'The paper needs to be checked over for English grammar and style' could be perceived as slightly impolite, preventing a higher politeness score.""]"
"['Post-rebuttal update:\nThe authors have clarified their main messages, and the paper is now less vague about what is being investigated and the conclusions of the experiments. The same experimental setup has been extended to use CIFAR-10 as an additional, more realistic dataset, the use of potentially more powerful LSTMs as well as GRUs, and several runs to have more statistically significant results - which addresses my main concerns with this paper originally (I would have liked to see a different experimental setup as well to see how generalisable these findings are, but the current level is satisfying). Indeed, these different settings have turned up a bit of an anomaly with the GRU on CIFAR-10, which the authors claim that they will leave for future work, but I would very much like to see addressed in the final version of this paper. In addition some of the later analysis has only been applied under one setting, and it would make sense to replicate this for the other settings (extra results would have to fit into the supplementary material).\n\nI did spot one typo on page 4 - ""exterme"", but overall the paper is also better written, which helps a lot. I commend the authors on their work revising this paper and will be upgrading my rating to accept.\n\n---\n\nThe authors investigate the hidden state dynamics of RNNs trained on a single task that mixes (but clearly separates) pattern recognition and memorisation. The authors then introduce two curricula specific to the task, and study how the trained RNNs behave under different deviations from the training protocol (generalisation). They show that under the curriculum that exhibited the best generalisation, there exist more robust (persisting for long time periods) fixed/slow points in the hidden state dynamics. They then extend the optimisation procedure developed by Sussillo & Barak for continuous-time RNNs in order to find these points. Finally, they use this method to track the speed of these points during the course of training, and link spikes in speed to one of the curricula which introduces new classes over time.\n\nUnderstanding RNNs - and in particular how they might ""generalise"" - is an important topic of research. As done previously, studying RNNs as dynamical systems is a principled way to do so. In this line of work some natural objects to look into are fixed points and even slow points (Sussillo & Barak) - how long they can persist, and how large the basins of attraction are. While I believe the authors did a reasonable job following this through, I have some concerns about the experimental setup. Firstly, only one task is used - based on object classification with images - so it is unclear how generalisable these findings are, given that the authors\' setup could be extended to cover at least another task, or at least another dataset. MNIST is a sanity check, and many ideas may fail to hold when extended to slightly more challenging datasets like CIFAR-10.\n\nSecondly, as far as I can tell, the results are analysed on one network per setting, so it is hard to tell how significant the differences are. While some analyses may only make sense for single networks, e.g. Figure 3, a proper quantification of some of the results over several training runs would be appropriate.\n\nFinally, it is worth investigating LSTMs on this task. This is not merely because they are more commonly used than GRUs, but they are strictly more powerful - see ""On the Practical Computational Power of Finite Precision RNNs for Language Recognition"", published at ACL 2018. Given the results in this paper and actually the paper that first introduces the forget gate for LSTMs, it seems that performing these experiments solely with GRUs might lead to wrong conclusions about RNNs in general.\n\nThere are also more minor spelling and grammatical errors throughout the text that should be addressed. For example, there is a typo on the task definition on page 2 - ""the network should *output* a null label.""', ""This paper titled <don't judge a book by its cover - on the dynamics of recurrent neural networks> studies how different curriculum learning results in different hidden state dynamics and impacts extrapolation capabilities. By training a 200-GRU-RNN to report the class label of a MNIST frame hidden among noisy frames, authors found different training paradigms resulted in different stability in memory structures quantified as stable fixed points. Their main finding is that training by slowly increasing the time delay between stimulus and recall creates more stable fixed point based memory for the classes.\n\nAlthough the paper was clearly written in a rush, I enjoyed reading it for the most part. These are very interesting empirical findings, and I can't wait to see how well it generalizes.\n\n# I find the title not very informative. Connection from 'Book' to 'Curriculum' is weak.\n\n# The task does not have inherent structure that requires stable fixed points to solve. In fact, since it only requires maximum 19 time frames, it could come up with weird strategies. Since the GRU-RNN is highly flexible, there would be many solutions. The particular strategy that was learned depends on the initial network and training strategy.\n\n# How repeatable were these findings? I do not see any error bars in Fig 2 nor table 1.\n\n# How sensitive is this to the initial conditions? If you use the VoCu trained network as initial condition for a DeCu training, does it tighten the sloppy memory structure and make it more stable?\n\n# I liked the Fig 2b manipulation to inject noise into the hidden states.\n\n# English can be improved in many places.\n\n# Algorithm 1 is not really a pseudo-code. I think it might be better to just describe it in words. This format is unnecessarily confusing and hard to understand.\n\n# Does the backtracking fixed/slow point algorithm assume that the location of the fixed point does not change through training? Wouldn't it make more sense to investigate the pack-projection of desired output at each training step?\n\n# PTMT, PMTP, and TaCu are not described well in the main text.\n\n# The pharse 'basin of attraction' is losely used in a couple of places. If there isn't an attractor, its basin doesn't make sense.\n\n# Fig 4 is not very informative. Also is this just from one network each?\n\n# Fig 5 is too small!\n\n# page 2: input a null label -> output a null label\n\n# it would be interesting to see how general those findings are on other tasks, e.g., n-back task with MNIST."", 'This manuscript attempts to use a delayed classification task to understand the dynamics of RNNs.  The hope is to use this paradigm to distinguish memorization from processing in RNNs, and to further probe when specific curricula (VoCu, DeCu) outperform each other, and what can be inferred from that.   \n\nQuality: \n- The experimental design is sensible.  However, it is rather too much a toy example, and too narrow, hence it is unclear how much these results can be generalized across RNNs\n- Highly problematic is that the key concepts in the paper -- memorization and processing -- are not well defined.  This means that the results inevitably are just interpretations rather than any sort of compelling empiricism.  After a careful read of the paper, I found it difficult to take away any particular learnings, other than ""training RNNs is hard."" \n\nClarity:\n- The paper is fairly straightforward, which is positive.\n- The lack of clarity around particular definitions means that clarity is limited to the empirical results.  If the results are incredibly compelling, that would be acceptable, but absent that (as is the case here), the paper comes across to me as rather unclear in its purpose or its takeaway message.\n\nOriginality: \n- The Barak 2013 paper seems to be the key foundation for this work.  This work is sufficiently original beyond that paper.\n\nSignificance: \n- The combination of lack of clarity and limited results on a toy setting imply that the significance is rather too low.\n\nOverall, this is a genuine effort to explore the dynamics of RNNs.  I suggest improvements can be made by either (1) working hard to clarify in the text *exactly* what question is being asked and answered, or (2) broadening the results to make a much more rigorously supported point, or (3) ideally both.\n']","[50, 50, -30]","[75, 70, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer begins by acknowledging the authors' efforts to address previous concerns and improve the paper, upgrading their rating to 'accept'. However, they still point out some remaining issues and areas for improvement. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, commends the authors on their revisions, and frames criticisms constructively. They use phrases like 'I would have liked to see' and 'it would make sense to' rather than making demands. The reviewer also acknowledges the importance of the research topic and the reasonableness of the authors' approach, balancing critiques with positive feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses enjoyment and interest in the paper's findings, stating 'I enjoyed reading it for the most part' and 'These are very interesting empirical findings.' However, they also point out several areas for improvement, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I liked...' and 'it would be interesting to see...' which maintain a positive tone. The reviewer also acknowledges the paper's strengths while suggesting improvements, which is a polite approach to peer review."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('genuine effort', 'experimental design is sensible', 'fairly straightforward'), the overall tone is critical. The reviewer points out several significant issues with the paper, such as lack of clarity, limited generalizability, and low significance. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They acknowledge the positive aspects before discussing the limitations, and use phrases like 'I suggest' rather than making demands. The tone is professional and not personally critical, focusing on the work itself rather than the authors.""]"
"['UPDATE (after author response):\n\nThank you for updating the paper, the revised version looks better and the reviewers addressed some of my concerns. I increased my score.\n\nThere\'s one point that the reviewers didn\'t clearly address:  ""It might be worth evaluating the usefulness of the method on higher-dimensional examples where the analytic forms of q(x|z) and q(z) are known, e.g. plot KL between true and estimated distributions as a function of the number of dimensions."" Please consider adding such an experiment.\n\nThe current experiments show that the method works better on low-dimensional datasets, but the method does not seem to be clearly better on more challenging higher dimensional datasets.  I agree with Reviewer1 that ""Perhaps more ambitious applications would really show off the power of the model and make it standout from the existing crowd."" Showing that the method outperforms other methods would definitely strengthen the paper.\n\nSection 5.4: I meant error bars in the numbers in the text, e.g. 13 +/- 5.\n\n---------\n\nThe paper proposes a new loss for training deep latent variable models. The novelty seems a bit limited, and the proposed method does not consistently seem to outperform existing methods in the experiments. I\'d encourage the authors to add more experiments (see below for suggestions) and resubmit to a different venue.\n\nSection 4:\n- q(z) seems to be undefined. Is it the aggregated posterior?\n- How is equation (1) related to ELBO that is used for training VAEs?\n\nSome relevant references are missing: I’d love to see a discussion of how this loss relates to other VAE-GAN hybrids.\n\nVEEGAN: Reducing mode collapse in GANs using implicit variational learning\nhttps://arxiv.org/pdf/1705.07761.pdf\n\nDistribution Matching in Variational Inference\nhttps://arxiv.org/pdf/1802.06847.pdf\n\n\nSection 5.1:\n- The quantitative comparison measures MSE in pixel space and inception score, neither of which are particularly good measures for measuring the quality of how well the conditionals match. I’d encourage the authors to consider other metrics such as log-likelihood.\n\n- It might be worth evaluating the usefulness of the method on higher-dimensional examples where the analytic forms of q(x|z) and q(z) are known, e.g. plot KL between true and estimated distributions as a function of the number of dimensions.\n\nSection 5.4: \n- The error bars seem quite high. Is there a reason why the method cannot reliably reduce mode collapse?\n\nMinor issues:\n- CIFAT-10 -> CIFAR-10\n', 'This paper presents a variant of the adversarial generative modeling\nframework, allowing it to incorporate an inference mechanism. As such it is\nvery much in the same spirit as existing methods such as ALI/BiGAN. The\nauthors go through an information theoretic motivation but end up with the\nstandard GAN objective function plus a latent space (z) reconstruction\nterm. The z-space reconstruction is accomplished by first sampling z from\nits standard normal prior and pushing that sample through the generator to\nget sample in the data space (x), then x is propagated through an encoder\nto get a new latent-space sample z\'. Reconstruction is done to reduce the\nerror between z\' and z.\n\nNovelty: The space of adversarially trained latent variable models has\ngrown quite crowded in recent years. In light of the existing literature,\nthis paper\'s contribution can be seen as incremental, with relatively low novelty. \n\nIn the end, the training paradigm is basically the same as InfoGAN, with\nthe difference being that, in the proposed model,  all the latent\nvariables are inferred (in InfoGAN, only a subset of the latent\nvariables are inferred) . This difference was a design decision on the part of the InfoGAN\nauthors and, in my opinion, does not represent a significantly novel\ncontribution on the part of this paper.  \n\nExperiments: The experiments show that the proposed method is\nbetter able to reconstruct examples than does ALI -- a result is not\nnecessarily surprising, but is interesting and worth further\ninvestigation. I would like to understand better why it is that latent\nvariable (z) reconstruction gives rise to better x-space reconstruction.\n\nI did not find the claims of better sample quality of AIM over ALI to be\nwell supported by the data. In this context, it is not entirely clear what\nthe significant difference in inception scores represents, though on this, the\nresults are consistent with those previously published\n\nI really liked the experiment shown in Figure 4 (esp. 4b), it makes the\ndifferences between AIM and ALI very clear. It shows that relative to ALI,\nAIM sacrifices coherence between the ""marginal"" posterior (the distribution\nof latent variables encoded from data samples) and the latent space\nprior, in favor of superior reconstructions. AIM\'s choice of trade-off is\none that, in many contexts, one would happy to take as it ensures that\ninformation about x is not lost -- as discussed elsewhere in the paper.\nI view this aspect of the paper by far the most interesting. \n\nSummary,\nOverall, the proposed AIM model is interesting and shows promise, but I\'m\nnot sure how much impact it will have in light of the existing literature\nin this area. Perhaps more ambitious applications would really show off the\npower of the model and make it standout from the existing crowd. \n', 'The goal this is work is to develop a generative model that enjoys the strengths of both GAN and VAE without their inherent weaknesses. The paper proposes a learning framework, in which a generating process p is modeled by a neural network called generator, and an inference process q by another neural network encoder. The ultimate goal is to match the joint distributions, p(x, z) and q(x, z), and this is done by attempting to match the priors  p(z) and q(z) and matching the conditionals p(x|z) and q(x|z). As both q(z) and q(x|z) are impossible to sample from, the authors mathematically expand this objective criterion and rewrite to be dependent only on p(x|z), q(x) and q(z|x), that can be easily sampled from. In the main part of the work, the authors use the f-divergence theory (Nowozin et al., 2016) to present the optimization problem as minmax optimization problem, that is learned using an adversarial game, using training and inference algorithms that are proposed by the authors. In experiments, the authors consider both reconstruction and generation tasks using the MNIST, CIFAR10 and CelebA datasets. Results show that the proposed method yields better MSE reconstruction error as better as a higher inception scores for the generated examples, compared to a standard GAN and a few other methods. \n\nThis work establishes an important bridge between the VAE and GAN framework, and has a a good combination of theoretical and experimental aspects. Experiments results are encouraging, even though only relatively simple and small datasets were used. Overall, I would recommend accepting the paper for presentation in the conference. ']","[-20, -20, 80]","[60, 60, 70]","[""Sentiment score: The review starts with some positive feedback about improvements made, but overall expresses concerns about the paper's novelty and performance. The reviewer suggests additional experiments and resubmission to a different venue, indicating a slightly negative sentiment. However, it's not entirely negative as there are constructive suggestions for improvement.\n\nPoliteness score: The language used is generally polite and professional. The reviewer uses phrases like 'Thank you for updating the paper' and 'I'd encourage the authors to...' which are courteous. They provide constructive criticism and suggestions rather than harsh criticism. However, the politeness is not overly effusive, maintaining a professional tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express concerns about its novelty and impact. The reviewer states that the paper's contribution is 'incremental, with relatively low novelty' and questions 'how much impact it will have'. However, they do note some positive aspects, like the interesting experiment in Figure 4, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths ('interesting and shows promise') while offering constructive criticism. They use phrases like 'I would like to understand better' and 'I really liked', which contribute to a polite tone. The reviewer also provides detailed explanations for their critiques, which is a courteous approach in academic review."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, highlighting its importance in bridging VAE and GAN frameworks, praising its combination of theoretical and experimental aspects, and recommending acceptance for conference presentation. The positive tone is evident in phrases like 'important bridge,' 'good combination,' and 'encouraging' results. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, avoiding harsh criticism and focusing on the paper's strengths. The reviewer offers a balanced assessment without using overly effusive praise, maintaining a courteous and constructive tone appropriate for academic peer review.""]"
"['Quality: \n- In 4.4, the authors have vigorously explored the space of hyperparameters. However, they do not describe how to determine the hyperparameters, e.g., set aside a validation set from a part of the training set and determine the hyperparameters using this validation set, while the authors split the two datasets into only training and test sets, respectively. Without this procedure, the results may overfit to the test set via repeated experiments. Even though the used datasets are of few-million, this procedure guarantees a minimum requirement for a reliable outcome from the proposed model. I firmly recommend the authors to update their results using a validation set to determine the hyperparameters and then report on the test set. Please describe these experimental details to ensure that the performed experiments are valid.\n   \nClarity:\n- Overall, the writing can be improved via proof-reading and polishing the sentences. In Introduction section, ""there is little work applying..."" can be specified or rephrased with ""it is underexplored to apply"", and ""input features are not independent"" can be specified on what there are not independent. Moreover, the last two sentences in the second paragraph in the Introduction section is unclear what the authors want to argue: ""The combinations in linear models are then made by cross product over different fields. Due to the sparsity problem, the combinations rely on much manual work of domain experts.""\n- The authors use top-k restriction (Shazeer et al., 2017) to consider sparse relationships among the features. For this reason, have you tried to use the L1 loss on the probability distributions, which are the outputs of softmax function?\n- In 4.5, the authors said, they ""are in most concern of complementarity."" What is the reason for this idea and why not the ""relevance""?\n- In Table 4, I\'m afraid that I don\'t understand the content (three numbers in parenthesis) of the third column. How does each input x_i or x_j, or a tuple of them get their own CTR?\n\nOriginality and significance:\n- They apply self-attention to learn multiple categorical features to predict Click-Through-Rate (CTR) with a top-k non-zero similarity weight constraint to adapt to their categorical inputs. Due to this, the scientific contribution to the corresponding community is highly limited to providing empirical results on the CTR task.\n- The authors argue that ""most of current DNN-based models simply concatenate all feature embeddings""; however, this argument might be an over-simplified statement for the existing models in section 2.\n- Similar works can be found but missed to cite: [1] proposes a general framework to self-attention to exploit sequential (time-domain) and parallel (feature-domain) non-locality. [2] learns bilinear attention maps to integrate multimodal inputs using skip-connections and multiple layers on top of the idea of low-rank bilinear pooling.\n\nPros:\n- Strong empirical results on two CTR tasks using the previous works of self-attention and top-k restriction techniques.\n\nCons:\n- This work fairly lacks its originality since the proposing method heavily relies on the two previous works, self-attention and top-k restriction. They apply them to multiple categorical features to estimate CTR; however, their application seems to be monotonic without a novel idea of task-specific adaptation.\n\nMinor comments:\n- In Figure 1, ""the number of head"" -> ""the number of heads"".\n\n\n[1] Wang, X., Girshick, R., Gupta, A., & He, K. (2018). Non-local Neural Networks. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\'18).\n[2] Kim, J.-H., Jun, J., & Zhang, B.-T. (2018). Bilinear Attention Networks. In Advances in Neural Information Processing Systems 32 (NIPS\'18).', 'Summary:\nThe authors apply the self-attention mechanism, a.k.a. transformer, to improve the representations of multi-field categorical features in recommendation systems. Unlike the previous approaches in which multi-field features are simply concatenated, the proposed method more actively combines those features improving the final performance.\n\nStrengths:\n+ It is reasonable to apply the permutation-invariant self-attention mechanism to the multi-field features as orders of the fields should not matter.\n+ The method achieves the state-of-the-art performance on two datasets.\n\nWeaknesses:\n- The paper lacks the technical novelty as it does not propose any novel technique. Rather, it simply applies an existing technique to a new type of dataset.\n- More extensive analyses on the learned representation would improve the paper.\n- As the authors argue, the method can be used upon other existing state-of-the-art networks. Showing the improvement on other methods would improve the paper. Currently, the authors only present improvement on a simple MLP.\n\nQuestions:\nTo apply the self-attention, the embeddings of the field features should be projected in the same space. I wonder if this physically makes sense. I wonder how they are embedded in the features and relate to each other. I would suggest to include some analysis on the features while putting some rows of Table 3 to the appendix since many of these rows are not directly related to the method itself.\n\nOverall, I like the idea of the paper. However, the paper lacks the technical novelty and presents only limited experiments and analysis. I would suggest the authors include more analyses on the learned representations.', 'Summary\nThe paper proposes to apply self-attention mechanism from (Vaswani et.al.) to the task of click-through rate prediction, which is a task where one has input features which are a concatenation of multiple one-hot vectors (referred to as fields). The paper finds that applying the self-attention mechanism outperforms state of the art approaches for the task on two benchmark datasets. It then proposes a small modification to the self-attention mechanism, retaining only the top-k attentions to sparsify attention, and finds that it leads to marginal improvements.\n\nStrengths\n+ The paper is fairly well written, and the contributions are succinctly summarized.\n+ The proposed approach appears to get state of the art results on click-through rate prediction.\n+ The results contain clear ablations of the approach.\n\nNegatives\n1. It is not clear why the skip connection is needed. Especially, using the skip connection the way it is done in Eqn. 4 is a bit odd since we are adding positive quantities to each other, meaning that across multiple rounds, the magnitude of the attended feature will keep increasing. Perhaps this is the reason why performance deteriorates after attending thrice?\n\n2. Calling top-K a regularizer is somewhat misleading as it is a fundamentally different model class, as opposed to a regularizer that imposes a soft constraint on the kind of solutions that should be preferred in our hypothesis class. The current paper does not show with enough clarity if the improvements with top-k are because it is a better model for the data or because it is a better regularizer. One way to do this would be to systematically look at the difference between training and validation losses with and without top-k and show that the difference is smaller when the model is regularized. \nMore generally, it would be ideal to show what kind of a constraint the top-k attention places on the hypothesis class of the original model. For example, the dropout paper shows that dropout, in the linear case is equivalent to L2 regularization (in expectation). (*)\n\n3. It would be interesting to report how often there is an overlap in the top k indices chosen across multi-head attentions.\n\n4. What are the relative number of parameters in each of the models for which the results are reported? Are we ensuring that a similar number of parameters are used to report all the results in say, Table. 1.? Also, it would be good to report error bars for the results in Table. 1 since the differences seem to quite small. (*)\n\n\nPreliminary Evaluation\nThe paper is a fairly straightforward application of self-attention to the task of click-through rate prediction. The major modeling novelty is in using top-k attentions for the click-through task, the interestingness/ validity of which needs to be demonstrated more clearly to understand if this heuristic might apply to other models and other datasets. Important points for the rebuttal are marked with a (*) above.\n']","[-30, 20, 20]","[50, 60, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths ('strong empirical results'), they express significant concerns about the methodology, originality, and clarity of the paper. The reviewer recommends major changes, such as updating results using a validation set, which indicates a somewhat negative sentiment. However, it's not entirely negative as they see some value in the work. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I firmly recommend' and 'Please describe', showing consideration for the authors. They also balance criticism with positive remarks. However, the tone is not overly polite, maintaining a professional, direct approach typical of academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer begins by acknowledging the strengths of the paper and states 'I like the idea of the paper.' However, they also point out significant weaknesses and suggest improvements, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as suggestions rather than demands. They use phrases like 'I would suggest' and 'I wonder if' which maintain a polite tone even when expressing criticisms. The review is balanced, offering both positive and negative feedback in a professional manner."", ""The sentiment score is slightly positive (20) because the review begins by highlighting the strengths of the paper, including that it's well-written, achieves state-of-the-art results, and contains clear ablations. However, the reviewer also points out several negatives and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The criticisms are framed as suggestions or questions rather than harsh judgments. The reviewer also uses phrases like 'it would be interesting' and 'it would be ideal,' which maintain a constructive tone. The review concludes with a balanced summary, referring to the paper as 'fairly straightforward' but still highlighting its novelty, which further contributes to the polite and professional tone.""]"
"['This paper proposes a justification to one observation on VAE: ""restricting the family of variational approximations can, in fact, have a positive regularizing effect, leading to better generalization"". The explanation given in this work is based on Gaussian mean-field approximation.\n\nI had trouble to understand some parts of this paper, since some of the sentences do not make sense to me. For example\n\n- the sentence under eq. (2)\n- the sentence ""Bacause the identity of the datapoint can never be learned by ..."" What is the identity of a dat point?\n\nIt looks like section 2.1 wants to show the connections between eq. (2) and other popularly used inference methods. Somehow, those connections are not clear to me.\n\nBesides some issues in the technical details, the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.\n\nAs in (Cover and Thomas, 2012), which is also cited in this paper, DPI is defined on a Markov chain X -> Y -> Z and we have I(X,Y) >= I(X,Z). \n\nHowever, based on the definition of \\theta and \\tilde{\\theta} given in the first sentence of section 2.3, the relation between \\theta, \\tilde{\\theta} and D should be: D <- \\theta -> \\tilde{\\theta} (if it is a generative model) or D -> \\theta -> \\tilde{\\theta} (if a discriminative model). Either case, I don\'t think we can have the inequality in eq. (5).  ', 'This paper studies ""Noisy Information Bottlenecks"". The overall idea is that, if the mutual information between learned parameters and the data is limited, then this prevents overfitting. It proposes to create a ""bottleneck"" to limit the mutual information. Specifically, the bottleneck is created by having the data depend on a noisy version of the parameters, rather than the true parameters and invoking the information processing inequality. The paper gives an example of Gaussian mean field inference. Ultimately, the analysis boils down to looking at a signal-to-noise ratio of the algorithm, which looks very much like regularization.\n\nI think this is a very interesting direction, but the present paper is somewhat unclear. In particular, the example in section 3.1 says that a noisy information bottleneck is introduced, but then says that the modified and unmodified models have ""training algorithms that are exactly equivalent."" I think this example needs to be clarified. Many of the parameters here are also unclear and not properly defined/introduced. What is the relationship between $\\theta$ and $\\tilde\\theta$ exactly? In this simple model, can we not calculate the mutual information directly (i.e., without the bottleneck)?\n\nThe connection between mutual information and generalization has been studied in several contexts [see, e.g., the references in this paper and https://arxiv.org/abs/1511.05219 https://arxiv.org/abs/1705.07809 https://arxiv.org/abs/1712.07196 https://arxiv.org/pdf/1605.02277.pdf https://arxiv.org/abs/1710.05233 https://arxiv.org/pdf/1706.00820.pdf ] and further exploration is desirable. This paper is giving an information-theoretic perspective on existing variational inference methods. Such a perspective is interesting, but needs to be further developed and explained. Specifically, how can mutual information in this context be formally linked to generalization/overfitting? Also, the definition of mutual information used in this paper uses the inferred distribution q (e.g., in eq. 2), which is somewhat unusual. As a result, constraining the model will alter the mutual information and I think the effect of this should be remarked on.\n\nOverall, I think this paper has some interesting ideas, but those need to be fleshed out and clearly explained in a future revision.', ""I read the paper and understand it, for the most part. The idea is to interpret some regularization technics as a from of noisy bottleneck, where the mutual information b tween learned parameters and the data is limited through the injection of noise. \n\nWhile, the paper is a plaisant read, I find difficult to access its importance and the applicability of the ideas presented beyond the analogy with the capacity computation. Perhaps other referee will have a clearer opinion.\n\nI'd be interested to hear if the authors see a connection between their formalism and the one of Reference prior in Bayesian inference (Bernardo et al https://arxiv.org/pdf/0904.0156)\n\nPro: nicely written, clear interpretation of regularization as a noise injection technics, explicit link with information theoery and Shanon capacity.\n\nCon: not clear to me how strong and wide the implications are, beyond the analogies and the reinterpretation""]","[-60, -20, 20]","[20, 50, 60]","[""The sentiment score is -60 because the review is generally negative, pointing out several issues with the paper. The reviewer mentions having trouble understanding parts of the paper, notes sentences that don't make sense, and identifies a major problem with the paper's use of the data processing inequality. However, it's not entirely negative as the reviewer acknowledges the paper's attempt to explain an observation on VAE. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'I had trouble to understand' and 'It looks like' rather than making blunt accusations. The reviewer also provides specific examples of issues, which is helpful. However, the use of bold text for the word 'wrong' could be seen as slightly impolite, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper's direction 'very interesting', they also state that it is 'somewhat unclear' and needs to be 'further developed and explained'. The reviewer points out several areas that need clarification or improvement, indicating a generally critical stance despite seeing potential in the work. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and framing criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'I think this is a very interesting direction' and 'Overall, I think this paper has some interesting ideas' demonstrate a polite and constructive tone, even while pointing out areas for improvement."", ""The sentiment score is slightly positive (20) because while the reviewer finds the paper 'plaisant' to read and acknowledges its clarity, they express uncertainty about its importance and wider applicability. The positive aspects (well-written, clear interpretation) are balanced against the concerns (unclear implications). The politeness score is moderately high (60) due to the reviewer's respectful tone, use of phrases like 'I'd be interested to hear' and 'Perhaps other referee will have a clearer opinion', which show consideration for the authors and other reviewers. The reviewer also balances criticism with praise, listing both pros and cons, which contributes to the polite tone.""]"
"['Summary:\nThe paper presents a novel combinatorial search algorithm for the discrete target propagation framework developed in Friesen & Domingos (2018). Experiments on small datasets with small models demonstrate some potential for the proposed approach; however, scalability remains a concern.\n\n  Pros:\n-\tI like the goal of the work and think that if the targeted problem were to be solved it would be an interesting contribution to the field.\n-\tThe proposed search algorithm is reasonable and works OK.\n-\tThe paper is mostly well written and clear.\n-\tThe experiments are reasonably thorough.\n\n  Cons:\n-\tThe paper states that it is a feasibility study on search methods for learning hard-threshold networks, however, it only evaluates the feasibility of one combinatorial search method. \n-\tIt’s not made clear whether other approaches were also investigated or what the authors learned from their exploration of this approach.\n-\tThe actual algorithm is not very well explained, despite being the main contribution of the paper.\n-\tThe datasets and models are small and not necessarily representative of the requirements of the field.\n-\tScalability remains a serious concern with the proposed approach.\n-\tIt’s not clear to me that the paper presents a sufficient enough contribution to warrant acceptance.\n\nOverall, I like the direction but do not feel that the paper has contributed enough to warrant acceptance. The authors should use the experiments they’ve run and also run more experiments in order to fully analyze their method and use this analysis to improve their proposed approach. \n\n\nQuestions and comments:\n\n1.\tDid you try alternative local search algorithms or did you just come up with a single approach and evaluate it? What did you learn from the experiments and the development of this algorithm that will let you create a better algorithm in the next iteration?\n\n2.\tI think that it is unfair to say that “it suggests a simpler, independent justification for the performance improvements obtained by their method.” in reference to the work of Friesen & Domingos (2018), given that the straight-through estimator is not well justified to begin with and their work in fact provides a justification for it. I do agree that it is important to investigate alternative heuristics and approaches within the discrete target propagation framework, however.\n\n3.\tSections 2 and 3 do not clearly define what L_i is and where it comes from. Since these do not normally exist in a deep network they should be clearly defined.\n\n4.\t“step 2(b)” is not well defined in section 3.1.1. I assume that this refers to lines 4-8 of Algorithm 1? The paper should explain this procedure more clearly in the text. Further, I question the locality of this method, as it seems capable of generating any possible target setting as a neighbor, with no guarantee that the generated neighbors are within any particular distance of the uniform random seed candidate. Please clarify this.\n\n5.\tI believe that a negative sign is missing in the equation for T_i in ‘Generating a seed candidate’. For example, in the case where |N| = 1, then T_i = sign(dL/dT_i) would set the targets to attain a higher loss, not lower. Further, for |N|=1, this seems to essentially reduce to the heuristic method of Friesen & Domingos (2018). \n\n6.\tIn the ‘Setting the probabilities’ section:\n(a) All uses of sign(h) can be rewritten as h (since h \\in {-1, +1}), which would be simpler.\n(b) The paper contradicts itself: it says here ‘flip entries only when sign(dL/dh) = sign(h)’ but Algorithm 1 says ‘flip entries only when sign(dL/dh) != sign(h)’. Which is it?\n(c) What is the value of a_h in the pseudocode? (i.e., how is this computed in the experiments)\n\n7.\tIn the experiments, the paper says that ‘[this indicates] that the higher dimensionality of the CIFAR-10 data manifold compared to MNIST may play a much larger role in inhibiting the performance of GRLS.’ How could GRLS overcome this? Also, I don’t agree with the claim made in the next sentence – there’s not enough evidence to support this claim as the extra depth of the 4-layer network may also be the contributing factor.\n\n8.\tIn Table 2, why are some numbers missing? The paper should explain what this means in the caption and why it occurs. Same for the bolded numbers.\n\n9.\tThe Loss Weighting, Gradient Guiding, Gradient Seeding, and Criterion Weighting conditions are not clearly defined but need to be to understand the ablation experiments. Please define these properly.\n\n10.\tThe overall structure of the algorithm is not stated. Algorithm 1 shows how to compute the targets for one particular layer but how are the targets for all layers computed? What is the algorithm that uses Algorithm 1 to set the targets and then set the weights? Do you use a recursive approach as in Friesen & Domingos (2018)?\n\n11.\tIn Figure 2, what dataset is this evaluation performed on? It should say in the caption. It looks like this is for MNIST, which is a dataset that GRLS performs well on. What does this figure look like for CIFAR-10? Does increasing the computation for the heuristic improve performance or is it also flat for a harder dataset? This might indicate that the initial targets computed are useful but that the local search is not helping. It would be helpful to better understand (via more experiments) why this is and use that information to develop a better heuristic.\n\n12.\tIt would be interesting to see how GRLS performs on other combinatorial search tasks, to see if it is a useful approach beyond this particular problem.\n\n13.\tIn the third paragraph of Section 4.2, it says ‘The results are presented in Table 3.’ I believe this should say Figure 3. Also, the ordering of Figure 3 and Table 3 should be swapped to align with the order they are discussed in the text. Finally, the caption for Table 3 is insufficiently explanatory, as are most other captions; please make these more informative.\n\n14.\tIn Section 4.3:\n(a), the paper refers to Friesen & Domingos (2018) indicating that zero loss is possible if the dataset is separable. However, what leads you to believe that these datasets are separable? A more accurate comparison would be the loss for a powerful non-binarized baseline network. \n(b) Further, given the standard error of GRLS, it’s possible that its loss could be substantially higher than that of FTPROP as well. It would be interesting to investigate the cases where it does much better and the cases where it does much worse to see if these cases are informative for improving the method.\n\n15.\tWhy is there no discussion of training time in the experiments? While it is not surprising that GRLS is significantly slower, it should not be ignored either. The existence of the Appendix should also be mentioned in the main paper with a brief mention of what information can be found in it.\n\n16.\tIn Algorithm 1, line 2 is confusingly written. Also, notationally, it’s a bit odd to use h both as an element and as an index into T.\n\n17.\tThere are a number of capitalization issues in the references.\n\n18.\tThe Appendix refers to itself (“additional hyperparameter details can be found in the appendices”).\n', 'The paper discusses a method for learning neural networks with hard-threshold activation. The classic perceptron network is a one-layer special case of this. This paper discusses a method called guided random local search for optimizing such hard-threshold networks. The work is based on a prior work by Friesen&Domingos (2018) on a discrete target propagation approach by separating the network into a series of Perceptron problem (not Perception problems as quoted by this paper). \nI feel the proposed method is mainly formulated in Equation (3), which makes sense but not very surprising. The proposed random local search is not very exciting either. Finally, the empirical results presented do not seem to justify the superiority of the proposed method over existing methods. Overall, the paper is too preliminary.', 'TargetProp\n\nThis paper addresses the problem of training neural networks with the sign activation function. A recent method for training such non-differentiable networks is target propagation: starting at the last layer, a target (-1 or +1) is assigned to each neuron in the layer; then, for each neuron in the layer, a separate optimization problem is solved, where the weights into that neuron are updated to achieve the target value. This procedure is iterated until convergence, as is typical for regular networks. Within the target propagation algorithm, the target assignment problem asks: how do we assign the targets at layer i, given fixed targets and weights at layer i+1? The FTPROP algorithm solves this problem by simply using sign of the corresponding gradient. Alternatively, this paper attempts to assign targets by solving a combinatorial problem. The authors propose a stochastic local search method which leverages gradient information for initialization and improvement steps, but is essentially combinatorial. Experimentally, the proposed algorithm, GRLS, is sometimes competitive with the original FTPROP, and is substantially better than the pure gradient approximation method that uses the straight-through estimator.\n\nOverall, I do like the paper and the general approach. However, I think the technical contribution is thin at the moment, and there is no dicussion or comparison with a number of methods from multiple papers. I look forward to discussing my concerns with the authors during the rebuttal period. However, I strongly believe that the authors should spend some time improving the method before submitting to the next major conference. I am confident they will have a strong paper if they do so.\n\nStrengths:\n- Clarity: a well-written paper, easy to read and clear w.r.t. the limitations of the proposed method.\n- Approach: I really like the combinatorial angle on this problem, and strongly believe this is the way forward for discrete neural nets.\n\nWeaknesses:\n- Algorithm: GRLS, in its current form, is quite basic. The Stochastic Local Search (SLS) literature (e.g. [1]) is quite rich and deep. Your algorithm can be seen as a first try, but it is really far from being a powerful, reliable algorithm for your problem. I do appreciate your analysis of the assignment rule in FTPROP, and how it is a very reasonable one. However, a proper combinatorial method should do better given a sufficient amount of time.\n- Related work: references [2-10] herein are all relevant to your work at different degrees. Overall, the FTPROP paper does not discuss or compare to any of these, which is really shocking. I urge the authors to implement some or all of these methods, and compare fairly against them. Even if your modified target assignment were to strictly improve over FTPROP, this would only be meaningful if the general target propagation procedure is actually better than [2-10] (or the most relevant subset).\n- Scalability: I realize that this is a huge challenge, but it is important to address it or at least show potential techniques for speeding up the algorithm. Please refer to classical SLS work [1] or other papers and try to get some guidance for the next iteration of your paper.\n\nGood luck!\n\n[1] Hoos, Holger H., and Thomas Stützle. Stochastic local search: Foundations and applications. Elsevier, 2004.\n[2] Stochastic local search for direct training of threshold networks\n[3] Training Neural Nets with the Reactive Tabu Search\n[4] Using random weights to train multilayer networks of hard-limiting units\n[5] Can threshold networks be trained directly?\n[6] The geometrical learning of binary neural networks\n[7] An iterative method for training multilayer networks with threshold functions\n[8] Backpropagation Learning for Systems with Discrete-Valued Functions\n[9] Training Multilayer Networks with Discrete Activation Functions\n[10] A Max-Sum algorithm for training discrete neural networks']","[-20, -70, -20]","[60, -20, 60]","[""The sentiment score is -20 because while the reviewer acknowledges some positive aspects ('I like the goal of the work', 'The proposed search algorithm is reasonable and works OK', 'The paper is mostly well written and clear'), the overall tone is critical and suggests that the paper is not ready for acceptance ('do not feel that the paper has contributed enough to warrant acceptance'). The reviewer lists more cons than pros and expresses concerns about the paper's contribution and scalability.\n\nThe politeness score is 60 because the reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'I like the goal of the work' and 'I think that it is unfair to say', and provide detailed, actionable feedback. The reviewer also balances criticism with positive comments. However, the score is not higher because the review is quite direct in its criticism, though it remains respectful."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer describes the paper as 'too preliminary' and states that the proposed method is 'not very surprising' or 'exciting'. They also mention that the empirical results don't justify the method's superiority. These criticisms indicate a strong negative sentiment towards the paper's content and contributions. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is quite dismissive and blunt. Phrases like 'not very exciting' and 'too preliminary' are direct criticisms without much softening language. However, the reviewer does start with a neutral summary of the paper, which prevents the score from being even lower."", ""The sentiment score is slightly negative (-20) because while the reviewer expresses liking aspects of the paper, they state the technical contribution is 'thin' and recommend significant improvements before resubmission. They list more weaknesses than strengths. However, it's not strongly negative as they believe the authors can produce a 'strong paper' with revisions. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, offers encouragement ('I look forward to...', 'Good luck!'), and frames criticisms constructively. They acknowledge positives before giving critiques and use phrases like 'I urge the authors' rather than harsh commands.""]"
"['Paper Summary: This paper studies the zero-shot learning problem with deep generative models. More specifically, it proposed a hybrid framework that combines VAEs (more precisely, the variational hetero-encoder or VHE) and GANs all together. The entire model is composed of an image encoder (Weibull upward-downward variational encoder), a text decoder (Poisson Gamma belief network), and an image generator (generative adversarial network). Once learned, the generative models can be directly used for zero-shot classification and various image generation applications. In the experiments, two benchmark datasets CUB and Oxford-Flowers are used.\n\n==\nNovelty/Significance:\nZero-shot learning is a challenging task and he main motivation of the paper (using generative model) is interesting. The text representation in the paper is simply bag-of-words which limits the application to some extent. In a broader context, image captioning using generative model seems quite relevant.\n\nDiverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space, Wang et al. In NIPS 2017.\n\n==\nQuality:\nOverall, reviewer feels this is a very interesting work. However, the results from the paper is quite mixed. It is not yet convincing whether the proposed approach is the state-of-the-art in zero-shot learning or text-to-image generation. \n\nFirst, this paper demonstrates the power of generative models in text-to-image generation and other applications. However, reviewer feels that the zero-shot classification result is weak. In Table 1 and Table 2, it seems that GAZSL (Zhu et al. 2018) outperforms the proposed approach. \n\nQ1: In Table 2, is it possible to report the top-5 accuracy on CUB-easy and top-1 accuracy on Oxford-Flower dataset? Otherwise, it is not very convincing that proposed approach is better than the state-of-the-art approach GAZSL.\n\nSecond, the text-to-image generation results look reasonably good. But the resolution and quality of generated images are far from state-of-the-art. One suggestion is to train the VHE model with an improved image generator.\n\nStackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, Zhang et al. In CVPR 2017.\n\nAttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks, Xu et al. In CVPR 2018.\n\nAlso, reviewer would expect to see an improved image generator can lead to a better ZSL performance.\n\nTypo: In the title: Zero-Short → Zero-Shot.\n\n', '[Paper Summary]\nThis work suggests a new model incorporating deep topic model (text decoder),  VHE (image encoder), and GAN. The topic model and the VHE shares the topic parameters, and the GAN generate an image regarding the topic. Then, for ZSL, the image is encoded to corresponding topic parameters, and the parameter can tell which text description (unseen) is matched with the highest probability. GAN model is used to generate an image given the topic distribution. During the training of the GAN, the VHE and topic model is jointly trained and can enhance the ZSL performance marginally.\n\n[pros]\n- This work successfully incorporated the topic model and image encoding/decoding. All the individual parts are already given, but I think incorporating them in terms of a unified probabilistic model is also meaningful for this field.\n- This work shows superior performance on the image to text ZSL problem.\n- This work mapped the text to image, image to text mapping in a generative manner.\n\n[cons]\n- The problem is only valid when the unseen class distribution is very similar to the given classes. For example, the text description of unseen classes should be well represented to the topics from seen classes. \n- It is doubtful that this corresponds to the term zero-shot learning; dealing with the case that the unseen class and the seen class are notably different from each other.\n- Similarly, GAN learns images from the seen classes, and by nature, GAN would not generate the proper images of the unseen class if the image distribution of the unseen class is different to the already seen class. In the paper, the classes are very similar to each other (birds, flowers) and that would be the reason GAN worked in this model.\n- (minor) The likelihood of the text (image) given topic should be provided and compared to the existing models.\n\n\n[Summary]\n- The reviewer is personally interested in the proposal of the work, but concern that ZSL is difficult to be the main target of the paper because the model can only deal with the classes with (very) similar semantics, and this is the main reason for the rating. The testing with more diverse class should be given, or solid explanation of the mentioned problem would be required.\n\n', 'This paper developed a generative model to perform simultaneous embedding/generation of images/texts, with application to zero-shot learning. The experiments are extensive.\n\nThe novelty of this work is lacking.\nThe proposed method consists of a bag of existing models proposed by previous works.\nBut why using a certain model is not justified or explanined.\nFor example, for image generation, why use GAN instead of VAE.\nFor text encoding, why use PGBN, instead of recurrent VAE.\n\nThe method seems deteched from the problem of ZSL.\nThroughout the paper, the authors mostly talk about how to perform joint embedding of texts and images. They give ZSL a touch, but as a side thing.\nI would suggest the authors to position this work as a text/iamge embedding/generation work. Then use ZSL as an application.\n\nThe writing needs to be significantly improved. In the first paragraph describing the problem of ZSL, the authors end up with talking about the evaluation metric of ZSL.\n\n\n']","[50, -20, -50]","[80, 60, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the work as 'very interesting' and acknowledges its potential, but also expresses some reservations about the results being 'quite mixed' and 'not yet convincing'. The reviewer sees value in the approach but feels improvements are needed. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. The reviewer also acknowledges the paper's strengths before discussing its limitations. The use of phrases like 'reviewer feels' and 'one suggestion is' contribute to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work ('pros'), they express significant concerns about the applicability and validity of the approach for zero-shot learning. The cons outweigh the pros, and the summary indicates that the reviewer has reservations about the main target of the paper. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, acknowledging the strengths of the work before presenting criticisms. They use phrases like 'I think incorporating them... is also meaningful' and 'This work successfully incorporated...', which show respect for the authors' efforts. The criticisms are presented as concerns rather than harsh judgments, using phrases like 'It is doubtful that...' and 'The problem is only valid when...', maintaining a polite tone while expressing reservations."", ""The sentiment score is -50 because the review is generally negative, pointing out several issues with the paper such as lack of novelty, unjustified model choices, and poor writing. However, it's not entirely negative as it acknowledges the extensive experiments. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state criticisms plainly (e.g., 'The novelty of this work is lacking') without softening the language, but also without using insulting or harsh words. The reviewer offers suggestions for improvement, which is constructive, but the overall tone remains neutral and matter-of-fact.""]"
"['This paper experiments with pre-trained language models for common sense tasks such as Winograd Schema Challenge and ConceptNet KB completion. While the authors get high numbers on some of the tasks, the paper is not particularly novel, and suffers from methodology and clarity problems. These prevent me from recommending its acceptance.\n\nThis paper shows that pre-trained language models (LMs) can be used to get strong improvements on several datasets. While some of the results obtained by the authors are impressive, this result is not particularly surprising in 2018. In the last year or so, methods based on pre-trained LMs have been shown extremely useful for a very wide number of NLP tasks (e.g., Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018). Moreover, as noticed to by the authors, Schwartz et al. (2017) demonstrated that LM perplexity can be useful for predicting common-sense information for the ROC story cloze task. As a result, the technical novelty in this paper is somewhat limited. \n\nThe paper also suffers from methodological problems:\n-- The main results observed by the author, the large improvement on the (hard!) Winograd schema challenge, is questionable: The GLUE paper (Wang et al., 2018) reports that the majority baseline for this dataset is about 65%. It is unclear whether the authors here used the same version of the dataset (the link they put does not unambiguously decide one way or another). If so, then the best results published in the current paper is below the majority baseline, and thus uninteresting. If this is not the same dataset, the authors should report the majority baseline and preferably also run their model on the (hard) version used in GLUE. \n-- The authors claim that their method on ConceptNet is unsupervised, yet they tune their LM on triplets from the training set, which makes it strongly rely on task supervision.\n\nFinally, the paper suffers clarity issues. \n-- Some sections are disorganized. For instance, the experimental setup mentions experiments that are introduced later (the ConceptNet experiments). \n-- The authors mention two types of language models (word and character level), and also 4 text datasets to train the LMs on, but do not provide results for all combinations. In fact, it is unclear in table 2 what is the single model and what are the ensemble (ensemble of the same model trained on the same dataset with different seeds? or the same model with different datasets?).\n-- The authors do not address hyper-parameter tuning. \n-- What is the gold standard for the ""special word retrieved"" data? how is it computed?\n\n\nOther comments: \n-- Page 2: ""In contrast, we make use of LSTMs, which are shown to be qualitatively different (Tang et al., 2018) and obtain significant improvements without fine-tuning."": 1. Tang et al. (2018) do not discuss fine-tuning. 2. Levy et al. (ACL 2018) actually show interesting connections between LSTMs and self-attention.\n-- Schwartz et al. (2017) showed that when using a pre-trained LM, normalizing the conditional probability of p(ending | story) by p(ending) leads to much better results than  p(ending | story). The authors might also benefit from a similar normalization. \n-- Page 5: how is F1 defined?\n\nMinor comments: \n-- Page 2: "" ... despite the small training data size (100K instances)."": 100K is typically not considered a small training set (for most tasks at least)\n-- Page 5: ""... most of the constituent documents ..."": was this validated in any way? how?\n-- The word ""extremely"" is used throughout the paper without justification in most cases.\n\n\nTypos and such:\npage 1: ""... a relevant knowledge to the above Winograd Schema example, **does** not present ... "": should be ""is""\npage 5: ""In the previous sections, we ***show*** ..."": showed\npage 7: ""For example, with the ***test*** ..."": ""test instance""\n', 'This paper uses a language model for scoring of question answer candidates in the Winograd schema dataset, as well as introduces a heuristic for scoring common-sense knowledge triples.\n\nQuality:\nPros: The paper shows improvements over previous papers for two tasks related to common-sense knowledge. They both mainly utilise simple language models, which is impressive. The second one uses an additional supervised collaborative filtering-style model. The authors further perform a detailed error analysis and ablation study.\nCons: The paper isn\'t very well-written. It contains quite a few spelling mistakes and is unclear in places. The Winograd Scheme Challenge isn\'t a very interesting dataset and isn\'t widely used. In fact, this is evidenced by the fact that most cited papers on that datasets are preprints and technical reports.\n\nClarity:\nThe paper is confusing in places. It should really be introduced in the abstract what is meant by ""common sense"". Details of the language model are missing. It is only clear towards the end of the introduction that the paper explores two loosely-related tasks using language models.\n\nOriginality:\nPros: The suggested model outperforms others on two datasets.\nCons: The suggested models are novel in themselves. As the authors also acknowledge, using language models for scoring candidates is a simple baseline in multiple-choice QA and merely hasn\'t been tested for the Winograd schema dataset.\n\nSignificance:\nOther researchers within the common-sense reasoning community might cite this paper. The significance of this paper to a larger representation learning audience is rather small.', 'This paper evaluates language models for tasks that involve ""commonsense knowledge"" such as the Winograd Schema Challenge (WSC), Pronoun Disambiguation Problems (PDP), and commonsense knowledge base completion (KBC). \n\nPros:\n\nThe approach is relatively simple in that it boils down to just applying language models. \n\nThe results outperform prior work, in some cases by pretty large margins. \n\nThe language models are quite large and it appears that this is the first time that large-scale language models have been applied seriously to the Winograd Schema Challenge (rather than, say, to the NLI version of it in GLUE, to which it is hard to compare these results). \n\nSome of the additional and ablation experiments are interesting. \n\n\nCons:\n\nWhile this paper has some nice results, there are some aspects of it that concern me, specifically related to hyperparameter tuning and experimental rigor:\n\nThere are three methods given for using an LM to make a prediction: full, full-normalized, and partial. For PDP, full (or perhaps full-normalized?) works best, while for WSC, partial works best. The differences among methods, at least for WSC, are quite large: from 2% to 10% based on Figure 3. I don\'t see a numerical comparison for PDP, so I\'m not sure how these methods compare on it. Since the datasets are so small, there is no train/dev/test split, so how were these decisions made? They seem to be oracle decisions. This is concerning to me, as there is not much explanation given for why one method is better than another method. \n\nMy guess is that the reason why partial works better than full for WSC is because the WSC sentences were constructed such that the words up to and including the ambiguous pronoun were written such that it would be difficult to identify the antecedent of the pronoun. The rest of the sentence would be needed to identify the antecedent. I\'ll assume for this discussion that the sentence can be divided into three parts x, y, and z, where x is the part before the pronoun, y is the phrase that replaces the pronoun, and z is the part after the pronoun. Then p(z|xy), which is partial scoring, corresponds to p(xyz)/p(xy), which can be viewed as ""discounting"" or ""normalizing for"" the probability of putting y in place of the pronoun given the context x. For WSC, I think one of the goals in writing the instances is to make the ""true"" p(xy) approximately equal for both values of y. The language model will not naturally have this be the case (i.e., that p(xy) is the same for both antecedents), so dividing by p(xy) causes the resulting partial score to account for the natural differences in p(xy) for different antecedents. This could be explored empirically. For example, the authors could compute p(xy) for both alternatives for all PDP and WSC instances and see if the difference (|p(xy_1) - p(xy_2)|, where y_1 and y_2 are the two alternatives) is systematically different between WSC and PDP. Or one could see if p(xy) is greater for the antecedent that is closer to the pronoun position or if it is triggered by some other effects. It could be the case that the PDP instances are not as carefully controlled as the WSC instances and therefore some of the PDP instances may exhibit the situation where the prediction can be made partially based on p(xy). The paper does not give an explanation for why full scoring works better for PDP and chalks it up to noise from the small size of PDP, but I wonder if there could be a good reason for the difference.\n\nThe results on KBC are positive, but not super convincing. The method involves fine-tuning pretrained LMs on the KBC training data, the same training data used by prior work. The new result is better than prior work (compared to the ""Factorized"", the finetuned LM is 2.1% better on the full test set, and 0.3% better on the novelty-based test set), but also uses a lot more unlabeled data than the prior work (if I understand the prior work correctly). It would be more impressive if the LM could use far fewer than the 100K examples for fine-tuning. Also, when discussing that task, the paper says: ""During evaluation, a threshold is used to classify low-perplexity and high-perlexity instances as fact and non-fact."" How was this threshold chosen?\n\nI also have a concern about the framing of the overall significance of the results. While the results show roughly a 9% absolute improvement on WSC, the accuracies are still far from human performance on the WSC task. The accuracy for the best pretrained ensemble of LMs in this paper is 61.5%, and when training on WSC-oriented training data, it goes up to nearly 64%. But humans get at least 92% on this task. This doesn\'t mean that the results shouldn\'t be taken seriously, but it does suggest that we still have a long way to go and that language models may only be learning a fraction of what is needed to solve this task. This, along with my concerns about the experimental rigor expressed above, limits the potential impact of the paper.\n\n\nMinor issues/questions:\n\nIn Sec. 3.1: Why refer to the full scoring strategy as ""naive""? Is there some non-empirical reason to choose partial over full?\n\nThe use of SQuAD for language modeling data was surprising to me. Why SQuAD? It\'s only 536 articles from Wikipedia. Why not use all of Wikipedia? Or, if you\'re concerned about some of the overly-specific language in more domain-specific Wikipedia articles, then you could restrict the dataset to be the 100K most frequently-visited Wikipedia articles or something like that. \n\nI think it would be helpful to give an example from PDP-60.\n\nSec. 5.1: How is F_1(n) defined?  I also don\'t see how a perfect score is 1.0, but maybe it\'s because I don\'t understand how F_1(n) is defined.\n\nSec. 6.1: Why would t range from 1 to n for full scoring? Positions before k are unchanged, right? So q_1 through q_{k-1} would be the same for both, right?\n\nIn the final example in Figure 2, I don\'t understand why ""yelled at"" is the keyword, rather than ""upset"". Who determined the special keywords?\n\nI was confused about the keyword detection/retrieval evaluation. How are multi-word keywords handled, like the final example in Figure 2? The caption of Table 5 mentions ""retrieving top-2 tokens"". But after getting the top 2 tokens, how is the evaluation done?\n\nSec. 6.3 says: ""This normalization indeed fixes full scoring in 9 out of 10 tested LMs on PDP-60."" Are those results reported somewhere in the paper? Was that normalization used for the results in Table 2?\n\nSec. 6.3 says: ""On WSC-273, the observation is again confirmed as partial scoring, which ignores c [the candidate] altogether, strongly outperforms the other two scorings in all cases"" -- What is meant by ""which ignores c altogether""?  c is still being conditioned on and it must not be ignored or else partial scoring would be meaningless (because c is the only part that differs between the two options). \n\n\nTypos and minor issues:\n\nBe consistent about ""common sense"" vs. ""commonsense"".\n\nBe consistent about ""Deepnet"" vs. ""DeepNet"" (Tables 2-3).\n\nSec. 1:\n""even best"" --> ""even the best""\n""such as Winograd"" --> ""such as the Winograd""\n""a few hundreds"" --> ""a few hundred""\n""this type of questions"" --> ""this type of question""\n""does not present"" --> ""is not present""\n""non-facts tuples"" --> ""non-fact tuples""\n\nSec. 2:\n""solving Winograd"" --> ""solving the Winograd""\n""Store Cloze"" --> ""Story Cloze""\n""constructed by human"" --> ""constructed by humans""\n\nSec. 4:\nWhat is ""LM-1-Billion""?\nWhy SQuAD?\n""Another test set in included"" --> ""Another test set is included""\n\nSec. 5.2:\nCheck margin in loss_new\n\n""high-perlexity"" --> ""high-perplexity""\n\nSec. 6:\nFigure 2 caption: ""keyword appear"" --> ""keyword appears""\n\nSec. 6.2:\n""for correct answer"" --> ""for the correct answer""\n\nAppendix A:\n""acitvation"" --> ""activation""\nAppendix B:\nFigure 4 caption: ""is of"" --> ""is""\nThe right part of Figure 4 has some odd spacing and hyphenation.\n']","[-70, -20, -20]","[20, 50, 60]","[""The sentiment score is -70 because the reviewer expresses significant criticism and does not recommend acceptance. They state the paper 'is not particularly novel, and suffers from methodology and clarity problems.' The reviewer points out multiple issues with the methodology, clarity, and novelty. However, they do acknowledge some positive aspects like 'impressive' results, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'The authors might also benefit from...' and provide constructive feedback. The reviewer avoids harsh language, but also doesn't use overtly polite phrasing, resulting in a slightly positive but close to neutral politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros like improvements over previous papers and a detailed error analysis, they also point out significant cons such as poor writing quality, unclear explanations, and the use of a dataset that isn't widely used or interesting. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) because the reviewer maintains a professional tone throughout, balancing critiques with acknowledgments of the paper's strengths. They use neutral language like 'isn't very well-written' instead of harsh criticism, and provide specific examples to support their points rather than making blanket negative statements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express significant concerns about the paper's methodology and experimental rigor. The reviewer states that certain aspects of the paper 'concern me' and that the impact is limited due to these issues. However, it's not entirely negative as they do recognize some merits of the work. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think it would be helpful' and 'I was confused about' rather than making blunt criticisms. They also provide detailed explanations for their concerns and offer constructive suggestions for improvement. The reviewer balances critique with recognition of the paper's strengths, which contributes to the polite tone.""]"
"[""The authors introduce the Attentive Task-Agnostic Meta-Learning (ATAML) algorithm for text classification.\nThe main idea is to learn task-independent representations, while other parameters, including the attention mechanism, are being fine-tuned for each specific task after pretraining. \nThe authors find that, for few-shot text classification tasks, their proposed approach outperforms several important baselines, e.g., random initialization and MAML, in certain settings. In particular, ATAML performs better than MAML for very few training examples, but in that setting, the gains are significant. \n\nComments:\n- I am unsure if I understand the contributions paragraph, i.e., I cannot count 3 contributions. I further believe the datasets are not a valid contribution, since they are just subsets of the original datasets.\n- Using a constant prediction threshold of 0.5 seems unnecessary. Why can't you just tune it?\n- 1-shot learning is maybe theoretically interesting, but how relevant is it in practice? "", 'This paper presents a meta learning approach for few-shot text classification, where task-specific parameters are used to compute a context-dependent weighted sum of hidden representations for a word sequence and intermediate representations of words are obtained by applying shared model parameters. \n\nThe proposed meta learning architecture, namely ATAML, consistently outperforms baselines in terms of 1-shot classification tasks and these results demonstrate that the use of task-specific attention in ATAML has some positive impact on few-shot learning problems. The performance of ATAML on 5-shot classification, by contrast, is similar to its baseline, i.e., MAML. I couldn’t find in the manuscript the reason (or explanation) why the performance gain of ATAML over MAML gets smaller if we provide more examples per class. It would be also interesting to check the performance of both algorithms on 10-shot classification.\n\nThis paper has limited its focus on meta learning for few-shot text classification according to the title and experimental setup, but the authors do not properly define the task itself.', ""Summary of paper: For the few shot text classification task, train a model with MAML where only a subset of parameters (attention parameters in this case) are updated in the inner loop of MAML. The empirical results suggest that this improves over the MAML baseline.\n\nI found this paper confusingly written. The authors hop between a focus on meta-learning to a focus on attention, and it remains unclear to me how these are connected. The description of models is poor -- for example, the ablation mentioned in 4.5.3 is still confusing to me (if the attention parameters are not updated in the inner loop of MAML, then what is?). Furthermore, even basic choices of notation, like A with a bar underneath in a crowded table, seem poorly thought out.\n\nI find the focus on attention a bit bizarre. It's unclear to me how any experiments in the paper suggest that attention is a critical aspect of meta-learning in this model. The TAML baseline (without attention) underperforms the ATAML model (with attention), but all that means is that attention improves representational power, which is not surprising. Why is attention considered an important aspect of meta learning?\n\nTo me, the most interesting aspect of this work is the idea of not updating every parameter in the MAML inner loop. So far, I've seen all MAML works update all parameters. The experiments suggest that updating a small subset of parameters can improve results significantly in the 1-shot regime, but the gap between normal MAML and the subset MAML is much smaller in the 5-shot regime. This result suggests updating a subset of parameters can serve as a method to combat overfitting, as the 1-shot regime is much more data constrained than the 5-shot regime.\n\nIt's unfortunate that the authors do not dig further down this line of reasoning. When does the gap between MAML on all parameters and only on a subset of parameters become near-zero? Does the choice of the subset of parameters matter? For example, instead of updating the attention weights, what happens if the bottommost weights are updated? How would using pretrained parameters (e.g., language modeling pretraining) in meta-learning affect these results? In general, what can be learned about overfitting in MAML?\n\nTo conclude, the paper is not written well and has a distracting focus on attention. While it raises an interesting question about MAML and overfitting, it does not have the experiments needed to explore this topic well.""]","[20, 20, -60]","[50, 50, -20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the proposed algorithm's improvements over baselines in certain settings, particularly for very few training examples. However, the score is not higher due to the critical comments and questions raised. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language to express concerns and ask questions without being overly critical or harsh. The reviewer presents their points as observations and inquiries rather than direct criticisms, which contributes to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and positive results, particularly for 1-shot classification tasks. However, they also point out limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without harsh criticism. They offer constructive feedback and suggestions for improvement in a respectful manner, such as proposing additional experiments and requesting clarifications, rather than dismissing the work outright."", ""The sentiment score is -60 because the reviewer expresses significant criticism throughout the review. They describe the paper as 'confusingly written,' with poor descriptions of models and notation. The reviewer finds the focus on attention 'bizarre' and states that the paper 'does not have the experiments needed to explore this topic well.' While they do mention some interesting aspects, the overall tone is quite negative. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. Phrases like 'confusingly written,' 'poorly thought out,' and 'bizarre' come across as somewhat impolite. However, they do use some neutral language and acknowledge some positive aspects, preventing the score from being lower.""]"
"['The paper introduces HR-TD, a variation of the TD(0) algorithm. The variant is meant to ameliorate a problem of ‘over-generalization’ with conventional TD. This problem is briefly characterized, but primarily it is presumed to be established by prior work. The algorithm is simple and a series of experiments are presented with it applied to Mountain Car, Acrobot, and Atari Pong, with both linear function approximation and neural networks (DDQN). It is claimed that the results establish HR-TD as an improvement over TD. However, I found the results unconvincing because they were statistically insufficient, methodologically flawed, and too poorly presented for me to be confident of the meaning of numbers reported. In addition, it is not hard to imagine very simple problems where the HR-TD technique would be counterproductive, and these cases were not included in the experimental testbeds.\n\nThe first weakness of the paper is with its characterization of the problem that it seeks to solve: over-generalization. This problem is never really characterized in this paper. It instead refers instead to two other papers, one published only in a symposium and the other with no publication venue identified.\n\nThe second weakness of the paper is the claim that it has done a theoretical analysis in Section 4.4. I don’t see how this section establishes anything of importance about the new method.\n\nThe problem with the main results, the empirical results, is that they do not come close to being persuasive. There are many problems, beginning with there simply not being clear. I read and reread the paragraphs in Section 5.1, but I cannot see a clear statement of what these numbers are. Whatever they are, to assess differences between them would require a statistical statement, and there is none given. Moreover to give such a statistical statement would require saying something about the spread of the results, such as the empirical variance, but none is given. And to say something about the variance one would need substantially more than 10 runs per algorithm. Finally, there is the essential issue of parameter settings. With just one number given for each algorithm, there are no results or no statement about what happens as the parameters are varied. Any one of these problems could render the results meaningless; together they surely are.\n\nThese problems become even greater in the larger problems.\n\nA nice property of HR-TD is that it is simple. Based on that simplicity we can understand it as being similar to a bias toward small weights. Such a bias could be helpful on some problems, possibly on all of those considered here. In general it is not clear that such a bias is a good idea, and regular TD does not have it. Further, HR-TD does not do exactly a bias to small weights, but something more complicated. All of these things need to be teased apart in careful experiments. I recommend small simple ones. \n\nHow about a simple chain of states that are passed through reliably in sequence leading to a terminal state with a reward of 1000 (and all the other rewards 0). Suppose all the states have the same feature representation. If gamma=1, then all states have value 1000, and TD will easily learn and stick at this value even for large alpha, but HR-TD will have a large bias toward 0, and the values will converge to something significantly less than the true value of 1000. \n\nThat would be an interesting experiment to do. Also good would be to compare HR-TD to a standard bias toward small weights to see if that is sufficient to explain the performance differences.', 'This paper introduces a variation on temporal difference learning for the function approximation case that attempts to resolve the issue of over-generalization across temporally-successive states. The new approach is applied to both linear and non-linear function approximation, and for prediction and control problems. The algorithmic contribution is demonstrated with a suite of experiments in classic benchmark control domains (Mountain Car and Acrobot), and in Pong.\n\nThis paper should be rejected because (1) the algorithm is not well justified either by theory or practice, (2) the paper never clearly demonstrates the existence of problem they are trying to solve (nor differentiates it from the usual problem of generalizing well), (3) the experiments are difficult to understand, missing many details, and generally do not support a significant contribution, and (4) the paper is imprecise and unpolished.\n\nMain argument\n\nThe paper does not do a great job of demonstrating that the problem it is trying to solve is a real thing. There is no experiment in this paper that clearly shows how this temporal generalization problem is different from the need to generalize well with function approximation. The paper points to references to establish the existence of the problem, but for example the Durugkar and Stone paper is a workshop paper and the conference version of that paper was rejected from ICLR 2018 and the reviewers highlighted serious issues with the paper—that is not work to build upon. Further the paper under review here claims this problem is most pressing in the non-linear case, but the analysis in section 4.1 is for the linear case. \n\nThe resultant algorithm does not seem well justified, and has a different fixed point than TD, but there is no discussion of this other than section 4.4, which does not make clear statements about the correctness of the algorithm or what it converges to. Can you provide a proof or any kind of evidence that the proposed approach is sound, or how it’s fixed point relates to TD?\n\nThe experiments do not provide convincing evidence of the correctness of the proposed approach or its utility compared to existing approaches. There are so many missing details it is difficult to draw many conclusions:\n1) What was the policy used in exp1 for policy evaluation in MC?\n2) Why Fourier basis features?\n3) In MC with DQN how did you adjust the parameters and architecture for the MC task?\n4) Was the reward in MC and Acrobot -1 per step or something else\n5) How did you tune the parameters in the MC and Acrobot experiments?\n6) Why so few runs in MC, none of the results presented are significant?\n7) Why is the performance so bad in MC?\n8) Did you evaluate online learning or do tests with the greedy policy?\n9) How did you initialize the value functions and weights?\n10) Why did you use experience replay for the linear experiments?\n11) IN MC and Acrobot why only a one layer MLP?\n\n\nIgnoring all that, the results are not convincing. Most of the results in the paper are not statistically significant. The policy evaluation results in MC show little difference to regular TD. The Pong results show DQN is actually better. This makes the reader wonder if the result with DQN on MC and Acrobot are only worse because you did not properly tune DQN for those domains, whereas the default DQN architecture is well tuned for Atari and that is why you method is competitive in the smaller domains. \n\nThe differences in the “average change in value plots” are very small if the rewards are -1 per step. Can you provide some context to understand the significance of this difference? In the last experiment linear FA and MC, the step-size is set equal for all methods—this is not a valid comparison. Your method may just work better with alpha = 0.1. \n\n\nThe paper has many imprecise parts, here are a few:\n1) The definition of the value function would be approximate not equals unless you specify some properties of the function approximation architecture. Same for the Bellman equation\n2) equation 1 of section 2.1 is neither an algorithm or a loss function\n3) TD does not minimize the squared TD. Saying that is the objective function of TD learning in not true\n4) end of section 2.1 says “It is computed as” but the following equation just gives a form for the partial derivative\n5) equation 2, x is not bounded \n6) You state TC-loss has an unclear solution property, I don’t know what that means and I don’t think your approach is well justified either\n7) Section 4.1 assumes linear FA, but its implied up until paragraph 2 that it has not assumed linear\n8) treatment of n_t in alg differs from appendix (t is no time episode number)\n9) Your method has a n_t parameter that is adapted according to a schedule seemingly giving it an unfair advantage over DQN.\n10) Over-claim not supported by the results: “we see that HR-TD is able to find a representation that is better at keeping the target value separate than TC is “. The results do not show this.\n11) Section 4.4 does not seem to go anywhere or produce and tangible conclusions\n\nThings to improve the paper that did not impact the score:\n0) It’s hard to follow how the prox operator is used in the development of the alg, this could use some higher level explaination\n1) Intro p2 is about bootstrapping, use that term and remove the equations\n2) Its not clear why you are talking about stochastic vs deterministic in P3\n3) Perhaps you should compare against a MC method in the experiments to demonstrate the problem with TD methods and generalization\n4) Section 2: “can often be a regularization term” >> can or must be?\n5) update law is a odd term\n6)” tends to alleviate” >> odd phrase\n7) section 4 should come before section 3\n8) Alg 1 in not helpful because it just references an equation\n9) section 4.4 is very confusing, I cannot follow the logic of the statements \n10) Q learning >> Q-learning\n11) Not sure what you mean with the last sentence of p2 section 5\n12) where are the results for Acrobot linear function approximation\n13) appendix Q-learning with linear FA is not DQN (table 2)', 'The paper considers the problem of overgeneralization between adjacent states of the one-step temporal difference error, when using function approximation. The authors suggest an explicit regularization scheme based on the correlation between the respective features, which reduces to penalizing the Hadamard product.\n\nThe paper has some interesting ideas, and the problem is very relevant to deep RL. Having a more principled approach to target networks would be nice. I have some concerns though:\n* The key motivation is not convincing. Our goal with representation learning for deep RL is to have meaningful generalization between similar states. The current work essentially tries to reduce this correlation for the sake of interim optimization benefits of the one-step update.\n* The back and forth between fixed linear features and non-linear learned features needs to be polished. The analysis is usually given for the linear case, but in the deep setting the features are replaced with gradients. Also, the relationship with target networks, as well as multi-step updates (e.g. A3C) needs to be mentioned early, as these are the main ways of dealing with or bypassing the issue the authors are describing.\n* The empirical validation is very weak -- two toy domains, and Pong, the easiest Atari game, so unfortunately there isn’t enough evidence to suggest that the approach would be impactful in practice.\n\nMinor comments:\n* there must be a max in the definition of v* somewhere\n* V_pi is usually used for the true value function, rather than the estimate\n* Sections 2.2 and 4.2 should be better bridged\n* The relationship with the discount factor just before Section 5 is interesting, but quite hand-wavy -- the second term only concerns the diagonal elements, and the schedule on gamma would be replaced by a schedule on eta.']","[-70, -80, -20]","[20, -20, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer finds the results 'unconvincing', points out multiple weaknesses in the paper, and states that the empirical results 'do not come close to being persuasive'. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the simplicity of HR-TD. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I found' and 'I recommend' rather than making blunt accusations. The reviewer also provides constructive suggestions for improvement, which is a polite approach. However, some phrases like 'These problems become even greater' and 'All of these things need to be teased apart in careful experiments' have a slightly stern tone, preventing a higher politeness score."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer explicitly states 'This paper should be rejected' and provides four major reasons for rejection. They criticize the paper's justification, experimental design, and overall quality. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite harsh and critical. They use phrases like 'The paper does not do a great job' and 'The experiments do not provide convincing evidence'. The reviewer also lists numerous specific criticisms and questions, which, while potentially helpful, are presented in a somewhat confrontational manner. The slightly negative politeness score reflects this lack of softening language and the direct, uncompromising nature of the criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas and the relevance of the problem, they express several significant concerns about the paper's motivation, analysis, and empirical validation. The reviewer states that the key motivation is 'not convincing,' the analysis 'needs to be polished,' and the empirical validation is 'very weak.' These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin by acknowledging the paper's interesting ideas and the relevance of the problem. Even when expressing concerns, the reviewer uses phrases like 'I have some concerns' and 'needs to be polished' rather than harsh or dismissive language. The reviewer also provides constructive feedback and specific suggestions for improvement, which is a polite approach to peer review.""]"
"[""The paper describes an imitation reinforcement learning approach where\nthe primitive actions of the agent are augmented with the most common\nsequences of actions perform by experts. It is experimentally shown\nhow this simple change has clear improvements in the performance of\nthe system in Atari games. In practice, the authors double the number\nof primitive actions with the most frequent double actions perform by\nexperts. \n\nA positive aspect of this paper comes from the simplicity of the\nidea. There are however several issues that should be taken into\naccount:\n- It is not clear how to determine when the distribution of action\n  pair saturates. This is relevant for the use of the proposed approach.\n- The total training time should consider both the initial time to\n  obtain the extra pairs of frequent actions plus the subsequent\n  training time used by the system. Either obtained from a learning\n  system (15 hours) or by collecting traces of human experts (< 1\n  hour?). \n- It would be interesting to see the performance of the system with\n  all the possible pairs of primitive actions and with a random subset\n  of these pairs, to show the benefits of choosing the most frequent\n  pairs used by the expert.\n- This analysis could be easily extended to triplets and so on, as\n  long as they are the most frequently used by experts.\n- The inclusion of macro-actions has been extensively studied in\n  search algorithms. In general, the utility of those macros depends on\n  the effectiveness of the heuristic function. Perhaps the authors\n  could revise some of the literature.\n- Choosing the most frequent pairs in all the game may not be a\n  suitable strategy. Some sequences of actions may be more frequent\n  (important) at certain stage of the game (e.g., at the beginning/end\n  of the game) and the most frequent sequences over all the game may\n  introduce additional noise in those cases.\n\nThe paper is well written and easy to follow, there are however, some\nsmall typos:\n- expert(whose => expert (whose\n% there are several places where there is no space between a word and\n% its following right parenthesis \n- don't need train => don't need to train\n- experiments4. => experiments.\n- Atmost => At most\n"", ""The paper proposes an idea of using the most frequent expert action sequence to assist the novice, which, as claimed, has lower memory overhead than other imitation learning methodologies. The authors present comparison of their proposed method with state-of-the-art and show its superior performance. However I do have the following few questions. \n\n1. The proposed method requires a long time of GA3C training. How is that a fair comparison in Figure 2, where proposed method already has a lead over GA3C? It could be argued that it's not using all of the training outcome, but have the authors considered other form of experts and see how that works?\n\n2. The authors claimed one of the advantages of their method is reducing the memory overhead. Some supporting experiments will be more convincing.\n\n3. In Figure 3, atlantis panel, the score shows huge variance, which is not seen in Figure 2. Are they generated from the same runs? Could the authors give some explanation on the phenomenon in Figure 3?\n\nOverall, I think the paper has an interesting idea. But the above unresolved questions raises some challenge on its credibility and reproducibility. "", '[Summary]\n\nThis paper presents an interesting idea that to append the agent\'s action space with the expert\'s most frequent action pairs, by which the agent can perform better exploration as to achieve the same performance in a shorter time. The authors show performance gain by comparing their method with two baselines - Dagger and InfoGAIL.\n\n\n[Stengths]\n\nThe proposed method is simple yet effective, and I really like the analogy to mini-moves in sports as per the motivation section.\n\n\n[Concerns]\n\n- How to choose the number and length of the action sequences?\nThe authors empirically add the same number of expert\'s action sequences as the basic ones and select the length k as 2. However, no ablation studies are performed to demonstrate the sensitivity of the selected hyperparameters. Although the authors claim that ""we limit the size of meta-actions k to 2 because large action spaces may lead to poor convergence"", a more systematic evaluation is needed. How will the performance change if we add more and longer action sequences? When will the performance reach a plateau? How does it vary between different environments?\n\n- Analysis of the selected action sequences.\nIt might be better to add more analysis of the selected action sequences. What are the most frequent action pairs? How does it differ from game to game? What if the action pairs are selected in a random fashion?\n\n- Justification of the motivation\nThe major motivation of the method is to release the burden of memory overheads. However, no quantitative evaluations are provided as to justify the claim. Considering that the input images are resized to 84x84, storing them should not be particularly expensive.\n\n- The choice of baseline.\nInfoGAIL (Li et al., 2017) is proposed to identify the latent structures in the expert\'s demonstration, hence it is not clear to me how it suits the tasks in the paper. The paper also lacks details describing how they implemented the baselines, e.g. beta in Dagger and the length of the latent vector in InfoGAIL.\n\n- The authors only show experiments in Atari games, where the action space is discrete. It would be interesting to see if the idea can generalize to continuous action space. Is it possible to cluster the expert action sequences and form some basis for the agent to select?\n\n- Typos\n{LRR, RLR/RRL} --> {LRR, RLR, RRL}\nsclability --> scalability\nwe don\'t need train a ... --> we don\'t need to train a ...\nAtmost --> At most\n\n\n[Recommendation]\n\nThe idea presents in the paper is simple yet seemingly effective. However, the paper lacks a proper evaluation of the proposed method, and I don\'t think this paper is ready with the current set of experiments. I will decide my final rating based on the authors\' response to the above concerns.']","[20, -20, -20]","[60, 60, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the simplicity of the idea as a positive aspect and the paper is described as well-written and easy to follow. However, the reviewer also lists several issues and suggestions for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as 'interesting' or 'should be taken into account' rather than using demanding language. The reviewer also acknowledges both positive and negative aspects of the paper, which contributes to a polite tone. The mention of typos is done in a matter-of-fact way without harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper has 'an interesting idea', they raise several questions and concerns about the methodology and results, stating these 'raise some challenge on its credibility and reproducibility'. This indicates a somewhat critical stance, though not entirely negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their concerns as questions rather than direct criticisms. They also begin with a neutral summary and end by acknowledging the paper's interesting idea, which softens the overall tone. The use of phrases like 'Could the authors give some explanation' and 'have the authors considered' maintains a polite and constructive tone while raising concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents an 'interesting idea' and has some strengths, they express several concerns and state that the paper 'lacks a proper evaluation' and 'is not ready with the current set of experiments'. The overall tone suggests the reviewer is not fully satisfied with the paper in its current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms constructively (e.g., 'It might be better to...', 'I will decide my final rating based on the authors' response...'). The reviewer maintains a professional tone, avoiding harsh or rude language even when pointing out weaknesses.""]"
"['This paper proposes an approach for mitigating issues associated with high-frequency/amplitude control signals that may be obtained when one applies reinforcement learning algorithms to continuous control tasks. The approach taken by the paper is to solve a constrained optimization problem, where the constraint imposes a (potentially state-dependent) lower bound on the reward. This is done by using a Lagrangian relaxation that learns the parameters of a control policy that satisfies the desired constraints (and also learns the Lagrange multipliers). The presented approach is demonstrated on a cart-pole swing-up task as well as a quadruped locomotion task.\n\nStrengths:\n+ The paper is generally clear and readable.\n+ The simulation results for the Minitaur quadruped robot are performed using a realistic model of the robot.\n\nMajor concern:\n- My biggest concern is that the technical contributions of the paper are not clear at all. The motivation for the work (avoiding high amplitude/frequency control inputs) is certainly now new; this has always been a concern of control theorists and roboticists (e.g., when considering minimum-time optimal control problems, or control schemes such as sliding mode control). The idea of using a constrained formulation is not novel either (constrained MDPs have been thoroughly studied since Altman (1999)). The technical approach of using a Lagrangian relaxation is the standard way one goes about handling constrained optimization problems, and thus I do not see any novelty there either. Overall, the paper does not make a compelling case for the novelty of the problem or approach.\n\nOther concerns:\n- For the cart-pole task, the paper states that the reward is modified ""to exclude any cost objective"". Results are then presented for this modified reward showing that it results in high-frequency control signals (and that the proposed constrained approach avoids this). I don\'t think this is really a fair comparison; I would have liked to have seen results for the unmodified reward function.\n- The claim made in the first line of the abstract (applying RL algorithms to continuous control problems often leads to bang-bang control) is very broad and should be watered down. This is the case only when one considers a poorly-designed cost function that doesn\'t take into account realistic factors such as actuator limits.\n- In the last paragraph of Section 3.3, the paper proposes making the lower-bound on the reward state-dependent. However, this can be tricky in practice since it requires having an estimate for Q_r(s,a) as a function of the state (in order to ensure that the state-dependent lower bound can indeed be satisfied). \n\nTypos:\n- Pg. 5, Section 3.4: ""...this is would achieve...""\n- Pg. 6: ...thedse value of 90...""', 'This paper uses constrained Markov decision processes to solve a multi-objective problem that aims to find the correct trade-off between cost and return in continuous control. The main technique is Lagrangian relaxation and experiments are focus on cart-pole and locomotion task.\n\nComments:\n\n1) How to solve the constrained problem (8) is unclear. It is prefer to provide detailed description or pseudocode for this step.\n\n2) In equation (8), lambda is a trade-off between cost and return. Optimization on lambda reduces burdensome hyperparameter selection, but a new hyperparameter beta is introduced. How do we choose a proper beta, and will the algorithm be sensitive to beta?\n\n3) The paper only conducts comparison experiments with fixed-alpha baselines. The topic is similar to safe reinforcement learning. Including the comparison with safe reinforcement learning algorithms is more convincing.\n', 'This paper proposes a model free reinforcement learning algorithm with constraint on reward, with demonstration on cartpole and quadruped locomotion. \n\nstrength: (1) challenging examples like the quadruped.\n                (2) result seems to indicate the method is effective\n\nThere are several things I would like the authors to clarify:\n(1) In section 3.2, why is solving (4) would give a ""exactly the desired trade-off between reward and cost""? First of all, how is the desired trade-off defined? And how is (4) solved exactly? If it is solved iteratively, i.e, alternating between the inner min and outer max, then during the inner loop, wouldn\'t the optimal value for \\lambda be infinity when constrained is violated (which will be the case at the beginning)? And when the constrained is satisfied, wouldn\'t \\lambda = 0? How do you make sure the constrained will still be satisfied during the outer loop since it will not incurred penalty(\\lambda=0). Even if you have a lower bound on \\lambda, this is introducing additional hyperparameter, while the purpose of the paper is to eliminate hyperparamter?\n(2) In section 3.2, equation 6. This is clearly not a convex combination of Qr-Vr and Qc, since convex combination requires nonnegative coefficients. The subtitle is scale invariance, and I cannot find what is the invariance here (in fact, the word invariance\\invariant only appears once in the paper). By changing the parametrization, you are no longer solving the original problem (equation 4), since in equation (4), the only thing that is related to \\lambda is (Qr-Vr), and in (6), you introduce \\lambda to Qc as well. How is this change justified?\n(3)If I am not mistaken, the constrained can still be violated with your method. While from the result it seems your method outperforms manually selecting weights to do trade off,  I don\'t get an insight on why this automatic way to do tradeoff is better. And this goes back to ""exactly the desired trade-off between reward and cost"" in point(1), how is this defined?\n(3) The comparison in the cartpole experiment doesn\'t seem fair at all, since the baseline controller is not optimized for energy, there is no reason why it would be comparable to one that is optimized for energy. And why would a controller "" switch between maximum and minimum actuation is indeed the optimal solution"" after swingup? Maybe it is ""a"" optimal solution, but wouldn\'t a controller that does nothing is more optimal(assuming there is no disturbance)?\n(4)For Table I, the error column is misleading. If I understand correctly, exceeding the lower bound is not an error (If I am wrong, please clarify it in the paper). And it is interesting that for target=0.3, the energy consumption is actually the lowest.\n(5)Another simple way to impose constrained would be to terminate the episode and give large penalty, it will be interesting to see such comparison.\n\nminor points: \n* is usually used for optimal value, but is used in the paper as a bound.']","[-50, 20, -20]","[60, 50, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some strengths ('generally clear and readable', 'realistic model'), they express a 'major concern' about the lack of clear technical contributions. They state that the approach is not novel and that the paper 'does not make a compelling case for the novelty of the problem or approach'. This significant criticism, along with other concerns raised, indicates a generally negative sentiment, though not extremely so. The politeness score is 60 because the reviewer uses professional and respectful language throughout. They begin by noting strengths, use phrases like 'I would have liked to have seen' instead of more demanding language, and offer constructive feedback. The tone is critical but not harsh or rude, maintaining a polite and professional demeanor while expressing concerns."", ""The sentiment score is slightly positive (20) because the review acknowledges the paper's contribution and methodology without major criticisms. The first paragraph provides a neutral summary, and the subsequent comments are constructive suggestions rather than harsh criticisms. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They phrase their comments as suggestions or questions (e.g., 'It is prefer to provide...', 'How do we choose...') rather than direct criticisms. The reviewer also acknowledges the paper's merits while offering areas for improvement, maintaining a balanced and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they raise several significant concerns and questions about the methodology and results. The review begins positively but quickly moves into a detailed critique, indicating more skepticism than approval. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing their criticisms as questions or requests for clarification rather than direct criticisms. They use phrases like 'I would like the authors to clarify' and 'please clarify it in the paper', which maintain a polite tone. The reviewer also acknowledges the paper's strengths before diving into the critique, which is a courteous approach. However, the score is not higher because the review is quite direct in pointing out perceived flaws and doesn't use many explicitly polite phrases.""]"
"['This paper presents a joint optimization approach for the continuous weights and categorical structures of neural networks. The idea is the standard stochastic relaxation of introducing a parametrised distribution over the categorical parameters and marginalising it. The method then follows by alternating gradient descent on the weights and the parameters of the categorical distribution.\n\nThis exact approach was proposed in https://arxiv.org/abs/1801.07650 by Shirakawa et al. The only innovation in this work is that it uses categorical distributions with more than two values. This is a minor innovation.\n\nThe experiments are however interesting as the paper compares to the latest hyper-parameters optimization strategies for neural nets on simple tasks (eg CIFAR10) and gets comparable results. However, given that this is the biggest contribution of the paper, it would have been nice to see results in more complex tasks, eg imagenet or translation.\n\nI very much enjoyed the simplicity of the approach, but the question of innovation is making wonder whether this paper makes the ICLR bar of acceptance. The paper is also hard to read because of many English typos.   ', ""This paper proposes an architecture search technique in which the hyperparameters are modeled as categorical distribution and learned jointly with the NN. The paper is written well. I am not an expert of the literature in this domain so will not be able to judge the paper regarding where it is located in the related work field.\n\nPros:\n-This is a very important line of research direction that aims to make DNNs practical, easy to deploy and cost-effective for production pipelines.  \n-The categorical distribution for hyperparameters makes sense, and the derivation of the joint training seems original idea. I liked the fact that you need to train the NN just twice (the second one only to fine tune with optimized parameters)   \n-Two very different problems (inpainting/encoding-decoding + CNN/classification) have been demonstrated.\n-Existing experiments have been explained with enough detail except for minor points.\n\nCons:\n-I speculate that there is a trade-off between the number of different parameters and whether one training is good enough to learn the architecture distribution. i.e., When you have huge networks and many parameters, how well this method works? I think the authors could provide some experimental study suggesting their users what a good use case of this algorithm is compared to other techniques in the literature. In what type of network and complexity this search method works better than others?\n-E-CAE for in-painting seems to be working significantly better than the proposed technique. Regarding results, I was expecting more insights into why this is the case. As above, at what type of a problem one should pick which algorithm? If the 7hours vs. 3days GPU difference negligible for a client, should one pick E-CAE?  \n-In theory, there has been shown lambda samples (equation 2 and 3). However, the algorithm seems to be using just 2? If I didn't miss, this is not discussed thoroughly. I speculate that this parameter is essential as the categorical distribution gets a bigger search space. Also the reliability of the model and final performance, how does it change concerning this parameter?"", 'The authors propose to formulate the neural network architecture as a collection of multivariate categorical distributions. They further derive sample-based gradient estimators for both the stochastic architecture and the deterministic parameters, which leads to a simple alternating algorithm for architecture search.\n\nPros:\n+ Intuitions and formulations are easy to comprehend.\n+ Simpler to implement than most prior methods.\n+ Appealing results (on CIFAR-10) as compared to the state-of-the-art.\n\nCons:\n- Limited technical novelty. The approach is a straightforward extension of Shirakawa et al. 2018. The main algorithm is essentially the same except minor differences in gradient derivations.\n- Lack of theoretical justifications. It seems all the derivations at the beginning of Section 2 assume the architecture is optimized wrt the training set. However, the authors ended up splitting the dataset into two parts in the experiments and optimize the architecture wrt a separate validation set instead. This would invalidate all the previous derivations.\n- The method is a degenerated version of ENAS. A closer look at eq (2) and (3) suggests the resulting iterative algorithm is almost the same as that in ENAS, where the weights are optimized using GD wrt the training set and the architecture is optimized using the log-derivative trick wrt the validation set. The only distinction are (i) using a degenerated controller/policy formulated as categorical distributions (ii) using the validation loss instead of the validation accuracy as the reward (according to eq. (3)). This is also empirically reflected in Table 1, which shows the proposed PDAS is similar to ENAS both in terms of efficiency and performance. The mathematical resemblance with ENAS is not necessarily bad, but the authors need to make it more explicit in the paper. \n\nMinor issues:\n* I\'m not sure whether it\'s a good practice to report the ""best"" test error among multiple runs in Table 1.\n* The method is not really ""parameterless"" as claimed in the introduction. For example, a suitable learning rate adaptation rule can be task-specific thus requires manual tuning/design. The method also consists of some additional hyperparameters like the \\lambda in the utility transform.']","[-20, 50, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting experiments', 'enjoyed the simplicity'), they also point out significant issues. The main concern is the lack of innovation, stating that the approach was already proposed in a previous paper. The reviewer questions whether the paper meets the acceptance criteria for ICLR. Additionally, they mention the paper is hard to read due to English typos. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout. They acknowledge the paper's strengths and express their enjoyment of certain aspects. Even when criticizing, the tone remains professional and constructive, avoiding harsh or rude language. The use of phrases like 'I very much enjoyed' and 'it would have been nice to see' contribute to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the paper is well-written and highlights several pros, including the importance of the research direction and the originality of the idea. However, they also list some cons and areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert'), and frames criticisms constructively as suggestions for improvement rather than harsh critiques. The reviewer also uses phrases like 'I liked the fact that' and 'I speculate,' which maintain a collegial tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper (intuitive formulations, simple implementation, appealing results), they also point out significant cons that outweigh the positives. These include limited technical novelty, lack of theoretical justifications, and the method being a degenerated version of an existing approach. The reviewer also raises concerns about the reporting of results and the claim of the method being 'parameterless'. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout. They present both pros and cons in a balanced manner, use neutral language when pointing out issues (e.g., 'Limited technical novelty' instead of more harsh phrasing), and offer constructive feedback. The reviewer also uses phrases like 'I'm not sure' when expressing uncertainty, which adds to the polite tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a primarily neutral, professional tone.""]"
"['This paper considers parameterizing Dirichlet, Dirichlet-multinomial, and Beta distributions with the outputs of a neural network. They present the distributions and gradients, discuss appropriate activation functions for the output layer, and evaluate this approach on synthetic and real datasets with mixed results. Overall, I found the writing very clear, the main idea sound, and paper generally well executed, but I have serious concerns about the significance of the contributions that lead me to recommend rejection. It would be very useful to me if the authors would provide a concise list of what they consider the main contributions to be and why they are significant. As I see it, the paper does three main things:\n\n1. In section 2, the authors consider parameterizing Dirichlet, Dirichlet-multinomial, and Beta distributions with the outputs of a neural network (Section 2). As the authors note, parameterizing an exponential family distribution with the outputs of a neural network is not a novel contribution (e.g. Rudolph et al. (2016) and David Belanger\'s PhD thesis (2017)) and though I have never personally seen the Dirichlet, Dirichlet-multinomial, and Beta distributions used, the conceptual leap required is small. Most of section 2 is dedicated to writing down, simplifying, and deriving gradient equations for these three distributions. The simplifications and gradient derivations are well known and appear in many places (e.g. http://jonathan-huang.org/research/dirichlet/dirichlet.pdf, https://arxiv.org/pdf/1405.0099.pdf) and should not be considered contributions in the age of automatic differentiation (see Justin Domke\'s blog post on autodiff).\n\n2. In section 3, the authors consider the unique challenges of using the proposed networks. They propose targeted activation functions that will improve the stability of learning. I found this to be the most interesting portion of the paper and the most significant contribution. Unfortunately, it is short on details and empirical results are referenced that do not appear in the paper (i.e. the second to last paragraph on page 5). If I were to rewrite this paper, I would focus on answering the question ""What are the unique challenges of parameterizing Dirichlet, Dirichlet-multinomial, and Beta distributions with the outputs of a neural network and how can we address them?"", replacing section 2 with an expanded section 3.\n\n3. In section 4, the authors evaluate the proposed networks on a collection of synthetic and real tasks. In the end, the results are mixed, with the Dirichlet network performing best on the XENON1T task and the standard softmax network performing best on the CIFAR-100 task. In general, I don\'t mind mixed results and I appreciate that the authors included both sets of experiments; however, it is important that there is a convincing argument for why one would prefer the proposed solution even when accuracy is the same (e.g. it is faster, it is interpretable, etc.). The authors briefly argue that the proposed methods are superior because they provide uncertainty estimates for the output distributions. This may be true, but they only perform evaluations on tasks where the primary goal is accuracy. If the main benefit of the proposed networks is proper uncertainty quantification, then the evaluations (even if they are qualitative) should reflect that.\n\nIn summary, I do not think the models proposed in section 2 are sufficiently novel to justify publication alone which means that the authors need to either: (1) evaluate novel methods that are critical for use of these models or (2) present a convincing evaluation that strongly motivates the proposed model\'s use or that provides some novel insight into the model\'s behavior. I think that the authors are on their way to achieving (1), but do not achieve (2). I would suggest finding an application that requires uncertainty estimates for the distribution and centering the paper around that application.\n\nMinor comments:\n\n- Figure 2 (right) should include a y-axis label (e.g. ""parameter value"").\n\n- In Figure 3 (right), it is not obvious what the ""Sigmoid"" line corresponds to. \n\n- It is not clear what the authors are trying to show in section 4.1. The EL activation function is smooth and monotone and the likelihood is convex, so there should be no question that the distribution will concentrate around y.\n\n- Section 4.4 was interesting, but would have been more convincing if paired with an evaluation on real data.', 'The paper shows how to model the outputs of neural networks via likelihoods other than commonly used ones. The likelihoods discussed include Beta, Dirichlet and Dirichlet-Multinomial. The paper introduces the gradient computation of these likelihoods and test them in several datasets. \n\nThis paper lacks novelty and has conceptual mistakes. It is a common practice, in Bayesian learning, to model different types of data with different likelihoods. The examples discussed in this paper are very basis and the gradient computation is standard. I do not see anything new. And the authors misunderstand that if you involve some likelihood in training, you can quantify the uncertainty. It is wrong. Uncertainty should be estimated in the posterior inference framework --- you need to integrate the posterior distribution of the (latent) random variables into the test likelihood to obtain the predictive distribution, from which you can identify the confidence levels. That’s why auto-encoding variational Bayes framework is useful and popular.  \nWhat the paper is doing is still the point estimation. \n\nBesides, the paper exceeds the 8-page limit for the content. \n', ""The authors use neural networks to parameterize conditional probability distributions. This is well-known and has been applied in the literature since extensions to generalized linear models beyond their canonical link function in the 70s. Their transformation from real-valued network output to, say, strictly positive concentration parameters in a Dirichlet are worth studying; but they don't analyze this in any detail.\n\nIn addition, while lacking novelty may be fine in and of itself, the purpose of applying these ideas doesn't have a focused purpose. For example, the authors argue in the abstract this quantifies uncertainty. That's only true if you care about data noise, but the end-result is still point estimation for the parameters with uncalibrated probabilities. In the rest of the paper, they write primarily about simplex-valued outputs (i.e., soft one-hot labels).""]","[-50, -70, -60]","[50, -20, -20]","[""The sentiment score is -50 because while the reviewer found some positive aspects ('writing very clear', 'main idea sound', 'paper generally well executed'), they ultimately recommend rejection due to 'serious concerns about the significance of the contributions'. This indicates an overall negative sentiment, though not extremely harsh. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and provides constructive feedback. They use phrases like 'It would be very useful to me if...' and 'I appreciate that the authors included...', which are polite ways of offering criticism. However, the review is not overly deferential, maintaining a professional tone, hence the moderate positive score rather than a very high one."", ""The sentiment score is -70 because the reviewer expresses strong negative opinions about the paper, stating it 'lacks novelty and has conceptual mistakes.' They dismiss the work as 'very basic' and assert that they 'do not see anything new.' The reviewer also points out what they perceive as fundamental misunderstandings by the authors. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, their tone is quite dismissive and blunt. They directly state the paper's shortcomings without softening their criticism or offering much constructive feedback. The phrase 'It is wrong' is particularly direct and could be seen as impolite in academic discourse. However, the review isn't completely impolite, as it does begin with a neutral summary of the paper's content."", ""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's novelty and purpose. They state that the methods used are 'well-known' and have been applied since the 1970s, implying a lack of originality. The reviewer also points out that the paper lacks a focused purpose and questions the authors' claims about quantifying uncertainty. These criticisms suggest a generally negative sentiment towards the paper.\n\nThe politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the criticism or acknowledge positive aspects of the work. Phrases like 'lacking novelty' and 'uncalibrated probabilities' are used without any mitigating language, which can come across as somewhat impolite in academic discourse. However, the reviewer does maintain a professional tone overall, which is why the score is not lower.""]"
"['This paper presents Partially Mutual Exclusive Softmax (PMES), a relaxation of the full softmax that is commonly used for multi-class data. PMES is designed for positive-unlabeled learning, e.g., language modeling, recommender systems (implicit feedback), where we only get to observe positive examples. The basic idea behind PMES is that rather than considering all the non-positive examples as negative in a regular full softmax, it instead only considers a ""relevant"" subset of negatives. Since we actually don\'t know which of the negatives are more relevant, the authors propose to incorporate a discriminator which attempts to rate each negative by how hard it is to distinguish it from positives, and weight them by the predicted score from the discriminator when computing the normalizing constant for the multinomial probability. The motivation is that the negatives with higher weights are the ones that are closer to the decision boundary, hence will provide more informative gradient comparing to the negatives that are further away from the decision boundary. On both real-world and synthetic data, the authors demonstrate the PMES improves over some other negative sampling strategies used in the literature. \n\nOverall the idea of PMES is interesting and the solution makes intuitive sense. However, the writing of the paper at the current stage is rather subpar, to the extend that makes me decide to vote for rejection. In details:\n \n1. The motivation of PMES from the perspective of mutual exclusivity is quite confusing. First of all, it is not clear to me what exactly the authors mean by claiming categorical distribution assumes mutual exclusivity -- does it mean given a context word, only one word can be generated from it? Some further explanation will definitely help. Further more, no matter what mutual exclusive means in this context, I can hardly see that PSME being fundamentally different given it\'s still a categorical distribution (albeit over a subset).\n\nThe way I see PMES from a positive-unlabeled perspective seems much more straight-forward -- in PU learning, how to interpret negatives is the most crucial part. Naively doing full softmax or uniform negative sampling carry the assumption that all the negatives are equal, which is clearly not the right assumption for language modeling and recommender systems. Hence we want to weight negatives differently (see Liang et al., Modeling user exposure in recommendation, 2016 for a similar treatment for RecSys setting). From an optimization perspective, it is observed that for negative sampling, the gradient can easily saturate if the negative examples are not ""hard"" enough. Hence it is important to sample negatives more selectively -- which is equivalent to weighting them differently based on their relevance. A similar approach has also been explored in RecSys setting (Rendle, Improving pairwise learning for item recommendation from implicit feedback, 2014). Both of these perspectives seem to offer more clear motivation than the mutual exclusivity argument currently presented in the paper.\n\nThat being said, I like the idea of incorporating a discriminator, which is something not explored in the previous work.  \n\n2. The rigor in the writing can be improved. In details:\n\n* Section 3.3, ""Multivariate Bernoulli"" -> what is presented here is clearly not multivariate Bernoulli\n\n* Section 3.3, the conditional independence argument in ""Intuition"" section seems no difference from what word2vec (or similar models) assumes. The entire ""Intuition"" section is quite hand-wavy.\n\n* Section 3.3, Equation 4, 5, it seems that i and j are referred both as binary Bernoulli random variables and categorical random variables. The notation here about i and j can be made more clear. Overall, there are ambiguously defined notations throughout the paper. \n\n* Section 4, the details about the baselines are quite lacking. It is worth including a short description for each one of them. For example, is PopS based on popularity or some attenuated version of it? As demonstrated from word2vec, a attenuated version of the unigram (raised to certain power < 1) works better than both uniform random, as well as plain unigram. Hence, it is important to make the description clear. In addition, the details about matrix factorization experiments are also rather lacking. \n\n3. On a related note, the connection to GAN seems forced. As mentioned in the paper, the discriminator here is more on the ""cooperative"" rather than the ""adversarial"" side. \n\nMinor:\n\n1. There are some minor grammatical errors throughout. \n\n2. Below equation 3, ""\\sigma is the sigmoid function"" seems out of the context.\n\n3. Matt Mohaney -> Matt Mahoney ', ""This paper proposed PMES to relax the exclusive outcome assumption in softmax loss. The proposed methods is motivated from PU settings. The paper demonstrate its empirical metrit in improving word2vec type of embedding models. \n\n- on experiment: \n-- word2vec the window size = 1 but typically a longer window is used for NS. this might not reflect the correct baseline performance. is the window defined after removing rare words? what's the number of NS used? how stop words are taken care of? \n-- would be good to elaborate how CIS in word similarity task were better than full softmax. Not sure what;s the difference between the standard Negative sample objective. Can you provide some quantitative measure?  \n-- what is the evaluation dataset for the analogy task? \n\n-- MF task: the results/metrics suggests this is a implicit [not explicit (rating based)] task but not clearly defined. Better to provide - embedding dimensions, datasets positive/negative definition and overall statistics (# users, movies, sparsity, etc), how the precision@K are calculated, how to get a positive label from rating based dataset (movielens and netflix), how this compares to the plain PU/implicit-matrix factorization baseline. How train/test are created in this task?\n\n\n- on problem formulation:\nin general, it is difficult to parse the technical contribution clearly from the current paper. \n-- in 3.3., the prob. distribution is not the standard def of multi-variate bernoulli distribution.\n-- (6) first defined the support set but not clear the exact definition. what is the underlying distribution and what is the support for a sington means?\n-- it is better to contrast against the ns approximation in word2vec paper and clarify the difference in term of the mathematical terms. \n"", 'The mutually exclusive assumption of traditional softmax can be biased in case negative samples are not explicitly defined. This paper presents Cooperative Importance Sampling towards resolving this problem. The authors experimentally verify the effectiveness of the proposed approach using different tasks including applying matrix factorization in recommender system, language modeling tasks and a task on synthetic data.\n\nI like this interesting idea, and I agree with the authors that softmax does exist certain problem especially when negative samples are not well defined. I appreciate the motivation of this work from the PU learning setting. It would be interested to show more results in PU learning setting using some synthetic data. I am interested to see the benefit of this extension of softmax with respect to different amount of labeled positive samples.\n\nHowever, I am not completely convinced that the proposed method would be a necessary choice for language modeling tasks.\n--To me, the proposed method has close connection to 2-gram language model. \n--But for language tasks, and other sequential input, we typically make prediction based on representation of very large context. Let’s say, we would like to make prediction for time step t given the context of word_{1:t} based on some recurrent model, do you think the proposed softmax can generally bring sizable improvement with respect to traditional choices. And how?\n\nBy the way, I think the proposed method would also be applicable in the soft-label setting.\n\nFor the experiments part, maybe put more details and discussions to the supplementary material.\nA few concrete questions.\n-- In some tables and settings, you only look at prec@1, why? I expect the proposed approach would work better in prec@K.\n-- Can you provide more concrete analysis fortable 6? Why proposed methods does not work well for syntactic. \n-- Describe a little bit details about MF techniques and hyper-parameters you used. \n\n\n']","[-60, -20, 50]","[20, 50, 80]","[""The sentiment score is -60 because the reviewer explicitly states they are voting for rejection due to subpar writing, which indicates a strongly negative sentiment. However, they do mention some positive aspects like the idea being interesting, which prevents the score from being even lower. The politeness score is 20 because the reviewer uses generally polite and professional language, offering constructive criticism and suggestions for improvement. They avoid harsh or rude phrasing, instead using phrases like 'can be improved' and 'it is worth including'. However, the directness of some criticisms (e.g., 'subpar', 'rather lacking') prevents the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal and empirical merit, they raise several concerns and questions about the methodology, experiments, and problem formulation. The review is not entirely negative, but it does highlight multiple areas that need improvement or clarification. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases their criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'would be good to elaborate' and 'better to provide' which maintain a constructive tone. The reviewer also acknowledges the paper's contributions at the beginning, which adds to the politeness. However, the review doesn't use overtly polite language or praise, keeping it from scoring higher on the politeness scale."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses appreciation for the idea and its motivation, stating 'I like this interesting idea' and 'I appreciate the motivation of this work'. However, they also express some doubts and questions, which prevent the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' work positively, and frames criticisms as questions or suggestions rather than direct criticisms. Phrases like 'I am interested to see' and 'maybe put more details' contribute to the polite tone. The reviewer also provides specific, constructive feedback, which is a polite way to help improve the paper.""]"
"['This paper proposes a new variational recurrent model for learning sequences. Comparing to existing work, instead of having latent variables that are dependent on the neighbors, this paper proposes to use independent latent variables with observations that are generated from multiple latent variables. \nThe paper further combined the proposed method with multiple existing ideas, such as the shared/prviate representation from VAE-CCAE, adding the hierarchical structure, and prior updating. \n\nPros:\nThe proposed method seems technical correct and reasonable. \nThere are many extensions which are potentially useful for many applications \nThere are many experimental results showing promising performance. \n\nCons:\nThe framework is very incremental. It is novel but limited. \nThe paper claim that the main point to use the simpler variations distribution is to speed up the inference. But no speed comparisons are shown in the experiments section. \nThe evaluation shows that prior updating (one extension) seems contributes to the biggest performance gain, not the main proposed method. \n\n', '(best read in typora)\n\nThe authors claim to propose a family of methods and generative models that are suited better for downstream tasks than previously proposed approaches.\n\n## Major points\n\nIt feels as if the proposed method tries to be many things. First, it is used for finding unsupervised representations down stream. Then, it still tries to be a generative model ""of sorts"", which is the reason for the use of variational inference in the first place. Additionally, the approximate posterior necessary to evaluate the ELBO is simultaneously used as a feature extractor.\n\nThe resulting issues are:\n\n  - A ""bad"" variational posterior is used because it is unclear how to get vectorial features otherwise. \n  - An adhoc likelihood function is used, which is not sufficiently well explored theoretically in the paper.  Specifically,\n      - Stochastic generation is claimed to be ""more complex than simple Gaussian""; the burden of proof is on the authors, as Gaussian density is closed under multiplication. \n      - It appears to be a Monte Carlo approximation to sth that is computable in closed form.\n      - It is not clear if that MC approximation is normalised and if the normalisation is the same at each optimisation step. Does this bias optimisation? What happens to the KL penalty weight?\n  - The ELBO change (prior updating) seems to make the claim that we still have a generative model (as written in the intro) invalid. My intuition is that the KL penalty vanishes for small step rates of the optimiser, reducing the model to that of a noisy auto encoder.\n\n\n## Summary\n\nThe authors want to evaluate variational sequence models for feature extraction for downstream tasks. But why? What is the use of a generative inspired algorithm, when necessary ingredients are discarded? Both goals appear to be at conflict and I am not convinced that the variational ingredient is necessary.\n\nI do not cover the experimental section since the method itself has issues so severe that I don\'t consider it relevant. \n\n\n## Minor points\n\n- Notation $\\mu_{\\phi_t}$ gives the impression that $\\phi$ is time dependent.\n- Equations (9) and (11) are formatted badly.\n- The approximate posterior used was used first in (Bayer & Osendorfer, ""Learning stochastic recurrent networks"", 2014) not (Chen 2018).\n- Diagrams follow GM notation only half-heartedly.\n', 'This is largely an experimental paper, proposing and evaluating various modifications of variational recurrent models towards obtaining sequence data representations that are effective in downstream tasks. The highlighted contribution is a ""stochastic generation"" training procedure in which the training objective evaluates the reconstruction of output sequence elements from individual latent variables independently. The main claim is that the resulting model, augmented with prior updating and/or hierarchical latent variables, improves results w.r.t. the baselines.\n\nMy main concern is that the various choices are not motivated well, e.g. with examples or detailed descriptions of the issues addressed and that the resulting implications are not discussed in detail (see detailed comments below). This could perhaps be alleviated during the rebuttal discussion.\n\nEmpirically, when used in conjunction with prior updating and/or hierarchical latent variables, the proposed ""stochastic generation"" approach improves upon the baselines, but not when used in isolation. This is OK, but it weakens the contribution since it\'s more unclear what the exact advantage ""stochastic generation"" is, how it takes advantage of prior updating, and so on. Could you maybe discuss this in the rebuttal? The fact that not all model variants considered are evaluated on all settings also contributes to this problem (again, see below).\n\nGeneral questions:\n- ""dependence of observations at each time step on all latent variables"": Unfortunately, this means that the complexity of evaluating the model during training is O(n^2), where n is the sequence size, rather than linear in the standard case. Is that correct? I think this is what is alluded to on the top on page 4. Could you discuss this trade-off?\n- regarding section 2.1.: Multi-modal marginal probabilities are also used due their increased modeling power, and this again seems like a potential limitation of the proposed approach w.r.t. the baseline, and is not discussed.\n- ""the mean of z_t may have very small probability and thus may not be a good choice"": I think this statement requires more context. The mean of z_t can have low probability in both cases (e.g. if the posterior has a high variance). Are you suggesting that the low probability issue is exacerbated by to the sampling of previous z_{t-1}? Or are you comparing to the case where the mean z_{t-1} is used instead of sampling as well?\n\nStochastic generation:\n- While I understand where it\'s coming from, the term ""stochastic generation"" is somewhat misleading, since stochasticity is already present in the generation process for VAEs;\n- Stochastic generation is introduced as a way to approximate the generation process. However, when it\'s introduced, it\'s not clear what the generation process that needs to be approximated is. Introducing the model in eq. (6-7), motivating its use and then showing how it is obtained through stochastic generation second would improve the clarity of the paper.\n- Related to the point above, the implications of using the model in eq. (6-7) are not discussed. The graphical model in Figure 1 suggests that x_k depends jointly on all the (z_t)_{t=1 ... sequence_size}. Instead, in eq. (6-7), each x_k is generated independently from each z_t (for t = 1 ... T, and k sampled from a distribution which depends on t). In particular, if I understand this correctly, the distribution p(x_k | z) = p(x_k | z_1 \\dots z_T) factorizes as p(x_k | z_1) p(x_k | z_2) ... p(x_k | z_T). Could you motivate this choice and its expected effect? It seems to me that this encourages each z_t to capture all the information needed to reconstruct each x_k in the corresponding window.\n\nExperimental results:\n- Table 2: I think this table since it includes most models, but it still misses RecRep (without delta = 0) and StocCon. Could you confirm whether StocCon vs. RecRep have the same setting except the use of recurrent stochastic connections in StocCon vs. using eq. (4) in RecRep with window size 1?\n- In Table 4, the difference between line 5 and line 6 is interesting and I wish it was discussed more, maybe used in the visualization experiment to show how/why ""stochastic generation"" with a larger window improves performance.\n- Figure 3, could it be that the use of hierarchical latent variables (H) accounts for the visual difference? Is a difference still observed when comparing lines 3 and 7 in Table 4, whose settings seem more comparable?\n- \n\nMinor issues:\n- the lack of parenthesis around citations makes the text hard to follow at times (maybe use \\citep whenever the citation mixes with the text?);\n- typo: ""for use in a downstream tasks""\n- typo: ""with graphical model as described"" => ""with the/a graphical model as described""\n']","[20, -70, -20]","[50, -20, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as technical correctness, potential usefulness, and promising experimental results. However, the cons mentioned, including the incremental nature of the work and lack of speed comparisons, prevent a higher positive score. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, presenting both pros and cons objectively without using harsh language. The reviewer's critique is constructive and balanced, avoiding overly negative or confrontational statements."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses significant concerns about the proposed method, pointing out several issues and stating that the method has 'issues so severe that I don't consider it relevant.' The tone is critical throughout, with phrases like 'It feels as if the proposed method tries to be many things' and 'Both goals appear to be at conflict.' The politeness score is -20 because while the reviewer maintains a professional tone, the language is quite direct and at times dismissive. Phrases like 'why?' and 'But why?' come across as somewhat impatient or confrontational. The reviewer also uses phrases like 'I am not convinced' and 'I don't consider it relevant,' which, while not overtly rude, are not particularly polite either. The review lacks softening language or positive reinforcement that would be expected in a more polite critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express several concerns and criticisms. The review begins with a neutral summary but then highlights 'main concerns' about motivation and implications not being well-discussed. The reviewer also points out weaknesses in the empirical results and asks for clarification on multiple points. However, the tone is not entirely negative, as the reviewer suggests ways to improve and invites further discussion in the rebuttal.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They frame criticisms as questions or suggestions rather than direct attacks. Phrases like 'Could you maybe discuss this in the rebuttal?' and 'Could you motivate this choice and its expected effect?' show a collaborative approach. The reviewer also acknowledges positive aspects and uses polite language like 'This is OK, but...' when introducing criticisms. The overall tone is professional and aimed at improving the paper rather than dismissing it.""]"
"['I like the idea of trying to qualitatively illustrate the behavior of SGD when optimizing parameters of complex models, such as Deep and Conv Nets, but I think that the contribution is not very substantial. The connection between SGD and diffusion has been pointed out in previous papers, as acknowledged by the Authors. The study of the effect of batch size is interesting, but again somewhat derived from previous works. \n\nIt would helpful to illustrate the difference between ""crossing"" and ""moving over"" a barrier with a simple figure. \n\nThe experimental validation is interesting, although I think it is limited and perhaps the conclusions that can be drawn from it are not so surprising. I believe it would have been interesting to study other important factors that affect the behavior of SGD, such as learning rate and type of momentum. For example, a larger learning rate might allow for more crossing of barriers. Also, different SGD algorithms (ADAGRAD, ADAM, etc...) would behave considerably differently I expect. At the moment these important factors are overlooked. \n\nIt is not clear to me why we would want to avoid larger batch sizes. A larger batch size allows for a lower variance of stochastic gradients, and therefore faster convergence. I think this point requires elaboration, because this forms the motivation behind theoretically grounded and successful SGD works, such as SAGA and the like. I agree that a smaller batch-size is preferable at the beginning of the optimization, but again this is a well known fact (again, see SAGA) and it is for computational reasons mostly (being far away from the (local) mode, a noisy gradient is enough to move in the right direction - no need to spend computations to use an accurate gradient). There is no guarantee that the local optimum close to initialization is a bad local optimum in general, so I don\'t think that using a large batch size at the beginning is a bad idea for this reason - again it is just computational. \n\nAnother thing missing I think is the discussion around why it is potentially a good thing to cross the barrier, either at the beginning of the exploration or towards convergence to a local optimum. At the moment, the paper seems to report the behavior of SGD without key insights on the importance of crossing or avoiding crossing barriers.\n\nAs a concluding remark - there has been a lot of work on the connections between diffusions and MCMC algorithms (see e.g., the Metropolis Adjusted Langevin Algorithm - MALA) and a lot of the considerations made in the paper are somewhat known. That is, random walk/diffusion type MCMC (and even gradient-based MCMC like Hybrid Monte Carlo) struggle a lot in non-convex problems and they hardly move across modes of a posterior distribution (equivalent to crossing barriers of potential). So I\'m not at all surprised that SGD does not cross barriers during optimization and I would challenge the statement in the introduction saying ""Intuitively, when performing random walk on a potential, one would expect barriers being crossed quite often during the process.""', ""This paper explores the idea that mini-batch SGD rarely *crosses* barriers during DNN optimization, but rather uses a 'seemingly' or 'alternate' mechanism, as the authors somewhat mysteriously call it on the first page. In the second part of the paper,  they also investigate why the loss surface is explored more slowly when the batch size increases. \n\nI found both parts of the paper reasonably interesting but not too surprising. My main concern is that both parts are , in themselves, not strong enough to warrant publication at ICLR, and the connection between them is rather weak. The authors write 'to complement this finding'  to connect the first to the second investigation, but that's not connecting them very closely is it?\nI think it would be better to work out both insights in more detail and publish them in separate papers. \nEspecially the second insight should be explored more thoroughly. For example, the authors write 'in convex optimization theory, when gradients point along the sharp directions of the loss surface, optimization exhibits under-damped convergence'. This is repeated later in different wordings.  But no reference to this result (I presume it's a mathematical theorem?) is given, neither here nor later when it is said again. The link from the convex to the nonvex DNN case could also be established more convincingly. Everything became quite (too) heuristic at some point...\n\nA few small remarks (which did not influence my judgement):\n- while in general (with the exception of the too-fast move from convex to nonconvex that I just explained) the paper is written quite clearly, the prose could be made significantly tighter. For example, the definition of what 'crossing a barrier' means is given three times (!) in the paper (two times in a figure, once in section 2). BTW, isn't it better to say 'moving *around* barriers' rather than 'over' barriers? You now use 'over' but still sounds very similar to just 'crossing'. \n- plural nouns are often combined with singular vers ('measurements that ensures'). This happens not just once but all the time...\n\nPROS:\n- two nice little ideas; esp. the first one is well-explained\n- easy to read\nCONS:\n- ideas are not very surprising; and just tested on a few data sets; things could be more  robust. \n- second idea not fully convincingly explained\n- (most important): the two ideas are not closely connected, making this a somewhat strange paper. "", 'The subject of how a given algorithm explores the landscape is still a poorly understood area in training neural networks. There is a large body of recent work that attempts to shed light on this puzzle, and each one tries to claim their share in the furthering of the understanding of the relationship between the geometry of the landscape and the dynamics that one chooses in optimization. The present paper is a fine addition to the literature with interesting observations and novel questions, however, it falls short in many core areas: An apparent work in progress that has a great potential. \n\nIt is safe to say that ""A walk with SGD"" has an important single focus in mind: Does the SGD cross over barriers in the weight space of the underlying neural network? This question, at its heart, is intimately linked with the many properties that are attributed to the modern algorithm of the choice and the way it navigates a given non-convex landscape. The paper claims to provide an almost negative answer to the question and thereby busting several myths that are attributed to the ""trick"" part of SGD algorithm. As good as it sounds, unfortunately, the paper falls short of providing a convincing evidence (be it theoretical or empirical), and the way it tries to frame itself unique and different in relation to related works only indicate a lack of deep understanding of the existing literature. Therefore, I think there are several ways the paper should be improved before it is ready.\n\nA major question (that I hope will easily be addressed) is on the definition of the barrier itself. According to the text, a barrier is defined judging by the minima of two 1-dimensional segments that connect weights connecting three consecutive steps: if the minimum of the line segment defined by the latter step is larger than the former, then it declared that a barrier is crossed. In a low dimensional world, this makes total sense, however, I fail to understand what kind of barrier it implies on the geometry of the landscape: Can the 1-dimensional lines be on the sides of a valley? Can one find *another* 1-dimensional projection for which the inequality is broken? How do such dependencies change the understanding of the problem? And if one is indeed only interested in the flat line segments (since SGD is making discrete steps), then one can, in principle, observe barrier crossing in a convex problem, as well? Is there an argument for otherwise? Or if it is a notion that applies equally well in a convex case then how should we really think about the barrier crossing? On the opposite point of view, can one not imagine a barrier crossing that doesn\'t appear in this triangular inequality above?\n\nThe paper is full of empirical evidence that is guided by a simple observable that is very intuitive, however, it lacks a comprehensive discussion on the new quantity they propose that I consider a major flaw, but that I think (hope) that the authors can fix very easily. Some minor points that would improve the readability and clarity for the reader:\n- The figures are not very reader-friendly, this can be improved by better using the whitespaces in the paper but it can also be improved by finding further observables that would summarize the observations instead of showing individual consecutive line interpolations.\n- What are the values of the y-axis in Figure 5 and 6? Are they the top eigenvalues of the Hessian?\n- In the models that are compared in Figure 7, what are their generalization properties (early stopping and otherwise)?\n- The interpretation at the end of p. 6 may be a good motivation for the reader if it had been introduced earlier for that section.\n\nFinally, Section 5 reads very strangely, I have hard times understanding why certain phrases exist the way they are in this part. Here are further notes on Section 5:\n- Why the whole first paragraph focused on hot the current paper is different than Goodfellow et al (2014) (it is obvious that it is for a different purpose), or why do we read the sentence ""Li et al (2017b) also visualize...."" What way do they visualize, is it the only paper that does visualization, what\'s the relation with the current paper and barrier crossing? \n- For the second paragraph, I can suggest another paper, https://arxiv.org/abs/1803.06969, that was at ICML which also looks at the diffusion process through the parameter distance at different times which is similar to Hoffer et al. which also claims no barrier crossing similar to the present paper. \n- However, my main issue is the exact connection between diffusion and no barrier crossing and it\'s connection to SGD preferring wide local minima instead of a narrow one. The second paragraph of the conclusion touches upon this subject. But it is not entirely clear how they are linked (except for the brittle SDE approximation at Li et al (see https://arxiv.org/abs/1810.00004)). Overall, the paper would benefit a lot from the discussion on why it is preferable to have SGD choose one basin over another in the beginning, as it is, it looks like the paper has another agenda behind the scenes.\n- In the fourth paragraph of the conclusion, the paper refers to three papers that link DNN to spin glasses, in two of the (older) references the networks are far from what we have today, and the third one is far from ""showing"" anything between DNN and spin glass. In any case, what\'s the link between the aspects studied there with the present paper?\n- Finally, the paper claims at the last few sentences that the works referred a little bit earlier look at the loss surface ""in isolation from the optimization dynamics"", however, many of those works cited have their empirical observations much like the current paper, and clearly they all ""study the DNN loss surface along the trajectory of SGD"" necessarily as it is the way to find local minima, saddle points, paths, curvature etc... The present paper is already very interesting and full of novel insight, I fail to see the value of struggling to stand out like this.\n\nOverall, I think the paper is a very interesting step forward in understanding SGD dynamics on the DNN landscape. And, even though it has many shortcomings as it currently stands, I think it has a lot of room to improve.\n\n']","[-30, -30, -20]","[50, 20, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('I like the idea...', 'The experimental validation is interesting'), they express several criticisms and limitations of the work. The overall tone suggests that the reviewer finds the contribution not very substantial and lacking in key areas. The politeness score is 50 because the reviewer uses polite language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'It would be helpful...', 'I believe it would have been interesting...', and 'I think this point requires elaboration...', which maintain a respectful tone while conveying their concerns."", ""The sentiment score is slightly negative (-30) because while the reviewer found parts of the paper 'reasonably interesting', they express several concerns. They state that neither part is strong enough for publication, the connection between the two parts is weak, and the second insight needs more thorough exploration. The reviewer also mentions that the ideas are 'not very surprising' and could be more robust. However, they do acknowledge some positive aspects, like 'two nice little ideas' and that it's 'easy to read', which prevents the score from being more negative. The politeness score is slightly positive (20) because the reviewer uses generally respectful language and offers constructive criticism. They use phrases like 'I found' and 'I think' to soften their critiques, and they clearly separate their main concerns from 'small remarks'. However, some phrases like 'somewhat mysteriously' and 'that's not connecting them very closely is it?' have a slightly sarcastic tone, which prevents the politeness score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'a fine addition to the literature with interesting observations and novel questions', they also state that it 'falls short in many core areas' and is 'an apparent work in progress'. The review points out several shortcomings and areas for improvement, indicating a generally critical stance despite recognizing potential. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses hope for improvement. They use phrases like 'I hope will easily be addressed' and 'I think there are several ways the paper should be improved', which maintain a polite and encouraging tone even while critiquing. The reviewer also ends on a positive note, stating the paper is 'very interesting' and has 'a lot of room to improve', further contributing to the polite tone.""]"
"['The authors suggest a reward shaping algorithm for multi-agent settings that adds a shaping term based on the TD-error of other agents to the reward. In order to implement this, each agent needs to keep tack of two different value estimates through different DQN networks, one for the unshaped reward and one for the shaped reward. \n\nPoints of improvement and questions: \n-Can you please motivate the form of the reward shaping suggested in (2) and (3)? It looks very similar to simply taking \\hat{r}_a = r_a + sum_{a\' not a} z_{\'a}. Did you compare against this simple formulation? I think this will basically reduce the method to Value Decomposition Networks (Sunehag \u200e2017) \n-The results on the prisoners dilemma seem miss-leading: The ""peer review"" signal effectively changes the game from being self-interested to optimising a joint reward. It\'s not at all surprising that agents get higher rewards in a single shot dilemma when optimising the joint reward. The same holds for the ""Selfish Quota-based Pursuit"" - changing the reward function clearly will change the outcome here. Eg. there is a trivial adjustment that adds all other agents rewards to the reward for agent i that will will also resolve any social dilemma.\n-What\'s the point of playing an iterated prisoners dilemma when the last action can\'t be observed? That seems like a confounding factor. Also, using gamma of 0.9 means the agents\' horizon is effectively limited to around 10 steps, making 50k games even more unnecessary. \n-""The input for the centralized neural network involves the concatenation of the observations and actions, and optionally, the full state"": This is not true. For example, the Central-V baseline in COMA can be implemented by feeding the central state along (without any actions or local observations) into the value-function. It is thus scalable to large numbers of agents. \n-The model seems to use a feed-forward policy in a partially observable multi-agent setting. Can you please provide a justification for this choice? Some of the baseline methods you compare against, eg. QMIX, were developed and tested on recurrent policies. Furthermore, independent Q-learning is known to be less stable when using feedfoward networks due to the non-stationarity issues arising (see eg. ""Stabilising Experience Replay"", ICML 2017, Foerster et al). In it\'s current form the concerns mentioned outweigh the contributions of the paper.', 'The paper introduces a DQN based, hierarchical, peer-evaluation scheme for reward design that induces cooperation in semi-cooperative multi-agent RL systems. The key feature of this approach is its scalability since only local “communication” is required -- the number of agents is impertinent; no states and actions are shared between the agents. Moreover this “communication” is bound to be low dimensional since only scalar values are shared and has interesting connections to sociology. Interesting metaphor of “feel” about a transition.\n\nRegarding sgn(Z_a) in Eq2, often DQN based approaches clip their rewards to be between say -1 and 1. The paper says this helps reduce magnitude, but is it just an optimization artifact, or it’s necessary for the reward shaping to work, is slightly unclear. \n\nI agree with the paper’s claim that it’s important for an agent to learn from it’s local observation than to depend on joint actions. However, the sentence “This is because similar partially-observed transitions involving different subsets of agents will require different samples when we assume that agents share some state or action information.” is unclear to me. Is the paper trying to just say that it’s more efficient because what we care about is the value of the transition and different joint actions might have the same transition value because the same change in state occured. However, it seems that paper is making an implicit assumption about how rewards look like. If the rewards are a function of both states and actions, r(s,a) ignoring actions might lead to incorrect approximations.\n\nIn Sec 3.2, under scalability and flexibility, I agree with the paper that neural networks are weird and increasing the number of parameters doesn’t necessarily make the task more complex. However the last sentence ignores parameter sharing approaches as in [1], whose input size doesn’t necessarily increase as the number of agents grows. I understand that the authors want to claim that the introduced approach works in non homogeneous settings as well.\n\nI get the point being made, but Table 1 is unclear to me. In my understanding of the notations, Q_a should refer to Action Q-table. But the top row seems to be showing the perceived reward matrix. How does it relate to Mission Q-table and Action Q-table is not obviously clear.\n\nGiven all the setup and focus on flexibility and scalability, as I reach the experiment section, I am expecting some bigger experiments compared to a lot of recent MARL papers which often don’t have more two agents. From that perspective the experiments are a bit disappointing. Even if the focus is on pedagogy and therefore pursuit-evasion domain, not only are the maps quite small, the number of agents is not that large (maximum being 5). So it’s hard to confirm whether the scalability claim necessarily make sense here. I would also prefer to see some discussion/intuitions for why the random peer evaluation works as well as it did in Fig 4(a). It doesn’t seem like the problem is that of \\beta being too small. But then how is random evaluation able to do so much better than zero evaluation?\n\nOverall it’s definitely an interesting paper. However it needs more experiments to confirm some of its claims about scalability and flexibility.\n\nMinor points\nI think the section on application to actor critic is unnecessary and without experiments, hard to say it would actually work that well, given there’s a policy to be learned and the value function being learned is more about variance reduction than actual actions.\nIn Supplementary, Table 2: map size says 8x7. Which one is correct?\n\n[1]: https://link.springer.com/chapter/10.1007/978-3-319-71682-4_5\n', 'This work is well-written, but the quality of some sections can be improved significantly as suggested in the comments. I have a few main concerns that I explain in detailed comments. Among those, the paper argues that the algorithms converge without discussing why. Also, the amount of overestimation of the Q-values are one of my big concerns and not intuitive for me in the game of Prisoner\'s Dilemma that needs to be justified. For these reasons, I am voting for a weak reject now and conditional on the authors\' rebuttal, I might increase my score later.\n\n1) I have a series of questions about Prisoner\'s Dilemma example. I am curious to see what are the Q-values for t=100000 in PD. Is table 1h shows the converged values? What I am expecting to see is that the Q-values should converge to some values slightly larger than 3, but the values are  ~ 30. It is important to quantify how much bias you add to the optimal solution by reward shaping, and why this difference in the Q-values are observed.\n\n2) One thing that is totally missing is the discussion of convergence of the proposed method. In section 3.4, you say that the Q-values converge, but it is not discussed why we expect convergence. The only place in the paper which I can make a conjecture about the convergence is in figure 4c which implicitly implies the convergence of the Mission DQN, but for the other one, I don\'t see such an observation. Is it possible to formalize the proposed method in the tabular case and discuss whether the Q-values should converge or not? Also, I would like to see the comparison of the Q-values plots in the experiments for both networks.\n\n3) The intuition behind (2) should be better clarified. An example will be informative. I don\'t understand what |Z_a| is doing in this formula.\n\n4) One of the main contributions of the paper is proposing the reward shaping mechanism. When I read section 3.3, I was expecting to see some result for policy gradient algorithms as well, but this paper does not analyze these algorithms. That would be very nice to see its performance in PG algorithms though. In such case that you are not going to implement these algorithms, I would suggest moving this section to the end of the paper and add it to a section named discussion and conclusion.\n\n5) Is it possible to change the order of parts where you define $\\hat{r}$ with the next part where you define $z_a$? I think that the clarity of this section should be improved. This is just a suggestion to explore. I was confused at the first reading when I saw $z_a$, ""evaluation of transition"" and then (2) without knowing how you define evaluation and why.\n\n6) Is there any reason that ablation testing is only done for trio case? or you choose it randomly. Does the same behavior hold for other cases too?\n\n7) Why in figure 4a, random is always around zero?\n\n8) What will happen if you pass the location of the agent in addition to its observation? In this way, it is possible to have one  Dual-Q-network shared for all agents. This experiment might be added to the baselines in future revisions.\n\nMinor: \n* afore-mentioned -> aforementioned\nsection 4.2: I-DQN is used before definition\n* Is it R_a in (4)?\n* I assume that the table 1f-1h are not for the case of using independent Q-learning. Introducing these tables for the first time right after saying ""This is observed when we use independent Q-learning"" means that these values are coming from independent Q-learning, while they are not as far as I understand. Please make sure that this is correct.\nsection 4.1: * who\'s -> whose\n* This work is also trying to answer a similar question to yours and should be referenced: ""Learning Policy Representations in Multiagent Systems, by Grover et al. 2018""\n* Visual illustrations of the game would be helpful in understanding the details of the experiment. Preparing a video of the learned policies also would informative.\n-----------------------------------------------\nAfter rebuttal: after reading the answers, I got answers to most of my questions. Some parts of the paper are vague that I see that other reviewers had the same questions. Given the amount of change required to address these modifications, I am not sure about the quality of the final work, so I keep my score the same.']","[-50, 50, -60]","[20, 70, 50]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several issues with the paper. The reviewer questions the motivation behind the reward shaping algorithm, suggests the results may be misleading, and expresses concerns about the methodology. The final sentence states that 'the concerns mentioned outweigh the contributions of the paper,' indicating a negative overall sentiment. However, it's not entirely negative as the reviewer acknowledges the authors' work and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use polite phrases like 'Can you please motivate...' and 'Can you please provide a justification...', which shows respect for the authors. The reviewer also frames their points as questions or suggestions rather than outright dismissals, which contributes to a more polite tone. However, the directness of the criticisms prevents the score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'interesting' and praises its key features like scalability and connections to sociology. However, they also express disappointment with the experiments and request more evidence for some claims. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I agree,' 'I understand,' and 'I would prefer to see' rather than making blunt demands. The reviewer also balances critique with praise, ending on a positive note about the paper being 'definitely interesting.'"", ""The sentiment score is -60 because the reviewer expresses several major concerns and votes for a 'weak reject', indicating an overall negative sentiment. However, they do acknowledge some positive aspects ('well-written') and leave room for improvement based on the authors' rebuttal. The politeness score is 50 because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g. 'can be improved', 'I am curious to see'), and offers suggestions rather than demands. They also acknowledge the possibility of changing their score based on the authors' response, showing openness. The review maintains a professional tone without being overly formal or deferential, hence a moderately positive politeness score.""]"
"['In this work the authors use a score-based adversarial attack (based on the natural evolution strategy (NES)) to successfully attack a multitude of defended networks, with success rates rivalling the best gradient-based attacks.\n\nAs confirmed by the authors in a detailed and very open response to a question of mine, the attack introduced here is actually equivalent to [1]. While the attack itself is not novel (which will require a major revision of the manuscript), the authors point out the following contributions over [1]:\n\n* Attack experiments here go way beyond Ilyas et al. in terms of Lp metrics, different defense models, different datasets and transferability.\n* Different motivation/derivation of NES.\n* Concept of adversarial distributions.\n* Regression network for good initialization.\n* Introduction of accuracy-iterations plots.\n\nMy main concerns are as follows:\n* The review of the prior literature, in particular on score-based and decision-based defences (the latter of which are not even mentioned), is very limited and is framed wrongly. In particular, the statement “However, existing black-box attacks are weaker than their white-box counterparts” is simply not true: as an example, the most prominent decision-based attack [2] rivals white-box attacks on vanilla DNNs as well as defended networks [3].\n* The concept of adversarial distributions is not new but is common in the literature of real-world adversarials that are robust to transformations and perturbations (like gaussian noise), check for example [4]. In [4] the concept of _Expectation Over Transformation (EOT)_ is introduced, which is basically the generalised concept of the expectation over gaussian perturbations introduced in this work.\n* While I like the idea of accuracy-iterations plots, the idea is not new, see e.g. the accuracy-iterations plot in [2] (sample-based, Figure 6), the loss-iterations plot in [5] or the accuracy-distortion plots in [3]. However, I agree that these type of visualisation or metric is not as widespread as it should be.\n\nHence, in summary the main contribution of the paper is the application of NES against different defence models, datasets and Lp metrics as well as the use of a regression network for initialisation. Along this second point it would be great if the authors would be able to demonstrate substantial gains in the accuracy-query metric. In any case, in the light of previous literature a major revision of the manuscript will be necessary.\n\n[1] Ilyas et al. (2018) “Black-box Adversarial Attacks with Limited Queries and Information” (https://arxiv.org/abs/1804.08598) \n[2] Brendel et al. (2018) “Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models” (https://arxiv.org/abs/1712.04248)\n[3] Schott et al. (2018) “Towards the first adversarially robust neural network model on MNIST” (https://arxiv.org/abs/1805.09190)\n[4] Athalye et al. (2017) “Synthesizing Robust Adversarial Examples” (https://arxiv.org/pdf/1707.07397.pdf)\n[5] Madry et al. {2017) “Towards Deep Learning Models Resistant to Adversarial Attacks” (https://arxiv.org/pdf/1706.06083.pdf)', 'Summary: In this paper the authors discuss a black-box method to learn\nadversarial inputs to DNNs which are ""close"" to some nominal example\nbut nevertheless get misclassified. The algorithm essentially tries to\nlearn the mean of a joint Gaussian distribution over image\nperturbations so that the perturbed image has high likelihood of being\nmisclassified. The method takes the form of zero-th order gradient\nupdates on an objective measuring to what degree the perturbed example\nis misclassified. The authors test their method against 10 recent DNN\ndefense mechanisms, which showed higher attack-success rates than\nother methods. Additionally the authors looked at transferrability of\nthe learned adversarial examples.\n\nFeedback: As noted before, this paper shares many similarities with\n\n[1] ""Black-box Adversarial Attacks with Limited Queries and Information"" (https://arxiv.org/abs/1804.08598)\n\nand the authors have responded to those similarities in two follow-ups. I have reviewed these results and their \nmethod does appear to improve over [1]. However, I am still reluctant to admit these additions to the original submission, \nmainly because dropping [1] in the original submission seems to be a fairly major omission of one of the most relevant competitors out there. In its current form, the apparent redundancies distract significantly from the paper, and to remedy this, the paper would have to change significantly in order to relate it properly to [1] clear is needed. I\'d be curious on the ACs thoughts on this. \n\nI appreciate the authors\' claim that their method can breach many of the popular defense methods out there, but we \nalso see that many of the percentages in Figure 1 converge  to 1. On the one hand this suggests that all defense methods \nare in some sense equally bad, but on the other, it could also just reflect on the fact that the thresholds are chosen \n""too large"". I understand that many of the thresholds were inherited from previous work, but it would nevertheless help if the authors showed some example adversarial images to help baseline this Figure.  ', 'In this paper, authors propose a ""universal"" Gaussian balck-box adversarial attack.\nOriginal and well-written (although there are a few grammar mistakes that would require some revision) and structured. Having followed the comments and discussion I am convinced that the proposed method is state of the art and interesting enough fro ICLR.\nTo the best of my knowledge, the study is technically sound.\nIt fairly accounts for recent literature in the field.\nExperiments are convincing.\nOne thing I am not so convinced about is the naming of the evaluation curve as ""a new ROC curve"". I understand the appeal of pairing the proposed evaluation curve with the ROC curve but, beyond an arguable resemblance, they have no much in common, really.']","[-20, -20, 80]","[60, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some contributions of the paper, they express several major concerns and state that a 'major revision of the manuscript will be necessary.' The overall tone suggests that the paper has some value but falls short in several important areas. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and provides detailed, constructive feedback. They use phrases like 'I like the idea' and 'it would be great if' which contribute to a polite tone. However, the critique is direct and doesn't use overly deferential language, keeping the score from being extremely high."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some improvements and appreciates the authors' claims, they express reluctance and concerns about the paper's originality and presentation. The reviewer points out similarities with previous work and suggests significant changes are needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and phrases criticisms constructively. They use phrases like 'I appreciate' and 'I'd be curious' which maintain a polite tone. The reviewer also offers specific suggestions for improvement rather than just criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'original and well-written,' 'state of the art and interesting,' and 'technically sound.' The experiments are called 'convincing,' and the reviewer states they are 'convinced' by the method. The only slight criticism is about the naming of an evaluation curve, which doesn't significantly detract from the overall positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and offer a mild suggestion for improvement without harsh criticism. The tone is professional and courteous, though not excessively formal or deferential, hence not reaching the highest levels of politeness.""]"
"['Paper Summary - This paper presents an approach for fine-grained action recognition and video captioning. The authors train a model using both classification and captioning tasks and show that this improves performance on transfer learning tasks. The method is evaluated on the Something-Something v2 dataset as well as a new dataset (proposed in this paper). The authors also evaluate the benefit of using fine-grained action categories vs. coarse-grained action categories on transfer learning.\n\nPaper Strengths\n-  Comparing fine-grained vs. coarse-grained action categories for transfer learning is well motivated. Evaluating just this aspect in the context of video classification is helpful (Section 5.1). Establishing the baseline using linear classifiers for feature transfer makes the feature transfer result more robust. The authors have also done a good job of evaluating their method in the coarse-grained and fine-grained settings (Table 1, 2).\n- The architectural and experimental design in this paper is well illustrated.\n- The 20bn kitchen dataset has interesting categories about intention - pretending to use, using, and using & failing.\n- The ablation in Table 1 is helpful in understanding the contribution of 3D vs. 2D convolutions.\n\nPaper Weaknesses\n- I believe this paper tries to do too much and as a result fails to show results convincingly. There are too many results and not much focus on analyzing them. In my opinion, the experimental setup in the paper is weak to fully support the authors\' claims.\n- I now analyze the main contributions of this paper as outlined by the authors in Section 1.\n    - Label granularity and feature quality: To me this is the most interesting part of this paper and most related to its title. However, this is also the most under-analyzed aspect. The only result that the authors show is in Sec 5.1 and Fig 5. Apart from using the provided fine-grained vs. coarse-grained labels for evaluation, the authors do not perform many experiments in this domain and neither do they analyze these results. For example, the gain using fine-grained labels is not significant in Figure 5 (2Channel - CG vs. 2Channel - FG). The authors do not explain this aspect. Another missing baseline from Figure 5 is ""2Channel - Captions & CG actions"". This baseline is needed to understand the contribution of FG vs CG actions when also using captioning as additional supervision.\n    - Baselines for captioning: The authors do not provide any details for this task. If the intent is to establish baselines there needs to be more effort on analyzing design decisions - e.g. decoding, layers in LSTM. Captioning metrics such as CIDER and SPICE are missing.\n    - Captions as a source for transfer learning: This is poorly analyzed in this paper. 1) Can the captions be converted to ""tags"" and then used for supervision? What is the benefit of producing the full sequential text description over this simple approach? 2) Captions for transfer learning are only analyzed in Figure 5 without much explanation. It is hard to claim that captioning is the reason for performance gains without really analyzing it completely.\n    - 20bn-kitchenware dataset - This dataset is explained in just one paragraph in Section 6. What is the motivation behind collecting this dataset as opposed to showing transfer learning on some other dataset?\n- Missing references\n        - There has been work in understanding the effect of fine-grained categories in ImageNet transfer learning - What makes ImageNet good for transfer learning? Huh et al. What is the insight provided over this work?\n- Minor comments\n    - Section 1: Figure 4 is referenced in points 1 & 3. I think you mean Figure 5.\n', 'Summary\nThis paper studied video classification and video caption generation problem.\nEspecially, the paper tried few baseline architectures datasets used from pretraining features on recently proposed Something-something-V2 dataset and another newly proposed dataset.\nThis paper argues that fine-grained annotation helps learning good features and enhance transfer learning results\n\nStrength\nThere are some interesting observations in terms of transfer learning.\nEspecially, comparison of fine-grained and coarse-grained dataset for transfer learning (Table 2), and effect of using caption and newly collected dataset for transfer learning (Figure 5) is interesting and the result is worth to be shared to the community.\nIn addition, a new dataset that are carefully collected for transfer learning might be useful to make progress on video classification and captioning.\n\nWeakness\nTo many tables with different neural network parameter settings look distracting and does not provide much information. Instead, focusing more on effect of dataset for transfer learning and providing more analysis on this aspect would make the main argument of this paper stronger.\nFor example, effect of transfer could be studied on different dataset. If transfer learning with proposed dataset containing find-grained annotation / captions is useful, it might help boosting performance on other video recognition dataset as well.\nProviding analysis on understanding the effect of fine-grained / captioning dataset for feature learning might help understanding as well.\n\nOverall rating\nThis paper suggest interesting observations and useful dataset, but provides relatively less analysis on these observations. I believe providing more analysis on the dataset and effect of transfer would make the main argument of this paper stronger.', ""This paper describes a multi-task video classification and captioning model applied to a fine-grained object relationship video dataset, for a range of different classification and captioning tasks at different levels of granularity. This paper also creates a new video action dataset around kitchen objects and actions.  Finally, the paper includes an empirical study on both the multi-task performance and transfer learning performance between the two datasets considered.\n\nPros:\n- This paper is clearly written and includes a thorough and well-laid out empirical component\n- The contribution to the video action classification and captioning space seems like a worthwhile one\n\nCons:\n- The novelty of this paper mainly seems to be with respect to video classification and captioning; other methodological aspects and empirical themes are interesting but fairly standard more generally.  The lack of experiments outside of one video action classification & captioning dataset (and one additional one for a transfer learning study) limit the empirical generality of the findings.\n\nOverall take: This paper's contributions seem of interest to the video classification and captioning community, but less so to a broader or more methodologically-focused one such as ICLR.\n\nNotes:\n- The comments on insufficiency of existing video classification tasks in Sec. 3 are interesting, but seem pretty restricted to that specific domain\n- The model used is a fairly standard CNN + LSTM video encoder, plus a basic MTL network approach with hard parameter sharing between tasks, as is commonly used today. Similarly, the transfer learning approach---pre-training on one task, then freezing layers and fine-tuning---is a standard approach.\n- The empirical findings are interesting---for example, that training on fine-grained tasks improves coarse-grained accuracy, that MTL training is helpful, etc---but (a) seem in general like known themes, and (b) have limited generality either way beyond the specific types of tasks considered in the dataset examined.\n- In general, much of the paper is focused on details specific to this application domain, rather than to general methods or themes potentially interesting to the broader ICLR community""]","[-30, 20, 20]","[50, 50, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper (e.g., 'well motivated', 'well illustrated', 'helpful'), they also express significant criticisms. The review states that the paper 'tries to do too much and as a result fails to show results convincingly' and has a 'weak' experimental setup. The reviewer also points out several missing analyses and baselines. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I believe' and 'In my opinion' to soften criticisms, and they provide specific, constructive feedback. The reviewer also acknowledges the paper's strengths before delving into weaknesses. However, the score is not higher because the review is quite direct in its criticisms, without using many additional polite phrases or softening language."", ""The sentiment score is slightly positive (20) because the reviewer notes some strengths and interesting observations in the paper, while also pointing out weaknesses. The overall tone is constructive rather than overtly negative or positive. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions while offering suggestions for improvement in a professional manner. The reviewer avoids harsh criticism and instead frames weaknesses as opportunities for enhancing the paper's argument. The use of phrases like 'interesting observations', 'worth to be shared', and 'useful dataset' contribute to the polite tone, even when discussing areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as it being clearly written with a thorough empirical component and making a worthwhile contribution to the field. However, they also point out significant cons, particularly the limited novelty and generalizability of the findings. The overall tone suggests the paper has merit but may not be suitable for the broader ICLR audience. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout. They balance criticism with praise, use phrases like 'interesting' and 'worthwhile' when discussing positive aspects, and frame negative points constructively without harsh language. The reviewer maintains an objective tone, focusing on the paper's content rather than making personal comments about the authors.""]"
"['The paper proposes a generative infection cascade model based on latent vector representations. The main idea is to use all possible paths of infections in the model. \n\nComments:\n- The papers clarity could be much improved. It is not easy to follow, is overflowing with notation, and lengthy. Sec. 2.1 for example can easily be made much more concise. Secs. 3.1 and 3.2 are especially confusing. In the first equation in Sec. 3, what is \\phi with and without sub/superscript? In Eq. (2), what is k - a probability, or an index? And what is the formal definition ""infection"" and ""future"" in the description of k stating that it is ""the probability that u infects v in the future""?\n\n- The authors mention that the actual infectors in a diffusion process are rarely observed. While this might be true, in many types of data include infection attempts. This should be worthwhile to model - there are many works on reconstructing cascades from partial data.\n\n- The authors note (rightly) the Eq. (9) is hard to solve, and propose a simple lower bound based on (what I think is) a decomposition assumption.  Unless I misunderstood, this undermines the contribution of the structure of past infections. Could the authors please clarify?\n\n- The results mention 5 (tables?), but only 4 are available, of which one appears floating on the last page.\n\n- Why are methods discussed in the introduction (e.g., DeepCas, Wang 2017a,b 2018) not used as baselines?\n\nMinor:\n- Wang 2017a and Wang 2017b are not the same Wang\n- Several occurrences of empty parentheses - ()\n- ', 'The authors of this paper are proposing a neural network approach for learning diffusion dynamics in networks. The authors argue that the main advantage of their framework is that it incorporates the structure of independent cascades into the model which predicts the diffusion process.\n\nThe primary difficulty in reviewing this paper is the poor presentation of the paper. There are many typos and mistakes (e.g., the last paragraph of the paper starts with a sentence that does not make any sense), missing references (e.g., there is an empty parenthesis at the end of the second paragraph on the second page) and in at least two cases, there are references to a formula that is not in the manuscript (e.g., reference to formula 15 on line 3 of page 5). This issues makes reviewing this paper very difficult.\n\nIn the modeling section, authors use p(I|D) as q^D(.) in the Eq. 12, where p(I|D) is the conditional probability that a particular node infected an observed infected node first. Plugging p(I|D) in Eq. 12 and using decomposition of p(D ,I) used in Eq. 10, we arrive at a formulation which drops all p(I|D) terms. This results in an objective function which only involves infected nodes (and no term associated with the parent node), weighted by likelihood of each node j infecting the node at step i. This should make the training more simplified than what is discussed in Algorithm 2. Beyond this simplification, I am not clear if that is actually intended by the authors.\n\nThe experiments demonstrate a superior performance of the proposed model compared to alternative benchmarks. The authors explain how they trained their own model but there is no mention on how they trained benchmark models. However, given that the datasets used in the experiments were not used in the associated benchmark papers, it is necessary for authors to explain how they trained competing models.\n\nDue to several shortcomings of the paper, most important of which is on presentation of the paper, this manuscript requires a significant revision by the authors to reach the necessary standards for publication, moreover it would be helpful to clarify the modeling choices and consequences of these choices more clearly.', 'The problem that the paper tackles is very important and the approach to tackle it id appealing. The idea of regarding the history as a tree looks very promising. However, it’s noteworthy that embedding to a vector could be useful too if the embedding espace is representative of the entire history and the timing of the events. \n\nUsing neural network if an interesting choice for capturing the influence probability and its timing.\n\nThe authors need to be clear about their contribution. Is the paper only about replacing the traditional parametric functions of influence and probability with  deep neural networks? \nThe experimental sections look rather mechanical. I would have put some results on the learned embedding. Or some demonstration of the embedded history or probability to intuitively convey the idea and how it works. This could have made the paper much stronger.\n\nIt was nice that the paper iterated and reviewed the possible inference and learning ways. There is one more way. Similar to [1] one can use MCMC with importance sampling on auxiliary variables to infer the hidden diffusion given the observed cascades in continuous-time independent cascade model.\n\nThe paper can benefit from a proofreading. There are a few typos throughout the paper such as:\nReference is missing in section 2.1\nPage 2 paragraph 1: “an neural attention mechanism”\n\n[1] Back to the Past: Source Identification in Diffusion Networks from Partially Observed Cascades, AISTATS 2015']","[-30, -60, 20]","[20, 20, 60]","[""The sentiment score is -30 because the review is generally critical, pointing out several areas for improvement such as clarity, model assumptions, and missing comparisons. However, it's not entirely negative as it acknowledges some positive aspects like the main idea being interesting. The politeness score is 20 because while the reviewer is direct in their criticisms, they use polite language such as 'could be much improved' and 'please clarify'. They also offer constructive feedback and suggestions rather than just criticism. The review maintains a professional tone throughout, avoiding harsh or rude language."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, including poor presentation, typos, missing references, and unclear modeling choices. The reviewer states that the paper requires 'significant revision' to meet publication standards. However, it's not entirely negative as the reviewer acknowledges some positive aspects, such as the superior performance demonstrated in experiments. The politeness score is 20 because while the reviewer is direct in pointing out the paper's flaws, the language used is professional and constructive. The reviewer offers specific suggestions for improvement and uses phrases like 'it would be helpful to clarify' rather than using harsh or dismissive language. The tone is critical but maintains a level of respect for the authors' work."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem and the appeal of the approach, calling it 'very promising'. However, they also point out several areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'it's noteworthy', 'The authors need to be clear', and 'The paper can benefit from', which are polite ways of pointing out areas for improvement. The reviewer also compliments aspects of the paper, such as 'It was nice that the paper iterated and reviewed the possible inference and learning ways', further contributing to the polite tone.""]"
"['The paper suggest a shrinkage-based estimator (James-Stein estimator) to compute policy gradients in reinforcement learning to reduce the variance by trading some bias. Two versions are suggested: The on-policy gradients is shrinked either towards (i) model based gradient, or towards (ii) a delayed average of previous on-policy gradients. Empirically, both methods have better performance than the baseline.\n\nThe paper is clearly written and well motivated. Some details are lacking that would be of interest to the reader and to make the results reproducible. For example how is \\hat Q estimated? The trick that is referred to in the end of page about only simulating short horizon trajectories deserves more detail. I would suggest providing more details, in the text and/or in the two algorithms.\n\nThe authors claim that JS estimator for gradient estimation in RL has not been used before. I am also not aware of any other work, but have also not been looking after that line of work. The paper seems to be a good contribution to the ever increasing literature of how to improve deep RL.\n\nMinors:\n\\hat \\theta on RHS in eq (7) should be \\bar \\theta ? Otherwise, what is \\hat \\theta?\nsection 4.2 Ww -> We\n\n======= After revision =========\n\nI still think this is a very interesting, novel and relevant idea that desires attention. However, on the same time, I agree with the points raised by the other two reviewers which are all well-motivated and relevant concerns. Therefore, I join the view that the paper is not yet ready for publication but I do encourage the authors to improve their work and resubmit to another venue.', 'This paper presents two algorithms that improve on PPO by using James-Stein (JS) shrinkage estimator. The first algorithm, PPO-MBS, combines low bias of on-policy methods with low variance of model-based RL algorithms. The second, PPO-STS, uses JS to create a statistical momentum and reduce variance of the PPO algorithm. Both algorithms are evaluated on Mujoco environments aiming to show improvements in average cumulative reward, reduced bias and variance.\n\nThe paper’s topic is highly relevant, as the authors point out, the current state of the art in RL is largely divided between model-based and model-free methods. This paper aims at bridging the gap, and taking advantage of both sides. The writing is clear and concise, with all the math properly introduced. The proposed methods are interesting and novel. As far as I am aware, this is solid and unexplored approach with potentially significant impact.\n\nThere are two concerns with this paper. First, the evaluation results are promising, yet not fully convincing. It appears that 5 million steps is not sufficient for the policy convergence for any of the tasks (average reward keeps increasing). At the same time the variance gap (Figure 1) is reducing. \n- As the training continues, does the variance for PPO-MBS become larger?\n- Similar question for the average reward - the advantage of the PPO-MBS vs. comparison methods seems to be reducing. What happens with the additional training?\n- How do the trajectories and behavior of the Walker2D (and other) look with PPO-MBS vs. others - is the higher average reward indicative of the qualitatively better behavior?\n- Why do Walker2D and Hopper increase \\alpha over time, while Swimmer and Reacher lean more towards mode model based policy over time?\n- Is there something significant about the structure of the problems?\n- Similar questions arise from the evaluation of the PPO-STS - it appears that the training is even less complete in this case, rendering the conclusions about the quality of the learned policy at convergence invalid.\n- Why are Humanoid and Ant not evaluated on PPO-MBS? The authors should extend the training to convergence on all problems, and present the results including movies of example trajectories of all environments for both algorithms in the supplementary material.\n\nSecond, the paper introduces two competing methods.  While, the authors compare them directly,  they do not discuss how the two methods relate to each other. In the Reacher and Hopper task seems like all three methods perform about the same, and in the Hopper PPO-STS even performs worse than the baseline. This makes it difficult to assess the significance of the exposition. When should one be used, and when the other one is better?\n\nThe authors should consider either a) splitting the paper into two focusing each paper on a single algorithm with more in-depth evaluations and discussions, or b) combining the two algorithms into ones. In any case, further analysis that illuminates when the methods should be used, and how they improve the training are needed.\n', 'The paper claims that a combination of policy gradients calculate by different RL algorithms would provide better objective values. Main focus of the work is to devise and adaptive combination scheme for policy gradient estimators. Authors claim that by using the statistical shrinkage estimators combining different gradients that have different bias-variance trade-off would provide better mean-square error than each of those individual gradient estimators. The key observations made by the authors are that gradients computed by on-policy methods would provide nearly unbiased estimators with very high variance while the gradients obtained by the off-policy methods in particular model based approaches would provide highly biased estimators with low variance. Proposed statistical tool to combine gradients is James-Steim shrinkage estimator. JS estimator provides strong theoretical guarantees for Gaussian cases but some practical  heuristics tor more complex non-Gaussian cases. Authors do not discuss  whether the JS estimator actually suitable for this task given the fact that strong assumptions of the underlying statistical approach is violated. They also do not go into any discussion about theoretical guarantees nor they provide any exposures or intuitions about that. The scope of the experiments is very limited. Given the fact that there is no theory behind the claims and the lack of strong evidence I believe this paper does not cut the requirements for publication.\n\nTo improve please add significantly more empirical evidence, provide more discussion about theoretical ground work and discussion about the suitability of the JS estimators when its required assumptions are not satisfied.']","[-20, 50, -70]","[60, 80, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer initially praises the paper as 'clearly written and well motivated' and a 'good contribution', they ultimately conclude that it's 'not yet ready for publication'. This indicates a overall negative sentiment, albeit a mild one. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and providing constructive feedback. They use phrases like 'I would suggest' and 'I encourage the authors to improve their work', which are polite ways of offering criticism. The reviewer also balances negative points with positive ones, showing consideration for the authors' efforts."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the relevance and novelty of the paper, describing it as 'highly relevant' and 'solid and unexplored approach with potentially significant impact'. However, they also express concerns about the evaluation results and the presentation of two competing methods, which tempers the overall positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They phrase their concerns as questions rather than direct criticisms, such as 'Why are Humanoid and Ant not evaluated on PPO-MBS?' and 'When should one be used, and when the other one is better?'. The reviewer also acknowledges the paper's strengths before presenting concerns, which is a polite approach to feedback."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper and concludes that it 'does not cut the requirements for publication.' They point out several weaknesses, including lack of theoretical discussion, limited experiments, and concerns about the suitability of the statistical approach used. The overall tone is critical and suggests major revisions are needed. The politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. They state their criticisms directly but without using harsh language, and provide constructive suggestions for improvement at the end.""]"
"['\n[pros]\n- It proposes a general formulation of GAN-type adversarial learning as in (1), which includes the original GAN, WGAN, and IPM-type metrics as special cases.\n- It also proposes use of the penalty term in terms of the Lipschitz constant  of the discriminative function.\n\n[cons]\n- Some of the arguments on the Wasserstein distance and on WGAN are not sound.\n- Theorem 3 does not make sense.\n- The proposed scheme is eventually similar to the gradient-penalty-based formulation in Gulrajani et al. (2017).\n\n[Quality]\nI found some weaknesses in this paper, so that I judge the quality of this paper not to be high. For example, the criticisms on the Wasserstein distance in Section 2.3 and in Section 4.4, as well as the argument on WGAN at the end of Section 3.1, is not sound. The claim in Theorem 3 does not make sense, if we literally take its statement. All these points are detailed below.\n\n[Clarity]\nThe main paper is clearly written, whereas in the appendices I noticed several grammatical and spelling errors as well as unclear descriptions.\n\n[Originality]\nDespite that the arguments in this paper are interesting, the proposed scheme is somehow eventually similar to the gradient-penalty-based formulation in Gulrajani et al. (2017), with differences being introduction of loss metrics $\\phi,\\varphi,\\psi$ and the form of the gradient penalty, $\\max \\|\\nabla f(x)\\|_2^2$ in this paper versus $E[(\\|\\nabla f(x)\\|_2-1)^2]$ in Gulrajani et al. (2017). This fact has made me to think that the originality of this paper is marginal.\n\n[Significance]\nThis paper is significant in that it would stimulate empirical studies on what objective functions and what types of gradient penalty are efficient in GAN-type adversarial learning.\n\nDetailed comments:\n\nIn Section 2.3, the authors criticize use of the Wasserstein distance as the distance function of GANs, but their criticism is off the point. It is indeed a problem not of the Wasserstein distance itself, but of its dual formulation.\n\nIt is true mathematically that $f$ in equation (8) does not have to be defined outside the supports of $P_g$ and $P_r$ because it does not affect the expectations in (8). In practice, however, one may regard that $f$ satisfies the condition $f(x)-f(y)\\le d(x,y)$ not only on the supports of $P_g$ and $P_r$ but throughout the entire space $\\mathbb{R}^n$. It is equivalent to requiring $f$ to satisfy the 1-Lipschitz condition on $\\mathbb{R}^n$, and is what WGAN (Arjovsky et al., 2017) tries to do in its implementation of the ""critic"" $f$ via a multilayer neural network with weight clipping.\n\nOne can also argue that, if one defines $f$ only on the supports of $P_g$ and $P_r$, then it should trivially be impossible to obtain gradient information which can change the support of $P_g$. The common practice of requiring the Lipschitz condition throughout $\\mathbb{R}^n$ is thus reasonable from this viewpoint. This is therefore not the problem of the Wasserstein distance itself, but the problem regarding how the dual problem is implemented in learning of GANs. In this regard, the discussion in this section, as well as that in Section 4.4, is misleading.\n\nOn optimizing $k$, I do not agree with the authors\'s claim at the end of Section 3.1 that WGAN may not have zero gradient with respect to $f$ even when $P_g=P_r$. Indeed, when $P_g=P_r$, for any measurable function $f$ one trivially has $J_D[f]=E_{x\\sim P_g}[f(x)]-E_{x\\sim P_r}[f(x)]=0$, so that the functional derivative of $J_D$ with respect to $f$ does vanish identically. \n\nI do not understand the claim of Theorem 3. I think that the assumption is too strong. If one literally takes ""$\\forall x \\not= y$"", then one can exchange $x$ and $y$ in the condition $f(y)-f(x)=k\\|x-y\\|$ to obtain $f(x)-f(y)=k\\|y-x\\|$, which together would imply $k=0$, and consequently $f$ is constant. One would be able to prove that if there exists $(x,y)$ with $x \\not= y$ such that $f(y)-f(x)=k\\|x-y\\|$ holds then the gradient of $f$ at $x_t$ is equal to $k(y-x)/\\|x-y\\|$ under the Lipschitz condition.\n\nAppendix G: Some notations should be made more precise. For example, in the definition of J_D the variable of integration $x$ has been integrated out, so that $J_D$ no longer has $x$ as its variable. The expression $\\partial J_D/\\partial x$ does not make any sense. Also, $J_D^*(k)$ is defined as ""arg min"" of $J_D$, implying as if $J_D^*(k)$ were a $k$-Lipschitz function.\n\nPage 5, line 36: $J_D(x)$ appears without explicit definition.\n\nPage 23, lines 34 and 38: Cluttered expression $\\frac{\\partial [}{\\partial 2}]$ makes the statements not understandable. It also appears on page 24 several times.', ""The authors try to claim that Lipschitz continuity of the discriminator is a fundamental solution of GANs, and that current methods do not satisfy this approach in principle.\n\nThere are several false statements in this paper. In particular, sections 2.3 and 4.4 are wrong (and most of the paper is based on statements made there). The necessary constraint for the Wasserstein distance is NOT f(x) - f(y) <= d(x, y) for all x ~ Pr, y ~ Pg. It has to actually be 1-Lipschitz in the entire space. See Chapters 5 and 6 of [1], for example remark 6.4 or particular cases 5.16 and 5.4. Indeed, this is how it is written in all of the literature this reviewer is aware off, and it's a fact well used in the literature. Indeed, all the smoothness results for optimal transport in [1] heavily exploit the fact that the gradient of the critic is in the direction of the optimal transport map, which wouldn't be the case in the situation the authors try to claim of 'f not being defined outside of the support of Pr or Pg'.\n\nFurthermore, the relationship between Lipschitz continuity and having a gradient is elaborated in [2] https://arxiv.org/abs/1701.07875 , for example figure 2 clearly show this. Furthermore, and contrary to what section 4.5 tries to claim, the idea that most conclusions of wgan hold *without* the Wasserstein distance, but with Lipschitz continuity are already elaborated in the wgan paper. See in fact, appendix G.1 [3], where this is described in detail.\n\n[1]: http://cedricvillani.org/wp-content/uploads/2012/08/preprint-1.pdf\n[2]: http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf\n[3]: http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a-supp.pdf"", ""The authors study the fundamental problems with GAN training. By performing a gradient analysis of the value surface of the optimal discriminator, the authors identify several key issues. \n\nIn particular, for a fixed GAN objective they consider the optimal discriminator f* and analyze the gradients of f* at points x ~ P_g and x~P_d. The gradient decouples into the magnitude and direction terms. In previous work, the gradient vanishing issue was identified and the authors show that it is fundamentally only controlling the magnitude. Furthermore, controlling the magnitude doesn’t suffice as the gradient direction itself might be non-informative to move P_g to P_d. The authors proceed to analyze two cases: (1) No overlap between P_g and P_d where they show that the original GAN formulation, as well as the Wasserstein GAN will suffer from this issue, unless Lipschitzness is enforced. (2) For the case where P_g and P_d have overlap, the gradients will be locally useful which the authors identify as the fundamental source of mode collapse. \n\nThe main theoretical result suggests that (1) penalizing the discriminator proportionally to the square of the Lipschitz constant is the key -- the choice of divergence is not. This readily implies that pure Wasserstein divergence may fail to provide useful gradients, as well as that other divergences combined with Lipschitz penalties (precise technical details in the paper) might succeed. Furthermore, it also implies that one can mix and match the components of the objective function for the discriminator, as long as the penalty is present, giving rise to many objectives which are not necessarily proper divergences. Finally, one can explain the recent success of many methods in practice: While the degenerate examples showing deficiencies of current methods can be derived, in practice we implement discriminators as some deep neural networks which induce relatively smooth value surfaces which in turn make the gradients more meaningful.\n\nPro:\n- Clear setup and analysis of the considered cases. Interesting discussion from the perspective of the optimal discriminator and divergence minimization. The experiments on the toy data are definitely interesting and confirm some of the theoretical results. \n- A convincing discussion of why Wasserstein distance is not the key, but rather it is the Lipschitz constant. This brings some light on why the gradient penalty or spectral normalization help even for the non-saturating loss [2]. \n- Discussion on why 1-Lip is sufficient, but might be too strong. The authors suggest that instead of requiring 1-Lip on the entire space, it suffices to require Lipschitz continuity in the blending region of the marginal distributions. \n\nCon:\n- Practical considerations: I appreciate the theoretical implications of this work. However, how can we exploit this knowledge in practice? As stated by the authors, many of these issues are sidestepped by our current inductive biases in neural architectures.\n-  Can you provide more detail on your main theorem, in particular property (d). Doesn't it imply that the discriminator is constant?\n- Which currently known objectives do not satisfy the assumptions of the theorem?\n- The work would benefit from a polishing pass.\n\n========\nThank you for the response. Given that there is no consensus on the questions posed by AnonReviewer2, there will be no update to the score.""]","[-30, -80, 70]","[50, -20, 60]","[""The sentiment score is -30 because the review expresses several significant criticisms of the paper, including 'weaknesses', 'not sound' arguments, and a claim that 'does not make sense'. However, it's not entirely negative as it acknowledges some positive aspects like the paper's significance in stimulating further research. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or personal criticisms. They present their concerns objectively, using phrases like 'I found some weaknesses' and 'I do not agree' rather than more confrontational language. The reviewer also balances criticisms with positive comments about clarity and significance."", ""The sentiment score is highly negative (-80) because the reviewer strongly disagrees with the paper's main claims, pointing out 'several false statements' and asserting that key sections are 'wrong'. The reviewer contradicts the authors' understanding of fundamental concepts and cites multiple sources to support their criticism. The politeness score is slightly negative (-20) because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and dismissive. Phrases like 'There are several false statements in this paper' and 'sections 2.3 and 4.4 are wrong' are direct and could be perceived as somewhat impolite in academic discourse. The reviewer doesn't soften their criticism or offer any positive feedback, which contributes to the slightly negative politeness score."", ""The sentiment score is 70 (positive) because the reviewer provides several 'Pro' points highlighting the strengths of the paper, such as 'clear setup and analysis', 'interesting discussion', and 'convincing discussion'. The reviewer also notes the paper brings 'light on why the gradient penalty or spectral normalization help'. While there are some 'Con' points, they are framed more as suggestions for improvement rather than major criticisms. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' work with phrases like 'I appreciate the theoretical implications of this work'. The reviewer also frames criticisms constructively, using phrases like 'The work would benefit from...' rather than using harsh or dismissive language. However, the review maintains a professional tone rather than being overly deferential, hence the score is not higher.""]"
"[""Summary: \nThis paper expands on the work on 'emergent communication' with 2 innovations: \n- The architecture has a separate 'message channel' that processes the incoming and outgoing messages mostly independently of the hidden state of the agent. There are also dedicated architecture elements for the interaction between the hidden state and the message stream. \n- The outgoing message is gated with a 'speak' action: only when the agent takes the speak-action at time step t is a message sent out at timestep t+1. \n\nComments for improvement: \n-The paper proposes a rather complicated architecture, with many moving part. In the paper's current form it is extremely hard to see which part of this architecture contribute to the success of the method. A set of ablation studies on the different components would indeed be very helpful. \n-Using the word 'thought' to describe the hidden state of the agent is rather distracting.\n-Equation (1): This just seems to be the policy gradient term for a factorised action space across 'environment action' and 'communication action'. The only obvious difference is that the policy here is shown to condition on the state representation s_t, rather than on the input. Is that intended?\n-The paper suffers from a lot of undefined notation, e.g. the s_t above. Please clarify.\n-In Figure 2b) the MCU is shown to produce the action a_t as an output. That seems like a mistake. \n-Figure 4): The results seem to be extremely unstable, which is a well known issue for independent learning. Recent work (MADDPG, COMA) has shown that centralised critics can drastically avoid these instabilities and improve final performance. Did you compare against using a centralised critic, V(central state), rather the V(observation)? Also, using a single seed on this kind of unstable learning process renders the results highly non-conclusive. \n-In Figure (5), what are the red-arrows? Do these correspond to the actual actions taken by the agents or are they simply annotations? It would be good to see how far the communication range is by comparison. Also, why is there a blob of 'communicating' agents far from the enemy? \n-Are different methods in the large scale battle task trained in self-play and then pitched against other methods in a round-robin tournament after training has finished or are they trained against each other? \n-In Figure 6 (a), why are average rewards changing over the course of training? I would expect this to be a zero-sum setting in self-play. \n-I couldn't find any supplementary material referenced in the text for the details. Instead the paper seems to have another copy of the paper itself attached in the pdf. This makes it hard to evaluate the paper given that few details around training are provided in the main text. \n\nOverall I am concerned that the learning method used in the paper (independent baseline) is known to be unstable and to produce poor results in the multi-agent setting (see COMA and MADDPG). This raises the concern that the communication channel is mostly useful for overcoming the issues introduced from having a decentralised critic."", ""The paper presents a study on multi-agent communication. The main innovation from previous work is the introduction of an explicit Speak binary action that controls whether or not an agent will emit a message. The proposed model is test on two tasks, multi-camera surveillance and battle tasks with a large number of population.\n\nOverall, this paper is clear (although model details are missing, the authors point at the Appendix, but the Appendix is missing) and the authors compare to a number of baselines. I appreciate the use of multi-agent communication in cases where the number of agents very large,  as this is a very good stress test for current algorithms and can potentially help identifying novel challenges. \n\nMy main concern is that in a collaborative setting I don't see why we should expect that occluding information is better than revealing information? Isn't always revealing everything the best strategy? When only 3 cameras, I really cannot think of why a model would get better performance by choosing to not reveal information. Figure 4b somewhat confirms that as there seems to be a lot of variance on the Ssoc. Have you checked how stable are your results across runs? I could believe that occluding information can be beneficial if the number of agents is very big and there is redundancy. But in the limit, not revealing information should only facilitate training --  and indeed this seems to be happening in 6a as Ssoc is learning faster but meanfield is catching up. Could there be an ablation experiment in which everything stays the same in the model but the agents always activate the Speak action? This would answer the question of how crucial this main Speak feature is for Ssoc.\n\nCan you elaborate on this? Moreover, since the Appendix appears to be missing, can you comment on stable results were across runs?\n\n"", ""This paper proposes a spontaneous and self-organizing communication learning scheme in multi-agent RL setup. The problem is interesting. I mainly have one concern regarding its originality.\n\nFrom a technical perspective, it's not clear to me that there's much novelty in this approach.  I guess it might be the case the focus of the paper is to propose a framework or scheme. However, almost all the ingredients/components are standard.\n\nRegarding clarity, it's not clear to me:\n* how the structure from Figure 2 can be reproduced. \n* how statistically significant the evaluation results are. ""]","[-50, -20, -30]","[20, 60, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some innovations in the paper, they express several significant concerns and criticisms. The reviewer points out multiple issues with the methodology, results, and presentation, suggesting that the overall impression is somewhat negative. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Comments for improvement' and offer specific suggestions. The language is not overly harsh or rude, but rather direct and focused on scientific critique. However, it's not excessively polite either, as the reviewer doesn't shy away from pointing out flaws and expressing concerns."", ""Sentiment score: The review starts with a neutral tone, acknowledging the paper's clarity and innovation. However, it expresses concerns about missing details and questions the main premise of the study. The reviewer's skepticism about the benefits of occluding information and request for additional experiments indicate a slightly negative sentiment, hence the score of -20.\n\nPoliteness score: The language used is generally polite and professional. The reviewer uses phrases like 'I appreciate' and frames criticisms as questions or suggestions rather than direct attacks. They also acknowledge positive aspects of the paper before raising concerns. However, the tone is not overly deferential, maintaining a balance between politeness and critical analysis, resulting in a score of 60.\n\nThe scores reflect a review that is slightly critical in content but expressed in a respectful and constructive manner."", ""The sentiment score is -30 because the review expresses a significant concern about the paper's originality, stating 'I mainly have one concern regarding its originality' and 'it's not clear to me that there's much novelty in this approach.' However, it's not entirely negative as the reviewer acknowledges the problem as 'interesting.' The politeness score is 20 because the language is generally neutral and professional, avoiding harsh criticism. The reviewer uses phrases like 'it's not clear to me' instead of making definitive negative statements, which maintains a respectful tone. The reviewer also provides specific points for clarification, which is helpful and considerate to the authors.""]"
"['[Summary:]\nThis paper presents a meta-learning architecture where the slow learner is trained by SGD and the fast learner is trained according to what the meta-learner guides. CNN is split into two parts: (1) bottom conv layers devoted to learn meaningful representation, which is referred to as slow learner; (2) top-fully connected layers involving task-specific fast learners. As in [Andrychowicz et al., 2016], the meta-learner guides the training of task-specific learners. In addition, slow learners are trained by SGD. The motivation is that low-level features should be meaningful everywhere while high-level features should vary wildly. They introduce “miracle representations” and prove that fast/slow learning on a two-layer linear network should converge to somewhere near this miracle representation. They evaluate on few-shot classification benchmarks to evaluate how well this fast/slow meta-learning approach works.\n\n[Strengths:]\nThe paper has a clear motivation. It is easy to read. Training slow/fast learners using different strategies is an interesting idea. \n\n[Weaknesses:]\n- The technique used in this work is a mix of SGD and  [Andrychowicz et al., 2016].\n- The analysis is limited to a simple two-layer linear network. It is not clear whether this analysis is carried over to the proposed deep nets. \n- Quantitative results did not compare to recent results such as Reptile[1] or MT-Nets[2].\n\n[Specific comments:]\n- The current work is an improvement over [Andrychowicz et al., 2016], claiming that training conv layers and fully-connected layers with different strategies improves the generalization. I am wondering why the comparison to [Andrychowicz et al., 2016] is missing. You can use (fully) pre-trained CNN (which already learns meaningful representation using a huge amount of data) in the framework of [Andrychowicz et al., 2016]. \n-As one of the points of the paper is that this meta-learning strategy enables life-long learning, it would have been nice to see an experiment using this, where the distribution of tasks changes as time goes on.\n-The paper says SOA(State Of the Art); I think the term SOTA(State Of The Art) is more commonly used.\n-The use of the term “miracle” keeps changing(miracle solution, miracle representation, miracle W, miracle knowledge); the paper would be clearer if only one “miracle X” was defined and used as these are all essentially saying the same thing.\n\nReferences\n[1]https://arxiv.org/abs/1803.02999\n[2]https://arxiv.org/abs/1801.05558\n\n', '[Summary]\nThe paper presents a novel learning framework for meta-learning that is motivated by neural learning process of human over long periods. Specifically, the process of meta-learning is divided into a slow and a fast learning modules, where the slowly-learnt component accounts for low-level representation that is progressively optimized over all data seen so far to achieve generalization power, and the fastly-learnt component is supposed to pick up the target in a new task for quick adaptation. It is proposed that meta-learning should focus on capturing the meta-information for the fast learning module, and leave the slow module being updated steadily without task-specific adaptation. Theoretical analysis is presented on a linear MLP examples to shed some light on the properties of the proposed algorithm. Results on both synthetic dataset and benchmarks justify the theoretical observation and advantages.               \n\nPros\nNovel treatment and formulation of meta-learning from the perspective of fast and slow  learning process\nCons\nSome interesting cases not tested\nPresentation could be improved \n\n[Originality]\nThe paper approaches the recently popular meta-learning from a novel perspective by decomposing the learning process into slow and fast ones. \n\n[Quality]\nOverall,  the paper is well motivated and implemented with both theoretical study and empirical justification. There are a few questions / areas for further improvements, though:\n- It seems that to initialize the slow module, another set of data is needed to pretrain it before the actual meta-learning takes place to learn to optimize the fast learner (as opposed to other meta-learning methods where all parameters in a base model were meta-learnt over the meta training set). How does this affect the performance? E.g., what if the slow module is only updated over the meta-training set (still without reinitialization across different batches) without pre-training?\n- In the current formulation, the base model is decomposed into two distinct (slow and fast) modules. What is the rule to decide which layers should belong to slow or fast modules? How does different choice affect the performance? Can we decompose the base model into finer granularities for different learning behaviors? E.g., a third module module in-between the fast and slow ones that follows medium learning pace.          \n- The theoretical study can be better organized. The proofs can be left in appendix to make room for more discussion on conclusions, non-linear and / or non-Gaussian cases.     \n- The write-up can be improved too at some places: proper reference at line 4 of section 1 is missing; \\phi in (1) is not well defined, as well as “SOA” in section 2;\n\n[Clarity]\nThe paper is generally clearly written, with a few places to improve (see comments above).\n\n[Significance]\nThe paper brings in an interesting perspective to meta-learning. It can also inspire more follow-up work to better understand the problem.   \n', 'The overall contribution makes sense. Consider solving a linear system i.e., learning an unknown matrix. Splitting it into two components (like in NMF or MMF) and learning each separately gives more control on the conditioning of the matrices. This is the basis of residual networks (at least the theory for linear resnets). Within this, the technical/theoretical results presented in the paper are sensible. Couple of issues: \n1) Where are we breaking the slow/fast learners in terms of the depth of the network? I.e., How many of the layers are slow? Does this break point influence the overall convergence? \n2) It is unclear what the aim of simulations is? The reported figures are not conveying useful information. It makes sense to do a repeatability experiment here with multiple sets of simulated datasets. \n3) Put confidence intervals on the results (table/figure). \n4) What is the nature and choice of g()? The evaluations uses LSTM but will the structure of g() influence the rate of learning? \n5) The authors should choose a better reference than miracle for the ']","[20, 60, 50]","[60, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear motivation, readability, and interesting ideas in the 'Strengths' section. However, they also point out several weaknesses and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement without using harsh or dismissive language. The reviewer maintains a professional tone, balancing positive feedback with areas of concern, and uses phrases like 'I am wondering' and 'it would have been nice' to soften their critiques."", ""The sentiment score is 60 (positive) because the review begins with a summary that highlights the novel aspects of the paper and its contributions. The reviewer mentions both pros and cons, but the pros outweigh the cons. The review acknowledges the paper's originality, quality, and significance, which are all positive aspects. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. The reviewer acknowledges the paper's strengths while politely pointing out areas for improvement, using phrases like 'can be better organized' and 'can be improved' instead of more negative language. The review maintains a professional and courteous tone throughout, even when discussing potential weaknesses in the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating 'The overall contribution makes sense' and describes the work as 'sensible'. However, they also list several issues, which tempers the positivity. The politeness score is 20 (slightly polite) as the reviewer uses neutral language and frames their criticisms as questions or suggestions ('Consider...', 'It makes sense to...') rather than direct criticisms. They also acknowledge the value of the work. However, the review is still primarily focused on improvements rather than praise, preventing a higher politeness score.""]"
"['This paper presents an algorithm for finding a polytope of adversarial examples. This means that within a convex hull, you can move around freely and get a new adversarial example at each point, while still maintaining misclassification. It then couples this with a method of generating nearest neighbor patch-based images in an effort to create ""macro-level different"" examples. The premise is interesting, but the implications are questionable and I do not find the work in macro-level differences to be sound. This could be based in misunderstandings, so please let me know if you think that is the case.\n\nStrengths:\n- The notion of the polytope is interesting and the algorithm for finding such polytope seems perfectly reasonable.\n- I think the goal of macro-level adversarial examples is interesting.\n\nWeaknesses:\n- First of all, the 5 corners of the polytope all look the same to me (for instance fig 2). This is not encouraging, because it means that every single point in the polytope will also look exactly like the corners. To be frank, this means the polytope is not that interesting and has only found an extremely small pocket of adversarial examples. If you use a regular method of finding a single adversarial example, I\'m sure the outcome wouldn\'t change within some ball around the sample (perhaps with very small radius, but nonetheless). In fact, a comparison between that ball\'s volume and the volume of the polytope would be interesting.\n- The implication of these polytopes is not at all clear if it doesn\'t really allow us to generate adversarial example of a new flavor. The investigation into macro-level differences does not help the case, as I will explain.\n- I am not at all convinced that there is any meaning to the examples with ""macro-level differences.""  It\'s a bit unclear to me how many patches are used per image, but assuming that a patch is centered over each pixel,  it would mean that we have as many control parameters as we have pixels, which assuming the pixels each have three color values, is just 1/3 of the original degrees of freedoms. Now, the patches probably do constrain what we can paint a bit, but since the patches are applied with a pyramid, it means the center pixel will contribute more than any other for a given patch, so I\'m not so sure. I\'m not convinced that we can\'t come up with linear combinations of these patches that produce highly non-natural images with ""micro-level"" adversarial patterns. In fact, I think section 4.1 and figure 7 provide evidence to the contrary. Let me explain:\n    - Section 4.1: Why do you need a total variation penalty at all if you have constructed a patch-based drawing method that is supposed to be unable to produce unnatural high-frequency patterns? If you only had a handful of patches and they were all non-overlapping, then this would be impressive and.\n    - Figure 7: We can clearly see high-frequency patterns that create the shadow of an obelisk in 7(a). I think the same is true for ""erase"", although the pattern is not as recognizable. The examples actually look more suspicious than regular adversarial examples, since it looks like the original image has simply been blurred, which means the adversarial perturbations are more clear. I understand that these patterns were created using a complicated scheme of natural patches, but I think you made this method too powerful. The one interesting quality is the bottom right of the trimaran which looks like a shark - however, that is a singular occurrence in your examples and it certainly feels like the high-frequency patterns will contribute much more to class than the shark itself.\n- Please let me know if I am misinterpreting the importance of the results in Figure 7, since this is an important culmination of this work.\n\nOther comments:\n- Some of notation is a bit confusing. In (1), why is p not bold but x and t are bold? They are all vectors. In Algorithm 1, x is not bold anymore.\n- Algorithm 1 also seems quite unnecessary to include so explicitly.\n- Isn\'t a bounded polytope called a ""simplex""? Perhaps there is a distinction that I\'m not aware of, but the absence of the word ""simplex"" throughout the whole paper surprised me a bit. Perhaps this is a perfectly correct omission due to differences that I\'m not aware of.\n\nMinor comments:\n- abstract, ""We propose a way to finding"" -> either ""to->""of"" or ""find""\n- page 3, ""and we can generate new colliding example"" -> ""a new colliding example""\n- page 3, ""taking arbitrary an convex combinations"" -> ""combination""\n- page 3, ""Given a target x"", I think you mean ""Given a target t""\n- page 5, ""As many gradient-based method"" -> ""methods""\n- page 8, ""carton""? ""rubber""? Those are not in figure 7(b).\n- page 10, ""are crucial to less non-robust"" ? This sentence (which is the final sentence of the conclusion and thus has a certain level of importance) is not something that is novel to your paper. The impact of non-linearities on adversarial examples have been well-studied.', 'This paper follow recent trend of adversarial examples which is on generating images with small differences in the input space, but that are misclassified by a large margin by a neural net. The key idea of the paper is that any negative component before a ReLU activation share the same zero feature after the ReLU. Thus, any neural network that has ReLU activations have a polytope in the input space that will have identical activations in the later layers. Based on this observation, the paper assert that such polytope always exist and describe how to find its corners with a gradient descent based method. Two simple experiments on MNIST and ImageNet datasets are carried to show the feasibility of the method in practice and the existence of images with feature collision, together with their average L2 distance from real images. Since the images are clearly not ""natural"" images, a further method based on selecting patches of real images is reported and tested on ImageNet. This shows that the approach can be further applied on macro-level differences.\n\nStrengths\n+ The observation of the existence of the polytope in presence of ReLU activation is interesting and can probably be used to further refine attacks for generating adversarial examples.\n+ The paper is clear and is comprehensive of all the basic steps.\n+ Examplar experiments show the possibility of using the key idea to generate adversarial examples\n\nWeaknesses:\n- The experiments are very limited and show just 5 examples of generated images on MNIST and ImageNet. In Sect 3.2 it is observed that it is hard for human eyes to notice the difference but that is clearly not the case for the figure reported. The same for Fig. 7 on the macro-level which are even more distorted. Although this is minor, since the method is still shown to be working, the statements on the similarity of images seem incorrect. Beside the qualitative examples, the measurement of average similarity based on L2 is not so indicative at the perception level, but still interesting to see.\n- No comparison with other methods to generate adversarial examples are reported (e.g. Shafani et al 2018, Szegedy et al. 2013).\n\nMinor issues:\n- Figure 2, Figure 3 show the results, but it would also be interesting to observe what happens from the starting image to the final generated images.    \n- Personally, I prefer to see related work after the introduction section. Reading it at the end breaks the flux of the paper.\n- The observation is only applicable to ReLU activations (but other activation functions may be in the last layer), limiting the impact of the paper.\n\n', ""This paper studies a non-local form of adversarial perturbation, which, to my limited knowledge is new. The form of the perturbation is specific to ReLU activations, but it may be a large set. The authors also devise an algorithm to generate natural-looking perturbations in this set. Instead of updating a seed example through gradient descent, they propose to generate perturbations by combinations of image patches from multiple seed images. The weights of the combination are optimized by a gradient descent like algorithm in a similar manner as standard gradient-based approaches to generating adversarial examples. This produces perturbations that look like ```in-paintings'' or transplants of one seed image onto another. Here are a few comments:\n\n1. The perturbation set is generally a high-dimensional polytope. Although it has a compact representation in terms of intersection of hyperplanes, it may have many more verticies, so the endeavor of attempting to characterize all the verticies of this polytope may be infeasible. \n\n2. This technique of generating adversarial examples from combinations of image patches seems generally applicable, but it does not seems to produce good results here. The perturbations are still unnatural looking (eg. the images in Figure 7 are not exactly natural looking).""]","[-50, 50, 20]","[20, 70, 50]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several weaknesses and questioning the implications and soundness of the work. However, it does acknowledge some strengths and interesting aspects, preventing it from being extremely negative. The politeness score is 20 because while the reviewer maintains a professional tone and uses phrases like 'please let me know' and 'I think,' there are also some blunt criticisms such as 'To be frank, this means the polytope is not that interesting.' The reviewer also offers constructive feedback and asks for clarification on potential misunderstandings, which adds to the politeness."", ""The sentiment score is 50 (slightly positive) because the review acknowledges both strengths and weaknesses of the paper. The reviewer praises the paper's interesting observation, clarity, and comprehensive approach, while also pointing out limitations in experiments and comparisons. The overall tone suggests the paper has merit but could be improved. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'interesting' and 'comprehensive' for positives, and soften criticisms with phrases like 'Although this is minor' and 'Personally, I prefer'. The review maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the paper's approach and provides a detailed summary of the work. However, the reviewer also points out some limitations, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents their comments in a constructive manner without harsh criticism. The phrase 'to my limited knowledge' shows humility, which contributes to the politeness. The reviewer provides specific, objective comments without using overly negative language, maintaining a professional and respectful tone throughout the review.""]"
"['The authors explore the possibility of using an end-to-end approach for predicting pharmacological assay outcome using fluorescence microscopy images from the public Cell Painting dataset. In my view, the primary contributions are the following: an interesting and relatively new application (predicting assay outcomes), enriching the CellPainting dataset with drug activity data, and a comparison of several relevant methods and architectures. The technical novelty is weak, and although the authors demonstrate that end-to-end holistic approaches outperform previous segmentation-and-feature-extraction approaches, this result is not surprising and has been previously reported in closely related contexts.\n\n\nOVERVIEW\n\nThe authors evaluate the possibility of using and end-to-end deep learning approach to predict drug activity using only image data as input. The authors repurpose the CellPainting dataset for activity prediction by adding activity data from online ChEMBL databases. If made available as promised, the dataset will be a valuable resource to the community. The authors compare a number of previous approaches and state-of-the-art image classification network architectures to evaluate the use of CNNs instead of more classical image analysis pipelines. The comparison is a strong point of the paper, although some details are lacking. For example, the authors claim that GapNet is the quickest method to train, and while they report the number of hyperparameters and time per epoch, the number of epochs trained is never mentioned. \n\nThe authors propose an architecture (GapNet) for the assay prediction task. While the way Global Average Pooling is used to extract features at different stages in the network might be new, it is a straightforward combination of GAP and skip connections. Little insight into why this approach is more efficient or evidence for its effectiveness is provided. Similarly, more explanation for why dilated convolutions and SELU activations would be appreciated. A comparison between GapNet and the same network without the GAP connections could possibly provide a more interesting comparison and might also provide a more pervasive argument as to why GapNet’s should be used. Ultimately, the benefit of using GapNet over the other architectures is not strongly motivated, as training time is less of a concern in this application than predictive power.\n\n\nRELATED WORK\n\nThe authors present previous work in a clear and comprehensive manner. However, the reported finding that “CNNs operating on full images containing hundreds of cells can perform significantly better at assay prediction than networks operating on a single-cell level” is not surprising, and partial evidence of this can be found in the literature. In [1], it was shown that penultimate feature activations from pre-trained CNNs applied to whole-image fluorescence microscopy data (MOA prediction) outperform the baseline segmentation-then-feature extraction method (FNN). Similarly, in [2] (the paper proposing MIL-Net), it is shown that end-to-end whole-image CNN learning for protein localization outperforms the baseline (FNN). In [3] whole image end-to-end learning outperforms whole image extracted features for a phenotyping task. All of these references use fluorescence microscopy data similar to the dataset in this work.\n\n[1] Pawlowski, Nick, et al. ""Automating morphological profiling with generic deep convolutional networks."" bioRxiv (2016): 085118.\n[2] Kraus, Oren Z., Jimmy Lei Ba, and Brendan J. Frey. ""Classifying and segmenting microscopy images with deep multiple instance learning."" Bioinformatics 32.12 (2016): i52-i59\n[3] Godinez, William J., et al. ""A multi-scale convolutional neural network for phenotyping high-content cellular images."" Bioinformatics 33.13 (2017): 2010-2019.\n\n\nAPPROACH\n\nThe authors compile enrich the CellPaining dataset with activity data from various drug discovery assays. In my view, the creation of this dataset is the strongest and most valuable contribution of the paper. The method used to collect the data is described clearly and the choices made when compiling the dataset, including the thresholds and combinations of activity measures seems like a well founded approach.\n\nThe authors then identify a number of approaches that are relevant for the problem at hand, binary prediction of drug activity based on image data. These include previous approaches used for cell images and modern image classification networks.\n\n\nEXPERIMENTS\n\nThe different approaches/networks mentioned above were evaluated on a testset. The results indicate that end-to-end CNN approaches outperform all non-end-to-end with no significant difference between the individual end-to-end CNNs. The results are stated clearly and the presentation of different metrics is a nice addition to properly compare the results. It would however contribute valuable information if the authors stated how the confidence intervals of the F1 score are calculated (are the experiments based on several runs of each network or how is it done).\n\n\nNOVELTY/IMPACT\n\n+ Creation of a new dataset on a new and interesting problem \n+ Useful comparison of modern networks on the task\n- GapNet - lacking technical novelty, insight, and performance is unconvincing\n- Demonstrates that end-to-end learning outperforms cell centric approach - was this really surprising or even new information?\n\n\nOTHER NOTES:\n* Figure 3 is never mentioned in the main text\n* Figure 3 (*’s) are confusing. Do they represent outliers? Statistical significance tests?\n* Figure 5 which panel is which?\n* Be clear what you mean when you refer to “upper layers” of a network\n* An important point not mentioned: in practice, many assays use stains that are closely tied to the readout, unlike the dataset here which provides only landmark stains. The results found here do not necessarily apply in other cases.\n', 'Edit: changed ""Clarity""\n\n[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? no\n\n[Novelty] Are the problems or approaches novel? no\n\n[Soundness] Is the paper technically sound? okay\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal\n\n[Clarity] Is the paper well-organized and clearly written? no\n\nConfidence: 3/5\n\nSeen submission posted elsewhere: No\n\nDetailed comments:\n\nIn this work, the authors compare several state-of-the-art approaches for high-resolution microscopy analysis to predicting coarse labels for the outcomes of pharmacological assays. They also propose a new convolutional architecture for the same problem. An empirical comparison on a large dataset suggests that end-to-end systems outperform those which first perform a cell segmentation step; the predictive performance (AUC) of almost all the end-to-end systems is statistically indistinguishable.\n\n=== Major comments\n\nThe paper is primarily written as though its main contribution is as an empirical evaluation of different microscopy analysis approaches. Recently, there have been a large number of proposed approaches, and I believe a neutral evaluation of these approaches on datasets other than those used by the respective authors would be a meaningful contribution. However, the current paper has two major shortcomings that prevent it from fulfilling such a place.\n\nFirst, the authors propose a novel approach and include it in the evaluation. This undercuts claims of neutrality. (Minor comments about the proposed approach are given below.) \n\nSecond, the discussion of the results of the empirical evaluation is restricted almost solely to repeating in text the what the tables already show. Further, the discussion focuses only on the “top line” numbers, with the exception of a deep look at the Gametocytocidal compounds screen. It would be helpful to instead (or additionally) identify meaningful trends, supported by the data acquired during the experiments. For example: (1) Do the end-to-end systems perform well on the same assays? (2) Would a simple ensemble approach improve things? if they perform well on different assays, then that suggests it might. (3) What are the characteristics of the assays on which the CNN-based approaches perform well or poorly (i.e., how representative is Figure 5)? (4) What happens when the FNN-based approach outperforms the CNN-based ones? in particular, what happens in A13? (5) How sensitive are the approaches to the number of labeled examples of each assay type? (6) Are there particular compounds which seem particularly informative for different assays?\n\nA second major concern is whether the binarized version of this problem (i.e., assay result prediction) is of interest to practitioners. In many contexts, quantitative information is also important (“how much of a response do we see?”). While one could imagine the rough qualitative predictions (“do we see a response?”) shown here as an initial filtering step, it is hard to believe that the approach proposed here would replace other more informative analysis approaches.  \n\n=== Minor comments\n\nAre individual images from the same sample image always in only the training, validation, or testing set? that is, are there cases where some of the individual images from a particular sample image are in the training set, while others from that sample image are in the testing set?\n\nI did not find the dataset construction description very clear. Does each row in the final, 10 574 x 209 matrix correspond to a single image? Does each image correspond to a single row? For example, it seems as though multiple rows may correspond to the same image (up to four? the three pChEMBL thresholds as well as the activity comment). What is the order in which the filtering and augmenting happens? It would be very helpful to provide a coherent, pipeline description of this (say, in an appendix).\n\nDo all the images in the dataset come from the same microscope (and cell line) at the same resolution, zoom, etc.? If so, it is unclear how well this approach may work for images which are more heterogeneous. There are not very many datasets of the size described (I believe, at least) available. This may significantly limit the practical impact of this work.\n\nHow many epochs are required for convergence of the different architectures? For example, MIL-net has significantly fewer parameters than the others; does it converge on the validation set faster?\n\n=== Typos, etc.\n\nThe references are not consistently formatted.\n\n“not loosing” -> “not losing”\n“doesn’t” -> “does not”\n', 'The paper is well written, deals with a valid and crucial end-to-end imaging problem. \n\nComments\n1) Section 2: It is not clear how 10574 compounds increase to 11585 (2nd paragraph page 3). Also how does one arrive at 11171 compounds (para 3). \n2) How do you arrive at 209 assays from 10818?\nDo consider enumerating this Section: data dimensions you started with and then how the dimensions were reduced per step. I gather you have mentioned this but it is confusing to grasp, at this point. \n\n3) In page 2, you mention the images have 5 channels but towards the end of the section on page 3, it says 1) views have ‘6’ such images per sample image and 2) 4 channels for stains. How many stains are there per channel and how are 5 channels related to the ‘6’ and 4 channels? \n\n4) In Section 4 and Appendix 6, it does not seem that Gapnet outperforms, rather it is at par to, other architectures. Is the only gain with Gapnet the runtime across epochs?']","[-20, -40, 50]","[50, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'interesting application', 'valuable resource', 'strong point of the paper'), they also point out several weaknesses (e.g., 'technical novelty is weak', 'little insight', 'benefit... is not strongly motivated'). The overall tone suggests that the reviewer sees more areas for improvement than strengths in the paper. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'in my view' and 'it would contribute valuable information if' which soften criticism. The reviewer also balances negative points with positive ones and provides constructive feedback, which contributes to the polite tone. However, the review is not overly effusive or deferential, maintaining a neutral professional tone in many parts, which is why the score is not higher."", ""The sentiment score is -40 because the review is generally critical, pointing out major shortcomings and concerns about the paper's contribution. The reviewer states that the paper has 'two major shortcomings' and expresses doubt about its practical impact. However, it's not entirely negative as the reviewer acknowledges some potential value in the work, hence not a lower score. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'it would be helpful' and offer constructive suggestions for improvement. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'well written' and dealing with a 'valid and crucial' problem, which is positive. However, the rest of the review consists of questions and suggestions for improvement, indicating some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'Do consider' and the use of questions to seek clarification contribute to the polite tone. The reviewer also acknowledges the authors' efforts ('I gather you have mentioned this') while suggesting improvements.""]"
"['The idea proposed in this paper is to improve classification accuracy by making use of the context.\nE.g. on the north pole we will see polar bears but no penguins, on Antartica we have no polar bears but many penguins.\nHence, if we apply our imagenet-like classifier in the wild, we can improve accuracy by taking into account changes in the prior distribution.\n\nThe paper proposes a way to rescale the probabilities to do exactly this and reports improved results on modified versions of \n CIFAR 10 and imagenet with artificial class skew. To achieve this, an additional trick is introduced where the re-scaling is only used when the model is not very certain of its prediction. And additional motivation for this work is that less compute resources are needed if the problem is simplified by utilizing class skew. \n\nThe core idea of the paper is interesting. However, I am not able to understand what exactly is done and I am 100% confident I cannot re-implement it. The authors already improved upon this in our interactions prior to the review deadline. \nAn additional issue is that the paper does not have a good baseline. \nI would not like to dismiss the approach based on its simplicity. An elegant solution is always preferred. However, all the tasks are quite artificial and this limits the ""impact"" of this work. If an ""natural"" application/evaluation where this approach would be possible, it would strengthen the paper greatly. \n\nFor the reasons above I recommend rejection of the manuscript in the current state but I am confident that many of these issues can be resolved easily and if this is done I will update the review.\n\nMissing information\n----------------------------\n- The original manuscript had a lot of information missing, but much of it has since been provided by the authors.\n- In the static class skew experiment, were two passes over the data needed? Or was the Pt(i) pre-set? Would it also be possible to give details about LR, optimizer, LR schedule, batch size, .... for the transfer learning experiments. This would enhance reproducibility. \n- For the imagenet experiments how was Pt(i) set in the if I assume correctly, static setting.\n\nPossible additional baselines:\n-----------------------------------------\n\nWe could make a simpler rescaling by changing the prior distribution and assuming everything else remains constant.\nWhile this is a simplifying assumption, it is very easy to implement and should take only a couple of minutes to run. \nP(i|x)=1/P(X)*P(X|i)*P(i)\nPt(i|x)=P(i|x)*Pt(i)/P(i)\n\nOne could also introduce another baseline where only the most probably classes are considered. Since this approach is clearly sub-optimal since it guarantees some mis-predictions it should serve as a lower bound on the performance that is to be expected. \n', 'This paper proposed a way to detect a skew in the distribution of classes in a stream of images and reweight the class priors accordingly, to estimate the final posterior probabilities of present classes. This probability re-calibration is referred to as the probability layer. A simple algorithm is proposed to detect the class distribution skew. The proposed benefit of this method is that they do not require fine-tuning any network parameters using newly skewed data. \n\nOverall the method is quite simple and heuristic. The technical contribution - i) updating class priors online ii) detecting class skews, is marginal. \n\nThe evaluation is performed on a contrived setting of skewed imagenet images. I would have liked to see some evaluation on video stream data where the skews are more natural. \n\nIn real scenarios, the class specific appearances P_{X|Y}(x|i) as well as class distributions P_Y(i) change online. The method seems incapable to handle such problems.  In these situations, there is no simple fix, and one needs to resort to transfer.\n ', 'The paper proposes a simple idea to calibrate probabilities outputted by a CNN model to adapt easily to environments where class distributions change with space and time (and are often skewed). The paper shows that such a simple approach is sufficient to get good accuracies without requiring any costly retraining or transfer learning. Thereby proving to give benefits in terms of resource consumption and at the same time giving better results than the state of the art.\n\nHowever, \nA] The proposed calibration doesn\'t take any CNN specific details into consideration, rather it is a general calibration method which was also proposed in Saerens et. al, 2002 (cited in the paper). It is unclear why the paper specifically talks about CNN.\nB] The proposed Class Skew Detector is a simple method. Change-point detection is a well-studied area. The paper lacks a literature review in this area and a reasoning of why the proposed approach is preferred. Also, an independent analysis of how the class skew detector behaves in the face of rapidly changing class skews versus slow changing class skews is warranted here. Particularly, given that the paper proposes to use this approaches in mobile which may work in both rapid and slow changing class skews.\nC] The Class Skew Detector is dependent on the base model. Thus, it is also likely that the empirical distribution estimated is biased and yet the final accuracies reported are much higher than the base model accuracies. There is something interesting happening here. An analysis of the robustness of the proposed approach in the face of noisy class skew detection could potentially make this paper a stronger work.\nD] The analysis in the paper has largely focused on pre-trained models. However, another analysis that could have been useful here is, varying the quality of the classifier (e.g. classifier trained on skewed training data vs. balanced training data) and measuring how the quality of the classifier correlates with the final performance. Maybe even attempt to answer the question ""which classifiers are likely to work with this approach?"" In fact, this analysis can be either done in a general context of any classifier or just CNN\'s and identifying whether certain properties of CNN help in getting better performance.\n\nThe paper lacks novelty and at the same time, it is not quite compensating that with a detailed analysis of the work. The problem is interesting and I like the work because the approach is simple and the results look good. I think with a stronger focus on more detailed analysis, this can be a good submission to an applied conference like MobiCom etc.\n\nBy the way, the paper is riddled with several spelling errors - \n""filed"" -> ""field"", page 1, second paragraph, last line\n""complimentary"" -> ""complementary"", page 2, section 2, paragraph 1, last line\n""epoches"" -> ""epochs"", page 2, section 2, transfer learning, second paragraph, second last line\n""CNNs does not use"" -> ""CNNs do not use"", page 3, section 3, intuition, first paragraph, first line\n""formular"" -> ""formula"", page 4, above equation 4\nEquation 4 has a typo in the denominator, P_t(i) should be P_t(j), same with Equation 5\n""obstained"" -> ""obtained"", page 7, second paragraph, first line\n""adaptation"" is almost everywhere spelled as ""adaption""']","[-30, -30, -20]","[50, 20, 60]","[""The sentiment score is -30 because while the reviewer acknowledges the core idea as interesting, they recommend rejection due to several issues. The overall tone is critical but not entirely negative, as they express confidence that many issues can be resolved. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and offers constructive feedback. They avoid harsh criticism and use phrases like 'I would not like to dismiss the approach' and 'I am confident that many of these issues can be resolved easily', which maintain a polite tone even while pointing out shortcomings."", ""The sentiment score is -30 because the review is slightly negative overall. While the reviewer acknowledges the proposed method, they describe it as 'quite simple and heuristic' and the technical contribution as 'marginal'. They also point out limitations of the method and express a desire for more comprehensive evaluation. However, it's not entirely negative, as they do describe the method objectively at first. The politeness score is 20 because the language is generally professional and neutral, without any overtly rude comments. The reviewer offers constructive criticism and suggestions for improvement, which is polite in academic contexts. However, the directness of some criticisms ('quite simple', 'marginal') prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('simple approach', 'good accuracies', 'benefits in terms of resource consumption'), they also point out several significant shortcomings (lack of novelty, insufficient analysis, and multiple areas for improvement). The overall tone suggests that the paper needs substantial work to be considered a strong submission. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the interesting aspects of the work, and provides constructive feedback. They use phrases like 'I like the work' and offer specific suggestions for improvement rather than harsh criticism. The reviewer also politely points out spelling errors at the end, which is helpful without being overly critical.""]"
"['This work aims to use formal languages to add a reward shaping signal in the form of a penalty on the system when constraints are violated. There is also an interesting notion of using an embedding based on the action history to aid the agent in avoiding violations. However, I do not believe this paper did a good enough job in situating this work in the context of prior work — in particular (Camacho 2017). There is a significant related work section that does an ok job of describing many other works, but to my knowledge (Camacho 2017) is the most similar to this one (minus the embedding), yet is not mentioned here. It is difficult to find all related work of course, so I would encourage revision with detailed description of the novelty of this work in comparison with that one. I would also encourage an more thoughtful examination of the theoretical ramifications of the reward shaping signal with respect to the optimal policy as (Camacho 2017) do and as is modeled in the (Ng 1999) paper. As of this revision, however, I\'m not sure I would recommend it for publication. Additionally, I suggest that the authors describe the reward shaping mechanism a bit more formally, it was unclear whether it fits into Ng\'s potential function methodology at first pass.\n\nComments:\n\n+ It would be nice to explain to the reader in intuitive terms what “no-1D-dithering” means near this text. I understand that later on this is explained, but for clarity it would be good to have a short explanation during the first mentioning of this term as well.\n+ It would be good to clarify in Figure 1 what . * (lr)^2 is since in the main text near the figure is is just (lr)^2 and the .* is only explained several pages ahead\n+ An interesting connection that might be made is that Ng et al.’s reward shaping mechanism, if the\xa0shaping function is based on a state-dependent potential then the optimal policy under the new MDP is still optimal for the old MDP. It would be interesting to see how well this holds under this holds under this schema. In fact, this seems like analysis that several other works have done for a very similar problem (see below).\n+ I have concerns about the novelty of this method. It seems rather similar to \n\nCamacho, Alberto, Oscar Chen, Scott Sanner, and Sheila A. McIlraith. ""Decision-making with non-markovian rewards: From LTL to automata-based reward shaping."" In\xa0Proceedings of the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), pp. 279-283. 2017.\nCamacho, Alberto, Oscar Chen, Scott Sanner, and Sheila A. McIlraith. ""Non-Markovian Rewards Expressed in LTL: Guiding Search Via Reward Shaping."" In Proceedings of the Tenth International Symposium on Combinatorial Search (SoCS), pp. 159-160. 2017.\n\nHowever, that work proposes a similar framework in a much more formal way. In fact, in that work also a DFA is used as a reward shaping signal -- from what I can tell for the same purpose through a similar mechanism. It is possible, however, that I missed something which contrasts the two works.\n\nAnother work that can be referenced:\n\nDe Giacomo, Giuseppe, Luca Iocchi, Marco Favorito, and Fabio Patrizi. ""Reinforcement Learning for LTLf/LDLf Goals.""\xa0arXiv preprint arXiv:1807.06333\xa0(2018).\n\nI think it is particularly important to situate this work within the context of those others. \n\n+ General the structure of the paper was a bit all over the place, crucial details were spread throughout and it took me a couple of passes to put things together. For example, it wasn\'t quite clear what the reward shaping mechanism was until I saw the -1000 and then had to go back to figure out that basically -1000 is added to the reward if the constraint is violated. I would suggest putting relevant details all in one place. For example, ""Our reward shaping function F(x) was  { -1000, constraint violation, 0 otherwise}"". ', ""This paper presents an approach for biasing an agent to avoid particular action sequences. These action sequence constraints are defined with a deterministic finite state automaton (DFA). The agent is given an additional shaping reward that penalizes it for violating these constraints. To make this an easier learning problem for the agent, its state is augmented with additional information: either an action history, the state of the DFA, or an embedding of the DFA state. The authors show that these approaches do reduce these action constraint violations over not doing anything about them.\n\nIt's unclear to me what the use case is for constraints solely on the action space of the agent, and why it would be useful to treat them this way. The authors motivate and demonstrate these constraints on 3 Atari games, but it is clear that the constraints they come up with negatively affect performance on most of the games, so they are not improving performance or safety of the agent. Are there useful constraints that only need to view the sequence of actions of the agent and not any of the state?  If there are such constraints, why not simply restrict the agent to only take the valid actions? What is the benefit of only biasing it to avoid violating those constraints with a shaping reward? This restriction was applied during testing, but not during training. \n\nIn all but the first task (no 1-d dithering in breakout), none of the proposed approaches were able to completely eliminate constraint violations. Why was this? If these are really constraints on the action sequence, isn't this showing that the algorithm does not work for the problem you are trying to solve? \n\nThe shaping reward used for the four Atari games is -1000. In most work on DQN in Atari, the game rewards are clipped to be between -1 and 1 to improve stability of the learning algorithm. Were the Atari rewards clipped or unclipped in this case? Did having the shaping reward be such large magnitude have any adverse effects on learning performance?\n\nAdding a shaping reward for some desired behavior of an agent is straightforward. The more novel part of this work is in augmenting the state of the agent with the state of a DFA that is tracking the action sequence for constraint violations. Three approaches are compared and it does appear that DFA one-hot is better than the other approaches or no augmentation.\n\nPros:\n- Augmenting agent state with state of DFA tracking action sequence constraints is novel and useful for this problem\nCons:\n- Unclear if constraints on action sequences alone useful\n- No clear benefit of addressing this problem through shaping rewards.\n- No comparison to simply training with only non-violating action sequences.\n- Algorithm still results in action constraint violations in 5/6 tasks. "", 'This paper presents an DFA-based approach to constrain certain behavior of RL agents, where ""behavior"" is defined by a sequence of actions. This approach assumes that the developer has knowledge of what are good/bad behavior for a specific task and that the behavior can be checked by hand-coded DFAs or PDAs. During training, whenever such behavior is detected, the agent is given a negative reward, and the RL state is augmented with the DFA state. The authors experimented with different state augmentation methods (e.g. one-hot encoding, learned embedding) on 3 Atari tasks.\n\nThe paper is clearly written. I also like the general direction of biasing the agent\'s exploration away from undesirable regions (or conversely, towards desired regions) with prior knowledge. However, I find the results hard to read.\n\n1. Goal. The goal of this work is unclear. Is it to avoid disastrous states during exploration / training, or to inject prior knowledge into the agent to speed up learning, or to balance trade-offs between constraint violation and reward optimization? It seems the authors are trying to do a bit of everything, but then the evaluation is insufficient. For example, when there are trade-offs between violation and rewards, we expect to see trade-off curves instead of single points for comparison. Without the trade-off, I suppose adding the constraint should speed up learning, in which case learning curves should be shown.\n\n2. Interpreting the results. 1) What is the reward function used? I suppose the penalty should have a large effect on the results, which can be tuned to generate a trade-off curve. 2) Why not try to add the enforcer during training? A slightly more complex baseline would be to enforce with probability (1-\\epsilon) to control the trade-off. 3) Except for Fig 3 right and Fig 4 left, the constraints doesn\'t seem to affect the results much (judging from the results of vanilla DQN and DQN+enforcer) - are these the best settings to test the approach?\n\nOverall, an interesting and novel idea, but results are a bit lacking.']","[-50, -40, -20]","[50, 20, 60]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and its positioning within existing literature. They state, 'I'm not sure I would recommend it for publication,' which is a clear negative sentiment. However, they also acknowledge some positive aspects like the 'interesting notion' of using embeddings, so it's not entirely negative. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I would encourage' and 'It would be nice to explain,' which are polite ways of giving feedback. The reviewer also acknowledges the difficulty in finding all related work, showing empathy. While critical, the tone remains professional and courteous throughout."", ""The sentiment score is -40 because the review is generally critical of the paper, pointing out several issues and limitations. The reviewer questions the usefulness of the approach, highlights that the algorithm doesn't fully solve the stated problem, and lists more cons than pros. However, it's not entirely negative as it acknowledges some novel aspects of the work. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism. They phrase concerns as questions rather than direct criticisms (e.g., 'It's unclear to me...', 'Why was this?'). The reviewer also acknowledges positive aspects ('is novel and useful') alongside the criticisms, maintaining a balanced tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'clearly written' and likes the 'general direction', they express several criticisms and state that the 'results are a bit lacking'. The overall tone suggests the reviewer sees potential in the work but has significant reservations. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balancing criticism with praise ('interesting and novel idea'), and frames concerns as suggestions for improvement rather than harsh criticisms. The reviewer also uses phrases like 'I find' and 'I suppose' to soften their critiques, maintaining a collegial tone.""]"
"['This paper presents an end to end rl approach for hierarchical text classification. The paper proposes a label assignment policy for determining the appropropriate positioning of a document in a hierarchy. It is based on capturing the global hierachical structure during training and prediction phases as against most methods which either exploit the local information or neural net approaches which ignore the hierarchical structure. It is demonstrated the method particularly works well compared to sota methods especially for macro-f1 measure which captures the label weighted performance. The approach seems original, and a detailed experimental analysis is carried out on various datasets. \n\nSome of the concerns that I have regarding this work are :\n - The problem of hierarchical text classification is too specific, and in this regard the impact of the work seems quite limited. \n - The significance is further limited by the scale of the datasets of considered in this paper. The paper needs to evaluate against on much bigger datasets such as LSHTC datasets http://lshtc.iit.demokritos.gr/. For instance, the dataset available under LSHTC3 is in the raw format, and it would be really competitive to evaluate this method against other such as Flat SVM, and HRSVM[4] on this dataset, and those from the challenge.\n- The experimental evaluation seems less convincing such as the results for HRSVM for RCV1 dataset are quite different in this paper, and that given HRSVM paper. It is 81.66/56.56 vs 72.8/38.6 reported in this paper. Given that  81.66/56.56 is not too far from that given by HiLAP, it remains a question if the extra computational complexity, and lack of scalability (?) of the proposed method is really a significant advantage over existing methods.\n - Some of the references related to taxonomy adaptation, such as [3] and reference therein,  which are also based on modifying the given taxonomy for better classification are missing.\n - Comparison with label embedding methods such as [1,2] are missing. For the scale of datasets discussed, where SVM based methods seem to be working well, it is possible that approaches [1,2] which can exploit label correlations can do even better.\n[1] K. Bhatia, H. Jain, P. Kar, M. Varma, and P. Jain, Sparse Local Embeddings for Extreme Multi-label Classification, in NIPS, 2015.\n[2]  H. Yu, P. Jain, P. Kar, and I. Dhillon, Large-scale Multi-label Learning with Missing Labels, in ICML, 2014.\n[3] Learning Taxonomy Adaptation in Large-scale Classification, JMLR 2016.\n[4] Recursive regularization for large-scale classification with hierarchical and graphical dependencies, https://dl.acm.org/citation.cfm?id=2487644', 'This work proposes an RL approach for hierarchical text classification by learning to navigating the hierarchy given a document. Experiments on 3 datasets show better performance. I\'m happy to see that it was possible to \n\n1. ""we optimize the holistic metrics over the hierarchy by providing the policy network with holistic rewards""\n\nI don\'t quite understand what are the ""holistic metrics"" and ""holistic rewards"". I would like the authors to answer ""what exactly does reinforcement learning get us ?""\n - Is it optimizing F1 metric or is it the ability to fix inconsistent labeling problem ? \n- If it is the latter, what is an example of inconsistent labeling, what fraction of errors (in table 2/3) are inconsistent errors. Are we really seeing the inconsistent errors drop ?\n- If it is the former, how does this compare to existing approaches for optimizing F1 metric.\n\n2. ""the F1 score of each sample xi""\n\na. F1 is a population metric, what does it mean to have F1 for a single sample ?\nb. I\'m not aware of any work that shows optimizing per-example f_1 minimizes f_1 metric over a sample.\n\n3. with 10 roll-outs per training sample, imho, it seems unrealistic that the expected reward can be computed correctly. Would\'nt most of the reward just be zero ? Or is it the case the model is initialized with an MLE pretrained parameters (which seems like it, but im not too sure).\n\nResults analysis,\n- imho, most of the rows in Table 2 does not seem comparable with each other due to pretrained word-embeddings and dataset filtering, e.g. SVM-variants, HLSTM.\n- in addition to above, there is the standard issue of using different #parameters across models which increases/decreases model capacity. This is ok as long as all parameters were tuned on held out set, or using a common well established unfiltered test set - neither of which is clear to me.\n- it is not clear how the F1 metric captures inconsistent labeling, which seems to be the main selling point for hi-lap. \n\nside comment\n- reg textcnn performance, could it be that dropout is too high ? (the code was set to 0.5)\n   ', 'This papers uses the label hierarchy to drive the search process over a set of labels using reinforcement learning. The approach offers clever and promising techniques to force the inference process in structured classification to converge, but experiments seem to lack apple-to-apple comparisons.\n\nHowever, I think the authors should rather present this work as structured classification, as labels dependencies not modeled by the hierarchy are exploited, and as other graph structure could be exploited to drive the RL search.\nI tend to see hierarchical classification as an approach to multi-label classification justified by a greedy decomposition that reduced both training and test time. This view has been outmoded for more than an decade, first as flat approaches became feasible, and now as end-to-end  structured classification is implementable with DNNs (see for instance David Belanger work with McCallum)\n\nCompared to other structured classification approaches whose scope is limited by the complexity of the inference process, this approaches is very attractive. The authors open the optimization black box of the inference process by adding a few very clever tricks that facilitate convergence:\n- Intermediate rewards based on the gain on F1 score\n- Self critical training approach\n- ""Clamped"" pre-training enabled by the use of state embeddings that are multiplied my a transition to any state in the free mode, and just the next states in the hierarchy in the clamped mode\n- Addition of a flat loss to improve the quality of the document representation\n\nWhile those tricks may have been used for other applications, they seem new in the context of hierarchical/multi-label/structured classification.\n\nWhile the experiments appear thorough, they could be the major weakness of this paper. The results the authors quote as representative of other approaches seem in fact entirely reproduced on datasets that were not used on the original papers, and the authors do not try an apple-to-apple comparison to determine if this \'reproduction\' is fair. None of the quoted work used the 2018 version of Yelp, and I could only find RCV1 Micro-F1 experiments in Johnson and Yang, who report a 84% micro-F1, far better than the 76.6% reported on their behalf here, and better than the 82.7% reported  by the authors. I read note 4 about the difference in the way the threshold is computed, but I doubt it can explain such a large difference. I did not check everything, but could not find and apple-to-apple comparison?\n\nHave the network architecture been properly optimized in terms of hyper-parameters?\nIn particular, having tried Kim CNN on large label sets, I suspect the author settings using a single layer after the convolution is sub-optimal. I concur with the following paper than an additional hidden layer is essential: Liu et al ""Deep Learning for Extreme Multi-label Text Classification"". I also note the 32 batch size could be way too small for sparse label sets (I tend to use a batch size of 512 on this type of data).']","[20, -20, 20]","[60, 60, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the originality of the approach and the detailed experimental analysis. However, they also express several concerns, which temper the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, presenting their concerns as suggestions for improvement rather than harsh criticisms. They use phrases like 'Some of the concerns that I have' and 'It remains a question', which maintain a polite tone while expressing critiques. The reviewer also acknowledges the potential of the work and provides specific suggestions for improvement, which contributes to the polite and constructive nature of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I'm happy to see...'), they raise several significant concerns and questions about the methodology, results, and clarity of the paper. The overall tone suggests skepticism about some of the claims and approaches used.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like the authors to answer' and 'imho' (in my humble opinion), which soften their criticisms. The reviewer also frames their points as questions or requests for clarification rather than direct criticisms.\n\nHowever, the review is not overly effusive or deferential, maintaining a balance between politeness and critical analysis. The reviewer directly points out issues and areas needing improvement, but does so in a constructive manner without using harsh or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'clever and promising techniques' and finds the approach 'very attractive'. However, they also point out significant weaknesses, particularly in the experiments section, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I think the authors should' and 'I tend to see' which maintain a polite tone while expressing disagreement. The reviewer also acknowledges the novelty and potential of the work, which contributes to the polite tone.""]"
"['I feel like I am missing something about this paper, so rather than a review, this is just mainly a long question making sure I understand things properly.  Ignore the score for now, I\'ll change once I get a clearer picture of what\'s happening here.\n\nThe network you propose in this paper is motivated by solving PDEs where, as in (1), the actual solution as they are computed numerically depends on the current spatial field of the state, as well as difference operators over this field (e.g., both the gradients and the Laplacian terms).  So, I naturally was assuming that you\'d be designing a network that actually represented state as a spatial field, and used these difference operators in computing the next state.  But instead, it seems like you reverted to the notion of ""because difference operators can be expressed as convolutions, we use a convolutional network"", and I don\'t really see anything specific to PDEs thereafter, just general statements about state-space models.\n\nAm I understanding this correctly?  Why not just actually use the PDE-based terms in the dynamics model of an architecture?  Why bother with a generic ResNet? (And I presume you\'re using a fully convolutional ResNet here?)  Wouldn\'t the former work much better, and be a significantly more interesting contribution that just applying a ResNet and a generic U-Net as a state estimator?  I\'m not understanding why the current proposed architecture (assuming I understand it correctly) could be seen as ""PDE guided"" in all but the loosest possible sense.  Can you correct me if I\'m misunderstanding some element here?', ""+ An interesting idea to learn the hidden state evolution and the state-observation mapping jointly\n+ The experiments on Euler's equation are slightly better than ResNet for 30 steps ahead forecasting in terms of MSE\n+ The paper is clearly written and well-explained\n\n- The model is not new: ResNet for state evolution and  Conv-Deconv for state-observation mapping\n- The difference between ResNet and the proposed framework is not significant, ResNet is even better in Figure 2\n- Missing an important experiment:  test whether the model can generalize, that is to forecast on different initial conditions than the training dataset\n- How does the model compare with GANs (Y. Xie* , E. Franz* and M. Chu* and N. Thuereyy, “tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow”)?\n"", ""I very much like the aim of this work. This is a problem of interest to a wide community, which as far as I'm aware hasn't yet had much focus from the deep learning community. However, perhaps in part because of this, the paper reads as naive in places. Pages 1-4 are all background saying nothing new, but ignoring the effort made on this problem by other communities. There has been some work done o this problem within statistics, and within the Gaussian process community, to which no reference is made at all by the paper.\n\nThere are two novelties as far as I can see (these may or may not be novel - but they were novel to me). The first is use of NNs to model the system. The second is the multiple state restimation (MRSE) on page 5. I struggled to get a feeling about how successful these two aspects of the work are. The results section is difficult to follow, and doesn't compare the method to existing methods and so there is no baseline to say that this is successful or not. Thus I find it hard to judge the execution of the idea. What I really want to know reading a paper like this is should I use this approach? Because there is no comparison to existing methods, it leaves me unsure.\n\nOther comments:\n- Is the title correct? I don't see how these are PDE guided NNs? You've used data from a PDE to train the network and as a test problem. A PDE guided NN would, for me, know something about the dynamics (compare with recently work in the GP community where kernels are derived that lead to GPs that analytically obey simple PDEs). \n- There is an obvious link to work in the uncertainty quantification community, particularly around the use of multi-fidelity/ multi-level simulation. This paper is likely to be of interest to them and the link could be more explicit.\n- Page 3, after eq 2 - there is notation used here that is undefined Y_{t-k}^t\n- The simplifying assumption on page 3 is very strong and unlikely to hold for many systems. But it isn't clear to me whether this is necessary or not? Presumably if it doesn't hold then we may still get an approximation that could be useful, but it is just that we lose any guarantee the method will work.\n- I thought the MSRE idea was interesting. It wasn't very well explained or motivated, and it was unclear to me whether it works well or not from the results, or whether it is novel to this paper or not. But I'd like to have read more about it.\n- Is the trick in Section 8.2 original to this paper? If so, it seems a nice idea (I've not checked the detail). \n- Most of section 8.1 strikes me as unnecessary.\n- There are quite a few typos. In particular, words such as Markovian, Newtonian should be capitalised. \n""]","[-50, 20, -20]","[50, 50, 50]","[""The sentiment score is -50 because the reviewer expresses confusion and skepticism about the paper's approach, suggesting they are 'missing something' and questioning the novelty and appropriateness of the methods used. However, it's not entirely negative as they are open to clarification. The politeness score is 50 because the reviewer frames their critique as questions and personal understanding rather than direct criticism. They use phrases like 'Am I understanding this correctly?' and 'Can you correct me if I'm misunderstanding', which maintain a respectful tone. The reviewer also acknowledges their potential misunderstanding, which adds to the politeness. However, the questioning of the paper's contribution and methods prevents it from being extremely polite."", ""The sentiment score is slightly positive (20) because the review starts with positive points, acknowledging the interesting idea and slightly better performance in some experiments. However, it also includes significant criticisms, which balance out the positives. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both positive and negative points in a professional manner without harsh criticism. The review is structured with clear '+' and '-' points, which is a polite way to provide feedback. The language used is objective and constructive, avoiding personal attacks or overly negative phrasing."", ""The sentiment score is slightly negative (-20) because while the reviewer starts by saying they 'very much like the aim of this work', they go on to express several criticisms. They describe the paper as 'naive in places', mention that it ignores existing work in the field, and state that the results section is 'difficult to follow'. The reviewer also expresses uncertainty about the novelty and effectiveness of the method. However, the criticism is balanced with some positive comments and interest in certain aspects of the work, hence the score is only slightly negative rather than strongly negative. The politeness score is moderately positive (50) because the reviewer uses polite language throughout, even when criticizing. They use phrases like 'I struggled to get a feeling about...', 'I find it hard to judge...', and 'What I really want to know...' rather than making blunt criticisms. They also express interest in certain aspects of the work, which adds to the politeness. The reviewer provides constructive feedback and suggestions, which is a polite way to offer criticism.""]"
"['## Strength\n\nThis paper explores ways of identifying prototypes with extensive qualitative and quantitative empirical attempts. \n\n## Weakness\n\n### Not practical\n\nThe authors report that “removing individual training examples did not have a measurable impact on model performance”. However, this seems not to be supported by experiments.\nFirst, it is not clear what exactly models do they use in Section 4, e.g. ResnetV2 with how many layers? Learning rate schedules? \nSecond, why is the baseline models on CIFAR-10 perform so bad (<90%) even with 100% data?\nThird, with `""adv"" metric, we need to perform adversarial-example attacks before training, which has little value in practice. \n\n### Datasets\n\nThey only conduct quantitative experiments (section 4) on relatively small datasets (i.e. MNIST, Fashion-MNIST and CIFAR-10). It is not clear how it will generalize to more realistic settings. \n\n## Most confusing typos\n\n1. Section 4, paragraph 5, ""However, we find that training only on the most prototypical examples gives extremely high accuracy on the other prototypical examples."" Is there a missing ""than""? It\'s confused.\n2. The description of Figure 6 is not clear enough. Especially there is no explanation to (d, e, f). \n', 'Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics. While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable. I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them. \n\nPros:\n1. Novel attempt at understanding prototypes. Two specific contributions: a) outlining the properties desirable in prototypicality metrics b) proposing new prototypicality metrics and demonstrating the relevance of the various prototypicality metrics. \n2. Detailed experimental analysis along with some user studies\n\nCons:\n1. An important drawback of this paper is that the notion of prototype is not very clearly contextualized and explained. There is often a purpose associated with identifying prototypes - are we summarizing a dataset? are we thinking about helping humans understand the behavior of a specific learning model? Answers to these questions guide the process of choosing prototypes. However, this paper seems to approach the problem of choosing prototypes via the ""one approach fits all"" strategy which I am not sure is even possible. \n2. The choice of desirable properties is not clearly justified (Beginning of Section 2). For instance, why should prototypes be independent of learning tasks? \n3. Lack of rigor in defining prototypicality metrics as well as properties in Section 2. For example, wouldn\'t it be possible to theoretically prove that the metrics outlined in Section 2 satisfy the desired properties? \n\nDetailed Comments: \n1. I would strongly encourage the authors to illustrate using examples in the introduction the significance of finding prototypes. What are the end goals for which these prototypes would be used? Why do you think the metric for chooosing prototypes should be independent of the learning task or model? \n2. Along the same lines as the comment above, please provide detailed justifications for the list of properties provided in the beginning of Section 2. It would be even better if you could formalize these a bit more.\n3. Would it be possible to theoretically show that the metrics defined in Section 2 satisfy any of the desirable properties highlighted in Section 2? ', ""Summary: The paper proposes methods for identifying prototypes. Unfortunately, a formal definition of a prototype is lacking, and the authors instead present a set of heuristics for sorting data points that purport to measure 'prototypicality', although different heuristics have different (and possibly conflicting) notions of what this means. The experiments are not very convincing, and often present results that are either inconclusive or negative, i.e. seem to demonstrate that prototypes are not very useful. \n\nPros:\n- The notion of prototypes is used in various papers, but a formal definition is lacking, and the usefulness of prototypes is not demonstrated. The fact that this paper sets out to do both is laudable, although the paper needs work before it can be accepted for publications.\n\nDetailed comments / cons:\n*Defining prototypes: \n  - The authors list desirable properties before defining (even informally) what a prototype is, and what its purposes are. Taking the first property as an example, is it reasonable to expect a metric for prototypes to be useful for image classification AND image generation? The answer completely depends on what one expects from a prototype, what its purpose is, etc.\n  - The second property seems to indicate that prototypes are model-independent, i.e. two models trained on the same dataset will have the same prototypes. This is confusing as the metrics proposed are clearly model-dependent (e.g. adv completely depends on the trained model's decision boundary, conf obviously depends on the model providing the confidence score)\n- The third and fourth property are poorly defined. Human intuition presupposes that humans agree on what a prototype means. Using 'modes of prototypical examples' in trying to define a metric for prototypes is circular, as a mode of prototypical example depends on a working notion of prototypical examples.\n- The last property is completely dependent on which models are trained, and how they are trained. If a model has high label complexity, maybe it does not achieve high accuracy even when trained on high quality prototypes. In any case, this property is at odds with the first two properties.\n\nIn sum: it's not clear what prototypes are, so it becomes hard to judge if the list of desiderata is reasonable. The list is in any case ill-defined, and contains contradictions.\n\n* Metrics for prototypicality\n- The second paragraph in this section is unnecessary\n- All of the metrics proposed are heuristics with little to no justification. Specific comments below.\n- Adversarial robustness is a property of a trained model, not of prototypical examples, unless prototypes are supposed to be model dependent (contra property 1). In any case, it is not clear why examples that are robust to adversarial noise are good 'prototypes'.  Using facial recognition as an example, a 'mean face' may be very robust to adversarial noise but not prototypical at all under common definitions. A face with a particular type of facial hair (e.g. nose hair) may be very representative of a class of faces (i.e. a prototype), but very susceptible to adversarial noise. In fact, any examples in the boundary of the decision function will be more susceptible to adversaries, but that does not make them 'less prototypical'.\n- Holdout retraining is again completely model dependent. Why should we expect a model to treat a prototype the same regardless of whether or not it is trained on it? This basically means that we expect the model to always be accurate on prototypes.\n- Ensemble agreement proposes a notion of prototypes that is based on prediction 'hardness'. It is clear that such a notion depends completely on which models are being considered, which features are being used, and etc, much more than on notions of prototypicality inherent in the data. The same criticism applies to model confidence.\n- Privacy preserving training assumes prototypicality has to do with the model being able to learn with some robustness to noise (related to Adversarial Robustness, but different). This assumes a definition of prototypes that is not congruent with the other metrics.\n\nIn sum: the proposed metrics are basically heuristics with little justification, and different metrics assume different notions of what a prototype is.\n\n* Evaluation\n- Section 3.1 claims that the metrics are strongly correlated, but that is not true for MNIST or CIFAR, and is somewhat true for fashion-mnist. In any case, since the metrics are so model-dependent, it is not clear if these results would hold if other models were used.\n- Section 3.2 - The question asked of turkers in the study is too vague, and borderline irrelevant for the task at hand - what does the 'best image' of an airplane mean, and how does this translate to it being a prototype? All that the study demonstrates is that the proposed metrics score malformed images with low score. The results in Table 1 are very spread out, and seem to indicate a low agreement between the metrics and human evaluation - although Table 1 is almost irrelevant given the question that was asked of users.\n- The results in Section 4 are very discouraging: sometimes it is better to train on most prototypical examples according to the metrics, sometimes it is worse, sometimes it's better to take examples in the middle. That is, prototypes don't seem to help at all. 'Prototype percentile' is uncorrelated with robustness for MNIST in Appendix E, while being correlated for other datasets. It is clear why this would be the case for metrics such as confidence, but in general models trained on less examples are less robust than models trained on the whole dataset (again, as expected). As a whole, the results do not provide any help for a user who wants to produce a more robust model, other than 'ignore prototypes and use the whole dataset'.\n\n""]","[-50, -30, -70]","[20, 50, 20]","[""The sentiment score is -50 because while the review acknowledges some strengths, it focuses more on weaknesses and areas of confusion. The reviewer points out issues with practicality, lack of clarity in experimental details, and limitations in dataset choices. The politeness score is 20 because the language is generally professional and constructive, offering specific recommendations for improvement. However, it's not overly polite or deferential. The reviewer uses direct language to point out flaws but frames criticisms as areas for improvement rather than harsh judgments. The mention of 'confusing typos' is presented neutrally as a list of items to address."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('Novel attempt', 'Detailed experimental analysis'), they express several significant concerns and criticisms. The reviewer points out 'important drawbacks', 'lack of rigor', and encourages the authors to make substantial improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would strongly encourage' and 'please provide' when making suggestions, and balance critiques with acknowledgments of the paper's strengths. The reviewer also frames their concerns as opportunities for improvement rather than outright dismissals."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous flaws in the paper's approach, methodology, and results. They state that the paper lacks a formal definition of prototypes, presents conflicting notions of prototypicality, and provides inconclusive or negative experimental results. The reviewer does acknowledge one positive aspect (the paper's attempt to define and demonstrate the usefulness of prototypes), but this is overshadowed by the extensive criticisms. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'the paper needs work before it can be accepted' and 'laudable' to soften their criticisms. The reviewer also provides detailed explanations for their concerns, which is helpful and respectful to the authors. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['This paper considers adversarial attack and its defense to DQN. Specifically, the authors propose a poisoning attack that is able to fool DQN, and also propose a modification of DQN that enables the use of strong defense. Experimental results are provided to justify the proposed approach.\n\nDetailed comments:\n\n1.  Although the attack approach seems easy to implement, it would be interesting to see why it works. It might make this paper better if the intuition of the UQP is provided. FGSM is a well-known attack for deep learning models. What is the intuition of using the sign of the gradient of the cross-entropy? Since the argmax is a one-hot vector, this cross-entropy seems ill-defined. How to compute the gradient?\n\n2. It would also be interesting to see why taking actions based on the student network enables better defense.  In DADQN, the authors seem to combine a few tricks proposed by existing works together. It might be better to highlight the contribution and novelty of this approach. ', 'Stating the observation that the RL agents with neural network policies are likely to be fooled by adversarial attacks the paper investigates a way to decrease this susceptibility.   Main assumption is that the environment is aware of the fact that the agent is using neural network policies and also has an access to those weights. The paper introduces a poisoning attack and a method to incorporate defense into an agent trained by DQN.  Main idea is to decouple the DQN Network into what they call a (Student) policy network and a Q network and use the policy network for exploration. This is the only novelty in the paper. The rest of the paper builds upon earlier ideas and incorporates different training techniques in order to include defense strategies to the DQN algorithm. This is summarized in Algorithm 1 called DadQN. Both proposed training methods; adversarial training and Provable robust training are well known techniques. The benefits of the proposed decoupling is evidenced by the experimental results. However, only three games from the Atari benchmark set is chosen, which impairs the quality of the evidence. In my opinion the work is very limited in originality with limited scope that it only applies to one type of RL algorithm combined with the very few set of experiments for supporting the claim fails to make the cut for publication.\n\nBelow are my suggestions for improving the paper.\n1. Major improvement of the exposition\n  a. Section 2.2 Agent Aware Game notation is very cumbersome. Please clean up and give an intuitive example to demonstrate.\n  b. Section 3 title is Our Approach however mostly talks about the prior work. Either do a better compare contrast of the underlying method against the  previous work with clear distinction or move this entire discussion to related work section.\n2. Needs more explanation how training with a defending strategy can achieve better training rewards as opposed to epsilon greedy.\n3. Improve the exposition in Tables 1 and 2. It is hard to follow the explanations with the results in the table. User better titles and highlight the major results.\n4. Discuss the relationship of adversarial training vs the Safe RL literature.\n5. Provide discussions about how the technique can be extended into TRPO and A3C.', 'The goal of this paper is to train deep RL agents that perform well both in the presence and absence of adversarial attacks at training and test time. To achieve this, this paper proposes using policy distillation. The approach, Distilled Agent DQN (DaDQN), consists of: (1) a ""teacher"" neural network trained in the same way as DQN, and (2) a ""student"" network trained with supervised learning to match the teacher’s outputs. Adversarial defenses are only applied to the student network, so as to not impact the learning of Q-values by the teacher network. At test time, the student network is deployed.\n\nThis idea of separating the learning of Q-values from the incorporation of adversarial defenses is promising. One adversarial defense considered in the paper is adversarial training -- applying small FGSM perturbations to inputs before they are given to the network. In a sense, the proposed approach is the correct way of doing adversarial training in deep RL. Unlike in supervised learning, there is no ground truth for the correct action to take. But by treating the teacher\'s output (for an unperturbed input) as ground truth, the student network can more easily learn the correct Q-values for the corresponding perturbed input.\n\nThe experimental results support the claim that applying adversarial training to DaDQN leads to agents that perform well at test time, both in the presence and absence of adversarial attacks. Without this teacher-student separation, incorporating adversarial training severely impairs learning (Table 2, DQN Def column). This separation also enables training the student network with provably robust training.\n\nHowever, I have a few significant concerns regarding this paper. The first is regarding the white-box poisoning attack that this paper proposes, called Untargeted Q-Poisoning (UQP). This is not a true poisoning attack, since it attacks not just at training time, but also at test time. Also, the choice of adding the *negative* of the FGSM perturbation during training time is not clearly justified. Why not just use FGSM perturbations? The reason given in the paper is that this reinforces the choice of the best action w.r.t. the learned Q-values, to give the illusion of successful training -- but why is this illusion important, and is this illusion actually observed during training time? What are the scores obtained at the end of training? Table 1 only reports test-time scores.\n\nIn addition, although most of the paper is written clearly, the experiment section is confusing. I have the following major questions:\n- What is the attack Atk (Section 4.3) -- is it exactly the same as the defense Def, except the perturbations are now stored in the replay buffer? Are attack and defense perturbations applied at every timestep?\n- In Section 4.2, when UQP is applied, is it attacking both at training and at test time? Given the definition of UQP (Section 2.4), the answer would be yes. If that’s the case, then the ""none"" row in Table 1 is misleading, since there actually is a test time attack.\n\nThe experiments could also be more thorough. For instance, is the adversarial training defense still effective when the FGSM \\epsilon used in test time attacks is smaller or larger? Also, how important is it that the student network chooses actions during training time, rather than the teacher network? An ablation study would be helpful here.\n\nOverall, although the algorithmic novelty is promising, it is relatively minor. Due to this, and the weaknesses mentioned above, I don\'t think this paper is ready for publication.\n\nMinor comments / questions:\n- Tables 1 and 2 should report 95% confidence intervals or the standard error.\n- It’s strange to apply the attack to the entire 4-stack of consecutive frames used (i.e., the observations from the last four timesteps); it would make more sense if the attack only affected the current frame.\n- For adversarial training, what probability p (Section 3.2) is used in the experiments?\n- In Section 4.2, what does “weighted by number of frames” mean?\n- In which experiments (if any) is NoisyNet used? Section 4.1 mentions it is disabled, and \\epsilon-greedy exploration is used instead. But I assume it’s used somewhere, because it’s described when explaining the DaDQN approach (Section 3.1).']","[20, -50, -50]","[60, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and experimental results, but also points out areas for improvement. The review begins with a neutral summary and then provides constructive feedback, indicating a generally positive but cautious stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing suggestions as 'it would be interesting' and 'it might be better,' rather than using harsh or demanding language. The reviewer also acknowledges the paper's efforts and results before offering critiques, which is a polite approach to peer review."", ""The sentiment score is -50 because the reviewer expresses significant criticism of the paper, stating it has 'very limited originality' and 'fails to make the cut for publication'. However, it's not entirely negative as they acknowledge some benefits and provide suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone and offer constructive feedback. They use phrases like 'In my opinion' and 'my suggestions for improving the paper', which soften the critique. The reviewer also provides specific, detailed recommendations for improvement, which is a polite and helpful approach in academic peer review."", ""The sentiment score is -50 because while the reviewer acknowledges some promising aspects of the paper, they ultimately conclude that it's not ready for publication due to significant concerns. The reviewer points out weaknesses in the experimental design and lack of thorough experiments. However, it's not entirely negative as they do recognize the potential of the approach.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'This idea... is promising' and 'The experimental results support the claim...', showing appreciation for the work. Even when expressing concerns, the language is constructive rather than harsh, using phrases like 'I have a few significant concerns' instead of more confrontational language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism.""]"
"['Summarization: This paper studies how to inject structured prior knowledge into the teaching model for machine learning. The authors propose a very general framework called `teach to teach’, in which 1) the knowledge is distilled via subset selection that matches the teacher decision distribution 2) the distilled knowledge is then transferred into the teacher model by reweighting the contributions of teacher objective and coherence constraints. Extensive experiments are conducted on image classification, unsupervised domain adaptation and sequence learning.\n \nQuestions: 1) Can the teacher models, like those in L2T, be successfully transferred? For example, the teacher model trained with task 1 (with prior knowledge 1) successfully applied to task 2?\n2) I’m not that clear about the relationship with knowledge distillation (Hinton et. al 2015). Per my understanding, the authors seem to make the distribution of the knowledge (specified by the set prior function F) coherent with teacher model and let the both influence each other (in section 3.2). In that sense I do not know what is the `dark’ knowledge here.\n \nPros: In general I think this paper is a decent work that the structural prior knowledge is elegantly combined with teaching strategy (a.k.a. the teacher models in curriculum learning). The proposed method is intuitive and natural. The empirical verifications are deep and comprehensive to demonstrate the effectiveness of the `teaching to teach’ framework.\n \nCons: 1) I think the authors should compare with self-paced learning with diversity (SPLD) since you also take diversity as a form of structural knowledge.\n2) The writing needs to be significantly polished. First, please simply the writing both in terms of general logic and language. I spent quite a few efforts in figuring out the meaning of some notations and complicated terms such as `curriculum-routed’ and `g_i’. Furthermore, I see no reason of putting so much fancy decorations on an essentially iterative algorithm (the bottom part of page 5 and all page 6). Second,  I suggest the authors give more intuitive and concrete examples towards what is the structural prior knowledge at the earlier phase of the paper, rather than putting most of them into appendix. Last but not least, please use more clear citation formats: currently quite a few citations are missing of publishing venues such as Fan et.al 2018 and Furlanello et.al 2018.', 'In this paper, the authors propose a new technique called Teaching to Teach via Structured Dark Knowledge for curriculum learning.  See my comments below.\n\nI don’t like this paper because it is full of buzzwords, and it is really poorly written. The author first started in the abstract on “hyper deep learners”, which confuses me a lot. It is unclear to me what type of deep learning models that you are aiming for and what exactly “hyper deep learners” are. Also, in the abstract, the authors mention Structured Dark Knowledge, but they have not discussed it in the introduction, which makes it extremely hard for the readers to understanding the relationship between this work and the so called “Structured Dark Knowledge”. \n\nThe 3.2 is also poorly written and insufficiently motivated. The term Structured Dark Knowledge sounds fancy, but I fail to see what the structures are. It sounds like the authors just propose “Training Subset” as Structured Dark Knowledge, which is extremely misleading. This work gives people an impression that you are trying to leverage external knowledge for curriculum learning, it turns out it is not the case.\n\nIn section 4.1, the hyperparameters’ setting seems to be mysterious. It is unclear to me how the authors come up with magic numbers like 0.04, 0.1, 15%. \n\nIn Figure 2, the improvements from SDK do not look like it is very impressive. And also 4.2 the datasets are too small. The metric in Table 4 is poorly chosen. I don’t understand what the numbers mean un Table 4 and how significant they are. Please use standard metrics. \n\nThe future stock price regression experiments are also poorly presented. In Table 5, the authors do not explain what the price, percentage and error mean. It only says “Results”. Please pick common benchmark datasets and well-known metrics. \n\nOverall, this paper is poorly written, and it has not met the requirement of ICLR.\n\n\n', 'Summary\n==============\nThis paper proposes ""teaching to teach"". A drawback of existing curriculum learning approaches is that it requires a human to manually and heuristically define a curriculum. Teaching to teach avoids this using a teacher model to perform subset selection, and reweighting the data points based on the teacher loss. \n\nEvaluation\n==============\nUnfortunately, after reading section 3 a few times I am still not 100% clear on the exact methodology. It could be lack of background on my part, but I find the presentation extremely confusing, and unnecessarily verbose/florid. Also I am not exactly sure how the proposed methodology relates to Hinton et al\'s ""knowledge distillation"", which trains a (typically smaller) student model to mimic the output from a teacher model. The empirical study seems to be strong however, with applications across various domains/datasets and sensible baselines.']","[50, -90, -20]","[60, -60, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as a 'decent work' with 'intuitive and natural' methods and 'deep and comprehensive' empirical verifications. However, they also list some cons and areas for improvement, balancing out the positive aspects. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I think' and 'I suggest' to soften their recommendations. The reviewer also acknowledges the paper's strengths before discussing its weaknesses. However, the score is not higher as the review is still direct in pointing out areas that need improvement, particularly in the writing and presentation of the paper."", ""The sentiment score is -90 because the reviewer expresses strong dislike for the paper, citing numerous issues such as poor writing, confusing terminology, insufficient motivation, and poorly presented experiments. The reviewer concludes that the paper does not meet the conference requirements. The politeness score is -60 because the language used is quite harsh and direct, with phrases like 'I don't like this paper,' 'poorly written,' 'extremely misleading,' and 'mysterious.' While the reviewer provides specific criticisms, the tone is consistently negative and lacks the diplomatic language often used in peer reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the strong empirical study and applications across various domains, they express significant concerns about the clarity of the methodology presentation, describing it as 'extremely confusing' and 'unnecessarily verbose/florid'. The reviewer also questions the relationship between the proposed method and existing work. The politeness score is slightly positive (20) as the reviewer uses polite language throughout, starting with 'Unfortunately' to soften criticism, and using phrases like 'It could be lack of background on my part' to avoid sounding too harsh. The reviewer also balances criticism with positive comments about the empirical study. However, the overall tone remains professional rather than overtly polite, hence the moderate positive score.""]"
"[""In this work, the authors tackle the problem of few-shot learning and open-set classification using a new type of NNs which they call alignment-based matching networks or ABM-Nets for short. They main idea is to benefit from binary maps between the query image and the support set (for the case of few-shot learning for the sake of discussion here) to guide the similarity measure. \n\nI have quite a few concerns;\n\n- After reading the paper two times, I still couldn't find a clear explanation as how the binary map C is constructed. The paper says the cost of M,i,j,k = 1 is C. So what exactly happens given I_t and I_k. My understanding is that a vector representation of each image is obtained and then from those representations the matrix C is constructed (maybe an outer product or something). This does not come out clearly. \n\n- Nevertheless, I suspect if such a construction (based on my understanding) is the right approach. Firstly, I guess the algorithm should somehow encourage to match more points between the images. Right now the loss  does not have such a term so hypothetically you can match two images because they just share a red pixel which is obviously not right. \n\n- Aside from the above (so basically regularizing norm(C) somehow), one wonders why matching a point to several others (as done according to matrix C) is the right choice. \n\n- Related to the issues mentioned before, I may also complain that matching far away points might not be ideal. Currently I do not see how this can be avoided nor a solid statement as why this should not be a problem.  \n\n\n- Another comment is how the alignment here differs from attention models? They surely resemble each-other though the alignment seems not that rich.\n\n\n-  last but not least, I have found the language confusing. Some examples,\n   -p2 bandwidth signal than the traditional label-only signal : I am very confused by how bandwidth comes to the picture and how this can be measured/justified\n\n  - fig.1, what are \\phi and \\psi. paper never discussed these.\n\n  - the authors say M is a tensor with 3dimensions. Then the marginalization before eq.1 uses M_{i,\\cdot,\\cdot} = 1 . What does this really mean?\n\n    "", 'This paper proposed a new way of learning point-wise alignment of two images, and based on this idea, one-shot classification and open-set recognition can be further improved. The idea is interesting. As a human, when we say two images are similar, we may compare them locally and globally in our mind. However, traditional CNN models do not make direct comparisons. And this work give a good direction to further improve this motivation.\n\nThe paper is well written and easy to understand. \n\nFor the experiments, MNIST, Omniglot and MiniImageNet are used to demonstrate the effectiveness of the proposed method. From Figure 2. we can see many interesting correspondences.  ', 'The authors propose a deep learning method based on image alignment to perform one-shot classification and open-set recognition. The proposed model is an extension of Matching Networks [Vinyals et al., 2016] where a different image embedding is adopted and a pixel-wise alignment step between test and reference image is added to the architecture. \n\nThe work relies on two strong assumptions: (i) to consider each point mapping as independent, and (ii) to consider the correct alignment much more likely than the incorrect ones. The manuscript doesn’t report arguments in favour of these assumptions. The motivation is partially covered by your statement “marginalizing over all possible matching is intractable”, nevertheless an explanation of why it is reasonable to introduce these assumptions is not clearly stated.\n\nThe self-regularization allows the model to have a performance improvement, and it is considered one of the contribution of this work. Nevertheless the manuscript doesn’t provide a detailed explanation on how the self regularization is designed. For example it is not clear whether the 10% and 20% pixel sampling is applied also during self regularization.\n\nThe model is computationally very expensive and force the use of only 10% of the target image pixels and 20% of the reference images’ pixels. The complexity is intrinsic of the pixel-wise alignment formulation, but in any case this approximation is a relevant approximation that is never justified. The use of hyper column descriptors is an effective workaround to achieve good performance even though this approximation. The discussion is neglecting to argue this aspect.\n\nOne motivation for proposing an alignment-based matching is a better explanation of results. The tacit assumption of the authors is that a classifier driven by a point-wise alignment may improve the interpretation. The random uniformly distributed subsampling of pixels makes the model less interpretable.It may occur for example as shown in figure 3 where the model finds some points that for human interpretation are not relevant and at the same time these points are matched with points that have some semantic meaning.\n', 'Authors argue that using average (independent) greedy matching of pixel embedding (based on 4-6 layer cnn hypercolumns) is a better metric for one-shot learning than just using final layer embedding of a 4-6 layer cnn for the whole image.  Their argument is backed by outperforming their baseline and getting competitive results on few shot learning tasks. Their method is much more computationally heavy than the baseline matching networks. In order to make training feasible, in practice they train with 90% dropout of test pixels embedding & 80% dropout of reference pixels embedding. \n\n\nThe caveats: \n-> Using hyper-columns is related to adding residual connections. The question remains how much performance can be gained by just adding residual connections (with dropout) to the matching networks and letting the network automatically (or with a probability) choose to embed higher layers or lower ones. Adding the residual connection and just comparing the final layer embeddings is a cleaner method than ABM which  provides a richer embedding than baseline and could potentially close the performance gap between ABM and final layer matching.\n\n->It is strictly designed for one-shot learning. It does not benefit from few shots (extra shots) and the fact that these different shots are getting classified as the same label. Vinyal et al mitigates this shortcoming by adding the FCE. However FCE is not directly applicable anymore. Author’s don’t suggest any alternatives either. Their smaller gains (or even worse than baseline without self-regularization) in the 5-shot cases is an evidence of this shortcoming. \n\nThe fact that SNAIL (TCML Mishra et al. (2017)) consistently outperforms this method puts a question mark on the significance of this work. If it was computationally feasible, authors could have used SNAIL and replaced the 64 dimensional embedding of each picture with the 10-20% hypercolumns. Essentially due to computational costs authors are sacrificing a more thorough matching system (non-greedy) for a richer embedding and they don’t get better results. \n\n\nOn the other hand, authors may argue that the hyper-column matching is not just about performance, whereas it also adds interpretability to why two images are categorized the same. Illustrations like fig. 3 for example shows that the model is not matching semantically similar points and can be used to debug & improve the model. While understanding why a blackbox matching network is making a mistake and improving, is  harder. \nIt would have been nice if authors used this added interpretability in some manner. Such as getting an idea about a regularizer, a prior, a mask, etc. and improved the performance.\n\nI would argue for accepting this paper for two reasons.\n-> Given that they beat their baseline and  they get comparable performance to sota even with a greedy matching (min-pooling followed by average pooling), is impressive. Furthermore, it is orthogonal to methods like SNAIL if the computational cost could be resolved.\n\n-> They not only provide which image is a match but how they are matched, which could be interesting for one-shot detection as well as classification. \n\n\nQuestion: At test/validation: do you still only categorize with 10,20% samples or do you average the full attention map for all test pixels?\n\n\nNit: The manuscript needs several passes of proofreading, spell & grammar checking. A few examples in the first couple of pages:\n-> The citing format needs to be fixed (like: LSTMsRavi, there should be () around citations). \n-> are not incompatible: are compatible\n->incomprehensible sentence with two whiles: ABM networks outperforms these other state-of-the-art models on the open-set recognition task while in the one-shot setting by achieving a high accuracy of matching the non-open-set classes while maintaining a high F1 score for identifying samples in the open-set. \n-> add dots to the end of contribution list items.\n-> we first look pairwise matchings: we first look at the pairwise matchings\n']","[-60, 90, -50, 20]","[20, 70, 20, 60]","[""The sentiment score is -60 because the reviewer expresses 'quite a few concerns' and lists several major issues with the paper, indicating a generally negative view. However, it's not extremely negative as the reviewer engages deeply with the content and offers constructive criticism. The politeness score is 20 because while the reviewer is direct in their criticisms, they use polite language such as 'I have quite a few concerns' and 'I may also complain' rather than harsh or rude phrasing. The reviewer also uses 'I' statements to frame their criticisms as personal observations rather than absolute facts. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is 90 (highly positive) because the reviewer describes the paper's idea as 'interesting' and states that it provides 'a good direction' for improvement. They also mention that the paper is 'well written and easy to understand', and highlight 'interesting correspondences' in the results. The politeness score is 70 (polite) as the reviewer uses respectful and constructive language throughout, acknowledging the paper's strengths without using overly effusive praise. The tone is professional and supportive, offering positive feedback without any criticism, which contributes to the polite impression."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several limitations and assumptions of the proposed method that are not well justified. However, it's not entirely negative as it acknowledges some positive aspects like the performance improvement from self-regularization. The politeness score is 20 because the language used is professional and constructive, avoiding harsh criticism. The reviewer presents their concerns as observations and suggestions rather than direct attacks. They use phrases like 'The manuscript doesn't report' or 'It is not clear' instead of more accusatory language. The review maintains a respectful tone throughout, focusing on the work rather than the authors personally."", ""The sentiment score is slightly positive (20) because while the reviewer points out some caveats and areas for improvement, they ultimately argue for accepting the paper, highlighting its impressive aspects and potential contributions. The reviewer acknowledges the paper's strengths, such as beating the baseline and providing interpretability, which outweigh the criticisms. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They offer balanced feedback, presenting both positive and negative aspects without using harsh language. The reviewer provides suggestions for improvement and asks a clarifying question, which demonstrates engagement and respect for the authors' work. The mention of proofreading needs is presented as a 'nit' and with specific examples, which is a polite way to address such issues.""]"
"['The paper propose an end-to-end technique that applies both spatial and temporal attention. The spatial attention is done by training a mask-filter, while the temporal-attention use a soft-attention mechanism.  In addition the authors propose several regularization terms  to directly improve attention. The evaluated datasets are action recognition datasets, such as HMDB51, UCF10, Moments in Time, THUMOS’14. The paper reports SOTA on all three datasets. \n\n\n\nStrengths:\n\nThe paper is well written: easy to follow, and describe the importance of spatial-temporal attention. \n\nThe model is simple, and propose novel attention regularization terms. \n\nThe authors evaluates on several tasks, and shows good qualitative behavior. \n\n\nWeaknesses:\n\nThe reported number on UCF101 and HMDB51 are confusing/misleading.  Even with only RGB, the evaluation miss numbers of models like ActionVLAD with 50% on HMDB51 or Res3D with 88% on UCF101. I’ll also add that there are available models nowadays that achieve over 94% accuracy on UCF101, and over 72% on  HMDB51. The paper should at least have better discussion on those years of progress. The mis-information also continues in THUMOS14, for instance R-C3D beats the proposed model. \n\nIn my opinion the paper should include a flow variant. It is a common setup in action recognition, and a good model should take advantage of these features. Especially for spatial-temporal attention, e.g., VideoLSTM paper by Li. \n\nIn general spatial attention over each frame is extremely demanding. The original image features are now multiplied by 49 factor, this is more demanding in terms of memory consumption than the flow features they chose to ignore.  The authors reports on 15-frames datasets for those short videos. But it will be interesting to see if the model is still useable on longer videos, for instance on Charades dataset. \n\nCan you please explain why you chose a regularized making instead of Soft-attention for spatial attention? \n\nTo conclude: \nThe goal of spatial-temporal attention is important, and the proposed approach behaves well. Yet the model is an extension of known techniques for image attention, which are not trivial to apply on long-videos with many frames. Evaluating only on rgb features is not enough for an action recognition model. Importantly, even when considering only rgb models, the paper still missed many popular stronger baselines. \n\n', 'A method for activity recognition in videos is presented, which uses spatial soft attention combined with temporal soft attention. In a nutshell, a pixelwise mask is output and elementwise combined with feature maps for spatial attention, and temporal attention is a distribution over frames. The method is tested on several datasets.\n\nMy biggest concern with the paper is novelty, which is rather low. Attention models are one of the most highly impactful discoveries in deep learning, which have been widely and extensively studied in computer vision, and also in activity recognition. Spatial and temporal attention mechanisms are now widely used by the community. I am not sure to see the exact novelty of the proposed, it seems to be very classic: soft attention over feature maps and frames is not new. Using attention distributions for localization has also been shown in the past.\n\nThis also shows in the related works section, which contains only 3 references for spatial attention and only 2 references for temporal attention out of a vast body of known work.\n\nThe unimodality prior (implemented as log concave prior) is interesting, but uni-modality is a very strong assumption. While it could be argued that spurior attention should be avoided, unimodality is much less clear. For this reason, the prior should be compared with even simpler priors, like total variation over time (similar to what has been done over space).\n\nThe ablation study in the experimental section shows, that the different mechanisms only marginally contribute to the performance of the method: +0.7p on HMDB51, slightly more on UCF101. Similarly, the different loss functions only very marginally contribute to the performance.\n\nThe method is only compared to Sharma 2015 on these datasets, which starts to be dated and is not state of the art anymore. Activity recognition has recently very much benefitted from optimization of convolutional backbones, like I3D and variants.\n\nThe LSTM equations at the end of page are unnecessary because widely known.\n', '# 1. Summary\nThis paper presents a novel spatio-temporal attention mechanism. The spatial attention is decomposed from the temporal attention and acts on each frame independently, while the temporal attention is applied on top of it on the temporal domain. The main contribution of the paper is the introduction of regularisers that improve performance and interpretability of the model.\n\nStrengths:\n* Quality of the paper, although some points need to clarified and expanded a bit more (see #2)\n* Nice diversity of experiments, datasets and tasks that the method is tested on (see #4)\n\nWeaknesses:\n* The paper do not present substantial novelty compared to previous work (see #3)\n\n\n# 2. Clarity and Motivation\nThe paper is in general clear and well motivated, however there are few points that need to be improved:\n* How is the importance mask (Eq. 1) is defined? The authors said “we simply use three convolutional layers to learn the importance mask”, however the convolutional output should be somehow processed to get out the importance map, in order to match the same sizes of X_i. The details of this network are missing to be able to reproduce the model.\n* The authors introduced \\phi(H) and \\phi(X) which are feedforward networks, but their definition and specifics are not mentioned in the paper.\n* It is not clear how Eq. 9 performs regularization of the mask. Can the authors give an intuition about the definition of L_{contrast}? What does it encourages? In which cases might it be useful?\n* Why does L_{unimodal} need to encourage the temporal attention weights to be unimodal? It seems that the assumption is valid because of the nature of the dataset, i.e., the video clips contain only a single action with some “background” frames in the beginning and the end. This is not valid in general. Can the authors discuss about this maybe with an example?\n\n\n# 3. Novelty\nThe main concern of the proposal in this paper is its novelty. Temporal attention pooling have been explored in other papers; just to cite a popular one among others:\n* Long, Xiang, et al. ""Attention clusters: Purely attention based local feature integration for video classification."" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.\n* Other paper from the youtube8m workshops explore the same ideas: https://research.google.com/youtube8m/workshop2017/ \nSec. 2.2 should be expanded by including papers and discuss how the presented temporal attention differs from that.\n\nMoreover spatio-temporal attention has been previously explored. For example, the following paper also decouple the spatial and temporal component as the proposal:\n* Song, Sijie, et al. ""An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data."" AAAI. Vol. 1. No. 2. 2017.\nThis is just an example, but there are there are other papers that model the spatio-temporal extent of videos without attention for action recognition. The authors should expand Sec. 2 by including such relevant literature.\n\n\n# 4. Experimentation\nThe experiments are carried on video action recognition task on three public available datasets, including HMDB51, UCF101 and Moments in Time. The authors show a nice ablation study by removing the main components of the proposed method and show nice improvements with respect to some baseline (Table 1). Although the results are not too close to the state of the art for video action recognition on HMDB51 and UCF101, the authors first show nice accuracy on Moments in Time (Table 2).\n\nMoreover the authors show that the model can be useful on the more challenging task of weakly supervised action localization (UCF101-24, THUMOS). Specifically, spatial attention is used to localize the action in each frame by thresholding, showing competitive results (Table 3). Although some more recent references are missing, see the following paper for example:\n* G. Singh, S Saha, M. Sapienza, P. H. S. Torr and F Cuzzolin. ""Online Real time Multiple Spatiotemporal Action Localisation and Prediction."" ICCV, 2017.\nThen the authors tested also for temporal action localization (Table 4).\n\nIn general, the paper is not showing state-of-the-art results, however the diversity of experiments, datasets and tasks that are presented makes it pretty solid and interesting.\n\n']","[-20, -60, 50]","[60, 20, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper (well-written, novel approach, good qualitative behavior), they also point out significant weaknesses. These include misleading or missing comparisons with existing models, lack of flow variant, and concerns about the model's applicability to longer videos. The overall tone suggests the paper has potential but falls short in several important areas.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They begin by highlighting the paper's strengths before moving on to weaknesses. The language used is respectful and objective, with phrases like 'Can you please explain' and 'In my opinion' showing consideration for the authors. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. However, the score is not higher because the criticism, while politely phrased, is quite direct and extensive."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses significant concerns about the novelty of the method, stating it's 'rather low' and that the proposed approach seems 'very classic'. They also point out that the ablation study shows only marginal improvements, and that the method is compared to outdated benchmarks. However, it's not entirely negative as they do mention an 'interesting' aspect (the unimodality prior), hence not scoring at the extreme negative end.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone throughout. They use phrases like 'My biggest concern' and 'I am not sure to see' rather than making blunt or harsh statements. The reviewer also provides specific suggestions for improvement, which is constructive. However, the tone is not overtly polite or complimentary either, hence the slightly positive but not high score."", ""Sentiment score: The review is generally positive, acknowledging the paper's strengths such as quality, diversity of experiments, and interesting results. However, it also points out weaknesses, particularly regarding novelty. The balanced view with a slight positive lean suggests a score of 50.\n\nPoliteness score: The reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before discussing areas for improvement. The use of phrases like 'can the authors' and 'the authors should' when making suggestions is polite. The critique is presented as helpful feedback rather than harsh criticism, warranting a score of 75.\n\nThe review maintains a professional and objective tone while providing detailed, constructive feedback, balancing positive aspects with areas for improvement.""]"
"[""The authors propose a hierarchical model of symbolic music that takes explicit advantage of measures and chords to construct the hierarchy. Their model is very similar to SampleRNN (2-level RNN Autoregressive Model) but with an additional cross-entropy loss for chord labels at the higher level and a summarization connection passing back to the high level from the low-level at the end of each bar. They show that given monophonic music with chord labels their model is able to produce reasonably coherent chords and note samples, and improves the NLL over a low-level model alone. \n\nThe core of their approach (using measures as a natural hierarchy for a multi-level RNN) is a good one, but not new in of itself as it was the basis for the prior work of Roberts et al. (http://proceedings.mlr.press/v80/roberts18a/roberts18a.pdf). The authors highlight in section 3.3 that their work is distinguished by the summarization connection, but do not provide any evidence in their results that the connection is useful. They find in Table 1 that connection hurts NLL on the note level, and do not compare summarized to non-summarized models in the listening tests. \n\nThe area for most improvement in the paper is the evaluation, especially the listening tests. The authors compare samples from four models that generate different types of outputs and were trained on different datasets. Because of this, the notion of user preference is completely convoluted with external factors. In particular the comparisons to DeepBach and SequenceTutor are inappropriate and give little information about the quality of the model architecture itself. To be useful comparisons should be restricted to model architectures that are trained on the exact same data as HAPPIER, and output both chords and melodies like HAPPIER does. Given that the novelty of the paper rests on the summarization connections, and they were not shown to help NLL, it would be natural to try and compare the different model variants in the paper and see if the NLL misses some element of larger structure that listeners may care about. My rating is thus based on the lack of novelty and poor quality of evaluation justifying the actual novel aspects of the paper. \n\nSome minor comments that could also help improve the paper:\n\n* Including NLL for chords is important to compare summarization (does it help in chord prediction?)\n* The input representation could use further clarifying. What is the dictionary of chords to predict from? Are they just chord names or individual notes (the figures imply notes, but that doesn't seem what's happening). In Figure 2, clarify the meaning of tick, what 1, 0 means in terms of time progression.\n* Provide quantitative evidence for the claims in 4.2 that the notes and chords belong to the same key. Compare real data and generated data for those statistics. \n* Provide explanation for why Note NLL is higher for Summarization.\n* Minor notation problems: Eq 1, f should not be a function of n_i. Similar, in Eq 2, p(n_{ij}) should be a function of c_i. Eq 3 doesn't define what the hat represents. "", 'PRO\'s:\n+good problem: generating polyphonic music with long-term structure\n+reasonable approach: modification of SampleRNN: makes sense\n\nCON\'s:\n-doesn\'t work. \n\nMy fundamental critique of this paper is that, while the authors claim that their system "" generates polyphonic music which maintains long-term dependencies"", in fact what it generates it is not really polyphonic, nor-- more importantly-- does it demonstrate the kind of long-term structure present in the training set.\n\n1) Polyphony: The model predicts a combination of monophonic melody plus chords (i.e. chord names such as ""A+"", ""C7"" etc). This is different from polyphony, in which the model would predict the actual voicing used for those chords. However, this could be seen as an error in terminology; if the authors claimed that they were predicting a monophonic musical voice plus chords, and they did that well, that would be absolutely fine. Generating a coherent melodic line that continues, along with the chords underneath it, would be a great achievement. However, that is not what happens here. For examples, in the provided examples, e.g. Measure 19 of Fig 4, Measures 1,3,4,5, ... of Fig 6, contain stylistically unusual combinations of chords and melodic lines. By ""stylistically unusual"", I simply mean that those examples are not consistent with the Nottingham dataset.  Furthermore, in my subjective opinion, the examples that I listed above also just don\'t really musically work. There is no question that in the right context, any of those particular combinations of chords and melody notes *could* be made to work: for example, the first measure of Fig 6 would be perfectly fine as the beginning of a different song. (E.g. it could be taken as a slight reharmonization of the opening of ""lullaby of birdland"", but that would require a coherent continuation. )\n\n2) Long-term structure: It seems to me that one of the key things that this paper sets out to do is to get strong long-term dependencies. The motivation for the SampleRNN-inspired approach is to have generation at multiple time scales, for example. However, there is no evidence in the presented examples of long-term structure. Consider Fig 6, for example. Where is the long-term structure? A D major chord is frequently repeated with occasional A7. That is reasonable but it does not necessarily demonstrate long-term structure, anymore than learning that ""q"" is often followed by ""u"" demonstrates long-term structure. There is no melodic motif, there is no sense of 4-bar phrasing (or any other recurring such pattern that I can tell). In fact, all of the samples shown (Fig 4, 6, 7, 8) all end up with the chord D major played most of the time, after what appears to be a bit more variation in the first few chords.\n\nThe results of the listening test are strange to me (beyond some of the apples-to-oranges comparisons). I cannot comment on those without hearing the pairs of examples that were actually played. How were those pairs selected?\n\nAt the moment, it does not seem worthwhile for this review to get into details about exactly how the system works, in light of the problematic output. If there is reason for me to do so, I would gladly oblige. The authors do make a variety of choices that appear to be fairly sensible. \n\nI would very much look forward to seeing a revised version of the system in future that produces the  kind of output that the system is intended to produce (and described as producing).', ""This paper proposes a hierarchical RNN, where the first layer is note-level and the second level is measure-level. In an experiment on the Nottingham MIDI dataset, they show slight improvements in log-likelihood.\n\nOverall:\n\nThis is an interesting application of hierarchical RNNs. However, hierarchical RNNs are known to improve performance. This is an application of existing work (for example, Alexander Graves' thesis also uses hierarchical RNNs and shows improved performance). For an applications-oriented paper, I would hope to see many more experiments than just one on a tiny dataset, and improvements in log-likelihood that are more than the marginal improvements reported here. The human evaluation is neat but is inconclusive–in a glaring act of omission, the authors do not link to samples generated by their model, while they include samples generated by the competition. For a fair review, one would hope to compare the models side by side to qualitatively judge the reliability of the MTurk experiments.\n\nMinor nits:\n\nI appreciate the human evaluation experiments on MTurk but they are very difficult to understand with the figure 5. Please label the y-axis. Think of a different way to present the results. Do not include the numbers on the bars. \n\nThe acronym HierArchical PolyPhonic musIc gEnerative RNN is destructive; it devalues useful acronyms. Please do not use it.\n\nThe paper has many grammatical and spelling errors. Please hyphenate compound adjectives. \n""]","[-50, -70, -20]","[20, 20, 30]","[""The sentiment score is -50 because the reviewer expresses significant criticism of the paper, particularly regarding the lack of novelty and poor quality of evaluation. They state that the core approach is 'not new in of itself' and that the authors don't provide evidence that their novel contribution (the summarization connection) is useful. The reviewer also points out that the evaluation methods are flawed, especially the listening tests. However, the score is not extremely negative as the reviewer does acknowledge some positive aspects, such as the core approach being 'a good one'.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They offer specific suggestions for improvement and provide detailed explanations for their criticisms. The language used is not harsh or rude, but rather matter-of-fact and focused on the content of the paper. The reviewer also includes some positive comments, such as acknowledging the good core approach. However, the score is not higher as the review is predominantly critical and doesn't use particularly warm or encouraging language."", ""The sentiment score is -70 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('good problem', 'reasonable approach'), the bulk of the review criticizes the paper's main claims and results. The reviewer states that the system 'doesn't work' and provides detailed explanations of why the output fails to meet the paper's claims regarding polyphony and long-term structure. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'My fundamental critique' and 'I would very much look forward to seeing a revised version', which soften the criticism. The reviewer also offers to provide more detailed feedback if needed, showing a willingness to engage constructively. However, the directness of some statements (e.g., 'doesn't work') prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they express several criticisms. They note that the improvements shown are only 'slight', the experiments are limited, and there's a 'glaring act of omission' in not providing samples from their model. The reviewer also points out that the work is an application of existing techniques rather than novel research. However, the score isn't deeply negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is moderately positive (30) because the reviewer maintains a professional tone throughout. They use phrases like 'I appreciate' and 'Please' when giving feedback, which adds politeness. The criticisms are presented factually rather than harshly. However, some phrases like 'glaring act of omission' and calling the acronym 'destructive' are more direct, preventing a higher politeness score. The reviewer also offers constructive suggestions for improvement, which is a polite approach to criticism.""]"
"['This paper presents a method for learning the Q function from multi-agent demonstrations, such as trajectories of soccer players in a soccer game.  The basic ideas are:\n\n-- The policy class pi(m|s) maps states s to actions m probabilistically.  In particular, the probability class is a mixture of Gaussians, with the mean/covariance functions and the mixture function all being instantiated via neural nets.  The behavior of the individual players are assumed to be conditionally independent given the current state.\n\n-- A hand-designed reward function is used, such as the ball being in a ""strike zone"" of some kind for the team on offense. \n\n-- The Q function class is also a neural net.\n\n-- The policy pi is learned through maximum likelihood of the state/action pairs of the the pre-collected demonstrations.  This is essentially probabilistic behavioral cloning over the policy class.\n\n-- The Q function is learned via Q-fitting over the demonstration data, i.e., minimizing squared error on the Bellman residual.  This requires the pre-specified reward function, the policy pi, and some details regarding the state transitions (e.g., the non-deterministic transitions of the ball). \n\n-- The policy pi and the Q function are trained jointly by adding the two objectives.\n\n-- The main empirical evaluation is comparing the quality of the Q function estimation against a naive baseline (random movements) and a non-mixture policy class (i.e., a single mode, rather than a mixture of Gaussians).  The results against the non-mixture policy class do not seem to show much difference in performance.  \n\n-- Some qualitative evaluations are also presented, but it\'s unclear what insight one is expected to gain from looking at them.\n\n\n**Clarity**\nThe paper is reasonably well written.  Some aspects of the logical flow could be improved, but overall it\'s fine.  Detailed comments are:\n\n-- The proposed approach is essentially imitation learning and not, strictly speaking, reinforcement learning.  Yet the work is positioned as reinforcement learning.  Perhaps it\'s just a difference in norms of terminology usage.\n\n--  There are more multi-agent RL & IL works than what was discussed in the related works section.  Of course, an exhaustive discussion is not expected, but the writing makes it sound like there hasn\'t been much work at all.  Examples include:\nhttps://arxiv.org/abs/1807.09936\nhttps://arxiv.org/abs/1706.02275\nhttp://www.cs.ox.ac.uk/people/shimon.whiteson/pubs/rashidicml18.pdf\n\n-- The authors comment in the related work that team sports cannot yet be simulated.  This statement is sort of true, although it\'s not clear how true. For instance, the physics engines of many sports video games are very realistic.  Moreover, it doesn\'t strike me as the most prominent point of contrast with [Hausknecht & Stone 2016].  For instance, a more prominent point of contrast is simply imitation learning vs reinforcement learning.  \n\n-- It\'s not clear what the authors mean specifically when they refer to ""average performance"" contrasting with [Le et al. 2017b].  Also, desn\'t that work also condition on game context and situation? \n\n-- Section 4.1 is written in a somewhat disorganized way.  The exposition alternates between discussing baselines and the evaluation methodology in a way that is confusing. \n\n-- One of the baselines is described but then left to the appendix for analysis.  This doesn\'t make sense from a narrative perspective.\n\n\n**Originality**\nFrom a technical perspective, it\'s not clear that there\'s much novelty in this approach.  All the ingredients are pretty standard, and the ingredients are put together in a standard way. \n\nFrom an applications perspective, there might be some novelty here but it\'s not clear.  The application of imitation learning to sports data is not new, but also not saturated either.  The specific idea of learning a better rating system is interesting, but it\'s not clear how fleshed out this application is in the paper (more comments on this below).\n\n\n**Significance**\nFor me, the key question for significance boils down to: ""Does this paper change the way people think about doing X?"" for the most interesting instantiation of X possible.  In this case, it seems X should be computing a rating system for multi-agent spatial multi-agent behavior (as suggested by the title).  But the limitations in the model and the experiments make this a questionable proposition.  \n\nThe model class all but ignores the multi-agent aspect (the agents are all independent conditioned on the states). Moreover there was no comparison against a model class that made a worse assumption on how to handle the multi-agent aspect.  So it\'s not clear how the multi-agent aspect is significant.\n\nThe evaluation of the rating approach is not convincing.  The approach essentially performed as well as a single-mixture baseline.  Furthermore, the direction V(s) learning approach is deferred to the appendix, and I\'d like to see it included in the main paper.  Finally, it would be nice if there was some attempt to compare with a non-MDP based approach.  For instance, people directly compute things like P(goal|state).  I\'d like to see evidence that this style of approach will outperform those approaches, which are the de facto standard in sports analytics right now.\n\n\n**Overall Quality**\nBased on the above comments, it is my opinion that this paper has too many holes in it to be ready for publication at a venue such as ICLR.  As a primarily applications paper, the burden is on the authors to demonstrate reasonably convincing evidence that this line of approach is valuable to the application.', ""The paper proposes to learn a policy and action value over continuous next movement from professional soccer game. The policy is modeled as a gmm and the value of the mean of each component is learned jointly. \n\nThe experiment section seems a bit light. The dataset seems quite small, would be good to get learning curves on training / test sets separately to see of the model is overfitting. Also a breakdown of results with bigger / deeper convnets rather than just number of mixture components would be interesting. There is not much comparison with other ML / RL types methods. \n\np3: why not ' instead of + to denote next state ?\n\nf+i = fi + mi : why no f^{i+1}\n\nNevertheless, the movement of\nthe ball is a part of the environment and is modeled as random movement. Therefore, the movement\ndistribution is governed by a stochastic policy. \n\nEven if the ball movement was deterministic, the movement could still be stochastic.\n\nEq (2) right hand side, inconsistency between p(m | s, m) with p(s+ | s, m) defined above ?\n\nEq 6: I guess a softmax over a grid centered around player position would also work ? Possibly convolutional all the way? It wouldnt have much more parameters than the proposed arch?\n"", 'The paper studies the credit assignment problem in multi-agent domain (soccer playing as a concrete application). The paper itself is well-written. I hope that the author could use a better methodology to make the evaluation part stronger.\n\nI have a few questions to the author:\n\n1. Why features like which team has ball possession (a boolean) is represented as a channel in the image? What if you concatenate this bit with the output of the last layer of convolution?\n\n2. Compared to the proposed algorithm, the evaluation part is somewhat weaker. \n i) I understand that it might be hard to get ground truth of the credit assignment, but is there any way to get a more competitive baseline model.\nii) the dataset you used only contains 6 games from the same team in one tournament.  This seems biased and not a reliable dataset itself.\n\nMinor typos:\n* section 4. We extract all episodes of open play (where) one team']","[-50, -20, -20]","[50, 50, 60]","[""The sentiment score is -50 because the reviewer expresses several significant concerns and criticisms about the paper, including lack of novelty, insufficient evaluation, and questionable significance. However, they do acknowledge some positive aspects like reasonable writing clarity. The overall tone suggests the paper is not ready for publication, which indicates a negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without being harsh or rude. They use phrases like 'reasonably well written' and 'it's not clear' rather than more direct criticisms. The reviewer also provides detailed explanations for their concerns, which is a polite way to offer feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they point out several limitations and areas for improvement. The reviewer mentions that the experiment section seems 'light,' the dataset 'quite small,' and notes a lack of comparison with other methods. However, they also provide constructive feedback and suggestions, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases their criticisms as suggestions or questions rather than direct criticisms. They use phrases like 'would be good to' and 'why not' which maintain a respectful tone. The reviewer also acknowledges the paper's contributions before providing critiques, which is a polite approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written, they express concerns about the methodology and evaluation, suggesting improvements are needed. The phrase 'I hope that the author could use a better methodology to make the evaluation part stronger' indicates dissatisfaction with a key aspect of the paper. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'I hope' and 'I understand' show consideration for the authors. The reviewer also balances critique with positive comments, such as noting the paper is 'well-written'. The tone is professional and constructive throughout, without any rude or harsh language.""]"
"['This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking.  A major limitation of the paper is that it is not clear what contribution it makes. Some of the analyses are indeed interesting but 1) these analyses are mostly descriptive and 2) they are limited to one particular (outdated) architecture. How would batch norm or residual connections or any of the developments that have happened since AlexNet affect these results?\n\nAs a side note, the references/comparisons between AlexNet and recurrent nets (see abstract, etc) are misleading. This is based on the claim that Bowers et al (2014) qualitatively different results but this is for entirely different domains (words). Indeed what could have made potentially the work more relevant would have been to show some kind of benchmarking between AlexNet and alternative architectures (possibly RNNs). As such the current study does not contribute much except for comparing different semi-arbitrary measures of selectivity for one specific (outdated) network architecture trained on a particular problem (ILSVRC).\n\n****\nMinor points:\n\nThe study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned. It seems to me that the conclusions of the paper could be heavily biased because of this (when computing any measure based on inter and intraclass responses).\n\nIn general, this is a relatively poorly written paper which would be hard to reproduce. For instance, the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.', 'Summary - This paper analyzes the selectivity of individual units in CNNs. The authors analyze existing techniques such as precision selectivity, class-conditional mean activity selection and localist sensitivity. These methods are analyzed in the context of AlexNet and ImageNet. The authors also use Activation Maximization (AM) techniques for visualizing single-unit representations in CNNs.\n\n\nPaper strengths\n- The authors have minutely examined each of the metrics and the underlying assumptions they make. \n    - Example - Number of images used for computing the precision threshold in Zhou et al., 2014; The wrongly stated range of CCMAS [0, 1]. Considering the second highest CCMAS class is a good way of handling multiple classes that activate a single unit.\n- The results of this paper are surprising compared to existing work. The authors have made a surprising discovery and done a good job of both presenting it well and experimentally validating it. The paper raises interesting questions and this should inspire future work in understanding networks.\n- Figure 2 is insightful - It compares the various different interpretations of selectivity for a single unit in fc6. It shows how the mean activating class and the maximally activating class can be semantically very different. It also shows that despite the high precision and CCMAS score, the unit cannot be labelled as a detector for the single concept ""custard apple"". More such results are presented in the Appendix (e.g. Fig A6)\n- The human study in Section 3.3 is a good way to evaluate the generated AM images.\n\n\nPaper weaknesses\n- One of the major weaknesses of this paper is that it uses only ImageNet images to evaluate the units. As this is limited to 1000 classes, the authors cannot probe other visual concepts such as color, texture, materials for the units. As an example, Network dissection (Zhou et al., 2017) proposes a dataset called Broden which has many diverse sets of visual concepts labeled. This paper focuses only on one definition of selectivity - selecting objects. This should be made explicit and the authors have not done a good job of clarifying this assumption or showing that it exists.\n- All of the analysis is limited to AlexNet. With modern architectures that use residual/skip connections, it is not clear how well this analysis will generalize. It is an open question if the authors work overfits to AlexNet.\n- The jitterplots are hard to understand especially if there are many overlapping ""dots"" (samples). Since the y-axis values are not really meaningful anyway, using a histogram to see how many samples have a particular activation value is easier. A possible suggestion for Figure 2(a): split into two parts - 1) histogram of all samples; 2) histogram of the highest mean activating class.\n- The organization of the paper could be improved. The sections in the paper are not well connected.', 'Summary: \n\nThis paper explores different metrics to measure the ‘selectivity’ of single neurons for a class in deep neural networks. Using AlexNet as the model under study, the paper shows strengths and weaknesses of several recent methods in the literature. The paper conducts a psychophysics experiment to see if human subjects can reliably label images generated through activation maximization techniques. \n\nMajor comments:\n\nThis paper undertakes a careful analysis of different ways of measuring single-unit selectivity for a class. The conclusions drawn are that no neurons exhibit true localist selectivity, and most have some more complex selectivity. Some of the specific examples make this point very nicely (for instance, a unit that responds very strongly to several custard apples and would appear to be a custard apple detector, except that it responds extremely weakly to other custard apples). This is a somewhat negative result that may be useful in advancing the field away from single neuron analyses, which may be misleading.\n\nOne worry is that the methods applied are looking for a very strong form of selectivity. In particular, even the output layer is judged to contain a low percentage of selective units according to the definitions in the paper. It may be worth considering slightly weakened versions of the metrics that allow for some errors. \n\nIt would be useful to add discussion of the connections between these metrics and generalization performance. The class conditional selectivity metric, for instance, may not measure localist coding very directly, but it does correlate with important performance metrics like generalization performance. The discussion in Morcos 2018 suggests that high single unit selectivity is detrimental to generalization. Do these correlations persist using other metrics?\n\nThe psychophysics experiment with human subjects appears to have been done to a high standard, and yields the result that only the very highest layers of a network yield interpretable images. This is somewhat interesting but unlikely to be that surprising, as selectivity for objects in lower layers is not a claim made by many works. In these lower layers, selectivity for ‘object parts’ is a claim that has been made and could potentially be addressed by the data collected.\n\nOverall this paper critically analyzes single unit selectivity measures, reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding. The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many.\n']","[-70, 50, 20]","[-20, 70, 60]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'scattered potentially interesting ideas' but criticizes the execution, writing quality, and lack of clear contribution. They also point out major limitations and misleading comparisons. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. Phrases like 'execution is limited', 'writing poor', and 'relatively poorly written paper' contribute to the negative tone. The reviewer does acknowledge some potentially interesting aspects, which prevents the scores from being even lower."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting several strengths of the paper, including the authors' detailed examination of metrics, surprising results, and insightful figures. However, it also points out significant weaknesses, such as limited dataset usage and analysis confined to AlexNet. The balance of strengths and weaknesses suggests a moderately positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and discoveries. They provide constructive criticism without harsh language, using phrases like 'One of the major weaknesses' and 'The organization of the paper could be improved' rather than more direct or negative phrasing. The reviewer also offers suggestions for improvement, which is a polite way to address shortcomings."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's careful analysis and high-standard experiments, they also express some concerns and suggest that the significance of the conclusion may not be very high. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions or 'worries' rather than direct attacks. They use phrases like 'It would be useful to add' and 'One worry is' which maintain a polite and constructive tone. The reviewer also balances critique with praise, noting both strengths and weaknesses of the paper.""]"
"['This work provides theoretical insights on recent learning rate proposals such as Cyclical Learning Rates (Smith et al.). The authors focus on stochastic approximation i.e. how large is the SGD loss as a function of condition number and horizon. The critical contribution is the theoretical benefit of oscillating learning rates over more traditional learning rate schemes. Authors provide novel upper/lower bounds to establish benefit of oscillating LR, support their theory with experiments and provide insights on finite horizon learning rate selection. An important drawback is that results only apply to linear regression which is a fairly simple setup.\n\nI have two important comments regarding this work:\n1) I believe proof of Theorem 3 has a bug. In the proof, authors use the inequality\n(1-gamma_t lambda^k)^2 < exp(-2lambda^k gamma_t).\nObviously this can only be correct for gamma_t lambda^k<1. However, checking the setup of the problem, it can be seen that for largest eigenvalue and gamma_0, ignoring log factors:\n\ngamma_0L = L/(mu T_e)=kappa / T_e=kappa/T.\n\nSince, no restriction is imposed on T, gamma_0L can be as large as O(kappa) and invalidates the above inequality. So T should be T>O(kappa). I am not sure if this affects the overall statement or the remaining argument.\n\n2) The paper can benefit from more detailed experiments (e.g. Figs 1 and 2). Arguably the most obvious baseline is ""constant learning rate"". However, authors compare to 1/T or 1/sqrt(T) learning rates. It is not at all clear from current experiments, if the proposed approach beats a good constant LR choice.\n\nI am happy to increase my score if the comments above are addressed.', 'The paper studies the effect of learning-rate choices for stochastic optimization, focusing on least-mean-squares with decaying stepsizes. The main result is showing that exponentially decaying stepsizes can yield improved rates of convergence of the final iterate in terms of dependence on the condition number. The proposed learning rate schedule depends on the condition number and the number of iterations. This positive result is complemented by showing that without prior knowledge of the time horizon, any stepsize sequence will frequently yield suboptimal solutions.\n\nI have mixed feelings about the paper. On the positive side, the particular observation that exponential learning-rate schedules lead to faster convergence for SGD in linear least-squares problems indeed seems to be a novel result, and the lower bound also appears to be new and interesting. The analysis seems to be technically correct as well. \n\nOn the other hand, I have several concerns about the presentation of the results:\n\n- The abstract and the introduction sets up a misleading narrative around the results: the authors seem to suggest that their work somehow explains why certain learning-rate schedules work better than others for deep learning applications / non-convex optimization, although the actual results exclusively concern the classical problem of linear least-squares regression. This presentation is completely uncalled for as the authors themselves admit that it is unclear how the results would generalize to other convex optimization settings, let alone non-convex optimization. Also, I think that this presentation style is rather harmful as it suggests that learning-theory results concerning classical setups are somehow embarrassing, so they need to be sold through some made-up connections to trendy topics in deep learning. I would suggest that the authors completely ""rethink"" the presentation of the paper and write it in a style that is consistent with the actual results: as a learning theory paper, without the irrelevant deep learning experiments (that only show well-known phenomena anyway).\n\n- The paper misrepresents a large body of work on stochastic/online optimization. Specifically, the authors suggest that the stochastic optimization literature exclusively suggests the use of polynomially decaying stepsizes. This picture is grossly inaccurate for multiple reasons:\n*** It has been known for a while that the de facto optimal tuning of SGD for least squares involves a large constant stepsize and iterate averaging (see, e.g., Bach and Moulines, NIPS 2013). This approach is only mentioned in passing without any discussion, even though it yields convergence rates that do not involve *any* dependence on the condition number in the leading term---thus achieving a much more significant improvement than the learning-rate schedule studied in this paper. In light of these results, learning-rate schedules are already being ""re-thought"" as we speak, and studying the behavior of the last iterate has received less attention in the past couple of years. If anything, the present paper only provides further evidence (through the negative result) that the individual iterates are ill-behaved in general and it is better to average the iterates instead. I would consider this negative result as an interesting addition to the stochastic-optimization literature, had it been presented in a completely different narrative (e.g., augmenting the discussion in ""Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes"" by Shamir and Zhang, 2013).\n*** Exponentially decaying (or ""constant-and-cut"", as they are called here) schedules have actually been studied before in the paper ""Beyond the Regret Minimization Barrier: Optimal Algorithms for Stochastic Strongly-Convex Optimization"" by Hazan and Kale (JMLR 2014). This significantly weakens the main intended selling point of the paper which was being the first-ever study of such learning-rate schedules. The results in said paper are of a somewhat different nature, but they have arguably as little to do with deep learning as the results of the present paper has. Notably, both the present paper and the cited work rely on *strong convexity* of the objective (through assuming prior knowledge of the condition number), so I would expect that none of these results would explain anything in the context of deep learning.\n\nOn the technical side, the proofs appear to be correct but presented somewhat sloppily, with most of the notation appearing without proper definitions. For instance, the proof of Theorem 2 seems to import notation from the proof of Theorem 1, although without explicitly mentioning that the covariance matrix is assumed to be diagonal(ized). The proof of Theorem 3 then seems to again replace this previously (non-)established notation by another one (e.g., v becomes err and \\eta becomes \\gamma). The proofs also involve long sequences of inequalities without explanation, and only bound the variances (w_k-w^*_k)^2 without mentioning how this quantity is related to the excess risk. (The relation is well-known but not obvious at all for first-time readers of such proofs.)\n\nOne technical limitation of the results is that they assume a simple additive-noise model for the gradients, which the authors conveniently call ""fairly natural"" and incorrectly claim to hold for linear regression with well-specified models (footnote 8). In reality, the gradient noise in this setting also depends on the current iterate w_t, which makes analysis significantly harder. (To see the difference, just compare the complexity of the proofs of Lemma 1 and Theorem 2 that correspond to these different settings in ""Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression"" by Dieleveut, Flammarion and Bach, 2017.)\n\nOverall, I don\'t think that this paper is fit for publication in its present form. Once again, I would suggest that in a future version, the authors focus solely on discussing the actual results without attempting to draw disproportionate conclusions from them.\n\nDetailed comments\n=================\n- pp.1, abstract: the first half of the abstract is completely irrelevant to the rest of the paper, so I\'d suggest removing it.\n- pp.1, ""learning-rate schedules for SGD is a rather enigmatic topic""---""enigmatic"" feels like a bit of a strong adjective here, given that there are many aspects of learning-rate tuning that are actually pretty well-understood.\n- pp.2: The second paragraph on page 2 is again irrelevant to the actual technical content of the paper.\n- pp.2, ""all the works in stochastic approximation try to bound the error of each iterate of SGD""---This is simply not true, given the growing literature concerning the behavior of the *averaged iterates*.\n- pp.4, first display: poor typesetting.\n- pp.6, Eqs. 1--3: ditto.\n- pp.8, last paragraph: Singling out the particular setting of gradient-norm minimization feels arbitrary and poorly justified.\n- pp.11: the first and second displays should be switched for better readability (otherwise the first one comes without explanation). Also note that this form is not just due to the algorithm design, but also to the simplified noise model.\n- pp.12, App B: \n*** It appears that you forgot to mention here that you\'re working in the coordinate system induced by the eigenvectors, and also forgot to define the eigenvalues, etc. \n*** The indices (1) and (k) are incoherent in the first display. \n*** Although you promise you\'ll prove the inequality in the second display, you eventually prove something else.\n*** It is not very clear on first sight that \\ell^* actually exists and falls within the scope of \\ell---you should explain that it exists due to the choice of the number of phases. (Which, by the way, should be rounded up to allow this property?)\n*** The sequence of inequalities in the last display seems correct but unnecessarily hard to verify due to the lack of explanations.', 'This paper presents a theoretical study of different learning rate schedules. Its main result are statistical minimax lower bounds for both polynomial and constant-and-cut schemes.\n\nI enjoyed reading the paper and I think the contributions in it shed some light in step size schedules that have shown to be useful in practice. I do have however some concerns that I hope the authors can address in their rebuttal. My initial rating is marginally below acceptance but I will gladly increase this rating if my concerns are addressed.\n\n\n# Pros\n\n* The paper is written in a way that\'s both clear and accessible.\n\n* The Theoretical contributions are important, as they address the choice of step size in one of the most used optimization methods machine learning and are novel to the best of my knowledge.\n\n* Due to time constraints, I only skimmed through the proofs, but results seem correct.\n\n\n# Concerns\n\n\nMy biggest concern is that its unclear how realistic is their noise model. The authors assume that the noise in the stochastic gradients e verifies E[e e^T ] = \\sigma H. While they claim that this is verified for problems like least squares, it is not clear to me that this is indeed the case. Related work like (Moulines and Bach, 2013) and (Flammarion and Bach, 2015) take the same setting but can only assume that the covariance of the noise is _bounded_ by a matrix of sigma times H. How do the authors obtain a much stronger condition on the noise covariance with the same assumption? I would be much more convinced with a proof in appendix clearly showing that the assumptions in footnote 8 imply the aforementioned covariance of the noise and a paragraph comparing their noise model with that of related literature like the aforementioned references (I\'m not affiliated with any of that work). \n\nAlso, the authors claim that their results hold for an arbitrary noise covariance matrix but the proofs are all done with the specific \\sigma H matrix. I don\'t think its OK to say ""our results hold for a more general setting"" without proof. If they do hold for a more general setting then the proofs should be done in the general setting. If not, it should only be mentioned as future work. Please edit that remark accordingly.\n\n* The paper does not compare or discuss against constant step size with averaging, which has been shown to be theoretically optimal in some scenarios (see aforementioned papers). This should at least be mentioned, and ideally also included in experiments.\n\n\n# Presentation issues\n\nClarity of the proofs can be improved. For example, in Theorem 1, the formula for v_T(1) and v_T(d) follow from a recurrence that is stated _below_ the formula, needing several passes to understand. The proofs could benefit from a pass on them to improve the flow.\n\n\nIt is never clear whether expectations are taken with respect to the full randomness of the algorithm or conditioned on previous randomness. The E in Eq. just-before-section-4 (please add equation numbers) is a full expectation while the E[e] should be conditioned on previous randomness. The expectation in footnote 8 is also unclear if its wrt to the stochasticity of the algorithm or the randomness in the data generating process.\n\n\nNo equation numbers  makes it difficult to reference equations. Please add equation numbers so that reviewing is not more difficult than it should (and others can reference your work more precisely).\n\nOther minor presentation issues include:\n\n  * Page 1: Why l-BFGS and not L-BFGS? the lowercase l makes it look like a 1.\n  * Page 2: There important -> There *are* important.\n  * Page 2: In fact, at least ... (missing parenthesis around Omega tilde).\n  * Page 4: ""a stochastic gradient oracle which gives us"" the second w should also be boldface.\n  * Page 4: I would have appreciated\n\n  * Page 11: ""variance in the i-th"" direction. It would be more correct to say in the i-th coordinate as otherwise it can be mistaken with the i-th update direction.\n\nUpdate:\n  I am satisfied with the answers and have upgraded my rating.']","[-20, -60, 50]","[60, -20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and theoretical insights, they also point out significant drawbacks and issues. The reviewer mentions an 'important drawback' regarding the limited applicability of the results, and identifies a potential bug in one of the proofs. They also suggest that more detailed experiments are needed. The reviewer's statement 'I am happy to increase my score if the comments above are addressed' implies a current negative leaning.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's contributions before presenting criticisms, and frame their comments as suggestions for improvement rather than harsh criticisms. The use of phrases like 'I believe' and 'The paper can benefit from' softens the critique. The final statement about being willing to increase the score is particularly polite, showing openness to revision."", ""The sentiment score is -60 because the reviewer expresses significant concerns and criticisms about the paper, particularly regarding its presentation and positioning of results. While they acknowledge some positive aspects (novel results, technically correct analysis), the overall tone is quite negative, suggesting the paper is not fit for publication in its current form. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism and somewhat harsh language. Phrases like 'completely uncalled for', 'grossly inaccurate', and 'sloppily' indicate a lack of politeness. However, the reviewer does provide detailed feedback and suggestions for improvement, which prevents the score from being even lower."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses enjoyment reading the paper and appreciation for its contributions, but also raises significant concerns. The initial rating is 'marginally below acceptance', indicating a mix of positive and negative sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I enjoyed reading the paper', 'I hope the authors can address', and 'I would gladly increase this rating' demonstrate politeness. The reviewer also provides detailed feedback and suggestions for improvement, which is considerate and helpful to the authors.""]"
"['This paper analyses the learning dynamics of GANs by formulating the problem as a primal-dual optimisation problem. This formulation assumes a limited class of models -- Wasserstein GANs with discriminators using linear combinations of base functions. Although this setting is limited, it advanced our understanding of a central problem related to GANs, and provides intuition for more general cases. The paper further shows the same analysis can be applied to multi-task learning and distributed learning.\n\nPros:\n\n* The paper is well written and well motivated\n* The theoretical analysis is solid and provide intuition for more complex problems\n\nCons:\n\n* The primal-dual formulation assumes Wasserstein GANs using linear discriminator. This simplification is understandable, but it would be helpful to at least comment on more general cases.\n\n* Experiments are limited: only results from GANs with LQG setting were presented. Since the assumption of linear discriminator (in basis) is already strong, it would be helpful to show the experimental results from this more general setting.\n\n* The results on multi-task learning were interesting, but the advantage of optimising the mixing weights was unclear compared with the even mixture baseline. This weakens the analysis of the learning dynamics, since learning the mixing did not seem to be important.\n\nIt would also be helpful to comment on recently proposed stabilising methods. For example, would spectral normalisation bring learning dynamics closer to the assumed model?', 'This paper studies the convergence of a primal-dual algorithm on a certain min-max problem and experimentally shows that it works in GANs and multi-task learning.\n\nThis paper is clear and well-written. The convergence guarantee looks neat, and convergence to stationary points is a sensible thing on non convex-concave problems. I am not super familiar with the literature of saddle-point optimization and may not have a good sense about the significance of the theoretical result.\n\nMy main concern is that the assumptions in the theory are rather over-restrictive and it’s not clear what intuitions or new messages they bring in for the practice of GANs. The convergence theorem requires the maximization problem (over discriminators) to be strictly concave. On GANs, this assumption is not (near) satisfied beyond the simple case of the LQG setting (PSD quadratic discriminators). On the other hand, the experiments on GANs just seem to say that the algorithm works but not much more beyond that. There is a brief discussion about the improvement in time consumption but it doesn’t have a report a quantitative comparison in the wall time.\n\nOn multi-task learning, the proposed algorithm shows improvement over the baseline. However it is also unclear whether it is the *formulation* (12) that brings in the improvement, or it is the actual primal-dual *algorithm*. Perhaps it might be good to try gradient descent on (12) and see if it also works well. \n\nIn general, I would recommend the authors to have a more convincing demonstration of the strength of this algorithm over baseline methods on min-max problems, either theoretical or empirical. ', 'The paper proposed a primal-dual optimization framework for GANs and multi-task learning. It also analyzes the convergence rate of models. Some results are conducted on both real and synthetic data.\n\nHere are some concerns for the paper:\n\n1. The idea of the model is pretty similar with Xu et al. [2018] (Training Generative Adversarial Networks via Primal-Dual Subgradient Methods: A Lagrangian Perspective on GAN), especially the primal-dual setting. The author totally ignored it. \n\n2. The motivation of the paper is not clear. GANs and multi-task learning are two different perspectives. Which one is your focus and what is the connection between them? \n\n3. The experimental results are not good. The convergence analysis is good. However we also need more empirical evidence to support. ']","[50, -20, -50]","[80, 60, 0]","[""The sentiment score is 50 (slightly positive) because the review begins with acknowledging the paper's contribution to understanding GANs and its solid theoretical analysis. It also mentions several pros. However, it also lists some cons and areas for improvement, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The cons are presented as suggestions for improvement rather than harsh criticisms. Phrases like 'it would be helpful' are used to soften the recommendations, maintaining a constructive and polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clear and well-written', 'convergence guarantee looks neat'), they express significant concerns about the paper's assumptions and practical implications. The reviewer's main concern and subsequent critiques outweigh the initial positive comments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific recommendations for improvement. They avoid harsh or dismissive language, instead using phrases like 'My main concern is...' and 'I would recommend...', which maintain a professional and courteous tone."", ""The sentiment score is -50 because the review expresses several significant concerns about the paper without any positive comments, indicating a generally negative view. However, it's not extremely negative as it acknowledges some aspects like the convergence analysis. The politeness score is 0 (neutral) because the language is direct and matter-of-fact without being overtly polite or rude. The reviewer states concerns plainly without using harsh language, but also doesn't use any particularly courteous phrasing. The review focuses on content rather than tone.""]"
"[""This paper is of high quality and clarity. I think it's originality is at least decent. Whether it is significant or not depends on how significant one thinks fully connected neural networks are as these are the models for which this explanation model makes sense.\n\nGood things:\n- It is a very elegant method. It is also very simple (in a good way).\n- The paper is really well written.\n- The experiments are carefully conducted and are indeed showing what the authors describe.\n- I think the method is potentially of practical use.\n\nProblems:\n- I think qualifying this paper as a paper on representation learning is a small stretch. It would be perhaps more suitable to submit it to ICML or NIPS. I think it is close enough though.\n- The font is too small in many figures. It is impossible to read it. \n- I am not sure whether model compression is actually necessary here. How good is the additive model if it is trained as a standalone model straight from the training data in comparison to the neural networks and to the additive model when trained with model compression? If the neural network and the additive model were similar in performance when trained from scratch, I would not see the point in explaining the neural network.\n- Only makes sense to apply this to fully connected networks."", 'Summary: This paper makes an interesting contribution of providing global explanations of black box models (such as neural nets) using a special class of models called generalized additive models.  While the paper is well written and experiments are quite detailed, I have some problems with some of the basic premises of this work. \n1. The concept of using simpler models to approximate other complex models (model distillation) is not new and has been explored quite a bit already in ML literature. The only new proposition of this work is to use generalized additive models to approximate other complex models. This seems rather incremental. \n2. The premise behind using generalized additive models (GAMs) to explain other complex models is that GAMs are interpretable. I am not convinced about this premise. While I can intuitively see that GAMs might be able to better approximate complex models compared to rules and trees, I highly doubt if they are even interpretable. \n\nPros:\n1. The paper is well written\n2. Experiments are very detailed and thorough\n\nCons:\n1. The proposed approach lacks novelty\n2. Experimentation lacks a user study which helps understand if and when GAMs are at least as interpretable as rule-based approaches.\n\nDetailed Comments: \nI actually like the way this paper is written and executed. The writing is very clear and experiments are quite thorough. But, as discussed earlier, I have some issues with the basic premises of this paper i.e., novelty of the proposed approach and justification for the claim that GAMs are interpretable. I would encourage the authors to discuss these two aspects in their rebuttal. I would strongly encourage the authors to carry out at least a simple user study which compares the interpretability aspect of GAMs with rule-based or prototype based approaches. \n', ""Summary:\nThis paper incorporates Generalized Additive Models (GAMs) with model distillation to provide global explanations of neural nets (fully-connected nets as black-box in the paper). It is well written with detailed experiments of synthetic and real tabular data, and makes some contribution towards the interpretability of black-box models. However, it lacks novelty and is limited to tabular data as presented.\n\nPros:\n- The paper is well written.\n- The experiments are detailed and thorough with both synthetic and real data.\n\nCons:\n- The novelty is limited. The core consists of GAMs well studied in the literature, e.g. Caruana et al 2015. Admittedly, this work also tries to incorporate model distillation to explain black-box models globally. The concept of student models approximating teacher models is not new either. The originality seems incremental in both directions.\n- The scope is limited. The paper only presents applications in tabular data. Also, it would be better to experiment with black-box models beside simple fully-connected nets.\n- The interpretability is not convincing. It is not sufficient to demonstrate the interpretability of the proposed method, or the expressive advantage of feature shapes. It is encouraged to include studies with human subjective to compare against other existing interpretable approaches.\n\nSpecifics:\n- With Figure 3, it is not convincing that the student model actually explains the teacher model, so the paper tries to elaborate more with Table 1. I think Table 1 also needs more details to help, such as the significance of error difference and '-' elements.\n- Many figures are hard to read mostly because of font, color, and overlap.\n""]","[70, -20, -20]","[80, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer starts by stating the paper is of 'high quality and clarity' and lists several 'good things' about the paper, including its elegance, well-written nature, and careful experiments. The few 'problems' mentioned are relatively minor and presented as suggestions rather than severe criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I think' and 'I am not sure' to soften their critiques, and the overall tone is professional and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting contribution', 'well written', 'detailed experiments'), they express significant concerns about the paper's novelty and premises. The reviewer states they have 'some problems with some of the basic premises of this work' and questions the novelty and interpretability claims. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and offers constructive feedback. They use phrases like 'I would encourage' and 'I would strongly encourage' which are polite ways of suggesting improvements. The reviewer also balances criticism with praise, noting both pros and cons of the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'detailed experiments'), they express more significant concerns about the paper's novelty, scope, and interpretability. The cons outweigh the pros in the review. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, balancing criticism with acknowledgment of the paper's strengths. They offer constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer's tone is objective and academic, avoiding personal attacks or overly negative language.""]"
"['This paper presents an interesting way to reformulate intrinsic curiosity as a differentiable function. The authors compare the differentiable function against using prediction error via REINFORCE and DQN, showing that their intrinsic curiosity method results in more interactions with unseen objects than the other two methods. For DQN this is to be expected, but it shows that backprop through this function is more efficient than reinforce in getting to unseen state spaces. I think this is an interesting method/proposal and is a somewhat novel reformulation of intrinsic error, but I do have some concerns in comparisons/claims. \n\nIn the introduction, the authors say that the intrinsic curiosity method proposed by Pathak et al. is sample inefficient and isn’t tested in robots. However, to my understanding the REINFORCE baseline isn’t really equivalent (though it may be possible that it is, it was unclear how exactly the loss was formulated in the baseline, did include the other components from Pathak et al.?). If the claim is that this method is more efficient, I think it should have compared against that method directly. \n\nMoreover, I think the description of the experiments doesn’t provide enough information. For example, the method says that different learning rates were used for the min-max game to stabilize it, but doesn’t say what they were. \nAlso, for the DQN baseline what were the parameters? Was there an epsilon greedy policy on top of the exploration reward? Was this annealed as in other work? Generally, I think more detail is needed throughout (even if it just refers to a more detailed appendix).\n\nOverall, I think this work needs to be revised to include more details on hyperaparameters, details on the baselines, and describing differences between Pathak et al.’s method and the REINFORCE baseline. Moreover, feedback from other comments on this work should be addressed which reflect in more detail my comments below on opinionated claims (e.g., https://openreview.net/forum?id=SkzeJ3A9F7&noteId=HJlFlZOa2X )\n\n\nComments/Thoughts:\n\n+ I think in the introduction there are some statements that probably need citations. For example, “But the same formulation from an optimization viewpoint, it suffers from all the bad properties of extrinsic rewards. The reward is a function of environment behavior with respect to the performed action. Since the environment behavior function is unknown, it is treated as black-box and hence the gradients have to be computed using REINFORCE (Williams, 1992) which is quite sample inefficient.” —> Why is this true? Is there a citation that can back this? Do you prove it later in the paper? \n+ “Yes, 54 environments but no real-world physical robots” —> this and the intro seems like a blogpost at times. That can be fine (some would argue it’s a good thing), but there seem to be some opinions without citations/backing, I suggest trying to back up statements wherever possible and avoid opinions. For example in this statement, robots aren\'t a requirement for evaluating intrinsic motivation.\n+ “Since the environment behavior function is unknown, it is treated as black-box and hence the gradients have to be computed using REINFORCE (Williams, 1992) which is quite sample inefficient.” —> citation/backing? it might be nice to point to the experiment section here to back it (e.g., ""As will be shown in Section X and in \\citet{something}, REINFORCE can be quite sample inefficient"")\n+ “In practice, the existing on-policy algorithms, e.g., A3C (Mnih et al., 2016), PPO (Schulman et al., 2017) etc. are deployed off-the shelf -> This is confusing, so is this using REINFORCE or PPO/A3C? what is this statement referring to?\n+ “regress to rti to learn value estimates (i.e., off-policy) as discussed in the previous section” —> regress to \\sum r_t{I} for a value estimate?? Value is the expected return so not sure if this is a typo or i missed something earlier\n+ What is the actual loss function used for the baseline? Is it the same as Pathak et al.?\n+ What are the hyper parameters for DQN exploration? What are all the hyper parameters for any/all the algorithms? \n+ Was a variance-reducing baseline used in REINFORCE?\n+ What is the variance representing in the graphs, std across several trials? Maybe I missed it, but how many trials represent this standard deviation?\n+ “Hence, we train the forward predictor slightly faster than the policy by keeping higher learning rate to stabilize the learning process. “ —> what were the learning rates?\n\n\nLinguistic/Typos:\n\nAlso, some minor, but frequent, grammatical issues/typos that I’ve added below could be fixed. I would ask that the authors please have the submission proof-read for English style and grammar issues. There are many minor mistakes, some of which I’ve tried to point out below. \n\n+ “This leads to a significantly sample efficient exploration policy. “ —> significantly more (?) sample efficient ?\n\n“Why is that? To understand the reason behind sample inefficiency of curiosity or intrinsic rewards, notice how the intrinsic rewards are given by agent” —> by the agent?\n\n“Forward model fθF is trained to minimize its loss which amounts to minimizing rti with respect to θF” —> the forward model\n\n“However, policy is optimized to maximize the objective” —> However, the policy\n\n“We can also optimize  for policy parameters θP via differentiable loss function” —> We can also optimize for (the) policy parameters \\theta via (a) differentiable loss function?\n\n“To optimize policy to maximize a discounted sum “ —> To optimize the policy\n\n“How good is Forward Prediction Model” —> How good is the forward prediction model\n\nThere are several other spots, but basically another pass over the paper might be worth it to check for these sorts of issues. \n', 'Summary:\n\nThis paper proposes a novel differentiable approximation to the curiosity reward by Pathak et al. that allows a learning agent to optimize a policy for greedy exploration directly by supervised learning, rather than RL.\nThe authors motivate this work with arguments about the sample-efficiency required by real robot learning, and demonstrate basic results using a real robot.\n\nComments:\n\nThe paper has serious style and tone issues that must be addressed before publication. The rest of my review will focus solely on the technical details.\n\nThe experimental details are lacking (learning rates? rollout lengths for REINFORCE? what are the inner and outer loops and what are their sizes? what are the plots measuring - extrinsic reward? intrinsic reward? what is ""multi-step learning"" in Table 2?).\nWithout these details, the results will be difficult to validate and reproduce independently.\n\nThe approach is compared only against very weak baselines. Why vanilla REINFORCE and not any of the modern policy-gradient algorithms (A3C, PPO, TRPO, DDPG, ...)? The ability to deal with this large action space is certainly impressive, but it is likely far too large for DQN or REINFORCE to work, so the comparison is questionable to begin with: you can make any algorithm fail if you give it an unnecessarily difficult interface. Did the authors try a smaller, more traditional action space?\n\nThe authors claim the sample-efficiency improvements by many existing exploration approaches are insignificant. In what way are the results in this paper more significant? Table 1 shows very minor improvements to a MPC planning task, Appendix Figure 1 shows barely any improvement over the baseline, and Appendix Figure 4 shows that learning from extrinsic rewards using REINFORCE seems to work just fine. Why use intrinsic rewards at all in this case? It appears that maybe some of the results look significant because the baselines are so weak.\n\nThe paper contains many factual errors and unsupported claims. For example:\n- ""the field of RL was born out of need to make our robots learn""\n- ""none of the recent advances have translated to success in the field of robotics"" (see e.g. the proceedings of CoRL 2017 and 2018)\n- ""Building a good model will require enormous number of interactions"" (see e.g. PILCO)\n- ""[our approach enables us to] for the first time ever, implement exploration on a real-world physical robot"" (PILCO and many others)\n- describing Pathak et al. curiosity as a ""gaussian density model"" in eq1; it\'s a deterministic forward model\n- in sec3, ""regress r^i_t to learn value estimates"", this is probably meant to be the discounted sum of rewards\n- also sec3, ""[REINFORCE] gives no signal as to what action to take""; the signal has high variance but it works (see all policy gradient work)\n\nThese errors can be easily corrected. However, the contribution of the paper is based on a more serious error:\n- sec3.1, ""If the policy could be optimized using direct gradients, the rewarder could ... inform the agent to change its action space in the direction where forward prediction loss is high.""\nThis is incorrect. The paper is based on using the gradient of the forward model to directly optimize the policy to produce higher prediction errors, as in Pathak et al.\nBut in order to make the prediction error differentiable, it makes the severe assumption that the next state x_{t+1} is constant and does not depend on a_t, which is false and invalidates the idea of optimizing actions for prediction error.\nAs a result, the gradient obtained does not actually move the policy toward higher prediction errors.\n\nTo understand what the author\'s approximation actually does, consider a perfect forward model. No matter what actions the policy produces, the prediction error is always zero, but the authors\' gradient is not. So it can\'t be optimizing for higher prediction errors.\nInstead of optimizing for high prediction errors as the authors claim, the policy is being optimized for state transitions that are maximally different from the observed state x_{t+1}.\n\nThis is an interesting objective to optimize. I can see how it could result in interesting exploration. But it\'s not what the authors say they\'re proposing.\nIt\'s much more like a count-based exploration strategy, which prefers visiting states that are maximally different from the states visited so far. It is much less like the prediction-error based curiosity of Pathak et al. that the authors are motivated by.\nI would like to see focused analysis of this particular objective. For example, would this not result in the policy oscillating between different parts of the state space, since it\'s only optimizing for maximal difference to what it just saw, rather than long-term knowledge gain? This issue requires more discussion.\n\nFinally, the approach is not really robot-specific despite the title and arguments in the paper. I recommend pursuing a more general investigation, because if this objective is truly as effective as the authors believe, then it should be applicable in a wide variety of domains (many of which are very easy to evaluate in: Atari, OpenAI Gym, DMLab, VizDoom, Mujoco, etc.).\n\nConclusion:\n\nThe paper proposes an interesting new objective, but it is motivated by a very naive approximation that completely changes the behavior of the exploration compared to what the authors want to approximate. The idea is novel and worth exploring, but the paper should be heavily rewritten to emphasize what the authors are actually doing with this new objective, and should include thorough analysis of its behavior, before I can recommend acceptance.', 'Beyond Games: Bringing Exploration to Robots in Real-world\n===========================================================\n\nThis paper tackles the laudable goal of making an algorithm for efficient exploration in ""real-world"" RL.\nTo do this, they augment the ""curiosity"" algorithm of Pathak et al with a differentiable approximation to the reward prediction model.\nThey motivate this algorithm through several intuitive arguments together with a series of experiments where the algorithm outperforms vanilla DQN/REINFORCE.\n\n\nThere are several things to like about this paper:\n\n- The problem of making ""real-world"" practical algorithms for exploration is clearly one of the biggest outstanding problems in reinforcement learning.\n\n- The authors have sucessfully gone from ideas, to algorithm, to real robot and their algorithm really seems to outperform the baselines.\n\n- The authors clearly make an effort to survey a wide variety of recent papers in the field\n\n\n\nHowever, there are several important places where this paper falls down:\n\n- In a paper that posits a new, groundbreaking, real-world application of ""exploration"" there is remarkably little discussion of the key issues of ""efficient exploration"". Indeed, I don\'t think that this paper even presents a clear metric for how we can tell if something *is* a good method for exploration.\n  + This is a huge shortcoming, since we know that it is possible to guarantee polynomial regret bounds for many settings (mostly tabular, but some with function approximation too... see UCRL2, PSRL and more)... there is no discussion of whether the proposed algorithm would also satisfy these bounds?\n  + Of course, this is not a paper designed for ""tabular MDPs"", but we already have exploration algorithms like UCB / Thompson sampling that *are* widely used in online advertising... so why is this method not compared/contrasted to these approaches?\n\n- There is very little *science* in this paper, beyond the experiments pitting ""improved algorithm"" vs DQN/REINFORCE, which nobody ever claimed would be a good approach to exploration! I don\'t think it\'s possible to assess if their algorithm (which I don\'t think has a clear name beyond ""sample-efficient exploration formulation"") performs better than the myriad of other exploration approaches listed. Although many intuitive arguments are presented, I did not find these convincing, and the overall narrative ends up being a little jumbled.\n\n- A lot of the writing is generally imprecise, and alludes to claims/statements that make no sense to me:\n  + ""... most of these sucesses have been demonstrated in either video games or simulation environments. This is primarily becuase the rewards (even the intrinsic ones) are non-differentiable ...""\n  + ""Again these approaches have mostly been considered in context of external rewards and hence turn out to be sample inefficient""\nI would suggest that each statement/claim is backed up by some material reasoning/statement/experiment unless extremely obvious - at the moment these are not!\n\n- Nothing in this algorithm really seems specific to real-world... or at least nothing in the competing algorithms seems to preclude them from being run on a real-world robot... I think that the main issue is that if people want to iterate fast (or don\'t have a robot) they prefer to do things in simulation. If your point is really that findings from simulation don\'t translate to real robots, then I think that is really interesting, but I don\'t see any evidence for that in this paper.\n\n\nOverall, it is clear that this is an interesting area to do work in.\nThe goal of making a practical algorithm for real-world exploration tasks is exciting.\nHowever, in its current form, this paper falls well short of the level of science and insight I would expect for ICLR.']","[20, -70, -60]","[60, -20, 20]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and 'somewhat novel', but also expresses several concerns and recommends revisions. The overall tone suggests the reviewer sees potential in the work but feels it needs improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames concerns as suggestions rather than harsh criticisms. The reviewer also acknowledges positive aspects of the work before diving into areas for improvement. The use of phrases like 'I think' and 'I suggest' further contributes to the polite tone. However, it's not extremely high as the review is still quite direct in pointing out flaws and areas needing clarification."", ""The sentiment score is -70 because the review is highly critical of the paper, pointing out numerous issues including 'serious style and tone issues', lack of experimental details, weak baselines, factual errors, and a fundamental misunderstanding of the method being proposed. The reviewer concludes that the paper needs to be 'heavily rewritten' before it can be accepted. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism ('The paper has serious style and tone issues') and dismissive language ('These errors can be easily corrected'). The reviewer does not use overtly rude language, but the tone is quite harsh and direct, particularly when pointing out errors and flaws in the paper."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('several things to like'), the majority of the review focuses on significant shortcomings and criticisms. The reviewer states that the paper 'falls well short' of expectations and lists several major issues. The politeness score is 20 because the reviewer maintains a professional tone and uses some polite language ('laudable goal', 'clearly make an effort'), but is also quite direct in their criticisms. The reviewer balances negative feedback with some positive comments, which adds to the politeness. However, the critique is still quite pointed, preventing a higher politeness score.""]"
"['i take reviewing very seriously, and it often takes hours per paper. this paper, however, has many typos, grammatical errors, and seems to have been submitted last minute.  therefore, i have read the paper quickly.\nthat said, i do not understand the results.\nclearly, many discretization methods have previously been described, as alluded to by citing the taxonomy paper on the subject.  the authors state they have developed a better approach.  however, i do not see a comparison to the state of the art in the simulations, and i do not follow the results of Table 2, which columns correspond to which particular algorithms? in either case, the proposed approach does not seem to improve the empirical results, nor have theoretical guarantees, so i am not particularly impressed with the results either.', 'This paper presents a feature quantization technique for logistic regression, which has already been a common practice in \n many finance applications.  The text feels rushed. From the current presentation, I find it difficult to understand what is the motivation of adopting the proposed relaxation of the optimization method, and how is the neural network-based estimation strategy connected to the logistic regression model. It seems the difference lies in the parameterized nonlinear transformation such that the cutting points can be somehow optimized.  The quality of the experiments performed is way below the expectation for ICLR. Although numerical experiments are performed on both simulated data and credit scoring data, it is still unclear whether the proposed method has superiority over competitors.  \n\nQuestion: In the test phase, how would the proposed method handle features that are not seen in the training phase? ', ""The paper describes a question about discretize continuous features or group discrete features in the preprocessing step, which they call feature quantification. It considers that a joint training of feature quantification and a discriminative model can lead to a better performance than treating feature quantification as a preprocessing step. \n\nThis paper has many typos, grammar mistakes and question marks, which make it hard to follow. The question proposed is simple and easy to understand. However, I don't convinced by the solution in this paper. Since it is a hard optimization question, the authors proposed a relaxation approach in section 3.1. I do not think that exp(a+bx) is able to approach step functions since exp(a+bx) is monotone. I think Figure 1 is misleading. For grouping discrete features, the author propose to use exp(\\alpha_{x_j, j}^h) and hoping that some \\alpha parameters can be optimized to be equal, which is too simple. The exponential transformation here does not have an effect. It is more interesting to consider how to add some constraints. For example, if the discrete feature is ordinal, how one can assure that the grouped discrete feature is still ordinal. The relaxation in this paper is too much without handling any interesting constraints and the proposed exp(a+bx) can not approach step functions. The authors do not provide a good way to select number of cut points, which I think is a hard but interesting question.\n\nThe work also lacks value in literature review, optimization and experiments.""]","[-70, -60, -70]","[-30, 20, -20]","[""The sentiment score is -70 because the reviewer expresses strong dissatisfaction with the paper's quality and results. They mention numerous errors, lack of understanding of the results, and unimpressive findings. The politeness score is -30 as the reviewer's language is quite direct and critical, bordering on rudeness. They state they've read the paper 'quickly' due to its poor quality, which could be seen as dismissive. However, they do not use explicitly rude language, which prevents the score from being lower. The reviewer's tone is professional but clearly frustrated, leading to these negative scores in both sentiment and politeness."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper feels rushed, is difficult to understand, and that the quality of experiments is 'way below the expectation for ICLR'. They also express uncertainty about the method's superiority over competitors. However, it's not entirely negative as they acknowledge that the paper presents a technique that is common in finance applications. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone without using overtly rude language. They phrase criticisms as observations (e.g., 'I find it difficult to understand') rather than direct attacks. The reviewer also asks a constructive question at the end, which is a polite way to point out potential issues."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous issues with the paper, including typos, grammar mistakes, unconvincing solutions, and lack of value in literature review, optimization, and experiments. The only positive aspect mentioned is that the question proposed is simple and easy to understand. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'I don't convinced by the solution' and 'It is more interesting to consider...' imply that the reviewer finds the work lacking without offering much constructive feedback. The reviewer also uses direct language to point out flaws without softening the criticism, which contributes to the slightly impolite tone.""]"
"[""This paper studies the problem of robust policy optimization, motivated by the fact that policies that work in simulations do not transfer well to real world. The authors propose to use the diversity measure on the roll out trajectories to select a diverse set of simulator configurations and train policies that can work well for all of those selected configurations. \n\nOverall, I think the idea is interesting but it is not entirely clear why adding diverse configurations should result in good performance, and the experiments are very limited and not convincing enough. \n\nPros:\n- The paper is easy to follow.\n- The idea of using a diverse summary to do robust policy optimization is interesting. \n- The diversity measure on the trajectories instead of the space of configuration parameters also intuitively makes sense since it takes into account that the similarity between two configuration parameters does not typically mean the similarity between their corresponding policies. \n\nCons:\n- The setting of this paper seems to only work for the fully observable case with state space being in R^d, deterministic dynamics and deterministic policy (otherwise the diversity measure would be stochastic?). It would be good to clarify these in Sec. 2. \n- For the example in Fig 2 and the first experiment, what I don't understand is why the initial state is not part of the policy.\n- It is not clear if the reason that EP-OPT performed worse than the proposed approach is only because there are not enough rollouts for EP-OPT. This could be an unfair comparison.\n- It would be good to show the comparison to EP-OPT for the second experiment as well. \n- Two experiments may not be enough to verify valid performance since there could be a lot of randomness in the results.\n- In page 6, it would be good to clarify that the summary being optimal is only with respect to f(M_s), but not the original problem of finding optimal policy. "", 'This paper addresses the problem of finding a policy that will perform well in a real environment when training in a simulator that may have errors.  It takes the now standard approach of trying to find a policy that performs well in an ensemble of simulated environments that are perturbations of the basic simulator.   The question is:  how can we construct an ensemble that represents the uncertainty about the real world well while being small enough for computational efficiency.  The idea is to construct a diverse set of samples that represents the whole space of important variations in the simulation;  the particular novelty here is to ensure that the sample set attains coverage over the *behaviors* of the simulator rather than the parameters of the simulation.  This problem is made difficult by the fact that there is no finite space of samples to choose from and the fact that we don\'t have a natural distance metric on the simulator behavior.\n\nThe main positive contributions of the paper are:\n- The view of the problem of selecting from an infinite set as one of streaming sub-modular optimization.  This is a nice idea that is new to me and seemed appropriate for the problem.\n- The idea that we want diversity in behavior, and then the technical approach of defining a kernel on simulator parameter sets that depends on the trajectories that those parameters induce.\n\nI do have a set of questions and concerns:\n- Might it not be better (more robust) to use not just trajectories from the current policy, but from other policies as well, to compute the kernel on parameter sets?  \n- How do you get the length-scale parameters for the kernel?\n- The confidence intervals in table 1 are too big to really justify firm conclusions;  it would be better to run the algorithms several more times, until the intervals pull apart.\n- You say: ""For ease of implementation  and since, in higher dimensional system, the variance of the policy gradients becomes  a significant factor, we train the  robot  on both the environment summaries and the N_s random rollouts.""   This seems like it might be an important point that should be addressed earlier.  And, why does this ease implementation?\n- I didn\'t understand:  ""Diverse summaries are more consistent than pure random sampling.""  What do you mean by consistent here?\n- The metrics used in the empirical comparisons don\'t seem exactly right to me.  The goal of this work is to learn a policy that is robust in some sense (so  that,  e.g., it will do sim-2-real well).   We  really want  it to  work well in all  possible cases, not just in expectation or according to the sampling distribution you create, (I guess---since the paper said  the minimax criterion was desirable but difficult to work with).  So, then, it seems like  the best performance criterion would be to sample a whole lot of  domain parameters and report performance  on the worst  (rather than reporting performance on a distribution that\'s like the one you  trained it on or on an easy random one).\n\nOverall, my view is that the idea is good, but somewhat small, and it hasn\'t really yet been proven to make a big difference.', 'This paper presents a new method for learning diverse policies that can potentially transfer better to new environments. The proposed method aims to find simulation configurations that lead to diverse behaviors using “submodular optimizations” technique; an idea stemmed from past data summarization methods.  \n\nPros:\n\n-The paper deals with an important problem in RL which is learning robust policies that can transfer better\n\n- Simple idea based on prior information theory literature is proposed. \n\n- Good incorporation of past methods for improving robustness in RL.\n\nCons:\n\n>>The paper has provided weak evidence and to support the effectiveness and significance of the proposed approach. The current analysis and experimental evaluations are not convincing.\n\nRelevant baselines are missed and limited tasks are explored:\n- A relevant prior work of Pinto et al. (2017) is not considered in the baselines for comparison.  \n- Only two tasks are considered in experiments which are not representative of the effectiveness of the proposed approach and does not provide convincing evidence that the proposed method performs better than prior works.\n-In the HalfCheetah task only the performance of random baseline is shown and comparison with EpOpt is not reported\n-Results of the base DDPG policy is reported in the experiments (Fig 3 and Table 1). For a thorough comparison these missing results are necessary. \n\n>>Correct citation to the prior work of “domain randomization” is necessary:\n- The second paragraph of related work section (first paragraph of page 2) explains that the idea of domain randomization has been first used in computer vision by Tobin et al. 2017. The idea of domain randomization was first proposed and deployed on a real robot platform in Sadeghi and Levine 2016 (Sadeghi, Fereshteh, and Sergey Levine. ""CAD2RL: Real single-image flight without a single real image.""\xa0arXiv preprint arXiv:1611.04201\xa0(2016).) and was later used in Tobin et al. 2017 (this is also explained in the Tobin et al. 2017). Adding proper citation to Sadeghi and Levine 2016 is necessary. \n\n>> Relevant prior works are missed:\n- The proposed idea in the paper is relevant to multi-task RL (e.g. Teh Y, Bapst V, Czarnecki WM, Quan J, Kirkpatrick J, Hadsell R, Heess N, Pascanu R. Distral: Robust multitask reinforcement learning. InAdvances in Neural Information Processing Systems 2017 (pp. 4496-4506). Adding related discussion about prior multi-task RL methods is highly recommended for improving the paper.\n- Citating several relevant prior RL methods that deal with transfer learning is missed. A few examples are:\n\nRusu AA, Vecerik M, Rothörl T, Heess N, Pascanu R, Hadsell R. Sim-to-real robot learning from pixels with progressive nets. arXiv preprint arXiv:1610.04286. 2016 Oct 13.\n\nRusu AA, Rabinowitz NC, Desjardins G, Soyer H, Kirkpatrick J, Kavukcuoglu K, Pascanu R, Hadsell R. Progressive neural networks. arXiv preprint arXiv:1606.04671. 2016 Jun 15.\n\nRusu AA, Colmenarejo SG, Gulcehre C, Desjardins G, Kirkpatrick J, Pascanu R, Mnih V, Kavukcuoglu K, Hadsell R. Policy distillation. arXiv preprint arXiv:1511.06295. 2015 Nov 19.\n\n\n>> The format of the paper needs to be improved. \n- The introduction section is rather incomplete and does not properly motivate the problem and the proposed solution.\n-The organization of the experimental section should be improved. It is hard to follow the experiments and find the key experimental results in the current version of the paper.\n']","[-20, 20, -50]","[60, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting idea', 'easy to follow'), they express significant concerns about the paper's clarity, experimental design, and overall convincingness. The cons outweigh the pros in the review.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They begin with positive points, use phrases like 'I think' and 'it would be good to', and frame criticisms as suggestions for improvement rather than harsh judgments. The tone is professional and helpful, even when pointing out weaknesses.\n\nThe reasoning for these scores is based on the balance of positive and negative comments, the specific language used, and the overall tone of the review. The reviewer maintains a polite and professional demeanor while still clearly communicating their concerns about the paper's limitations."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's positive contributions and novel ideas, but also raises several questions and concerns. The overall tone suggests the reviewer sees potential in the work but feels it needs improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than direct attacks. The reviewer maintains a professional tone, offering constructive feedback without being overly critical or dismissive."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), the majority of the review focuses on criticisms and areas for improvement ('Cons'). The reviewer points out several weaknesses in the paper, including weak evidence, missed baselines, limited tasks explored, and missing citations. These criticisms outweigh the initial positive comments, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express criticisms (e.g., 'The paper has provided weak evidence' rather than 'The paper fails to provide evidence'). The reviewer also offers constructive suggestions for improvement, which is a polite approach. However, the score is not higher because the review is direct in its criticisms without much softening language, and the use of '>>' to emphasize points could be seen as slightly forceful.""]"
"[""\n> Even though the paper details the underlying Markovian setup in Section 2, it is unclear to the reader how this knits with the FFNN architecture, for example what are the Markovian functions at hidden layer and output layer. Are they all conditional probabilities? How do you prove that this is what occurs within each node?\n\n> Why is the functional form of f_\\theta in Eq 1? \n\n> How many hidden layers are in place?\n\n> What is the Stochastic dynamical process in Figure A and how is this tethered to DyMon? \n\n> The authors mention an nth-order Markovian process implemention but is this not the case with any fully connected neural network implementation? What the reader fails to see is why DyMoN is different to these already-existing architectures.\n\n> In the teapot example, the authors mention a DyMoN architecture. (Page 8). Is this what is used throughout for all the experiments? If yes, why is it generalizable and if not, what is DyMoN’s architecture? You could open the DyMoN box in Figure 10 (1) and explain what DyMoN consists.\n \n\nSection 2 is the crux of the paper and needs more work - explain the math in conjunction to the ‘deep’ architecture, what is the 'deep' architecture and why it is needed at all. Then go on to show/prove that the Markovian processes are indeed being realized. \n\n"", 'This paper describes a NN method called DyMoN for predicting transition vectors between states with a Markov process, and learning dynamics of stochastic systems.\n\nThree biological case studies are presented, it is unclear if any new biology was learned from these cases that we could not have learned using other methods, and how accurate they are. The empirical validations are all on nonbiological data and disconnected from the first part of the paper, making the main application/advantage of this method confusing.\n\nI agree with the computational advantages mentioned in the paper, however, interpretation of the representational aspect is challenging especially in the context of biological systems. Regarding denoising, what are the guarantees that this approach does now remove real biological heterogeneity? Also, a denoising method (MAGIC) was still used to preprocess the data prior to DyMon, there is no discussion about any contradictory assumptions.\n\nOverall, the main shortcoming of the paper is lack of performance evaluation, comparison to other methods and clarifying advantages or novel results over other methods. The description of the method could also be improved and clarified with presenting an algorithm.', 'This paper tackles the important challenge of making sense of temporal measurements made in biological systems. Among other, those have the peculiarity that they are not independent but with a dependency structure, which can be encoded as a graph or a network. The authors claim that their approach, DyMoN is adapted to the many challenges of biological high-throughput data sets: noise, sparsity and lack of temporal resolution. The paper presents three very different use of the method in complex biological systems in Section 3: (i) Calcium imaging of visual cortex neurons, (ii) T--cell development in the thymus, and (iii) Human embryonic stem cell differentiation. Section 4 assesses the performance of the method on simulated data sets as well as on a face-recognition data set. Moreover, the authors demonstrate how the features of the NN can be interrogated to shed new insight about the process under scrutiny. They also show the gain in running time a comapred to other approaches.\n\nRemarks:\n - I know very little about the literautr in the subject, could you clarify how your work relates to/can be distinguished from: Testolin and Zorzi, Front Comput Neurosci. 201, Kiegeskorte\'s Ann. Rev. Vis. Sc. 2015 (https://doi.org/10.1146/annurev-vision-082114-035447), Kai Fan\'s PhD work (@ Duke University), Betzel and Bassel, Interface 2017, Wang et al. bioRxiv 2018 (https://doi.org/10.1101/247577), etc.\n - l-4p2: \'repetitions\': what are those? Line below: \'sufficient for estimating $ P_{x}(y) $, means large sample size, no? No contradictory? And one line below: what is the precise meaning of \'similar\' (twice)?\n - top p3: line continued from bottom of p2 -> is it to rubber out noise?\nwhat is $ n $ in $ \\mathbb{R}^{n} $?\n - Make Fig 1 (B) and (C) clearer, since the transition vectors are learnt, why are they in (B) (input states)?\n - below ""...distribution approximates the distribution $ \\mathcal{P}_{x} $..."" -> but $ P_{x} $ also depends on $ \\theta $, not an issue?\n - remark at the end of Section 2: extending DyMoN to higher-order: OK, but this might be computationally VERY expensive, don\'t you think?\n - link how your empirical validation data have features that, even remotely resemble those of the kind of biological data sets (on which no ground truth exist, I sympathise) you focus on.']","[-50, -40, 50]","[0, 20, 80]","[""The sentiment score is -50 because the review is generally critical and points out several unclear aspects and shortcomings of the paper, without offering much positive feedback. However, it's not entirely negative as it provides constructive criticism and suggestions for improvement. The politeness score is 0 (neutral) because the language used is direct and professional, without being overly polite or rude. The reviewer asks straightforward questions and points out issues without using harsh language, but also doesn't use particularly courteous phrasing. The review focuses on technical content rather than personal comments, maintaining a neutral tone throughout."", ""The sentiment score is -40 because the review is generally critical, pointing out several shortcomings of the paper. The reviewer mentions lack of clarity on new biological insights, challenges in interpretation, and the main shortcoming being lack of performance evaluation and comparison to other methods. However, it's not entirely negative as the reviewer acknowledges some computational advantages. The politeness score is 20 because while the reviewer is critical, the language used is professional and constructive. The reviewer uses phrases like 'I agree with...' and 'Overall, the main shortcoming...' which maintain a respectful tone while providing criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the importance of the paper's topic and the method's adaptability to biological data challenges. They also highlight the diverse applications and performance assessments presented. However, the score is not higher due to the numerous questions and clarifications requested. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases their comments as questions or suggestions, and acknowledges their own limitations ('I know very little about the literature in the subject'). The reviewer also expresses sympathy for the challenges faced by the authors ('on which no ground truth exist, I sympathise'). The tone is constructive and aimed at improving the paper rather than criticizing it harshly.""]"
"['The paper proposes a data augmentation technique where the input image is sub-sampled by randomly sampling rows and columns without replacement, which the authors call ‘pseudosaccades’. Rather than multiple classifiers, the authors ensemble using multiple ‘pseudosaccades’ as input, with the same network.\n\nComments:\nI think that the proposed augmentation is a neat trick. However, the inner-workings of the method are poorly presented (or not well understood). For eg. In section 3.5, while discussing the effects of the method on individual classes, the authors mention ‘different architectures do tend to be affected by the pseudosaccades differently’ and provide no further insights.\n\nThere are no experiments that compare this method with other standard data augmentation techniques. For instance, one could use a similar ensembling technique for transformations like shear, translation, rotation, etc. by randomly sampling their corresponding parameters. I would be interested in experimental results that compare the proposed ensemble with ensembles constructed using these common techniques.\n\nSince there is no reason for this technique to be used in isolation (I found no such motivation in the paper), it would be insightful to have experimental results where this technique is combined with the aforementioned standard augmentation techniques. Will this method’s impact on the accuracy change with these other augmentations? (Ablation studies would be useful).\n\nThis is a a form of regularization and can be thought of reverse structured dropout. Also have the authors compared this with Cutout [1, 2]? Similar experiments and comparisons would be insightful.\n\n[1] Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.\n[2] Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. Random erasing data augmentation. arXiv preprint arXiv:1708.04896, 2017.\n\nIn summary:\nThe performance improvements are incremental. The paper lacks sufficient technical contribution. Further, it does not provide comparisons with standard techniques and similar augmentation methods to demonstrate the usefulness of the method.  ', '\tThis paper proposes a data ensemble method for image classification: sub sample an image, classify each sub sample, and vote those sub samples to get the final decision.\n\t\n\tQuestions:\n\t1. The validation accuracy of ResNet is much lower than that reported in the original ResNet paper, https://arxiv.org/pdf/1512.03385.pdf. For example, the top-1/5 accuracy of RestNet-50 is 79+/94+, which is only about 70+/89+% in this paper. Similarly, there is a big gap between the results of ResNet-152 reported in this paper and the original ResNet paper. Maybe I misunderstand something; otherwise, the results in this paper are not reliable.\n\t2. This work does not compare with any other data augmentation methods for testing, e.g., the widely used 10-crop test [ref1, ref2]: “At test time, the network makes a prediction by extracting five 224 × 224 patches (the four corner patches and the center patch) as well as their horizontal reflections (hence ten patches in all), and averaging the predictions made by the network’s softmax layer on the ten patches.”\n        3. A minor issue is the practical value of this work. If one can afford the computational cost of data ensemble test, why not train m (as the data ensemble in this paper) models and ensemble them given that ensemble of models usually brings more accuracy improvement? Note that the training of multiple models is conducted offline and the ensemble of models is of the same computation cost compared with the method in this paper. \n\n[ref1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. ""Imagenet classification with deep convolutional neural networks."" Advances in neural information processing systems. 2012.\n[ref2] He, Kaiming, et al. ""Deep residual learning for image recognition."" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n', 'Pros:\n-- Superior empirical results are the key highlights of this paper.\n-- The experiments are well designed and benchmarked against the state-of-the-art models.\n\nCons:\n-- One typically uses affine transformations of the training images to improve the performance of the CNN. From that perspective, the paper does not offer any new insight. I am not entirely convinced that this is a novel enough contribution to be accepted in ICLR.\n-- The ""ensemble of ensembles"" approach described in Section 3.5 is not clear. \n-- Overall, the paper does not have much novelty, but the results are quite promising.']","[-50, -50, -20]","[50, 20, 50]","[""The sentiment score is -50 because while the reviewer acknowledges the proposed technique as a 'neat trick', they express several criticisms and concerns. They point out that the inner workings are poorly presented, there's a lack of comparison with standard techniques, and insufficient technical contribution. The overall tone suggests that the paper needs significant improvements. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think', 'I would be interested', and 'it would be insightful', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects ('neat trick') before presenting criticisms, which is a polite approach to feedback."", ""The sentiment score is -50 because the reviewer raises significant concerns about the paper's methodology and results. They point out discrepancies in the reported accuracy compared to the original ResNet paper, lack of comparison with other data augmentation methods, and question the practical value of the work. These criticisms suggest a negative sentiment, though not entirely dismissive.\n\nThe politeness score is 20 because the reviewer maintains a professional and neutral tone throughout. They phrase their concerns as questions or observations rather than direct criticisms. The use of phrases like 'Maybe I misunderstand something' shows a willingness to consider alternative explanations. However, the review doesn't go out of its way to be overtly polite or complimentary, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('superior empirical results', 'well designed' experiments), they express significant doubts about the novelty and contribution of the paper. The phrase 'not entirely convinced' and the statement that the paper 'does not have much novelty' indicate a generally negative sentiment, albeit not extremely so. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They acknowledge the strengths of the paper before presenting criticisms, and phrase their concerns in a constructive manner (e.g., 'I am not entirely convinced' rather than making blunt negative statements). The reviewer maintains a balanced tone, presenting both pros and cons, which contributes to the overall politeness of the review.""]"
"['The paper proposes yet another variant of the celebrated Dropout algorithm. Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer. \n\nAs the authors have admitted in the paper (Sec. 1.2), there is a variety of methods already addressing the same problem. They argue that contrary to some of these methods ""jumpout does not rely on additional trained models: it adjusts the dropout rate solely based on the ReLU activation patterns. Moreover, jumpout introduces negligible computation and memory overhead relative to the original dropout methods, and can be easily incorporated into existing model architectures.""\n\nHowever, this is argument is certainly untrue and rather misleading. The works of Kingma et al. (2015) and Molchanov et al. (2017), that the authors cite, does not introduce additional trained models. In addition, there is additional related work that the authors do not cite, but ought to: \n\n[1] Yarin Gal, Jiri Hron, Alex Kendall, ""Concrete Dropout,"" Proc. NIPS 2017.\n[2] Yingzhen Li, Yarin Gal, ""Dropout Inference in Bayesian Neural Networks with Alpha-divergences,"" Proc ICML 2017.\n[3] Harris Partaourides, Sotirios Chatzis, “Deep Network Regularization via Bayesian Inference of Synaptic Connectivity,” J. Kim et al. (Eds.): PAKDD 2017, Part I, LNAI 10234, pp. 30–41, 2017. \n\nThese methods also address a similar problem, without introducing extra networks or imposing extra costs art inference time. Thus, citing them, as well as COMPARING to them, is a necessity for this paper to be convincing.\n\nThese crucial shortcoming aside, there are various theoretical claims in this paper that are not sufficiently substantiated. To begin with, the arguments used in the last paragraph of page 4 seem at least speculative; then,  the authors proceed to propose a solution to the alleged problem in the beginning of page 5. They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem; they limit themselves to noting that other selections, such as the Beta distribution, may also be considered in the future. We must also underline that [3] have suggested exactly that; sampling from a Beta. \n\nFinally, the last two modifications the authors propose seem reasonable, yet they are extremely heuristic. No one knows (which can be guaranteed through theoretical proofs or solid experimental evidence) that without these the method would not work. In addition, previous papers, e.g. [1-3] achieve similar goals in a principled fashion (ie by inferring proper posterior densities); without experimental comparisons, nobody knows which paradigm is best to adopt. \n\n', 'This paper proposes jumpout, which is a 3 step modification based on dropoout\nthat is designed to work better with batch normalization. Unfortunately, I did not understand the arguments on locally linear regions and ReLu and its relationship with the monotone dropout scheme,\nor why the half Gaussian is chosen.\n\nStill, jump out the procedure is fairly clear in Algorithm 1, and the results seems good.\nHowever, I could not make out much of why each step is done, and could not find empirical tests of the value of each step.\n\nI think the paper needs more work. All the proposals seem very heuristic, and it is important to test their separate effects. It should be easy to perform a ablation analysis since the 3 proposed steps are pretty independent and can be tested separately. Since two of these have to do with modifying the dropout rate, it would be important to compare with carefully cross-validated dropout rates, which I also do not see.', 'Authors propose three modifications to dropout, specifically in context of dropout applied to deep networks utilizing the ReLU non-linearity.  The three modifications seem independently motivated and aim to overcome separate potential shortcomings of the current dropout approach.  These three modifications are combined into a new approach termed Jumpout.\n\nOverall I find this to be a weak paper requiring further work, for the following main reasons:\n\n* The proposed modifications are intuitively motivated and then empirically supported.  However, I find the intuitive reasoning unclear and have to lean much more on empirical evidence.  For instance, the motivation for modification 2 “dropout rate adapted to number of active neurons”, is that in case ReLU causes a large number of neurons to ‘shut down’ then the dropout rate in that layer should be reduced (or increased, depending on how it is defined) causing fewer neurons to further dropout.  However, if preventing co-adaptation is a reason to dropout neurons then the issue of conditional correlation (or co-activation given related inputs) will remain regardless of number of active neurons in a layer, thus changing the dropout rate as a function of ReLU activation is not fully justified.  Similarly, modification 3 “rescale outputs to work with batch normalization” proposes exponentiation by -0.75 with weak justification as a compromise.\n\n* I find the empirical evidence and support for the three modifications lacking in detail.  The authors provide results of the combined Jumpout technique on a number of tasks, but do not demonstrate effectiveness and contribution of individual modifications on error rates on the tasks they evaluated.\n\n* I also find the baseline systems to be on the weaker side (e.g. on CIFAR100 many systems now have higher than 82% accuracy with best being over 84, on STL-10 many systems now are well above 85%).\n']","[-60, -30, -70]","[-20, 20, 20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several critical issues with the paper, including misleading arguments, lack of proper citations, insufficient substantiation of theoretical claims, and the heuristic nature of proposed modifications. The reviewer also suggests that the paper's main argument is 'untrue and rather misleading'. However, it's not entirely negative as the reviewer acknowledges some aspects as 'reasonable', preventing it from being at the extreme negative end.\n\nThe politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and direct. Phrases like 'certainly untrue and rather misleading' and 'crucial shortcoming' are quite harsh. The reviewer also uses phrases like 'nobody knows' and 'No one knows' which could be seen as dismissive. However, the reviewer does use some neutral language and acknowledges some positive aspects, preventing the score from being extremely negative."", ""The sentiment score is -30 because the review expresses several concerns and suggests that 'the paper needs more work'. However, it's not entirely negative as it acknowledges that 'the results seems good'. The politeness score is 20 because the reviewer uses polite language and constructive criticism, such as 'I think' and 'it would be important to', rather than harsh or dismissive statements. The reviewer also acknowledges their own lack of understanding in some areas, which comes across as humble. However, the overall tone is more neutral than overtly polite, hence the moderate positive score."", ""The sentiment score is -70 because the reviewer states that it is a 'weak paper requiring further work' and lists several major criticisms. They find the intuitive reasoning unclear, the empirical evidence lacking, and the baseline systems weak. These are significant negative points, though not entirely dismissive, hence not the lowest possible score. The politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone. They use phrases like 'I find' and 'Overall I find' to present their opinions, which is a polite way of expressing criticism. They also provide specific reasons for their concerns, which is constructive. However, the language is not overtly polite or complimentary, keeping the score only slightly positive.""]"
"['The authors present a simple algorithm based on the statistics of neural activations of deep networks to detect out-of-distribution samples. The idea is to use the existing running estimate of mean and variance within BatchNorm layers to construct feature representations that are later fed into a simple linear classifier. The authors demonstrate superior performance over the previous state-of-art in the standard evaluation setting and provide fascinating insights and empirical analysis of their method.\n\nThere are several aspects of this work that I admire.\n\n- The authors evaluate the generalization of their OOD detection model through evaluation against unseen OOD samples. This critical evaluation strategy is not typical in this literature and is much needed.\n- The organization of the material and the depth of the discussion is of high quality. They discuss and connect the previous work, they clearly explain the idea and provide empirical results to support the design decisions, and run several experiments to evaluate their method from different angles followed by interesting discussions.\n- The proposed method is easy to implement and has a minimal runtime complexity with no adverse effect on the underlying classifier.\n- The source code is already included in the submission.\n\nMy only concern is that the feature pooling strategy first averages the input spatially, then across the channels. This feature size reduction is necessary because we have to ensure the following OOD classifier does not overfit in the validation stage. However, this reduction also introduces a permutation invariance in the feature space that is not desirable in OOD sample detection. I think it would make the work more valuable if the authors also take a critical look at the possible failure cases -- a short discussion of the weaknesses and assumptions. \n\nOverall, the paper is technically sound and well-organized with sufficient coverage of the previous work. A thorough series of evaluations support the claims. It is a novel combination of existing techniques. The empirical evidence is strong and insightful. Given the simplicity of the method, I would expect a quick adoption by the community.\n------\nRev. In light of the rebuttal and the following discussions I have updated my rating to 7.', ""There has been recent interest in using statistics and information summary measures to evaluate what deep nets are trying to do. Following the line of work, the paper suggests to use mean and variance of Z-scores accumulated across all layers/channels as features to distinguish ID and OOD samples. Simple idea but needs some work in its current format. \n\nFirstly, the bulk of content in Sections 2 and 3 can be reduced/shortened since the importance of normalized statistics to understand learning models is well known, and not novel. \n\n1) The choice of datasets/netowrks needs to be understood here. How is the OOD summary changing as more layers are added into computing the score (since the score is basically averaging all layers'/channels contribution)? \n2)  What happens if we split the ID itself into two datasets and train on one, while using the other as OOD?\n3)  (r) is random and (c) is not is it for the TinyImages? Seems to be the other way around. \n4) What is the influence of the dataset? Since the summaries are first order statistics, there can be significant dependance of the 'coverage' of training data (i.e., how many and how good of instances are present for each class)? This is purely a sampling problem and it may reciprocate in the OOD scores (back to first order statistics). This needs to be tested. \n5) Statistical tests of significance needs to be reported for the performance summaries shown in the Tables. \n\n"", 'Summary: A relatively simple approach for detecting out-of-distribution samples by having a parallel logistic regression model using simple statistics (mean and variance) over output of each batch normalisation layer, in order to discriminate between in-distribution and out-of-distribution samples. Results are appealing but presentation is lacking clarity at time and some doubts on the correctness of the experiments remain.\n\nWith the goal of detecting out-of-distribution sets, the authors propose to use logistic regression over simple statistics (mean and variance) of each batch normalization layer of CNN in order to discriminate between in-distribution (ID) and out-of-distribution (OOD) samples. They argue that ID and OOD samples can be discriminated with these statistics.\n\nQuality: The motivations of the paper are clear, it aims at having better capacity to detect OOD samples with a method that involves less computations. However, the quality of the experiments is not good enough and I have doubts on their validity.\n\nOriginality: Ok. The proposal is relatively simple and is based on the intuition that statistics for the batch normalization is useful to detect OOD samples. The problem is not new, the approach is relatively ad hoc, but it works.\n\nSignificance of the work: The results reported are unreasonably good. Although the authors claim the improvement of detection of OOD is significant, the results achieved by detecting **all** the out-distribution samples sounds weird and irrational. How rejecting all Tiny-ImageNet is possible while there are several overlap between the classes presented in TinyImageNet vs. Cifar10/Cifar100 (cf. Table 8)? To me, it looks like the model either overfitted something else than the content of the images, maybe the background noise or similar regarding the nature of the data. More experiments with different in-distribution datasets should be made to be convincing. All experiments reported are using either Cifar10 or Cifar100 as in-distribution datasets.\n\nThe author also claim using few samples from a single OOD set is enough for training the regressor that provides OOD-ness score. Is it true for any OOD set or only a carefully chosen OOD set can demonstrate this behavior? What is the criteria for selecting a good OOD set for training the regressor?\n\nDespite of the fact that the proposed method is heavily dependent on the threshold, the authors barely discuss of it. I am assuming that threshold is on OOD-ness score, is that correct? How does look like the OOD-ness score for an ID set over different OOD sets? Providing the OOD-ness score for ID and OOD could reflect how the proposed method is sensitive to a selected threshold. In other words, is selecting a fix threshold will to the TPR / FPR across different OODs.\n\nThe overall writing style is perfectible. I did not found the paper super clear in the presentation and it is difficult to really get all useful information for it. However, the authors appear knowledgeable of the literature and the overall structure is clear.\n\nAn example of lack of clarity in the explanations: in Table 7, I have difficulty to make sense of the 100% achieved for “Ours (pair)” vs “Ours”. Is the “Ours (pair)” the rate obtained with the exact pair used for adjusting the threshold, while “Ours” is on another dataset? If not, what this mean? Moreover, reporting columns all with 100% is not a good practice, it seems to be a stunt to impress the reader, while not carrying much in term of content and understanding.\n\nIn Table 8, I do not understand what the values in parenthesis means. \n\nAnother element: why for training the regressor, the IN and OOD samples are not selected from their corresponding training sets instead of splitting their test sets to a validation and test sets?\n']","[90, -20, -30]","[80, 20, 20]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer expresses admiration for several aspects of the work, praises the organization and depth of discussion, and highlights the method's ease of implementation and minimal runtime complexity. The only concern mentioned is minor and presented constructively. The final statement suggests quick adoption by the community, indicating strong approval. The politeness score is 80 because the language used is consistently respectful and professional. The reviewer uses phrases like 'I admire' and provides balanced feedback, offering praise while also suggesting a potential area for improvement in a considerate manner. The tone is collegial and supportive throughout, without being overly deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution to a recent line of work, they state that the idea is 'simple' and 'needs some work in its current format.' The review then lists several areas for improvement, indicating that significant revisions are needed. However, the tone is not entirely negative, as the reviewer provides constructive feedback. The politeness score is slightly positive (20) because the reviewer uses neutral language and avoids harsh criticism. They offer suggestions for improvement in a professional manner, using phrases like 'needs to be understood' and 'needs to be tested' rather than more critical language. The reviewer also asks questions to prompt the authors to consider different aspects of their work, which is a polite way of pointing out potential weaknesses."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (e.g. 'Results are appealing', 'motivations of the paper are clear'), there are significant criticisms and doubts expressed about the quality and validity of the experiments, as well as the clarity of presentation. Phrases like 'quality of the experiments is not good enough', 'doubts on their validity', and 'results reported are unreasonably good' indicate a generally negative sentiment. The politeness score is 20 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and asking clarifying questions rather than making harsh criticisms. The language used is respectful (e.g. 'I have difficulty to make sense of', 'I did not found the paper super clear') even when pointing out flaws, which indicates a polite approach to the review.""]"
"['This paper combines a number of ideas to train generative models with (deep) structured constraints. The general idea is similar to Flow-GAN, which learns a normalizing flow-based generator by optimizing the negative loglikelihood with an augmented GAN loss. However, It’s difficult to impose prior structure information in the GAN framework. To address this problem, the authors proposed to minimize a so-called Gibbs-regularized variational bound of Jeffery divergence, which is the summation of KL and reverse KL divergence. The authors provide some justification that the Jeffery divergence works by yielding good mass-covering and mode-seeing properties. \n\nIt appears that the parameterization and adaptation of v throughout optimization is the key contribution of this work --- the technical details are not clear from the paper.\n\n1.    Typo in the training objective (Eq .1):  the second (or the first) ""sup"" should be removed? \n\n2.    Section 2.3 is very confusing. Particularly, how is the parameter \\phi introduced? What’s the detailed update of \\phi? \n- ""We now observe that our methods can also be interpreted as a way of learning v as a Gibbs distribution approximating p."" If v_\\phi(x) is a distribution, what’s the parametric form of v?  \n- ""Generally, this is achieved by structuring the energy function V_\\phi:=\\log v_\\phi."" It seems that V_\\phi(x) is a scalar-valued function that represents the negative energy of the distribution v_\\phi(x), however, why the distribution is self-normalized? Specifically, why \\int \\exp(V_\\phi) dx = 1? Otherwise, how the authors deal with the partition function \\int \\exp(V_\\phi(x)).  \n- It is unclear to me why the inner loop optimization is connected with Itakura-Saito divergence minimization? The authors may consider including the detailed proofs?\n\n3.    With the given description, the proposed algorithm is not easy to follow and implement by the reader. The paper would benefit from an Algorithm box with pseudocode.\n\nIf the authors can fully address the concerns above, I will consider changing the scores.  \n\nOther comments:\n1. The empirical results are fairly weak. Similar datasets are used, the authors may consider evaluating their approach on various different tasks. \n\n2. Duplicate citations – R2P2 [35] [36]\n\n3. Other related papers:\n - Belanger et al., End-to-End Learning for Structured Prediction Energy Networks, ICML 17\n- Tu et al., Learning Approximate Inference Networks for Structured Prediction, ICLR 18', ""The paper proposes to reparameterize the discriminator to be an explicit function of two densities so that one could inject domain specific knowledge easily. As the authors say, that one way to inject domain specific information is by learning an energy function. Making use of this intuition, authors proposed to  regularize the discriminator in  \n(GANs) framework by leveraging structured Gibbs distributions.\n\nI found the introduction a bit hard to read. Otherwise paper is written in a readable way. \n\nSomething which I like about this paper, is authors use the proposed method for actual RL problems as compared to just image generation. I think this is important as well as interesting.  As a community we should be moving towards evaluating generative models for the problems where we actually want to use generative models for.\n\nSome questions:\n\n- I'm not sure if the paper is really novel as the authors themselves point out that it corresponds to adding adversarial component in R2P2. \n- I also did not find results very convincing. As I said, its important to evaluate on RL problems ONLY if it makes sense on toy problems first. Like in the paper, authors made a big claim about reducing spurious modes, but it has not been demonstrated any where per se. May be authors can construct a toy problem in which they can show that the spurious mode issue, and how the proposed method kills these spurious modes.  This also reminds me of the literature in Boltzmann machines and more recently in Variational Walkback [1]. This could also be cited, and could be interesting to authors.\n\n[1] Variational Walkback, https://arxiv.org/abs/1711.02282. The authors in Variational walkback also make the assumption p == q. \n\nWhat would make the paper stronger ?\n- Constructing toy problems in order to illustrate the mode coverage and spurious modes issue would be interesting."", 'Summary: The paper tries to answer the problems of regularizing GANS. They reparametrize the discriminator to be an explicit function of two densities: the generator probability density function q and a structured Gibbs distribution v.  \n\nComments:\n1: This paper focuses on mode coverage problems, where spurious modes of learned model(q) not supported by target model(p) are pruned off.  It is not clear why this is a significant problem.  GAN trained models typically suffer from mode collapsing, requiring additional noise injection to support generation of diverse data.  This work seems to argue that the opposite is worth paying attention to, focusing on removal of modes.\n\n2: The implementation of the architecture is similar to R2P2, except for the introduction of a new adversarial component. But according the evaluation in table 1 and table 2, we see that baseline model R2P2 performs better in -H(p,q) and for -H(q, pKDE) the value is near equal to their model. \n\n3: They assume the generator is invertible, which enables the analytic evaluation of the q. But no supporting evidence or design architecture for the statement above is provided.\n\n4: The explanation of imposing structure on the model distribution is not clear. In the introduction they first claim “we cannot impose structure directly on the joint distribution of a GAN’s outputs.” But after they claim “we submit that regularizing the structure of a GAN’s generator and discriminator is generally more difficult than imposing meaningful structure directly on the model distribution, which we will refer to as q. These two statements conflict because the model distribution is a joint distribution of GAN’s outputs.\n\n\n6 Typos: \n1)\tin equation(1) we should minimize q for all the terms. \n2)\tin equation(1) first term is unrelated with v. \n3)\tin equation(1) the sup is for the last two terms. \n4)\tin equation(2) in RHS of equation the first term q_ |  should be q_ .\n\n7: Writing could be improved.\n\n8: In table 2 what’s the meaning of evaluation metric Road%\n']","[-50, 20, -50]","[20, 60, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'combines a number of ideas', 'address this problem'), they express significant concerns and confusion about key aspects of the work. The reviewer states that 'technical details are not clear', finds Section 2.3 'very confusing', and notes that 'empirical results are fairly weak'. They also state that they will 'consider changing the scores' only if concerns are fully addressed, implying current scores are not positive. The politeness score is 20 because the reviewer uses generally professional language and offers constructive feedback. They use phrases like 'The paper would benefit from...' and 'The authors may consider...', which are polite ways of suggesting improvements. However, the score is not higher because the review is quite direct in its criticisms without much softening language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as its readability and the use of the proposed method for actual RL problems. However, they also express concerns about novelty and the lack of convincing results, which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides suggestions for improvement without being harsh or dismissive. They use phrases like 'I found,' 'I think,' and 'Something which I like' to express their opinions politely. The reviewer also acknowledges the importance of the authors' work in evaluating generative models for RL problems, which adds to the politeness of the review."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several issues and inconsistencies. The reviewer questions the significance of the problem addressed, notes that the proposed model doesn't outperform the baseline, and highlights conflicting statements in the introduction. However, it's not entirely negative as the reviewer acknowledges the paper's focus and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language like 'It is not clear' and 'The explanation... is not clear' rather than harsh or dismissive phrasing. The reviewer also provides specific, actionable feedback such as pointing out typos and suggesting improvements to the writing, which is helpful and considerate. The overall tone is more matter-of-fact than overtly polite, but it avoids rudeness.""]"
"['The authors argue that graph neural networks based on the message passing frameworks are not able to infer the topological structure of graphs. Therefore, they propose to use the node embedding features from DeepWalk as (additional) input for the graph convolution. Moreover, a graph pooling operator is proposed, which clusters node pairs in a greedy fashion based on the l2-distances between feature vectors. The proposed methods are evaluated on seven common benchmark datasets and achieve better or comparable results to existing methods. Moreover, the method is evaluated using synthetic toy examples, showing that the proposed extensions help to infer topological structures.\n\nA main point of criticism is that the authors claim that graph convolution is not able to infer the topological structure of a graph when no labels are present. In fact the graph convolution operator is closely related to the Weisfeiler-Lehman heuristic for graph isomorphism testing and can distinguish most graphs in many practical application. Therefore, it is not clear why DeepWalk features would increase the expressive power of graph convolution. It should be stated clearly which structural properties can be distinguished using DeepWalk features, but no with mere graph convolution.\nThe example on page 4 provides only a weak motivation for the approach: The nodes v_1 and v_2 should be indistinguishable since they are generated using the same generator. Thus, the problem is the mean/max pooling, and not the graph convolution. When using the sum-aggregation and global add pooling, graphs with two clusters and graphs with three clusters are distinguishable again. Further insights how DeepWalk helps to learn more ""meaningful"" topological features are required to justify its use.\n\nClustering nodes that are close in feature space for pooling is a reasonable idea. However, this contradicts the intuition of clustering neighboring nodes in the graph. A short discussion of this phenomenon would strengthen the paper in my opinion.\n\nThere are several other questions that not been answered adequately in the article.\n\n* The 10-fold cross validation is usually performed using an additional validation set. What kind of stopping criteria has bee use? * It would be helpful to provide standard deviations on these small datasets (although a lot of papers sadly dismiss them).\n* I really like the use of synthetic data to show superior expressive power, but I am unsure whether this can be contributed to DeepWalk or the use of the proposed pooling operator (or both). Please divide the results for these toy experiments in ""GEO-DEEP"" and ""GEO-deep no pooling"". As far as I understand, node features in different clusters should be indistinguishable from each other (even when using DeepWalk), so I contribute this success to the proposed pooling operator.\n* A visualization of the graphs obtained by the proposed pooling operator would be helpful. How do the coarsened graphs look like? Given that any nodes can end up in the same cluster, and the neighborhood is defined to be the union of the neighboring nodes of the node pairs, I guess coarsened graphs are quite dense.\n* DiffPool (NIPS 2018, Ying et al.) learns assignment matrices based on a simple GCN model (and thus infers topological structure from message passing). How is the proposed pooling approach related to DiffPool (except that its non-differentiable)? How does it perform when using only the features generated by a GCN? How does it compare to other pooling approaches commonly used, e.g., Graclus? At the moment, it is quite hard to judge the benefits of the proposed pooling operator in comparison to others.\n\n\nIn summary, the paper presents promising experimental results, but lacks a theoretical justification or convincing intuition for the proposed approach. Therefore, at this point I cannot recommend its acceptance.\n\n\nMinor remarks:\n\n* p2: The definition of ""neighbour set"" is needless in its current form.\n* p2: The discussion of graph kernels neglects the fact that many graph kernels compute feature vectors that can be used with linear SVMs.\n\n-----------\nUpdate:\nThe comment of the authors clarified some misunderstandings. I now agree that the combination of DeepWalk features and GNNs can encode more/different topological information. I still think that the paper does not make this very clear and does not provide convincing examples. I have update my score accordingly.', 'The authors propose a method for learning representations for graphs. The main purpose is the classification of graphs.\n\nThe topic is timely and should be of interest to the ICLR community. \n\nThe proposed approach consists of four parts: \n\nInitial feature transformation\nLocal features aggregation\nGraph pooling\nFinal aggregator\n\nUnfortunately, each of the part is poorly explained and/or a method that has already been used before. For instance, the local feature aggregation is more or less identical to a GCN as introduced by Kipf and Welling. There are now numerous flavors of GCNs and the proposed aggregation function in (2) is not novel. \n\nGraph pooling is also a relatively well-established idea and has been investigated in several papers before. The authors should provide more details on their approach and compare it to existing graph pooling approaches. \n\nNeither (1) nor (4) are novel contributions. \n\nThe experiments look OK but are not ground-breaking and are not enough to make this paper more than a mere combination of existing methods. \n\nThe experiments do not provide standard deviation. Graph classification problems usually exhibit a large variance of the means. Hence, it is well possible that the difference in mean is not statistically significant. \n\nThe paper could also benefit from a clearer explanation of the method. The explanation of the core parts (e.g., the graph pooling) are difficult to understand and could be made much clearer. \n', 'This paper proposes a deep GNN network for graph classification problems using their adaptive graph pooling layer. It turns the graph down-sampling problem into a column sampling problem. The approach is applied to several benchmark datasets and achieves good results.\n\nWeakness\n\n1.\tThis paper is poorly written and hard to follow. There are lots of typos even in the abstract. It should be at least proofread by an English-proficient person before submitted. For example, in the last paragraph before Section 3. “In Ying et al. ……. In Ying et al.”\n2.\tIn paragraph 1 of Section 3, there should be 9 pixels around the center pixel including itself in regular 3x3 convolution layers.\n3.\tThe definition of W in Eq(2) is vague. Is this W shared across all nodes? If so, what’s the difference between this and regular GNN layers except for replacing summation with a max function?\n4.\tThe network proposed in this paper is just a simple CNN. GNN can adopt such kind of architectures as well. And I didn’t get numbers of first block in Figure 1. The input d is 64?\n5.\tThe algorithm described in Algorithm 1 is hard to follow. There are some latex tools for coding the algorithms.\n6.\tThe authors claim that improvements on several datasets are strong. But I think the improvement is not that big. For some datasets, the network without pooling layers even performs better at one dataset. The authors didn’t provide enough analysis on these parts.\n\nStrength:\n1.\tThe idea used in this paper for graph nodes sampling is interesting. But it needs more experimental studies to support this idea. \n']","[-50, -50, -30]","[50, 20, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some promising experimental results, they ultimately cannot recommend acceptance due to lack of theoretical justification and convincing intuition. The review starts with neutral observations but becomes increasingly critical, pointing out several weaknesses and unanswered questions. The update at the end slightly improves the sentiment, but the overall tone remains negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They acknowledge positive aspects ('promising experimental results', 'I really like the use of synthetic data') alongside critiques, and phrase concerns as questions or suggestions rather than harsh statements. The reviewer also shows willingness to update their view based on author feedback, which demonstrates respect and open-mindedness."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings and lack of novelty. However, it's not entirely negative as it acknowledges the timely topic and potential interest to the community. The politeness score is 20 because while the reviewer maintains a professional tone and offers some positive comments, the criticism is direct and somewhat blunt. The reviewer uses phrases like 'Unfortunately,' and 'poorly explained,' which are polite ways of expressing criticism, but also states that the paper is 'not ground-breaking' and 'mere combination of existing methods,' which are more direct criticisms. The reviewer also offers constructive feedback for improvement, which adds to the politeness."", ""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper (interesting idea, good results on benchmarks), they list more weaknesses than strengths and use phrases like 'poorly written' and 'hard to follow'. The overall tone is critical, but not entirely negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language like 'The authors claim' and 'I didn't get' rather than harsh criticisms. They also acknowledge strengths alongside weaknesses. However, some direct statements like 'poorly written' slightly reduce the politeness score from being highly polite.""]"
"['The paper aims at a better understanding of the positive impacts of Batch Normalisation (BN) on network generalisation (mainly) and  convergence of learning. First, the authors propose a novel interpretation of the BN re-parametrisation. They show that an affine transform of the variables with their local variance (scale) and mean (shift) can be interpreted as a decomposition of the gradient of the objective function into a regressor assuming that the gradient is parallel to the variables (up to a shift) and the residual part which is the gradient w.r.t. to the new variables. In the second part of the paper, authors review various normalisation proposals (differing mainly in the subset of variables over which the normalisation statistics is computed) as well as the known empirical findings about the dependence of BN on the batch size. The paper presents an experiment that combines two normalisation variants. A further experiment strives at regularising BN for small batch sizes.\n\nUnfortunately, it remains unclear what questions precisely the authors answer in the second part of the paper and, what is more important, how they are related to the novel interpretation of BN presented in the first part. This interpretation holds for any function and can be possibly seen as a gradient pre-conditioning. However, the authors do not ""extend"" it towards the gradients w.r.t. the network parameters and do not consider the specifics of the learning objectives (a sum of functions, each one depending on one training example only). The main presented experiment combines layer normalisation with standard batch normalisation for a convolutional network. The first one normalises using the statistics over channel and spatial dimensions, whereas the second one uses the statics over the batch and spatial dimensions. The improvements are rather marginal, but, what is more important, the authors do not explain how and why this proposal follows from their new interpretation of BN.\n\nOverall, in my view, this paper is premature and not appropriate for publishing at ICLR in its present form.\n', 'The primary technical contribution comes from Section 2, where it is demonstrated that the normalized back-propagated gradients obtained from a BN layer can be viewed as the residuals of the gradients obtained without BN regressed via a simple two-parameter model of the activations.  In some sense though this result is to be expected, since centering data (i.e., removing the mean as in BN) can be generically viewed as computing the residuals after a least squares fit of a single constant, and similarly for de-trending with respect to a single independent variable, in this case the activations.  So I\'m not sure that Theorem 1 is really that much of an insightful breakthrough, even if it may be nice to work through the precise details in the specific case of a BN layer and the relationship to gradients.\n\nBut beyond this a larger issue is as follows:  This paper is framed as taking a step in explaining why batch normalization (BN) works so well.  For example, even the abstract mentions this as an unsettled issue in motivating the proposed analysis.  However, to me the interpretation of BN as introducing a form of least squares fit does not really extend our understanding of why it actually works better in practice, and this is the biggest disconnect of the paper.  The new perspective presented might be another way to interpret BN layers, but it unfortunately remains mostly unanswered exactly why this new perspective is relevant in actually explaining BN behavior.\n\nThe presented normalization theory is also used to motivate heuristic modifications to standard BN schemes.  For example, the paper proposed concatenating BN with a layer normalization layer, demonstrating some modest improvement on CIFAR-10 data.  But again, I don\'t see how viewing these normalization schemes as least-squares residuals motivates such concatenation any more than the merits of the original versions themselves.  Moreover, it is not even clear that BN+LN is in fact generally better since only a single data set is considered.  There are also no comparisons against competing BN modifications such as switch normalization (Luo et al. 2018) which also involves a hybrid method combining aspects of LN and BN.  Why not compare against approaches like this?\n\nTo conclude, in Section 6 the paper asks ""Why do empirical improvements in neural networks with BN keep the gradient-least-squares residuals and drop the explained portion?""  But this question is not at all answered but rather deferred to future work.  For me this was a disappointment as this would seem to be an essential ingredient for actually developing a meaningful theory for why BN is helpful in practice.\n\n\nOther comments:\n\n* The analysis from Section 2, including Theorem 1, assume that the BN parameters c and b can be ignored (presumably this means fixing c = 1 and b = 0).  I did not carefully check the details, but do all the same derivations and conclusions still seamlessly go through when these parameters have general values that deviate from this standard initialization?  If not, then I don\'t really see what is the practical relevance, since once learning begins, both b and c will typically shift to arbitrary values.  Below eq. (1) it states that c and b are only ignored for clarity, but then later I did not see any subsequent discussion to handle the general case, which is what would be actually needed for explaining BN behavior in practice.\n\n* Please run a speck-checker.  Example, ""On some leve, the matrix gradient ...""\n\n* The paper cites (Lipton and Steinhardt, 2018) in arguing that reasons for the effectiveness of BN are lacking.  Indeed (Lipton and Steinhardt, 2018) criticize the original BN paper for conflating speculation with explanation, or more precisely, framing speculation about why BN should be helpful as an actual true explanation without clear evidence.  But to me this submission is hovering somewhere in the same category, speculating that regressing away certain portions of the gradient could be useful but never really providing concrete evidence for why this should offer an improvement. ', 'The authors propose a new interpretation of the batch normalization step inside a neural network.\nThe main result shows that the backpropagation of the gradient of some loss function through a batch normalization can be seen as a scaled residual of a least square linear fit. This new interpretation is extended to other normalization technics used in the literature and thus give a ""unified"" view of such methods. \n\nThe idea is simple yet very interesting and well introduced. The theoretical results are good and the proofs are well written and easy to follow.\n\nHowever the arguments brought forward by this new vision of batch normalization in applications look light (see sections 3.3, 4.1, 4.2). A more detailed interpretation of this new vision on a single application and its impact would have been preferred than numerous applications as it is done in this paper. \nNot all the existing normalization methods have been extended with success yet, this makes this unified vision a bit less convincing.']","[-70, -60, 50]","[20, 20, 75]","[""The sentiment score is -70 because the reviewer expresses significant concerns about the paper, stating it is 'premature and not appropriate for publishing at ICLR in its present form.' They point out unclear connections between different parts of the paper and marginal improvements in experiments. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They acknowledge the authors' efforts and explain their concerns without using harsh or rude language. The reviewer uses phrases like 'Unfortunately' and 'in my view' to soften their critique, maintaining a polite tone despite the negative overall assessment."", ""The sentiment score is -60 because the reviewer expresses significant criticism and disappointment with the paper. They question the novelty and relevance of the main contribution, state that the paper fails to explain why batch normalization works better in practice, and express disappointment that key questions are left unanswered. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the 'nice' working through of details.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and academic tone throughout. They use phrases like 'I'm not sure that...' and 'To me this was a disappointment...' which soften the criticism. The reviewer also provides constructive feedback and suggestions for improvement. However, the score is not higher because the criticism is direct and at times quite pointed, without much cushioning language."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses that the idea is 'simple yet very interesting and well introduced' and that the 'theoretical results are good and the proofs are well written and easy to follow.' However, the reviewer also points out some limitations, such as 'light' arguments in certain sections and incomplete extension to all normalization methods, which prevents a higher positive score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper before presenting criticisms. The criticisms are presented as suggestions for improvement rather than harsh judgments, using phrases like 'would have been preferred' instead of more direct negative statements.""]"
"[""The paper casts the problems of value learning and policy optimization, which can be problematic the non-linear setting, into the bilevel optimization framework. It proposes two novel algorithms with convergence guarantees. Although other works with similar guarantees exist, these algorithms are very appealing for their simplicity. A limited empirical evaluation is provided for the value-based method in Acrobot and Mountain Car and in the Atari games Pong and Breakout for the proposed bilevel Actor Critic.\n\nThere are a few missing references to similar, recent work, including Dai et al’s saddle-point algorithm (https://arxiv.org/pdf/1712.10285.pdf). Also, the claim that this is “the first attempt to study the convergence of online reinforcement learning algorithms with nonlinear function approximation” can’t be true (even replacing ‘attempt’ by ‘successfully’, there is e.g. Maei et al.’s nonlinear GTD paper, see below).\n\nAlthough certainly interesting, the claims relating bilevel optimization and the target network are not completely right. E.g. Equation 3.6 as given is a hard constraint on omega. More explicitly, there are no guarantees that either network is the minimizer of the RHS quantity in 3.6.\n\nThe two-timescale algorithm is closer in spirit to the use of a target network, but in DQN and variants the target network is periodically reset, as opposed to what the presented theory would suggest. A different breed of “soft target” networks, which is more closely related to bilevel optimization has been used to stabilize training in DDPG (https://arxiv.org/abs/1509.02971).\n\nThere was some confusion for me on the first pass that you define two algorithms called ‘online Q-learning’ and ‘actor-critic’. Neither algorithm is actually that, and they should be renamed accordingly (perhaps ‘bilevel Q-Learning’ and ‘bilevel actor-critic’?). In particular, standard Q-Learning is online; and the actor-critic method does not minimize the Bellman residual (i.e. I believe the RHS of 3.8 is novel within policy-gradient methods).\n\nOnce we’re operating on a bounded space with continuous operators, Theorem 4.2 is not altogether surprising – a case of Brouwer’s fixed point theorem, short of the result that theta* = omega*, which is explained in the few lines below the theorem. While I do think Theorem 4.2 is important, it would be good to contrast it to existing results from the GTD family of approaches. Also, requiring that |Q_theta(s,a)| <= Qmax is a significant issue -- effectively this test fails for most commonly used value-based algorithms.\n\nThe empirical evaluation lacks any comparison to baselines and serves for little more than as a sanity check of the developed theory. This is probably the biggest weakness of the paper, and is unfortunate given the claim of relevance to e.g. deep RL.\n\n\n\nQuestions\n\nThroughout, the assumption of the data being sampled on-policy is made without a clear argument as to why. Would the relaxation of this assumption affect the convergence results?\n\nCan the authors provide an intuitive explanation if/why bilevel optimization is necessary?\n\nCan you contrast your work with Maei et al., “Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation”?\n\n\nSuggestions\n\nThe discussion surrounding the target network should be improved. In particular, claiming that the DQN target network can be viewed “as the parameter of the upper level optimization subproblem” is a stretch from what is actually shown.\n\nThe paper was sometimes hard to follow, in part because the claims are not crisply made. I strongly encourage the authors to more clearly relate their results to existing work, and ensure that the names they use match common usage.\n\nI would have liked to know more about bilevel optimization, what it aims to solve, and the tools used to do it. Instead all I found was very standard two time-scale methods, which was a little disappointing – I don’t think these have been found to work particularly well in practice. This is particularly relevant in the context of e.g. the target network question.\n\nA proper empirical comparison to existing algorithms would significantly improve the quality and relevancy of this work. There are tons of open-source baselines out there, in particular good state of the art implementations. Modifying a standard implementation to optimize its target network along the lines of bilevel optimization should be relatively easy.\n\nRevision:\nI thank the authors for their detailed feedback, but still think the work isn't quite ready for publication. After reading the other reviews, I will decrease my score from 6 to 5. Some sticking points/suggestions:\n- Some of my concerns remain unanswered. E.g. the actor-critic method 3.8 is driven by the Bellman residual, which is not the same as e.g. the MSPBE used with linear function approximation. There is no harm in proposing variations on existing algorithms, and I'm not sure why the authors are reluctant to do. Also, Brouwer's fixed point theorem, unlike Banach's, does not require a contractive mapping.\n- The paper over-claims in a number of places. I highly recommend that the authors make their results more concrete by demonstrating the implications of their method on e.g. linear function approximation. This will also help contrast with Dai et al., etc."", ""In this paper the authors studied reinforcement learning algorithms with nonlinear function approximation. By formulating the problems of value function estimation and policy learning as a bilevel optimization problems, the authors proposed \nQ-learning and actor-critic algorithms that also contains convergence properties, even when nonlinear function approximations are used.  Similar to the stochastic approximation approach adopted by many previous work such as Borkar (https://core.ac.uk/download/pdf/148488247.pdf), they analyze the convergence properties by drawing connections to stability of a two-timescale ODE. Furthermore they also evaluated the effectiveness of the modified Q-learning/actor-critic algorithms on two toy examples.\n\nIn general I find this paper interesting in terms of addressing a long-standing open question of convergence analysis of actor-critic/Q-learning algorithms, when general nonlinear function approximations are used. Through reformulating the problem of value estimation and policy improvement as a bilevel optimization problem, they proposed modifications of Q-learning and actor-critic algorithms, and under certain assumptions they showed that these algorithms converge, which is a non-trivial contribution. \n\nWhile I appreciate the effort of extending existing analysis of these RL algorithms to general nonlinear function approximation,  I find the result of this paper rather incremental. While convergence results are provided, I am not sure how practical are the assumptions listed in the paper. Correct me if i am wrong, it seems that the assumptions are stated for the sake of proving the theoretical results without much practical justifications (especially Assumption 4.3).  Furthermore how can one ensure that these assumptions hold (for example Assumption 4.3 (i) and (ii), especially on the existence of locally stable equilibrium point) ? Unfortunately I haven't had a chance to go over all the proof details, it seems to me the analysis is built upon two-time scale stochastic approximation theory, which is a standard tool in convergence analysis of actor-critic. Since the contribution of this paper is mostly theoretical, can the authors highlight the novel contribution (such as proof techniques used here that are different than that in standard actor-critic analysis from e.g. https://www.semanticscholar.org/paper/Natural-actor-critic-algorithms-Bhatnagar-Sutton/6a40ffc156aea0c9abbd92294d6b729d2e5d5797)  in the main paper?\n\nMy other concern is on the scale of the experiments. While this paper focused on nonlinear function approximation, the examples chosen to evaluate these algorithms are rather small-scale. For example the domains to test Q-learning are standard in RL, and they were previously used to test algorithms with linear function approximation. Can the author compare their results with other existing baselines?"", 'This paper interprets the fitted Q-learning, policy evaluation and actor-critic as a bi-level optimization problem. Then, it uses two-timescale stochastic approximation to prove their convergence under nonlinear function approximation. It provides interesting view of the these existing popular reinforcement learning algorithms that is widely used in DRL. However, there are several points to be addressed in the revision, which are mainly in some of its claims.\n\nThis paper is mainly a theoretical paper and experiments are carried out on a few simple tasks (Acrobot, MountarinCar, Pong and Breakout). Therefore, it cannot be claimed as “thorough numerical experiments are conducted” as in abstract. This claim should be modified.\n\nFurthermore, it cannot be claimed that this paper is a “first attempt to study the convergence of online reinforcement learning algorithms with nonlinear function approximation in general”. There is a recent work [1], which developed a provably convergent reinforcement learning algorithm with nonlinear function approximation even in the off-policy learning setting.\n[1] B. Dai, A. Shaw, L. Li, L. Xiao, N. He, Z. Liu, J. Chen, L. Song, “SBEED Learning: Convergent Control with Nonlinear Function Approximation”, ICML, 2018.\n\nThe actor-critic algorithm in the paper uses TD(0) as its policy evaluation algorithm. It is known that the TD(0) algorithm will diverge in nonlinear function approximation and in off-policy learning case. I think the actor-critic algorithm analyzed in the paper is for on-policy learning setting. The authors need to clarify this. Furthermore, the authors may need to comment on how to extend the results to off-policy learning setting.\n', 'The authors frame value function estimation and policy learning as bilevel optimization problems, then present a two-timescale stochastic optimization algorithm and convergence results with non-linear function approximators. Finally, they relate the use of target networks in DQN to their two-timescale procedure.\n\nThe authors claim that their first contribution is to ""unify the problems of value function estimation and policy learning using the framework of bilevel optimization."" The bilevel viewpoint has a long history in the RL literature. Are the authors claiming novelty here? If so, can they clarify which parts are novel?\n\nThe paper is missing important previous work, SBEED (Dai et al. 2018) which shows (seemingly much stronger) convergence results for a smoothed RL problem. The authors need to compare their approach against SBEED and clearly explain what more they are bringing. Furthermore, the Fenchel trick used in SBEED could also be used to attack the ""double sampling"" issue here, resulting in a saddle-point problem (which is more specific than the bilevel problem). Does going to the bilevel perspective buy us anything?\n\n=====\n\nIn response to the author\'s comments, I have increased my score.\nThe practical implications of this theoretical work are unclear. It\'s nice that it relates to DQN, but it does not provide additional insight into how to improve existing approaches. The authors could significantly strengthen the paper by expanding in this area.']","[-30, 20, -20, -20]","[50, 60, 50, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting', 'appealing for their simplicity'), there are numerous criticisms and suggestions for improvement. The overall tone suggests the paper is not yet ready for publication. The politeness score is 50 because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I would have liked', 'I strongly encourage'). However, the critique is direct and doesn't use overly deferential language, keeping it from a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer finds the paper 'interesting' and acknowledges its 'non-trivial contribution' to addressing a 'long-standing open question'. However, they also express concerns about the paper being 'rather incremental' and having practical limitations, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They phrase criticisms as questions or personal opinions (e.g., 'I find', 'Can the authors...?') rather than direct attacks. The reviewer also uses polite phrases like 'Correct me if I am wrong' and 'I appreciate the effort', further contributing to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting perspective, they point out several significant issues that need to be addressed. The review starts positively but then lists multiple criticisms, including overstated claims and potential limitations of the study. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions before presenting criticisms. They use phrases like 'interesting view' and provide constructive feedback without harsh language. The reviewer also offers suggestions for improvement and clarification, which is a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they raise several critical points and suggest that the practical implications are unclear. The reviewer questions the novelty of the authors' claims, points out missing important previous work, and suggests that the paper could be significantly strengthened. However, the reviewer does mention that they have increased their score in response to the authors' comments, which prevents the score from being more negative. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions for improvement rather than harsh criticism. The use of phrases like 'The authors could significantly strengthen the paper...' and 'It's nice that...' contribute to a polite tone, even when expressing concerns or suggestions for improvement.""]"
"['Quality is good, just a handful of typos.\nClaritys above average in explaining the problem setting.\nOriginality: scan refs...\nSignificance: medium\nPros: the authors develop a novel GAN-based approach to denoising, demixing, and in the process train generators for the various components (not just inference). Further, for inference, the authors propose an explicit procedure. It seems like a noveel approach to demixing which is exciting.\nCons: The experiments do not push the limits of their method. It\'s difficult to judge the demixing \'power\' of the method because it\'s difficult to tell how hard the problem is. Their method seems to easily solve it (super low MSE). The classification measure is clearly improved by denoising, which is totally unsurprising-- There should definitely be comparison with other denoising methods.\n\nIn general, they don\'t compare to any other methods. Actually in the appendix, comparisons are provided for a basic compressive sensing problem, but their only comparator is ""LASSO"" with a ""fixed regularization parameter"", and vanilla GAN. Since the authors ""main contribution"" (their words) is demixing, I\'m surprised that they did not compare with other demixing approaches, or try on a harder problem. Could you  give some more details about the LASSO approach? How did you choose the L1 parameter?\n\nI have another problem with the demixing experimental setting. On one hand, both the sinusoids and MNIST have ""similar characteristics"" in the sense that they are both pretty sparse, basically simple combinations of primary curves. This actually makes the problem harder for a dictionary learning approach like MCA (referenced in your paper). On the other hand, both signals are very simple to reconstruct. For example, what if you superimposed the grid of digits onto a natural image? Would you be able to train the higher resolution GAN to handle a more difficult setting? The other demixing setting of adding 1\'s and 2\'s has a similar problem.\n\nThe authors need to provide (R)MSE  results that show how well the method can reconstruct mixture components on average over the dataset. The only comparison is visual, and no comparators are provided.\n\nConclusions:\nI\'m actually torn on this paper. On one hand this paper seems novel and clearly contributes to the field. On the other hand, HOW MUCH contribution is not addressed experimentally, i.e. the method is not properly compared with other denoising or demixing methods, and definitely not pushed to its limits. It\'s hard to assess the difficulty of the denoising problem because their method does so well, and it\'s hard to assess the difficulty of demixing because of the lack of comparators.\n\nCaveats:\nI am knowledgeable about iterative optimization approaches to denoising and demixing, especially MCA (morphological component analysis), but *not knowledgeable about GAN-based approaches*, though I have familiarity with GANs.\n\n*********************\nUpdate after author response:\nI think the Fashion-MNIST experiments and comparisons with ICA are many times more compelling than the original experiments. I think this is an exciting contribution to dually learning component manifolds for demixing.', 'This paper proposed two new GAN structures for learning a generative modeling using the superposition of two structured components. These two structures can be viewed as an extension of AmbientGAN. Experiments results on MNIST dataset are presented. Overall, the demixing-GAN structure is relatively novel. However, the potential application seems limited and the experiment result is not sufficient enough to support the idea. Detail comments are as following,\n\n\n1.\tIt seems there are no independent assumption imposed on the addition of two generators. It is possible that the possible model only will works on simple toy example, where the distributions of two structured components are drastic different. Or the performance will be affected by the initialization.  It would be nice if the author test this on more realistic examples, such as the source separation problem in acoustic or the unmixing problem in hyper-spectral images. More detail information about the experiments setting, such as the methods used to initialize the two generators are need. \n2.\tIn the experiment part, it would be nice to have Quantitive results presented, for example PSNR for denoising. Simple comparison with several traditional methods could also help understanding the advantage of the model.\n', 'In this, paper a GANs-based framework for additive (image) denoising and demixing is proposed. The proposed methodology for denoising largely relies on the Ambient GAN model and hence the technical contribution of the paper in this task appears to be limited. Regarding demixing, as explained in the comments below, the proposed model appears to be superficial in the sense that neither theoretical analysis nor thorough empirical evaluation is provided. The proposed method is evaluated on both tasks (i.e., denoising and demixing) by conducting toy experiments on handwritten digits (MNIST).\n\nMore specifically, the authors employ the Ambient GAN to train a generator that generates clean samples when the type of corruption is known (i.e., when corruption is modelled by a known function which interacts with the clean data in an additive way). For denoising, the authors propose to learn the latent variable that generates the clean test image by solving a ridge regularized non-convex inverse problem (Eq. 3). The problem is solved via gradient descent and theoretical analysis on the converge of the algorithm is not provided.  Clearly, this approach has limited practical applications since the corruption function needs to be known which rarely happens in practice.\n\nNext, considering additive demixing, the authors assume that the corruption/structured signal is unknown but it can be modelled using a convolutional network (using the architecture of DCGAN). They employ the same network architecture for modelling the clean data generation process and learn the parameters of both generators using adversarial training. Demixing is performed by solving a similar by solving a similar ridge regularized non-convex inverse problem as in the case of denoising (i.e., Eq. 4). As authors mention in the paper, it is indeed surprising that the proposed GANs-based model with two generators is able to produce samples from the distribution of each signal component by observing only additive mixtures of these signals. Without any assumptions, the proposed model is not identifiable. This is my main concern regarding this paper and a theoretical investigation is definitely needed. My main questions revolve around under what conditions the column spaces of the two generators are mutually independent and what is the type of components structure that the proposed model can recover. \n\nAs mentioned above, the experimental evaluation is limited to the NMIST dataset while comparisons with existing related models such as RPCA and ICA that work efficiently and with guarantees in the additive setting studied in this paper are considered essential in order to prove empirically the merits of the proposed framework. \n']","[20, -20, -50]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential of the approach, calling it 'exciting' and noting that it 'clearly contributes to the field'. However, they express significant concerns about the lack of comparisons and limited experimental validation, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'Could you give some more details...'), and acknowledges their own limitations ('not knowledgeable about GAN-based approaches'). The reviewer also provides a balanced view, discussing both pros and cons, and ends on a positive note after the author response, indicating a polite and fair approach to the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the demixing-GAN structure, they express concerns about limited potential applications and insufficient experimental results. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'It would be nice if...' and 'It seems...', softening their criticisms. They also begin with a neutral summary before presenting specific concerns, which is a polite approach. The reviewer offers constructive suggestions for improvement rather than harsh criticisms, maintaining a respectful tone throughout the review."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several limitations and concerns. The reviewer mentions that the technical contribution for denoising appears limited, the demixing model seems superficial, and there's a lack of theoretical analysis and thorough empirical evaluation. However, it's not entirely negative as the reviewer acknowledges some aspects of the work and provides constructive feedback. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'More specifically,' and 'As authors mention,' which show consideration. The reviewer also asks questions and suggests improvements rather than making harsh judgments, indicating a polite approach to criticism.""]"
"[""The authors study the task of sample-based quantitative evaluation applied to GANs. The authors suggest multiple modifications to existing evaluation pipelines: (1) Instead of embedding the samples in the InceptionNet feature space, train a domain-specific encoder. If labeled data is available, add a cross-entropy loss to the encoder training objective so that the class can be predicted. (2) Instead of fitting a single Gaussian in the feature space, fit a GMM instead. This should allow for a more fine-grained “class-aware” distance between the (empirical) distributions. \n\nPro: \nAttempt to attack a critical issue in generative modeling. Good overview of competing approaches.\nSeveral ablation studies of evaluation measures and the behavior of FID with respect to the representation space.\nThe ideas make sense on a conceptual level, albeit suffering from major practical concerns.\n\nCon:\n- Clarity can be improved (e.g. use of double negatives as in the top of page 3), the same arguments repeated multiple (>3) times (i.e. deficiencies of FID and IS, etc.), Many statements which should be empirically tested are stated as folklore (last paragraph on page 3). In general the paper merits another polishing pass (mode != model, last paragraph in  section 3, “unmatch”, etc.).\n- Why would a VAE capture a good feature space? It is known that the tradeoff between what is stored in the latent space versus the discriminator *completely* depends on the power of the discriminator -- if the discriminator is flexible enough it can just learn the marginal distribution and ignore the latent code. Hence, this subtle issue will likely undermine the entire model comparison.\n- Using the predictive distribution as a soft label for CAFD. Interesting idea, but why would one have access to labels in the first place? Why wouldn't one use a conditional GAN if we already have labels? Secondly, why would the modes necessarily correspond to classes?\n- Stated issues with FID: Why would you expect FID to be resistant to such drastic transformations as blocking out a significant proportion of pixels with “blocks”? This is a *major* change in the underlying distribution. The fact that humans can “fill in” this gap should have nothing to do with the quality of the underlying model. Arguably, you can also hide one eye, the nose and the mouth and still judge the sample as “good”.\n\nThe ideas presented in this paper are conceptually interesting. However, given the drawbacks discussed above I cannot recommend the acceptance of this work.\n"", 'This paper proposes a variant of the popular FID score for evaluating GAN-type generative models. The paper makes two major complaints about the FID as it is currently used:\n\n1. The standard Inception network features trained on ImageNet might not be a good representation for whatever different dataset is being modeled, e.g. CelebA or CIFAR-10.\n\n2. The globally-Gaussian assumption made by the FID doesn\'t hold, which can cause some problems with the metric.\n\nTo address issue 1, the paper proposes choosing features based on a dataset-specific VAE, which can additionally incorporate labels when they\'re available. For 2, the authors propose to compute something like the FID between each component of a Gaussian mixture, based on soft assignments of points to a class with the VAE\'s inference network to estimate p(y|x), when labels y are available.\n\nIn terms of the definition of the CAFD: it is worth emphasizing that (9) is *not* the Frechet = Wasserstein-2 distance between Gaussian mixtures (which is fine). Rather, it\'s essentially the mean FID of the class-conditional distributions. This has previously been considered in the conditional GAN case, e.g. by Miyato and Koyama (ICLR 2018, https://openreview.net/forum?id=ByS1VpgRZ ). The difference here is that soft-assignments are supported, through the VAE\'s inference network, though using any classifier would be essentially equivalent. As long as you have a classifier, you can compute the CAFD, regardless of using a VAE representation or not; the VAE just conveniently gives you a classifier out too. Thus the two components of your proposal are essentially orthogonal.\n\n\n\nOn the choice of dataset-dependent features:\n\nYou say several times through the paper that ImageNet-based features are ""ineffective"" because the class labels do not match with the target, e.g. ""fine-grained features distinguishing \'African hunting dog\' from \'Cape hunting dog\' (which all belong to the category \'dog\' in CIFAR-10) are not needed."" This is, I think, somewhat misguided: imagine I took ImageNet and assigned higher-level labels to it, such that each image is only assigned a label at the level ""dog,"" and then trained a GAN on it. Then a classifier wouldn\'t need to distinguish ""African hunting dog"" from ""Cape hunting dog."" But a GAN, which doesn\'t see the labels at all, is being given *exactly the same problem*, and so the GAN still needs to be able to produce both African hunting dogs and Cape hunting dogs (though it doesn\'t need to be able to tell the two apart).\n\nMoreover, some people believe that CNNs trained on general-purpose approximate the human visual system reasonably well (for an overview of the arguments, see https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/ ), and although the overall goals of GANs are somewhat fuzzy, ""the distribution appears the same to the human visual system"" seems pretty good as a goal.\n\n- I think it\'s obvious that ImageNet-trained Inception features do not model the human visual system very well on, say, MNIST.\n\n- They\'re probably also not amazing on CelebA, because it hasn\'t been fine-tuned for faces the way the human visual system has. (Incidentally, you say that ""the ImageNet models can hardly distinguish different faces"" -- this needs either a citation or some experimental support, in the appendix, because this is not a well-known fact and seems quite relevant to the common practice of applying ImageNet-trained features to CelebA evaluation.)\n\n- But it\'s not clear to me that they don\'t model the human visual system reasonably well on CIFAR-10, or at least a theoretical higher-resolution version of it. It\'s true that ImageNet models will contain some features specific to distinguishing different types of guitars, and there are no guitars in CIFAR-10. But as long as those features aren\'t strongly activated by actual images from your model, they shouldn\'t mess up the distributions you\'re comparing too much.\n\nSo if you\'re going to argue that ImageNet representations are insufficient on vaguely ImageNet-like tasks such as CIFAR-10, I don\'t think the arguments you have here are quite convincing. Probably, you need some evidence that the scores are made noisier by the irrelevant features and thus harder to estimate, or else maybe strong empirical evidence that using comparable features specific to the dataset distribution performs better.\n\nAnyway, for datasets that are not very much like ImageNet, using dataset-specific features is clearly sensible and perhaps necessary. But:\n\n- You only provide pretty limited evidence that the VAE is better than a plain autoencoder, namely Table 2 which shows that the VAE puts less information in the top few principal components. But you only show that up to the top 5 components, and in any case it\'s not obvious that a more-spread distribution would be better.\n\n- An important question that\'s not really considered here: how much does the FID/CAFD then just measure how well the generative model matches the VAE you get features from? Is it the case that this VAE would give a (nearly-)perfect score under the CAFD, or not?\n\n- The results of Figure 1/Table 3 are very interesting. But I wonder how much of this difference in behavior is due to training on CelebA vs ImageNet and how much is due to the architecture or objective of the autoencoder. It might be interesting to compare to features from an ImageNet VAE and/or a CelebA classifier and see what those say. (The discriminator features are something like a CelebA classifier, but there\'s other things going on there too.)\n\n\n\nOn the CAFD versus FID:\n\nYour main argument for the CAFD over the FID is that it is based on a richer model of the distribution, which you claim to be closer to true: the FID is based on a multivariate Gaussian assumption with a total of n + n (n-1)/2 parameters, while you use K times as many parameters. Your Table 9 also gives some slight evidence that the Gaussian mixture gives a better fit to the data than a single Gaussian.\n\nI\'m not entirely convinced by Table 9; comparing p-values is in general not necessarily very meaningful, and in particular it seems quite possible that the Anderson-Darling test simply prefers the mixture because the samples are more closely ""clumped together"" by the VAE than a random subset of inputs. Moreover, in either case the Gaussian assumption is clearly false a priori: in the Inception case, features are the output of a ReLU activation function and hence zero-inflated, and this or something like it may also be the case in your VAE. So comparing the p-value of tests for hypotheses known a priori to be false is probably a misguided endeavor.\n\nBut in any case the FID doesn\'t *really* assume Gaussianity. It coincides with the Frechet / Wasserstein-2 distance between Gaussians, but it\'s a perfectly plausible semimetric between any pair of distributions that have means and variances. The claim for superiority of CAFD over FID would then need to be something like ""the class-conditional means and variances are more representative of the distribution than the global means and variances.""\n\nRe: your claim that ""As both FID and CAFD aim to model how well domain-specific images are generated, they are not designed to deal with mode dropping"" -- this is something of a strange claim, as dropping an entire mode will hopefully affect both the feature mean and especially the variance unless it is done extremely carefully. A related problem, though, is that the CAFD is essentially insensitive to drastically *reweighting* modes, e.g. producing twice as many 1s as 2s on MNIST: if each mode is modeled correctly, the CAFD will not be changed, while the FID would be strongly affected with reasonable features. The Mode Score KL(p(y*) || p(y)) would be sensitive to this, as you suggest, but it feels somewhat hacky.\n\nThe type of analysis in Table 1 is interesting, but one issue is that it is sensitive to the scale of each mode in feature space: if your encoder happens to place 1s close together and 2s relatively more spread apart, you\'ll see a higher conditional FID for 2s than for 1s even if the visual ""sample quality"" is the same.\n\nOne important piece of related work that\'s missing is Binkowski et al. (ICLR 2018, https://openreview.net/forum?id=r1lUOzWCW ), who demonstrate that the FID estimator is strongly biased in a misleading way. The same problems are inherited by the CAFD, which you should at least mention. Binkowski et al., and independently Xu et al. (https://arxiv.org/abs/1806.07755 ), also proposed using MMD variants on top of Inception features. This has better statistical properties as shown by Binkowski et al., and also explicitly does not make any parametric assumptions about the distribution of features. It would be worth thinking about the relationship of that approach to the FID/CAFD.\n\nAnother metric you could compare to is the ""Adversarial Divergence"" of Yang et al. (ICLR 2017, https://openreview.net/forum?id=HJ1kmv9xx ) which compares the distribution of classifier output, p(y|x), for x from the model to that from test data. It\'s a pretty different metric from CAFD with different properties, but since you both require a classifier, it would be good to know how the two compare.\n\n\n\nMinor points:\n\nIn the related work, your discussion of the MMD is misleading: Dziugaite et al. and Li et al. proposed using the MMD for *training* generative models, not for evaluating. Evaluating with two-sample tests based on the MMD using simple kernels was done e.g. by Sutherland et al. (ICLR 2017, https://openreview.net/forum?id=HJWHIKqgl ) and Olmos et al. (https://openreview.net/forum?id=HJWHIKqgl ), and used on top of Inception-like representations e.g. by Lopez-Paz and Oquab (2017), as well as Xu et al. and Binkowski et al. mentioned above.\n\nThe derivation (6) of the CAFD is that the derivation (6) is somewhat sloppy about exactly what p() means -- in particular, it\'s somewhat confusing to use a lowercase p when every distribution you deal with here is actually discrete (for discrete y or for the empirical distribution S, since you\'re dealing with that and not actually the true distribution of the model, where p(x_i) would not be constant across samples x). It would probably be clearer to distinguish your notation for the true model distribution from the empirical distribution of the S samples.\n\nI don\'t understand your claim on page 6 that ""Unlike Inception Score, because CAFD measures distance on the feature space as FID does, it is able to report overfitting."" CAFD, like FID, probably doesn\'t allow for distributions to appear better than the target in the way that Inception score does. But I don\'t see how this corresponds to ""reporting overfitting""; a model that simply reproduces exactly the empirical distribution of the training set would get an excellent CAFD/FID score, but that\'s the usual sense of ""overfitting.""\n\n\n\nOverall thoughts:\n\nUsing dataset-specific features for evaluation metrics makes a lot of sense, but I don\'t feel totally satisfied by this paper\'s investigation of the specific proposal of a VAE, and am particularly worried about whether the metric just ends up preferring models similar to that VAE. I\'d really like to see some theoretical and empirical investigation into that.\n\nThe CAFD as opposed to FID doesn\'t feel as nice to me; it\'s both something of an obvious extension of the previously-used ""intra-class FID,"" and I am also unconvinced by the paper\'s arguments for its preferability over the FID or other metrics based on image representations like those of Xu et al.', ""The paper proposes a new evaluation metric for generative adversarial networks and shows that it is better aligned with human judgment than FID. The metric is based on a domain-specific encoder to extract features of the image rather than ImageNet inception network and a class-aware Frechet distance which makes a Gaussian mixture assumption for the extracted features rather than a simple Gaussian assumption for FID. The paper shows an advantage for the new metric vs the others by constructing examples where FID fails while the proposed metric doesn't. Although this is an interesting finding, it is not a breakthrough in the sense that a domain-specific representation is expected to be better behaved than the features of the inception classifier and using a Gaussian mixture would be an obvious step after FID. Moreover, other metrics don't even rely on any assumption on the features distributions [1,2], so I would expect them to behave at least as well as the proposed metric.  \n\n\n[1] :M. Arjovsky, S. Chintala, L. Bottou, Wasserstein gan\n[2] :M. Binkowski, D. J. Sutherland, M. Arbel, and A. Gretton. Demystifying MMD GANs.\n""]","[-60, -30, -20]","[20, 60, 50]","[""The sentiment score is -60 because the review is overall negative. While the reviewer acknowledges some positive aspects ('Pro' section), they ultimately state they 'cannot recommend the acceptance of this work' and list several significant criticisms ('Con' section). The politeness score is 20 because the reviewer uses professional language and acknowledges positive aspects, but also directly criticizes the work without much softening of the language. The reviewer provides constructive feedback and explains their reasoning, which adds to the politeness, but the overall tone remains critical."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper, they express significant skepticism and criticism throughout. They point out several limitations and areas where they are 'not entirely convinced' by the authors' arguments. The overall tone suggests the reviewer sees more weaknesses than strengths in the paper. The politeness score is 60 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I think' and 'I wonder' to soften criticisms. They also acknowledge positive aspects and interesting findings. However, they don't use overtly polite language or praise the authors directly, keeping the tone more neutral than highly polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting findings, they also point out that it's not a breakthrough and suggest that other existing metrics might perform equally well. The reviewer's tone is somewhat critical, but not overly negative. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They acknowledge the paper's contributions and provide constructive criticism without using harsh or dismissive language. The reviewer also supports their points with references, which adds to the professional tone of the review.""]"
"['This paper proposes a curriculum that encourages training on easy examples first and postpones training on hard examples. However, contrary to common ideas, they propose to keep hard examples contribute to the loss and only forcing them to have internal representations similar to a nearby easy example. The proposed objective is hence biased at the beginning but they dampen it over time to converge to the true objective at the end.\n\nPositives:\n- There is not much work considering each example as an individual subtask.\n- The observation that an under-fitted classifier can destroy a good feature extractor is good.\n\nNegatives:\n- In the intro it says “[update rule of gradient descent] assumes the top layer, F2, to be the right classifier.”. This seems like a fundamental misunderstanding of gradient descent and the chain rule. The term d output/d F1 takes into account the error in F2.\n- The caption of figure 2 says the “... they cannot separate from its neighbors…”. If the loss of all examples in a cluster is high, all are being misclassified. A classifier then might have an easy job fixing them if all their labels are the same or have a difficult job if their labels are random. The second scenario is unlikely if based on the claim of this figure, the entropy has decreased during training. In short, the conclusion made in fig 2 does not necessarily hold given that figure.\n- This method is supposed to speed up training, not necessarily improve the final generalization performance of the model. The figures show the opposite outcomes. It’s not clear why. The improvement might be due to not tuning the hyperparameters of the baselines.\n- Figure 3 does not necessarily support the conclusion. The fluctuations might be caused by any curriculum that forces a fixed ordering across training epochs. Often on MNIST, the ordering of data according to the loss does not change significantly throughout training.', 'This paper describes an approach for automated curriculum learning in a deep learning classification setup. The main idea is to weigh data points according to the current value of the loss on these data points. A naive approach would prevent learning from data points that are hard to classify given parameters of the current mode, and so the authors propose to use an additional loss term for these hard data points, which encourages the hidden representation of these data points to be closer to representation of points that are close in the hidden space and yet are easier to classify (in the sense that the loss of easy samples is lower by some threshold value then the loss of hard samples). This last part is implemented by caching hidden representations and classification loss values during training and fetching nearest neighbours in the feature space whenever a hard data point is encountered. The final loss takes the form of a linear combination of the classification loss and the representation loss.\n\nThe idea is interesting in the sense that it tries to use information about how difficult classification of a given data point is to improve learning. The proposed representation loss can lead to forming tight cluster of similar data point in the feature space and can make classification easier. It is related to student-teacher networks, where a student is trained to imitate the teacher in generated similar feature representations.\n\nThe authors justify the method by introducing the notion of “inverse internal covariate shift”. However, it is not defined formally, nor is it supported empirically, and is based on the (often criticized [1]) notion of “internal covariate shift”. For this reason, it is hard to accept the presented argumentation in its current state.\n\nMoreover, there seems to be a mistake in equation (2) in §4.2. The equation defines the method of computing loss weighting for a given datapoint. The authors note that it converges to the value of one with increasing training iterations, but for correctness it should be \\in [0, 1]. If it is > 1, one of the losses in equation (3) is negated and is therefore maximised (instead of being minimised), which can lead to unexpected behaviour. Current parameterization allows it to be \\in [0, + infinity].\n\nExperimental evaluation consists of quantitative evaluation of random sampling (usual SGD) and the proposed approach in training a classification model on MNSIT, CIFAR-10 and CIFAR-100. The proposed approach outperforms random sampling. This is encouraging, but the method should be compared to state of the art in curriculum learning in order to gauge how useful this approach is.\n\nThe paper is poorly written, with many grammatical (lack of “s” at the end of verbs used in singular 3rd person, many places in the paper) and spelling mistakes (e.g. §3.2¶6 “tough” instead of “through”, I think). Some descriptions are unclear (e.g. §4.2¶2), while some parts of the paper seem to be irrelevant to the problem at hand (§3.1 describes training on a single minibatch for multiple iterations as if it were a separate task and motivates random sampling, which is just SGD).\n\nTo summarize, the paper presents a very interesting idea. In its current state it is hard to read, however. It also contains a number of unsupported claims and can be misleading. It could also benefit from a more extensive evaluation. With this in mind, I suggest rejecting this paper.\n\n[1] Rahimi, A (2017). Test of Time Award Talk, NIPS.', 'This paper suggests a source of slowness when training a two-layer neural networks: improperly trained output layer (classifier) may hamper learning of the hidden layer (feature). The authors call this “inverse” internal covariate shift (as opposed to the usual one where the feature distribution shifts and trips the classifier). They identify “hard” samples, those with large loss, as being the impediment. They then propose a curriculum, where such hard samples are identified at early epochs, their loss attenuated and replaced with a requirement that their features be close to neighboring (in feature space) samples that are similarly classified, but with a more comfortable margin (thus “easy”.) The authors claim that this allows those samples to contribute through their features at first, without slowing the training down, then in later epochs fully contribute. Some experiments are offered as evidence that this indeed helps speedup.\n\nThe paper is extremely unclear and was hard to read. The narrative is too casual, a lot of handwaving is made. The notation is very informal and inconsistent. I had to second guess multiple times until deciphering what could have possibly been said. Based on this only, I do not deem this work ready for sharing. Furthermore, there are some general issues with the concepts. Here are some specific remarks.\n\n-\tThe intuition of the inverse internal covariate shift is perhaps the main merit of the paper, but I’m not sure if this was not mostly appreciated already.\n\n-\tThe paper offers some experimental poking and probing to find the source of the issue. But that part of the paper (section 3) is disconnected from what follows, mainly because hardness there is not a single point’s notion, but rather that of regions of space with a heterogeneous presence of classes. This is quite intuitive in fact. Later, in section 4, hard simply means high loss. This isn’t quite the same, since the former notion means rather being near the decision boundary, which is not captured by just having high loss. (Also, the loss is not specified.)\n\n-\tSome issues with Section 3: the notions of “task” needs a more formal definition, and then subtasks, and union of tasks, priors on tasks, etc. it’s all too vague. The term “non-computable” has very specific meaning, best to avoid. Figure 2 is very badly explained (I believe the green curve is the number of classes represented by one element or more, while the red curve is the number of classes represented by 5 elements or more, but I had to figure it out on my own). The whole paragraph preceding Figure 3 is hard to follow. I sort of can make up what is going, especially with the hindsight of Section 4, since it’s basically a variant of the proposed schedule (easy to hard making sure all clusters, as proxy to classes, are represented) without the feature loss, but it needs a rewriting.\n\n-\tIt is important to emphasize that the notion of “easy” and “hard” can change along the training, because they are relative to what the weights are at the hidden layer. Features of some samples may be not very separable at some stage, but they may become very separable later. The suggested algorithm does this reevaluation, but this is not made clear early on.\n\n-\tIn Section 4, the sentence where S_t(x) is mentioned is unclear. I assume “surpass” means achieving a better loss. Also later M_t (a margin) is used, when I think what is meant is S_t (a set). The whole notation (e.g. “topk”, indexing that is not subscripted, non-math mode math) is bad.\n\n-\tIf L_t is indeed a loss (and not a “performance” like it’s sometimes referred to, as in minus loss), then I assume larger losses means that the weight on the feature loss in equation (3) should be larger. So I think a minus sign is missing in the exponent of equation (2), and also in the algorithm.\n\n-\tI’m not sure if the experiments actually show a speedup, in the sense of what the authors started out motivating. A speedup, for me, would look like the training progress curves are basically compressed: everything happens sooner, in terms of epochs. Instead, what we have is basically the same shape curve but with a slight boost in performance (Figure 4.) It’s totally disingenuous to say “this is a great boost in speed” (end of Section 5.2) by saying it took 30 epochs for the non-curriculum version to get to its performance, when within 4 epochs (just like the curriculum version) it was at its final performance basically.\n\n-\tSo the real conclusion here is that this curriculum may not have sped up the training in the way we expect it at all. However, the gradual introduction of badly classified samples in later epochs, while essentially replacing their features with similarly classified samples for earlier epochs, has somehow regularized the training. The authors do not discuss this at all, and I think draw the wrong conclusion from the results.\n']","[-40, -60, -60]","[20, 20, -20]","[""The sentiment score is -40 because while the review acknowledges some positives ('not much work considering each example as an individual subtask', 'good observation'), it lists more negatives and points out several flaws in the paper's methodology and conclusions. The overall tone suggests skepticism about the paper's claims and results. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express criticisms ('This seems like a fundamental misunderstanding', 'It's not clear why') rather than harsh or dismissive language. The reviewer also acknowledges positive aspects before diving into criticisms, which is a polite approach in academic reviews."", ""The sentiment score is -60 because the review is overall negative, suggesting rejection of the paper. The reviewer points out several issues with the paper, including unsupported claims, poor writing, and a potential mistake in an equation. However, the reviewer does acknowledge that the idea is 'interesting,' which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'The idea is interesting' and 'This is encouraging, but...' which soften the criticism. However, some direct statements like 'The paper is poorly written' prevent the score from being higher. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states the paper is 'extremely unclear', 'hard to read', has 'too casual' narrative, and contains 'handwaving'. They also mention several issues with concepts, notation, and experiments. The reviewer concludes that the paper is 'not ready for sharing' and that the authors may have 'drawn the wrong conclusion'. However, it's not entirely negative as the reviewer acknowledges some merit in the paper's intuition. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical. Phrases like 'extremely unclear', 'too casual', and 'totally disingenuous' are somewhat harsh. The reviewer doesn't use softening language or positive reinforcement, which would be expected in a more polite review. However, they do provide detailed feedback and specific recommendations, which prevents the score from being lower.""]"
"[""*Summary:\nThis paper analyzes the convergence of ADAM and RMSProp to stationary points\nin the non convex setting.\nIn the second part the authors experimantally compare the performance of these methods to Nesterov's Accelerated method.\n\n\n\n*Comments:\n\n-The paper does not tell a coherent story and the two parts of the paper are somewhat unrelated.\n\n-The authors claim that they are the first to analyze adaptive methods in the non-convex setting, yet this was recently done in \n[Xiaoyu Li, Francesco Orabona; On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes]\nThe authors should cite this paper and compare their results to it.\n\n-The above paper of [Li and Orabona] demonstrates a nice benefit of AdaGrad in the non-convex setting. Concretely they show that in the noisless setting adaptive methods give a faster rate of $O(1/T)$ compared to the standard rate of $O(1/\\sqrt{T})$ of SGD.\n\nUnfortunately, the results of the current paper do not illustrate the benefit of adaptive methods over SGD, since the authors provide similar rates to SGD or even worse rates in some situations.\nI think that in light of [Li and Orabona] one should expect a $O(1/T)$ rate also for ADAM and RMSProp.\n\n\n-The experimental part is not so related to the first part. And the experimental phenomena is only demonstrated for the MNIST dataset, which is not satisfying. \n\n\n*Summary:\nThe main contribution of this paper is to provide rates for approaching stationary points.\nThis is done for ADAM and RMSProp, two adaptive training methods.\nThe authors do not mention a very relevant reference, [Li and Orabona].\nAlso, the authors do not show if ADAM and RMSProp have any benefit compared to SGD in the non-convex setting, which is a bit disappointing. Especially since [Li and Orabona] do demonstrate the benefit of AdaGrad in their paper.\n"", 'There may exist an error on the proof of Theorem 3.1 in appendix. For the first equation in page 13, the authors want to estimate lower-bound of the term $E<\\nabla{f}(xt),V_t^{-0/5}*gt>$. The second inequality $>$ may be wrong. Please check it carefully.  (Hints: both the index sets { i | \\nabla{f}(xt))_{i}*gt_{i} <0 } and { i | \\nabla{f}(xt))_{i}*gt_{i} >0 } depend on the random variable $gt$. Hence, the expectation and summation cannot be exchanged in the second inequality.)', 'Summary:\nThis paper present a convergence analysis of the popular methods RMSProp and ADAM in the case of smooth non-convex functions. In particular it was shown that the above adaptive gradient algorithms are guaranteed to reach critical points for smooth non-convex objectives and bounds on the running time are provided. An empirical investigation is also presented with main focus on the comparison of the adaptive gradient methods and the Nesterov accelerated gradient algorithm (NAG).  \n\nComments:\nAlthough the results are promising, I found the reading (mainly because of the not defined notation) of this paper really hard. \nIn terms of presentation, the motivation in introduction is fine, but the following section named ""Notations and Pseudocodes"" is confusing and has many undefined notations which makes the paper very hard to read. It gives the impression that the section was added the last minute. For example what is fundtion ""g"" in the definition 1? What is support(v) and the diag(v) in the definition 2. the diag(v) is more obvious to me but then why at page 18 the diag(v)at the top of the page is bold (are these two things different)?\nIn the presentation of RMSProp what the $g_t^2$ means? Please have a look to last year\'s ICLR paper [Reddi, Sashank J., Satyen Kale, and Sanjiv Kumar. ""On the convergence of adam and beyond."" (2018).] for a more appropriate introduction of the notation.\n\nIn the introduction the authors refer to NAG as a stochastic variant of the Nesterov\'s acceleration and they informally present the algorithm in the end of the first paragraph. There the update rule includes stochastic gradients \\nable f_i(.) while in the formal presentation in the update rule there is \\nabla f(x) which is the full gradient of the objective function of the original problem. I expect this difference is somehow justified from the mentioning in the algorithm of the possibly noisy oracle but this is never mention in the main text.\n\nIf the above statements in terms of presentation, are ignored the convergence results and numerical experiments are interesting. \nHowever, the numerical evaluation does not correspond to the theoretical results. It is a comparison of NAG ,ADAM and RMSPROP with interesting conclusions  that can be beneficial for practitioners that they use these methods.\n\nSome missing references:\nOn Adam methods:\n1) Chen, Xiangyi, et al. ""On the convergence of a class of adam-type algorithms for non-convex optimization."" arXiv preprint arXiv:1808.02941 (2018).\n2) Zhou, Dongruo, et al. ""On the convergence of adaptive gradient methods for nonconvex optimization."" arXiv preprint arXiv:1808.05671 (2018).\nOn momentum (heavy ball) methods:\n3) Loizou, Nicolas, and Peter Richtárik. ""Momentum and stochastic momentum for stochastic gradient, Newton, proximal point and subspace descent methods."" arXiv preprint arXiv:1712.09677 (2017).']","[-60, -20, -20]","[-20, 50, 50]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, such as the lack of coherence, missing important citations, and failure to demonstrate benefits over existing methods. The only positive aspect mentioned is the main contribution of providing rates for approaching stationary points. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much effort to soften the criticism. Phrases like 'does not tell a coherent story', 'not so related', and 'not satisfying' contribute to a somewhat impolite tone. The reviewer does not use any particularly polite language or acknowledge positive aspects of the work in detail, which could have balanced the criticism."", ""The sentiment score is slightly negative (-20) because the reviewer points out a potential error in the proof, which is a criticism of the work. However, it's not strongly negative as the reviewer suggests checking it carefully rather than outright rejecting the work. The politeness score is moderately positive (50) because the reviewer uses polite language such as 'Please check it carefully' and provides helpful hints for the authors to address the issue. The reviewer also uses tentative language like 'may exist an error' and 'may be wrong', which softens the criticism. The overall tone is constructive and aimed at improving the paper rather than harshly criticizing it."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the results are 'promising' and 'interesting', they also express significant concerns about the paper's presentation, notation, and readability. The reviewer states they found the paper 'really hard' to read and points out several issues with undefined notations and inconsistencies. However, they do recognize the value of the convergence results and numerical experiments. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'Although the results are promising' and 'If the above statements... are ignored'. They offer constructive criticism and suggestions for improvement, including references to consider, without using harsh or rude language. The reviewer balances critique with positive comments, which contributes to the overall polite tone.""]"
"[""This paper studies ReLU model, or equivalently, one-layer-one-neuron model, for the classification problem. This paper shows if the data is linearly separable, gradient descent may converge to either a global minimum or a sub-optimal local minimum, or diverges. This paper further studies the implicit bias induced by GD and SGD and shows if they converge, they can have a maximum margin solution. \n\nComments:\n1. Using ReLU model for linearly separable data doesn't make sense to me. When ReLU is used, I expect some more complicated separable condition. \n2. This paper only studies one-layer-one-neuron model, which is a very restricted setting. It's hard to see how this result can be generalized to the multiple-neuron case.\n3. The analysis follows closely with previous work in studying the implicit bias for linear models.\n"", ""Recently, the implicit bias where gradient descent converges the max-margin classifier was shown for linear models without an explicit regularization.\nThis paper tries to extend this result to ReLU network, which is more challenging because of the non-convexity.\nMoreover, a similar property of stochastic gradient descent is also discussed.\n\nThe implicit bias is a key property to ensure the superior performance of over-parameterized models, hence this line of research is also important.\nHowever, I think there are several concerns as summarized below.\n\n1. I'm not sure about the significance of the ReLU model (P) considered in the paper.\nIndeed, the problem (P) is challenging, but an obtained model is linear defined by $w$.\nTherefore, an advantage of this model over linear models is unclear.\n\nMoreover, since the max-margin in this paper is defined by using part of dataset and it is different from the conventional max-margin, the generalization guarantees are not ensured by the margin theory.\nTherefore, I cannot figure out the importance of an implicit bias in this setting (, which ensures the convergence to this modified max-margin solution).\nIn addition, the definition of the max-margin seems to be incorrect: argmin max -> argmax min.\n\n2. Proposition 1 (variance bound) gives a bound on the sum of norms of stochastic gradients.\nHowever, I think this bound is obvious because stochastic gradients of the ReLU model (P) are uniformly bounded by the ReLU activation.\nCombining this boundedness and decreasing learning rates, the bound in Proposition 1 can be obtained immediately.\nMoreover, the validity of an assumption on $w_t$ made in the proposition should be discussed.\n\n3. Lemma F.2 is key to show the main theorem, but I wonder whether this lemma is correct.\nI think the third equation in the proof seems to be incorrect.\n"", 'This paper considers the binary classification problem with exponential loss and ReLu activation function (single neuron). The authors characterize the asymptotic loss landscape by three different types of critical points. They prove that gradient descent (GD) will result in four different regions and provide convergence rates for GD to converge to an asymptotic global minimum, asymptotic local minimum and local minimum under certain assumptions. The authors also provide convergence results for stochastic gradient descent (SGD) and provide extensions to leaky ReLu activation and multi-neuron networks. The paper is well written and the results are mostly clearly presented. This paper mostly follows the line of research by Soudry et al. (2017, 2018), while it has its own merit due to the ReLu activation function considered. However, there are many strong assumptions that are not carefully verified and I really have concerns about the contribution of this paper since they simplify their analysis and results merely by imposing stringent conditions. In particular, I have the following major comments about the paper:\n\n1.\tIn the definition of max-margin direction, why you use \\argmin_{w} max_{i} (w^{\\top}x_i)? It seems to me that the definition should be \\argmax_{w} min_{i} (w^{\\top}x_i). This definition keeps appearing in multiple places in the main paper. \n2.\tIn the proof of Theorem 3.2, I am confused by the argument of the case that \\hat w^{+} is not in the linearly separable region. More clarification is needed to make the proof rigorous.\n3.\tIn the analysis of Theorem 3.3 and 3.4, the authors make a very stringent assumption that the iterate w_t staying in linear separable region for all t>\\mathcal{T}. This assumption seems too strong, which should be verified rather than imposed in analysis of SGD. Note that even the example shown in Proposition 2 is still very restrictive (you require all the positive examples or negative examples are very close to one another).\n4.\tFurthermore, in the analysis of SGD, the authors did not specify the assumption that \\hat w^{+} lies in the linear separable region, which is also required in this theorem and also very strong. Given such strong assumptions, the analytic results seem to be trivial and it is hard to evaluate the authors’ contribution.  \n5.\tFor the convergence results of SGD, the current rate is derived on the distance between \\|E[w_t] - \\hat{w}\\|^2. Can you provide similar results for mean square error (E\\| w_t - \\hat{w} \\|^2)? \n6.\tIn multi-neuron case, the authors again make very strong assumptions that all the neurons have unchanging activation status. This is not easily achievable without careful characterization or other rigorous assumptions. Under such strong assumptions, the extension to multi-neuron again seems not very meaningful.\n\nOther minor comments:\n1.\tThe references are not correctly cited. For instance, please correct the use of parenthesis in “… which is different from that in (Soudry et al., 2017, Corollary 8)” and “… hold for various other types of gradient-based algorithms Gunasekar et al. (2018)”.\n2.\tThe sentence “…, which the nature of convergence is different from …” does not read well. Should it be “where” or “of which”?\n']","[-20, -50, -50]","[0, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express skepticism about the relevance and generalizability of the study. The first paragraph summarizes the paper's content neutrally, but the comments section raises three critical points that question the paper's approach and significance. The politeness score is neutral (0) as the reviewer's language is neither particularly polite nor rude. They present their criticisms directly but professionally, without using overly harsh language or personal attacks. The reviewer maintains a formal, academic tone throughout, stating their concerns matter-of-factly without excessive courtesy or rudeness."", ""The sentiment score is -50 because the review expresses several concerns and criticisms about the paper, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges the importance of the research area. The politeness score is 20 because the reviewer uses polite and professional language throughout, avoiding harsh criticism. They use phrases like 'I think' and 'I'm not sure' to soften their critiques. However, the overall tone is more neutral than overtly polite, hence the moderate positive score. The reviewer provides specific, constructive feedback without personal attacks or overly emotional language."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('The paper is well written and the results are mostly clearly presented'), they express significant concerns about the paper's contribution and the strength of its assumptions. The overall tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude expressions. They provide constructive criticism and specific points for improvement, which is polite in academic contexts. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral professional tone.""]"
"[""The authors provided a training scheme that ensures network retains old performance as new data sets are encountered (e.g. (a) same class no drift, (b) same class with drift, (c) new class added). They do this by incrementally adding FC layers to the network, memory component that stores previous precomputed features, and the objective is a coupling between classification loss on lower level features and a feature-loss on retaining properties of older distributions. The results aren't very compelling and the approach looks like a good engineering solution without strong theoretical support or grounding. "", 'Summary:\n a method is presented for on-going adaptation to changes in data, task or domain distribution. The method is based on adding, at each timed step, an additional network module transforming the features from the previous to the new representation. Training for the new task/data at time t relies on re-training with all previous data, stored as intermediate features. The method is shown to provide better accuracy than naïve fine tuning, and slightly inferior to plain re-training with all the data.\nWhile the method is presented as a solution for life long learning, I think it severely violates at least two demands from a feasible solution: using finite memory and using finite computational capacity (i.e. a life-long learning cannot let memory or computation demands to rise linearly with time). Contrary to this, the method presented induces networks which grow linearly in time (in number of layers, hence computation requirements and inference time), and which use a training set growing indefinitely, keeping (representations of) all the examples ever seen so far. If no restrictions on memory and computation time are given, full retraining can be employed, and indeed it provides better results that the suggested method. In the bottom line, I hence do not see the justification for using this method, either as a life-long learner or in another setting.\n\nPros:\n+ the method shows that for continuous adaptation certain representations can be kept instead of the original examples \nCons:\n- The method claims to present a life long learning strategy, yet it is not scalable to long time horizon (memory and inference costs rise linearly with time)\n- Some experiments are not presented well enough to be understood.\n\nMore detailed comments:\nPage 3:\n-\tEq. 2 is not clear. It contains a term ‘classification loss’ and ‘feature_loss’ which are not defined or explained. While the former is fairly standard, leaving the latter without definition makes this equation incomprehensible. \no\tI later see that eq. 7 includes the details. Therefore eq.2 is redundant. \nPage 4:\n-\tEq. 5 seems to be flawed, though I think I can understand what it wants to say. Specifically, it states two sets: one of examples (represented by the previous feature extractor) and one of labels (of all the examples seen so far). The two sets are stated without correspondence between examples and labels – which is useless for learning (which requires example-label correspondence). I think the intention was for a set of (example, label) pairs, where the examples are represented using feature extractor of time t-1.\n-\tAlgorithm 1 seems to be a brute force approach in which the features of all examples from all problems encountered so far are kept (with their corresponding labels). This means keeping an ever growing set of examples, and training repeatedly at each iteration on this set. These are not realistic assumptions for a life-long learner with finite capacity of memory and computation.\no\tFor example, for the experiment reported at page 6, including 25 episodes on MNist, each feature transformer is adding 2 additional FC layers to the network. This leads to a network with >50 FC layers at time step 25 – not a reasonable and scalable network for life ling learning\nPage 6:\n-\tThe results show that the feature transformer method achieve accuracy close to cumulative re-training, but this is not too surprising, since feature transformer indeed does cumulative re-training: at each time step, it re-trains the classifier (a 2 stage MLP) using all the data at all times steps (i.e. cumulative retraining). The difference from pure cumulative re-training, if I understand correctly, is that the cumulative re-training is done not with the original image representations, but with the intermediate features of time t-1. What do we earn and what do we loose from this? If I understand correctly, we earn that the re-training is faster since only a 2-layer MLP is re-trained instead of the full network. We loose in the respect that the model gorws larger with time, and hence inference becomes prohibitively costly (as the network grows deeper by two layers each time step). Again, I do not think this is a practical or conceptual solution for life long learning.\n-\tThe experiment reported in figure 3 is not understandable without reading Lopez-Paz et al., 2017 (which I didn’t). the experiment setting, the task, the performance measurements – all these are not explained, leaving this result meaningless for a stand-alone read of this paper.\n-\tPage 8: it is stated that “we only store low dimensional features”. However, it is not reported in all experiment exactly what is the dimension of the features stored and if they are of considerably lower dimension than the original images. Specifically for the MNIst experiments it seems that feature stored are of dimension 256, while the original image is of dimension 784 – this is lower, but no by an order of magnitude (X10).\n-\tThe paper is longer than 8 pages.\n', 'This paper proposes a continual learning approach which transforms intermediate representations of new data obtained by a previously trained model into new intermediate representations that are suitable for a task of interest.\nWhen a new task and/or data following a different distribution arrives, the proposed method creates a new transformation layer, which means that the model’s capacity grows proportional to the number of tasks or data sets being addressed over time. Intermediate data representations are stored in memory and its size also grows.\nThe authors have demonstrated that the proposed method is robust to catastrophic forgetting and it is attributed to the feature transformation component. However, I’m not convinced by the experimental results because the proposed method accesses all data in the past stored in memory that keeps increasing infinitely. The authors discuss very briefly in Section 5.2 on the performance degradation when the memory size is restricted. In my opinion, the authors should discuss this limitation more clearly on experimental results with various memory sizes.\n\nThe proposed approach would make sense and benefit from storing lower dimensional representations of image data even though it learns from the entire data over and over again.\nBut it is unsure the authors are able to claim the same argument on a different type of data such as text and graph.']","[-30, -60, -20]","[0, 20, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the authors' efforts in providing a training scheme, they express that 'the results aren't very compelling' and describe the approach as lacking 'strong theoretical support or grounding'. This indicates a somewhat negative view of the work's overall contribution and scientific rigor. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states their observations and criticisms in a direct, matter-of-fact manner without using overly harsh language or personal attacks, but also without any notably courteous or encouraging phrases."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the method's practicality and scalability for life-long learning. They point out major flaws in the approach, such as linearly increasing memory and computation requirements, which violate key demands of a feasible life-long learning solution. The reviewer also states that they 'do not see the justification for using this method.' However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the method showing that certain representations can be kept instead of original examples.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone throughout. They use phrases like 'I think' and 'if I understand correctly' which soften their criticisms. The reviewer also balances their critique by mentioning both pros and cons of the method. However, the score is only slightly positive because the review is predominantly critical and doesn't use overtly polite language or praise the authors' efforts extensively."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'robust to catastrophic forgetting'), they express significant concerns about the experimental results and limitations of the approach. The reviewer is not fully convinced by the results and suggests that the authors should discuss limitations more clearly. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I'm not convinced' and 'In my opinion' to soften their critiques, maintaining a polite tone while still expressing their concerns.""]"
"['Comments: \n\nThe author(s) provide stability and generalization bounds for SGD with momentum for strongly convex, smooth, and Lipschitz losses. \n\nThis paper basically follows and extends the results from (Hardt, Recht, and Singer, 2016). Section 2 is quite identical but without mentioning the overlap from Section 2 in (Hardt et al, 2016). The analysis closely follows the approach from there. \n\nThe proof of Theorem 2 has some issues. The set of assumptions (smooth, Lipschitz and strongly convex) is not valid on the whole set R^d, for example quadratic function. In this case, your Lipschitz constant L would be arbitrarily large and could be damaged your theoretical result. To consider projected step is true, but the proof without projection (and then explaining in the end) should have troubles. \n\nFrom the theoretical results, it is not clear that momentum parameter affects positively or negatively. In Theorem 3, what is the advantage of this convergence compared to SGD? It seems that it is not better than SGD. Moreover, if \\mu = 0 and \\gamma > 0, it seems not able to recover the linear convergence to neighborhood of SGD. Please also notice that, in this situation, L also could be large. \n\nThe topic could be interesting but the contributions are very incremental. At the current state, I do not support the publications of this paper. \n', 'This paper studies the algorithmic stability of SGD with momentum and provides an upper-bound on true risk through convergence analysis.\nThis bound clarifies dependencies of convergence speed on the size of dataset and the momentum parameter.\n\nThe presentation is easy to follow and technically sounds good.\nSGD with momentum is heavily used for learning linear models and deep neural networks, hence to analyze its convergence behavior is quite important.\nThis paper achieves this goal well by extending a previous result on vanilla SGD in a straightforward manner, although it is not technically difficult.\n', 'This paper presents an analysis of generalization error of SGD with multiple passes for strongly convex objectives using the framework of algorithmic stability [Bousquet and Elisseef, 2002] and its recent use to analyze generalization error of SGD based methods [Hardt, Recht and Singer 2016].\n\nThe problem considered by this work is interesting and raises the possibility of understanding generalization related questions of SGD style methods when augmented with momentum, which is common practice in Deep Learning [Sutskever et al. 2013]. That said, there are some concerns about the results as presented in this paper, which I will elaborate below:\n\n- Consider the stability bound admitted by theorem 2: The special case (similar to theorem 3.9 of Hardt et al 2016) when the learning rate alpha = 1/beta (which is the typical learning rate that theory advocates), and setting kappa = beta/gamma where kappa is the condition number of the problem, leads to the following bound on momentum allowed by theorem 2, which is:\n\n(something non-positive) <= mu < 1/(3*kappa). \n\nThis is basically the regime where momentum does not make any difference towards accelerating optimization. Referring to the standard value of momentum for strongly convex functions, we see that the momentum is set as mu = (sqrt(kappa)-1)/(sqrt(kappa)+1) [Nesterov, 1983], or, mu = ( (sqrt(kappa)-1)/(sqrt(kappa)+1) )^2  [Polyak,1964]. Upon simplification of this standard momentum values, we see that mu \\approx 1 - 1/sqrt(kappa) which grows close to one as kappa grows large. On the other hand, the momentum values admitted by the paper for their bound is super tiny (which gets to zero as the condition number kappa grows large). This essentially implies there is not much about momentum that is captured by the bound of theorem 2 since there is no characterization of the provided bound for theoretically advocated and practically used parameters for momentum.\n\n- In proposition 1, there is no quantitative description of what ""sufficiently small"" mu (momentum parameter) is - this statement is imprecise. As mentioned in the previous point, sufficiently small mu really is not descriptive of momentum parameters employed in practice (mu in practice typically is >= 0.9). For strongly convex objectives, this should be closer to 1- (1/sqrt(kappa)). Sufficiently small mu parameter essentially does not yield quantitatively different behaviors compared to standard SGD. \n\n\nIn summary, while this paper attempts to make progress on an interesting question, but falls short and doesn\'t really capture the behavior of these methods that is even mildly reflective of practice (even in terms of the parameter regimes admitted by the bounds proven in the theorems).\n\n- This paper does not perform a thorough literature survey of published results. Furthermore, this paper does not present a precise treatment of assumptions (and implications) amongst other works cited in the paper (see for e.g. [4] below). \n\n[1] Polyak (1987) presents (generalization) behavior of Heavy Ball momentum with noisy (inexact) gradients.\n[2] Several efforts in Signal Processing literature do consider the similar setting as one considered by this paper, which is that of Heavy Ball (called accelerated LMS) method with noisy gradients: refer to Proakis (1974), Roy and Shynk (1990), Sharma et al. (1998). \n[3] Kidambi et al (2018) estimate the ""optimization"" power (which is a part of characterization of generalization error [Bach and Moulines 2011], since this dominates at the start of optimization) of HB method with Stochastic Gradients and prove that HB+stochastic gradients does not offer any speedup over vanilla SGD.\n[4] Loizou and Richtarik provide an analysis of stochastic heavy ball with super large batch sizes (so they end up showing accelerated rates) under similar assumptions as considered by this paper, such as assuming the function is smooth and strongly convex. However, the paper dismisses the work of Loizou and Richtarik to be working with a different set of assumptions - this is not really true.']","[-60, 70, -60]","[-20, 50, 20]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's originality, theoretical validity, and overall contribution. They state the paper 'closely follows' previous work, has 'issues' in its proofs, and that the contributions are 'very incremental'. The concluding statement 'I do not support the publications of this paper' clearly indicates a negative sentiment. However, it's not maximally negative as the reviewer does acknowledge the topic 'could be interesting'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. Phrases like 'quite identical but without mentioning the overlap' and 'should have troubles' come across as somewhat harsh. The reviewer also doesn't offer many positive comments or suggestions for improvement, which would be considered more polite in academic discourse."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They state that the presentation is easy to follow, technically sound, and that the paper achieves its goal well. The importance of the topic is also highlighted. However, it's not a perfect score as the reviewer notes that the work is 'not technically difficult' and is a straightforward extension of previous work. The politeness score is 50 (slightly positive) because the language is professional and respectful, without being overly formal or effusive. The reviewer provides balanced feedback, acknowledging both strengths and limitations of the work without using harsh or critical language. The tone is matter-of-fact and constructive, which is appropriate for a peer review."", ""The sentiment score is -60 because the review is predominantly critical. While it acknowledges the interesting nature of the problem, it raises several significant concerns about the paper's results and methodology. The reviewer points out that the paper's findings don't reflect practical applications of momentum in machine learning, lacks a thorough literature survey, and doesn't precisely treat assumptions. These criticisms outweigh the initial positive remarks, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'interesting question' and 'attempts to make progress.' However, the criticism is direct and doesn't employ many softening phrases, keeping the score only slightly positive. The reviewer also uses neutral academic language rather than overtly polite expressions.""]"
"['Summary:\nThe paper presents a method for ""learning an optimizer""(also in the literature Learning to Learn and a form of Meta-Learning) by using a Variational Optimization for the ""outer"" optimizer loss. The mean idea of the paper is to combine both the reparametrized gradient and the score-function estimator for the Variational Objective and weight them using a product of Gaussians formula for the mean. The method is simple and clearly presented. The paper also presents issues with the standard ""learning to learn"" optimizers, one being the short-horizon bias and as credited by the authors has been observed before in the literature, and the second one is what is termed the ""exponential explosion of gradients"" which I think lacks enough justification as currently presented (see below for details). The ideas are clearly stated, although the work is not groundbreaking, but more on combining several ideas into a single one. \n\nExperiments: \nThe authors evaluate their method on a single task which consists of optimizing a 3-layer convolutional neural network on downsampled images from ImageNet. A key idea, not new to this work, is to optimize the meta-optimizer with respect to the validation dataset rather than the training, which seems to be crucial for any meaningful training to happen. Although the experiments do show so promising results, they seem to be somewhat limited (see below for details). There is also a small ablation study on how do different features presented to the optimizer affect its performance. Given the still small-scale experiments, I\'m not sure this is a significant result for the community. \n\nConclusion:\nAs a whole, I think the idea in the paper is a good one and worth investigating further. However, the objections I have on section 2.3 and the experiments seem to indicate that there needs to be more work into this paper to make it ready for publication. \n\n\nOn section 2.3 and the explosion of gradients:\n\nThere is a mistake in the equation on page 4 regarding the ""gradient with respect to the learning rate"". Although the derivation in Appendix A is correct, the inner product in the equation starts wrongly from j=0, where it should in fact start at j = i + 1. To be more clear the actual enrolled equation for dw^T/dt for 3 steps back is:\n\ndw^T/dt = (I - tH^{T-1})(I - tH^{T-2})(I - tH^{T-3}) dw^{T-3} - (I - tH^{T-1})(I - tH^{T-2}) g^{T-3} - (I - tH^{T-1}) g^{T-2} - g^{T-1} \n\nHence the product must start at j = i + 1. \nIt is correct that in this setting the equation is a polynomial of degree T of the Hessian, however, there are several important factors that the authors have not discussed. Namely, if the learning rate is chosen accordingly such that the spectral radius of the Hessian is less than 1/t then rather than the gradient exploding the higher order term will vanish. However, even if they do vanish for large T since the Hessian plays with smaller and smaller power to more recent gradients (after correcting the mistake in the equation) than the actual T-step gradient will never vanish (in fact even if tH = I then dw^T/dt = g^{T-1}). Hence the claims of exploding gradients made in this section coupled with the very limited theoretical analysis seem to unconvincing that this is nessacarily an issue and under what circumstances they are. \n\nThe toy example with l(w) = (w - 4)(w - 3) w^2 is indeed interesting for visualizing a case where the gradient explosion does happen. However, surprisingly here the authors rather than optimizing the learning rate, which they analyzed in the previous part of the section, they are now optimizing the momentum. The observation that at high momentum the training is unstable are not really surprising as there are fundamental reasons why too high momentum leads to instabilities and these have been analyzed in the literature. Additionally, it is not mentioned what learning rate is used, which can also play a major role in the effects observed. \n\nAs a whole, although the example in this section is interesting, the claims made by the authors and some of the conclusions seem to lack any significant justifications, in addition to the fact that usually large over-parameterized models behave differently than small models. \n\n\nExperiments:\n\nI have a few key issues with the experimental setup, which I think need to be addressed:\n\n1. The CNN being optimized is quite small - only 3 layers. This allows the authors to train everything on a CPU. The key issue here, as well with previous work on Learning to Learn, is that it is not clear how scalable is this method to very Deep Networks. \n\n2. Figure 1 - The setup is to optimize the problem for 10000 iterations, however, I think it is pretty clear even to the naked eye that the standard first-order optimizers (Adam/RMS/Mom) have not fully converged on this problem. Hence I think its slightly unfair to compare their ""final performance"" after this fixed period. Additionally using the curriculum the ""meta""-optimizer is trained explicitly for 10000 iterations. Hence, it is also unclear if it retains its stability after letting it run for longer. From the text it is also unclear whether the authors have optimized the parameters of the first-order methods with respect to their training or validation performance - I hope this is the latter as that is the only way to fairly compare the two approaches. \n\n3. Figure 6 - the results here seem to indicate that the learned optimizer transfers reasonably well, achieving similar performance to first-order methods (slightly faster validation reduction). Given however that these are plots for only 10000 iterations it is still unclear if this is scalable to larger problems. \n\n', 'Review:\n\n\tThis paper proposes a method to learn a neural network to perform optimization. The idea is that the neural network will receive as an input several parameters, including the weights of the network to be trained, the gradient, and so on, and will output new updated weights. The neural network that is used to compute new weights can be trained through a complicated process called un-rolled optimization. The authors of the paper show two problems with this approach. Namely, the gradients tend to explode as the number of iterations increases. Truncating the gradient computation introduces some bias. To solve these problems the authors propose a variational objective that smooths the objective surface. The proposed method is evaluated on the image net dataset showing better results than first order methods optimally optimized.\n\nQuality: \n\n\tThe quality of the paper is high. It addresses an important problem of the community and it seems to give better results than first other methods.\n\nClarity: \n\n\tThe clarity of the paper is low. It is difficult  to follow and includes many abstract concepts that the reader is not familiar with. I have had problems understanding what the truncation means. Furthermore, it is not clear at all how the validation data is used as a target in the outer-objective.  It is also unclear how the bias problem is addressed by the method proposed by the authors. They have said nothing about that, yet in the abstract they say that the proposed method alleviates the two problems detected.\n\nOriginality: \n\n\tAs far as I know the idea proposed is original and very useful to alleviate, at least, one of the problems mentioned of exploding gradients.\n\nSignificance:\n\n\tIt is not clear at all that the method is evaluated on unseen data when using the validation data for outer-training. This may question the significance of the results.\n\nPros:\n\n\t- Interesting idea.\n\n\t- Nice illustrative figures.\n\n\t- Good results.\n\nCons:\n\n\t- Unclear points in the paper with respect to what truncation means.\n\n\t- The validation data is used for training and there is no left-out data, which may bias the results.\n\n\t- Unclear how the authors address the bias problem in the gradients.', 'This paper tackles the problem of learning an optimizer, like ""learning to learn by gradient descent by gradient descent"" and its follow-up papers. Specifically, the authors focus on obtaining cleaner gradients from the unrolled training procedure. To do this, they use a variational optimization formulation and two different gradient estimates: one based on the reparameterization trick and one based on evolutionary strategies. The paper then uses a method from the recent RL literature to combine these two gradient estimates to obtain a variance that is upper-bounded by the minimum of the two gradients\' variances. \n\nWhile the method for obtaining lower-variance gradients is interesting and appears useful, the application to learn optimizers is very much oversold: the paper states that the comparison is to ""well tuned hand-designed optimizers"", but what that comes down to in the experiments is Adam, SGD+Momentum, and RMSProp with a very coarse grid of 11 learning rates and *no regularization* and *no learning rate schedule*. The authors\' proposed optimizer is just a one-layer neural net with 32 hidden units that gets as input basically all the terms that the hand-designed optimizers compute, and it has everything it needs to simply use weight decay and learning rate schedules -- precisely what you need for the authors\' contributions (speed and generalization). This is a fundamental flaw in the experimental setup (in particular the choice of baselines) and thus a clear reason for rejection.\n\nSome details:\n\n- While the authors\' method is optimized by training 5 x 0.5 million, i.e. 2.5 million (!) full inner optimization runs of 10k steps each, the hand-designed optimizers get to try 11 values for the learning rate, which are logarithmically spaced between 10^{-4} and 10 (i.e., very coarsely, with sqrt{10} difference between successive values; even just for this fixed learning rate one would want to space factors by as little as 1.1 or so in the optimal region). \n\n- The lack of any learning rate schedule for the baselines is highly problematic; it is common knowledge that learning rate schedules are important. This is precisely why one would want to do research on learning optimizers to set the learning rate! Of course, without learning rate schedules one will not obtain a very efficient optimizer and it is easy to show large speedups over that poor baseline (the authors\' first stated contribution in the title).\n\n- The authors\' second stated contribution is that their learned optimizers generalize better than the baselines. But they pass their optimizers all information required to learn arbitrary weight decay, while the baselines are not allowed to use any weight decay. Thus, the second stated contribution in the title also does not hold up.\n\n- There are many details in the experiments that would be hard to reproduce truthfully. Given the reproducibility crisis in machine learning, I would trust the results far more if the authors made their code available in anonymized form during the review period. If the authors did this I could also evaluate it against properly tuned baseline optimizers myself. In that case I would lean towards increasing my score since the availability of code for this line of work would be very useful for the community.\n\n- Page 4 didn\'t print for me; both times I tried it came out as a blank page. \n\n- Several issues on page 4: \n - I don\'t see why the unnumbered equation necessarily leads to an exponential increase; H^{(j)} can be different for each j, such that there isn\'t a single term being exponentiated. Or am I mistaken?\n - The problem in Figure 3a is not the problem discussed in the text\n - The global minimum of the function is not 0.5 as stated in the caption\n - It is not stated what sort of MLP there is in Figure 3d (again, code availability would fix things like this)\n\n- Section 5 is extremely dense. This is the paper\'s key methodological contribution, and it is less than a page! I would suggest that the authors describe these methods in more detail (about another page) and save space elsewhere in the paper.\n\nThe paper is written well and the illustrations of the issues of TBPTT, as well as the authors\' fix are convincing. It\'s a shame, but unfortunately, the stated contributions for the learned optimizers do not hold up.']","[-20, 20, -60]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The ideas are clearly stated', 'the idea in the paper is a good one and worth investigating further'), they also express significant concerns and criticisms. The reviewer points out limitations in the experiments, mistakes in equations, and unconvincing claims, concluding that 'there needs to be more work into this paper to make it ready for publication.'\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'seem to indicate' to soften criticisms, and acknowledge positive aspects before presenting concerns. The reviewer also offers detailed explanations for their critiques, which is constructive. However, the score is not higher because the review is quite direct in pointing out flaws and doesn't use many explicitly polite phrases."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's high quality, originality, and good results, they also point out several significant concerns about clarity and methodology. The positive aspects (interesting idea, nice figures, good results) are balanced against the negative points (unclear explanations, potential bias in results). The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, acknowledging both strengths and weaknesses without using harsh language. They use phrases like 'The quality of the paper is high' and 'Interesting idea', while also clearly stating concerns in a constructive manner, such as 'It is difficult to follow' and 'It is not clear at all'. The reviewer provides a balanced critique without resorting to personal attacks or overly negative language."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges some interesting aspects of the paper, they identify 'a fundamental flaw in the experimental setup' and state that the paper's main contributions 'do not hold up'. This indicates a strong negative sentiment towards the paper's core claims and methodology. However, it's not entirely negative as the reviewer does mention some positive aspects, hence not scoring at the extreme negative end. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I would suggest' and acknowledging positive aspects. They avoid personal attacks or overly harsh language. However, the criticism is direct and doesn't employ many softening phrases, preventing a higher politeness score. The reviewer also offers constructive feedback and explains their reasoning, which contributes to the slightly positive politeness score.""]"
"['* The proposed SGLD-SA algorithm, together with its convergence properties, is very interesting. The introduction of step size $w^{k}$ is very similar to the ""convex combination rule"" in (Zhang & Brand 2017) to guarantee convergence.\n  \n* It seems that this paper only introduced Bayesian inference in the output layers. It would be more interesting to have a complete Bayesian model for the full network including the inner and activation layers.\n\n* This paper imposed spike-and-slab prior on the weight vector which can yield sparse connectivity. Similar ideas have been explored to compress the model size of deep networks (Lobacheva, Chirkova and Vetrov 2017; Louizos, Ullrich and Welling 2017 ). It would make this paper stronger to compare the sparsification and compression properties with the above work.\n\n* In equation (11) there is a summation from $\\beta_{p+1}$ to $\\beta_{p+u}$. I wonder where this term comes from, as I thought $\\beta$ is a vector of dimension $p$.\n\nReference:\nZhang, Ziming, and Matthew Brand. ""Convergent block coordinate descent for training tikhonov regularized deep neural networks."" Advances in Neural Information Processing Systems. 2017.\n\nLobacheva, Ekaterina, Nadezhda Chirkova, and Dmitry Vetrov. ""Bayesian Sparsification of Recurrent Neural Networks."" arXiv preprint arXiv:1708.00077 (2017).\n\nLouizos, Christos, Karen Ullrich, and Max Welling. ""Bayesian compression for deep learning."" Advances in Neural Information Processing Systems. 2017.\n\n', 'TITLE\nBayesian deep learning via stochastic gradient mcmc with a stochastic approximation adaptation\n\nREVIEW SUMMARY\nFairly well written paper on SG-MCMC type inference in neural networks with slab and spike priors. In my view, the originality and significance is limited.\n\nPAPER SUMMARY\nThe paper develops a method for sampling/optimization of a Bayesian neural network with slab and spike priors on the weights.\n\nQUALITY\nI belive the contribution is technically sound (but I have not checked all equations or the proof of Theorem 1). The empirical evaluation is not unreasonable, but also not strongly convincing.\n\nCLARITY\nThe paper is fairly well written, but grammar and use of English could be slightly improved (not so important).    \n\nORIGINALITY\nThe paper builds on existing work on EM-type algorithms for slab and spike models and SG-MCMC for Bayesian inference in neural networks. The novelty of the contribution is limited: The main contribution is the combination of the two methods and some theoretical results. I am not able to judge if there is significant originality in the theoretical results (Theorem 1 + Corr 1+2) but if I am not mistaken it is more or less an application of a known result to this particular setting?\n\nSIGNIFICANCE\nWhile I think the proposed algorithm is reasonable and most likely useful in practice, I am not sure the contribution is substantial enough to gain large interest in the community.  \n\nFURTHER COMMENTS\nFigure 2 (d+e) are in my view not so useful for assessing the training/test performance, but I am not even completely sure what the figures shows, as there are no axis labels. I would prefer some results on the loss, perhaps averaged over multiple data sets.\n\n', 'The authors describe a new method of posterior sampling with latent variables based on SG-MCMC and stochastic approximation (SA). The new method uses a spike and slab prior on the weights of the deep neural networks to encourage sparsity. Experiments on toy regressions, classification and adversarial attacks demonstrate the superiority over SG-MCMC and EMSV.\n\nCompared to the previous work EMSV (ESM), the novelty of SG-MCMC-SA is replacing the MAP in EMSV by SG-MCMC with stochastic approximation to alleviate the local trap problem in DNNs. However, I did not see why SG-MCMC with SA can achieve this goal. It is known that SG-MCMC methods tend to get trapped in a local optimal [1]. How did SA solve this problem? Besides, it is unclear to me where Eq. 17 uses stochastic approximation. The authors need to explain more about stochastic approximation for the readers who are not familiar with this method. \n\nEmpirical results on a synthetic example, MNIST and FMNIST show that SG-MCMC-SA outperforms the previous methods. However, the improvements of the proposed method are marginal. MNIST and FMNIST are small and easy datasets and it is very hard to tell the effectiveness of SG-MCMC-SA. It would be more convincing to show the empirical results on other datasets, e.g. CIFAR, using some larger architectures. The comparison would be more significant in that case. \n\n[1]. Zhang, Yizhe, et al. ""Stochastic Gradient Monomial Gamma Sampler."" arXiv preprint arXiv:1706.01498 (2017).\n']","[50, -20, -20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the proposed algorithm as 'very interesting' and notes its similarity to existing work, which is a positive point. However, they also suggest areas for improvement and raise questions, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, such as 'It would be more interesting' and 'It would make this paper stronger,' offering constructive criticism without being harsh. They also acknowledge the paper's strengths before suggesting improvements. The use of phrases like 'I wonder' when asking for clarification further contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'fairly well written' and 'technically sound', they express concerns about the originality and significance of the work. Phrases like 'the originality and significance is limited' and 'I am not sure the contribution is substantial enough to gain large interest in the community' indicate a somewhat negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout. They offer constructive criticism and use phrases like 'I believe' and 'in my view' to soften their critiques. The reviewer also acknowledges positive aspects of the paper alongside their criticisms, maintaining a respectful tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work, they express significant concerns and skepticism about the method's effectiveness and novelty. The reviewer points out that the improvements are marginal and suggests that more convincing evidence is needed. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'It would be more convincing' and 'The authors need to explain more' rather than harsh criticism. They also acknowledge the work's positive aspects before presenting their concerns. The language is constructive and aimed at improving the paper rather than dismissing it outright.""]"
"['The paper discusses clustering sparse sequences using some mixture model. It discusses results about clustering data obtained from a restaurant loyalty program.\n\nIt is not clear to me what the research contribution of the paper is. What I see is that some known techniques were used to cluster the loyalty program data and some properties of the experiments conducted noted down. No comparisons are made. I am not sure what to evaluate in this paper. ', 'The paper is very poorly written. It is hard to understand what the real contribution is in this paper. \nThe connection of the model with HMM is not clear. The literature review has to be rewritten.\n\nTo the reader, it sounds that the authors are confused with the fundamentals itself: mixture model, Bayesian models, inference. \n\n> Mixture models can be based on any of the exponential family distributions - Gaussian just happens to be the most commonly used.\n> Again if this is a Bayesian model, why are #clusters not inferred? The authors further mention that in their Pystan implementation K clusters were spun too quick. What was the K used here? Was it set to a very large value or just 3? Did the authors eventually use the truncated infinite mixture model in Pystan?\n> The authors mention their model is conceptually similar to EM but then end up using NUTS. \n> Why is a url given in Section 2.3 instead of being given in the references? \n> Provide a plate model describing Section 3.2.', 'This paper propose a hierarchical Bayesian model to cluster sparse sequences data. The observations are modeled as Poisson distributions, whose rate parameter \\lambda_i is written as the summation of \\lambda_{ik}, a Gamma distribution with rate equal to the mixture proportion \\alpha_{ik}. The model is implemented in Pystan. Experimental results on a real-world user visit dataset were presented.\n\nThe format of this paper, including the listing in the introduction section, the long url in section 2.3, and the model specification in section 3.2, can be improved. In particular, the presentation of the model would be more clear if the graphical model can be specified. \n\nThe motivation of choosing the observation model and priors is not clear. In section 3, the author described the details of model specification without explaining why those design choices were appropriate for modeling sparse sequence data.\n\nExperimental results on a real-world dataset is presented. However, to demonstrate how the model works, it would be best to add synthetic experiments as sanity check. Results using common baseline approaches should also be presented. The results should also be properly quantified in order to compare the relative advantage of different approaches.', 'The problem formulation at the bottom of page 3 correspond to what a bag of words preprocessing of a document would provide and in this the clustering would be a much simpler solution that just doing LDA.\n\nThe paper has zero interest.', 'Pros:\n-- Clustering sequence vectors is a practical and useful problem. Some of the business use-cases described in the paper are indeed useful and relevant for analytics in healthcare and retail.\n\nCons:\n-- The paper is poorly written. There are numerous typos and grammatical errors throughout the paper. \n-- The ideas are not presented coherently. The writing needs to improve quite a bit to get accepted at a conference like ICLR.\n-- Description of related literature is done very poorly.  \n-- The generative model described clearly lacks justification. The model is not described concretely either. There is no clear description of the inference techniques used.\n-- Empirical results are weak. ']","[-50, -90, -20, -100, -70]","[0, -50, 50, -80, -20]","[""The sentiment score is -50 because the reviewer expresses confusion about the paper's research contribution and states that they are unsure what to evaluate, indicating a negative sentiment. However, it's not extremely negative as they don't outright reject the paper. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They state their concerns directly without using overly harsh language or personal attacks, but also without any notably courteous phrasing. The review focuses on the content of the paper rather than on praising or criticizing the authors personally."", ""The sentiment score is -90 because the review is overwhelmingly negative. The reviewer states that the paper is 'very poorly written' and 'hard to understand', indicating significant issues with the content and presentation. They also suggest that the authors are 'confused with the fundamentals', which is a strong criticism of the authors' understanding of the subject matter. There are no positive comments to offset these criticisms. The politeness score is -50 because while the language is not overtly rude, it is quite blunt and lacks any softening phrases or constructive tone. The reviewer directly states negative opinions without cushioning the criticism or offering encouragement. However, the score is not lower because the reviewer does provide specific points for improvement, which is a professional approach, even if not particularly polite in delivery."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal and implementation, they point out several areas for improvement. The review starts with a neutral summary but then lists multiple criticisms about the paper's format, lack of clear motivation for model choices, and insufficient experimental results. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement without using harsh or dismissive language. The critique is presented in a matter-of-fact manner, focusing on the content rather than making personal comments about the authors."", ""The sentiment score is -100 (extremely negative) because the reviewer states that the paper has 'zero interest,' which is a harsh and dismissive evaluation. They also suggest that the problem formulation is overly simplistic, implying that the work is not valuable or innovative. The politeness score is -80 (very impolite) due to the blunt and curt nature of the feedback. The reviewer provides no constructive criticism or suggestions for improvement, and the phrase 'zero interest' is particularly rude and unprofessional in academic discourse. The brevity of the review and lack of any positive remarks or softening language further contribute to its impolite tone."", ""The sentiment score is -70 because the review is predominantly negative. While it acknowledges some positive aspects ('Clustering sequence vectors is a practical and useful problem'), the majority of the review lists significant cons, including poor writing, lack of coherence, weak empirical results, and inadequate description of the model and related literature. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and critical without much attempt to soften the criticism or offer constructive suggestions. Phrases like 'poorly written', 'needs to improve quite a bit', and 'clearly lacks justification' contribute to a somewhat impolite tone.""]"
"['The paper ""Neural Distribution Learning for generalized time-to-event prediction"" proposes HazardNet, a neural network framework for time-to-event prediction with right-censored data. \n \nFirst of all, this paper should be more clear from the begining of the kind of problems it aim to tackle. The tasks the proposal is able to consider is not easy to realize, at least before the experiments part. The problem should be clearly formalized in the begining of the paper (for instance in the introduction of section 3). It the current form, it is very hard to know what are the inputs, are they sequences of various kinds of events or only one type of event per sequence. It is either not clear to me wether the censoring time is constant or not and wether it is given as input (censoring time looks to be known from section 3.4 but in that case I do not really understand the contribution : does it not correspond to a very classical problem where events from outside of the observation window should be considered during training ? classical EM approaches can be developped for this). The problem of unevenly spaced sequences should also be more formally defined. \n\nAlso, while the HazardNet framework looks convenient, by using hazard and survival functions as discusses by the authors, it is not clear to me what are the benefits from recent works in neural temporal point processes which also define a general framework for temporal predictions of events. Approaches such at least like ""Modeling the intensity function of point process via recurrent neural networks"" should be considered in the experiments, though they do not explicitely model censoring but  with slight adapations should be able to work well of experimental data. \n\n\n', 'This paper proposes to use a mixture of distributions for hazard modeling. They use the standard censored loss and binning-based discretization for handling irregularities in the time series. \n\nThe evaluation is quite sub-par. Instead of reporting the standard ranking/concordance metrics, the authors report the accuracy of binary classification in certain future timestamps ahead. If we are measuring the classification accuracy, there is a little justification for using survival analysis; we could use just a classification algorithm instead. Moreover, the authors do not compare to the many existing deep hazard model such as Deep Survival [1], DeepSurv [2], DeepHit [3], or many variations based on deep point process modeling. The authors also don’t report the result for non-mixture versions, so we cannot see the true advantages of the proposed mixture modeling.\n\nA major baseline for mixture modeling is always non-parametric modeling. In this case, given that there are existing works on deep Cox hazard modeling, the authors need to show the advantages of their proposed mixture modeling against deep Cox models.\n\nOverall, the methodology in this paper is quite limited and the evaluation is non-standard. Thus, I vote for rejection of the paper.\n\n\n[1] Ranganath, Rajesh, et al. ""Deep Survival Analysis."" Machine Learning for Healthcare Conference. 2016.\n\n[2] Katzman, Jared L., et al. ""DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network."" BMC medical research methodology 18.1 (2018): 24.\n\n[3] Lee, Changhee, et al. ""Deephit: A deep learning approach to survival analysis with competing risks."" AAAI, 2018.', 'The authors propose a parametric framework (HazardNet) for survival analysis with deep learning where they mainly focus on the discrete-time case. The framework allows different popular architectures to learn the representation of the past events with different explicit features. Then, it considers a bunch of parametric families and their mixtures for the distribution of inter-event time. Experiments include a comprehensive comparison between HazardNet and different binary classifiers trained separately at each target time duration. \n\nOverall, the paper is well-written and easy to follow. It seeks to build a strong baseline for the deep survival analysis, which is an hot ongoing research topic recently in literature. However, there are a few weaknesses that should be addressed. \n\n1. In the beginning, the paper motivates the mixtures of distributions from MDN. Because most existing work focuses on the formulation of the intensity function, it is very interesting to approach the problem from the cumulative intensity function instead. Originally, it looks like the paper seeks to formulate a general parametric form based on MDN. However, it is disappointing that in the experiments, it still only considers a few classic parametric distributions. There is lack of solid technical connection between Sec 3.1, 3.2 and Sec 4.\n\n2. The discretization discussion of Sec 3.4 is not clear. Normally, the major motivation for discretization is application-driven, say, in hospital, the doctor regularly triggers the inspection event. However, how to optimally choose a bin-size and how to aggregate the multiple events within each bin is still not clear, which is not sufficiently discussed in the paper. Why is taking the summation of the events in a bin a proper way of aggregation? What if we have highly skewed bins?\n\n3. Although the comparison and experimental setting in Figure 4 is comprehensive, the paper misses a very related work ""Deep Recurrent Survival Analysis, https://arxiv.org/abs/1809.02403"", which also considers the discrete-time version of survival analysis. Only comparing with the binary classifiers is not quite convincing without referring to other survival analysis work.\n\n4. Finally, the authors state that existing temporal point process work ""have little meaning without taking into account censored data"". However, if inspecting the loss function of these work closely, we can see there is a survival term exactly the same as the log-cumulative hazard in Equation 3 that handles the censored case.\n\n5. A typo on the bottom of page 3, should be p(t) = F(t + 1) - F(t)\n']","[-30, -80, -20]","[20, -20, 60]","[""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper, particularly regarding clarity and comparison with existing work. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the convenience of the HazardNet framework. The politeness score is 20 because the reviewer uses relatively neutral language and phrases criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'should be more clear' and 'it is not clear to me' which are polite ways of pointing out issues. The overall tone is professional and constructive, albeit critical."", ""The sentiment score is -80 because the review is highly critical and recommends rejection. The reviewer points out several major flaws in the paper's methodology and evaluation, describing the evaluation as 'quite sub-par' and the methodology as 'quite limited'. The reviewer also states that there is 'little justification' for the approach and that the authors don't compare their work to existing models or show advantages over non-mixture versions. The politeness score is -20 because while the reviewer maintains a professional tone overall, the language is direct and somewhat harsh in its criticism. The reviewer doesn't use overtly rude language, but there's a lack of positive reinforcement or constructive suggestions for improvement. The blunt statement 'I vote for rejection of the paper' at the end contributes to the slightly impolite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and addresses an important topic, they also point out several weaknesses and areas of disappointment. The review starts positively but then lists multiple criticisms, indicating an overall slightly negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'well-written and easy to follow' and frame their criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone, avoiding personal attacks or overly negative language, which contributes to the politeness of the review.""]"
"['This paper while presenting interesting ideas, is very poorly written. It seems as though the authors were in a rush to submit a manuscript and did not even bother with basic typesetting.\nFirstly, the paper spends too much time motivating and re-introducing the model of Arora et.al. Note to the authors here, they cite the same paper from Arora et.al for 2017 twice. The first time the model they refer to was introduced by the paper ""RAND-WALK: A latent variable model approach to word embeddings"", this is probably what the authors mean by the 2016 reference?\n\nNow coming to the experiments, the results are presented in a table that is poorly formatted. The section partitions are not clearly delimited, making for a hard read. Even if we overcome that and look at the results, the presented numbers are incredibly confusing. On the STS 13 and 15 data sets, Ethayarajh 2018\'s numbers are much better at 66.1 and 79.0. Coming to STS14 Ethayarajh attain 78.4 while the proposed method achieves 78.1. If we discount this for the moment, and look at the results on STS12 where the proposed method achieves 71.4, this is the only data set where the proposed method does better than the other baselines.\n\nSo almost on 3 of the 4 datasets Ethayarajh 2018 does better. This makes me question what exactly is the proposed model improving?\n\nCoupled with the fact that there is no motivation to explain results or future work, this makes for a very poorly written paper that is very challenging to read.\n\nIt is very likely that there is some merit to the proposed methods that introduce non linearity, but these points simply get lost in the mediocre presentation.', 'PAPER SUMMARY:\n\nThis paper introduces a non-extensive statistic random walk model to generate sentence embedding while accounting for \nhigh non-linearity in the semantic space.\n\nNOVELTY & SIGNIFICANCE:\n\nI am not sure what the main focus of this paper is. It seems accounting for non-linearity in the semantic space while generating sentence embedding has already been achieved by existing LSTM models -- the goal seems to be more about interpretability and computational efficiency but the paper did not really discuss these in detail (more on this later).\n\nIn terms of the proposed solution, I am also not sure what is the significance of using non-extensive statistic in this context. In fact, the background section gave the impression that the non-linear form of q-exponential is the main reason to advocate this approach. But, if it is only about handling non-linearity, there are plenty of alternatives and it is important to point out exactly what advantages non-extensive statistic has over the existing literature (e.g., why is it more interpretable than LSTM). Please expand the respective background section to clarify this. \n\nTECHNICAL SOUNDNESS:\n\nThere are parts of the technical exposition that appear confusing and somewhat incoherent. For instance, what exactly is this confounding effect of vector length & why do we need to address this issue if according to the Section 2.2, it has already been addressed in the same context?\n\nSection 2.2 seems to discuss this effect but the exposition is unclear to me. The authors start with an example and a bunch of assumptions that lead to a contradiction. \n\nIt is then concluded that the cause of this is due to the linearity assumption (what about the other assumptions?) in estimating the discourse vector. \n\nI do not really follow this reasoning and it would be good if the authors can elaborate more on this.\n\nCLARITY:\n\nThe paper seems to focus too much on technical details and does not give enough discussion on its positioning. The significance of the proposed solution with respect to the literature remains unclear. \n\nEMPIRICAL RESULTS:\n\nI am not an expert in this field and cannot really judge the significance of the reported results. I do, however, have a few questions: in all benchmarks, are the algorithms tested on a different domain than the domain it was trained on? \n\nHave the authors compared the proposed sentence embedding framework with the LSTM literature mentioned in the introduction? I noticed there was a LSTM AVG in the comparison table.\n\nIs that the simple averaging scheme mentioned in the introduction when the authors discussed transferrable sentence embedding?\n\nIs there any reason for not comparing with RNN (Cho et al., 2014)? \n\nIn terms of the computation processing cost, how efficient is the proposed method (as compared to existing literature)?', ""Summary: this paper discussed an incremental improvement over the Random Walk based model for sentence embedding.\n\nConclusion: this paper is not ready for publication, very poor written and well below the bar of ICLR-caliber papers. \n\nMore:\nThis paper spent the majority of its content explaining background (those paragraphs were very poor written and difficult to read), and very briefly introduced their methodology with some mathematical derivations and equations, most of which can be put in the supplement instead of main context. The author didn't quite explain how the proposed method, such as why using non-extensive statistic in this context,\n\nThe experiment results aren't convincing and lack sufficient information for reproducibility.""]","[-70, -50, -80]","[-30, 20, -30]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper is 'very poorly written', criticizes the formatting, questions the results, and concludes that it's a 'very poorly written paper that is very challenging to read'. The only positive aspect mentioned is that there might be 'some merit to the proposed methods', but this is overshadowed by the criticisms. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and critical. Phrases like 'did not even bother with basic typesetting' and 'mediocre presentation' are particularly blunt. However, the reviewer does attempt to provide specific feedback and suggestions, which prevents the score from being even lower."", ""The sentiment score is -50 because the reviewer expresses significant doubts and criticisms about the paper's focus, novelty, and technical soundness. They use phrases like 'I am not sure what the main focus of this paper is' and 'There are parts of the technical exposition that appear confusing and somewhat incoherent', indicating a generally negative view. However, the score is not lower because the reviewer also asks questions and suggests improvements, showing some engagement with the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they use polite language throughout, such as 'Please expand', 'It would be good if the authors can elaborate', and 'I do, however, have a few questions'. The tone is professional and constructive, even when pointing out flaws, which keeps the score slightly positive on the politeness scale."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper is 'not ready for publication,' 'very poor written,' and 'well below the bar of ICLR-caliber papers.' They also criticize the content, methodology explanation, and experimental results. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. They use phrases like 'very poor written' and 'aren't convincing,' which are direct criticisms without much attempt to soften the blow. However, they do provide some specific feedback, which prevents the score from being even lower.""]"
"['This paper extends the definition of adversarial examples to the ones that are “far” from the training data, and provides two conditions that are sufficient to guarantee the non-existence of adversarial examples. The core idea of the paper is using the epistemic uncertainty, that is the mutual information measuring the reduction of the uncertainty given an observation of the data, to detect such faraway data. The authors provided simulation studies to support their arguments.\n\nIt is interesting to connect robustness with BNN. Using the mutual information to detect the “faraway” datapoint is also interesting. But I have some concerns about the significance of the paper:\n1.  The investigation of this paper seems shallow and vague. \n    (1). Overall, I don’t see the investigation on the “typical” definition of adversarial examples. The focus of the paper is rather on detecting “faraway” data points. The nearby perturbation part is taken care by the concept of “all possible transformations” which is actually vague.\n    (2). Theorem 1 is basically repeating the definition of adversarial examples. The conditions in the theorem hardly have practical guidance: while they are sufficient conditions, all transformations etc.. seem far from being necessary conditions, which raises the question of why this theory is useful? Also how practical for the notion of “idealized NN”?\n    (3). What about the neighbourhood around the true data manifold? How would the model succeed to generalize to the true data manifold, yet fail to generalize to the neighbourhood of the manifold in the space?  Delta ball is not very relevant to the “typical” definition of adversarial examples, as we have no control on \\delta at all.\n2. While the simulations support the concepts in section 4, it is quite far from the real data with the “typical” adversarial examples. \n\nI also find it difficult to follow the exact trend of the paper, maybe due to my lack of background in bayesian models. \n1. In the second paragraph of section 3, how is the Gaussian processes and its relation to BNN contributing to the results of this paper?\n2. What is the rigorous definition for \\eta in definition 1?\n3. What is the role of $\\mathcal{T}$, all the transformations $T$ that introduce no ambiguity, in Theorem 1. Why this condition is important/essential here?\n4. What is the D in the paragraph right after Definition 4? What is D’ in Theorem 1?\n5. Section references need to be fixed. \n\n\n\n', 'In this paper, the authors posit a class of discriminative Bayesian classifiers that, under sufficient conditions, do not have any adversarial examples. They distinguish between two sources of uncertainty (epistemic and aleatoric), and show that mutual information is a measure of epistemic uncertainty (essentially uncertainty due to missing regions of the input space). They then define an idealised Bayesian Neural Network (BNN), which is essentially a BNN that 1) outputs the correct class probability (and always with probability 1.0) for each input in the training set (and for each transformation of training inputs that the data distribution is invariant under), and 2) outputs a sufficiently high uncertainty for each input not in the union of delta-balls surrounding the training set points. Similarly, an example is defined to be adversarial if it has two characteristics: it 1) lies far from the training data but is classified with high output probability, and it 2) is classified with high output probability although it lies very close to another example that is classified with high output probability for the other class. Condition 1) of an idealised BNN prevents Definition 2) of an adversarial example using the fact that BNNs are continuous, and Condition 2) prevents Definition 1) of an adversarial example since it will prevent ""garbage"" examples by predicting with high uncertainty (of course I\'m glossing over many important technical details, but these are the main ideas if I understand correctly).\n\nThe authors backed up their theoretical findings with empirical experiments. In the synthetic MNIST examples, the authors show that adversarial attacks are indeed correlated with lower true input probability. They show that training with HMC results in high uncertainty for inputs not near the input-space, a quality certainly not shared with all other deep models (and another reason that Bayesian models should be preferred for preventing adversarial attacks). On the other hand, the out-of-sample uncertainty for training with dropout is not sufficient to prevent adversarial attacks, although the authors posit a form of dropout ensemble training to help prevent these vulnerabilities. \n\nThe authors are tackling an important issue with theoretical and technical tools that are not used often enough in machine learning research. Much of the literature on adversarial attacks is focused on finding adversarial examples, without trying to find a unifying theory for why they work. They do a very solid exposition of previous work, and one of the strengths of this paper comes in presenting their findings in the context of previously discovered adversarial attacks, in particular that of the spheres data set. \n\nUltimately, I\'m not convinced of the usefulness of their theoretical findings. In particular, the assumption that the model is invariant to all transformations that the data distribution is invariant under is an unprovable assumption that can expose many real-world vulnerabilities. This is the case of the spheres data set without a rotation invariance from Gilmer et al. (2018). In the appendix, the authors mention that the data invariance property is key for making the proof non-vacuous, and I would agree. Without the data invariance property, the proof mainly relies on the fact that BNNs are continuous. The experiments are promising in support of the theory, but they do not seem to address this data invariance property. Indeed a model can prevent adversarial examples by predicting high uncertainty for all points that are not near the training examples, which Bayesian models are well equipped to do.\n\nI also thought the paper was unclear at times. It is not easy to write such a technical and theoretical paper and to clearly convey all the main points, but I think the paper would\'ve benefited from more clarity. For example, the notation is overloaded in a way that made it difficult to understand the main proofs, such as not clearly explaining what is meant by I(w ; p) and not contrasting between the binary entropy function used for the entropy of a constant epsilon and the more general random variable entropy function. In contrast, I thought the appendices were clearer and helpful for explaining the main ideas. Additionally, Lemma 1 follows trivially from continuity of a BNN. Perhaps removing this and being clearer with notation would\'ve allowed for more room to be clearer for the proof of Theorem 1. \n\nA more minor point that I think would be interesting is comparing training with HMC to training with variational inference. Do the holes that come from training with dropout still exist for VI? VI could certainly scale in a way that HMC could not, which perhaps would make the results more applicable. \n\nOverall, this is a promising theoretical paper although I\'m not currently convinced of the real-world applications beyond the somewhat small examples in the experiments section.\n\nPROS\n-Importance of the issue\n-Exposition and relation to previous work\n-Experimental results (although these were for smaller data sets)\n-Appendices really helped aid the understanding\n\nCONS\n-Real world usefulness\n-Clarity ', 'The paper studies the adversarial robustness of Bayesian classifiers. The authors state two conditions that they show are provably sufficient for ""idealised models"" on ""idealised datasets"" to not have adversarial examples. (In the context of this paper, adversarial examples can either be nearby points that are classified differently with high confidence or points that are ""far"" from training data and classified with high confidence.) They complement their results with experiments.\n\nI believe that studying Bayesian models and their adversarial robustness is an interesting and promising direction. However I find the current paper lacking both in terms of conceptual and technical contributions.\n\nThey consider ""idealized Bayesian Neural Networks (BNNs)"" to be continuous models with a confidence of 1.0 on the training set. Since these models are continuous, there exists an L2 ball of radius delta_x around each point x, where the classifier has high confidence (say 0.9). This in turn defines a region D\' (the training examples plus the L2 balls around them) where the classifier has high confidence. By assuming that an ""idealized BNN"" has low certainty on all points outside D\' they argue that these idealized models do not have adversarial examples. In my opinion, this statement follows directly from definitions and assumptions, hence having little technical depth or value. From a conceptual point of view, I don\'t see how this argument ""explains"" anything. It is fairly clear that classifiers only predicting confidently on points _very_ close to training examples will not have high-confidence adversarial examples. How do these results guide our design of ML models? How do they help us understand the shortcomings of our current models?\n\nMoreover, this argument is not directly connected to the accuracy of the model. The idealized models described are essentially only confident in regions very close to the training examples and are thus unlikely to confidently generalize to new, unseen inputs. In order to escape this issue, the authors propose an additional assumption. Namely that idealized models are invariant to a set of transformations T that we expect the model to be also invariant to. Hence by assuming that the ""idealized"" training set contains at least one input from each ""equivalence class"", the model will have good ""coverage"". As far as I understand, this assumption is not connected to the main theorem at all and is mostly a hand-wavy argument. Additionally, I don\'t see how this assumption is justified. Formally describing the set of invariances we expect natural data to have or even building models that are perfectly encoding these invariances by design is a very challenging problem that is unlikely to have a definite solution. Also, is it natural to expect that for each test input we will have a training input that is close to L2 norm to some transformation of the test input?\n\nAnother major issue is that the value of delta_x (the L2 distance around training point x  where the model assigns high confidence) is never discussed. This value is _very_ small for standard NN classifiers (this is what causes adversarial examples in the first place!). How do we expect models to deal with this issue? \n\nThe experimental results of the paper are essentially for a toy setting. The dataset considered (""ManifoldMNIST"") is essentially synthetic with access to the ground-truth probability of each sample. Moreover, the results on real datasets are unreliable. When evaluating the robustness of a model utilizing dropout, using a single gradient estimation query is not enough. Since the model is randomized, it is necessary to estimate the gradient using multiple queries. By using first-order attacks on these more reliable gradient estimates, an adversary can completely bypass a dropout ""defense"" (https://arxiv.org/abs/1802.00420).\n\nOverall, I find the contributions of the paper limited both technically and conceptually. I thus recommend rejection.\n\n[UPDATE]: Given the discussion with the authors, I agree that the paper outlines a potentially interesting research direction. As such, I have increased my score from 3 to 5 (and updated the review title). I still do not find the contribution of the paper significant enough to cross the ICLR bar.\n\nComments to the authors:\n-- You cite certain detention methods for adversarial examples (Grosse et al. (2017), Feinman et al. (2017)) that have been shown to be ineffective (that is they can be bypassed by an adaptive attacker) by Carlini and Wagner (https://arxiv.org/abs/1705.07263)\n-- The organization of the paper could be improved. I didn\'t understand what the main contribution was until reading Theorem 1 (this is 6 pages into the paper). The introduction is fairly vague about your contributions. You should consider moving related work later in the paper (most of the discussion there is not directly related to your approach) and potentially shortening your background section.\n-- How is the discussion about Gaussian Processes connected with your results?\n-- Consider making the two conditions more prominent in the text.\n-- In Definition 5, the wording is confusing ""We define an idealized BNN to be a Bayesian idealized NN...""']","[-30, -20, -70]","[20, 60, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they express several significant concerns about its depth, clarity, and practical relevance. The overall tone is more critical than positive. The politeness score is 20 because the reviewer uses respectful language and frames their criticisms as 'concerns' and questions rather than direct attacks. They also acknowledge their own potential lack of background in some areas. However, the review is not overly polite or effusive, maintaining a professional, somewhat neutral tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the promising aspects of the paper, they express significant doubts about the real-world applicability and usefulness of the theoretical findings. The reviewer also points out issues with clarity and some assumptions made in the paper. However, the review is not entirely negative, as it recognizes the paper's strengths in exposition, relation to previous work, and experimental results. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I'm not convinced' rather than more harsh language, and they balance criticism with praise by mentioning both pros and cons. The reviewer also acknowledges the difficulty of writing such a technical paper, which shows empathy towards the authors."", ""The sentiment score is -70 because the reviewer expresses significant criticism throughout the review, recommending rejection and stating that the paper is 'lacking both in terms of conceptual and technical contributions'. They find the main arguments to have 'little technical depth or value' and the experimental results to be for a 'toy setting'. Despite acknowledging some potential in the research direction, the overall tone remains largely negative. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I believe', 'In my opinion', and 'I find', which soften the criticism. They also acknowledge the potential interest in the research direction. However, the review doesn't go out of its way to be overly polite, maintaining a mostly neutral, academic tone.""]"
"['This paper provides a theoretical perspective of the dual learning tasks and proposes two generalizations (multipath/cycle dual learning) that utilize multiple language sets. Through experiments, the paper discusses the relationship between theoretical perspective and actual translation quality.\n\nOverall, the paper is well written and discussed enough. My concern is about Theorem 1 that could be a critical problem.\nIn the proof of Theorem 1, it discussed that the dual learning can minimize Case 2. This assumption is reasonable if the vanilla translator is completely fixed (i.e., no longer updated) but this condition may not be assumed by the authors as far as I looked at Algorithm 2 and 3 that update the parameters of vanilla translators directly. The proof is constructed by only the effect against Case 2. However, if the vanilla translator is directly updated through dual training, there should exist some random changes in also Case 1 and this behavior should also be included in the theorem.\n\nCorrection and suggestions writing:\n* It is better to introduce an additional $\\alpha$, $\\beta$ and $\\gamma$ for the vanilla translation accuracy (e.g., $\\alpha_0 := p_{ij}p_{ji}^r$) so that most formulations in Section 3 can be largely simplified.\n* In Justification of Assumption1 ... ""the probability of each cluster is close to $p_max$"" ->  maybe ""greater than $p_max$"" to satisfy the next inequality.\n* Eq. (3) ... $T_{ji}^d(T_{ij}^d(x^{(i)})$ -> $T_{ji}^d(x^{(j)})$ to adjust other equations.\n* Section 3 Sentence 1: ""translatorby"" -> ""translator by""\n* Section 4.2: ${\\rm Pr}_{ X^{(3)} \\sim T_{23}^d (X^{(1)}) }$ -> $... (X^{(2)}) }$', 'The paper gives theorems concerning ""dual learning"" - that is, making\nuse of round-trip consistency in learning of translation and other\ntasks.\n\nThere are some interesting ideas here. Unfortunately, I think there\nare issues with clarity/choice of notation and correctness (errors\nresulting from problems with the notation - or at least it\'s very\nhard to figure out if things are correct under some intepretation).\n\nMore specifically, I\'m uneasy about the use of x^i and x^j as defined\nin section 2. In some cases x^j is a deterministic function of x^i, in\nsome cases it\'s a random variable, these cases are mixed. Section 2\nbecomes tangled up in this issue. It would be much better I think to\ndefine a function f_ij(x) for each (i,j) pair that maps a sentence\nx \\in S^i to its correct translation f_ij(x) \\in S^j.\n\nA critical problem with the paper is that Eq. 2 is I think incorrect.\nClearly,\n\nPr(T_ij(x_i) = f_ij(x_i), T_ji(f_ij(x_i)) = x_i)      [1]\n=\nPr(T_ij(x_i) = f_ij(x_i))                             [2]\n*\nPr(T_ji(f_ij(x_i)) = x_i) | T_ij(x_i) = f_ij(x_i))    [3]\n\nI think [1] is what is meant by the left-hand-side of Eq 2 in the paper -\nthough the use of x^j is ambiguous (this ambiguity is a real issue).\n\nIt can be verified that\n\nPr(T_ij(x_i) = f_ij(x_i)) = p_ij\n\nhowever\n\nPr(T_ji(f_ij(x_i)) = x_i) | T_ij(x_i) = f_ij(x_i)) \\neq p^r_ji\n\nThe definition of p^r_ji is that of a different quantity.\n\nThis problem unfortunately permeates the statement of theorem 1, and\nthe proof of theorem 1. It is probably fixable but without a\nsignificantly revised version of the paper a reader/reviewer is\nbasically guessing what a corrected version of the paper would\nbe. Unfortunately I think publishing the paper with errors such as\nthis would be a problem.\n\nSome other points:\n\n[1] The theorem really does have to assume that there is a unique\ncorrect translation f_ij(x^i) for each sentence x^i. Having multiple\npossible translations breaks things. The authors say in section 2 ""In\npractice, we may select a threshold BLEU (Papineni et al., 2002a)\nscore, above which the translation is considered correct"": this seems\nto imply that the results apply when multiple translations (above\na certain BLEU score) are possible. But my understanding is that this\nwill completely break the results (or at least require a significant\nmodification of the theory).\n\n[2] A further problem with ambiguity/notation is that T^d is never\nexplicitly defined. Presumably we always have T_ij^s(x^i) = T_ij(x^i) if\nT_ji(T_ij(x^i)) = x^i? That needs to be explicitly stated.\n\n[3] There may be something interesting in theorem 1 - putting aside point\n[1] above - but I am just really uneasy with this theorem and its proof\ngiven that it uses p^r_ji, and the issue with Eq. 2.\n\n[4] Another issue with the definition of p^r_ij: the notation\nP_{X^(j, r) ~ \\mu}(...) where the expression ... does not refer\nto X^{j, r} (instead it refers to x^j) is just really odd,\nand confusing.\n', 'The paper addresses a means of boosting the accuracy of automatic translators (sentences) by training dual models (a.k.a. language A to B, B to A), multipath (e.g. A to B to C) and cyclical (e.g. A to B to C to A) while starting with well initialized models for translating simple pairs. The idea that additional errors are revealed and allow classifiers to adapt, thus boosting classifier performance, is appealing and intuitive. That a theoretical framework is presented to support this assumption is encouraging, but the assumptions behind this analysis (e.g. Assumption 1) are rather strong. Equation 2 assumes independence. Equations 3-5 can be presented more clearly. Not only are translation errors not uniform in multiclass settings, but they can be highly correlated - this being a possible pitfall of boosting approaches, seen as general classifier errors. The same strong assumptions permeate from the dual to the cyclical case. On the other hand, the (limited) empirical test presented, using a single dataset and baseline classifier method, does support the proposed improvement by boosting, albeit leading to improvements which are slight.']","[-20, -50, 20]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'well written and discussed enough', they express a 'concern' about Theorem 1, which they describe as a 'critical problem'. This indicates a significant issue that impacts the overall positive aspects of the paper. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'It is better to' and 'maybe' when suggesting changes, which maintains a polite tone. The reviewer also balances criticism with positive comments, such as acknowledging the paper is well-written before discussing concerns."", ""The sentiment score is -50 because while the reviewer acknowledges 'some interesting ideas,' they express significant concerns about clarity, notation, and correctness. They state that there are 'critical problems' and 'errors' that make the paper unpublishable in its current state. However, it's not entirely negative as they suggest the issues might be fixable. The politeness score is 20 because the reviewer uses relatively polite language, such as 'Unfortunately, I think...' and 'I'm uneasy about...', rather than harsh criticisms. They also acknowledge the potential of the work. However, the review is still quite direct in pointing out flaws, which prevents a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the appeal and intuitiveness of the paper's idea, and notes that the empirical test supports the proposed improvement. However, they also express concerns about strong assumptions and limited empirical testing, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout, avoiding harsh criticism and acknowledging both strengths and weaknesses of the paper. They use phrases like 'appealing and intuitive' and 'encouraging', which contribute to a polite tone, while still providing constructive criticism in a respectful manner.""]"
"['(Since the reviewer was unclear about the OpenReview process, this review was earlier posted as public comment)\n\nMost claims of novelty can be clearly refuted such as the first sentence of the abstract ""...This work presents a new approach to active anomaly detection..."" and the paper does not give due credit to existing work. Current research such as Das et al. which is the most relevant has been deliberately not introduced upfront with other works (because it shows lack of the present paper\'s novelty) and instead deferred to later sections. The onus of a thorough literature review and laying down a proper context is on the authors, not the reviewers. Detailed comments are below.\n      \n      1. Related Works: ""...active anomaly detection remains an under-explored approach to this problem...""\n          - Active learning in anomaly detection is well-researched (AI2, etc.). See related works section in Das et al. 2016 and:\n            - K. Veeramachaneni, I. Arnaldo, A. Cuesta-Infante, V. Korrapati, C. Bassias, and K. Li, ""Ai2: Training a big data machine to defend,"" International Conference on Big Data Security, 2016.\n        \n      2. ""To deal with the cold start problem, for the first 10 calls of select_top..."":\n          - No principled approach to deal with cold start and one-sided labels (i.e., the ability to use labels when instances from only one class are labeled.)\n        \n      3. Many arbitrary hyper parameters as compared to simpler techniques:\n          - The number of layers, nodes in hidden layers.\n            - The number of instances (k) per iteration\n            - The number of pretraining iterations\n            - The number of times the network is retrained (100) after each labeling call\n            - Dealing with cold start (10 labeling iterations of 10 labels each, i.e. 100 labels).\n        \n      4. The paper mentions that s(x) might not be differentiable. However, the sigmoid form of s(x) is differentiable.\n      \n      5. Does not acknowledge the well-known result that mixture models are unidentifiable. The math in the paper is mostly redundant. Some references:\n          - Identifiability  Of  Nonparametric  Mixture  Models And  Bayes  Optimal  Clustering (pradeepr/arxiv npmix v.pdf)"" target=""_blank"" rel=""nofollow"">https://www.cs.cmu.edu/ pradeepr/arxiv npmix v.pdf)\n          - Semiparametric estimation of a two-component mixture model by Bordes, L., Kojadinovic, I., and Vandekerkhove, P., Annals of Statistics, 2006 (https://arxiv.org/pdf/math/0607812.pdf)\n          - Inference for mixtures of symmetric distributions by David R. Hunter, Shaoli Wang, Thomas P. Hettmansperger, Annals of Statistics, 2007 (https://arxiv.org/pdf/0708.0499.pdf)\n          - Inference on Mixtures Under Tail Restrictions by K. Jochmans, M. Henry, and B. Salanie, Econometric Theory, 2017 (http://econ.sciences-po.fr/sites/default/files/file/Inference.pdf)\n          \n      6. Does not acknowledge existing work that adds classifier over unsupervised detectors (such as AI2). This is very common.\n        - This is another linear model (logistic) on top of transformed features. The difference is that the transformed features are from a neural network and optimization can be performed in a joint fashion. The novelty is marginal.\n        \n      7. While the paper argues that a prior needs to be assumed, it does not use any in the algorithm. There seems to be a disconnect. It also does not acknowledge that AAD (LODA/Tree) does use a prior. Priors for anomaly proportions in unsupervised algorithms are well-known (most AD algos support that such as OC-SVM, Isolation Forest, LOF, etc.).\n        \n      8. Does not compare against current state-of-the-art Tree-based AAD\n          - Incorporating Expert Feedback into Tree-based Anomaly Detection by Das et al., KDD, 2017.\n        \n      9. The \'Generalized\' in the title is incorrect and misleading. This is specific to deep-networks. Stacking supervised classifiers on unsupervised detectors is very common. See comments on related works.\n      \n      10. Does not propose any other query strategies than greedily selecting top.\n      \n      11. Question: Does this support streaming?\n', 'This is an interesting paper on a topic with real-world application: anomaly detection.\n\nThe paper\'s organization is, at times quite confusing:\n- the introduction is unusually short, with a 1st paragraph virtually unreadable due to the abuse of citations. Two additional paragraphs, covering in an intuitive manner both the proposed approach & the main results, would dramatically improve the paper\'s readability\n- section 2.1 starts quite abruptly with he two Lemmas 7 and Theorem 3 (which, in fact, is Theorem 1). This section would probably read a lot better without the two Lemmas, as the authors only refer to the main result in the Theorem. The second, intuitive part of 2.1 is extremely helpful.\n- it is unclear why the authors have applied the approach in ""4.3"" only to a single dataset, rather than all the 11 datasets\n\nOther comments:\n- please change the color schemes for Figures 3 & 4, where the red/orange (Fig 3) and various blues (Fig 4) are difficult to distinguish \n- bottom of page 3: ""are rare as expected"" --> ""are as rare as expected""', 'The paper provided a convincing and intuitive motivation regarding the need for active learning in unsupervised anomaly detection. \nHowever the proposed approach of requesting expert feedback for the top ranked anomalies is straightforward and unsurprising, given past work on active learning. \nThe experiments on synthetic data are also unsurprising. Moreover these are based on a questionable premise: the instances that are ""hard"" to classify are treated as anomalies. This is not very realistic.\nRegarding the real data experiments: In Table 1 the results for DAE_uai are based on which budget b?  How does the result vary with b? \n']","[-80, -20, -20]","[-20, 50, 20]","[""The sentiment score is -80 because the review is highly critical, pointing out numerous flaws and lack of novelty in the paper. The reviewer refutes claims of originality, criticizes the literature review, and lists many specific issues with the methodology and comparisons. There are no positive comments. The politeness score is -20 because while the language is not overtly rude, the tone is quite harsh and dismissive. The reviewer uses phrases like 'can be clearly refuted', 'deliberately not introduced', and 'incorrect and misleading', which come across as somewhat impolite. However, the reviewer does maintain a professional tone overall and provides detailed, specific feedback, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer starts by calling the paper 'interesting' and acknowledges its 'real-world application', they then list several criticisms about the paper's organization and clarity. The reviewer points out multiple areas for improvement, including the confusing introduction, abrupt start of section 2.1, and unclear reasoning for applying the approach to only one dataset. However, the criticism is not overly harsh, hence the score is only slightly negative. The politeness score is moderately positive (50) because the reviewer uses polite language throughout, such as 'please change' and 'would dramatically improve'. They also balance criticism with positive comments, like noting the 'extremely helpful' intuitive part of section 2.1. The reviewer maintains a professional tone without using any rude or confrontational language, offering constructive feedback in a respectful manner."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'convincing and intuitive motivation', they express several criticisms. They describe the approach as 'straightforward and unsurprising', the experiments as 'unsurprising' and 'based on a questionable premise', and raise questions about the real data experiments. These criticisms outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is slightly positive (20) because the reviewer uses relatively neutral language and frames their criticisms as observations rather than direct attacks. They begin with a positive comment and use phrases like 'However' to introduce criticisms, which is a polite way to provide negative feedback. The questions at the end are presented in a neutral, inquiring manner rather than accusatorily.""]"

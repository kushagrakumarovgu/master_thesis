reviews,sentiment_scores,politeness_scores,reasonings
"['The major contribution of this work is extending routing networks (Rosenbaum et al., ICLR 2018) to use diverse architectures across routed modules. I view this as an important contribution and am very impressed by the experiment on Omniglot where it shows big performance gain on a split with very few examples. This idea of incorporating in architectural bias and not just parameter bias for small data problems is very compelling and intuitive to me on the surface. The ablation study was also very interesting in this regard. I really like the discourse and found it to be filled with interesting insights throughout ranging from the connection between routing networks and neural architecture search to the heuristic for selecting k.  However, after the great discourse, I was quite disappointed by the breadth of the experiments. \n\nThe paper is positioned as exploring two parallel ideas that are independently interesting 1) diversity in the architecture of modules in routing models 2) the effect of increasing depth in routing models. For the first idea, this is shown very well by the Omniglot experiment but is not evaluated in any other setting. Showing this in a few other experiments would have really driven this point home in my opinion.  The second idea is not really executed in a convincing way to me. The authors call it a ‘negative result’ in the end, but I’m not sure I really feel like I learned anything from this experiment. I wonder about statistical significance. I also feel like the authors are trying to turn it into a commentary that this is a pain point for all variants of routing models while they only actually tried it for their proposed architecture which makes quite a few decisions along the way. I would have liked to see more model variants and datasets before really feeling like I can make any empirical determinations about the fundamental limitations of all routing models in this regard.  Additionally, if there were such a fundamental scaling limitation, you would imagine that an experiment could be constructed that really highlighted this fact where all routing models do way worse.\n\nIn short, I think there are some really good idea in this paper and vote for acceptance on that basis. Had the authors provided more empirical evidence about architectural diversity, I would have given it a very high score. The analysis of depth is also a very interesting topic, but it could possibly even serve as another paper considering that the current results don’t really come to concrete conclusions for the community. \n', 'Overall, this is a valuable read. Authors tackle the head on problem of what is a good architecture where we can having routing with diverse models. The papers is written well, with comparisons to mixture of experts, other models that tackled this problem with either homogeneous architectures or static architectures. Below is my assessment on various axis:\n\nQuality - Enough experiments to justify some conclusions, equations helped ground the method with math.\n\nclarity - Very well written, good figures and analysis.\n\noriginality - While the authors achieve SOA results on OmniGlot and do explore a few options, I feel the work still lacks originality in the formulation or does not have original contributions to either the architectures used or the optimization procedures employed.\n\nsignificance - very significant to look at this problem both in terms of compute, accuracy perspective as well as scaling these networks for multiple tasks.\n\npros - thorough analysis, even the negative experiments are well written and throw more light into the problem space.\n\ncons - OmniGlot comparisons seem not fair as the model capacity is not added as part of the table which raises concerns on achieving state of the art with more high complexity models than routing mechanism. Will be great to move from CIFAR-10 and test things on CIFAR-100 to really see the value of proposed work. I would recommend a higher rating if authors address these two concerns.', 'The paper ""Diversity and Depth in Per-Example Routing Models"" extends previous work on routing networks by adding diversity to the type of architectural unit available for the router at each decision and by scaling to deeper networks. They evaluate their approach on Omniglot, where they achieve state of the art performance.\n\nOverall, the paper is very well written and every aspect can be easily understood. The overview over related work given in the paper is thorough, and the authors explain very well how their approach relates to previous approaches.\n\nThe architecture presented is a natural and important extension of previous work. Adding diversity in routing units has indeed not been investigated well and is an important contribution to the community. Additionally, the authors do a good job of identifying problems with existing approaches (overfitting, routing depth) and offer a empirically convincing solutions. \n\nThe result section given in the paper is its weakness and requires a more in-depth analysis:\n+ the results given for Omniglot are impressive\n+ the experiments analyzing the impact of diversity and routing depth are interesting and offer interesting insight into the architecture\n- the results do not show learning behavior over epochs; this is not necessary, but would give an additional insight into the learning behavior of the architecture\n- the experimental settings are confusing: why are the different experiments performed with different datasets? This makes it seem as if the authors cherry-picked the best results for the different experiments (this might not be the case, but the results on Omniglot alone are good enough that negative results and a detailed discussion of them would not have hurt the paper, but enriched the discourse)\n- additional experiments that offer a transition from larger datasets to smaller ones would be interesting; seeing how the performance of the architecture behaves e.g. on CIFAR10 for 1k, 5k, 10k, 25k and 50k would have illustrated how well the architecture is able to generalize from different numbers of samples\n\nIn summary, I think the paper analyzes a very important problem and has a lot of potential. However, it needs more extensive experiments that illustrate how the proposed architecture behaves over a wider variety of datasets.\n\nUPDATE AFTER REBUTTAL:\nI am still torn about this paper. On one hand, I still think that the topic and discourse provided by this paper is extremely important. On the other, the results - even after the revision - do not completely convince me. I might update my score after some discussion with the other reviewers.\n2ND UPDATE:\nAfter giving it some more thought, I find myself convinced that this paper has a contribution important enough to be accepted. I increase my score to 7.']","[50, 60, 60]","[80, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses both positive and negative opinions. They are impressed by the main contribution and find the ideas compelling, but are disappointed by the limited breadth of experiments. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the strengths of the paper while offering constructive criticism. They use phrases like 'I really like', 'very interesting', and 'I would have liked to see' which maintain a polite tone even when expressing concerns. The reviewer also balances critique with praise and provides specific suggestions for improvement, which is a hallmark of polite academic discourse."", ""The sentiment score is 60 (positive) because the reviewer starts with 'Overall, this is a valuable read' and mentions several positive aspects like 'well written', 'good figures and analysis', and 'thorough analysis'. However, it's not extremely positive due to some criticisms, particularly about originality and fairness of comparisons. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively (e.g., 'Will be great to move from CIFAR-10...'). The reviewer also offers suggestions for improvement rather than just pointing out flaws."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive views about the paper, praising its writing quality, thoroughness, and importance of the topic. They mention that the paper is 'very well written' and offers a 'natural and important extension of previous work'. However, they also point out some weaknesses in the results section, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance praise with criticism, using phrases like 'the paper analyzes a very important problem' while also offering specific suggestions for improvement. The reviewer's willingness to update their opinion after the rebuttal and further reflection also demonstrates a polite and fair approach.""]"
"['The paper proposes a method for learning regression models through evolutionary\nalgorithms that promise to be more interpretable than other models while\nachieving similar or higher performance. The authors evaluate their approach on\n99 datasets from OpenML, demonstrating very promising performance.\n\nThe authors take a very interesting approach to modeling regression problems by\nconstructing complex algebraic expressions from simple building blocks with\ngenetic programming. In particular, they aim to keep the constructed expression\nas small as possible to be able to interpret it easier. The evaluation is\nthorough and convincing, demonstrating very good results.\n\nThe presented results show that the new method beats the performance of existing\nmethods; however, as only very limited hyperparameter tuning for the other\nmethods was performed, it is unclear to what extent this will hold true in\ngeneral. As the main focus of the paper is on the increased interpretability of\nthe learned models, this is only a minor flaw though.\n\nThe interpretability of the final models is measured in terms of their size.\nWhile this is a reasonable proxy that is easy to measure, the question remains\nto what extent the models are really interpretable by humans. This is definitely\nsomething that should be explored in future work, as a small-size model does not\nnecessarily imply that humans can understand it easily, especially as the\ngenerated algebraic expressions can be complex even for small trees.\n\nThe description of the proposed method could be improved; in particular it was\nunclear to this reviewer why the features needed to be differentiable and what\nthe benefit of this was (i.e. why was this the most appropriate way of adjusting\nweights).\n\nIn summary, the paper should be accepted.', ""This paper introduces a genetic algorithm that maintains an archive of representations that are iteratively evolved and selected by comparing validation error. Each representation is constructed as a syntax tree consists of elements that are common in neural network architectures. The experimental results showed that their algorithm is competitive to the state-of-the-art while achieving much smaller model size.\n\nComments:\n1. I think this paper lacks technical novelty. I'm going to focus on experimental result in the following two questions.\n2. FEAT is a typical genetic algorithm that converges slowly. In the appendix, one can verify that FEAT converges at least 10x slower than XGBoost. Can FEAT achieve lower error than XGBoost when they use the same amount of time? \nCan the authors provide a convergence plot of their algorithm (i.e. real time vs test error)?\n3. From Figure 3 it seems that the proposed algorithm is competitive to XGBoost, and the model size is much smaller than XGBoost. Have the authors tried to post-processing the model generated by XGBoost? How's the performance compare?"", '# Summary\nThe paper presents a method for learning network architectures for regression tasks. The focus is on learning interpretable representations of networks by enforcing a concise structure made from simple functions and logical operators. The method is evaluated on a very large number of regression tasks (99 problems) and is found to yield very competitive performance.\n\n# Quality\nThe quality of the paper is high. The method is described in detail and differences to previous work are clearly stated. Competing methods have been evaluated in a fair way with reasonable hyperparameter tuning.\n\nIt is very good to see a focus on interpretability. The proposed method is computationally heavy, as can be seen from figure 7 in the appendix, but I see the interpretability as the main benefit of the method. Since many applications, for which interpretability is key, can bear the additional computational cost, I would not consider this a major drawback. However, it would be fair to mention this point in the main paper.\n\n# Clarity\nThe paper reads well and is nicely structured. The figures and illustrations are easy to read and understand.\n\n# Originality\nThe paper builds on a large corpus of previous research, but the novelties are clearly outlined in section 3. However, the presented method is very far from my own field of research, so I find it difficult to judge exactly how novel it is.\n\n# Significance\nThe proposed method should be interesting to a wide cross-disciplinary audience and the paper is clearly solid work. The focus on interpretability fits well with the current trends in machine learning. However, the method is far from my area of expertise, so I find it difficult to judge the significance.\n']","[80, -20, 80]","[70, 20, 90]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe the approach as 'very interesting' and the evaluation as 'thorough and convincing'. The reviewer also recommends acceptance of the paper. The only criticisms are minor and presented constructively. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the work, and frames criticisms as suggestions for improvement or future work. The reviewer maintains a professional tone and avoids harsh or dismissive language. The use of phrases like 'very interesting approach' and 'thorough and convincing' demonstrates respect for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (competitive results, smaller model size), they express concerns about the lack of technical novelty and the algorithm's slow convergence. The overall tone suggests skepticism rather than enthusiasm. The politeness score is mildly positive (20) as the reviewer uses neutral language and phrases their criticisms as questions or suggestions rather than harsh statements. They also begin with a neutral summary of the paper before moving into their concerns. The reviewer maintains a professional tone throughout, avoiding personal attacks or overly negative language, which contributes to the slightly positive politeness score."", ""The sentiment score is 80 (positive) because the review is overwhelmingly positive. The reviewer describes the paper as 'high' quality, praises its focus on interpretability, and notes that it 'reads well' and is 'nicely structured'. The only slight criticism is about computational heaviness, but this is not considered a major drawback. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise generously (e.g., 'It is very good to see...', 'The paper reads well...') and frame their one suggestion for improvement very gently ('it would be fair to mention...'). The reviewer also humbly acknowledges when certain aspects are outside their expertise, which adds to the polite tone.""]"
"['Quality: This submission claims to present a model that can control non-annotated attributes such as speaking style, accent, background noise, etc. Though empirical evidence in the form of numerical measurements is presented for some controllable attributes more evidence other than individual samples and authors claims is needed. For example a reliable numerical evidence is needed on page 4 following ""We also found..."", page 5 following ""We discovered...."", page 5 following ""It clearly presents..."", page 5 following ""Drawing samples..."" evidence is given only for 1 dimension, page 6 following ""Figure 7(b)..."". \n\nClarity: The model is simple though the exact form and nature of observed and latent class variables could be made more explicit. Including how they are computed/initialised/set. What are different modes using the proposed model? Why both negative results are in the appendix? \n\nOriginality: moderately\n\nSignificance: moderately\n', 'This paper proposes a two layer latent variable model to obtain disentangled latent representation, thus facilitates fine-grained control over various attributes including noise level, speaker rate etc.\n\nDetailed comments:\n\ni) This work is closely related to Akuzawa et al. (2018). The difference is not properly discussed. \n\nii) In the abstract, “end-to-end text-to-speech” is an unfortunate claim, because the proposed system has two separately trained component: 1) a text to mel-spectrogram model based on Tacotron and, 2) a WaveRNN for waveform synthesis.  In ASR, it’s absolutely fine to claim a spectrogram to text model as a end-to-end system, because the wave to spectrogram step is trivial.  In TTS, waveform synthesis is a very crucial step and largely determines the final naturalness results. \n\niii) In experiment, one need include the MOS score of ground truth for comparison or debiasing.\n\niv) Did you try different values of D other than 16? When you check the meaning of different dimensions, how many dimensions are meaningful? How many are meaningless, or even just dummy?\n\nIn summary,  \npros:\n- A good work with impressive results.\ncons:\n- Related work need to be properly discussed. \n- Doesn’t include the MOS of ground truth.\n- Moderate novelty. ', 'The authors describe the conditioned GAN model to generate speaker conditioned Mel spectra. They augment the z-space corresponding to the identification with latent variables that allow a richer set of produced audio. In a way this is like a partially conditioned model that has ""extra"" degrees of freedom. It looks that the ""latent"" variables are just concaneted to the ""original"" set of z-values (altough with particular conditions to maximize independence). The conditioning of the z-space has originality in it and may provide interesting to the audience. Ultimately one coud think about z-space direction being totally mapped to specific features of the produced signal.\n\nAlso, I am curious to know how the Mel spectra are used to produce the actual sound wave - as the phase information is not present if utilizing only the spectral amplitude. Very often this leads to suboptimal generation, and the remedy is to use the time domain like in ( https://arxiv.org/ftp/arxiv/papers/1810/1810.05319.pdf).  However, in this case the audio samples show a pretty nice generation of sound.  However, it is not really end to end.\n\nThe manuscript has some curious decisios in its concepts - I do not see the architecture really hiearchial, nor end to end. I would prefer modifications on the paper that concentrate on the truly novel features. \n\nThe paper is clear, well written and done with high ambition, from data set utilization  to novel architetures to human quality panels. Results are good and interesting.\n\nNEW:\nThe authors have addressed the concerns I had with the manuscript.\n\n\n\n']","[-30, 50, 70]","[20, 60, 80]","[""The sentiment score is slightly negative (-30) because the reviewer expresses several criticisms and requests for more evidence, using phrases like 'more evidence other than individual samples and authors claims is needed' and 'reliable numerical evidence is needed'. However, it's not extremely negative as the reviewer also notes some positive aspects like 'empirical evidence in the form of numerical measurements is presented for some controllable attributes'. The politeness score is slightly positive (20) because the reviewer uses neutral, professional language without harsh criticism. They phrase their concerns as requests for additional information rather than direct criticisms. The use of phrases like 'could be made more explicit' and 'Why both negative results are in the appendix?' indicate a polite questioning tone rather than an accusatory one."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the paper as 'a good work with impressive results' in the summary, but also lists several cons and areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 60 (moderately polite) because the reviewer uses neutral language and provides specific, constructive feedback without using harsh or dismissive terms. The reviewer points out both pros and cons in a balanced manner, and phrases suggestions as questions or observations rather than direct criticisms."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, noting its originality, clarity, and good results. They mention that the authors have addressed their previous concerns, which is a strong positive indicator. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and expressing curiosity rather than criticism. They offer suggestions for improvement in a constructive manner. The reviewer's tone is professional and courteous, avoiding harsh or dismissive language even when pointing out areas for potential modification.""]"
